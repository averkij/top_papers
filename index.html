
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF (10 статей)</title>
    <link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0989eacf;
            --secondary-color: #fff;
            --background-color: #f5f5f5;
            --text-color: #333333;
            --header-color: #0989eacf;
            --body-color: #f5f5f5;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        header {
            padding: 1.6em 0;
            text-align: center;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2em;
            padding: 10px 0 20px 0;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.tags {
            color: #555;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
            transition: background-color 0.2s ease;
            display: flex;
            flex-direction: column;
            position: relative;
        }
        .article-content {
            padding: 1.5em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
        }
        body.dark-theme>div>main>article {
            background-color: #444;
        }
        body.light-theme>div>main>article {
            background-color: #fff;
        }
        body.dark-theme>div>main>article:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
        }
        .pub-date {
            font-size: 0.9em;
            margin-bottom: 0.8em;
            font-weight: 300;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 1em;
            position: absolute;
            bottom: 10px;
            font-weight: 300;
            font-family: 'Roboto Slab';
        }
        .background-digit {
            position: absolute;
            bottom: -20px;
            right: -10px;
            font-size: 12em;
            font-weight: bold;
            color: rgba(0, 0, 0, 0.03);
            z-index: 0;
            line-height: 1;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 80px;
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        a:hover {
            color: var(--secondary-color);
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 1em 0;
            margin-top: 2em;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
        }
        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
        }
        .update-info-container {
            flex: 1;
        }
        .sort-container {
            flex: 2;
        }
        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .category-toggle {
            display: none;
            margin-bottom: 10px;
            margin-top: 15px;
            cursor: pointer;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }

        .svg-container span {
            position: relative;
            z-index: 1;
        }

        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .sort-container {
                margin-top: 0px;
                text-align: left;
                width: 100%;
            .sort-dropdown {
                float: right;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiffRu(dateString) {
        const timeUnits = {
            minute: ["минуту", "минуты", "минут"],
            hour: ["час", "часа", "часов"],
            day: ["день", "дня", "дней"]
        };

        function getRussianPlural(number, words) {
            if (number % 10 === 1 && number % 100 !== 11) {
                return words[0];
            } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                return words[1];
            } else {
                return words[2];
            }
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);

        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes == 0) {
            return 'только что';
        }
        else if (minutes < 60) {
            return `${minutes} ${getRussianPlural(minutes, timeUnits.minute)} назад`;
        } else if (hours < 24) {
            return `${hours} ${getRussianPlural(hours, timeUnits.hour)} назад`;
        } else {
            return `${days} ${getRussianPlural(days, timeUnits.day)} назад`;
        }
    }
    function formatArticlesTitle(number) {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;

        let word;

        if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
            word = "статей";
        } else if (lastDigit === 1) {
            word = "статья";
        } else if (lastDigit >= 2 && lastDigit <= 4) {
            word = "статьи";
        } else {
            word = "статей";
        }

        return `${number} ${word}`;
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">
            <h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">хф дэйли</h1>
            <p>22 октября | 10 статей</p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 Сортировка по</label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="category-toggle">
            <div class="svg-container">
                <span id="category-toggle">🔍 Фильтр</span>
                <svg height="3" width="200">
                    <line x1="0" y1="0" x2="200" y2="0" 
                        stroke="black" 
                        stroke-width="2" 
                        stroke-dasharray="3, 3" />
                </svg>
            </div>
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">градиент обреченный</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>    
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "хф найтли";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "хф дэйли";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2410.13861', 'title': 'PUMA: Empowering Unified MLLM with Multi-granular Visual Generation', 'url': 'https://huggingface.co/papers/2410.13861', 'abstract': 'Recent advancements in multimodal foundation models have yielded significant progress in vision-language understanding. Initial attempts have also explored the potential of multimodal large language models (MLLMs) for visual content generation. However, existing works have insufficiently addressed the varying granularity demands of different image generation tasks within a unified MLLM paradigm - from the diversity required in text-to-image generation to the precise controllability needed in image manipulation. In this work, we propose PUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA unifies multi-granular visual features as both inputs and outputs of MLLMs, elegantly addressing the different granularity requirements of various image generation tasks within a unified MLLM framework. Following multimodal pretraining and task-specific instruction tuning, PUMA demonstrates proficiency in a wide range of multimodal tasks. This work represents a significant step towards a truly unified MLLM capable of adapting to the granularity demands of various visual tasks. The code and model will be released in https://github.com/rongyaofang/PUMA.', 'score': 12, 'issue_id': 208, 'pub_date': '2024-10-17', 'pub_date_ru': '17 октября', 'hash': '31995f0502d70f2f', 'data': {'desc': 'Статья представляет PUMA - новую модель многомодального большого языкового моделирования (MLLM) для генерации визуального контента. PUMA объединяет визуальные признаки разной гранулярности как для входных, так и для выходных данных MLLM, что позволяет решать различные задачи генерации изображений в рамках единой парадигмы. Модель демонстрирует высокую эффективность в широком спектре мультимодальных задач после предварительного обучения и тонкой настройки под конкретные инструкции. Это значительный шаг к созданию унифицированной MLLM, способной адаптироваться к требованиям гранулярности различных визуальных задач.', 'emoji': '🐆', 'title': 'PUMA: Универсальная MLLM для мультигранулярной генерации изображений', 'categories': ['#multimodal', '#nlp', '#cv', '#training', '#code'], 'embedding': [-0.005515939772697067, 0.08036688959128836, 0.06423204261641437, 0.053219372279397284, -0.06356616236074848, -0.04141276439943629, 0.07929123339975691, 0.08000833616014379, -0.030630592257236897, 0.040516387999903834, 0.037391862383800316, -0.02111615608463256, -0.07519349249966162, -0.002165718674060336, -0.046714212625487625, -0.02635357976894717, -0.005365475639119662, -0.04602272009198567, 0.039312674521094375, 0.03411366925353385, 0.07114697615523845, -0.07498860863363112, -0.050683898289256034, 0.011313598604171898, -0.005563960127403196, -0.07524471500438261, -0.02952932583882053, 0.10510697994556051, -0.0012573333403179668, 0.026865796612352402, -0.014060364246990283, -0.04420434886223129, -0.11125359027022787, -0.04507512118773224, -0.02016855512942799, 0.09937014965866098, -0.08333775384608237, 0.15315296128618447, -0.0382882408342839, 0.10807784009845223, 0.017428191120402822, -0.1633973002052403, 0.04778986881701907, 0.0494545766345128, 0.03785285672248457, 0.08507928414042629, 0.01854226572868836, 0.08384996863853646, 0.0035471044093652836, 0.056036569020028355, -0.03191113641670112, 0.034805161787035806, -0.00571442364569526, 0.013394481325087908, -0.05808543844460043, -0.07345195810341543, 0.008822941588151246, -0.017261721569224134, -0.06546136632210876, 0.01998927943933127, -0.03926145406732453, -0.07478372476760063, 0.04317991517542082, -0.03467711065261121, -0.07744724784121534, -0.08180109921396438, -0.052809600445434014, -0.026481631928847334, 0.014879910991343543, -0.01122396075912354, 0.022972943680189886, -0.11391712154764715, 0.0385187390291016, -0.0052118107911932054, -0.012542919848724916, 0.027224347992545837, -0.053731593224704804, 0.038569961533822576, -0.06827856306273983, -0.02270403117052038, 0.031834303685095225, 0.0338063403780614, -0.03411366925353385, -0.011620929120405266, -0.03962000749846911, -0.031450140027065726, 0.019669142373989645, -0.013279232842964402, -0.06674190843062183, -0.062490508220168176, -0.042770141290506415, 0.01594276206943253, -0.06643458365705167, 0.050863173979352756, 0.0539364770907353, 0.08579638895176431, -0.008189073398258605, -0.09102100649716087, 0.09009902192169465, 0.09091856558962119, -0.0420018180763497, 0.00494609797039718, 0.0419249853447438, -0.0420018180763497, 0.049582631870839666, -0.07186407686467418, -0.02347235643562823, 0.012638960558137175, 0.012498101438938522, 0.07360562151567608, -0.043692134069777205, -0.016288510387134646, -0.005784853718032372, 0.036393038923874764, 0.07293973920905905, -0.11985883570057716, 0.022396700244096783, 0.00028952282531782836, 0.020360636958442736, -0.009187897473469495, -0.045920277133494856, -0.004216188455806937, -0.02773656483595107, -0.13030808309707717, 0.05501213328226674, -0.08953558052261729, 0.009821766073552363, 0.0004902079226460264, -0.042898194475882154, -0.011294391036555766, 0.006085781164806725, 0.018567875955573278, 0.04202742625228348, -0.04973629528310033, -0.13932310036138973, -0.04358968700938411, -0.06679313093534282, 0.012542919848724916, -0.04661177171794794, 0.09506752694348632, 0.08000833616014379, -0.04968507482933049, -0.014854300764458622, 0.04361529928722016, -0.08052055505450016, -0.02600783247672062, -0.006098586688439413, 0.022371090017211864, -0.07760091535537827, 0.047226431519844, -0.09896037372279542, -0.08661594287444656, -0.04015783251780812, 0.006972557267148046, -0.0814937641856385, -0.06561502973436942, -0.06346371735130653, 0.11688797964958772, 0.03831385106116883, -0.10403132990688248, 0.07263240418073318, 0.03570154433942168, -0.0002671132922724487, 0.007042987339485158, 0.07145431118356432, 0.05619023653419129, -0.10623386274371521, 0.04458851252026079, -0.11494155113255533, -0.1270298838139573, -0.13030808309707717, -0.010769368054232502, -0.04371774634761326, -0.07616671188555567, 0.03255140849643324, -0.08041811414696048, -0.10992182360604268, -0.06981520949105326, -0.06643458365705167, -0.14249883412555628, 0.0033166068298329282, 0.11709286146466709, -0.06920054763820606, -0.026507243181207823, -0.07155675209110401, -0.024240681700736084, 0.04469095752970275, 0.11760508651187689, 0.009239118542524674, 0.048430140896751184, -0.09035512419054384, 0.09194299722548052, 0.04983873824159115, 0.09686028179350237, 0.09337720479720542, -0.021346654279450254, 0.09409430960854341, -0.010551675383047493, -0.043794574977316876, 0.023690048491527897, -0.008310725565126468, 0.14936254721061049, -0.04090054960698219, -0.07350317650623413, -0.009988236650206622, -0.030374483835534278, -0.009373576027930113, 0.010859006104375974, -0.08569394804422462, -0.0013757835622660948, 0.019541087137662765, 0.02018135921739488, 0.1481332276068184, -0.06018552832294234, -0.022243034780884983, -0.11678553669109691, -0.08507928414042629, 0.06576869929948351, 0.008381154406892894, -0.053321817288839245, 0.03649547983141445, -0.03106597841998737, 0.07647404076102812, 0.08856236318767438, -0.05552435422757426, -0.002914836371552054, 0.01589154059018712, -0.07570571344496914, 0.043948240440528676, -0.05460235939735233, 0.06914932718443623, -0.017786744551547398, -0.04264208810513067, -0.03093792318366049, 0.004958903288934754, -0.09491385532742111, 0.0882550322612508, -0.046406881699064026, 0.09588707266236401, -0.03260262895020307, 0.058802541204987305, 0.08016199957240444, 0.030553759525630997, -0.04599710986510075, -0.035855207751682334, 0.1026483407379763, -0.05306571091808777, 0.016480590165198254, 0.09665539997842301, 0.042257926498052316, 0.10018969742848981, -0.022089369317673187, -0.15243586467865103, 0.04279575151739133, -0.02198692430823123, 0.07647404076102812]}}, {'id': 'https://huggingface.co/papers/2410.14940', 'title': 'Baichuan Alignment Technical Report', 'url': 'https://huggingface.co/papers/2410.14940', 'abstract': "We introduce Baichuan Alignment, a detailed analysis of the alignment techniques employed in the Baichuan series of models. This represents the industry's first comprehensive account of alignment methodologies, offering valuable insights for advancing AI research. We investigate the critical components that enhance model performance during the alignment process, including optimization methods, data strategies, capability enhancements, and evaluation processes. The process spans three key stages: Prompt Augmentation System (PAS), Supervised Fine-Tuning (SFT), and Preference Alignment. The problems encountered, the solutions applied, and the improvements made are thoroughly recorded.   Through comparisons across well-established benchmarks, we highlight the technological advancements enabled by Baichuan Alignment. Baichuan-Instruct is an internal model, while Qwen2-Nova-72B and Llama3-PBM-Nova-70B are instruct versions of the Qwen2-72B and Llama-3-70B base models, optimized through Baichuan Alignment. Baichuan-Instruct demonstrates significant improvements in core capabilities, with user experience gains ranging from 17% to 28%, and performs exceptionally well on specialized benchmarks. In open-source benchmark evaluations, both Qwen2-Nova-72B and Llama3-PBM-Nova-70B consistently outperform their respective official instruct versions across nearly all datasets. This report aims to clarify the key technologies behind the alignment process, fostering a deeper understanding within the community. Llama3-PBM-Nova-70B model is available at https://huggingface.co/PKU-Baichuan-MLSystemLab/Llama3-PBM-Nova-70B.", 'score': 9, 'issue_id': 208, 'pub_date': '2024-10-19', 'pub_date_ru': '19 октября', 'hash': 'e1222b08a95a2911', 'data': {'desc': 'В статье представлен детальный анализ методов выравнивания (alignment), применяемых в серии моделей Baichuan. Описываются три ключевых этапа: система расширения промптов (PAS), контролируемая тонкая настройка (SFT) и выравнивание предпочтений. Исследуются критические компоненты, улучшающие производительность модели в процессе выравнивания, включая методы оптимизации, стратегии работы с данными и процессы оценки. Результаты показывают значительные улучшения в основных возможностях моделей и их превосходство над официальными версиями на различных бенчмарках.', 'emoji': '🧠', 'title': 'Революция в выравнивании языковых моделей: метод Baichuan Alignment', 'categories': ['#alignment', '#optimization', '#benchmark'], 'embedding': [0.03515107729354385, -0.012261695083905465, 0.21489185304466513, -0.046203874065898105, -0.03663895588269507, -0.027631987140123184, 0.028747895602910353, -0.0001923154808563981, -0.05659243737471371, 0.004267680744370783, 0.03172364703229786, -0.028296218687356853, -0.06562597568578374, -0.039349015459711104, 0.061587454930605336, 0.050561225810444255, -0.000572483674887895, -0.11966776514555533, -0.02599798071499462, 0.0742875362052698, 0.024496821174204278, 0.02549316657874981, 0.032998970989768915, 0.11074050894108783, 0.0507472089573213, -0.044530012329869834, 0.02125537501798783, -0.03480567865198292, -0.02486879034241584, -0.15091317527532644, 0.04880765536892156, -0.05088005679981202, -0.05098633315749962, -0.003723011872117762, -0.11775477920934876, 0.10505469410207434, -0.037196905323326215, 0.01317833293273955, -0.014559932864637202, -0.00926601484928512, -0.01353701712507154, -0.01745597654668277, -0.0595150515834099, 0.013111909969646679, -0.014334094406860452, 0.013151763939132899, 0.05141144050455498, 0.0423779060260949, -0.06977077279864971, 0.038100259154433214, -0.06621049277860805, 0.105904912628795, -0.025838566178463224, -0.021029536560211077, 0.04771831839093751, 0.03206904759016377, 0.01628693086320429, 0.10016595865278523, 0.07742270696195115, 0.02380602101662496, -0.008555288377669428, -0.09708392703310018, -0.03942872224890055, 0.05359011446052307, -0.07960138283422423, -0.16154086853323527, -0.10834927843713459, 0.006841574013568425, -0.0002013448684508892, -0.08613741045104346, 0.018053785130823567, 0.08326793537934354, 0.01733641636289859, 0.04503482838241962, 0.06780464964175184, -0.012620379084606958, -0.011059437535619556, 0.17663217264663308, 0.01995348340832361, 0.011750237118307385, -0.10059106408353562, -9.989404072554533e-05, 0.06100293017256112, -0.06913310698730425, 0.06211883671904332, 0.01800064695197977, -0.003349382225644129, 0.017695100746861078, -0.06488203543305562, -0.07226827966029056, -0.033689772105500726, -0.04240447559459304, -0.019036845751120024, 0.002763198905642816, 0.09671196457195602, 0.05616733002765834, -0.03182992530629043, 0.008820980996562896, 0.018598452661663108, 0.07694445856159453, 0.032255034569650766, -0.038551937986291696, 0.06063096196250205, -0.0036300197237877454, 0.18056441129520895, -0.09107928312102388, 0.05839914503692771, -0.045008258813921474, -0.07338419003938272, 0.07960138283422423, -0.09564918758094523, 0.08921944207072852, -0.08385245438847284, 0.01924940038280019, -0.012919282993416364, -0.02408499861139799, 0.020617713039252302, 0.016433062531791588, -0.04360008893026469, 0.00454001546794304, -0.00688807027936393, 0.023314490706476728, 0.08847550181800043, -0.05558280910222408, 0.014121540733332771, -0.03464626124099406, 0.0902290741758281, -0.06743268334799774, -0.060896653814873525, -0.10500155496507804, 0.044025196277320044, 0.024975066700103438, 0.03754230971380207, -0.0553171172498526, -0.12211214628433473, -0.053616685945326197, -0.04522081152929667, -0.019647938161357407, -0.12731970505777168, -0.02888074152909609, 0.028083664055676683, -0.08900688552274337, -0.03090000190668529, -0.07779467517201022, -0.0953303623404924, 0.02654265016213913, -0.0007435230156455807, -0.060896653814873525, 0.043228122636510595, 0.03980069045895963, -0.08496836285126001, -0.033450645989017445, -0.0915575315213805, -0.02922614017065702, -0.03748916866050081, 0.02516105176328546, -0.05813345318455623, 0.014201247522522224, 0.07109923014420214, -0.1044701712603351, 0.04580533628734088, -0.025014920094698162, -0.019594799982513608, -0.012527387702798933, 0.07131178860849226, -0.017216854262809438, -0.06764523223076298, 0.02164062897044846, -0.15750233244761708, -0.08704076044954051, 0.07556286016274086, 0.012195272120812596, -0.0046130807273451965, -0.0734373215111591, 0.04277644380465211, -0.04673525777064105, -0.034486849578920134, -0.13932899671453422, -0.09724334444408902, -0.08204574864256381, 0.021959459959816224, 0.0064131453267279245, -0.039774120890461485, 0.023221498174885717, -0.10904007763656141, 0.0009149775047133593, -0.015011608822038214, 0.020723991313244875, -0.0010320481783765638, 0.04753233524406046, 0.004510125326181747, 0.0789105836347974, 0.13220842900923094, 0.051517716862242574, -0.01563598697467716, -0.06031212905682931, 0.03637326019771364, -0.014719347401168596, 0.07859174881281968, -0.03111255653836546, 0.00519428261256029, -0.04997670488500999, 0.1281699197518824, -0.06865486433586256, -0.03966784453277389, -0.05935563608872602, 0.0027399508685603115, 0.014878762895852476, -0.12094309293563635, -0.06344729406459572, 0.045699058013348316, -0.008003977400737617, 0.1173296718622934, -0.009305869202032333, -0.14007292546943245, -0.011079364424547416, -0.14272984399314723, -0.022610405764648334, -0.036506108040204356, 0.011922937205609841, 0.0772632895509623, -0.00874127363248195, 0.09293912992023418, 0.08193947228487622, -0.048276271664178604, 0.08077043426661763, 0.00026278619746182216, -0.0096246999997696, 0.08720017402791942, -0.09469269652914691, 0.023992005121654492, 0.006994346828682023, 0.061587454930605336, 0.017057438768125554, 0.016074378147829096, -0.04046492008988832, 0.001531881550541898, 0.012666875542032963, 0.042670167446964516, -0.08826295101893021, -0.006702085599442901, 0.0009075049309469364, 0.037250046376627474, -0.0017568896733723635, 0.04245761473158932, 0.09256716362648008, -0.04110258206862385, -0.10282288100910995, 0.038047121933741906, 0.0028063740232836783, 0.044742566961550004, 0.04604445857121422, -0.07800722597108044, -0.043174979666904346, -0.00022044150100096872, 0.03950842903809001]}}, {'id': 'https://huggingface.co/papers/2410.16256', 'title': 'CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution', 'url': 'https://huggingface.co/papers/2410.16256', 'abstract': 'Efficient and accurate evaluation is crucial for the continuous improvement of large language models (LLMs). Among various assessment methods, subjective evaluation has garnered significant attention due to its superior alignment with real-world usage scenarios and human preferences. However, human-based evaluations are costly and lack reproducibility, making precise automated evaluators (judgers) vital in this process. In this report, we introduce CompassJudger-1, the first open-source all-in-one judge LLM. CompassJudger-1 is a general-purpose LLM that demonstrates remarkable versatility. It is capable of: 1. Performing unitary scoring and two-model comparisons as a reward model; 2. Conducting evaluations according to specified formats; 3. Generating critiques; 4. Executing diverse tasks like a general LLM. To assess the evaluation capabilities of different judge models under a unified setting, we have also established JudgerBench, a new benchmark that encompasses various subjective evaluation tasks and covers a wide range of topics. CompassJudger-1 offers a comprehensive solution for various evaluation tasks while maintaining the flexibility to adapt to diverse requirements. Both CompassJudger and JudgerBench are released and available to the research community athttps://github.com/open-compass/CompassJudger. We believe that by open-sourcing these tools, we can foster collaboration and accelerate progress in LLM evaluation methodologies.', 'score': 7, 'issue_id': 208, 'pub_date': '2024-10-21', 'pub_date_ru': '21 октября', 'hash': '3b5265f629378d5d', 'data': {'desc': 'В статье представлен CompassJudger-1 - первая открытая универсальная модель-оценщик для больших языковых моделей (LLM). Эта модель способна выполнять разнообразные задачи оценки, включая сравнение моделей, генерацию критики и выполнение общих задач как обычная LLM. Авторы также создали бенчмарк JudgerBench для сравнения различных моделей-оценщиков. CompassJudger-1 и JudgerBench доступны сообществу исследователей для дальнейшего развития методов оценки LLM.', 'emoji': '⚖️', 'title': 'CompassJudger-1: Универсальный судья для языковых моделей', 'categories': ['#benchmark', '#nlp'], 'embedding': [0.016274579779880796, -0.002393027390890161, 0.09294445244371195, 0.01037587459419362, -0.008482709678535198, -0.013883212012686044, 0.00529422011163281, 0.0008054256015571237, 0.062228675825496266, 0.04360258687461549, 0.04724277707125545, -0.09097821672401848, 0.023847240429211092, -0.03608306674452624, 0.03682704980104672, -0.03138004445573983, 0.0003391921148130687, -0.0171514136411556, -0.012893452697967864, 0.10208479146498968, 0.04623309043183311, -0.020618894436846474, 0.08460124193167878, -0.0869394701663291, 0.04673793375154428, -0.10989659086443267, -0.051998942839372744, -0.007851654048851318, 0.04296488880336355, -0.1001716992246271, 0.09459184110117266, -0.03231002376973873, -0.03650819681863432, 0.043257168072717296, -0.02835098256407958, 0.12137514825339463, -0.011711054684203205, 0.012587889137495973, -0.03347913492697407, 0.06010301756138304, -0.026477744973125324, 0.00313036563777072, 0.01178412430420232, -0.024352084735618874, -0.07184728445342653, 0.0015518974226670123, 0.0764174539640654, 0.09788661446930766, -0.08922455492164853, 0.05303519924506731, -0.07572661636026902, 0.08077505547756039, 0.08720517374923098, -0.0038295080695810633, 0.06031558161174047, -0.05468258790252803, -0.06647999630050917, 0.08226301369702847, 0.030104650286629182, -0.03549851017921197, 0.012727384949229537, -0.03850100625138644, 3.669045744275317e-05, -0.04049381173735213, -0.08438867393453492, -0.03929812489366493, -0.036215921496067005, -0.015490742073951992, 0.024405226241556534, 0.01001052708621601, 0.032575731299427035, 0.016473858947102116, 0.051520667312540576, -0.03868699856207843, -0.04617995089928866, 0.00470966394099718, 0.1435882819481913, 0.15634224732001642, -0.011000287782309444, 0.00872848889682273, -0.04780076387029751, 0.014109063906269408, 0.00510490381740629, -0.0655765867527825, 0.06477947403068365, 0.02708887130471182, -0.010123452934338032, 0.03199117078732633, -0.08029678389751466, -0.06860565653801562, -0.049368437308761906, 0.029387240943167362, 0.014547481231585453, 0.1081429152483102, 0.11584843558266429, -0.07253812600400933, -0.08040306493599676, -0.1086743303076868, 0.08927769050740654, 0.048411892175277214, -0.03850100625138644, 0.019343499281039216, 0.07142215635271167, -0.019795202081509335, 0.11117198503354332, 0.0007962919286581326, 0.00768558708947028, -0.037066185591069584, -0.00614116278851204, -0.0050484410906846, -0.1279646831493053, 0.037757023194865964, -0.16771451775031662, -0.05369946708259147, -0.01883865596132804, -0.17334751737970872, -0.03390426500108214, -0.05072354472347566, -0.0491824430246767, -0.10729265904688048, -0.07508892026241029, 0.03778359493453141, 0.0706781752695844, -0.09103136020334937, 0.09735519940993105, -0.09554838426126414, 0.009572109563560645, -0.021004169861546216, 0.0019380033696360128, -0.04572824711212193, -0.055532850024137395, 0.01080100664169491, 0.09607979932064074, -0.09246618086366622, -0.08353841181292557, 0.011166354741690481, -0.08545150405328815, -0.003935791081456386, -0.10320075914289414, -0.006373656531645495, -0.013776929395489364, 0.03470138956354027, -0.06169726076611966, 0.04551568108837129, -0.04524997355868298, -0.07269754854842911, -0.0681273750910038, 0.00734681013712218, -0.1490087214740124, 0.06047501007633988, -0.03940440987893347, -0.09746147847501994, -0.06424805897130705, 0.056011123577576344, -0.0507501164631411, -0.000555909743479477, -0.02642460346718766, 0.0393512683729958, -0.022053715097163328, -0.09671750133867911, 0.06573601719077513, 0.054470019905384165, 0.019303643644934275, 0.09193476580428961, 0.044479420735890285, 0.07593918238401966, -0.06079385713857264, 0.039856111692706975, -0.10798349467728365, 0.014932756656285193, 0.07918081029943057, -0.06153783624830668, -0.008542493626040914, -0.10771778714759533, 0.011219495260931535, -0.11669869967766687, -0.07455750520303368, -0.06733026236890498, -0.020021054961789308, -0.05813678184168957, -0.061750404245450544, 0.011923620313275207, -0.02469750551091028, 0.008250215738062422, 0.004394136520833884, -0.06169726076611966, -0.008363140599487834, 0.06456690011336015, -0.04450599444894894, -0.051068963525373844, -0.03650819681863432, 0.07827740469849032, 0.10394473825262818, 0.12626417074644591, 0.12498876671036917, 0.004012181922239529, 0.10288190813387495, 0.12466992556831606, -0.012315538574221645, -0.020300047374613724, 0.013225586616729942, 0.03209745774598809, 0.025348488465298327, -0.1411437726750589, 0.0045900956513071035, 0.07073131874891529, 0.022744554674352924, -0.029493523955042688, -0.07248498252467846, -0.06706455483921667, 0.1044230098326739, 0.057924217791332146, 0.11032172291193396, 0.027421005223473897, -0.03502023662577302, -0.0003043180138751861, -0.02750071649568378, 0.02380738479310615, -0.03478110083575015, 0.0826350042385921, -0.015623596825492752, 0.07657687848187837, 0.03199117078732633, 0.010947145684353817, -0.07657687848187837, 0.04113150586181763, 0.049049590246529155, -0.07365409960209345, 0.0649388946017102, -0.03581735921483794, 0.05893390443075449, -0.012607817251557426, -0.10771778714759533, -0.0187988003252231, -0.005998344966637161, -0.08135961401626789, -0.047003641281232585, -0.01971549080929945, 0.12753955504859046, -0.05207865608497585, 0.06206925130768329, -0.006234160325233286, 0.019861630443976323, -0.06796795451997725, 0.04227404922617395, 0.011046785465303797, -0.06233496278415803, -0.08082819895689126, 0.10522014228870492, 0.030104650286629182, 0.024883499794995486, 0.02138944725963917, 0.010302804579515861, -0.021256594481491628, -0.03478110083575015, 0.036109638484191686]}}, {'id': 'https://huggingface.co/papers/2410.16271', 'title': 'FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without Learned Priors', 'url': 'https://huggingface.co/papers/2410.16271', 'abstract': 'Neural Radiance Fields (NeRF) face significant challenges in few-shot scenarios, primarily due to overfitting and long training times for high-fidelity rendering. Existing methods, such as FreeNeRF and SparseNeRF, use frequency regularization or pre-trained priors but struggle with complex scheduling and bias. We introduce FrugalNeRF, a novel few-shot NeRF framework that leverages weight-sharing voxels across multiple scales to efficiently represent scene details. Our key contribution is a cross-scale geometric adaptation scheme that selects pseudo ground truth depth based on reprojection errors across scales. This guides training without relying on externally learned priors, enabling full utilization of the training data. It can also integrate pre-trained priors, enhancing quality without slowing convergence. Experiments on LLFF, DTU, and RealEstate-10K show that FrugalNeRF outperforms other few-shot NeRF methods while significantly reducing training time, making it a practical solution for efficient and accurate 3D scene reconstruction.', 'score': 4, 'issue_id': 208, 'pub_date': '2024-10-21', 'pub_date_ru': '21 октября', 'hash': 'b3e061a400165087', 'data': {'desc': 'FrugalNeRF - это новый фреймворк для обучения нейронных полей излучения (NeRF) на малом количестве данных. Он использует разделение весов воксельной структуры на разных масштабах для эффективного представления деталей сцены. Ключевой особенностью является схема геометрической адаптации между масштабами, выбирающая псевдо-истинную глубину на основе ошибок репроекции. FrugalNeRF превосходит другие few-shot NeRF методы, значительно сокращая время обучения.', 'emoji': '🔍', 'title': 'Эффективное 3D-моделирование с минимумом данных', 'categories': ['#3d', '#training', '#cv'], 'embedding': [-0.03694071877600098, 0.02145113013507428, 0.08497146772037195, -0.04407374240249534, 0.01811891474829646, -0.023325501546829122, 0.01904308512689144, 0.07065335710471493, -0.1405777942754569, 0.07914008976674149, 0.027152340441110537, 0.03962211029957759, -0.055345999474050736, 0.01191006355393563, 0.04977495270853159, 0.012645493205088338, 0.07060129168850808, -0.1152737925379978, -0.028532086291823248, 0.03904938866776373, -0.0039472421714598265, -0.05925093649264242, 0.05414848463360054, -0.06102117707198357, 0.017064582882722907, -0.022141004087199906, 0.12027211356462598, 0.04232953658479616, 0.05638731395880331, -0.045635717209932015, -0.03902335390612176, -0.04654687020770601, -0.080754129990385, -0.009332803684188139, -0.01231357360984651, -0.0030849015794874833, -0.03889319036560464, 0.0502956130312157, -0.09590529342596721, 0.0547212062654144, 0.03420726594329462, -0.09944577047757241, -0.06435339040522285, 0.014383191359146301, 0.014370174389033027, 0.042980356340920296, 0.006361796075407013, 0.060656712997920005, 0.07122608079006734, 0.08866814512767479, -0.04766628692384594, 0.08049380290935076, -0.08674170829971309, -0.029599435538217783, -0.04269399860532117, -0.030666786838150866, 0.002111921053983245, -0.08861608176500649, -0.011493536733265329, 0.02250546405418638, 0.08674170829971309, -0.08054586627201907, 0.09522844096173964, 0.08939706300810918, -0.019368495004953506, 0.03628989696633831, -0.0362117967884895, 0.042980356340920296, 0.08684583913212678, 0.09252101262298253, -0.02348169984898821, -0.08101446117849634, 0.14276456639860702, -0.09653008663460354, -0.010126807647312042, -0.0018857600284808323, 0.0014212349273640564, -0.003908192903950837, -0.03204653063532503, -0.045115060994325, 0.08294090211353511, -0.02996389550520426, -0.039361785272081895, -0.04454233320189551, -0.0946557152228487, -0.1521364131896885, -0.031135377637551035, -0.05227411322184569, -0.0777863766241322, 0.02083935636079747, 0.0684665973027961, -0.01770238936510314, -0.02889654728557899, 0.03688865335979414, 0.035066351471323226, 0.0518836205467558, 0.07002857005669423, -0.0021932740368833976, 0.15484382920721437, 0.10527715048474143, -0.011434962421294137, 0.030588686660302056, -0.012717083665757389, -0.10381931061679552, 0.07336078544347205, 0.01450033875096556, -0.0026586124419399355, 0.038945255781811496, 0.10532921590094826, 0.04821297790109492, -0.04888983241886102, -0.05977159476178798, 0.008694996996454048, -0.004406072296813582, -0.01831416313937995, -0.10168460596339081, -0.14213977729704777, 0.06601949809861175, 0.022921991490918243, 0.0023250656227570194, -0.045245224534842116, 0.06909138229727826, 0.05425261546601423, 0.07039302591660361, 0.09850859298584916, -0.058678214860828554, 0.10423582983937321, -0.0648219853117001, 0.01412286160851196, -0.033348178361727474, 0.05151915852623078, 0.07127815031335127, -0.03722708267221573, 0.019850105238713202, -0.1143366027250433, -0.012241983149177458, -0.058209619954351303, -0.09882098548309025, -0.06044845338663116, -0.013016462067839159, -0.008942310187682823, 0.011766881605828255, 0.05300303315581864, 0.04027293416277881, 0.03017216127710873, 0.11995971696030781, 0.023065172412256345, 0.038112202961886305, 0.054356748351966466, 0.13058114811512345, -0.09892511836904248, -0.03571717533452445, -0.11985558407435558, -2.364318395935572e-06, -0.06273935018157932, -0.10007056368620876, -0.022791825896862582, 0.07221533191215161, 0.002464992506920656, -0.07461036364659054, 0.005785817326110872, 0.11392008144892705, -0.06643602553534361, 0.02670978029627525, 0.05997985848015391, 0.034467590970790316, -0.12610348946471792, -0.07320458303423588, -0.09809206144204022, -0.028636217124236942, -0.04740595778927316, -0.003885414233021878, 0.007425891900688652, -0.02098253728213557, 0.03009406109925992, 0.052117914919686606, 0.01081668036731454, -0.006807610052062911, 0.06268728271183394, -0.026553583020885438, -0.08679377166238139, 0.08064999505089422, -0.06732114171793711, 0.14849180325213107, 0.009866478512739262, -0.03886715765750122, -0.06024018966826523, 0.01689536719974284, 0.02663168217196498, 0.018548459565849308, -0.0947598460552624, 0.06747734002009619, -0.029495302652265548, 0.06747734002009619, 0.03740931368247824, -0.045843980928297945, 0.12391672350218344, 0.020006303540872288, -0.008688488716751265, -0.03678452458091899, -0.03222876164558754, 0.04011673791415827, -0.001757222479781675, -0.026996142138951452, 0.10215320086986807, -0.09252101262298253, 0.058730280277035404, -0.04862950533782679, -0.058678214860828554, 0.024171571747575293, 0.05248237694021162, 0.1382868954269702, 0.08278469970429894, -0.042980356340920296, -0.10538128131715511, 0.004314957202390036, 0.024171571747575293, 0.04308449128041107, 0.04040309770329592, 0.07768224784525705, 0.07330871797372665, -0.015372441865169008, 0.07986901380779152, 0.06430132293547745, -0.017337927344578122, -0.09970610166568374, -0.004331227798970066, -0.05248237694021162, 0.12381259266976974, -0.13016462889254574, 0.047431988443838044, 0.019017052418788014, -0.04930635985559288, 0.02730853668973108, -0.04126218528486308, -0.04204317268858141, -0.009846953468277058, -0.06378066877340897, 0.004383294036592331, -0.020084401665182557, 0.0017002754944284955, 0.041288217992966496, 0.012691050957653965, -0.030120093807363343, -0.04967081982257936, 0.03316594735146496, -0.09460364569956477, -0.008428159582178485, 0.07820290816794115, -0.05675177597932832, 0.05982366017799483, 0.05982366017799483, 0.029703568424170025, -0.09731107814539897, 0.012437229486722408, 0.06586329979645267]}}, {'id': 'https://huggingface.co/papers/2410.16153', 'title': 'Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages', 'url': 'https://huggingface.co/papers/2410.16153', 'abstract': "Despite recent advances in multimodal large language models (MLLMs), their development has predominantly focused on English- and western-centric datasets and tasks, leaving most of the world's languages and diverse cultural contexts underrepresented. This paper introduces Pangea, a multilingual multimodal LLM trained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages. PangeaIns features: 1) high-quality English instructions, 2) carefully machine-translated instructions, and 3) culturally relevant multimodal tasks to ensure cross-cultural coverage. To rigorously assess models' capabilities, we introduce PangeaBench, a holistic evaluation suite encompassing 14 datasets covering 47 languages. Results show that Pangea significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions, language popularity, and the number of multimodal training samples on overall performance. We fully open-source our data, code, and trained checkpoints, to facilitate the development of inclusive and robust multilingual MLLMs, promoting equity and accessibility across a broader linguistic and cultural spectrum.", 'score': 3, 'issue_id': 208, 'pub_date': '2024-10-21', 'pub_date_ru': '21 октября', 'hash': '023f2f5e4c6c7a7c', 'data': {'desc': 'Статья представляет Pangea - мультиязычную мультимодальную языковую модель, обученную на разнообразном наборе данных PangeaIns, охватывающем 39 языков. Авторы также вводят PangeaBench - комплексный набор для оценки возможностей моделей на 47 языках. Результаты показывают, что Pangea значительно превосходит существующие модели с открытым исходным кодом в многоязычных настройках и разнообразных культурных контекстах. Исследование направлено на развитие инклюзивных и надежных мультиязычных мультимодальных языковых моделей, способствуя равенству и доступности в широком лингвистическом и культурном спектре.', 'emoji': '🌍', 'title': 'Pangea: Прорыв в мультиязычных и мультикультурных ИИ-моделях', 'categories': ['#dataset', '#data', '#benchmark', '#multilingual', '#multimodal'], 'embedding': [0.030188200774017154, 0.045429084658479175, 0.17936781913078717, -0.002360746610121973, -0.037625162058796555, -0.010806837214626164, 0.024671636429805677, 0.07417392894473197, -0.005739794772952588, 0.06551377973306738, 0.04430375308223484, -0.02316711869438294, -0.038138899671598295, 0.000728177179268848, 0.04175952704887067, -0.011926051843298384, -0.027130239184866945, -0.0836169125053979, -0.06634554431440483, 0.09697409249525878, 0.03799211925966839, 0.008849741674149087, -0.0550433168327666, 0.05054199258480495, 0.0541136938437726, -0.021589212810010944, -0.019558725417956363, 0.14012805197060474, -0.0035869892053141924, -0.004758188940331129, 0.09731658149443902, -0.00394477088197707, -0.14345510206789178, 0.030432837536587917, -0.02840235117304118, 0.04227326466167241, -0.007583745399337549, 0.08899892333897035, -0.028549133641986777, 0.05587507935708836, -0.0702108002261852, -0.0821001658116686, -0.02847574137900613, 0.03977796886064436, 0.021136632330836205, 0.04882953524680962, 0.07045544110278734, 0.12818976232383233, -0.01294129523077332, 0.08146410570355007, -0.06340990110654, 0.0611103118357466, -0.05152054374911939, -0.07304859736848764, 0.03623073168933694, 0.012201267789787352, 0.01986452034266197, 0.06389917463168152, -0.09296203971542295, -0.04503766336994712, -0.04425482490691441, -0.04535569239549853, 0.014629289921019422, -0.04449946166948517, -0.063997026868291, -0.03478737725858828, -0.0425668295995636, -0.020133621192892942, 0.031656021349441725, -0.004492145843930717, 0.03517879443308894, -0.04792438045950722, -0.09017318103351941, 0.034029000826200084, -0.03168048543710194, -0.03901959448527187, -0.06663910102423325, 0.017063426531404777, -0.10362821325998978, -0.04207755607442208, 0.014213407630350698, 0.03133799438090601, -0.041074544936478816, -0.030334981185947053, 0.06742194565831304, 0.08562293478128442, 0.05103127022397787, 0.02911179737309325, -0.07534818046823397, -0.021662603015975897, -0.012195151870723082, -0.11732788019201519, -0.06409488116191617, 0.03444488414537666, 0.04838918989698853, -0.008170874246612085, 0.024072276567208884, -0.06008283661014312, 0.08572079113192528, 0.12280775560429126, -0.03481184134624849, -0.032610104312064556, 0.02211517938111925, -0.0784306061450444, 0.09418522764230816, -0.05186303274829962, 0.04224880057401219, -0.026689891778030155, 0.03950886801041339, 0.04900078386043113, -0.15715478545604275, 0.051667324161049286, 0.03375989997596911, -0.025442243877516132, 0.04701922155817343, -0.0799473548957894, -0.043031639037044905, -0.06252920423585073, 0.09814834401876076, -0.04775313184588571, -0.05063984893544581, 0.03960672436105425, 0.0038499741364809, -0.06340990110654, 0.03319723418784693, -0.05372227666927193, -0.053771204844592364, -0.011620254450173947, 0.05015057746731998, 0.00253505050915521, -0.0776966999713635, 0.0734400145429883, 0.05254801897472286, -0.09589768909433488, -0.13513745625451729, 0.043398596237916746, -0.05548366218258769, 0.012647730292882131, -0.10666170870446406, -0.01157744383953034, -0.013503960401790782, 0.027619512710008468, 0.018213220138293632, 0.0369401799464047, -0.06888976417672192, -0.07764777179604307, -0.012201267789787352, 0.04613853085853124, 0.014176711498860375, 0.0892435642155725, -0.11732788019201519, -0.036817863622135016, -0.034591664557306556, 0.07118935139049963, -0.13572458201626827, 0.001984617279117073, -0.11996996257602022, 0.04300717700640039, 0.08043662842093091, -0.14785857613625963, 0.07965379818596098, 0.040658659560286546, 0.023607466101219728, -0.021051011109548993, 0.10871665915567101, 0.06071889054721454, -0.14159586843199792, -0.009864985061624025, -0.16057969601800204, -0.060963527309785305, -0.04533122830783832, -0.05636435288222988, -0.05249909285641813, -0.04917202836002125, -0.014506971539734041, -0.10675956711212062, -0.07916452054678806, -0.07975165042257046, -0.047728671872256885, -0.13621386376947256, -0.1010839872266256, 0.13689883765380165, -0.08904784945727508, 0.004736782812203049, -0.06365453581209507, 0.032610104312064556, -0.013858683296115245, 0.10127969787089162, -0.025809199021372273, 0.056168644294979544, -0.059789271672251926, 0.07334215407831605, 0.1746707883525909, 0.01752823802590178, 0.0345182764083573, -0.05391798525652227, 0.09535948327984152, 0.027668440885328896, -0.04961237370984233, 0.007351340680596895, 0.0471415419964745, 0.014996245064875565, -0.02759504862234825, -0.15255559868639318, -0.01743038167526092, -0.05998498025950226, -0.06952582428484043, 0.029503216604609608, -0.02086753148060523, 0.04190631157483196, 0.05734290404654432, 0.03706250038470578, 0.05318407496880998, 0.0136385106212047, -0.01959541949243099, -0.019277392523895282, -0.05988712802289279, 0.015485518590017087, -0.009033219246077159, 0.04139257396203022, 0.020060230986927993, -0.06292062552438278, 0.06203993071070921, 0.08459545955568094, -0.043325203974936104, -0.06076781872253498, -0.007302412916679604, -0.018421163854897612, 0.04425482490691441, -0.10010544017634254, 0.10069257005212494, -0.02742380206574244, 0.0020656533095694224, 0.04139257396203022, -0.002892831980116518, -0.06830263635795522, 0.031827267906047535, -0.034126855119825245, -0.03488522949519775, 0.0058559970294721295, 0.060865675073175834, 0.09173886001660055, 0.012286891068090257, -0.01139396626760227, 0.01357735143056201, 0.03439595597005622, 0.016219430934745066, -0.06135494859831735, 0.004626696474747776, -0.04481749069503658, 0.02815771441047042, -0.02144243034106535, -0.050199503585624715, -0.10587887641247845, -0.029331970048003798, 0.018947131454513766]}}, {'id': 'https://huggingface.co/papers/2410.14745', 'title': 'SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation', 'url': 'https://huggingface.co/papers/2410.14745', 'abstract': 'Supervised fine-tuning (SFT) is crucial in adapting large language models (LLMs) to a specific domain or task. However, only a limited amount of labeled data is available in practical applications, which poses a severe challenge for SFT in yielding satisfactory results. Therefore, a data-efficient framework that can fully exploit labeled and unlabeled data for LLM fine-tuning is highly anticipated. Towards this end, we introduce a semi-supervised fine-tuning framework named SemiEvol for LLM adaptation from a propagate-and-select manner. For knowledge propagation, SemiEvol adopts a bi-level approach, propagating knowledge from labeled data to unlabeled data through both in-weight and in-context methods. For knowledge selection, SemiEvol incorporates a collaborative learning mechanism, selecting higher-quality pseudo-response samples. We conducted experiments using GPT-4o-mini and Llama-3.1 on seven general or domain-specific datasets, demonstrating significant improvements in model performance on target data. Furthermore, we compared SemiEvol with SFT and self-evolution methods, highlighting its practicality in hybrid data scenarios.', 'score': 3, 'issue_id': 207, 'pub_date': '2024-10-17', 'pub_date_ru': '17 октября', 'hash': '863b95d8e45c3aa2', 'data': {'desc': 'Статья представляет новый полу-контролируемый метод тонкой настройки больших языковых моделей под названием SemiEvol. Этот подход эффективно использует как размеченные, так и неразмеченные данные для адаптации модели к конкретной задаче или домену. SemiEvol применяет двухуровневый метод распространения знаний и механизм совместного обучения для отбора высококачественных псевдо-ответов. Эксперименты на семи наборах данных показали значительное улучшение производительности модели по сравнению с традиционными методами тонкой настройки.', 'emoji': '🧠', 'title': 'SemiEvol: эффективная полу-контролируемая настройка языковых моделей', 'categories': ['#nlp', '#dataset'], 'embedding': [0.02396001414792346, -0.06013493568530362, 0.13936677064213313, -0.04065710826490381, -0.003498136610833921, 0.04657409995300698, -0.008526311046590546, 0.037889071325759756, -0.07201971278985864, 0.08999924929267838, 0.020849147457884663, -0.0514499070580564, -0.10472824358984163, 0.012989451159889321, 0.007739071532226059, -0.01890644553614779, 0.03735578266995749, -0.0992937509648156, -0.04350132959313559, 0.049012004539437576, 0.015249590103970135, -0.0343337977671877, 0.07725104911179587, 0.07653999067802027, 0.050738848624280804, -0.08217764374175866, 0.00015603926813809462, 0.12209829464090076, 0.03517182397934085, -0.03555274799259123, 0.11559722677208194, -0.05729071435707185, -0.11102615515557164, -0.03687328153906859, -0.03367353306176079, 0.11661301655877312, 0.08248237509467424, 0.07780973049614893, -0.015109918310413625, 0.05327833239616169, -0.09172608924189808, -0.13875729552943136, -0.005688439968308244, 0.06653443263991923, -0.0481231866667475, -0.03288629230670924, 0.005015476830794161, 0.11905091287395664, -0.004542498593455347, 0.03529880002896549, -0.008215225101320786, -0.031438786846230776, 0.016024132220153333, -0.02573765196111537, 0.00080747594748253, -0.021826849185655514, -0.006602653257704421, 0.010888028969340475, -0.027756539305845852, -0.038981049637162195, -0.029077068716699676, -0.03476550930535145, -0.02030315830218345, -0.02717245898950666, -0.06506152617964288, -0.05657966212673156, -0.18284269923547086, 0.025382124812039344, -0.016659001922436495, 0.05000240159757794, -0.01155464371793568, -0.07323866715088571, -0.003596541498434187, -0.02628363904900482, -0.020734870874253082, 0.02788351328765872, 0.04672646873118242, 0.09086266823338235, -0.03598446159856675, -0.05045950793210426, 0.028696148839072844, 0.006072536418378051, -0.05155148831131847, -0.025382124812039344, -0.005075789523850567, -0.06404573846076349, -0.0941132063034153, -0.029000884327611956, -0.05845887912537377, -0.10858825470476458, -0.024506003303624672, 0.005177369329644394, -0.04512659656034029, 0.013370373725671457, 0.05637650168801921, 0.003723515687028232, -0.01883026114706007, -0.09787164030069971, 0.04951990046668905, 0.11468301203521752, -0.06389336761477626, 0.032276817194007476, 0.031362602457143056, -0.10980720906579165, 0.10168086595852105, -0.08888187618491337, 0.012424416010306765, -0.011440367134304099, 0.04682804791663271, -0.05642729334855612, -0.08832318859712499, -0.03773670461539609, -0.024201263679462022, 0.05183082900349501, 0.041749086576306244, -0.16303473739454583, -0.045278965338515734, 0.06765180574768424, -0.016341566967904328, 0.006513771677216591, 0.00810729649304573, 0.010557896823408196, 0.02526784719450188, 0.023083892639508788, 0.07262918997037218, 0.013903664035723146, -0.012792641591469965, -0.0665852201648326, 0.010316645844401394, -0.03166734208130571, 0.08578370275743233, -0.01681137173451782, 0.08994845349651794, -0.01870328509743543, -0.13784309526724936, 0.04131737090251895, -0.18284269923547086, 0.02349020938130996, -0.0649091594692792, -0.04014921233765235, -0.009580196336324408, -0.04063171553635301, -0.049088188928525296, 0.0539385971015886, 0.004459965401886395, -0.04672646873118242, 0.019503222216762383, 0.012284744216750257, -0.03501945933678896, 0.12148882159601077, -0.02564876913994048, -0.10041111993695706, -0.056935189275807596, 0.10838509840167576, -0.021623690814754924, 0.006843904443492401, -0.13885888505394053, 0.031845105655843725, 0.0941132063034153, -0.018462033498085097, -0.034409982156275415, 0.07247682326000851, 0.06521389702563009, -0.02319816818923448, 0.034663930119901154, 0.05101819551989265, -0.007008970413067951, 0.05099280279134185, -0.1570415778598491, 0.0014490919890599425, 0.020709476077890508, -0.014157612412911233, 0.003894930459085015, -0.041901455354481684, -0.09304662899181074, 0.010532502647389154, -0.0009158007484929565, -0.0680073308289485, -0.1215903987136493, -0.015884460633378002, -0.10411876847713987, 0.05414175754030096, -0.12118408817528344, 0.04286645761625948, -0.06399494680022656, -0.018855653875610872, 0.004380606714948648, 0.07552419882351732, 0.08669791956210852, -0.031718129606219087, -0.05820493116174803, 0.032175238008557185, 0.14698521988996402, 0.0818221124570591, -0.0011816528149920602, 0.03981907998493889, 0.09990322814532913, 0.0680073308289485, 0.04695502189844558, 0.04284106075208513, -0.04355211711804896, 0.002936276172663745, -0.04555831016631581, -0.08756134057062424, 0.024493303837631614, -0.01716689888359385, -0.049494505670326476, -0.01288787197443903, -0.014284587221848812, -0.08938977211216485, 0.11072141553140899, 0.09045634942376939, 0.10325534540081237, 0.03969210393531425, -0.056020976606754945, -0.009250063156486245, -0.061557046349419504, -0.109502469441629, 0.09446872931686778, 0.0604396732416545, 0.02115388604814143, -0.026461404691354603, 0.04243474401028396, 0.03966671120676345, -0.0680581162860501, -0.020912634448791097, -0.0220300075565561, -0.09924295723646691, -0.02406159333337375, -0.12219988002978636, 0.055411499426241406, -0.07831762642340041, -0.020658686485165362, -0.025712256130846916, -0.04360290671077411, -0.1122451095165987, 0.014195704814236272, -0.03697485865670711, 0.0440600151131122, -0.04131737090251895, 0.01314181952450241, 0.021788755957205766, -0.04682804791663271, -0.014056033227460941, -0.018423942337447125, 0.04352672232168639, -0.006666140455392032, -0.08705344877899632, 0.07948579119170233, 0.1021379702252356, 0.06424889683166407, -0.09863348419157691, -0.030676942955353576, -0.05363386368086127, -0.008729469417491136, 0.02686772143315578]}}, {'id': 'https://huggingface.co/papers/2410.13218', 'title': 'CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy', 'url': 'https://huggingface.co/papers/2410.13218', 'abstract': "There is a significant gap between patient needs and available mental health support today. In this paper, we aim to thoroughly examine the potential of using Large Language Models (LLMs) to assist professional psychotherapy. To this end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation of cognitive behavioral therapy (CBT) assistance. We include three levels of tasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of multiple-choice questions; II: Cognitive model understanding, with the tasks of cognitive distortion classification, primary core belief classification, and fine-grained core belief classification; III: Therapeutic response generation, with the task of generating responses to patient speech in CBT therapy sessions. These tasks encompass key aspects of CBT that could potentially be enhanced through AI assistance, while also outlining a hierarchy of capability requirements, ranging from basic knowledge recitation to engaging in real therapeutic conversations. We evaluated representative LLMs on our benchmark. Experimental results indicate that while LLMs perform well in reciting CBT knowledge, they fall short in complex real-world scenarios requiring deep analysis of patients' cognitive structures and generating effective responses, suggesting potential future work.", 'score': 3, 'issue_id': 207, 'pub_date': '2024-10-17', 'pub_date_ru': '17 октября', 'hash': 'f4f24ef7771a745c', 'data': {'desc': 'Исследователи представили новый бенчмарк CBT-BENCH для оценки потенциала использования больших языковых моделей в когнитивно-поведенческой терапии (КПТ). Бенчмарк включает три уровня задач: базовые знания КПТ, понимание когнитивной модели и генерацию терапевтических ответов. Эксперименты показали, что языковые модели хорошо справляются с воспроизведением знаний КПТ, но испытывают трудности в сложных сценариях, требующих глубокого анализа когнитивных структур пациентов. Результаты указывают на потенциальные направления для будущих исследований в области применения ИИ в психотерапии.', 'emoji': '🧠', 'title': 'Оценка потенциала ИИ в когнитивно-поведенческой терапии', 'categories': ['#benchmark', '#nlp', '#medicine'], 'embedding': [-0.025578980649462672, -0.028054364371478905, 0.1278294073180521, 0.04539515770985954, -0.023575096756998575, 0.0014660762675723612, 0.064229033504388, 0.054903777760467426, -0.044399765356553614, 0.12080927624912374, 0.017340793338380633, -0.1329635491917903, 0.013228248263463896, -0.019252995077501067, -0.030700013214330208, -0.029390286966454966, 0.08733263650564549, -0.003683608691128205, -0.05715651176586169, 0.054589443865898105, 0.05621350603294635, 0.07077767486678263, -0.0025867120221534858, -0.0479360292627223, 0.038741743106683726, -0.04646913303065686, 0.014184349133024113, -0.043640123930325604, -0.012946657069555627, 0.03206213013180341, 0.09623877904040451, -0.026548178680271456, -0.1449082655298761, 0.004937673117229059, -0.021400949768303094, 0.11127445377760396, 0.03580795064255287, 0.09398605110882129, 0.09367171923885566, 0.01635849814632328, -0.049376729147686906, -0.049193366865603265, 0.007308280156637854, 0.010209327288122872, -0.08759457973061685, 0.004662630301484706, 0.07193024125348611, -0.01044507740535931, -0.07800737266331018, 0.026115968309861334, -0.07135395806013436, 0.091523768597261, 0.008873404693146807, -0.03515309055552077, 0.0010281360662688151, 0.03350283001676802, 0.003552636066340681, 0.04628577277317691, 0.05346307990010651, 0.05157707045887952, 0.009809859820834172, -0.032978941542221606, -0.028918785112299145, 0.02839489258854536, -0.17864684647372203, -0.05930446645666372, -0.030071345425191565, -0.03599131494924019, 0.03929182792833096, 0.0009184464803554908, 0.026928000405687304, 0.02235705063786331, 0.00017752947984671366, 0.0352316714984085, 0.017733712225045047, -0.002431181764489067, 0.09786284323205642, 0.08073160852286027, -0.02944267561144924, -0.043273401390762016, 0.0021184843570796193, -0.07633092590047504, -0.014799921785517872, -0.04222561836785813, 0.03701289960043956, 0.020890154405797882, -0.0069153616748941745, 0.06176675301743138, -0.11399868761255036, -0.09791522985244702, 0.025565881463610416, -0.07465447508843251, -0.09388127179422907, 0.06779149983146855, 0.13034408657302138, -0.0012573384127224432, 0.03030709432766579, 0.006011649450328231, 0.04123022398994852, 0.09210004369219799, -0.015428590384497986, 0.05521811570424412, 0.0059461630367042845, -0.05804712682917906, 0.09534817005089818, -0.008938890499389647, 0.05731367567624082, -0.07821692926789095, -0.06380993041824487, 0.05270343644927481, -0.16387311293689025, 0.05220574027262185, -0.028971173757293415, -0.03510069583671544, 0.032376464026372724, -0.10991234090933814, -0.05694695516128091, -0.024950310835720343, -0.05453705522090383, 0.016712123524638304, 0.038008293978349164, 0.09812479050623517, 0.047595496996448466, -0.05878057393290993, 0.0059134199311224964, -0.014642754230852106, 0.08879953273771092, -0.05809951344956965, 0.030228513384778073, -0.026797026768597933, -0.04707161054650574, 0.06328603789449108, 0.08879953273771092, -0.010870738992684776, -0.12510518158152042, 0.020261484592055554, -0.13243965261882915, 0.04123022398994852, -0.05631828737214227, -0.10153008077531449, 0.051839017733058254, -0.0008586901608234496, 0.003366000000095821, 0.007884560110623696, -0.09843912035159712, -0.018755298900848105, 0.007799427752666529, 0.016620443395898327, -0.07748348621336745, 0.05841384936874266, -0.022854744789912586, -0.06270975470113935, -0.032586020630953505, 0.03819165828503649, -0.0626049774111508, -0.08046965922407785, 0.0212044883003672, 0.061400026428660416, 0.06202869826700643, -0.10959800296556145, 0.09854390574000041, 0.010451625783523223, 0.05134131953180161, 0.01363426431137688, 0.10042990910741634, 0.1069785464206036, -0.032009741486809136, 0.10310175429736845, -0.055270504349238386, -0.07124917672093846, -0.010248618164487468, -0.030411873642258024, -0.06370514705444526, -0.07931710093578911, -0.0050359028388951635, -0.03287416222762938, 0.05464183251089238, -0.042880480479493915, -0.013241345424712463, -0.043587733260727644, -0.0801553293787159, 0.128458067008776, -0.055427670284221214, 0.029495064256443514, -0.04474029357362007, 0.01487850475300928, -0.0718254578896865, 0.028159143686071135, -0.04088969577288207, -0.00489838082364188, -0.00672545101464662, 0.014236738790320228, 0.16303488449396344, 0.14480347406766175, 0.10042990910741634, -0.029626036881231037, 0.11536080453002356, 0.06124286251828128, -0.0199602478587348, -0.015232132155927992, -0.007301731171092832, 0.02218678551702824, 0.0005337139977136653, -0.15863419782237084, 0.08565618366899927, -0.0103337501175239, 0.017314599015883496, 0.029049756724784825, -0.061923918952414204, -0.018113533950460895, 0.07575464473172698, -0.0564754512825214, 0.11850414752492415, 0.060037911535790904, -0.08780413835980132, 0.02658747016401716, -0.0834034537128124, -0.0067647427008526925, -0.007249342121177823, 0.060561802034941, 0.0007547305070337354, 0.06711044339733563, 0.04437357103405648, 0.015821510485924617, -0.042278007012852406, 0.040680139168301294, 0.049193366865603265, -0.08796130227018044, 0.06506726599652216, -0.12416217382400141, 0.04845992178647608, -0.032795579260137965, -0.051943792998443115, -0.060561802034941, -0.0026505611387760844, -0.007380314948425715, 0.009790213269119845, -0.009285968309382232, 0.04660010869234992, -0.10682138048562077, 0.1263625171597977, 0.005618731373505291, 0.037929711010857764, -0.07748348621336745, 0.0025130397309039076, 0.04398065214739206, -0.05050309513808219, -0.12468606837235888, 0.09115703795928266, -0.05469422318049033, -0.03381716796054471, -0.07999815736992202, -0.05532289299423266, -0.05961880035123304, -0.05689456651628664, 0.04476648789611721]}}, {'id': 'https://huggingface.co/papers/2410.12788', 'title': 'Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception', 'url': 'https://huggingface.co/papers/2410.12788', 'abstract': 'Retrieval-Augmented Generation (RAG), while serving as a viable complement to large language models (LLMs), often overlooks the crucial aspect of text chunking within its pipeline, which impacts the quality of knowledge-intensive tasks. This paper introduces the concept of Meta-Chunking, which refers to a granularity between sentences and paragraphs, consisting of a collection of sentences within a paragraph that have deep linguistic logical connections. To implement Meta-Chunking, we designed two strategies based on LLMs: Margin Sampling Chunking and Perplexity Chunking. The former employs LLMs to perform binary classification on whether consecutive sentences need to be segmented, making decisions based on the probability difference obtained from margin sampling. The latter precisely identifies text chunk boundaries by analyzing the characteristics of perplexity distribution. Additionally, considering the inherent complexity of different texts, we propose a strategy that combines Meta-Chunking with dynamic merging to achieve a balance between fine-grained and coarse-grained text chunking. Experiments conducted on eleven datasets demonstrate that Meta-Chunking can more efficiently improve the performance of single-hop and multi-hop question answering based on RAG. For instance, on the 2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while only consuming 45.8% of the time. Our code is available at https://github.com/IAAR-Shanghai/Meta-Chunking.', 'score': 2, 'issue_id': 208, 'pub_date': '2024-10-16', 'pub_date_ru': '16 октября', 'hash': '0fbcf072cc98c553', 'data': {'desc': 'Статья представляет концепцию Мета-Чанкинга для улучшения Retrieval-Augmented Generation (RAG). Мета-Чанкинг - это метод разбиения текста на фрагменты, учитывающий лингвистические связи между предложениями. Авторы предлагают две стратегии реализации: Margin Sampling Chunking и Perplexity Chunking, использующие большие языковые модели. Эксперименты на одиннадцати наборах данных показывают, что Мета-Чанкинг повышает эффективность RAG в задачах вопросно-ответных систем.', 'emoji': '🧩', 'title': 'Мета-Чанкинг: Новый подход к разбиению текста для повышения эффективности RAG', 'categories': ['#rag', '#nlp', '#dataset', '#code'], 'embedding': [0.011314953977182435, 0.034142111247153425, 0.08105165101046777, 0.038828280471551915, -0.03868482961659378, 0.017094964749779167, 0.04026282609257101, 0.024076405211792745, -0.033616112421827674, 0.09157162751698267, 0.04243854682135306, -0.014106334315452083, -0.07823038387421939, 0.048846173132328426, 0.013293426756148178, -0.037561102636206614, -0.007250416570888573, -0.054416976123961215, -0.024435039178137143, 0.06723222679478365, -0.019019641604563722, 0.0012626962887503565, 0.0012440173570719987, -0.004856523797275711, -0.04490117901569289, -0.03222938895547009, 0.05752515082351077, 0.08650291032221658, -0.0024192960738683494, -0.011476339603484868, -0.025487036828788633, -0.04107573248119794, -0.006993394439776314, 0.0369633783834018, 0.02641949079955614, 0.06135059540687742, -0.05403443400697851, 0.004055571191298696, 0.023657996478813906, 0.019210914614183377, 0.0007019545022171149, -0.040382369772455, 0.0250088562558678, 0.08521182140954052, 0.03301838621789456, 0.07937801607855241, 0.01808718958492452, 0.0029811583933849494, 0.03725028594670298, 0.0836816412348399, -0.038254465344949556, 0.02957548375151061, -0.016114694477735045, -0.033185746199055156, 0.006180486880472411, 0.02689767137247697, -0.011153567375315853, -0.009862479438203947, 0.11763248142350197, -0.027112853508299083, -0.044446907568974514, -0.09812270663404449, -0.03294665688815889, 0.056807882890821976, -0.10988595575195882, -0.06407622798944429, -0.13647280067929066, -0.06909712498067717, -0.06383713672741971, -0.007704688602945439, 0.042749363510856696, -0.020430276148252064, -0.0035654356650509753, -0.024136177051734736, -0.051356621627944875, -0.004736978556489088, 0.01011352409265276, 0.1192582961518841, -0.019055507244995707, 0.011045977282968949, 0.013257563066844493, -0.032325025460279926, 0.060537690969378805, -0.07086639836853065, 0.06115932629951437, -0.015863648652609252, -0.006455440856236511, 0.02014336760938673, -0.11112922055884505, -0.04478163338468061, -0.09692725422617825, -0.02284508813905868, -0.10194815121741113, 0.03763283196594229, 0.05250425383227789, 0.054990795152820175, -0.050208987472483556, -0.044088272627065966, 0.08435109481738037, -0.040741006665491845, -0.06833204074671176, -0.10223506073184062, 0.03127302585850013, -0.08057347043754692, 0.07846947318511564, -0.1018525108103447, -0.04164954955892859, 0.05303025265760363, -0.05106971016238709, -0.046550900919149193, -0.08812872505059871, -0.006694531532922587, -0.15875603215710482, 0.021482273798903554, 0.06068114572659354, -0.13245609089081756, -0.09888779086800989, 0.08047783198160881, -0.0004651055743926604, 0.09434507249856953, -0.0525520701335545, 0.005134466706484364, 0.019569551507220225, -0.105104140267109, 0.006867872112551908, -0.06618022329074727, 0.09601871133274151, -0.006503259108641425, 0.014106334315452083, 0.04707690169560324, 0.04243854682135306, -0.003161970623730745, 0.061398417561538944, -0.036246106548456405, -0.17252764202264062, -0.02213977184277866, -0.10051360364526374, -0.018684915788857632, -0.07191839406805385, 0.0102689332178559, -0.05250425383227789, -0.038900009801287584, -0.05522988446371645, 0.00999995593830392, -0.16860655703220753, -0.009228889544967147, -0.0385652839855815, 0.06077678223140338, -0.04698126714192172, 0.018398006274428152, -0.07956928713704375, -0.09286271252740212, -0.11151177048034097, 0.04872662750131615, -0.033066202519171174, -0.034142111247153425, -0.0550864297065017, 0.00803941480887719, 0.057286061512614506, -0.10127869958599894, 0.032014204868519684, 0.056329702317901145, 0.031057845673806324, -0.022115863692140355, 0.07952146888463885, 0.0641718683965107, -0.10127869958599894, 0.08095601255452964, -0.08095601255452964, -0.08846345476856142, -0.10969468469346748, -0.1452713357082551, -0.027591034081219917, -0.06364586371780007, -0.014369334118340614, -0.04889398748247674, -0.1420197023492342, -0.07005348612651884, 0.0680929533869438, 0.020753047400856928, -0.07913892676765613, 0.12059720136583678, -0.08105165101046777, 0.09353217391445581, -0.05413007051178834, -0.09573179791605542, 0.057859878590345165, 0.045714087355448116, 0.05427352136674648, 0.09539707014922102, -0.05446479632749443, 0.09238453975899451, 0.10778195849952754, 0.03648519781048097, 0.04298845477288126, 0.004557661085534814, 0.17109309445049323, 0.0031470275174106245, 0.049156989821832066, -0.08659854682702639, -0.038134919713937274, 0.09429725619729291, -0.019724958876407895, -0.14871423817463902, -0.0010878613399551752, 0.010519977872304713, -0.009826615748900262, 0.005585749805096678, -0.045785812782927184, -0.01371183509890136, 0.04920480417198038, -0.05599497650219505, 0.07292257541742872, 0.026873762246274514, 0.013245609089081754, -0.0837294614383731, -0.05781206228906855, 0.07631765768027945, 0.017836145710927023, -0.05876842538603852, 0.032564116722304484, -0.031536028197855455, 0.026013037605242678, 0.06928840384368172, -0.07273130435893738, 0.005549886115792993, 0.03952164513142316, -0.10854704273349296, 0.09769234431352855, -0.08071692129250507, 0.07727402077724943, 0.0036222197422253947, -0.08760272427414467, -0.05484734234673374, 0.04066927733575617, -0.021673544857394905, -0.0036311855669949006, -0.05479952214320052, -0.04236682139387399, 0.04671826480256639, -0.008314369369979781, 0.014668196244743022, 0.02924075793580452, -0.01958150411919315, -0.033544383092092005, 0.07335293773794464, -0.09214544849696993, -0.012020270273462455, 0.12222301609421891, -0.009515798278945305, 0.008015506268013225, -0.0862160008077871, -0.008625187035047568, -0.027734486887306353, -0.0811951038165542, 0.03717856051922391]}}, {'id': 'https://huggingface.co/papers/2410.13394', 'title': 'Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs', 'url': 'https://huggingface.co/papers/2410.13394', 'abstract': 'Evaluating machine-generated text remains a significant challenge in NLP, especially for non-English languages. Current methodologies, including automated metrics, human assessments, and LLM-based evaluations, predominantly focus on English, revealing a significant gap in multilingual evaluation frameworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an extensible framework that includes evaluator LLMs (Hercule) and a novel test set (Recon) specifically designed for multilingual evaluation. Our test set features 500 human-annotated instructions spanning various task capabilities along with human judgment scores across six languages. This would enable benchmarking of general-purpose multilingual LLMs and facilitate meta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a cross-lingual evaluation model that addresses the scarcity of reference answers in the target language by learning to assign scores to responses based on easily available reference answers in English. Our experiments demonstrate that Hercule aligns more closely with human judgments compared to proprietary models, demonstrating the effectiveness of such cross-lingual evaluation in low resource scenarios. Further, it is also effective in zero-shot evaluation on unseen languages. This study is the first comprehensive examination of cross-lingual evaluation using LLMs, presenting a scalable and effective approach for multilingual assessment. All code, datasets, and models will be publicly available to enable further research in this important area.', 'score': 1, 'issue_id': 208, 'pub_date': '2024-10-17', 'pub_date_ru': '17 октября', 'hash': 'd456f53989a80b51', 'data': {'desc': 'Статья представляет новый фреймворк CIA Suite для многоязычной оценки генеративных языковых моделей. Он включает в себя модель-оценщик Hercule и тестовый набор Recon с 500 аннотированными инструкциями на шести языках. Hercule способна оценивать ответы на целевом языке, используя эталонные ответы на английском, что решает проблему нехватки ресурсов. Эксперименты показывают, что Hercule лучше соответствует оценкам людей, чем проприетарные модели, и эффективна даже для ранее не виденных языков.', 'emoji': '🌐', 'title': 'Преодоление языковых барьеров в оценке ИИ', 'categories': ['#nlp', '#multilingual', '#benchmark'], 'embedding': [-0.04935933007947497, -0.012026771143256279, 0.1637310674158379, 0.010389721932289172, -0.009039645162987418, -0.05509878934626928, 0.019096739382625846, 0.08066546356732636, 0.00902660100851848, 0.09553587478302344, -0.029793000301288397, -0.10419723424966804, -0.06162089788119983, -0.015170428229170866, 0.017074883963104536, -0.0074873826430637835, 0.06130783900862432, -0.0942314551627348, -0.013957316646816044, 0.01681400087372579, 0.07184756840430165, 0.03824565454844846, 0.04599392111556998, -0.001641126075255335, 0.045759125917789606, -0.041115383138496886, -0.0037860850843931208, 0.043854670183855936, 0.015679152966166118, -0.05173338246906174, 0.1177110458884848, 0.0032088782755987644, -0.07868273789850518, 0.03545419171989264, -0.042080655994611645, 0.11969376947060853, 0.051342053661598705, 0.04646351359782816, 0.0031648539673452, 0.08150029279205429, -0.04218500964770263, -0.03428021364429336, 0.021288168184234107, -0.03135830614100198, -0.07623043018091309, -0.014518217584347555, 0.07445641181827387, 0.049776746778536385, -0.03897613220678285, 0.052803006891570026, -0.1177110458884848, 0.07868273789850518, 0.05384654342247994, -0.045628686459797695, -0.007924364217475261, -0.08838764224284949, 0.0026544988936273582, 0.08134375709567417, -0.08431784142551103, -0.012065904441342073, -0.04252416058527145, -0.06595157552782467, 0.02924514414423506, -0.028488578594302285, -0.12887689720270806, -0.007409117507580413, -0.020714222048884928, 0.0030050621882542978, 0.04677657455710113, -0.016435718098759402, 0.05629885531346694, 0.05048113445857494, 0.010141881745360888, -0.009117910089801042, -0.035088954977422905, -0.037019498602954955, 0.02569711367904901, 0.1382687468478718, -0.027210244778914556, 0.05170729040406844, -0.050037631954612596, -0.06172525570768574, 0.019475022157592232, -0.08363954372376833, 0.10800614571753539, 0.014570394202223306, -0.02934949779732605, 0.022592589891220215, -0.07737832036491399, -0.09934478625089078, -0.06636899222688608, 0.019096739382625846, 0.013957316646816044, -0.004956804155905187, 0.0349063355628393, -0.03096698046358513, 0.0027311336923881383, -0.07216063353696954, 0.043202458287014155, 0.06188178305727604, -0.04375031444406749, 0.030497387981326948, 0.04437643844931089, -0.04077623428762553, 0.08066546356732636, -0.032871436197518804, 0.010787570625954345, 0.008576575488307809, 0.008309168756671498, 0.01472692572520852, -0.16675731292198934, 0.009137476217169574, -0.07690872788265579, -0.12157214148633873, 0.04390684805375016, -0.1260593548293437, -0.07294328489180324, -0.05890770290083408, -0.06156872209800307, 0.008857025957073564, 0.005478572838699631, 0.10023179125881548, 0.1003883227818007, -0.1119715907950854, 0.06626464274719002, -0.029192966274340836, 0.02835813600626418, 0.023010004503584182, -0.007369984835503856, -0.07116927070255895, -0.06986484273548046, 0.043776408595758244, 0.07549994834918378, -0.042393716953884615, -0.1374339113630515, 0.08755281719151649, 0.0035545503513881894, -0.03707167438615173, -0.08781369610750032, -0.028071163981938322, -0.026544988936273578, -0.012574628760997835, -0.05220297077792501, 0.02676674227495221, -0.09564022426271954, -0.003443674308058112, -0.043985111728545315, 0.03135830614100198, -0.030079972325614254, 0.10946709894750671, -0.007924364217475261, -0.05363783611629795, -0.025827557310435838, 0.09824906767669175, -0.13252928549438003, -0.038297832418342684, -0.10717132066620237, 0.00577532876138874, 0.014805190860691889, -0.1152065540409061, 0.0879180455871964, 0.059377291209697355, -0.02285347506729642, 0.05541185030554225, 0.05609015218067988, 0.06229919975633746, -0.00898094615487258, -0.005494877875283494, -0.10998886721296167, 0.0006057409984216576, -0.11144982252963044, -0.11625009265851347, -0.01750534356461642, -0.03576725267916561, -0.051655112534174215, -0.12272002958364217, -0.04607218896376004, -0.031593102382131075, -0.029610380886704795, -0.006512327140604252, -0.0484462371799519, 0.09986655868974066, -0.09485757290788584, -0.03928919316605582, -0.06751689075767682, -0.058959878684030846, -0.038271742440046844, 0.027810278805862114, -0.0763869617038983, 0.02484924050852189, -0.0246535771481391, 0.08202206105750925, 0.15162603113709824, 0.09746641840855551, 0.048159266198974766, 0.0003576969828858437, 0.0858831462218759, 0.06777776967366064, -0.05890770290083408, -0.005064418899780848, 0.06459498221103671, 0.06349926572353512, 0.038636983355911494, -0.1256419360435848, 0.07482165273413853, 0.007076489794929671, -0.014583438148022498, 0.027653749369574356, -0.059899059475152304, 0.04140235620617148, 0.06746470662769022, 0.009320095423083426, 0.08082198674352176, 0.10717132066620237, -0.06715164984181217, -0.024340516188866127, -0.02702762536433096, 0.021979511918473464, 0.10341457663474198, 0.02452313560344973, -0.024301382264771097, 0.0902660100851848, 0.15214778896906592, -0.05288127056636518, -0.10205798540465147, 0.012894212736519133, 0.01157674562304561, -0.05022025136919619, 0.026571076827871964, -0.10680607975033772, 0.08494396543075444, -0.015496535220940485, -0.11374560707102715, -0.02316653706991812, -0.03644555246760578, -0.05953382481938002, 0.02051855868850214, -0.026871093841345745, -0.012587672706797028, -0.03918483951296483, 0.007161277111982383, 0.041584975620755076, 0.00800915174319772, -0.02250128018392842, 0.0010402766921437092, -0.009496192864767428, -0.014844323324098702, -0.07184756840430165, 0.13993839695053784, -0.05415960646845037, -0.06287314380498918, -0.0403849054801625, 0.02404049917539235, -0.0396022541253288, -0.049437597927665035, 0.060055590998137516]}}, {'id': 'https://huggingface.co/papers/2410.15017', 'title': 'DM-Codec: Distilling Multimodal Representations for Speech Tokenization', 'url': 'https://huggingface.co/papers/2410.15017', 'abstract': 'Recent advancements in speech-language models have yielded significant improvements in speech tokenization and synthesis. However, effectively mapping the complex, multidimensional attributes of speech into discrete tokens remains challenging. This process demands acoustic, semantic, and contextual information for precise speech representations. Existing speech representations generally fall into two categories: acoustic tokens from audio codecs and semantic tokens from speech self-supervised learning models. Although recent efforts have unified acoustic and semantic tokens for improved performance, they overlook the crucial role of contextual representation in comprehensive speech modeling. Our empirical investigations reveal that the absence of contextual representations results in elevated Word Error Rate (WER) and Word Information Lost (WIL) scores in speech transcriptions. To address these limitations, we propose two novel distillation approaches: (1) a language model (LM)-guided distillation method that incorporates contextual information, and (2) a combined LM and self-supervised speech model (SM)-guided distillation technique that effectively distills multimodal representations (acoustic, semantic, and contextual) into a comprehensive speech tokenizer, termed DM-Codec. The DM-Codec architecture adopts a streamlined encoder-decoder framework with a Residual Vector Quantizer (RVQ) and incorporates the LM and SM during the training process. Experiments show DM-Codec significantly outperforms state-of-the-art speech tokenization models, reducing WER by up to 13.46%, WIL by 9.82%, and improving speech quality by 5.84% and intelligibility by 1.85% on the LibriSpeech benchmark dataset. The code, samples, and model checkpoints are available at https://github.com/mubtasimahasan/DM-Codec.', 'score': 0, 'issue_id': 208, 'pub_date': '2024-10-19', 'pub_date_ru': '19 октября', 'hash': 'd2c6c349adfb4796', 'data': {'desc': 'В статье представлен новый подход к токенизации речи, названный DM-Codec. Он объединяет акустическую, семантическую и контекстную информацию для создания более точных речевых представлений. Авторы предлагают два метода дистилляции: с использованием языковой модели и комбинированный метод с языковой моделью и самообучающейся речевой моделью. Эксперименты показывают, что DM-Codec значительно превосходит современные модели токенизации речи, снижая ошибки распознавания и улучшая качество и разборчивость речи.', 'emoji': '🗣️', 'title': 'DM-Codec: Революция в токенизации речи с использованием мультимодальных представлений', 'categories': ['#audio', '#nlp', '#benchmark', '#code'], 'embedding': [0.03224484014777453, 0.05336740479420214, -0.016159005869799695, -0.005289788109409671, -0.02443973367516587, 0.0229762788927343, 0.05956270531953494, 0.08517320740983296, -0.03165945743668244, 0.09107581957256766, 0.035098580116111465, -0.05556259045962213, -0.08956357674537428, -0.05800168342642362, 0.03153750278834237, -0.05419669680197437, 0.017988327590199457, 0.016159005869799695, 0.014463835260223337, 0.06858735927319366, -0.0286837608247068, 0.02717152198811069, -0.024098261258403256, 0.04117192798840283, 0.05073318159663843, 0.031683847967290735, 0.003551932475029897, 0.03217166456535239, 0.012500362828059903, -0.06424577099886891, -0.03090333702073507, -0.024878772204958915, -0.049879497062959265, -0.09492958925353212, -0.0015930340654749728, 0.04175731069949492, -0.06458723842738494, -0.03158628584485759, -0.043196379939564815, 0.04190365787374192, -0.015500450768763293, -0.018195651090967175, -0.09941751871620795, 0.1044908368758718, 0.019756670988779857, 0.06917274198428576, 0.04858677898773366, 0.08380731175688656, -0.05829437577961898, 0.0072502105280678845, -0.14156508189603273, 0.10556404217092147, 0.009799065272263676, -0.02478120808722713, -0.056440665523909576, -0.08180725432693015, 0.018817619597971694, -0.05561137351613734, -0.05414791374545916, -0.004957461143975841, -0.01902494309873941, -0.1029298209686564, -0.03283022485416526, 0.005975783355499852, 0.021207933498855254, -0.03995237950970344, -0.03553761764825519, -0.03758645813472681, -0.06805075762331815, 0.03953773450346665, 0.06087981991126476, 0.021878685062374982, 0.029366706655881352, -0.0034208311781818513, -0.10029559577579404, -0.046245248143365315, -0.058684634245844775, 0.10761288066209444, -0.03158628584485759, -0.01674438858089178, -0.052196637376719326, -0.058830975434195854, 0.009073434017225981, -0.03204971191231096, -0.08590492931397747, -0.059952959795163456, -0.12751589483452402, 0.07156305388987066, 0.02548854544665929, -0.08951479368885906, 0.009116118443439803, 0.024073870727794967, -0.006914835145367747, -0.022720172335451365, 0.06419698794235369, -0.02448851772933041, 0.01486628579927545, 0.05234298255566769, 0.07736810393017225, 0.03517175569853361, 0.012610122410625698, -0.04261099523317408, 0.03463515205335945, -0.00601846758218381, 0.08395365693583492, -0.026878829634915325, 0.04897703346336217, -0.07678271722848289, -0.15249223514781202, 0.008238044576331538, -0.007738029520487911, 0.04068410939504253, -0.0332692583957117, 0.04961119723567083, 0.0736118943763423, -0.15815094200446386, -0.06975812669067649, 0.02926914353579889, -0.03539127047400818, 0.03963529662589979, -0.02509829097103078, -0.002652516095519924, 0.04139144874977333, 0.0008826475704689932, 0.053611312095583646, -0.07107523529651039, 0.04670867421081869, -0.06546531548697103, -0.011408868226591574, -0.048196520521507864, -0.057367519654114955, 0.014646767033203587, 0.09117337570910489, -0.006920932977549683, -0.06863614232970888, -0.07429483920986753, -0.10780800889755802, 0.006359940996595747, -0.06912395892777054, 0.04007433615334216, -0.00059567278544024, -0.03958651755998186, 0.03363512433603057, 0.0006604612497357404, -0.03295217750720669, -0.010945439764779834, -0.03670838706103665, 0.010982025959751993, -0.1736635828507548, 0.0740997129697026, -0.04797700375073465, -0.16693167269435194, -0.06370917134429205, 0.03885478767464277, -0.12000348570335734, -0.10605185876898313, -0.07736810393017225, 0.10722262618646594, 0.05751386483306332, -0.056391882467394364, -0.02612270921896795, 0.06034321826138925, -0.0461964650868501, -0.060148090025925666, 0.008847818017561774, -0.043732979594141685, -0.020903047875654387, 0.058684634245844775, -0.10253956449772925, -0.09990534130016554, -0.0325619190409809, -0.06263596205864509, -0.11005197761949322, -0.09683208256575675, -0.020281077373351226, -0.0968808676175706, 0.0660506981980631, -0.1433212439963995, -0.12136937936100507, -0.0495868047097639, -0.012805250646089275, 0.04463544319373877, -0.02953744336308732, 0.05326984067647035, -0.07292894355692114, -0.09175876241079427, -0.05273324102189348, 0.06424577099886891, 0.07317285484889993, 0.027000784283255398, -0.03380585805028857, 0.15668749021498027, 0.09575888325660299, 0.05083074371907158, 0.03161067238486859, 0.0523917656121829, -0.0021646969035700333, 0.13297948143690688, 0.0030595400585909528, -0.08434391540206071, -0.04041581156305274, 0.022659194013632006, -0.1015639293063073, -0.10019803564865955, -0.03931821773269342, 0.0024421439779560333, -0.01476872168154366, -0.03792793354443739, -0.047342839978425984, 0.005466622449267711, 0.07536804051431992, -0.0019451785365578993, 0.14029675036081812, -0.03395220522453558, -0.10732019030419772, 0.056733357877104935, -0.04702575709462234, 0.05390400444877901, 0.04419640366629641, -0.07375823955529065, 0.020268882108047087, 0.03209849496882617, 0.07839252616870669, 0.026805656047791823, -0.08136821879008506, -0.036196173946470775, 0.0433915041844311, -0.08414878716659714, 0.06922152703609961, -0.11688144191713468, 0.05809924953945404, -0.06419698794235369, -0.0675629410252565, -0.038293795494158976, -0.01659804340194342, -0.037610848665335095, -0.002661662744027896, -0.056001627991765855, 0.07366067942815616, -0.012512558691953638, -0.035805917475543625, -0.051562473604410665, 0.1492726292391562, 0.06312378663790132, 0.022890910040306654, 0.10322251332185177, -0.020537181935335522, -0.0826365463347024, 0.06634339055125847, -0.04417201712628541, 0.06419698794235369, -0.009792967639611606, -0.02335433610776002, 0.018512731979472185, -0.030805772903003282, 0.09049043686147558]}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            const themeToggle = document.getElementById('theme-toggle');
            let settingSortBy = localStorage.getItem('sort_by');
            const sortDropdown = document.getElementById('sort-dropdown');
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "хф найтли";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }
            
            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }
        
        function createCategoryButtons() {
            const categories = getUniqueCategories(articlesData);
            categories.forEach(category => {
                const button = document.createElement('span');
                button.textContent = category;
                button.className = 'category-button';
                button.onclick = () => toggleCategory(category, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if (selectedArticles.length === articlesData.length) {
                categoryToggle.textContent = '🏷️ Фильтр';
            } else {
                categoryToggle.textContent = `🏷️ Фильтр (${formatArticlesTitle(selectedArticles.length)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles = selectedCategories.length === 0
                ? articlesData
                : articlesData.filter(article => 
                    article.data && article.data.categories && 
                    article.data.categories.some(cat => selectedCategories.includes(cat))
                );

            console.log('filteredArticles', filteredArticles)

            if (filteredArticles.length === 0) {
                selectedArticles = articlesData;
                selectedCategories = [];
                cleanCategorySelection();
            } else {
                selectedArticles = filteredArticles;
            }

            console.log('selectedArticles', selectedArticles)

            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                const explanation = item["data"]["desc"];
                const cats = item["data"]["categories"].join(" ");
                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="background-digit">${index + 1}</div>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <h2>${item['data']['emoji']} ${item['title']}</h2>
                            <p class="meta"><svg class="text-sm peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path transform="translate(0, 2)" fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg> ${item['score']}. ${item['data']['title']}</p>
                            <p class="pub-date">📅 Статья от ${item['pub_date_ru']}</p>
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>
                            <div class="links">
                                <a href="${item['url']}" target="_blank">Статья</a>
                            </div>
                            <p class="tags">${cats}</p>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            }
            if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
        });

        clearCategoriesButton.addEventListener('click', clearAllCategories);
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiffRu('2024-10-22 04:15');
        } 

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();  
    </script>
</body>
</html>
    