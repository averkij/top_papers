
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 11 papers. May 20.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">20 мая</span> | <span id="title-articles-count">11 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-05-19.html">⬅️ <span id="prev-date">19.05</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-05-21.html">➡️ <span id="next-date">21.05</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-05.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '20 мая', 'en': 'May 20', 'zh': '5月20日'};
        let feedDateNext = {'ru': '21.05', 'en': '05/21', 'zh': '5月21日'};
        let feedDatePrev = {'ru': '19.05', 'en': '05/19', 'zh': '5月19日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2505.11896', 'title': 'AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via\n  Reinforcement Learning', 'url': 'https://huggingface.co/papers/2505.11896', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to substantial computational costs and inefficiency, especially for simpler inputs. To address this critical issue, we introduce AdaCoT (Adaptive Chain-of-Thought), a novel framework enabling LLMs to adaptively decide when to invoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem that seeks to balance model performance with the costs associated with CoT invocation (both frequency and computational overhead). We propose a reinforcement learning (RL) based method, specifically utilizing Proximal Policy Optimization (PPO), to dynamically control the CoT triggering decision boundary by adjusting penalty coefficients, thereby allowing the model to determine CoT necessity based on implicit query complexity. A key technical contribution is Selective Loss Masking (SLM), designed to counteract decision boundary collapse during multi-stage RL training, ensuring robust and stable adaptive triggering. Experimental results demonstrate that AdaCoT successfully navigates the Pareto frontier, achieving substantial reductions in CoT usage for queries not requiring elaborate reasoning. For instance, on our production traffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and decreased average response tokens by 69.06%, while maintaining high performance on complex tasks.', 'score': 27, 'issue_id': 3846, 'pub_date': '2025-05-17', 'pub_date_card': {'ru': '17 мая', 'en': 'May 17', 'zh': '5月17日'}, 'hash': 'bdc79864df7cbd51', 'authors': ['Chenwei Lou', 'Zewei Sun', 'Xinnian Liang', 'Meng Qu', 'Wei Shen', 'Wenqi Wang', 'Yuntao Li', 'Qingping Yang', 'Shuangzhi Wu'], 'affiliations': ['ByteDance Seed'], 'pdf_title_img': 'assets/pdf/title_img/2505.11896.jpg', 'data': {'categories': ['#optimization', '#reasoning', '#rlhf', '#rl', '#training'], 'emoji': '🧠', 'ru': {'title': 'AdaCoT: Умное рассуждение для языковых моделей', 'desc': 'AdaCoT - это новый фреймворк, позволяющий крупным языковым моделям (LLM) адаптивно решать, когда использовать метод цепочки рассуждений (Chain-of-Thought, CoT). Используя обучение с подкреплением, в частности Proximal Policy Optimization (PPO), AdaCoT оптимизирует баланс между производительностью модели и вычислительными затратами, связанными с применением CoT. Ключевым техническим вкладом является метод Selective Loss Masking (SLM), предотвращающий коллапс границы принятия решений во время многоэтапного обучения с подкреплением. Эксперименты показывают, что AdaCoT значительно снижает использование CoT для запросов, не требующих сложных рассуждений, сохраняя при этом высокую производительность на сложных задачах.'}, 'en': {'title': 'Adaptive Reasoning for Efficient Language Models', 'desc': 'This paper presents AdaCoT, a new framework that improves the efficiency of Large Language Models (LLMs) by adaptively deciding when to use Chain-of-Thought (CoT) prompting. Traditional CoT prompting can be computationally expensive, especially for simpler queries, but AdaCoT optimizes this by framing the decision to use CoT as a Pareto optimization problem. The authors employ reinforcement learning, specifically Proximal Policy Optimization (PPO), to dynamically adjust when CoT is triggered based on the complexity of the input. Their approach includes a technique called Selective Loss Masking (SLM) to ensure stable training, resulting in significant reductions in CoT usage while maintaining high performance on complex tasks.'}, 'zh': {'title': '自适应链式推理，提升效率与性能', 'desc': '大型语言模型（LLMs）在处理复杂推理任务时表现出色，但在某些情况下面临挑战。为了解决这一问题，本文提出了AdaCoT（自适应链式推理），它允许模型根据输入的复杂性自适应地决定是否使用链式推理。我们将自适应推理视为一个帕累托优化问题，旨在平衡模型性能与链式推理的计算成本。实验结果表明，AdaCoT在不需要复杂推理的查询中显著减少了链式推理的使用，提升了效率。'}}}, {'id': 'https://huggingface.co/papers/2505.11254', 'title': 'Delta Attention: Fast and Accurate Sparse Attention Inference by Delta\n  Correction', 'url': 'https://huggingface.co/papers/2505.11254', 'abstract': 'The attention mechanism of a transformer has a quadratic complexity, leading to high inference costs and latency for long sequences. However, attention matrices are mostly sparse, which implies that many entries may be omitted from computation for efficient inference. Sparse attention inference methods aim to reduce this computational burden; however, they also come with a troublesome performance degradation. We discover that one reason for this degradation is that the sparse calculation induces a distributional shift in the attention outputs. The distributional shift causes decoding-time queries to fail to align well with the appropriate keys from the prefill stage, leading to a drop in performance. We propose a simple, novel, and effective procedure for correcting this distributional shift, bringing the distribution of sparse attention outputs closer to that of quadratic attention. Our method can be applied on top of any sparse attention method, and results in an average 36%pt performance increase, recovering 88% of quadratic attention accuracy on the 131K RULER benchmark when applied on top of sliding window attention with sink tokens while only adding a small overhead. Our method can maintain approximately 98.5% sparsity over full quadratic attention, making our model 32 times faster than Flash Attention 2 when processing 1M token prefills.', 'score': 14, 'issue_id': 3847, 'pub_date': '2025-05-16', 'pub_date_card': {'ru': '16 мая', 'en': 'May 16', 'zh': '5月16日'}, 'hash': '2aba31b686859e82', 'authors': ['Jeffrey Willette', 'Heejun Lee', 'Sung Ju Hwang'], 'affiliations': ['DeepAuto.ai', 'KAIST'], 'pdf_title_img': 'assets/pdf/title_img/2505.11254.jpg', 'data': {'categories': ['#optimization', '#long_context', '#architecture', '#inference', '#benchmark'], 'emoji': '🔍', 'ru': {'title': 'Коррекция распределения для эффективного разреженного внимания', 'desc': 'Статья предлагает новый метод для повышения эффективности разреженного внимания в трансформерах. Авторы обнаружили, что разреженное вычисление вызывает сдвиг распределения в выходных данных механизма внимания, что приводит к снижению производительности. Предложенная процедура корректирует этот сдвиг, приближая распределение выходных данных разреженного внимания к квадратичному. Метод может применяться поверх любого алгоритма разреженного внимания, значительно повышая точность при сохранении высокой разреженности и скорости обработки.'}, 'en': {'title': 'Boosting Sparse Attention: Aligning Outputs for Enhanced Performance', 'desc': 'This paper addresses the inefficiencies of the attention mechanism in transformers, which typically has a quadratic complexity that increases inference costs for long sequences. It highlights that while sparse attention methods can reduce computation, they often lead to performance degradation due to a distributional shift in attention outputs. The authors propose a novel procedure to correct this shift, aligning sparse attention outputs more closely with those of traditional quadratic attention. Their method significantly improves performance, achieving an average increase of 36 percentage points while maintaining high sparsity and speed, making it much faster than existing methods.'}, 'zh': {'title': '稀疏注意力的分布修正，提升性能与效率', 'desc': '本文探讨了变换器的注意力机制在处理长序列时的计算复杂度问题，导致推理成本高和延迟大。尽管注意力矩阵通常是稀疏的，但稀疏注意力推理方法在减少计算负担的同时，可能会导致性能下降。我们发现，性能下降的一个原因是稀疏计算引起了注意力输出的分布偏移，这使得解码时的查询与预填阶段的键对齐不佳。为了解决这个问题，我们提出了一种简单而有效的修正方法，使稀疏注意力输出的分布更接近于二次注意力，从而显著提高了性能。'}}}, {'id': 'https://huggingface.co/papers/2505.13417', 'title': 'AdaptThink: Reasoning Models Can Learn When to Think', 'url': 'https://huggingface.co/papers/2505.13417', 'abstract': 'Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking, which prompts the reasoning model to skip thinking and directly generate the final solution, is a better choice for relatively simple tasks in terms of both performance and efficiency. Motivated by this, we propose AdaptThink, a novel RL algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty. Specifically, AdaptThink features two core components: (1) a constrained optimization objective that encourages the model to choose NoThinking while maintaining the overall performance; (2) an importance sampling strategy that balances Thinking and NoThinking samples during on-policy training, thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process. Our experiments indicate that AdaptThink significantly reduces the inference costs while further enhancing performance. Notably, on three math datasets, AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive thinking-mode selection for optimizing the balance between reasoning quality and efficiency. Our codes and models are available at https://github.com/THU-KEG/AdaptThink.', 'score': 12, 'issue_id': 3845, 'pub_date': '2025-05-19', 'pub_date_card': {'ru': '19 мая', 'en': 'May 19', 'zh': '5月19日'}, 'hash': 'edd33223d8d833a7', 'authors': ['Jiajie Zhang', 'Nianyi Lin', 'Lei Hou', 'Ling Feng', 'Juanzi Li'], 'affiliations': ['Tsinghua University'], 'pdf_title_img': 'assets/pdf/title_img/2505.13417.jpg', 'data': {'categories': ['#math', '#reasoning', '#inference', '#training', '#optimization', '#rl'], 'emoji': '🧠', 'ru': {'title': 'Адаптивное мышление для оптимизации рассуждений ИИ', 'desc': 'Исследователи представили новый алгоритм AdaptThink, который учит модели рассуждения адаптивно выбирать оптимальный режим мышления в зависимости от сложности задачи. Алгоритм использует метод обучения с подкреплением и включает в себя ограниченную целевую функцию оптимизации и стратегию выборки по важности. Эксперименты показали, что AdaptThink значительно сокращает вычислительные затраты при одновременном повышении производительности моделей. На трех наборах математических данных алгоритм сократил среднюю длину ответа модели DeepSeek-R1-Distill-Qwen-1.5B на 53% и повысил ее точность на 2.4%.'}, 'en': {'title': 'Optimize Reasoning with Adaptive Thinking Modes!', 'desc': 'This paper introduces AdaptThink, a reinforcement learning algorithm designed to optimize reasoning models by allowing them to choose between two thinking modes: NoThinking and traditional thinking. NoThinking enables models to skip lengthy reasoning processes for simpler tasks, improving efficiency without sacrificing performance. AdaptThink employs a constrained optimization objective to encourage the use of NoThinking while maintaining overall accuracy, and it uses importance sampling to balance training between both modes. The results show that AdaptThink significantly reduces inference costs and enhances performance on math tasks, demonstrating the effectiveness of adaptive thinking-mode selection.'}, 'zh': {'title': '自适应思考模式选择，提升推理效率与质量', 'desc': '最近，大型推理模型在各种任务上表现出色，但其冗长的思考过程显著增加了推理开销，导致效率成为瓶颈。本文提出了一种名为NoThinking的方法，鼓励推理模型跳过思考，直接生成最终解决方案，适用于相对简单的任务。基于此，我们提出了AdaptThink，这是一种新颖的强化学习算法，旨在根据问题难度自适应选择最佳思考模式。实验表明，AdaptThink显著降低了推理成本，同时提高了模型的性能。'}}}, {'id': 'https://huggingface.co/papers/2505.13379', 'title': 'Thinkless: LLM Learns When to Think', 'url': 'https://huggingface.co/papers/2505.13379', 'abstract': "Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless", 'score': 12, 'issue_id': 3846, 'pub_date': '2025-05-19', 'pub_date_card': {'ru': '19 мая', 'en': 'May 19', 'zh': '5月19日'}, 'hash': 'd41117eabc11e5c3', 'authors': ['Gongfan Fang', 'Xinyin Ma', 'Xinchao Wang'], 'affiliations': ['National University of Singapore'], 'pdf_title_img': 'assets/pdf/title_img/2505.13379.jpg', 'data': {'categories': ['#optimization', '#reasoning', '#rl', '#benchmark', '#training'], 'emoji': '🧠', 'ru': {'title': 'Умное переключение между кратким и развернутым мышлением в языковых моделях', 'desc': 'Статья представляет Thinkless - обучаемую систему, позволяющую языковым моделям адаптивно выбирать между кратким и развернутым рассуждением в зависимости от сложности задачи. Система использует обучение с подкреплением и два управляющих токена: <short> для кратких ответов и <think> для детального рассуждения. В основе метода лежит алгоритм DeGRPO, который разделяет цель обучения на выбор режима рассуждения и улучшение точности ответов. Эмпирические результаты показывают, что Thinkless способен сократить использование длинных цепочек рассуждений на 50-90%, значительно повышая эффективность моделей.'}, 'en': {'title': 'Thinkless: Smart Reasoning for Efficient Language Models', 'desc': "This paper introduces Thinkless, a framework designed to enhance the efficiency of Reasoning Language Models (RLMs) by enabling them to choose between short-form and long-form reasoning based on task complexity. The framework utilizes reinforcement learning and two control tokens, <short> for brief answers and <think> for detailed reasoning, to guide the model's response strategy. A novel algorithm called Decoupled Group Relative Policy Optimization (DeGRPO) is employed to separate the learning objectives, allowing for better control over reasoning mode selection and response accuracy. The results show that Thinkless can significantly reduce the reliance on long-chain reasoning, improving computational efficiency while maintaining performance on various benchmarks."}, 'zh': {'title': '让模型学会何时思考', 'desc': '本文提出了一种名为Thinkless的可学习框架，旨在提高大型语言模型（LLM）在推理任务中的效率。该框架通过强化学习训练，使模型能够根据任务复杂性和自身能力自适应选择短期或长期推理。Thinkless使用两个控制标记<short>和<think>来分别表示简洁回答和详细推理。实验结果表明，Thinkless能够将长期推理的使用减少50%至90%，显著提升推理语言模型的效率。'}}}, {'id': 'https://huggingface.co/papers/2505.13427', 'title': 'MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable\n  Step-Level Supervision', 'url': 'https://huggingface.co/papers/2505.13427', 'abstract': 'While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.', 'score': 11, 'issue_id': 3847, 'pub_date': '2025-05-19', 'pub_date_card': {'ru': '19 мая', 'en': 'May 19', 'zh': '5月19日'}, 'hash': '22362149c9b7b5ae', 'authors': ['Lingxiao Du', 'Fanqing Meng', 'Zongkai Liu', 'Zhixiang Zhou', 'Ping Luo', 'Qiaosheng Zhang', 'Wenqi Shao'], 'affiliations': ['Shanghai AI Laboratory', 'Shanghai Innovation Institute', 'Shanghai Jiao Tong University', 'The University of Hong Kong'], 'pdf_title_img': 'assets/pdf/title_img/2505.13427.jpg', 'data': {'categories': ['#optimization', '#reasoning', '#multimodal', '#math', '#training', '#open_source', '#benchmark', '#data', '#dataset'], 'emoji': '🧠', 'ru': {'title': 'Автоматизированное обучение мультимодальных моделей пошаговым рассуждениям', 'desc': 'В статье представлена модель MM-PRM, обучающаяся оценивать промежуточные шаги рассуждений в мультимодальных задачах. Авторы создали датасет MM-K12 с 10 000 мультимодальных математических задач и использовали метод Монте-Карло для генерации более 700 тысяч аннотаций шагов решения без участия человека. Применение MM-PRM в схеме вывода Best-of-N значительно улучшило результаты как на тестовом наборе MM-K12, так и на внешних бенчмарках. Исследование показывает эффективность использования мягких меток, меньших скоростей обучения и разнообразия путей для оптимизации производительности модели.'}, 'en': {'title': 'Enhancing Multimodal Reasoning with Process Supervision', 'desc': 'This paper introduces MM-PRM, a novel process reward model designed to improve the reasoning capabilities of Multimodal Large Language Models (MLLMs) in solving complex math problems. The authors highlight that MLLMs often struggle with multi-step reasoning due to insufficient supervision of intermediate steps. To overcome this, they create a strong multimodal model called MM-Policy and a new dataset, MM-K12, containing 10,000 multimodal math problems. By employing a Monte Carlo Tree Search method, they generate over 700,000 annotations to train the PRM, which significantly enhances the logical consistency of reasoning in various benchmarks.'}, 'zh': {'title': '过程监督提升多模态推理的逻辑稳健性', 'desc': '这篇论文介绍了一种新的多模态过程奖励模型（MM-PRM），旨在提高多模态大语言模型在复杂多步骤推理中的表现。研究发现，现有模型在推理过程中缺乏细粒度的监督，导致逻辑不一致或部分正确的结果。为了解决这个问题，作者构建了一个强大的多模态模型MM-Policy，并创建了一个包含10,000个可验证答案的多模态数学问题数据集MM-K12。通过无人工标注的方式生成超过70万条步骤级注释，MM-PRM在推理路径评分中表现出显著的改进，证明了过程监督在增强多模态推理系统逻辑稳健性方面的有效性。'}}}, {'id': 'https://huggingface.co/papers/2505.13215', 'title': 'Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation', 'url': 'https://huggingface.co/papers/2505.13215', 'abstract': 'Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.', 'score': 11, 'issue_id': 3846, 'pub_date': '2025-05-19', 'pub_date_card': {'ru': '19 мая', 'en': 'May 19', 'zh': '5月19日'}, 'hash': '0ab00a261298ad44', 'authors': ['Seungjun Oh', 'Younggeun Lee', 'Hyejin Jeon', 'Eunbyung Park'], 'affiliations': ['Department of Artificial Intelligence, Sungkyunkwan University', 'Department of Artificial Intelligence, Yonsei University'], 'pdf_title_img': 'assets/pdf/title_img/2505.13215.jpg', 'data': {'categories': ['#3d'], 'emoji': '🎥', 'ru': {'title': 'Гибридный 3D-4D подход для эффективной реконструкции динамических сцен', 'desc': 'Статья представляет новый метод 3D-4DGS для реконструкции динамических 3D-сцен. Он комбинирует 3D гауссианы для статичных областей и 4D гауссианы для динамических элементов. Это позволяет значительно сократить вычислительные затраты и память по сравнению с полностью 4D подходом. Метод демонстрирует более быстрое обучение при сохранении или улучшении визуального качества.'}, 'en': {'title': 'Efficient 3D-4D Scene Reconstruction with Hybrid Gaussian Splatting', 'desc': 'This paper presents a new method called hybrid 3D-4D Gaussian Splatting (3D-4DGS) for dynamic 3D scene reconstruction. It combines 3D and 4D Gaussian representations to efficiently model static and dynamic elements in a scene. By converting static regions to 3D Gaussians, the method reduces computational load and memory usage while preserving the quality of dynamic elements with 4D Gaussians. The results show that 3D-4DGS achieves faster training times and improved visual quality compared to traditional 4D Gaussian Splatting techniques.'}, 'zh': {'title': '高效的动态3D场景重建新方法', 'desc': '最近动态3D场景重建的进展显示出良好的效果，能够实现高保真度的3D新视图合成，并提高时间一致性。在这些方法中，4D高斯点云（4DGS）因其能够建模高保真的空间和时间变化而受到关注。然而，现有方法在静态区域冗余分配4D高斯时，导致了显著的计算和内存开销，并可能降低图像质量。我们提出了一种混合3D-4D高斯点云（3D-4DGS）框架，能够自适应地用3D高斯表示静态区域，同时为动态元素保留4D高斯，从而显著提高计算效率。'}}}, {'id': 'https://huggingface.co/papers/2505.12081', 'title': 'VisionReasoner: Unified Visual Perception and Reasoning via\n  Reinforcement Learning', 'url': 'https://huggingface.co/papers/2505.12081', 'abstract': 'Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object cognitive learning strategies and systematic task reformulation, VisionReasoner enhances its reasoning capabilities to analyze visual inputs, and addresses diverse perception tasks in a unified framework. The model generates a structured reasoning process before delivering the desired outputs responding to user queries. To rigorously assess unified visual perception capabilities, we evaluate VisionReasoner on ten diverse tasks spanning three critical domains: detection, segmentation, and counting. Experimental results show that VisionReasoner achieves superior performance as a unified model, outperforming Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting).', 'score': 11, 'issue_id': 3845, 'pub_date': '2025-05-17', 'pub_date_card': {'ru': '17 мая', 'en': 'May 17', 'zh': '5月17日'}, 'hash': '9b7953f88ae7653d', 'authors': ['Yuqi Liu', 'Tianyuan Qu', 'Zhisheng Zhong', 'Bohao Peng', 'Shu Liu', 'Bei Yu', 'Jiaya Jia'], 'affiliations': ['CUHK', 'HKUST', 'SmartMore'], 'pdf_title_img': 'assets/pdf/title_img/2505.12081.jpg', 'data': {'categories': ['#multimodal', '#cv', '#benchmark', '#reasoning'], 'emoji': '🧠', 'ru': {'title': 'Единая модель для многозадачного визуального восприятия', 'desc': 'В статье представлен VisionReasoner - унифицированная модель для решения различных задач визуального восприятия. Модель использует новые стратегии когнитивного обучения с несколькими объектами и систематическое переформулирование задач для улучшения способностей к рассуждению. VisionReasoner генерирует структурированный процесс рассуждений перед выдачей ответов на запросы пользователей. Экспериментальные результаты показывают превосходство VisionReasoner над Qwen2.5VL в задачах обнаружения, сегментации и подсчета объектов.'}, 'en': {'title': 'VisionReasoner: Unifying Visual Perception with Advanced Reasoning', 'desc': 'This paper presents VisionReasoner, a unified framework designed to enhance visual perception tasks through advanced reasoning capabilities. It employs innovative multi-object cognitive learning strategies and reformulates tasks systematically to improve its performance across various visual challenges. The model processes visual inputs in a structured manner, allowing it to effectively respond to user queries. Evaluation results demonstrate that VisionReasoner significantly outperforms existing models in detection, segmentation, and counting tasks, showcasing its effectiveness as a comprehensive solution for visual perception.'}, 'zh': {'title': '统一视觉感知的推理能力', 'desc': '本文介绍了一种名为VisionReasoner的统一框架，能够在共享模型中处理多种视觉感知任务。通过设计新颖的多对象认知学习策略和系统的任务重构，VisionReasoner增强了其推理能力，以分析视觉输入并解决多样的感知任务。该模型在生成所需输出之前，会先进行结构化的推理过程，以响应用户查询。实验结果表明，VisionReasoner在检测、分割和计数等三个关键领域的十个任务上表现优异，超越了Qwen2.5VL。'}}}, {'id': 'https://huggingface.co/papers/2505.12504', 'title': 'CPGD: Toward Stable Rule-based Reinforcement Learning for Language\n  Models', 'url': 'https://huggingface.co/papers/2505.12504', 'abstract': 'Recent advances in rule-based reinforcement learning (RL) have significantly improved the reasoning capability of language models (LMs) with rule-based rewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO -- often suffer from training instability, where large policy updates and improper clipping can lead to training collapse. To address this issue, we propose Clipped Policy Gradient Optimization with Policy Drift (CPGD), a novel algorithm designed to stabilize policy learning in LMs. CPGD introduces a policy drift constraint based on KL divergence to dynamically regularize policy updates, and leverages a clip mechanism on the logarithm of the ratio to prevent excessive policy updates. We provide theoretical justification for CPGD and demonstrate through empirical analysis that it mitigates the instability observed in prior approaches. Furthermore, we show that CPGD significantly improves performance while maintaining training stability. Our implementation balances theoretical rigor with practical usability, offering a robust alternative for RL in the post-training of LMs. We release our code at https://github.com/ModalMinds/MM-EUREKA.', 'score': 9, 'issue_id': 3847, 'pub_date': '2025-05-18', 'pub_date_card': {'ru': '18 мая', 'en': 'May 18', 'zh': '5月18日'}, 'hash': 'f8b07da7e5e43f1e', 'authors': ['Zongkai Liu', 'Fanqing Meng', 'Lingxiao Du', 'Zhixiang Zhou', 'Chao Yu', 'Wenqi Shao', 'Qiaosheng Zhang'], 'affiliations': ['Shanghai AI Laboratory', 'Shanghai Innovation Institute', 'Shanghai Jiao Tong University', 'Sun Yat-Sen University'], 'pdf_title_img': 'assets/pdf/title_img/2505.12504.jpg', 'data': {'categories': ['#training', '#optimization', '#rl', '#reasoning'], 'emoji': '🧠', 'ru': {'title': 'Стабильное обучение с подкреплением для языковых моделей', 'desc': 'Статья представляет новый алгоритм CPGD для стабилизации обучения с подкреплением языковых моделей. CPGD вводит ограничение на дрейф политики на основе KL-дивергенции и использует механизм отсечения для предотвращения чрезмерных обновлений политики. Авторы теоретически обосновывают CPGD и эмпирически демонстрируют, что он уменьшает нестабильность, наблюдаемую в предыдущих подходах. Результаты показывают значительное улучшение производительности при сохранении стабильности обучения.'}, 'en': {'title': 'Stabilizing Reinforcement Learning with CPGD', 'desc': 'This paper introduces Clipped Policy Gradient Optimization with Policy Drift (CPGD), a new algorithm aimed at improving the stability of reinforcement learning in language models. Traditional methods often face issues like training collapse due to large policy updates and improper clipping. CPGD addresses these challenges by using a KL divergence-based policy drift constraint to regulate updates and a clipping mechanism to limit excessive changes. The authors provide theoretical support for CPGD and demonstrate its effectiveness in enhancing performance while ensuring stable training.'}, 'zh': {'title': '稳定强化学习，提升语言模型性能', 'desc': '最近，基于规则的强化学习（RL）在语言模型（LM）的推理能力上取得了显著进展，但现有的RL方法如GRPO、REINFORCE++和RLOO常常面临训练不稳定的问题。为了解决这个问题，我们提出了一种新算法——带有策略漂移的剪切策略梯度优化（CPGD），旨在稳定语言模型中的策略学习。CPGD通过基于KL散度的策略漂移约束动态地规范策略更新，并利用对数比率的剪切机制防止过大的策略更新。我们的理论分析和实证结果表明，CPGD不仅缓解了之前方法的训练不稳定性，还显著提高了性能。'}}}, {'id': 'https://huggingface.co/papers/2505.12849', 'title': 'Accelerate TarFlow Sampling with GS-Jacobi Iteration', 'url': 'https://huggingface.co/papers/2505.12849', 'abstract': 'Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computation, TarFlow\'s sampling process is extremely slow. In this paper, we demonstrate that through a series of optimization strategies, TarFlow sampling can be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as GS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow model have varying importance: a small number of blocks play a major role in image generation tasks, while other blocks contribute relatively little; some blocks are sensitive to initial values and prone to numerical overflow, while others are relatively robust. Based on these two characteristics, we propose the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM is used to identify whether a TarFlow block is "simple" (converges in few iterations) or "tough" (requires more iterations); IGM is used to evaluate whether the initial value of the iteration is good. Experiments on four TarFlow models demonstrate that GS-Jacobi sampling can significantly enhance sampling efficiency while maintaining the quality of generated images (measured by FID), achieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in Img64uncond, and 2.51x in Img64cond without degrading FID scores or sample quality. Code and checkpoints are accessible on https://github.com/encoreus/GS-Jacobi_for_TarFlow', 'score': 5, 'issue_id': 3846, 'pub_date': '2025-05-19', 'pub_date_card': {'ru': '19 мая', 'en': 'May 19', 'zh': '5月19日'}, 'hash': '191f5a409cc6b32e', 'authors': ['Ben Liu', 'Zhen Qin'], 'affiliations': ['TapTap, Shanghai, China', 'Zhejiang University, Hangzhou, China'], 'pdf_title_img': 'assets/pdf/title_img/2505.12849.jpg', 'data': {'categories': ['#optimization', '#architecture', '#open_source', '#cv', '#training'], 'emoji': '🚀', 'ru': {'title': 'Ускорение генерации изображений в TarFlow с помощью оптимизированных итераций', 'desc': 'Данная статья представляет метод ускорения процесса сэмплирования в модели TarFlow для генерации изображений. Авторы применяют итерационный метод Гаусса-Зейделя-Якоби и вводят две метрики: Convergence Ranking Metric (CRM) и Initial Guessing Metric (IGM). CRM используется для определения сложности блоков TarFlow, а IGM оценивает качество начальных значений для итераций. Эксперименты показали значительное ускорение сэмплирования (до 5.32 раз) без ухудшения качества генерируемых изображений.'}, 'en': {'title': 'Accelerating TarFlow: Faster Sampling without Quality Loss', 'desc': 'This paper presents an optimization strategy for the TarFlow model, which combines transformer architecture with Normalizing Flow for image generation. The authors introduce the Gauss-Seidel-Jacobi (GS-Jacobi) iteration method to accelerate the slow sampling process of TarFlow. They identify that certain blocks within the model are more critical for image generation and propose metrics to evaluate their performance: the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM). Experimental results show that the GS-Jacobi method significantly improves sampling speed while preserving image quality, achieving notable speed-ups across various benchmarks.'}, 'zh': {'title': '加速TarFlow采样，提升图像生成效率', 'desc': '图像生成模型在多个应用中取得了显著进展。TarFlow模型结合了变换器架构和归一化流模型，在多个基准测试中达到了最先进的结果。然而，由于因果注意力的顺序计算，TarFlow的采样过程非常缓慢。本文通过优化策略，利用高斯-赛德尔-雅可比迭代方法显著加速了TarFlow的采样过程，同时保持生成图像的质量。'}}}, {'id': 'https://huggingface.co/papers/2505.11932', 'title': 'Neuro-Symbolic Query Compiler', 'url': 'https://huggingface.co/papers/2505.11932', 'abstract': "Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar G[q] to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.", 'score': 3, 'issue_id': 3846, 'pub_date': '2025-05-17', 'pub_date_card': {'ru': '17 мая', 'en': 'May 17', 'zh': '5月17日'}, 'hash': '9445be4eff7e4edc', 'authors': ['Yuyao Zhang', 'Zhicheng Dou', 'Xiaoxi Li', 'Jiajie Jin', 'Yongkang Wu', 'Zhonghua Li', 'Qi Ye', 'Ji-Rong Wen'], 'affiliations': ['Huawei Poisson Lab', 'Renmin University of China'], 'pdf_title_img': 'assets/pdf/title_img/2505.11932.jpg', 'data': {'categories': ['#optimization', '#reasoning', '#rag', '#multimodal'], 'emoji': '🧠', 'ru': {'title': 'Компиляция запросов для точного поиска в RAG-системах', 'desc': 'QCompiler - это нейро-символическая система для улучшения понимания сложных запросов в RAG-системах. Она использует минимальную грамматику BNF для формализации запросов и компилирует их в абстрактные синтаксические деревья. Это позволяет более точно извлекать документы и генерировать ответы на сложные запросы с вложенными структурами. QCompiler включает в себя переводчик выражений запросов, лексический синтаксический анализатор и рекурсивный процессор.'}, 'en': {'title': 'Enhancing Query Understanding in RAG Systems with QCompiler', 'desc': 'This paper introduces QCompiler, a neuro-symbolic framework designed to enhance the understanding of complex search queries in Retrieval-Augmented Generation (RAG) systems. It utilizes a specially designed Backus-Naur Form (BNF) grammar to formalize these queries, ensuring that they are both complete and free of unnecessary complexity. QCompiler operates through a series of components, including a Query Expression Translator and a Lexical Syntax Parser, which work together to convert queries into Abstract Syntax Trees (ASTs). By focusing on the atomicity of sub-queries, QCompiler improves the accuracy of document retrieval and response generation for intricate queries.'}, 'zh': {'title': '提升RAG系统的复杂查询识别能力', 'desc': '本文提出了一种名为QCompiler的神经符号框架，旨在提高检索增强生成（RAG）系统对复杂查询的识别能力。QCompiler基于语言语法规则和编译器设计，设计了一种最小但足够的巴科斯-诺尔形式（BNF）语法G[q]，以形式化复杂查询。与以往方法不同，这种语法在保持完整性的同时，减少了冗余。通过将查询编译成抽象语法树（AST），QCompiler能够更精确地检索文档并生成响应，从而显著提升RAG系统处理复杂查询的能力。'}}}, {'id': 'https://huggingface.co/papers/2505.13437', 'title': 'FinePhys: Fine-grained Human Action Generation by Explicitly\n  Incorporating Physical Laws for Effective Skeletal Guidance', 'url': 'https://huggingface.co/papers/2505.13437', 'abstract': 'Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as "switch leap with 0.5 turn" poses substantial difficulties for current methods, often yielding unsatisfactory results. To bridge this gap, we propose FinePhys, a Fine-grained human action generation framework that incorporates Physics to obtain effective skeletal guidance. Specifically, FinePhys first estimates 2D poses in an online manner and then performs 2D-to-3D dimension lifting via in-context learning. To mitigate the instability and limited interpretability of purely data-driven 3D poses, we further introduce a physics-based motion re-estimation module governed by Euler-Lagrange equations, calculating joint accelerations via bidirectional temporal updating. The physically predicted 3D poses are then fused with data-driven ones, offering multi-scale 2D heatmap guidance for the diffusion process. Evaluated on three fine-grained action subsets from FineGym (FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms competitive baselines. Comprehensive qualitative results further demonstrate FinePhys\'s ability to generate more natural and plausible fine-grained human actions.', 'score': 2, 'issue_id': 3847, 'pub_date': '2025-05-19', 'pub_date_card': {'ru': '19 мая', 'en': 'May 19', 'zh': '5月19日'}, 'hash': '28a08dbfb09c6639', 'authors': ['Dian Shao', 'Mingfei Shi', 'Shengda Xu', 'Haodong Chen', 'Yongle Huang', 'Binglu Wang'], 'affiliations': ['School of Astronautics, Northwestern Polytechnical University, Xian, China', 'School of Automation, Northwestern Polytechnical University, Xian, China', 'School of Software, Northwestern Polytechnical University, Xian, China', 'Unmanned System Research Institute, Northwestern Polytechnical University, Xian, China'], 'pdf_title_img': 'assets/pdf/title_img/2505.13437.jpg', 'data': {'categories': ['#3d', '#optimization', '#diffusion', '#video'], 'emoji': '🤸', 'ru': {'title': 'Точная генерация движений человека с помощью физического моделирования', 'desc': 'Статья представляет FinePhys - фреймворк для генерации точных движений человека с использованием физических моделей. Система сначала оценивает 2D позы, затем преобразует их в 3D с помощью обучения в контексте. Далее применяется физическое моделирование на основе уравнений Эйлера-Лагранжа для улучшения 3D поз. Полученные физически корректные позы комбинируются с данными для создания многомасштабных 2D тепловых карт, используемых в процессе диффузии.'}, 'en': {'title': 'Bridging Physics and Data for Realistic Human Action Generation', 'desc': 'This paper presents FinePhys, a framework designed to improve the generation of fine-grained human actions in videos by integrating physics-based modeling. It addresses the challenges of synthesizing complex movements, such as gymnastics routines, by first estimating 2D poses and then converting them to 3D using in-context learning. To enhance the stability and interpretability of the generated poses, FinePhys employs a motion re-estimation module based on Euler-Lagrange equations, which calculates joint accelerations through bidirectional temporal updates. The combination of physics-based predictions with data-driven approaches results in more realistic and coherent human actions, as demonstrated by superior performance on benchmark datasets.'}, 'zh': {'title': 'FinePhys：物理驱动的细粒度人类动作生成框架', 'desc': '尽管视频生成技术取得了显著进展，但合成物理上合理的人类动作仍然是一个持续的挑战，尤其是在建模细粒度语义和复杂时间动态方面。本文提出了FinePhys，一个细粒度人类动作生成框架，结合物理学以获得有效的骨骼指导。FinePhys首先以在线方式估计2D姿势，然后通过上下文学习进行2D到3D的维度提升。通过引入基于物理的运动重新估计模块，FinePhys能够生成更自然和合理的细粒度人类动作。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (2)', '#agents', '#agi', '#alignment', '#architecture (2)', '#audio', '#benchmark (4)', '#cv (2)', '#data (1)', '#dataset (1)', '#diffusion (1)', '#ethics', '#games', '#graphs', '#hallucinations', '#healthcare', '#inference (2)', '#interpretability', '#leakage', '#long_context (1)', '#low_resource', '#machine_translation', '#math (2)', '#multilingual', '#multimodal (3)', '#open_source (2)', '#optimization (9)', '#plp', '#rag (1)', '#reasoning (7)', '#rl (4)', '#rlhf (1)', '#robotics', '#science', '#security', '#small_models', '#story_generation', '#survey', '#synthetic', '#training (6)', '#transfer_learning', '#video (1)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-05-20 04:15',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-05-20 04:15')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-05-20 04:15')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    