
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF (10 —Å—Ç–∞—Ç–µ–π)</title>
    <link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0989eacf;
            --secondary-color: #fff;
            --background-color: #f5f5f5;
            --text-color: #333333;
            --header-color: #0989eacf;
            --body-color: #f5f5f5;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        header {
            padding: 1.6em 0;
            text-align: center;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2em;
            padding: 10px 0 20px 0;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.tags {
            color: #555;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
            transition: background-color 0.2s ease;
            display: flex;
            flex-direction: column;
            position: relative;
        }
        .article-content {
            padding: 1.5em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
        }
        body.dark-theme>div>main>article {
            background-color: #444;
        }
        body.light-theme>div>main>article {
            background-color: #fff;
        }
        body.dark-theme>div>main>article:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
        }
        .pub-date {
            font-size: 0.9em;
            margin-bottom: 0.8em;
            font-weight: 300;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 1em;
            position: absolute;
            bottom: 10px;
            font-weight: 300;
            font-family: 'Roboto Slab';
        }
        .background-digit {
            position: absolute;
            bottom: -20px;
            right: -10px;
            font-size: 12em;
            font-weight: bold;
            color: rgba(0, 0, 0, 0.03);
            z-index: 0;
            line-height: 1;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 80px;
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        a:hover {
            color: var(--secondary-color);
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 1em 0;
            margin-top: 2em;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
        }
        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
        }
        .update-info-container {
            flex: 1;
        }
        .sort-container {
            flex: 2;
        }
        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .category-toggle {
            display: none;
            margin-bottom: 10px;
            margin-top: 15px;
            cursor: pointer;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }

        .svg-container span {
            position: relative;
            z-index: 1;
        }

        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .sort-container {
                margin-top: 0px;
                text-align: left;
                width: 100%;
            .sort-dropdown {
                float: right;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiffRu(dateString) {
        const timeUnits = {
            minute: ["–º–∏–Ω—É—Ç—É", "–º–∏–Ω—É—Ç—ã", "–º–∏–Ω—É—Ç"],
            hour: ["—á–∞—Å", "—á–∞—Å–∞", "—á–∞—Å–æ–≤"],
            day: ["–¥–µ–Ω—å", "–¥–Ω—è", "–¥–Ω–µ–π"]
        };

        function getRussianPlural(number, words) {
            if (number % 10 === 1 && number % 100 !== 11) {
                return words[0];
            } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                return words[1];
            } else {
                return words[2];
            }
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);

        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes == 0) {
            return '—Ç–æ–ª—å–∫–æ —á—Ç–æ';
        }
        else if (minutes < 60) {
            return `${minutes} ${getRussianPlural(minutes, timeUnits.minute)} –Ω–∞–∑–∞–¥`;
        } else if (hours < 24) {
            return `${hours} ${getRussianPlural(hours, timeUnits.hour)} –Ω–∞–∑–∞–¥`;
        } else {
            return `${days} ${getRussianPlural(days, timeUnits.day)} –Ω–∞–∑–∞–¥`;
        }
    }
    function formatArticlesTitle(number) {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;

        let word;

        if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
            word = "—Å—Ç–∞—Ç–µ–π";
        } else if (lastDigit === 1) {
            word = "—Å—Ç–∞—Ç—å—è";
        } else if (lastDigit >= 2 && lastDigit <= 4) {
            word = "—Å—Ç–∞—Ç—å–∏";
        } else {
            word = "—Å—Ç–∞—Ç–µ–π";
        }

        return `${number} ${word}`;
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">
            <h1 class="title-sign" id="doomgrad-icon">üî∫</h1><h1 class="title-text" id="doomgrad">—Ö—Ñ –¥—ç–π–ª–∏</h1>
            <p>22 –æ–∫—Ç—è–±—Ä—è | 10 —Å—Ç–∞—Ç–µ–π</p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">üîÄ –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ</label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">—Ä–µ–π—Ç–∏–Ω–≥—É</option>
                    <option value="pub_date">–¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏</option>
                    <option value="issue_id">–¥–æ–±–∞–≤–ª–µ–Ω–∏—é –Ω–∞ HF</option>
                </select>
            </div>
        </div>
        <div class="category-toggle">
            <div class="svg-container">
                <span id="category-toggle">üîç –§–∏–ª—å—Ç—Ä</span>
                <svg height="3" width="200">
                    <line x1="0" y1="0" x2="200" y2="0" 
                        stroke="black" 
                        stroke-width="2" 
                        stroke-dasharray="3, 3" />
                </svg>
            </div>
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">üßπ</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">–≥—Ä–∞–¥–∏–µ–Ω—Ç –æ–±—Ä–µ—á–µ–Ω–Ω—ã–π</a> ‚úñÔ∏è <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>    
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "—Ö—Ñ –Ω–∞–π—Ç–ª–∏";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "—Ö—Ñ –¥—ç–π–ª–∏";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2410.13861', 'title': 'PUMA: Empowering Unified MLLM with Multi-granular Visual Generation', 'url': 'https://huggingface.co/papers/2410.13861', 'abstract': 'Recent advancements in multimodal foundation models have yielded significant progress in vision-language understanding. Initial attempts have also explored the potential of multimodal large language models (MLLMs) for visual content generation. However, existing works have insufficiently addressed the varying granularity demands of different image generation tasks within a unified MLLM paradigm - from the diversity required in text-to-image generation to the precise controllability needed in image manipulation. In this work, we propose PUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA unifies multi-granular visual features as both inputs and outputs of MLLMs, elegantly addressing the different granularity requirements of various image generation tasks within a unified MLLM framework. Following multimodal pretraining and task-specific instruction tuning, PUMA demonstrates proficiency in a wide range of multimodal tasks. This work represents a significant step towards a truly unified MLLM capable of adapting to the granularity demands of various visual tasks. The code and model will be released in https://github.com/rongyaofang/PUMA.', 'score': 12, 'issue_id': 208, 'pub_date': '2024-10-17', 'pub_date_ru': '17 –æ–∫—Ç—è–±—Ä—è', 'hash': '31995f0502d70f2f', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç PUMA - –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è (MLLM) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. PUMA –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–∑–Ω–æ–π –≥—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –∫–∞–∫ –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö, —Ç–∞–∫ –∏ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö MLLM, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ—à–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ä–∞–º–∫–∞—Ö –µ–¥–∏–Ω–æ–π –ø–∞—Ä–∞–¥–∏–≥–º—ã. –ú–æ–¥–µ–ª—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤—ã—Å–æ–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ —à–∏—Ä–æ–∫–æ–º —Å–ø–µ–∫—Ç—Ä–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ—Å–ª–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. –≠—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —à–∞–≥ –∫ —Å–æ–∑–¥–∞–Ω–∏—é —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π MLLM, —Å–ø–æ—Å–æ–±–Ω–æ–π –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≥—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á.', 'emoji': 'üêÜ', 'title': 'PUMA: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è MLLM –¥–ª—è –º—É–ª—å—Ç–∏–≥—Ä–∞–Ω—É–ª—è—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', 'categories': ['#multimodal', '#nlp', '#cv', '#training', '#code'], 'embedding': [-0.005515939772697067, 0.08036688959128836, 0.06423204261641437, 0.053219372279397284, -0.06356616236074848, -0.04141276439943629, 0.07929123339975691, 0.08000833616014379, -0.030630592257236897, 0.040516387999903834, 0.037391862383800316, -0.02111615608463256, -0.07519349249966162, -0.002165718674060336, -0.046714212625487625, -0.02635357976894717, -0.005365475639119662, -0.04602272009198567, 0.039312674521094375, 0.03411366925353385, 0.07114697615523845, -0.07498860863363112, -0.050683898289256034, 0.011313598604171898, -0.005563960127403196, -0.07524471500438261, -0.02952932583882053, 0.10510697994556051, -0.0012573333403179668, 0.026865796612352402, -0.014060364246990283, -0.04420434886223129, -0.11125359027022787, -0.04507512118773224, -0.02016855512942799, 0.09937014965866098, -0.08333775384608237, 0.15315296128618447, -0.0382882408342839, 0.10807784009845223, 0.017428191120402822, -0.1633973002052403, 0.04778986881701907, 0.0494545766345128, 0.03785285672248457, 0.08507928414042629, 0.01854226572868836, 0.08384996863853646, 0.0035471044093652836, 0.056036569020028355, -0.03191113641670112, 0.034805161787035806, -0.00571442364569526, 0.013394481325087908, -0.05808543844460043, -0.07345195810341543, 0.008822941588151246, -0.017261721569224134, -0.06546136632210876, 0.01998927943933127, -0.03926145406732453, -0.07478372476760063, 0.04317991517542082, -0.03467711065261121, -0.07744724784121534, -0.08180109921396438, -0.052809600445434014, -0.026481631928847334, 0.014879910991343543, -0.01122396075912354, 0.022972943680189886, -0.11391712154764715, 0.0385187390291016, -0.0052118107911932054, -0.012542919848724916, 0.027224347992545837, -0.053731593224704804, 0.038569961533822576, -0.06827856306273983, -0.02270403117052038, 0.031834303685095225, 0.0338063403780614, -0.03411366925353385, -0.011620929120405266, -0.03962000749846911, -0.031450140027065726, 0.019669142373989645, -0.013279232842964402, -0.06674190843062183, -0.062490508220168176, -0.042770141290506415, 0.01594276206943253, -0.06643458365705167, 0.050863173979352756, 0.0539364770907353, 0.08579638895176431, -0.008189073398258605, -0.09102100649716087, 0.09009902192169465, 0.09091856558962119, -0.0420018180763497, 0.00494609797039718, 0.0419249853447438, -0.0420018180763497, 0.049582631870839666, -0.07186407686467418, -0.02347235643562823, 0.012638960558137175, 0.012498101438938522, 0.07360562151567608, -0.043692134069777205, -0.016288510387134646, -0.005784853718032372, 0.036393038923874764, 0.07293973920905905, -0.11985883570057716, 0.022396700244096783, 0.00028952282531782836, 0.020360636958442736, -0.009187897473469495, -0.045920277133494856, -0.004216188455806937, -0.02773656483595107, -0.13030808309707717, 0.05501213328226674, -0.08953558052261729, 0.009821766073552363, 0.0004902079226460264, -0.042898194475882154, -0.011294391036555766, 0.006085781164806725, 0.018567875955573278, 0.04202742625228348, -0.04973629528310033, -0.13932310036138973, -0.04358968700938411, -0.06679313093534282, 0.012542919848724916, -0.04661177171794794, 0.09506752694348632, 0.08000833616014379, -0.04968507482933049, -0.014854300764458622, 0.04361529928722016, -0.08052055505450016, -0.02600783247672062, -0.006098586688439413, 0.022371090017211864, -0.07760091535537827, 0.047226431519844, -0.09896037372279542, -0.08661594287444656, -0.04015783251780812, 0.006972557267148046, -0.0814937641856385, -0.06561502973436942, -0.06346371735130653, 0.11688797964958772, 0.03831385106116883, -0.10403132990688248, 0.07263240418073318, 0.03570154433942168, -0.0002671132922724487, 0.007042987339485158, 0.07145431118356432, 0.05619023653419129, -0.10623386274371521, 0.04458851252026079, -0.11494155113255533, -0.1270298838139573, -0.13030808309707717, -0.010769368054232502, -0.04371774634761326, -0.07616671188555567, 0.03255140849643324, -0.08041811414696048, -0.10992182360604268, -0.06981520949105326, -0.06643458365705167, -0.14249883412555628, 0.0033166068298329282, 0.11709286146466709, -0.06920054763820606, -0.026507243181207823, -0.07155675209110401, -0.024240681700736084, 0.04469095752970275, 0.11760508651187689, 0.009239118542524674, 0.048430140896751184, -0.09035512419054384, 0.09194299722548052, 0.04983873824159115, 0.09686028179350237, 0.09337720479720542, -0.021346654279450254, 0.09409430960854341, -0.010551675383047493, -0.043794574977316876, 0.023690048491527897, -0.008310725565126468, 0.14936254721061049, -0.04090054960698219, -0.07350317650623413, -0.009988236650206622, -0.030374483835534278, -0.009373576027930113, 0.010859006104375974, -0.08569394804422462, -0.0013757835622660948, 0.019541087137662765, 0.02018135921739488, 0.1481332276068184, -0.06018552832294234, -0.022243034780884983, -0.11678553669109691, -0.08507928414042629, 0.06576869929948351, 0.008381154406892894, -0.053321817288839245, 0.03649547983141445, -0.03106597841998737, 0.07647404076102812, 0.08856236318767438, -0.05552435422757426, -0.002914836371552054, 0.01589154059018712, -0.07570571344496914, 0.043948240440528676, -0.05460235939735233, 0.06914932718443623, -0.017786744551547398, -0.04264208810513067, -0.03093792318366049, 0.004958903288934754, -0.09491385532742111, 0.0882550322612508, -0.046406881699064026, 0.09588707266236401, -0.03260262895020307, 0.058802541204987305, 0.08016199957240444, 0.030553759525630997, -0.04599710986510075, -0.035855207751682334, 0.1026483407379763, -0.05306571091808777, 0.016480590165198254, 0.09665539997842301, 0.042257926498052316, 0.10018969742848981, -0.022089369317673187, -0.15243586467865103, 0.04279575151739133, -0.02198692430823123, 0.07647404076102812]}}, {'id': 'https://huggingface.co/papers/2410.14940', 'title': 'Baichuan Alignment Technical Report', 'url': 'https://huggingface.co/papers/2410.14940', 'abstract': "We introduce Baichuan Alignment, a detailed analysis of the alignment techniques employed in the Baichuan series of models. This represents the industry's first comprehensive account of alignment methodologies, offering valuable insights for advancing AI research. We investigate the critical components that enhance model performance during the alignment process, including optimization methods, data strategies, capability enhancements, and evaluation processes. The process spans three key stages: Prompt Augmentation System (PAS), Supervised Fine-Tuning (SFT), and Preference Alignment. The problems encountered, the solutions applied, and the improvements made are thoroughly recorded.   Through comparisons across well-established benchmarks, we highlight the technological advancements enabled by Baichuan Alignment. Baichuan-Instruct is an internal model, while Qwen2-Nova-72B and Llama3-PBM-Nova-70B are instruct versions of the Qwen2-72B and Llama-3-70B base models, optimized through Baichuan Alignment. Baichuan-Instruct demonstrates significant improvements in core capabilities, with user experience gains ranging from 17% to 28%, and performs exceptionally well on specialized benchmarks. In open-source benchmark evaluations, both Qwen2-Nova-72B and Llama3-PBM-Nova-70B consistently outperform their respective official instruct versions across nearly all datasets. This report aims to clarify the key technologies behind the alignment process, fostering a deeper understanding within the community. Llama3-PBM-Nova-70B model is available at https://huggingface.co/PKU-Baichuan-MLSystemLab/Llama3-PBM-Nova-70B.", 'score': 9, 'issue_id': 208, 'pub_date': '2024-10-19', 'pub_date_ru': '19 –æ–∫—Ç—è–±—Ä—è', 'hash': 'e1222b08a95a2911', 'data': {'desc': '–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–≤ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (alignment), –ø—Ä–∏–º–µ–Ω—è–µ–º—ã—Ö –≤ —Å–µ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π Baichuan. –û–ø–∏—Å—ã–≤–∞—é—Ç—Å—è —Ç—Ä–∏ –∫–ª—é—á–µ–≤—ã—Ö —ç—Ç–∞–ø–∞: —Å–∏—Å—Ç–µ–º–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ (PAS), –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–∞—è —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ (SFT) –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π. –ò—Å—Å–ª–µ–¥—É—é—Ç—Å—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, —É–ª—É—á—à–∞—é—â–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è, –≤–∫–ª—é—á–∞—è –º–µ—Ç–æ–¥—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã –æ—Ü–µ–Ω–∫–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö –º–æ–¥–µ–ª–µ–π –∏ –∏—Ö –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö.', 'emoji': 'üß†', 'title': '–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –º–µ—Ç–æ–¥ Baichuan Alignment', 'categories': ['#alignment', '#optimization', '#benchmark'], 'embedding': [0.03515107729354385, -0.012261695083905465, 0.21489185304466513, -0.046203874065898105, -0.03663895588269507, -0.027631987140123184, 0.028747895602910353, -0.0001923154808563981, -0.05659243737471371, 0.004267680744370783, 0.03172364703229786, -0.028296218687356853, -0.06562597568578374, -0.039349015459711104, 0.061587454930605336, 0.050561225810444255, -0.000572483674887895, -0.11966776514555533, -0.02599798071499462, 0.0742875362052698, 0.024496821174204278, 0.02549316657874981, 0.032998970989768915, 0.11074050894108783, 0.0507472089573213, -0.044530012329869834, 0.02125537501798783, -0.03480567865198292, -0.02486879034241584, -0.15091317527532644, 0.04880765536892156, -0.05088005679981202, -0.05098633315749962, -0.003723011872117762, -0.11775477920934876, 0.10505469410207434, -0.037196905323326215, 0.01317833293273955, -0.014559932864637202, -0.00926601484928512, -0.01353701712507154, -0.01745597654668277, -0.0595150515834099, 0.013111909969646679, -0.014334094406860452, 0.013151763939132899, 0.05141144050455498, 0.0423779060260949, -0.06977077279864971, 0.038100259154433214, -0.06621049277860805, 0.105904912628795, -0.025838566178463224, -0.021029536560211077, 0.04771831839093751, 0.03206904759016377, 0.01628693086320429, 0.10016595865278523, 0.07742270696195115, 0.02380602101662496, -0.008555288377669428, -0.09708392703310018, -0.03942872224890055, 0.05359011446052307, -0.07960138283422423, -0.16154086853323527, -0.10834927843713459, 0.006841574013568425, -0.0002013448684508892, -0.08613741045104346, 0.018053785130823567, 0.08326793537934354, 0.01733641636289859, 0.04503482838241962, 0.06780464964175184, -0.012620379084606958, -0.011059437535619556, 0.17663217264663308, 0.01995348340832361, 0.011750237118307385, -0.10059106408353562, -9.989404072554533e-05, 0.06100293017256112, -0.06913310698730425, 0.06211883671904332, 0.01800064695197977, -0.003349382225644129, 0.017695100746861078, -0.06488203543305562, -0.07226827966029056, -0.033689772105500726, -0.04240447559459304, -0.019036845751120024, 0.002763198905642816, 0.09671196457195602, 0.05616733002765834, -0.03182992530629043, 0.008820980996562896, 0.018598452661663108, 0.07694445856159453, 0.032255034569650766, -0.038551937986291696, 0.06063096196250205, -0.0036300197237877454, 0.18056441129520895, -0.09107928312102388, 0.05839914503692771, -0.045008258813921474, -0.07338419003938272, 0.07960138283422423, -0.09564918758094523, 0.08921944207072852, -0.08385245438847284, 0.01924940038280019, -0.012919282993416364, -0.02408499861139799, 0.020617713039252302, 0.016433062531791588, -0.04360008893026469, 0.00454001546794304, -0.00688807027936393, 0.023314490706476728, 0.08847550181800043, -0.05558280910222408, 0.014121540733332771, -0.03464626124099406, 0.0902290741758281, -0.06743268334799774, -0.060896653814873525, -0.10500155496507804, 0.044025196277320044, 0.024975066700103438, 0.03754230971380207, -0.0553171172498526, -0.12211214628433473, -0.053616685945326197, -0.04522081152929667, -0.019647938161357407, -0.12731970505777168, -0.02888074152909609, 0.028083664055676683, -0.08900688552274337, -0.03090000190668529, -0.07779467517201022, -0.0953303623404924, 0.02654265016213913, -0.0007435230156455807, -0.060896653814873525, 0.043228122636510595, 0.03980069045895963, -0.08496836285126001, -0.033450645989017445, -0.0915575315213805, -0.02922614017065702, -0.03748916866050081, 0.02516105176328546, -0.05813345318455623, 0.014201247522522224, 0.07109923014420214, -0.1044701712603351, 0.04580533628734088, -0.025014920094698162, -0.019594799982513608, -0.012527387702798933, 0.07131178860849226, -0.017216854262809438, -0.06764523223076298, 0.02164062897044846, -0.15750233244761708, -0.08704076044954051, 0.07556286016274086, 0.012195272120812596, -0.0046130807273451965, -0.0734373215111591, 0.04277644380465211, -0.04673525777064105, -0.034486849578920134, -0.13932899671453422, -0.09724334444408902, -0.08204574864256381, 0.021959459959816224, 0.0064131453267279245, -0.039774120890461485, 0.023221498174885717, -0.10904007763656141, 0.0009149775047133593, -0.015011608822038214, 0.020723991313244875, -0.0010320481783765638, 0.04753233524406046, 0.004510125326181747, 0.0789105836347974, 0.13220842900923094, 0.051517716862242574, -0.01563598697467716, -0.06031212905682931, 0.03637326019771364, -0.014719347401168596, 0.07859174881281968, -0.03111255653836546, 0.00519428261256029, -0.04997670488500999, 0.1281699197518824, -0.06865486433586256, -0.03966784453277389, -0.05935563608872602, 0.0027399508685603115, 0.014878762895852476, -0.12094309293563635, -0.06344729406459572, 0.045699058013348316, -0.008003977400737617, 0.1173296718622934, -0.009305869202032333, -0.14007292546943245, -0.011079364424547416, -0.14272984399314723, -0.022610405764648334, -0.036506108040204356, 0.011922937205609841, 0.0772632895509623, -0.00874127363248195, 0.09293912992023418, 0.08193947228487622, -0.048276271664178604, 0.08077043426661763, 0.00026278619746182216, -0.0096246999997696, 0.08720017402791942, -0.09469269652914691, 0.023992005121654492, 0.006994346828682023, 0.061587454930605336, 0.017057438768125554, 0.016074378147829096, -0.04046492008988832, 0.001531881550541898, 0.012666875542032963, 0.042670167446964516, -0.08826295101893021, -0.006702085599442901, 0.0009075049309469364, 0.037250046376627474, -0.0017568896733723635, 0.04245761473158932, 0.09256716362648008, -0.04110258206862385, -0.10282288100910995, 0.038047121933741906, 0.0028063740232836783, 0.044742566961550004, 0.04604445857121422, -0.07800722597108044, -0.043174979666904346, -0.00022044150100096872, 0.03950842903809001]}}, {'id': 'https://huggingface.co/papers/2410.16256', 'title': 'CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution', 'url': 'https://huggingface.co/papers/2410.16256', 'abstract': 'Efficient and accurate evaluation is crucial for the continuous improvement of large language models (LLMs). Among various assessment methods, subjective evaluation has garnered significant attention due to its superior alignment with real-world usage scenarios and human preferences. However, human-based evaluations are costly and lack reproducibility, making precise automated evaluators (judgers) vital in this process. In this report, we introduce CompassJudger-1, the first open-source all-in-one judge LLM. CompassJudger-1 is a general-purpose LLM that demonstrates remarkable versatility. It is capable of: 1. Performing unitary scoring and two-model comparisons as a reward model; 2. Conducting evaluations according to specified formats; 3. Generating critiques; 4. Executing diverse tasks like a general LLM. To assess the evaluation capabilities of different judge models under a unified setting, we have also established JudgerBench, a new benchmark that encompasses various subjective evaluation tasks and covers a wide range of topics. CompassJudger-1 offers a comprehensive solution for various evaluation tasks while maintaining the flexibility to adapt to diverse requirements. Both CompassJudger and JudgerBench are released and available to the research community athttps://github.com/open-compass/CompassJudger. We believe that by open-sourcing these tools, we can foster collaboration and accelerate progress in LLM evaluation methodologies.', 'score': 7, 'issue_id': 208, 'pub_date': '2024-10-21', 'pub_date_ru': '21 –æ–∫—Ç—è–±—Ä—è', 'hash': '3b5265f629378d5d', 'data': {'desc': '–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω CompassJudger-1 - –ø–µ—Ä–≤–∞—è –æ—Ç–∫—Ä—ã—Ç–∞—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å-–æ—Ü–µ–Ω—â–∏–∫ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –≠—Ç–∞ –º–æ–¥–µ–ª—å —Å–ø–æ—Å–æ–±–Ω–∞ –≤—ã–ø–æ–ª–Ω—è—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏ –æ—Ü–µ–Ω–∫–∏, –≤–∫–ª—é—á–∞—è —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫—Ä–∏—Ç–∏–∫–∏ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±—â–∏—Ö –∑–∞–¥–∞—á –∫–∞–∫ –æ–±—ã—á–Ω–∞—è LLM. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ —Å–æ–∑–¥–∞–ª–∏ –±–µ–Ω—á–º–∞—Ä–∫ JudgerBench –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π-–æ—Ü–µ–Ω—â–∏–∫–æ–≤. CompassJudger-1 –∏ JudgerBench –¥–æ—Å—Ç—É–ø–Ω—ã —Å–æ–æ–±—â–µ—Å—Ç–≤—É –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è –º–µ—Ç–æ–¥–æ–≤ –æ—Ü–µ–Ω–∫–∏ LLM.', 'emoji': '‚öñÔ∏è', 'title': 'CompassJudger-1: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å—É–¥—å—è –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π', 'categories': ['#benchmark', '#nlp'], 'embedding': [0.016274579779880796, -0.002393027390890161, 0.09294445244371195, 0.01037587459419362, -0.008482709678535198, -0.013883212012686044, 0.00529422011163281, 0.0008054256015571237, 0.062228675825496266, 0.04360258687461549, 0.04724277707125545, -0.09097821672401848, 0.023847240429211092, -0.03608306674452624, 0.03682704980104672, -0.03138004445573983, 0.0003391921148130687, -0.0171514136411556, -0.012893452697967864, 0.10208479146498968, 0.04623309043183311, -0.020618894436846474, 0.08460124193167878, -0.0869394701663291, 0.04673793375154428, -0.10989659086443267, -0.051998942839372744, -0.007851654048851318, 0.04296488880336355, -0.1001716992246271, 0.09459184110117266, -0.03231002376973873, -0.03650819681863432, 0.043257168072717296, -0.02835098256407958, 0.12137514825339463, -0.011711054684203205, 0.012587889137495973, -0.03347913492697407, 0.06010301756138304, -0.026477744973125324, 0.00313036563777072, 0.01178412430420232, -0.024352084735618874, -0.07184728445342653, 0.0015518974226670123, 0.0764174539640654, 0.09788661446930766, -0.08922455492164853, 0.05303519924506731, -0.07572661636026902, 0.08077505547756039, 0.08720517374923098, -0.0038295080695810633, 0.06031558161174047, -0.05468258790252803, -0.06647999630050917, 0.08226301369702847, 0.030104650286629182, -0.03549851017921197, 0.012727384949229537, -0.03850100625138644, 3.669045744275317e-05, -0.04049381173735213, -0.08438867393453492, -0.03929812489366493, -0.036215921496067005, -0.015490742073951992, 0.024405226241556534, 0.01001052708621601, 0.032575731299427035, 0.016473858947102116, 0.051520667312540576, -0.03868699856207843, -0.04617995089928866, 0.00470966394099718, 0.1435882819481913, 0.15634224732001642, -0.011000287782309444, 0.00872848889682273, -0.04780076387029751, 0.014109063906269408, 0.00510490381740629, -0.0655765867527825, 0.06477947403068365, 0.02708887130471182, -0.010123452934338032, 0.03199117078732633, -0.08029678389751466, -0.06860565653801562, -0.049368437308761906, 0.029387240943167362, 0.014547481231585453, 0.1081429152483102, 0.11584843558266429, -0.07253812600400933, -0.08040306493599676, -0.1086743303076868, 0.08927769050740654, 0.048411892175277214, -0.03850100625138644, 0.019343499281039216, 0.07142215635271167, -0.019795202081509335, 0.11117198503354332, 0.0007962919286581326, 0.00768558708947028, -0.037066185591069584, -0.00614116278851204, -0.0050484410906846, -0.1279646831493053, 0.037757023194865964, -0.16771451775031662, -0.05369946708259147, -0.01883865596132804, -0.17334751737970872, -0.03390426500108214, -0.05072354472347566, -0.0491824430246767, -0.10729265904688048, -0.07508892026241029, 0.03778359493453141, 0.0706781752695844, -0.09103136020334937, 0.09735519940993105, -0.09554838426126414, 0.009572109563560645, -0.021004169861546216, 0.0019380033696360128, -0.04572824711212193, -0.055532850024137395, 0.01080100664169491, 0.09607979932064074, -0.09246618086366622, -0.08353841181292557, 0.011166354741690481, -0.08545150405328815, -0.003935791081456386, -0.10320075914289414, -0.006373656531645495, -0.013776929395489364, 0.03470138956354027, -0.06169726076611966, 0.04551568108837129, -0.04524997355868298, -0.07269754854842911, -0.0681273750910038, 0.00734681013712218, -0.1490087214740124, 0.06047501007633988, -0.03940440987893347, -0.09746147847501994, -0.06424805897130705, 0.056011123577576344, -0.0507501164631411, -0.000555909743479477, -0.02642460346718766, 0.0393512683729958, -0.022053715097163328, -0.09671750133867911, 0.06573601719077513, 0.054470019905384165, 0.019303643644934275, 0.09193476580428961, 0.044479420735890285, 0.07593918238401966, -0.06079385713857264, 0.039856111692706975, -0.10798349467728365, 0.014932756656285193, 0.07918081029943057, -0.06153783624830668, -0.008542493626040914, -0.10771778714759533, 0.011219495260931535, -0.11669869967766687, -0.07455750520303368, -0.06733026236890498, -0.020021054961789308, -0.05813678184168957, -0.061750404245450544, 0.011923620313275207, -0.02469750551091028, 0.008250215738062422, 0.004394136520833884, -0.06169726076611966, -0.008363140599487834, 0.06456690011336015, -0.04450599444894894, -0.051068963525373844, -0.03650819681863432, 0.07827740469849032, 0.10394473825262818, 0.12626417074644591, 0.12498876671036917, 0.004012181922239529, 0.10288190813387495, 0.12466992556831606, -0.012315538574221645, -0.020300047374613724, 0.013225586616729942, 0.03209745774598809, 0.025348488465298327, -0.1411437726750589, 0.0045900956513071035, 0.07073131874891529, 0.022744554674352924, -0.029493523955042688, -0.07248498252467846, -0.06706455483921667, 0.1044230098326739, 0.057924217791332146, 0.11032172291193396, 0.027421005223473897, -0.03502023662577302, -0.0003043180138751861, -0.02750071649568378, 0.02380738479310615, -0.03478110083575015, 0.0826350042385921, -0.015623596825492752, 0.07657687848187837, 0.03199117078732633, 0.010947145684353817, -0.07657687848187837, 0.04113150586181763, 0.049049590246529155, -0.07365409960209345, 0.0649388946017102, -0.03581735921483794, 0.05893390443075449, -0.012607817251557426, -0.10771778714759533, -0.0187988003252231, -0.005998344966637161, -0.08135961401626789, -0.047003641281232585, -0.01971549080929945, 0.12753955504859046, -0.05207865608497585, 0.06206925130768329, -0.006234160325233286, 0.019861630443976323, -0.06796795451997725, 0.04227404922617395, 0.011046785465303797, -0.06233496278415803, -0.08082819895689126, 0.10522014228870492, 0.030104650286629182, 0.024883499794995486, 0.02138944725963917, 0.010302804579515861, -0.021256594481491628, -0.03478110083575015, 0.036109638484191686]}}, {'id': 'https://huggingface.co/papers/2410.16271', 'title': 'FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without Learned Priors', 'url': 'https://huggingface.co/papers/2410.16271', 'abstract': 'Neural Radiance Fields (NeRF) face significant challenges in few-shot scenarios, primarily due to overfitting and long training times for high-fidelity rendering. Existing methods, such as FreeNeRF and SparseNeRF, use frequency regularization or pre-trained priors but struggle with complex scheduling and bias. We introduce FrugalNeRF, a novel few-shot NeRF framework that leverages weight-sharing voxels across multiple scales to efficiently represent scene details. Our key contribution is a cross-scale geometric adaptation scheme that selects pseudo ground truth depth based on reprojection errors across scales. This guides training without relying on externally learned priors, enabling full utilization of the training data. It can also integrate pre-trained priors, enhancing quality without slowing convergence. Experiments on LLFF, DTU, and RealEstate-10K show that FrugalNeRF outperforms other few-shot NeRF methods while significantly reducing training time, making it a practical solution for efficient and accurate 3D scene reconstruction.', 'score': 4, 'issue_id': 208, 'pub_date': '2024-10-21', 'pub_date_ru': '21 –æ–∫—Ç—è–±—Ä—è', 'hash': 'b3e061a400165087', 'data': {'desc': 'FrugalNeRF - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π –∏–∑–ª—É—á–µ–Ω–∏—è (NeRF) –Ω–∞ –º–∞–ª–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –≤–æ–∫—Å–µ–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π —Å—Ü–µ–Ω—ã. –ö–ª—é—á–µ–≤–æ–π –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é —è–≤–ª—è–µ—Ç—Å—è —Å—Ö–µ–º–∞ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º–µ–∂–¥—É –º–∞—Å—à—Ç–∞–±–∞–º–∏, –≤—ã–±–∏—Ä–∞—é—â–∞—è –ø—Å–µ–≤–¥–æ-–∏—Å—Ç–∏–Ω–Ω—É—é –≥–ª—É–±–∏–Ω—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—à–∏–±–æ–∫ —Ä–µ–ø—Ä–æ–µ–∫—Ü–∏–∏. FrugalNeRF –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –¥—Ä—É–≥–∏–µ few-shot NeRF –º–µ—Ç–æ–¥—ã, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞—è –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è.', 'emoji': 'üîç', 'title': '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ 3D-–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–∏–Ω–∏–º—É–º–æ–º –¥–∞–Ω–Ω—ã—Ö', 'categories': ['#3d', '#training', '#cv'], 'embedding': [-0.03694071877600098, 0.02145113013507428, 0.08497146772037195, -0.04407374240249534, 0.01811891474829646, -0.023325501546829122, 0.01904308512689144, 0.07065335710471493, -0.1405777942754569, 0.07914008976674149, 0.027152340441110537, 0.03962211029957759, -0.055345999474050736, 0.01191006355393563, 0.04977495270853159, 0.012645493205088338, 0.07060129168850808, -0.1152737925379978, -0.028532086291823248, 0.03904938866776373, -0.0039472421714598265, -0.05925093649264242, 0.05414848463360054, -0.06102117707198357, 0.017064582882722907, -0.022141004087199906, 0.12027211356462598, 0.04232953658479616, 0.05638731395880331, -0.045635717209932015, -0.03902335390612176, -0.04654687020770601, -0.080754129990385, -0.009332803684188139, -0.01231357360984651, -0.0030849015794874833, -0.03889319036560464, 0.0502956130312157, -0.09590529342596721, 0.0547212062654144, 0.03420726594329462, -0.09944577047757241, -0.06435339040522285, 0.014383191359146301, 0.014370174389033027, 0.042980356340920296, 0.006361796075407013, 0.060656712997920005, 0.07122608079006734, 0.08866814512767479, -0.04766628692384594, 0.08049380290935076, -0.08674170829971309, -0.029599435538217783, -0.04269399860532117, -0.030666786838150866, 0.002111921053983245, -0.08861608176500649, -0.011493536733265329, 0.02250546405418638, 0.08674170829971309, -0.08054586627201907, 0.09522844096173964, 0.08939706300810918, -0.019368495004953506, 0.03628989696633831, -0.0362117967884895, 0.042980356340920296, 0.08684583913212678, 0.09252101262298253, -0.02348169984898821, -0.08101446117849634, 0.14276456639860702, -0.09653008663460354, -0.010126807647312042, -0.0018857600284808323, 0.0014212349273640564, -0.003908192903950837, -0.03204653063532503, -0.045115060994325, 0.08294090211353511, -0.02996389550520426, -0.039361785272081895, -0.04454233320189551, -0.0946557152228487, -0.1521364131896885, -0.031135377637551035, -0.05227411322184569, -0.0777863766241322, 0.02083935636079747, 0.0684665973027961, -0.01770238936510314, -0.02889654728557899, 0.03688865335979414, 0.035066351471323226, 0.0518836205467558, 0.07002857005669423, -0.0021932740368833976, 0.15484382920721437, 0.10527715048474143, -0.011434962421294137, 0.030588686660302056, -0.012717083665757389, -0.10381931061679552, 0.07336078544347205, 0.01450033875096556, -0.0026586124419399355, 0.038945255781811496, 0.10532921590094826, 0.04821297790109492, -0.04888983241886102, -0.05977159476178798, 0.008694996996454048, -0.004406072296813582, -0.01831416313937995, -0.10168460596339081, -0.14213977729704777, 0.06601949809861175, 0.022921991490918243, 0.0023250656227570194, -0.045245224534842116, 0.06909138229727826, 0.05425261546601423, 0.07039302591660361, 0.09850859298584916, -0.058678214860828554, 0.10423582983937321, -0.0648219853117001, 0.01412286160851196, -0.033348178361727474, 0.05151915852623078, 0.07127815031335127, -0.03722708267221573, 0.019850105238713202, -0.1143366027250433, -0.012241983149177458, -0.058209619954351303, -0.09882098548309025, -0.06044845338663116, -0.013016462067839159, -0.008942310187682823, 0.011766881605828255, 0.05300303315581864, 0.04027293416277881, 0.03017216127710873, 0.11995971696030781, 0.023065172412256345, 0.038112202961886305, 0.054356748351966466, 0.13058114811512345, -0.09892511836904248, -0.03571717533452445, -0.11985558407435558, -2.364318395935572e-06, -0.06273935018157932, -0.10007056368620876, -0.022791825896862582, 0.07221533191215161, 0.002464992506920656, -0.07461036364659054, 0.005785817326110872, 0.11392008144892705, -0.06643602553534361, 0.02670978029627525, 0.05997985848015391, 0.034467590970790316, -0.12610348946471792, -0.07320458303423588, -0.09809206144204022, -0.028636217124236942, -0.04740595778927316, -0.003885414233021878, 0.007425891900688652, -0.02098253728213557, 0.03009406109925992, 0.052117914919686606, 0.01081668036731454, -0.006807610052062911, 0.06268728271183394, -0.026553583020885438, -0.08679377166238139, 0.08064999505089422, -0.06732114171793711, 0.14849180325213107, 0.009866478512739262, -0.03886715765750122, -0.06024018966826523, 0.01689536719974284, 0.02663168217196498, 0.018548459565849308, -0.0947598460552624, 0.06747734002009619, -0.029495302652265548, 0.06747734002009619, 0.03740931368247824, -0.045843980928297945, 0.12391672350218344, 0.020006303540872288, -0.008688488716751265, -0.03678452458091899, -0.03222876164558754, 0.04011673791415827, -0.001757222479781675, -0.026996142138951452, 0.10215320086986807, -0.09252101262298253, 0.058730280277035404, -0.04862950533782679, -0.058678214860828554, 0.024171571747575293, 0.05248237694021162, 0.1382868954269702, 0.08278469970429894, -0.042980356340920296, -0.10538128131715511, 0.004314957202390036, 0.024171571747575293, 0.04308449128041107, 0.04040309770329592, 0.07768224784525705, 0.07330871797372665, -0.015372441865169008, 0.07986901380779152, 0.06430132293547745, -0.017337927344578122, -0.09970610166568374, -0.004331227798970066, -0.05248237694021162, 0.12381259266976974, -0.13016462889254574, 0.047431988443838044, 0.019017052418788014, -0.04930635985559288, 0.02730853668973108, -0.04126218528486308, -0.04204317268858141, -0.009846953468277058, -0.06378066877340897, 0.004383294036592331, -0.020084401665182557, 0.0017002754944284955, 0.041288217992966496, 0.012691050957653965, -0.030120093807363343, -0.04967081982257936, 0.03316594735146496, -0.09460364569956477, -0.008428159582178485, 0.07820290816794115, -0.05675177597932832, 0.05982366017799483, 0.05982366017799483, 0.029703568424170025, -0.09731107814539897, 0.012437229486722408, 0.06586329979645267]}}, {'id': 'https://huggingface.co/papers/2410.16153', 'title': 'Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages', 'url': 'https://huggingface.co/papers/2410.16153', 'abstract': "Despite recent advances in multimodal large language models (MLLMs), their development has predominantly focused on English- and western-centric datasets and tasks, leaving most of the world's languages and diverse cultural contexts underrepresented. This paper introduces Pangea, a multilingual multimodal LLM trained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages. PangeaIns features: 1) high-quality English instructions, 2) carefully machine-translated instructions, and 3) culturally relevant multimodal tasks to ensure cross-cultural coverage. To rigorously assess models' capabilities, we introduce PangeaBench, a holistic evaluation suite encompassing 14 datasets covering 47 languages. Results show that Pangea significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions, language popularity, and the number of multimodal training samples on overall performance. We fully open-source our data, code, and trained checkpoints, to facilitate the development of inclusive and robust multilingual MLLMs, promoting equity and accessibility across a broader linguistic and cultural spectrum.", 'score': 3, 'issue_id': 208, 'pub_date': '2024-10-21', 'pub_date_ru': '21 –æ–∫—Ç—è–±—Ä—è', 'hash': '023f2f5e4c6c7a7c', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Pangea - –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—É—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö PangeaIns, –æ—Ö–≤–∞—Ç—ã–≤–∞—é—â–µ–º 39 —è–∑—ã–∫–æ–≤. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –≤–≤–æ–¥—è—Ç PangeaBench - –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–µ–π –Ω–∞ 47 —è–∑—ã–∫–∞—Ö. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ Pangea –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∫—É–ª—å—Ç—É—Ä–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏–Ω–∫–ª—é–∑–∏–≤–Ω—ã—Ö –∏ –Ω–∞–¥–µ–∂–Ω—ã—Ö –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å–ø–æ—Å–æ–±—Å—Ç–≤—É—è —Ä–∞–≤–µ–Ω—Å—Ç–≤—É –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤ —à–∏—Ä–æ–∫–æ–º –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–º –∏ –∫—É–ª—å—Ç—É—Ä–Ω–æ–º —Å–ø–µ–∫—Ç—Ä–µ.', 'emoji': 'üåç', 'title': 'Pangea: –ü—Ä–æ—Ä—ã–≤ –≤ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã—Ö –∏ –º—É–ª—å—Ç–∏–∫—É–ª—å—Ç—É—Ä–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª—è—Ö', 'categories': ['#dataset', '#data', '#benchmark', '#multilingual', '#multimodal'], 'embedding': [0.030188200774017154, 0.045429084658479175, 0.17936781913078717, -0.002360746610121973, -0.037625162058796555, -0.010806837214626164, 0.024671636429805677, 0.07417392894473197, -0.005739794772952588, 0.06551377973306738, 0.04430375308223484, -0.02316711869438294, -0.038138899671598295, 0.000728177179268848, 0.04175952704887067, -0.011926051843298384, -0.027130239184866945, -0.0836169125053979, -0.06634554431440483, 0.09697409249525878, 0.03799211925966839, 0.008849741674149087, -0.0550433168327666, 0.05054199258480495, 0.0541136938437726, -0.021589212810010944, -0.019558725417956363, 0.14012805197060474, -0.0035869892053141924, -0.004758188940331129, 0.09731658149443902, -0.00394477088197707, -0.14345510206789178, 0.030432837536587917, -0.02840235117304118, 0.04227326466167241, -0.007583745399337549, 0.08899892333897035, -0.028549133641986777, 0.05587507935708836, -0.0702108002261852, -0.0821001658116686, -0.02847574137900613, 0.03977796886064436, 0.021136632330836205, 0.04882953524680962, 0.07045544110278734, 0.12818976232383233, -0.01294129523077332, 0.08146410570355007, -0.06340990110654, 0.0611103118357466, -0.05152054374911939, -0.07304859736848764, 0.03623073168933694, 0.012201267789787352, 0.01986452034266197, 0.06389917463168152, -0.09296203971542295, -0.04503766336994712, -0.04425482490691441, -0.04535569239549853, 0.014629289921019422, -0.04449946166948517, -0.063997026868291, -0.03478737725858828, -0.0425668295995636, -0.020133621192892942, 0.031656021349441725, -0.004492145843930717, 0.03517879443308894, -0.04792438045950722, -0.09017318103351941, 0.034029000826200084, -0.03168048543710194, -0.03901959448527187, -0.06663910102423325, 0.017063426531404777, -0.10362821325998978, -0.04207755607442208, 0.014213407630350698, 0.03133799438090601, -0.041074544936478816, -0.030334981185947053, 0.06742194565831304, 0.08562293478128442, 0.05103127022397787, 0.02911179737309325, -0.07534818046823397, -0.021662603015975897, -0.012195151870723082, -0.11732788019201519, -0.06409488116191617, 0.03444488414537666, 0.04838918989698853, -0.008170874246612085, 0.024072276567208884, -0.06008283661014312, 0.08572079113192528, 0.12280775560429126, -0.03481184134624849, -0.032610104312064556, 0.02211517938111925, -0.0784306061450444, 0.09418522764230816, -0.05186303274829962, 0.04224880057401219, -0.026689891778030155, 0.03950886801041339, 0.04900078386043113, -0.15715478545604275, 0.051667324161049286, 0.03375989997596911, -0.025442243877516132, 0.04701922155817343, -0.0799473548957894, -0.043031639037044905, -0.06252920423585073, 0.09814834401876076, -0.04775313184588571, -0.05063984893544581, 0.03960672436105425, 0.0038499741364809, -0.06340990110654, 0.03319723418784693, -0.05372227666927193, -0.053771204844592364, -0.011620254450173947, 0.05015057746731998, 0.00253505050915521, -0.0776966999713635, 0.0734400145429883, 0.05254801897472286, -0.09589768909433488, -0.13513745625451729, 0.043398596237916746, -0.05548366218258769, 0.012647730292882131, -0.10666170870446406, -0.01157744383953034, -0.013503960401790782, 0.027619512710008468, 0.018213220138293632, 0.0369401799464047, -0.06888976417672192, -0.07764777179604307, -0.012201267789787352, 0.04613853085853124, 0.014176711498860375, 0.0892435642155725, -0.11732788019201519, -0.036817863622135016, -0.034591664557306556, 0.07118935139049963, -0.13572458201626827, 0.001984617279117073, -0.11996996257602022, 0.04300717700640039, 0.08043662842093091, -0.14785857613625963, 0.07965379818596098, 0.040658659560286546, 0.023607466101219728, -0.021051011109548993, 0.10871665915567101, 0.06071889054721454, -0.14159586843199792, -0.009864985061624025, -0.16057969601800204, -0.060963527309785305, -0.04533122830783832, -0.05636435288222988, -0.05249909285641813, -0.04917202836002125, -0.014506971539734041, -0.10675956711212062, -0.07916452054678806, -0.07975165042257046, -0.047728671872256885, -0.13621386376947256, -0.1010839872266256, 0.13689883765380165, -0.08904784945727508, 0.004736782812203049, -0.06365453581209507, 0.032610104312064556, -0.013858683296115245, 0.10127969787089162, -0.025809199021372273, 0.056168644294979544, -0.059789271672251926, 0.07334215407831605, 0.1746707883525909, 0.01752823802590178, 0.0345182764083573, -0.05391798525652227, 0.09535948327984152, 0.027668440885328896, -0.04961237370984233, 0.007351340680596895, 0.0471415419964745, 0.014996245064875565, -0.02759504862234825, -0.15255559868639318, -0.01743038167526092, -0.05998498025950226, -0.06952582428484043, 0.029503216604609608, -0.02086753148060523, 0.04190631157483196, 0.05734290404654432, 0.03706250038470578, 0.05318407496880998, 0.0136385106212047, -0.01959541949243099, -0.019277392523895282, -0.05988712802289279, 0.015485518590017087, -0.009033219246077159, 0.04139257396203022, 0.020060230986927993, -0.06292062552438278, 0.06203993071070921, 0.08459545955568094, -0.043325203974936104, -0.06076781872253498, -0.007302412916679604, -0.018421163854897612, 0.04425482490691441, -0.10010544017634254, 0.10069257005212494, -0.02742380206574244, 0.0020656533095694224, 0.04139257396203022, -0.002892831980116518, -0.06830263635795522, 0.031827267906047535, -0.034126855119825245, -0.03488522949519775, 0.0058559970294721295, 0.060865675073175834, 0.09173886001660055, 0.012286891068090257, -0.01139396626760227, 0.01357735143056201, 0.03439595597005622, 0.016219430934745066, -0.06135494859831735, 0.004626696474747776, -0.04481749069503658, 0.02815771441047042, -0.02144243034106535, -0.050199503585624715, -0.10587887641247845, -0.029331970048003798, 0.018947131454513766]}}, {'id': 'https://huggingface.co/papers/2410.14745', 'title': 'SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation', 'url': 'https://huggingface.co/papers/2410.14745', 'abstract': 'Supervised fine-tuning (SFT) is crucial in adapting large language models (LLMs) to a specific domain or task. However, only a limited amount of labeled data is available in practical applications, which poses a severe challenge for SFT in yielding satisfactory results. Therefore, a data-efficient framework that can fully exploit labeled and unlabeled data for LLM fine-tuning is highly anticipated. Towards this end, we introduce a semi-supervised fine-tuning framework named SemiEvol for LLM adaptation from a propagate-and-select manner. For knowledge propagation, SemiEvol adopts a bi-level approach, propagating knowledge from labeled data to unlabeled data through both in-weight and in-context methods. For knowledge selection, SemiEvol incorporates a collaborative learning mechanism, selecting higher-quality pseudo-response samples. We conducted experiments using GPT-4o-mini and Llama-3.1 on seven general or domain-specific datasets, demonstrating significant improvements in model performance on target data. Furthermore, we compared SemiEvol with SFT and self-evolution methods, highlighting its practicality in hybrid data scenarios.', 'score': 3, 'issue_id': 207, 'pub_date': '2024-10-17', 'pub_date_ru': '17 –æ–∫—Ç—è–±—Ä—è', 'hash': '863b95d8e45c3aa2', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–ª—É-–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–π –º–µ—Ç–æ–¥ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º SemiEvol. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–∞–∫ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ, —Ç–∞–∫ –∏ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–µ –∏–ª–∏ –¥–æ–º–µ–Ω—É. SemiEvol –ø—Ä–∏–º–µ–Ω—è–µ—Ç –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π –º–µ—Ç–æ–¥ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏ –º–µ—Ö–∞–Ω–∏–∑–º —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ—Ç–±–æ—Ä–∞ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Å–µ–≤–¥–æ-–æ—Ç–≤–µ—Ç–æ–≤. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ —Å–µ–º–∏ –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–∫–∞–∑–∞–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.', 'emoji': 'üß†', 'title': 'SemiEvol: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–æ–ª—É-–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π', 'categories': ['#nlp', '#dataset'], 'embedding': [0.02396001414792346, -0.06013493568530362, 0.13936677064213313, -0.04065710826490381, -0.003498136610833921, 0.04657409995300698, -0.008526311046590546, 0.037889071325759756, -0.07201971278985864, 0.08999924929267838, 0.020849147457884663, -0.0514499070580564, -0.10472824358984163, 0.012989451159889321, 0.007739071532226059, -0.01890644553614779, 0.03735578266995749, -0.0992937509648156, -0.04350132959313559, 0.049012004539437576, 0.015249590103970135, -0.0343337977671877, 0.07725104911179587, 0.07653999067802027, 0.050738848624280804, -0.08217764374175866, 0.00015603926813809462, 0.12209829464090076, 0.03517182397934085, -0.03555274799259123, 0.11559722677208194, -0.05729071435707185, -0.11102615515557164, -0.03687328153906859, -0.03367353306176079, 0.11661301655877312, 0.08248237509467424, 0.07780973049614893, -0.015109918310413625, 0.05327833239616169, -0.09172608924189808, -0.13875729552943136, -0.005688439968308244, 0.06653443263991923, -0.0481231866667475, -0.03288629230670924, 0.005015476830794161, 0.11905091287395664, -0.004542498593455347, 0.03529880002896549, -0.008215225101320786, -0.031438786846230776, 0.016024132220153333, -0.02573765196111537, 0.00080747594748253, -0.021826849185655514, -0.006602653257704421, 0.010888028969340475, -0.027756539305845852, -0.038981049637162195, -0.029077068716699676, -0.03476550930535145, -0.02030315830218345, -0.02717245898950666, -0.06506152617964288, -0.05657966212673156, -0.18284269923547086, 0.025382124812039344, -0.016659001922436495, 0.05000240159757794, -0.01155464371793568, -0.07323866715088571, -0.003596541498434187, -0.02628363904900482, -0.020734870874253082, 0.02788351328765872, 0.04672646873118242, 0.09086266823338235, -0.03598446159856675, -0.05045950793210426, 0.028696148839072844, 0.006072536418378051, -0.05155148831131847, -0.025382124812039344, -0.005075789523850567, -0.06404573846076349, -0.0941132063034153, -0.029000884327611956, -0.05845887912537377, -0.10858825470476458, -0.024506003303624672, 0.005177369329644394, -0.04512659656034029, 0.013370373725671457, 0.05637650168801921, 0.003723515687028232, -0.01883026114706007, -0.09787164030069971, 0.04951990046668905, 0.11468301203521752, -0.06389336761477626, 0.032276817194007476, 0.031362602457143056, -0.10980720906579165, 0.10168086595852105, -0.08888187618491337, 0.012424416010306765, -0.011440367134304099, 0.04682804791663271, -0.05642729334855612, -0.08832318859712499, -0.03773670461539609, -0.024201263679462022, 0.05183082900349501, 0.041749086576306244, -0.16303473739454583, -0.045278965338515734, 0.06765180574768424, -0.016341566967904328, 0.006513771677216591, 0.00810729649304573, 0.010557896823408196, 0.02526784719450188, 0.023083892639508788, 0.07262918997037218, 0.013903664035723146, -0.012792641591469965, -0.0665852201648326, 0.010316645844401394, -0.03166734208130571, 0.08578370275743233, -0.01681137173451782, 0.08994845349651794, -0.01870328509743543, -0.13784309526724936, 0.04131737090251895, -0.18284269923547086, 0.02349020938130996, -0.0649091594692792, -0.04014921233765235, -0.009580196336324408, -0.04063171553635301, -0.049088188928525296, 0.0539385971015886, 0.004459965401886395, -0.04672646873118242, 0.019503222216762383, 0.012284744216750257, -0.03501945933678896, 0.12148882159601077, -0.02564876913994048, -0.10041111993695706, -0.056935189275807596, 0.10838509840167576, -0.021623690814754924, 0.006843904443492401, -0.13885888505394053, 0.031845105655843725, 0.0941132063034153, -0.018462033498085097, -0.034409982156275415, 0.07247682326000851, 0.06521389702563009, -0.02319816818923448, 0.034663930119901154, 0.05101819551989265, -0.007008970413067951, 0.05099280279134185, -0.1570415778598491, 0.0014490919890599425, 0.020709476077890508, -0.014157612412911233, 0.003894930459085015, -0.041901455354481684, -0.09304662899181074, 0.010532502647389154, -0.0009158007484929565, -0.0680073308289485, -0.1215903987136493, -0.015884460633378002, -0.10411876847713987, 0.05414175754030096, -0.12118408817528344, 0.04286645761625948, -0.06399494680022656, -0.018855653875610872, 0.004380606714948648, 0.07552419882351732, 0.08669791956210852, -0.031718129606219087, -0.05820493116174803, 0.032175238008557185, 0.14698521988996402, 0.0818221124570591, -0.0011816528149920602, 0.03981907998493889, 0.09990322814532913, 0.0680073308289485, 0.04695502189844558, 0.04284106075208513, -0.04355211711804896, 0.002936276172663745, -0.04555831016631581, -0.08756134057062424, 0.024493303837631614, -0.01716689888359385, -0.049494505670326476, -0.01288787197443903, -0.014284587221848812, -0.08938977211216485, 0.11072141553140899, 0.09045634942376939, 0.10325534540081237, 0.03969210393531425, -0.056020976606754945, -0.009250063156486245, -0.061557046349419504, -0.109502469441629, 0.09446872931686778, 0.0604396732416545, 0.02115388604814143, -0.026461404691354603, 0.04243474401028396, 0.03966671120676345, -0.0680581162860501, -0.020912634448791097, -0.0220300075565561, -0.09924295723646691, -0.02406159333337375, -0.12219988002978636, 0.055411499426241406, -0.07831762642340041, -0.020658686485165362, -0.025712256130846916, -0.04360290671077411, -0.1122451095165987, 0.014195704814236272, -0.03697485865670711, 0.0440600151131122, -0.04131737090251895, 0.01314181952450241, 0.021788755957205766, -0.04682804791663271, -0.014056033227460941, -0.018423942337447125, 0.04352672232168639, -0.006666140455392032, -0.08705344877899632, 0.07948579119170233, 0.1021379702252356, 0.06424889683166407, -0.09863348419157691, -0.030676942955353576, -0.05363386368086127, -0.008729469417491136, 0.02686772143315578]}}, {'id': 'https://huggingface.co/papers/2410.13218', 'title': 'CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy', 'url': 'https://huggingface.co/papers/2410.13218', 'abstract': "There is a significant gap between patient needs and available mental health support today. In this paper, we aim to thoroughly examine the potential of using Large Language Models (LLMs) to assist professional psychotherapy. To this end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation of cognitive behavioral therapy (CBT) assistance. We include three levels of tasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of multiple-choice questions; II: Cognitive model understanding, with the tasks of cognitive distortion classification, primary core belief classification, and fine-grained core belief classification; III: Therapeutic response generation, with the task of generating responses to patient speech in CBT therapy sessions. These tasks encompass key aspects of CBT that could potentially be enhanced through AI assistance, while also outlining a hierarchy of capability requirements, ranging from basic knowledge recitation to engaging in real therapeutic conversations. We evaluated representative LLMs on our benchmark. Experimental results indicate that while LLMs perform well in reciting CBT knowledge, they fall short in complex real-world scenarios requiring deep analysis of patients' cognitive structures and generating effective responses, suggesting potential future work.", 'score': 3, 'issue_id': 207, 'pub_date': '2024-10-17', 'pub_date_ru': '17 –æ–∫—Ç—è–±—Ä—è', 'hash': 'f4f24ef7771a745c', 'data': {'desc': '–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ CBT-BENCH –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–π —Ç–µ—Ä–∞–ø–∏–∏ (–ö–ü–¢). –ë–µ–Ω—á–º–∞—Ä–∫ –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ —É—Ä–æ–≤–Ω—è –∑–∞–¥–∞—á: –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –ö–ü–¢, –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ—Ä–∞–ø–µ–≤—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏, —á—Ç–æ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º –∑–Ω–∞–Ω–∏–π –ö–ü–¢, –Ω–æ –∏—Å–ø—ã—Ç—ã–≤–∞—é—Ç —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –≤ —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö, —Ç—Ä–µ–±—É—é—â–∏—Ö –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –±—É–¥—É—â–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ò–ò –≤ –ø—Å–∏—Ö–æ—Ç–µ—Ä–∞–ø–∏–∏.', 'emoji': 'üß†', 'title': '–û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –ò–ò –≤ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–π —Ç–µ—Ä–∞–ø–∏–∏', 'categories': ['#benchmark', '#nlp', '#medicine'], 'embedding': [-0.025578980649462672, -0.028054364371478905, 0.1278294073180521, 0.04539515770985954, -0.023575096756998575, 0.0014660762675723612, 0.064229033504388, 0.054903777760467426, -0.044399765356553614, 0.12080927624912374, 0.017340793338380633, -0.1329635491917903, 0.013228248263463896, -0.019252995077501067, -0.030700013214330208, -0.029390286966454966, 0.08733263650564549, -0.003683608691128205, -0.05715651176586169, 0.054589443865898105, 0.05621350603294635, 0.07077767486678263, -0.0025867120221534858, -0.0479360292627223, 0.038741743106683726, -0.04646913303065686, 0.014184349133024113, -0.043640123930325604, -0.012946657069555627, 0.03206213013180341, 0.09623877904040451, -0.026548178680271456, -0.1449082655298761, 0.004937673117229059, -0.021400949768303094, 0.11127445377760396, 0.03580795064255287, 0.09398605110882129, 0.09367171923885566, 0.01635849814632328, -0.049376729147686906, -0.049193366865603265, 0.007308280156637854, 0.010209327288122872, -0.08759457973061685, 0.004662630301484706, 0.07193024125348611, -0.01044507740535931, -0.07800737266331018, 0.026115968309861334, -0.07135395806013436, 0.091523768597261, 0.008873404693146807, -0.03515309055552077, 0.0010281360662688151, 0.03350283001676802, 0.003552636066340681, 0.04628577277317691, 0.05346307990010651, 0.05157707045887952, 0.009809859820834172, -0.032978941542221606, -0.028918785112299145, 0.02839489258854536, -0.17864684647372203, -0.05930446645666372, -0.030071345425191565, -0.03599131494924019, 0.03929182792833096, 0.0009184464803554908, 0.026928000405687304, 0.02235705063786331, 0.00017752947984671366, 0.0352316714984085, 0.017733712225045047, -0.002431181764489067, 0.09786284323205642, 0.08073160852286027, -0.02944267561144924, -0.043273401390762016, 0.0021184843570796193, -0.07633092590047504, -0.014799921785517872, -0.04222561836785813, 0.03701289960043956, 0.020890154405797882, -0.0069153616748941745, 0.06176675301743138, -0.11399868761255036, -0.09791522985244702, 0.025565881463610416, -0.07465447508843251, -0.09388127179422907, 0.06779149983146855, 0.13034408657302138, -0.0012573384127224432, 0.03030709432766579, 0.006011649450328231, 0.04123022398994852, 0.09210004369219799, -0.015428590384497986, 0.05521811570424412, 0.0059461630367042845, -0.05804712682917906, 0.09534817005089818, -0.008938890499389647, 0.05731367567624082, -0.07821692926789095, -0.06380993041824487, 0.05270343644927481, -0.16387311293689025, 0.05220574027262185, -0.028971173757293415, -0.03510069583671544, 0.032376464026372724, -0.10991234090933814, -0.05694695516128091, -0.024950310835720343, -0.05453705522090383, 0.016712123524638304, 0.038008293978349164, 0.09812479050623517, 0.047595496996448466, -0.05878057393290993, 0.0059134199311224964, -0.014642754230852106, 0.08879953273771092, -0.05809951344956965, 0.030228513384778073, -0.026797026768597933, -0.04707161054650574, 0.06328603789449108, 0.08879953273771092, -0.010870738992684776, -0.12510518158152042, 0.020261484592055554, -0.13243965261882915, 0.04123022398994852, -0.05631828737214227, -0.10153008077531449, 0.051839017733058254, -0.0008586901608234496, 0.003366000000095821, 0.007884560110623696, -0.09843912035159712, -0.018755298900848105, 0.007799427752666529, 0.016620443395898327, -0.07748348621336745, 0.05841384936874266, -0.022854744789912586, -0.06270975470113935, -0.032586020630953505, 0.03819165828503649, -0.0626049774111508, -0.08046965922407785, 0.0212044883003672, 0.061400026428660416, 0.06202869826700643, -0.10959800296556145, 0.09854390574000041, 0.010451625783523223, 0.05134131953180161, 0.01363426431137688, 0.10042990910741634, 0.1069785464206036, -0.032009741486809136, 0.10310175429736845, -0.055270504349238386, -0.07124917672093846, -0.010248618164487468, -0.030411873642258024, -0.06370514705444526, -0.07931710093578911, -0.0050359028388951635, -0.03287416222762938, 0.05464183251089238, -0.042880480479493915, -0.013241345424712463, -0.043587733260727644, -0.0801553293787159, 0.128458067008776, -0.055427670284221214, 0.029495064256443514, -0.04474029357362007, 0.01487850475300928, -0.0718254578896865, 0.028159143686071135, -0.04088969577288207, -0.00489838082364188, -0.00672545101464662, 0.014236738790320228, 0.16303488449396344, 0.14480347406766175, 0.10042990910741634, -0.029626036881231037, 0.11536080453002356, 0.06124286251828128, -0.0199602478587348, -0.015232132155927992, -0.007301731171092832, 0.02218678551702824, 0.0005337139977136653, -0.15863419782237084, 0.08565618366899927, -0.0103337501175239, 0.017314599015883496, 0.029049756724784825, -0.061923918952414204, -0.018113533950460895, 0.07575464473172698, -0.0564754512825214, 0.11850414752492415, 0.060037911535790904, -0.08780413835980132, 0.02658747016401716, -0.0834034537128124, -0.0067647427008526925, -0.007249342121177823, 0.060561802034941, 0.0007547305070337354, 0.06711044339733563, 0.04437357103405648, 0.015821510485924617, -0.042278007012852406, 0.040680139168301294, 0.049193366865603265, -0.08796130227018044, 0.06506726599652216, -0.12416217382400141, 0.04845992178647608, -0.032795579260137965, -0.051943792998443115, -0.060561802034941, -0.0026505611387760844, -0.007380314948425715, 0.009790213269119845, -0.009285968309382232, 0.04660010869234992, -0.10682138048562077, 0.1263625171597977, 0.005618731373505291, 0.037929711010857764, -0.07748348621336745, 0.0025130397309039076, 0.04398065214739206, -0.05050309513808219, -0.12468606837235888, 0.09115703795928266, -0.05469422318049033, -0.03381716796054471, -0.07999815736992202, -0.05532289299423266, -0.05961880035123304, -0.05689456651628664, 0.04476648789611721]}}, {'id': 'https://huggingface.co/papers/2410.12788', 'title': 'Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception', 'url': 'https://huggingface.co/papers/2410.12788', 'abstract': 'Retrieval-Augmented Generation (RAG), while serving as a viable complement to large language models (LLMs), often overlooks the crucial aspect of text chunking within its pipeline, which impacts the quality of knowledge-intensive tasks. This paper introduces the concept of Meta-Chunking, which refers to a granularity between sentences and paragraphs, consisting of a collection of sentences within a paragraph that have deep linguistic logical connections. To implement Meta-Chunking, we designed two strategies based on LLMs: Margin Sampling Chunking and Perplexity Chunking. The former employs LLMs to perform binary classification on whether consecutive sentences need to be segmented, making decisions based on the probability difference obtained from margin sampling. The latter precisely identifies text chunk boundaries by analyzing the characteristics of perplexity distribution. Additionally, considering the inherent complexity of different texts, we propose a strategy that combines Meta-Chunking with dynamic merging to achieve a balance between fine-grained and coarse-grained text chunking. Experiments conducted on eleven datasets demonstrate that Meta-Chunking can more efficiently improve the performance of single-hop and multi-hop question answering based on RAG. For instance, on the 2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while only consuming 45.8% of the time. Our code is available at https://github.com/IAAR-Shanghai/Meta-Chunking.', 'score': 2, 'issue_id': 208, 'pub_date': '2024-10-16', 'pub_date_ru': '16 –æ–∫—Ç—è–±—Ä—è', 'hash': '0fbcf072cc98c553', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –ú–µ—Ç–∞-–ß–∞–Ω–∫–∏–Ω–≥–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è Retrieval-Augmented Generation (RAG). –ú–µ—Ç–∞-–ß–∞–Ω–∫–∏–Ω–≥ - —ç—Ç–æ –º–µ—Ç–æ–¥ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, —É—á–∏—Ç—ã–≤–∞—é—â–∏–π –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –¥–≤–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏: Margin Sampling Chunking –∏ Perplexity Chunking, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ –æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç–∏ –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ú–µ—Ç–∞-–ß–∞–Ω–∫–∏–Ω–≥ –ø–æ–≤—ã—à–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å RAG –≤ –∑–∞–¥–∞—á–∞—Ö –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º.', 'emoji': 'üß©', 'title': '–ú–µ—Ç–∞-–ß–∞–Ω–∫–∏–Ω–≥: –ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑–±–∏–µ–Ω–∏—é —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ RAG', 'categories': ['#rag', '#nlp', '#dataset', '#code'], 'embedding': [0.011314953977182435, 0.034142111247153425, 0.08105165101046777, 0.038828280471551915, -0.03868482961659378, 0.017094964749779167, 0.04026282609257101, 0.024076405211792745, -0.033616112421827674, 0.09157162751698267, 0.04243854682135306, -0.014106334315452083, -0.07823038387421939, 0.048846173132328426, 0.013293426756148178, -0.037561102636206614, -0.007250416570888573, -0.054416976123961215, -0.024435039178137143, 0.06723222679478365, -0.019019641604563722, 0.0012626962887503565, 0.0012440173570719987, -0.004856523797275711, -0.04490117901569289, -0.03222938895547009, 0.05752515082351077, 0.08650291032221658, -0.0024192960738683494, -0.011476339603484868, -0.025487036828788633, -0.04107573248119794, -0.006993394439776314, 0.0369633783834018, 0.02641949079955614, 0.06135059540687742, -0.05403443400697851, 0.004055571191298696, 0.023657996478813906, 0.019210914614183377, 0.0007019545022171149, -0.040382369772455, 0.0250088562558678, 0.08521182140954052, 0.03301838621789456, 0.07937801607855241, 0.01808718958492452, 0.0029811583933849494, 0.03725028594670298, 0.0836816412348399, -0.038254465344949556, 0.02957548375151061, -0.016114694477735045, -0.033185746199055156, 0.006180486880472411, 0.02689767137247697, -0.011153567375315853, -0.009862479438203947, 0.11763248142350197, -0.027112853508299083, -0.044446907568974514, -0.09812270663404449, -0.03294665688815889, 0.056807882890821976, -0.10988595575195882, -0.06407622798944429, -0.13647280067929066, -0.06909712498067717, -0.06383713672741971, -0.007704688602945439, 0.042749363510856696, -0.020430276148252064, -0.0035654356650509753, -0.024136177051734736, -0.051356621627944875, -0.004736978556489088, 0.01011352409265276, 0.1192582961518841, -0.019055507244995707, 0.011045977282968949, 0.013257563066844493, -0.032325025460279926, 0.060537690969378805, -0.07086639836853065, 0.06115932629951437, -0.015863648652609252, -0.006455440856236511, 0.02014336760938673, -0.11112922055884505, -0.04478163338468061, -0.09692725422617825, -0.02284508813905868, -0.10194815121741113, 0.03763283196594229, 0.05250425383227789, 0.054990795152820175, -0.050208987472483556, -0.044088272627065966, 0.08435109481738037, -0.040741006665491845, -0.06833204074671176, -0.10223506073184062, 0.03127302585850013, -0.08057347043754692, 0.07846947318511564, -0.1018525108103447, -0.04164954955892859, 0.05303025265760363, -0.05106971016238709, -0.046550900919149193, -0.08812872505059871, -0.006694531532922587, -0.15875603215710482, 0.021482273798903554, 0.06068114572659354, -0.13245609089081756, -0.09888779086800989, 0.08047783198160881, -0.0004651055743926604, 0.09434507249856953, -0.0525520701335545, 0.005134466706484364, 0.019569551507220225, -0.105104140267109, 0.006867872112551908, -0.06618022329074727, 0.09601871133274151, -0.006503259108641425, 0.014106334315452083, 0.04707690169560324, 0.04243854682135306, -0.003161970623730745, 0.061398417561538944, -0.036246106548456405, -0.17252764202264062, -0.02213977184277866, -0.10051360364526374, -0.018684915788857632, -0.07191839406805385, 0.0102689332178559, -0.05250425383227789, -0.038900009801287584, -0.05522988446371645, 0.00999995593830392, -0.16860655703220753, -0.009228889544967147, -0.0385652839855815, 0.06077678223140338, -0.04698126714192172, 0.018398006274428152, -0.07956928713704375, -0.09286271252740212, -0.11151177048034097, 0.04872662750131615, -0.033066202519171174, -0.034142111247153425, -0.0550864297065017, 0.00803941480887719, 0.057286061512614506, -0.10127869958599894, 0.032014204868519684, 0.056329702317901145, 0.031057845673806324, -0.022115863692140355, 0.07952146888463885, 0.0641718683965107, -0.10127869958599894, 0.08095601255452964, -0.08095601255452964, -0.08846345476856142, -0.10969468469346748, -0.1452713357082551, -0.027591034081219917, -0.06364586371780007, -0.014369334118340614, -0.04889398748247674, -0.1420197023492342, -0.07005348612651884, 0.0680929533869438, 0.020753047400856928, -0.07913892676765613, 0.12059720136583678, -0.08105165101046777, 0.09353217391445581, -0.05413007051178834, -0.09573179791605542, 0.057859878590345165, 0.045714087355448116, 0.05427352136674648, 0.09539707014922102, -0.05446479632749443, 0.09238453975899451, 0.10778195849952754, 0.03648519781048097, 0.04298845477288126, 0.004557661085534814, 0.17109309445049323, 0.0031470275174106245, 0.049156989821832066, -0.08659854682702639, -0.038134919713937274, 0.09429725619729291, -0.019724958876407895, -0.14871423817463902, -0.0010878613399551752, 0.010519977872304713, -0.009826615748900262, 0.005585749805096678, -0.045785812782927184, -0.01371183509890136, 0.04920480417198038, -0.05599497650219505, 0.07292257541742872, 0.026873762246274514, 0.013245609089081754, -0.0837294614383731, -0.05781206228906855, 0.07631765768027945, 0.017836145710927023, -0.05876842538603852, 0.032564116722304484, -0.031536028197855455, 0.026013037605242678, 0.06928840384368172, -0.07273130435893738, 0.005549886115792993, 0.03952164513142316, -0.10854704273349296, 0.09769234431352855, -0.08071692129250507, 0.07727402077724943, 0.0036222197422253947, -0.08760272427414467, -0.05484734234673374, 0.04066927733575617, -0.021673544857394905, -0.0036311855669949006, -0.05479952214320052, -0.04236682139387399, 0.04671826480256639, -0.008314369369979781, 0.014668196244743022, 0.02924075793580452, -0.01958150411919315, -0.033544383092092005, 0.07335293773794464, -0.09214544849696993, -0.012020270273462455, 0.12222301609421891, -0.009515798278945305, 0.008015506268013225, -0.0862160008077871, -0.008625187035047568, -0.027734486887306353, -0.0811951038165542, 0.03717856051922391]}}, {'id': 'https://huggingface.co/papers/2410.13394', 'title': 'Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs', 'url': 'https://huggingface.co/papers/2410.13394', 'abstract': 'Evaluating machine-generated text remains a significant challenge in NLP, especially for non-English languages. Current methodologies, including automated metrics, human assessments, and LLM-based evaluations, predominantly focus on English, revealing a significant gap in multilingual evaluation frameworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an extensible framework that includes evaluator LLMs (Hercule) and a novel test set (Recon) specifically designed for multilingual evaluation. Our test set features 500 human-annotated instructions spanning various task capabilities along with human judgment scores across six languages. This would enable benchmarking of general-purpose multilingual LLMs and facilitate meta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a cross-lingual evaluation model that addresses the scarcity of reference answers in the target language by learning to assign scores to responses based on easily available reference answers in English. Our experiments demonstrate that Hercule aligns more closely with human judgments compared to proprietary models, demonstrating the effectiveness of such cross-lingual evaluation in low resource scenarios. Further, it is also effective in zero-shot evaluation on unseen languages. This study is the first comprehensive examination of cross-lingual evaluation using LLMs, presenting a scalable and effective approach for multilingual assessment. All code, datasets, and models will be publicly available to enable further research in this important area.', 'score': 1, 'issue_id': 208, 'pub_date': '2024-10-17', 'pub_date_ru': '17 –æ–∫—Ç—è–±—Ä—è', 'hash': 'd456f53989a80b51', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ CIA Suite –¥–ª—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –º–æ–¥–µ–ª—å-–æ—Ü–µ–Ω—â–∏–∫ Hercule –∏ —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä Recon —Å 500 –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –Ω–∞ —à–µ—Å—Ç–∏ —è–∑—ã–∫–∞—Ö. Hercule —Å–ø–æ—Å–æ–±–Ω–∞ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ü–µ–ª–µ–≤–æ–º —è–∑—ã–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, —á—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Ö–≤–∞—Ç–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ Hercule –ª—É—á—à–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Ü–µ–Ω–∫–∞–º –ª—é–¥–µ–π, —á–µ–º –ø—Ä–æ–ø—Ä–∏–µ—Ç–∞—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏, –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –¥–∞–∂–µ –¥–ª—è —Ä–∞–Ω–µ–µ –Ω–µ –≤–∏–¥–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤.', 'emoji': 'üåê', 'title': '–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –±–∞—Ä—å–µ—Ä–æ–≤ –≤ –æ—Ü–µ–Ω–∫–µ –ò–ò', 'categories': ['#nlp', '#multilingual', '#benchmark'], 'embedding': [-0.04935933007947497, -0.012026771143256279, 0.1637310674158379, 0.010389721932289172, -0.009039645162987418, -0.05509878934626928, 0.019096739382625846, 0.08066546356732636, 0.00902660100851848, 0.09553587478302344, -0.029793000301288397, -0.10419723424966804, -0.06162089788119983, -0.015170428229170866, 0.017074883963104536, -0.0074873826430637835, 0.06130783900862432, -0.0942314551627348, -0.013957316646816044, 0.01681400087372579, 0.07184756840430165, 0.03824565454844846, 0.04599392111556998, -0.001641126075255335, 0.045759125917789606, -0.041115383138496886, -0.0037860850843931208, 0.043854670183855936, 0.015679152966166118, -0.05173338246906174, 0.1177110458884848, 0.0032088782755987644, -0.07868273789850518, 0.03545419171989264, -0.042080655994611645, 0.11969376947060853, 0.051342053661598705, 0.04646351359782816, 0.0031648539673452, 0.08150029279205429, -0.04218500964770263, -0.03428021364429336, 0.021288168184234107, -0.03135830614100198, -0.07623043018091309, -0.014518217584347555, 0.07445641181827387, 0.049776746778536385, -0.03897613220678285, 0.052803006891570026, -0.1177110458884848, 0.07868273789850518, 0.05384654342247994, -0.045628686459797695, -0.007924364217475261, -0.08838764224284949, 0.0026544988936273582, 0.08134375709567417, -0.08431784142551103, -0.012065904441342073, -0.04252416058527145, -0.06595157552782467, 0.02924514414423506, -0.028488578594302285, -0.12887689720270806, -0.007409117507580413, -0.020714222048884928, 0.0030050621882542978, 0.04677657455710113, -0.016435718098759402, 0.05629885531346694, 0.05048113445857494, 0.010141881745360888, -0.009117910089801042, -0.035088954977422905, -0.037019498602954955, 0.02569711367904901, 0.1382687468478718, -0.027210244778914556, 0.05170729040406844, -0.050037631954612596, -0.06172525570768574, 0.019475022157592232, -0.08363954372376833, 0.10800614571753539, 0.014570394202223306, -0.02934949779732605, 0.022592589891220215, -0.07737832036491399, -0.09934478625089078, -0.06636899222688608, 0.019096739382625846, 0.013957316646816044, -0.004956804155905187, 0.0349063355628393, -0.03096698046358513, 0.0027311336923881383, -0.07216063353696954, 0.043202458287014155, 0.06188178305727604, -0.04375031444406749, 0.030497387981326948, 0.04437643844931089, -0.04077623428762553, 0.08066546356732636, -0.032871436197518804, 0.010787570625954345, 0.008576575488307809, 0.008309168756671498, 0.01472692572520852, -0.16675731292198934, 0.009137476217169574, -0.07690872788265579, -0.12157214148633873, 0.04390684805375016, -0.1260593548293437, -0.07294328489180324, -0.05890770290083408, -0.06156872209800307, 0.008857025957073564, 0.005478572838699631, 0.10023179125881548, 0.1003883227818007, -0.1119715907950854, 0.06626464274719002, -0.029192966274340836, 0.02835813600626418, 0.023010004503584182, -0.007369984835503856, -0.07116927070255895, -0.06986484273548046, 0.043776408595758244, 0.07549994834918378, -0.042393716953884615, -0.1374339113630515, 0.08755281719151649, 0.0035545503513881894, -0.03707167438615173, -0.08781369610750032, -0.028071163981938322, -0.026544988936273578, -0.012574628760997835, -0.05220297077792501, 0.02676674227495221, -0.09564022426271954, -0.003443674308058112, -0.043985111728545315, 0.03135830614100198, -0.030079972325614254, 0.10946709894750671, -0.007924364217475261, -0.05363783611629795, -0.025827557310435838, 0.09824906767669175, -0.13252928549438003, -0.038297832418342684, -0.10717132066620237, 0.00577532876138874, 0.014805190860691889, -0.1152065540409061, 0.0879180455871964, 0.059377291209697355, -0.02285347506729642, 0.05541185030554225, 0.05609015218067988, 0.06229919975633746, -0.00898094615487258, -0.005494877875283494, -0.10998886721296167, 0.0006057409984216576, -0.11144982252963044, -0.11625009265851347, -0.01750534356461642, -0.03576725267916561, -0.051655112534174215, -0.12272002958364217, -0.04607218896376004, -0.031593102382131075, -0.029610380886704795, -0.006512327140604252, -0.0484462371799519, 0.09986655868974066, -0.09485757290788584, -0.03928919316605582, -0.06751689075767682, -0.058959878684030846, -0.038271742440046844, 0.027810278805862114, -0.0763869617038983, 0.02484924050852189, -0.0246535771481391, 0.08202206105750925, 0.15162603113709824, 0.09746641840855551, 0.048159266198974766, 0.0003576969828858437, 0.0858831462218759, 0.06777776967366064, -0.05890770290083408, -0.005064418899780848, 0.06459498221103671, 0.06349926572353512, 0.038636983355911494, -0.1256419360435848, 0.07482165273413853, 0.007076489794929671, -0.014583438148022498, 0.027653749369574356, -0.059899059475152304, 0.04140235620617148, 0.06746470662769022, 0.009320095423083426, 0.08082198674352176, 0.10717132066620237, -0.06715164984181217, -0.024340516188866127, -0.02702762536433096, 0.021979511918473464, 0.10341457663474198, 0.02452313560344973, -0.024301382264771097, 0.0902660100851848, 0.15214778896906592, -0.05288127056636518, -0.10205798540465147, 0.012894212736519133, 0.01157674562304561, -0.05022025136919619, 0.026571076827871964, -0.10680607975033772, 0.08494396543075444, -0.015496535220940485, -0.11374560707102715, -0.02316653706991812, -0.03644555246760578, -0.05953382481938002, 0.02051855868850214, -0.026871093841345745, -0.012587672706797028, -0.03918483951296483, 0.007161277111982383, 0.041584975620755076, 0.00800915174319772, -0.02250128018392842, 0.0010402766921437092, -0.009496192864767428, -0.014844323324098702, -0.07184756840430165, 0.13993839695053784, -0.05415960646845037, -0.06287314380498918, -0.0403849054801625, 0.02404049917539235, -0.0396022541253288, -0.049437597927665035, 0.060055590998137516]}}, {'id': 'https://huggingface.co/papers/2410.15017', 'title': 'DM-Codec: Distilling Multimodal Representations for Speech Tokenization', 'url': 'https://huggingface.co/papers/2410.15017', 'abstract': 'Recent advancements in speech-language models have yielded significant improvements in speech tokenization and synthesis. However, effectively mapping the complex, multidimensional attributes of speech into discrete tokens remains challenging. This process demands acoustic, semantic, and contextual information for precise speech representations. Existing speech representations generally fall into two categories: acoustic tokens from audio codecs and semantic tokens from speech self-supervised learning models. Although recent efforts have unified acoustic and semantic tokens for improved performance, they overlook the crucial role of contextual representation in comprehensive speech modeling. Our empirical investigations reveal that the absence of contextual representations results in elevated Word Error Rate (WER) and Word Information Lost (WIL) scores in speech transcriptions. To address these limitations, we propose two novel distillation approaches: (1) a language model (LM)-guided distillation method that incorporates contextual information, and (2) a combined LM and self-supervised speech model (SM)-guided distillation technique that effectively distills multimodal representations (acoustic, semantic, and contextual) into a comprehensive speech tokenizer, termed DM-Codec. The DM-Codec architecture adopts a streamlined encoder-decoder framework with a Residual Vector Quantizer (RVQ) and incorporates the LM and SM during the training process. Experiments show DM-Codec significantly outperforms state-of-the-art speech tokenization models, reducing WER by up to 13.46%, WIL by 9.82%, and improving speech quality by 5.84% and intelligibility by 1.85% on the LibriSpeech benchmark dataset. The code, samples, and model checkpoints are available at https://github.com/mubtasimahasan/DM-Codec.', 'score': 0, 'issue_id': 208, 'pub_date': '2024-10-19', 'pub_date_ru': '19 –æ–∫—Ç—è–±—Ä—è', 'hash': 'd2c6c349adfb4796', 'data': {'desc': '–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ä–µ—á–∏, –Ω–∞–∑–≤–∞–Ω–Ω—ã–π DM-Codec. –û–Ω –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∞–∫—É—Å—Ç–∏—á–µ—Å–∫—É—é, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö —Ä–µ—á–µ–≤—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –¥–≤–∞ –º–µ—Ç–æ–¥–∞ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏: —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —Å —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é –∏ —Å–∞–º–æ–æ–±—É—á–∞—é—â–µ–π—Å—è —Ä–µ—á–µ–≤–æ–π –º–æ–¥–µ–ª—å—é. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ DM-Codec –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ä–µ—á–∏, —Å–Ω–∏–∂–∞—è –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ —É–ª—É—á—à–∞—è –∫–∞—á–µ—Å—Ç–≤–æ –∏ —Ä–∞–∑–±–æ—Ä—á–∏–≤–æ—Å—Ç—å —Ä–µ—á–∏.', 'emoji': 'üó£Ô∏è', 'title': 'DM-Codec: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ä–µ—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π', 'categories': ['#audio', '#nlp', '#benchmark', '#code'], 'embedding': [0.03224484014777453, 0.05336740479420214, -0.016159005869799695, -0.005289788109409671, -0.02443973367516587, 0.0229762788927343, 0.05956270531953494, 0.08517320740983296, -0.03165945743668244, 0.09107581957256766, 0.035098580116111465, -0.05556259045962213, -0.08956357674537428, -0.05800168342642362, 0.03153750278834237, -0.05419669680197437, 0.017988327590199457, 0.016159005869799695, 0.014463835260223337, 0.06858735927319366, -0.0286837608247068, 0.02717152198811069, -0.024098261258403256, 0.04117192798840283, 0.05073318159663843, 0.031683847967290735, 0.003551932475029897, 0.03217166456535239, 0.012500362828059903, -0.06424577099886891, -0.03090333702073507, -0.024878772204958915, -0.049879497062959265, -0.09492958925353212, -0.0015930340654749728, 0.04175731069949492, -0.06458723842738494, -0.03158628584485759, -0.043196379939564815, 0.04190365787374192, -0.015500450768763293, -0.018195651090967175, -0.09941751871620795, 0.1044908368758718, 0.019756670988779857, 0.06917274198428576, 0.04858677898773366, 0.08380731175688656, -0.05829437577961898, 0.0072502105280678845, -0.14156508189603273, 0.10556404217092147, 0.009799065272263676, -0.02478120808722713, -0.056440665523909576, -0.08180725432693015, 0.018817619597971694, -0.05561137351613734, -0.05414791374545916, -0.004957461143975841, -0.01902494309873941, -0.1029298209686564, -0.03283022485416526, 0.005975783355499852, 0.021207933498855254, -0.03995237950970344, -0.03553761764825519, -0.03758645813472681, -0.06805075762331815, 0.03953773450346665, 0.06087981991126476, 0.021878685062374982, 0.029366706655881352, -0.0034208311781818513, -0.10029559577579404, -0.046245248143365315, -0.058684634245844775, 0.10761288066209444, -0.03158628584485759, -0.01674438858089178, -0.052196637376719326, -0.058830975434195854, 0.009073434017225981, -0.03204971191231096, -0.08590492931397747, -0.059952959795163456, -0.12751589483452402, 0.07156305388987066, 0.02548854544665929, -0.08951479368885906, 0.009116118443439803, 0.024073870727794967, -0.006914835145367747, -0.022720172335451365, 0.06419698794235369, -0.02448851772933041, 0.01486628579927545, 0.05234298255566769, 0.07736810393017225, 0.03517175569853361, 0.012610122410625698, -0.04261099523317408, 0.03463515205335945, -0.00601846758218381, 0.08395365693583492, -0.026878829634915325, 0.04897703346336217, -0.07678271722848289, -0.15249223514781202, 0.008238044576331538, -0.007738029520487911, 0.04068410939504253, -0.0332692583957117, 0.04961119723567083, 0.0736118943763423, -0.15815094200446386, -0.06975812669067649, 0.02926914353579889, -0.03539127047400818, 0.03963529662589979, -0.02509829097103078, -0.002652516095519924, 0.04139144874977333, 0.0008826475704689932, 0.053611312095583646, -0.07107523529651039, 0.04670867421081869, -0.06546531548697103, -0.011408868226591574, -0.048196520521507864, -0.057367519654114955, 0.014646767033203587, 0.09117337570910489, -0.006920932977549683, -0.06863614232970888, -0.07429483920986753, -0.10780800889755802, 0.006359940996595747, -0.06912395892777054, 0.04007433615334216, -0.00059567278544024, -0.03958651755998186, 0.03363512433603057, 0.0006604612497357404, -0.03295217750720669, -0.010945439764779834, -0.03670838706103665, 0.010982025959751993, -0.1736635828507548, 0.0740997129697026, -0.04797700375073465, -0.16693167269435194, -0.06370917134429205, 0.03885478767464277, -0.12000348570335734, -0.10605185876898313, -0.07736810393017225, 0.10722262618646594, 0.05751386483306332, -0.056391882467394364, -0.02612270921896795, 0.06034321826138925, -0.0461964650868501, -0.060148090025925666, 0.008847818017561774, -0.043732979594141685, -0.020903047875654387, 0.058684634245844775, -0.10253956449772925, -0.09990534130016554, -0.0325619190409809, -0.06263596205864509, -0.11005197761949322, -0.09683208256575675, -0.020281077373351226, -0.0968808676175706, 0.0660506981980631, -0.1433212439963995, -0.12136937936100507, -0.0495868047097639, -0.012805250646089275, 0.04463544319373877, -0.02953744336308732, 0.05326984067647035, -0.07292894355692114, -0.09175876241079427, -0.05273324102189348, 0.06424577099886891, 0.07317285484889993, 0.027000784283255398, -0.03380585805028857, 0.15668749021498027, 0.09575888325660299, 0.05083074371907158, 0.03161067238486859, 0.0523917656121829, -0.0021646969035700333, 0.13297948143690688, 0.0030595400585909528, -0.08434391540206071, -0.04041581156305274, 0.022659194013632006, -0.1015639293063073, -0.10019803564865955, -0.03931821773269342, 0.0024421439779560333, -0.01476872168154366, -0.03792793354443739, -0.047342839978425984, 0.005466622449267711, 0.07536804051431992, -0.0019451785365578993, 0.14029675036081812, -0.03395220522453558, -0.10732019030419772, 0.056733357877104935, -0.04702575709462234, 0.05390400444877901, 0.04419640366629641, -0.07375823955529065, 0.020268882108047087, 0.03209849496882617, 0.07839252616870669, 0.026805656047791823, -0.08136821879008506, -0.036196173946470775, 0.0433915041844311, -0.08414878716659714, 0.06922152703609961, -0.11688144191713468, 0.05809924953945404, -0.06419698794235369, -0.0675629410252565, -0.038293795494158976, -0.01659804340194342, -0.037610848665335095, -0.002661662744027896, -0.056001627991765855, 0.07366067942815616, -0.012512558691953638, -0.035805917475543625, -0.051562473604410665, 0.1492726292391562, 0.06312378663790132, 0.022890910040306654, 0.10322251332185177, -0.020537181935335522, -0.0826365463347024, 0.06634339055125847, -0.04417201712628541, 0.06419698794235369, -0.009792967639611606, -0.02335433610776002, 0.018512731979472185, -0.030805772903003282, 0.09049043686147558]}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            const themeToggle = document.getElementById('theme-toggle');
            let settingSortBy = localStorage.getItem('sort_by');
            const sortDropdown = document.getElementById('sort-dropdown');
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "—Ö—Ñ –Ω–∞–π—Ç–ª–∏";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }
            
            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }
        
        function createCategoryButtons() {
            const categories = getUniqueCategories(articlesData);
            categories.forEach(category => {
                const button = document.createElement('span');
                button.textContent = category;
                button.className = 'category-button';
                button.onclick = () => toggleCategory(category, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if (selectedArticles.length === articlesData.length) {
                categoryToggle.textContent = 'üè∑Ô∏è –§–∏–ª—å—Ç—Ä';
            } else {
                categoryToggle.textContent = `üè∑Ô∏è –§–∏–ª—å—Ç—Ä (${formatArticlesTitle(selectedArticles.length)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles = selectedCategories.length === 0
                ? articlesData
                : articlesData.filter(article => 
                    article.data && article.data.categories && 
                    article.data.categories.some(cat => selectedCategories.includes(cat))
                );

            console.log('filteredArticles', filteredArticles)

            if (filteredArticles.length === 0) {
                selectedArticles = articlesData;
                selectedCategories = [];
                cleanCategorySelection();
            } else {
                selectedArticles = filteredArticles;
            }

            console.log('selectedArticles', selectedArticles)

            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                const explanation = item["data"]["desc"];
                const cats = item["data"]["categories"].join(" ");
                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="background-digit">${index + 1}</div>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <h2>${item['data']['emoji']} ${item['title']}</h2>
                            <p class="meta"><svg class="text-sm peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path transform="translate(0, 2)" fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg> ${item['score']}. ${item['data']['title']}</p>
                            <p class="pub-date">üìÖ –°—Ç–∞—Ç—å—è –æ—Ç ${item['pub_date_ru']}</p>
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>
                            <div class="links">
                                <a href="${item['url']}" target="_blank">–°—Ç–∞—Ç—å—è</a>
                            </div>
                            <p class="tags">${cats}</p>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            }
            if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
        });

        clearCategoriesButton.addEventListener('click', clearAllCategories);
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = 'üîÑ ' + getTimeDiffRu('2024-10-22 04:15');
        } 

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();  
    </script>
</body>
</html>
    