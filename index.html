
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 9 papers. May 13.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">13 мая</span> | <span id="title-articles-count">9 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-05-12.html">⬅️ <span id="prev-date">12.05</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-05-14.html">➡️ <span id="next-date">14.05</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-05.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '13 мая', 'en': 'May 13', 'zh': '5月13日'};
        let feedDateNext = {'ru': '14.05', 'en': '05/14', 'zh': '5月14日'};
        let feedDatePrev = {'ru': '12.05', 'en': '05/12', 'zh': '5月12日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2505.07062', 'title': 'Seed1.5-VL Technical Report', 'url': 'https://huggingface.co/papers/2505.07062', 'abstract': 'We present Seed1.5-VL, a vision-language foundation model designed to advance general-purpose multimodal understanding and reasoning. Seed1.5-VL is composed with a 532M-parameter vision encoder and a Mixture-of-Experts (MoE) LLM of 20B active parameters. Despite its relatively compact architecture, it delivers strong performance across a wide spectrum of public VLM benchmarks and internal evaluation suites, achieving the state-of-the-art performance on 38 out of 60 public benchmarks. Moreover, in agent-centric tasks such as GUI control and gameplay, Seed1.5-VL outperforms leading multimodal systems, including OpenAI CUA and Claude 3.7. Beyond visual and video understanding, it also demonstrates strong reasoning abilities, making it particularly effective for multimodal reasoning challenges such as visual puzzles. We believe these capabilities will empower broader applications across diverse tasks. In this report, we mainly provide a comprehensive review of our experiences in building Seed1.5-VL across model design, data construction, and training at various stages, hoping that this report can inspire further research. Seed1.5-VL is now accessible at https://www.volcengine.com/ (Volcano Engine Model ID: doubao-1-5-thinking-vision-pro-250428)', 'score': 33, 'issue_id': 3722, 'pub_date': '2025-05-11', 'pub_date_card': {'ru': '11 мая', 'en': 'May 11', 'zh': '5月11日'}, 'hash': 'c3406b40cc21820d', 'authors': ['Dong Guo', 'Faming Wu', 'Feida Zhu', 'Fuxing Leng', 'Guang Shi', 'Haobin Chen', 'Haoqi Fan', 'Jian Wang', 'Jianyu Jiang', 'Jiawei Wang', 'Jingji Chen', 'Jingjia Huang', 'Kang Lei', 'Liping Yuan', 'Lishu Luo', 'Pengfei Liu', 'Qinghao Ye', 'Rui Qian', 'Shen Yan', 'Shixiong Zhao', 'Shuai Peng', 'Shuangye Li', 'Sihang Yuan', 'Sijin Wu', 'Tianheng Cheng', 'Weiwei Liu', 'Wenqian Wang', 'Xianhan Zeng', 'Xiao Liu', 'Xiaobo Qin', 'Xiaohan Ding', 'Xiaojun Xiao', 'Xiaoying Zhang', 'Xuanwei Zhang', 'Xuehan Xiong', 'Yanghua Peng', 'Yangrui Chen', 'Yanwei Li', 'Yanxu Hu', 'Yi Lin', 'Yiyuan Hu', 'Yiyuan Zhang', 'Youbin Wu', 'Yu Li', 'Yudong Liu', 'Yue Ling', 'Yujia Qin', 'Zanbo Wang', 'Zhiwu He', 'Aoxue Zhang', 'Bairen Yi', 'Bencheng Liao', 'Can Huang', 'Can Zhang', 'Chaorui Deng', 'Chaoyi Deng', 'Cheng Lin', 'Cheng Yuan', 'Chenggang Li', 'Chenhui Gou', 'Chenwei Lou', 'Chengzhi Wei', 'Chundian Liu', 'Chunyuan Li', 'Deyao Zhu', 'Donghong Zhong', 'Feng Li', 'Feng Zhang', 'Gang Wu', 'Guodong Li', 'Guohong Xiao', 'Haibin Lin', 'Haihua Yang', 'Haoming Wang', 'Heng Ji', 'Hongxiang Hao', 'Hui Shen', 'Huixia Li', 'Jiahao Li', 'Jialong Wu', 'Jianhua Zhu', 'Jianpeng Jiao', 'Jiashi Feng', 'Jiaze Chen', 'Jianhui Duan', 'Jihao Liu', 'Jin Zeng', 'Jingqun Tang', 'Jingyu Sun', 'Joya Chen', 'Jun Long', 'Junda Feng', 'Junfeng Zhan', 'Junjie Fang', 'Junting Lu', 'Kai Hua', 'Kai Liu', 'Kai Shen', 'Kaiyuan Zhang', 'Ke Shen', 'Ke Wang', 'Keyu Pan', 'Kun Zhang', 'Kunchang Li', 'Lanxin Li', 'Lei Li', 'Lei Shi', 'Li Han', 'Liang Xiang', 'Liangqiang Chen', 'Lin Chen', 'Lin Li', 'Lin Yan', 'Liying Chi', 'Longxiang Liu', 'Mengfei Du', 'Mingxuan Wang', 'Ningxin Pan', 'Peibin Chen', 'Pengfei Chen', 'Pengfei Wu', 'Qingqing Yuan', 'Qingyao Shuai', 'Qiuyan Tao', 'Renjie Zheng', 'Renrui Zhang', 'Ru Zhang', 'Rui Wang', 'Rui Yang', 'Rui Zhao', 'Shaoqiang Xu', 'Shihao Liang', 'Shipeng Yan', 'Shu Zhong', 'Shuaishuai Cao', 'Shuangzhi Wu', 'Shufan Liu', 'Shuhan Chang', 'Songhua Cai', 'Tenglong Ao', 'Tianhao Yang', 'Tingting Zhang', 'Wanjun Zhong', 'Wei Jia', 'Wei Weng', 'Weihao Yu', 'Wenhao Huang', 'Wenjia Zhu', 'Wenli Yang', 'Wenzhi Wang', 'Xiang Long', 'XiangRui Yin', 'Xiao Li', 'Xiaolei Zhu', 'Xiaoying Jia', 'Xijin Zhang', 'Xin Liu', 'Xinchen Zhang', 'Xinyu Yang', 'Xiongcai Luo', 'Xiuli Chen', 'Xuantong Zhong', 'Xuefeng Xiao', 'Xujing Li', 'Yan Wu', 'Yawei Wen', 'Yifan Du', 'Yihao Zhang', 'Yining Ye', 'Yonghui Wu', 'Yu Liu', 'Yu Yue', 'Yufeng Zhou', 'Yufeng Yuan', 'Yuhang Xu', 'Yuhong Yang', 'Yun Zhang', 'Yunhao Fang', 'Yuntao Li', 'Yurui Ren', 'Yuwen Xiong', 'Zehua Hong', 'Zehua Wang', 'Zewei Sun', 'Zeyu Wang', 'Zhao Cai', 'Zhaoyue Zha', 'Zhecheng An', 'Zhehui Zhao', 'Zhengzhuo Xu', 'Zhipeng Chen', 'Zhiyong Wu', 'Zhuofan Zheng', 'Zihao Wang', 'Zilong Huang', 'Ziyu Zhu', 'Zuquan Song'], 'affiliations': [], 'pdf_title_img': 'assets/pdf/title_img/2505.07062.jpg', 'data': {'categories': ['#agi', '#multimodal', '#survey', '#architecture', '#training', '#reasoning', '#data'], 'emoji': '🧠', 'ru': {'title': 'Компактная мультимодальная модель с выдающимися способностями', 'desc': 'Seed1.5-VL - это мультимодальная модель, сочетающая зрение и язык для общего понимания и рассуждений. Она состоит из энкодера изображений на 532 млн параметров и языковой модели на основе смеси экспертов с 20 млрд активных параметров. Несмотря на компактную архитектуру, модель показывает высокие результаты в широком спектре задач, достигая state-of-the-art на 38 из 60 публичных бенчмарков. Seed1.5-VL особенно эффективна в задачах управления интерфейсами, игровом процессе и визуальных головоломках, превосходя ведущие мультимодальные системы.'}, 'en': {'title': 'Empowering Multimodal Understanding with Seed1.5-VL', 'desc': 'Seed1.5-VL is a vision-language foundation model that enhances multimodal understanding and reasoning. It features a compact architecture with a 532M-parameter vision encoder and a 20B parameter Mixture-of-Experts (MoE) language model, achieving state-of-the-art results on many benchmarks. The model excels in agent-centric tasks like GUI control and gameplay, outperforming other leading systems. Additionally, it showcases strong reasoning capabilities, making it effective for complex multimodal challenges such as visual puzzles.'}, 'zh': {'title': 'Seed1.5-VL：多模态理解与推理的新突破', 'desc': '我们介绍了Seed1.5-VL，这是一种旨在提升多模态理解和推理的视觉-语言基础模型。Seed1.5-VL由一个532M参数的视觉编码器和一个具有20B活跃参数的专家混合模型（MoE LLM）组成。尽管其架构相对紧凑，但在多个公共VLM基准测试中表现出色，在60个公共基准中有38个达到了最先进的性能。此外，在以代理为中心的任务中，如图形用户界面控制和游戏玩法，Seed1.5-VL超越了领先的多模态系统，包括OpenAI CUA和Claude 3.7。'}}}, {'id': 'https://huggingface.co/papers/2505.07608', 'title': 'MiMo: Unlocking the Reasoning Potential of Language Model -- From\n  Pretraining to Posttraining', 'url': 'https://huggingface.co/papers/2505.07608', 'abstract': "We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing strategy to strengthen the base model's reasoning potential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional Multi-Token Prediction objective for enhanced performance and accelerated inference speed. During post-training, we curate a dataset of 130K verifiable mathematics and programming problems for reinforcement learning, integrating a test-difficulty-driven code-reward scheme to alleviate sparse-reward issues and employing strategic data resampling to stabilize training. Extensive evaluations show that MiMo-7B-Base possesses exceptional reasoning potential, outperforming even much larger 32B models. The final RL-tuned model, MiMo-7B-RL, achieves superior performance on mathematics, code and general reasoning tasks, surpassing the performance of OpenAI o1-mini. The model checkpoints are available at https://github.com/xiaomimimo/MiMo.", 'score': 25, 'issue_id': 3723, 'pub_date': '2025-05-12', 'pub_date_card': {'ru': '12 мая', 'en': 'May 12', 'zh': '5月12日'}, 'hash': '9db5f7b72add3369', 'authors': ['Xiaomi LLM-Core Team', ':', 'Bingquan Xia', 'Bowen Shen', 'Cici', 'Dawei Zhu', 'Di Zhang', 'Gang Wang', 'Hailin Zhang', 'Huaqiu Liu', 'Jiebao Xiao', 'Jinhao Dong', 'Liang Zhao', 'Peidian Li', 'Peng Wang', 'Shihua Yu', 'Shimao Chen', 'Weikun Wang', 'Wenhan Ma', 'Xiangwei Deng', 'Yi Huang', 'Yifan Song', 'Zihan Jiang', 'Bowen Ye', 'Can Cai', 'Chenhong He', 'Dong Zhang', 'Duo Zhang', 'Guoan Wang', 'Hao Tian', 'Haochen Zhao', 'Heng Qu', 'Hongshen Xu', 'Jun Shi', 'Kainan Bao', 'QingKai Fang', 'Kang Zhou', 'Kangyang Zhou', 'Lei Li', 'Menghang Zhu', 'Nuo Chen', 'Qiantong Wang', 'Shaohui Liu', 'Shicheng Li', 'Shuhao Gu', 'Shuhuai Ren', 'Shuo Liu', 'Sirui Deng', 'Weiji Zhuang', 'Weiwei Lv', 'Wenyu Yang', 'Xin Zhang', 'Xing Yong', 'Xing Zhang', 'Xingchen Song', 'Xinzhe Xu', 'Xu Wang', 'Yihan Yan', 'Yu Tu', 'Yuanyuan Tian', 'Yudong Wang', 'Yue Yu', 'Zhenru Lin', 'Zhichao Song', 'Zihao Yue'], 'affiliations': ['Xiaomi LLM-Core Team'], 'pdf_title_img': 'assets/pdf/title_img/2505.07608.jpg', 'data': {'categories': ['#plp', '#reasoning', '#optimization', '#dataset', '#math', '#rl', '#data', '#training'], 'emoji': '🧠', 'ru': {'title': 'MiMo-7B: Мощная языковая модель для сложных рассуждений', 'desc': 'MiMo-7B - это большая языковая модель, оптимизированная для задач рассуждения. В процессе предварительного обучения использовалась улучшенная обработка данных и трехэтапная стратегия смешивания для усиления потенциала базовой модели. На этапе пост-обучения применялось обучение с подкреплением на наборе из 130 тысяч верифицируемых задач по математике и программированию. Итоговая модель MiMo-7B-RL превосходит более крупные модели в задачах рассуждения, математики и программирования.'}, 'en': {'title': 'MiMo-7B: Revolutionizing Reasoning with Advanced Training Techniques', 'desc': 'MiMo-7B is a large language model specifically designed for reasoning tasks, optimized through both pre-training and post-training processes. In the pre-training phase, it utilizes an advanced data preprocessing pipeline and a three-stage data mixing strategy to enhance its reasoning capabilities, training on a massive dataset of 25 trillion tokens. The post-training phase involves reinforcement learning with a curated dataset of 130,000 math and programming problems, addressing sparse-reward challenges with a code-reward scheme and strategic data resampling. Evaluations demonstrate that MiMo-7B-Base excels in reasoning tasks, outperforming larger models, while the final RL-tuned version, MiMo-7B-RL, achieves outstanding results in mathematics, coding, and general reasoning tasks.'}, 'zh': {'title': 'MiMo-7B：推理任务的强大语言模型', 'desc': '我们介绍了MiMo-7B，这是一个专为推理任务设计的大型语言模型，优化了预训练和后训练阶段。在预训练过程中，我们增强了数据预处理流程，并采用三阶段数据混合策略，以提升基础模型的推理能力。MiMo-7B-Base在25万亿个标记上进行预训练，并增加了多标记预测目标，以提高性能和加速推理速度。在后训练阶段，我们整理了130K个可验证的数学和编程问题数据集，结合测试难度驱动的代码奖励机制，解决稀疏奖励问题，并采用战略性数据重采样来稳定训练。'}}}, {'id': 'https://huggingface.co/papers/2505.07787', 'title': 'Learning from Peers in Reasoning Models', 'url': 'https://huggingface.co/papers/2505.07787', 'abstract': 'Large Reasoning Models (LRMs) have the ability to self-correct even when they make mistakes in their reasoning paths. However, our study reveals that when the reasoning process starts with a short but poor beginning, it becomes difficult for the model to recover. We refer to this phenomenon as the "Prefix Dominance Trap". Inspired by psychological findings that peer interaction can promote self-correction without negatively impacting already accurate individuals, we propose **Learning from Peers** (LeaP) to address this phenomenon. Specifically, every tokens, each reasoning path summarizes its intermediate reasoning and shares it with others through a routing mechanism, enabling paths to incorporate peer insights during inference. However, we observe that smaller models sometimes fail to follow summarization and reflection instructions effectively. To address this, we fine-tune them into our **LeaP-T** model series. Experiments on AIME 2024, AIME 2025, AIMO 2025, and GPQA Diamond show that LeaP provides substantial improvements. For instance, QwQ-32B with LeaP achieves nearly 5 absolute points higher than the baseline on average, and surpasses DeepSeek-R1-671B on three math benchmarks with an average gain of 3.3 points. Notably, our fine-tuned LeaP-T-7B matches the performance of DeepSeek-R1-Distill-Qwen-14B on AIME 2024. In-depth analysis reveals LeaP\'s robust error correction by timely peer insights, showing strong error tolerance and handling varied task difficulty. LeaP marks a milestone by enabling LRMs to collaborate during reasoning. Our code, datasets, and models are available at https://learning-from-peers.github.io/ .', 'score': 18, 'issue_id': 3722, 'pub_date': '2025-05-12', 'pub_date_card': {'ru': '12 мая', 'en': 'May 12', 'zh': '5月12日'}, 'hash': '350f28f20ab516fc', 'authors': ['Tongxu Luo', 'Wenyu Du', 'Jiaxi Bi', 'Stephen Chung', 'Zhengyang Tang', 'Hao Yang', 'Min Zhang', 'Benyou Wang'], 'affiliations': ['DualityRL', 'Huawei', 'The Chinese University of Hong Kong, Shenzhen', 'USTB'], 'pdf_title_img': 'assets/pdf/title_img/2505.07787.jpg', 'data': {'categories': ['#optimization', '#math', '#training', '#small_models', '#reasoning', '#dataset'], 'emoji': '🧠', 'ru': {'title': 'Коллективный разум: как модели машинного обучения учатся друг у друга', 'desc': "Исследование показывает, что крупные модели рассуждений (LRM) могут попадать в 'ловушку доминирования префикса', когда плохое начало рассуждения мешает самокоррекции. Для решения этой проблемы предложен метод 'Обучение у сверстников' (LeaP), позволяющий моделям обмениваться промежуточными выводами во время вывода. Авторы также представили серию моделей LeaP-T, настроенных для эффективного следования инструкциям по обобщению и рефлексии. Эксперименты на математических бенчмарках показали значительное улучшение производительности моделей с использованием LeaP."}, 'en': {'title': 'Empowering LRMs through Peer Collaboration', 'desc': "This paper introduces a new approach called Learning from Peers (LeaP) to enhance the self-correction capabilities of Large Reasoning Models (LRMs). It identifies a challenge known as the 'Prefix Dominance Trap', where poor initial reasoning hinders recovery. LeaP allows models to share intermediate reasoning insights through a routing mechanism, promoting collaborative learning among reasoning paths. The results show that LeaP significantly improves performance on various benchmarks, demonstrating effective error correction and adaptability to different task difficulties."}, 'zh': {'title': '同伴学习：提升推理模型的自我纠正能力', 'desc': '大型推理模型（LRMs）具有自我纠正的能力，但当推理过程以短而差的开头开始时，模型很难恢复。我们称这种现象为“前缀主导陷阱”。为了解决这个问题，我们提出了“从同伴学习”（LeaP），通过路由机制让每个推理路径总结其中间推理并与其他路径共享，从而在推理过程中融入同伴的见解。实验结果表明，LeaP显著提高了模型的表现，尤其是在处理不同任务难度时展现出强大的错误容忍能力。'}}}, {'id': 'https://huggingface.co/papers/2505.03733', 'title': 'WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional\n  Websites from Scratch', 'url': 'https://huggingface.co/papers/2505.03733', 'abstract': "LLM-based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructions for website generation, created through the combined efforts of human annotators and GPT-4o. These instructions span three major categories and thirteen minor categories, encompassing nearly all important types of web applications. To assess the quality of the generated websites, we use GPT-4o to generate test cases targeting each functionality described in the instructions, and then manually filter, adjust, and organize them to ensure accuracy, resulting in 647 test cases. Each test case specifies an operation to be performed on the website and the expected result after the operation. To automate testing and improve reproducibility, we employ a powerful web-navigation agent to execute tests on the generated websites and determine whether the observed responses align with the expected results. We evaluate three high-performance code-agent frameworks, Bolt.diy, OpenHands, and Aider, using multiple proprietary and open-source LLMs as engines. The best-performing combination, Bolt.diy powered by DeepSeek-R1, achieves only 27.8\\% accuracy on the test cases, highlighting the challenging nature of our benchmark. Additionally, we construct WebGen-Instruct, a training set consisting of 6,667 website-generation instructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories generated from a subset of this training set achieves an accuracy of 38.2\\%, surpassing the performance of the best proprietary model.", 'score': 10, 'issue_id': 3722, 'pub_date': '2025-05-06', 'pub_date_card': {'ru': '6 мая', 'en': 'May 6', 'zh': '5月6日'}, 'hash': '1d5e56d00ea8d485', 'authors': ['Zimu Lu', 'Yunqiao Yang', 'Houxing Ren', 'Haotian Hou', 'Han Xiao', 'Ke Wang', 'Weikang Shi', 'Aojun Zhou', 'Mingjie Zhan', 'Hongsheng Li'], 'affiliations': ['Multimedia Laboratory (MMLab), The Chinese University of Hong Kong'], 'pdf_title_img': 'assets/pdf/title_img/2505.03733.jpg', 'data': {'categories': ['#optimization', '#games', '#benchmark', '#training', '#agents', '#dataset'], 'emoji': '🌐', 'ru': {'title': 'WebGen-Bench: Новый рубеж в оценке LLM-агентов для веб-разработки', 'desc': 'WebGen-Bench - это новый бенчмарк для оценки способности LLM-агентов создавать многофайловые веб-сайты с нуля. Он включает разнообразные инструкции по генерации сайтов, охватывающие почти все важные типы веб-приложений. Качество сгенерированных сайтов оценивается с помощью автоматизированных тестовых случаев, созданных GPT-4o и проверенных вручную. Лучшая комбинация - Bolt.diy с DeepSeek-R1 - достигает только 27,8% точности, что подчеркивает сложность бенчмарка.'}, 'en': {'title': 'Benchmarking LLMs for Website Code Generation', 'desc': 'This paper presents WebGen-Bench, a benchmark for evaluating LLM-based agents in generating multi-file website codebases. It includes a variety of instructions for website creation, developed by both human annotators and GPT-4o, covering a wide range of web application types. The quality of the generated websites is assessed using 647 test cases that check if the websites function as expected, with a web-navigation agent automating the testing process. The results show that even the best-performing code-agent framework, Bolt.diy with DeepSeek-R1, only achieves 27.8% accuracy, indicating the complexity of the task and the need for improved models.'}, 'zh': {'title': '评估LLM代理生成网站代码的挑战', 'desc': '本文介绍了一种新的基准测试WebGen-Bench，旨在评估基于大型语言模型（LLM）的代理在从零开始创建多文件网站代码库的能力。该基准包含多样化的网站生成指令，涵盖了三大类和十三小类，几乎包括所有重要类型的Web应用程序。为了评估生成网站的质量，使用GPT-4o生成针对每个功能的测试用例，并手动过滤和调整，最终形成647个测试用例。通过强大的网页导航代理自动执行测试，评估生成网站的响应是否符合预期结果，结果显示最佳模型组合的准确率仅为27.8%，显示出基准的挑战性。'}}}, {'id': 'https://huggingface.co/papers/2505.06548', 'title': 'REFINE-AF: A Task-Agnostic Framework to Align Language Models via\n  Self-Generated Instructions using Reinforcement Learning from Automated\n  Feedback', 'url': 'https://huggingface.co/papers/2505.06548', 'abstract': 'Instruction-based Large Language Models (LLMs) have proven effective in numerous few-shot or zero-shot Natural Language Processing (NLP) tasks. However, creating human-annotated instruction data is time-consuming, expensive, and often limited in quantity and task diversity. Previous research endeavors have attempted to address this challenge by proposing frameworks capable of generating instructions in a semi-automated and task-agnostic manner directly from the model itself. Many of these efforts have relied on large API-only parameter-based models such as GPT-3.5 (175B), which are expensive, and subject to limits on a number of queries. This paper explores the performance of three open-source small LLMs such as LLaMA 2-7B, LLama 2-13B, and Mistral 7B, using a semi-automated framework, thereby reducing human intervention, effort, and cost required to generate an instruction dataset for fine-tuning LLMs. Furthermore, we demonstrate that incorporating a Reinforcement Learning (RL) based training algorithm into this LLMs-based framework leads to further enhancements. Our evaluation of the dataset reveals that these RL-based frameworks achieve a substantial improvements in 63-66% of the tasks compared to previous approaches.', 'score': 8, 'issue_id': 3722, 'pub_date': '2025-05-10', 'pub_date_card': {'ru': '10 мая', 'en': 'May 10', 'zh': '5月10日'}, 'hash': 'db28335cad79db53', 'authors': ['Aniruddha Roy', 'Pretam Ray', 'Abhilash Nandy', 'Somak Aditya', 'Pawan Goyal'], 'affiliations': ['Indian Institute of Technology, Kharagpur'], 'pdf_title_img': 'assets/pdf/title_img/2505.06548.jpg', 'data': {'categories': ['#optimization', '#open_source', '#training', '#small_models', '#rl', '#dataset', '#data'], 'emoji': '🤖', 'ru': {'title': 'Малые модели и RL улучшают генерацию инструкций для обучения больших ЯМ', 'desc': 'Статья исследует эффективность малых открытых языковых моделей (LLaMA 2-7B, LLama 2-13B, Mistral 7B) для полуавтоматической генерации инструкций для обучения больших языковых моделей. Авторы применяют фреймворк, уменьшающий необходимость ручной разметки и затраты на создание датасета инструкций. Они также интегрируют алгоритм обучения с подкреплением (RL) для улучшения результатов. Эксперименты показывают, что предложенный подход с RL превосходит предыдущие методы в 63-66% задач.'}, 'en': {'title': 'Empowering LLMs with Cost-Effective Instruction Generation', 'desc': 'This paper discusses the challenges of creating instruction data for training Large Language Models (LLMs) in Natural Language Processing (NLP). It introduces a semi-automated framework that utilizes smaller open-source LLMs, like LLaMA and Mistral, to generate this data with less human effort and cost. The authors also incorporate a Reinforcement Learning (RL) training algorithm, which significantly improves the performance of the generated instruction datasets. The results show that this approach enhances task performance in a majority of cases compared to earlier methods.'}, 'zh': {'title': '高效生成指令数据，提升LLMs性能', 'desc': '这篇论文探讨了指令驱动的大型语言模型（LLMs）在自然语言处理任务中的应用。作者提出了一种半自动化框架，利用开源的小型LLMs（如LLaMA 2-7B、LLaMA 2-13B和Mistral 7B）来生成指令数据集，从而减少人工干预和成本。通过引入基于强化学习的训练算法，研究表明这种方法在63-66%的任务中显著提高了性能。该研究为生成多样化的指令数据提供了一种更高效的解决方案。'}}}, {'id': 'https://huggingface.co/papers/2505.07796', 'title': 'Learning Dynamics in Continual Pre-Training for Large Language Models', 'url': 'https://huggingface.co/papers/2505.07796', 'abstract': 'Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.', 'score': 4, 'issue_id': 3723, 'pub_date': '2025-05-12', 'pub_date_card': {'ru': '12 мая', 'en': 'May 12', 'zh': '5月12日'}, 'hash': 'c63d617be0b4d13a', 'authors': ['Xingjin Wang', 'Howe Tissue', 'Lu Wang', 'Linjing Li', 'Daniel Dajun Zeng'], 'affiliations': ['Ritzz-AI', 'School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China', 'State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China'], 'pdf_title_img': 'assets/pdf/title_img/2505.07796.jpg', 'data': {'categories': ['#optimization', '#transfer_learning', '#training'], 'emoji': '📈', 'ru': {'title': 'Раскрытие секретов непрерывного предобучения языковых моделей', 'desc': 'Статья исследует динамику обучения при непрерывном предобучении (CPT) больших языковых моделей. Авторы наблюдают, как меняется производительность модели на общих и специфических задачах на каждом шаге обучения. Они предлагают масштабируемый закон CPT, объединяющий эффекты смещения распределения и снижения скорости обучения. Этот подход позволяет прогнозировать потери на любом этапе обучения и настраивать гиперпараметры для различных целей CPT.'}, 'en': {'title': 'Unlocking the Dynamics of Continual Pre-Training', 'desc': "This paper investigates the learning dynamics of Continual Pre-Training (CPT) for large language models, focusing on how performance in general and specific domains changes during training. The authors analyze the CPT loss curve, revealing that it represents a transition between different performance states influenced by distribution shifts and learning rate adjustments. They propose a scaling law that predicts loss across various training steps and learning rate schedules, providing insights into key factors like peak learning rate and replay ratio. The findings are validated through extensive experiments, showing the law's applicability across different datasets and training configurations."}, 'zh': {'title': '持续预训练的动态与优化法则', 'desc': '持续预训练（CPT）是一种将强大的基础模型应用于特定下游任务的有效方法。本文探讨了大型语言模型在CPT过程中的学习动态，特别关注在每个训练步骤中，通用性能和下游领域性能的演变。我们观察到CPT损失曲线本质上描述了从一个曲线到另一个隐藏曲线的过渡，并通过解耦分布变化和学习率退火的影响来进行描述。我们推导出了一种CPT缩放法则，结合了这两个因素，使得能够预测在任何（持续）训练步骤和学习率调度下的损失。'}}}, {'id': 'https://huggingface.co/papers/2505.07596', 'title': 'Reinforced Internal-External Knowledge Synergistic Reasoning for\n  Efficient Adaptive Search Agent', 'url': 'https://huggingface.co/papers/2505.07596', 'abstract': 'Retrieval-augmented generation (RAG) is a common strategy to reduce hallucinations in Large Language Models (LLMs). While reinforcement learning (RL) can enable LLMs to act as search agents by activating retrieval capabilities, existing ones often underutilize their internal knowledge. This can lead to redundant retrievals, potential harmful knowledge conflicts, and increased inference latency. To address these limitations, an efficient and adaptive search agent capable of discerning optimal retrieval timing and synergistically integrating parametric (internal) and retrieved (external) knowledge is in urgent need. This paper introduces the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), which could indentify its own knowledge boundary and prioritize the utilization of internal knowledge, resorting to external search only when internal knowledge is deemed insufficient. This is achieved using a novel knowledge-boundary aware reward function and a knowledge-boundary aware training dataset. These are designed for internal-external knowledge synergy oriented RL, incentivizing the model to deliver accurate answers, minimize unnecessary retrievals, and encourage appropriate external searches when its own knowledge is lacking. Evaluations across multiple knowledge reasoning tasks demonstrate that IKEA significantly outperforms baseline methods, reduces retrieval frequency significantly, and exhibits robust generalization capabilities.', 'score': 4, 'issue_id': 3723, 'pub_date': '2025-05-12', 'pub_date_card': {'ru': '12 мая', 'en': 'May 12', 'zh': '5月12日'}, 'hash': '10063104a79da512', 'authors': ['Ziyang Huang', 'Xiaowei Yuan', 'Yiming Ju', 'Jun Zhao', 'Kang Liu'], 'affiliations': ['Beijing Academy of Artificial Intelligence', 'Institute of Automation, Chinese Academy of Sciences', 'University of Chinese Academy of Sciences'], 'pdf_title_img': 'assets/pdf/title_img/2505.07596.jpg', 'data': {'categories': ['#reasoning', '#rag', '#agents', '#optimization', '#hallucinations', '#rl', '#training'], 'emoji': '🧠', 'ru': {'title': 'Умный поиск: когда искать, а когда довериться себе', 'desc': 'Статья представляет новый подход к улучшению работы больших языковых моделей (LLM) с использованием метода retrieval-augmented generation (RAG). Авторы предлагают агента IKEA, который способен эффективно определять границы собственных знаний и принимать решение о необходимости внешнего поиска информации. Для обучения агента используется функция вознаграждения, учитывающая границы знаний, и специально подготовленный набор данных. Эксперименты показывают, что IKEA превосходит базовые методы, значительно сокращает частоту обращений к внешним источникам и демонстрирует хорошую обобщающую способность.'}, 'en': {'title': 'Optimizing Knowledge Use in Language Models with IKEA', 'desc': 'This paper presents the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), a novel approach to enhance the performance of Large Language Models (LLMs) by optimizing their retrieval processes. IKEA intelligently determines when to use its internal knowledge versus when to perform external searches, reducing unnecessary retrievals and improving inference speed. The model employs a unique reward function that encourages effective use of internal knowledge while still allowing for external retrieval when needed. Evaluations show that IKEA not only outperforms existing methods but also generalizes well across various knowledge reasoning tasks.'}, 'zh': {'title': '智能检索，优化知识利用', 'desc': '本文介绍了一种新的强化学习模型，名为IKEA，旨在提高大型语言模型（LLMs）的检索能力。IKEA能够识别自身知识的边界，并优先使用内部知识，只有在内部知识不足时才会进行外部检索。通过引入一种新的奖励函数和训练数据集，IKEA能够有效减少冗余检索，提高回答的准确性。实验结果表明，IKEA在多个知识推理任务中表现优异，显著降低了检索频率，并展现出强大的泛化能力。'}}}, {'id': 'https://huggingface.co/papers/2505.07818', 'title': 'DanceGRPO: Unleashing GRPO on Visual Generation', 'url': 'https://huggingface.co/papers/2505.07818', 'abstract': 'Recent breakthroughs in generative models-particularly diffusion models and rectified flows-have revolutionized visual content creation, yet aligning model outputs with human preferences remains a critical challenge. Existing reinforcement learning (RL)-based methods for visual generation face critical limitations: incompatibility with modern Ordinary Differential Equations (ODEs)-based sampling paradigms, instability in large-scale training, and lack of validation for video generation. This paper introduces DanceGRPO, the first unified framework to adapt Group Relative Policy Optimization (GRPO) to visual generation paradigms, unleashing one unified RL algorithm across two generative paradigms (diffusion models and rectified flows), three tasks (text-to-image, text-to-video, image-to-video), four foundation models (Stable Diffusion, HunyuanVideo, FLUX, SkyReel-I2V), and five reward models (image/video aesthetics, text-image alignment, video motion quality, and binary reward). To our knowledge, DanceGRPO is the first RL-based unified framework capable of seamless adaptation across diverse generative paradigms, tasks, foundational models, and reward models. DanceGRPO demonstrates consistent and substantial improvements, which outperform baselines by up to 181% on benchmarks such as HPS-v2.1, CLIP Score, VideoAlign, and GenEval. Notably, DanceGRPO not only can stabilize policy optimization for complex video generation, but also enables generative policy to better capture denoising trajectories for Best-of-N inference scaling and learn from sparse binary feedback. Our results establish DanceGRPO as a robust and versatile solution for scaling Reinforcement Learning from Human Feedback (RLHF) tasks in visual generation, offering new insights into harmonizing reinforcement learning and visual synthesis. The code will be released.', 'score': 3, 'issue_id': 3723, 'pub_date': '2025-05-12', 'pub_date_card': {'ru': '12 мая', 'en': 'May 12', 'zh': '5月12日'}, 'hash': '023078250e0d651f', 'authors': ['Zeyue Xue', 'Jie Wu', 'Yu Gao', 'Fangyuan Kong', 'Lingting Zhu', 'Mengzhao Chen', 'Zhiheng Liu', 'Wei Liu', 'Qiushan Guo', 'Weilin Huang', 'Ping Luo'], 'affiliations': ['ByteDance Seed', 'The University of Hong Kong'], 'pdf_title_img': 'assets/pdf/title_img/2505.07818.jpg', 'data': {'categories': ['#alignment', '#optimization', '#video', '#multimodal', '#rl', '#diffusion', '#benchmark', '#rlhf'], 'emoji': '🎨', 'ru': {'title': 'DanceGRPO: Революция в обучении с подкреплением для генерации визуального контента', 'desc': 'Статья представляет DanceGRPO - унифицированный фреймворк для адаптации Group Relative Policy Optimization (GRPO) к задачам генерации визуального контента. DanceGRPO совместим с различными генеративными парадигмами, задачами, фундаментальными моделями и моделями вознаграждения. Фреймворк демонстрирует значительные улучшения по сравнению с базовыми методами на нескольких бенчмарках. DanceGRPO стабилизирует оптимизацию политики для сложной генерации видео и позволяет генеративной политике лучше захватывать траектории шумоподавления.'}, 'en': {'title': 'DanceGRPO: Unifying Reinforcement Learning for Visual Generation', 'desc': 'This paper presents DanceGRPO, a novel framework that enhances visual content generation by integrating Group Relative Policy Optimization (GRPO) with generative models like diffusion models and rectified flows. It addresses key challenges in reinforcement learning (RL) for visual generation, such as instability during training and compatibility with modern sampling methods. DanceGRPO is versatile, supporting multiple tasks including text-to-image and video generation, and utilizes various foundational and reward models to improve output quality. The framework shows significant performance improvements over existing methods, making it a promising solution for aligning generative models with human preferences in visual synthesis.'}, 'zh': {'title': 'DanceGRPO：视觉生成的统一强化学习框架', 'desc': '本论文介绍了DanceGRPO，这是第一个将群体相对策略优化（GRPO）应用于视觉生成的统一框架。它解决了现有基于强化学习（RL）的方法在现代常微分方程（ODE）采样、训练稳定性和视频生成验证方面的局限性。DanceGRPO能够在扩散模型和修正流等多种生成范式中无缝适应，并在文本到图像、文本到视频和图像到视频等任务中表现出显著的性能提升。该框架在多个基准测试中超越了基线，展示了在视觉生成任务中结合强化学习与人类反馈的潜力。'}}}, {'id': 'https://huggingface.co/papers/2505.07747', 'title': 'Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured\n  3D Assets', 'url': 'https://huggingface.co/papers/2505.07747', 'abstract': 'While generative artificial intelligence has advanced significantly across text, image, audio, and video domains, 3D generation remains comparatively underdeveloped due to fundamental challenges such as data scarcity, algorithmic limitations, and ecosystem fragmentation. To this end, we present Step1X-3D, an open framework addressing these challenges through: (1) a rigorous data curation pipeline processing >5M assets to create a 2M high-quality dataset with standardized geometric and textural properties; (2) a two-stage 3D-native architecture combining a hybrid VAE-DiT geometry generator with an diffusion-based texture synthesis module; and (3) the full open-source release of models, training code, and adaptation modules. For geometry generation, the hybrid VAE-DiT component produces TSDF representations by employing perceiver-based latent encoding with sharp edge sampling for detail preservation. The diffusion-based texture synthesis module then ensures cross-view consistency through geometric conditioning and latent-space synchronization. Benchmark results demonstrate state-of-the-art performance that exceeds existing open-source methods, while also achieving competitive quality with proprietary solutions. Notably, the framework uniquely bridges the 2D and 3D generation paradigms by supporting direct transfer of 2D control techniques~(e.g., LoRA) to 3D synthesis. By simultaneously advancing data quality, algorithmic fidelity, and reproducibility, Step1X-3D aims to establish new standards for open research in controllable 3D asset generation.', 'score': 1, 'issue_id': 3723, 'pub_date': '2025-05-12', 'pub_date_card': {'ru': '12 мая', 'en': 'May 12', 'zh': '5月12日'}, 'hash': 'd9ffe741ebae4acb', 'authors': ['Weiyu Li', 'Xuanyang Zhang', 'Zheng Sun', 'Di Qi', 'Hao Li', 'Wei Cheng', 'Weiwei Cai', 'Shihao Wu', 'Jiarui Liu', 'Zihao Wang', 'Xiao Chen', 'Feipeng Tian', 'Jianxiong Pan', 'Zeming Li', 'Gang Yu', 'Xiangyu Zhang', 'Daxin Jiang', 'Ping Tan'], 'affiliations': [], 'pdf_title_img': 'assets/pdf/title_img/2505.07747.jpg', 'data': {'categories': ['#open_source', '#dataset', '#architecture', '#data', '#diffusion', '#transfer_learning', '#3d', '#benchmark'], 'emoji': '🧊', 'ru': {'title': 'Открытая платформа для AI-генерации 3D-объектов нового поколения', 'desc': 'Статья представляет Step1X-3D - открытую систему для генерации 3D-объектов с использованием искусственного интеллекта. Авторы разработали процесс обработки большого набора данных, создав высококачественный датасет из 2 миллионов 3D-моделей. Архитектура системы включает гибридный VAE-DiT генератор геометрии и диффузионный модуль для синтеза текстур. Step1X-3D демонстрирует высокое качество генерации и позволяет применять методы контроля из 2D-генерации к 3D-синтезу.'}, 'en': {'title': 'Revolutionizing 3D Generation with Step1X-3D', 'desc': 'The paper introduces Step1X-3D, a framework designed to improve 3D generation in artificial intelligence. It tackles challenges like limited data and algorithmic issues by creating a high-quality dataset and employing a two-stage architecture that combines a geometry generator and a texture synthesis module. The framework allows for better detail preservation and consistency in 3D assets by integrating techniques from 2D generation. By providing open-source resources, it aims to enhance research and development in controllable 3D asset generation.'}, 'zh': {'title': 'Step1X-3D：开创可控3D生成的新标准', 'desc': '本论文介绍了Step1X-3D，这是一个开放框架，旨在解决3D生成中的数据稀缺、算法限制和生态系统碎片化等挑战。该框架通过严格的数据整理流程，处理超过500万资产，创建了一个200万高质量数据集，并采用标准化的几何和纹理属性。它结合了混合VAE-DiT几何生成器和基于扩散的纹理合成模块，能够生成高质量的3D模型。Step1X-3D还支持将2D控制技术直接转移到3D合成，推动了可控3D资产生成的新标准。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (1)', '#agents (2)', '#agi (1)', '#alignment (1)', '#architecture (2)', '#audio', '#benchmark (3)', '#cv', '#data (4)', '#dataset (5)', '#diffusion (2)', '#ethics', '#games (1)', '#graphs', '#hallucinations (1)', '#healthcare', '#inference', '#interpretability', '#leakage', '#long_context', '#low_resource', '#machine_translation', '#math (2)', '#multilingual', '#multimodal (2)', '#open_source (2)', '#optimization (7)', '#plp (1)', '#rag (1)', '#reasoning (4)', '#rl (4)', '#rlhf (1)', '#robotics', '#science', '#security', '#small_models (2)', '#story_generation', '#survey (1)', '#synthetic', '#training (7)', '#transfer_learning (2)', '#video (1)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-05-13 03:37',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-05-13 03:37')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-05-13 03:37')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    