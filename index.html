
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 8 papers. September 4.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ", "Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹", "Ğ¼Ğ¸Ğ½ÑƒÑ‚"],
                hour: ["Ñ‡Ğ°Ñ", "Ñ‡Ğ°ÑĞ°", "Ñ‡Ğ°ÑĞ¾Ğ²"],
                day: ["Ğ´ĞµĞ½ÑŒ", "Ğ´Ğ½Ñ", "Ğ´Ğ½ĞµĞ¹"],
                justNow: "Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾",
                ago: "Ğ½Ğ°Ğ·Ğ°Ğ´"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["åˆ†é’Ÿ", "åˆ†é’Ÿ", "åˆ†é’Ÿ"],
                hour: ["å°æ—¶", "å°æ—¶", "å°æ—¶"],
                day: ["å¤©", "å¤©", "å¤©"],
                justNow: "åˆšåˆš",
                ago: "å‰"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            } else if (lastDigit === 1) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒÑ";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒĞ¸";
            } else {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "ç¯‡è®ºæ–‡"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">ğŸ”º</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">4 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ</span> | <span id="title-articles-count">8 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-09-03.html">â¬…ï¸ <span id="prev-date">03.09</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-09-05.html">â¡ï¸ <span id="next-date">05.09</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-09.html">ğŸ“ˆ <span id='top-month-label'>ĞœĞµÑÑÑ†</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">ğŸ”€ <span id="sort-label-text">Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ</option>
                    <option value="pub_date">Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸</option>
                    <option value="issue_id">Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">ğŸ·ï¸ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> AâˆªB</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> Aâˆ©B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">ğŸ§¹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> âœ–ï¸ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '4 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ', 'en': 'September 4', 'zh': '9æœˆ4æ—¥'};
        let feedDateNext = {'ru': '05.09', 'en': '09/05', 'zh': '9æœˆ5æ—¥'};
        let feedDatePrev = {'ru': '03.09', 'en': '09/03', 'zh': '9æœˆ3æ—¥'};
        let filterLabel = {'ru': 'Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€', 'en': 'Topics', 'zh': 'ä¸»é¢˜ç­›é€‰'}
        let publishedLabel = {'ru': 'ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ñ‚ ', 'en': 'published on ', 'zh': 'å‘è¡¨äº'}
        let sortLabel = {'ru': 'Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾', 'en': 'Sort by', 'zh': 'æ’åºæ–¹å¼'}
        let paperLabel = {'ru': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ', 'en': 'Paper', 'zh': 'è®ºæ–‡'}
        let topMonthLabel = {'ru': 'ĞœĞµÑÑÑ†', 'en': 'Month', 'zh': 'æœˆåº¦è®ºæ–‡'}
        let topDayLabel = {'ru': 'Ğ”ĞµĞ½ÑŒ', 'en': 'Day', 'zh': 'æ—¥åº¦è®ºæ–‡'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2509.01106', 'title': 'Robix: A Unified Model for Robot Interaction, Reasoning and Planning', 'url': 'https://huggingface.co/papers/2509.01106', 'abstract': 'Robix, a unified vision-language model, integrates robot reasoning, task planning, and natural language interaction, demonstrating superior performance in interactive task execution through chain-of-thought reasoning and a three-stage training strategy.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce Robix, a unified model that integrates robot reasoning, task planning, and natural language interaction within a single vision-language architecture. Acting as the high-level cognitive layer in a hierarchical robot system, Robix dynamically generates atomic commands for the low-level controller and verbal responses for human interaction, enabling robots to follow complex instructions, plan long-horizon tasks, and interact naturally with human within an end-to-end framework. Robix further introduces novel capabilities such as proactive dialogue, real-time interruption handling, and context-aware commonsense reasoning during task execution. At its core, Robix leverages chain-of-thought reasoning and adopts a three-stage training strategy: (1) continued pretraining to enhance foundational embodied reasoning abilities including 3D spatial understanding, visual grounding, and task-centric reasoning; (2) supervised finetuning to model human-robot interaction and task planning as a unified reasoning-action sequence; and (3) reinforcement learning to improve reasoning-action consistency and long-horizon task coherence. Extensive experiments demonstrate that Robix outperforms both open-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in interactive task execution, demonstrating strong generalization across diverse instruction types (e.g., open-ended, multi-stage, constrained, invalid, and interrupted) and various user-involved tasks such as table bussing, grocery shopping, and dietary filtering.', 'score': 32, 'issue_id': 5707, 'pub_date': '2025-09-01', 'pub_date_card': {'ru': '1 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ', 'en': 'September 1', 'zh': '9æœˆ1æ—¥'}, 'hash': 'd0766d32afe23fec', 'authors': ['Huang Fang', 'Mengxi Zhang', 'Heng Dong', 'Wei Li', 'Zixuan Wang', 'Qifeng Zhang', 'Xueyun Tian', 'Yucheng Hu', 'Hang Li'], 'affiliations': ['bytedance.com'], 'pdf_title_img': 'assets/pdf/title_img/2509.01106.jpg', 'data': {'categories': ['#training', '#rl', '#reasoning', '#alignment', '#robotics', '#multimodal', '#agents', '#optimization'], 'emoji': 'ğŸ¤–', 'ru': {'title': 'Robix: Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸Ñ', 'desc': 'Robix - ÑÑ‚Ğ¾ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑÑÑ‰Ğ°Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°, Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ğ½Ğ° ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ Ğ² ĞµĞ´Ğ¸Ğ½Ğ¾Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºÑƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ñ‚Ñ€ĞµÑ…ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰ÑƒÑ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ, Ñ‚Ğ¾Ğ½ĞºÑƒÑ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Robix Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ĞºĞ°Ğº Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ, Ñ‚Ğ°Ğº Ğ¸ ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¸Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±Ğ»Ğ°Ğ´Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸, Ñ‚Ğ°ĞºĞ¸Ğ¼Ğ¸ ĞºĞ°Ğº Ğ¿Ñ€Ğ¾Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³, Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ´Ñ€Ğ°Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¼Ñ‹ÑĞ»Ğ°.'}, 'en': {'title': 'Robix: Revolutionizing Robot Interaction and Task Execution', 'desc': 'Robix is a unified vision-language model designed to enhance robot reasoning, task planning, and natural language interaction. It operates as a cognitive layer in robotic systems, generating commands and responses that allow robots to execute complex tasks and interact with humans effectively. The model employs chain-of-thought reasoning and a three-stage training strategy, which includes pretraining, supervised finetuning, and reinforcement learning to improve its performance. Experiments show that Robix significantly outperforms existing models in executing diverse interactive tasks, showcasing its ability to generalize across various instruction types.'}, 'zh': {'title': 'Robixï¼šæ™ºèƒ½æœºå™¨äººäº¤äº’çš„æ–°çºªå…ƒ', 'desc': 'Robixæ˜¯ä¸€ç§ç»Ÿä¸€çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œç»“åˆäº†æœºå™¨äººæ¨ç†ã€ä»»åŠ¡è§„åˆ’å’Œè‡ªç„¶è¯­è¨€äº¤äº’ã€‚å®ƒé€šè¿‡é“¾å¼æ€ç»´æ¨ç†å’Œä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œå±•ç¤ºäº†åœ¨äº¤äº’ä»»åŠ¡æ‰§è¡Œä¸­çš„ä¼˜è¶Šæ€§èƒ½ã€‚Robixèƒ½å¤ŸåŠ¨æ€ç”ŸæˆåŸå­å‘½ä»¤å’Œäººæœºäº¤äº’çš„è¯­è¨€å“åº”ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ‰§è¡Œå¤æ‚æŒ‡ä»¤å¹¶è¿›è¡Œè‡ªç„¶äº’åŠ¨ã€‚å®éªŒè¡¨æ˜ï¼ŒRobixåœ¨å¤šç§æŒ‡ä»¤ç±»å‹å’Œç”¨æˆ·å‚ä¸çš„ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºç°æœ‰çš„å¼€æºå’Œå•†ä¸šæ¨¡å‹ã€‚'}}}, {'id': 'https://huggingface.co/papers/2509.00375', 'title': 'Open Data Synthesis For Deep Research', 'url': 'https://huggingface.co/papers/2509.00375', 'abstract': 'InfoSeek is a scalable framework for generating complex Deep Research tasks by synthesizing hierarchical constraint satisfaction problems, enabling models to outperform larger baselines on challenging benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) are increasingly expected to go beyond simple factual queries toward Deep Research-tasks that require decomposing questions into sub-problems, coordinating multi-step reasoning, and synthesizing evidence from diverse sources. We formalize Deep Research tasks with verifiable answers as Hierarchical Constraint Satisfaction Problems (HCSPs), which are fundamentally different from single-constraint, multi-hop, or flat CSP formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA) fail to capture this complexity, while recent synthetic datasets often introduce shortcut reasoning, knowledge leakage, or lack sufficient structural depth. To address this gap, we introduce InfoSeek, a scalable framework for synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to recursively build a Research Tree from large-scale webpages, blurring intermediate nodes into valid sub-problems, and converting these trees into natural language questions that require traversing the full hierarchy. It also enables rapid scaling, yielding over 50K training examples, a curated test set, and reasoning trajectories generated via reject sampling. Experiments show that models trained on InfoSeek consistently outperform strong baselines. On a challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash), while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro). By preserving meta-information such as intermediate steps and retrieval labels, InfoSeek further supports advanced optimization strategies, including compound reward design and trajectory-level exploration. We provide our codes and datasets in https://github.com/VectorSpaceLab/InfoSeek{this repository}.', 'score': 30, 'issue_id': 5707, 'pub_date': '2025-08-30', 'pub_date_card': {'ru': '30 Ğ°Ğ²Ğ³ÑƒÑÑ‚Ğ°', 'en': 'August 30', 'zh': '8æœˆ30æ—¥'}, 'hash': 'd7d79c964b418fac', 'authors': ['Ziyi Xia', 'Kun Luo', 'Hongjin Qian', 'Zheng Liu'], 'affiliations': ['BAAI'], 'pdf_title_img': 'assets/pdf/title_img/2509.00375.jpg', 'data': {'categories': ['#training', '#dataset', '#synthetic', '#reasoning', '#benchmark', '#multimodal', '#optimization'], 'emoji': 'ğŸ”', 'ru': {'title': 'InfoSeek: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹', 'desc': 'InfoSeek - ÑÑ‚Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿ÑƒÑ‚ĞµĞ¼ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ ÑƒĞ´Ğ¾Ğ²Ğ»ĞµÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ²ÑƒÑ…Ğ°Ğ³ĞµĞ½Ñ‚Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ´ĞµÑ€ĞµĞ²Ğ° Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ²ĞµĞ±-ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†, Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒÑ ĞµĞ³Ğ¾ Ğ² Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ½Ğ° ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. ĞœĞ¾Ğ´ĞµĞ»Ğ¸, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° InfoSeek, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…. InfoSeek Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.'}, 'en': {'title': 'Unlocking Deep Research with Hierarchical Constraints', 'desc': 'InfoSeek is a novel framework designed to tackle complex Deep Research tasks by structuring them as Hierarchical Constraint Satisfaction Problems (HCSPs). This approach allows models to break down intricate questions into manageable sub-problems, facilitating multi-step reasoning and evidence synthesis from various sources. Unlike traditional benchmarks, InfoSeek generates a large dataset of over 50,000 training examples that reflect the complexity of real-world queries without shortcut reasoning. Experiments demonstrate that models trained with InfoSeek significantly outperform larger models on challenging benchmarks, showcasing its effectiveness in enhancing the capabilities of large language models.'}, 'zh': {'title': 'InfoSeekï¼šæ·±åº¦ç ”ç©¶ä»»åŠ¡çš„æ–°æ¡†æ¶', 'desc': 'InfoSeekæ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå¤æ‚çš„æ·±åº¦ç ”ç©¶ä»»åŠ¡ï¼Œé€šè¿‡åˆæˆå±‚æ¬¡çº¦æŸæ»¡è¶³é—®é¢˜ï¼Œä½¿æ¨¡å‹åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šæ›´å¤§çš„åŸºçº¿ã€‚è¯¥æ¡†æ¶ä½¿ç”¨åŒä»£ç†ç³»ç»Ÿï¼Œä»å¤§è§„æ¨¡ç½‘é¡µé€’å½’æ„å»ºç ”ç©¶æ ‘ï¼Œå°†ä¸­é—´èŠ‚ç‚¹æ¨¡ç³ŠåŒ–ä¸ºæœ‰æ•ˆçš„å­é—®é¢˜ï¼Œå¹¶å°†è¿™äº›æ ‘è½¬æ¢ä¸ºéœ€è¦éå†å®Œæ•´å±‚æ¬¡çš„è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚InfoSeekèƒ½å¤Ÿå¿«é€Ÿæ‰©å±•ï¼Œç”Ÿæˆè¶…è¿‡50,000ä¸ªè®­ç»ƒç¤ºä¾‹ï¼Œå¹¶æä¾›ç»è¿‡ç­–åˆ’çš„æµ‹è¯•é›†å’Œé€šè¿‡æ‹’ç»é‡‡æ ·ç”Ÿæˆçš„æ¨ç†è½¨è¿¹ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäºInfoSeekè®­ç»ƒçš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†è®¸å¤šå¤§å‹æ¨¡å‹å’Œå•†ä¸šAPIã€‚'}}}, {'id': 'https://huggingface.co/papers/2509.03405', 'title': 'LMEnt: A Suite for Analyzing Knowledge in Language Models from\n  Pretraining Data to Representations', 'url': 'https://huggingface.co/papers/2509.03405', 'abstract': 'LMEnt is a suite for analyzing knowledge acquisition in language models during pretraining, providing annotated corpora, retrieval methods, and pretrained models to study knowledge representations and learning dynamics.  \t\t\t\t\tAI-generated summary \t\t\t\t Language models (LMs) increasingly drive real-world applications that require world knowledge. However, the internal processes through which models turn data into representations of knowledge and beliefs about the world, are poorly understood. Insights into these processes could pave the way for developing LMs with knowledge representations that are more consistent, robust, and complete. To facilitate studying these questions, we present LMEnt, a suite for analyzing knowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a knowledge-rich pretraining corpus, fully annotated with entity mentions, based on Wikipedia, (2) an entity-based retrieval method over pretraining data that outperforms previous approaches by as much as 80.4%, and (3) 12 pretrained models with up to 1B parameters and 4K intermediate checkpoints, with comparable performance to popular open-sourced models on knowledge benchmarks. Together, these resources provide a controlled environment for analyzing connections between entity mentions in pretraining and downstream performance, and the effects of causal interventions in pretraining data. We show the utility of LMEnt by studying knowledge acquisition across checkpoints, finding that fact frequency is key, but does not fully explain learning trends. We release LMEnt to support studies of knowledge in LMs, including knowledge representations, plasticity, editing, attribution, and learning dynamics.', 'score': 14, 'issue_id': 5713, 'pub_date': '2025-09-03', 'pub_date_card': {'ru': '3 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ', 'en': 'September 3', 'zh': '9æœˆ3æ—¥'}, 'hash': 'c66ad503192a18e1', 'authors': ['Daniela Gottesman', 'Alon Gilae-Dotan', 'Ido Cohen', 'Yoav Gur-Arieh', 'Marius Mosbach', 'Ori Yoran', 'Mor Geva'], 'affiliations': ['McGill University', 'Mila Quebec AI Institute', 'Tel Aviv University'], 'pdf_title_img': 'assets/pdf/title_img/2509.03405.jpg', 'data': {'categories': ['#data', '#open_source', '#interpretability', '#dataset', '#training', '#benchmark', '#science', '#multimodal'], 'emoji': 'ğŸ§ ', 'ru': {'title': 'LMEnt: Ğ—Ğ°Ğ³Ğ»ÑĞ´Ñ‹Ğ²Ğ°Ñ Ğ²Ğ½ÑƒÑ‚Ñ€ÑŒ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹', 'desc': 'LMEnt - ÑÑ‚Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ÑƒÑĞ²Ğ¾ĞµĞ½Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ñ€Ğ¿ÑƒÑĞ°, Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. LMEnt Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ±Ğ¾Ğ³Ğ°Ñ‚Ñ‹Ğ¹ Ğ·Ğ½Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ ĞºĞ¾Ñ€Ğ¿ÑƒÑ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ’Ğ¸ĞºĞ¸Ğ¿ĞµĞ´Ğ¸Ğ¸, ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ ÑÑƒÑ‰Ğ½Ğ¾ÑÑ‚ÑĞ¼ Ğ¸ 12 Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ°Ğ¼Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸Ğ·ÑƒÑ‡Ğ°Ñ‚ÑŒ ÑĞ²ÑĞ·Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ ÑÑƒÑ‰Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹.'}, 'en': {'title': 'Unlocking Knowledge Acquisition in Language Models with LMEnt', 'desc': "LMEnt is a comprehensive toolkit designed to analyze how language models acquire knowledge during their pretraining phase. It includes a specially annotated corpus based on Wikipedia, an advanced retrieval method that significantly improves performance, and a set of pretrained models with substantial parameters. This suite allows researchers to explore the relationship between entity mentions in the training data and the models' performance on knowledge tasks. By providing insights into knowledge representations and learning dynamics, LMEnt aims to enhance the development of more reliable and complete language models."}, 'zh': {'title': 'LMEntï¼šæ­ç¤ºè¯­è¨€æ¨¡å‹çŸ¥è¯†è·å–çš„ç§˜å¯†', 'desc': 'LMEntæ˜¯ä¸€ä¸ªç”¨äºåˆ†æè¯­è¨€æ¨¡å‹åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­çŸ¥è¯†è·å–çš„å·¥å…·å¥—ä»¶ã€‚å®ƒæä¾›äº†å¸¦æ³¨é‡Šçš„è¯­æ–™åº“ã€æ£€ç´¢æ–¹æ³•å’Œé¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥ç ”ç©¶çŸ¥è¯†è¡¨ç¤ºå’Œå­¦ä¹ åŠ¨æ€ã€‚é€šè¿‡LMEntï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´å¥½åœ°ç†è§£è¯­è¨€æ¨¡å‹å¦‚ä½•å°†æ•°æ®è½¬åŒ–ä¸ºå¯¹ä¸–ç•Œçš„çŸ¥è¯†å’Œä¿¡å¿µã€‚è¯¥å·¥å…·çš„æ¨å‡ºæœ‰åŠ©äºå¼€å‘æ›´ä¸€è‡´ã€ç¨³å¥å’Œå®Œæ•´çš„çŸ¥è¯†è¡¨ç¤ºçš„è¯­è¨€æ¨¡å‹ã€‚'}}}, {'id': 'https://huggingface.co/papers/2509.01977', 'title': 'MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware\n  Alignment and Disentanglement', 'url': 'https://huggingface.co/papers/2509.01977', 'abstract': 'MOSAIC framework enhances multi-subject image generation by ensuring precise semantic alignment and orthogonal feature disentanglement, achieving high fidelity even with multiple references.  \t\t\t\t\tAI-generated summary \t\t\t\t Multi-subject personalized generation presents unique challenges in maintaining identity fidelity and semantic coherence when synthesizing images conditioned on multiple reference subjects. Existing methods often suffer from identity blending and attribute leakage due to inadequate modeling of how different subjects should interact within shared representation spaces. We present MOSAIC, a representation-centric framework that rethinks multi-subject generation through explicit semantic correspondence and orthogonal feature disentanglement. Our key insight is that multi-subject generation requires precise semantic alignment at the representation level - knowing exactly which regions in the generated image should attend to which parts of each reference. To enable this, we introduce SemAlign-MS, a meticulously annotated dataset providing fine-grained semantic correspondences between multiple reference subjects and target images, previously unavailable in this domain. Building on this foundation, we propose the semantic correspondence attention loss to enforce precise point-to-point semantic alignment, ensuring high consistency from each reference to its designated regions. Furthermore, we develop the multi-reference disentanglement loss to push different subjects into orthogonal attention subspaces, preventing feature interference while preserving individual identity characteristics. Extensive experiments demonstrate that MOSAIC achieves state-of-the-art performance on multiple benchmarks. Notably, while existing methods typically degrade beyond 3 subjects, MOSAIC maintains high fidelity with 4+ reference subjects, opening new possibilities for complex multi-subject synthesis applications.', 'score': 7, 'issue_id': 5711, 'pub_date': '2025-09-02', 'pub_date_card': {'ru': '2 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ', 'en': 'September 2', 'zh': '9æœˆ2æ—¥'}, 'hash': '5a1bf5cc33f3e20f', 'authors': ['Dong She', 'Siming Fu', 'Mushui Liu', 'Qiaoqiao Jin', 'Hualiang Wang', 'Mu Liu', 'Jidong Jiang'], 'affiliations': ['ByteDance', 'The Hong Kong University of Science and Technology', 'Zhejiang University'], 'pdf_title_img': 'assets/pdf/title_img/2509.01977.jpg', 'data': {'categories': ['#dataset', '#cv', '#synthetic', '#benchmark'], 'emoji': 'ğŸ§©', 'ru': {'title': 'Ğ¢Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ÑĞ¾ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²', 'desc': 'MOSAIC - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ñ€Ñ‚Ğ¾Ğ³Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ². ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ SemAlign-MS Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¼Ñƒ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ĞµĞ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ñ†ĞµĞ»ĞµĞ²Ñ‹Ğ¼Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸. MOSAIC Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ loss-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ². Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ°Ğ¶Ğµ Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ 4 Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹.'}, 'en': {'title': 'MOSAIC: Mastering Multi-Subject Image Generation with Precision', 'desc': "The MOSAIC framework improves the generation of images featuring multiple subjects by focusing on precise semantic alignment and separating features effectively. It addresses common issues like identity blending and attribute leakage that arise when synthesizing images from multiple references. By introducing a new dataset, SemAlign-MS, it provides detailed semantic correspondences, which helps in maintaining clarity in the generated images. The framework's innovative loss functions ensure that different subjects are represented distinctly, allowing for high-quality image generation even with more than three subjects."}, 'zh': {'title': 'MOSAICï¼šå¤šä¸»ä½“å›¾åƒç”Ÿæˆçš„æ–°çªç ´', 'desc': 'MOSAICæ¡†æ¶é€šè¿‡ç¡®ä¿ç²¾ç¡®çš„è¯­ä¹‰å¯¹é½å’Œæ­£äº¤ç‰¹å¾è§£è€¦ï¼Œå¢å¼ºäº†å¤šä¸»ä½“å›¾åƒç”Ÿæˆçš„èƒ½åŠ›ã€‚è¯¥æ–¹æ³•è§£å†³äº†åœ¨å¤šä¸ªå‚è€ƒä¸»ä½“æ¡ä»¶ä¸‹åˆæˆå›¾åƒæ—¶èº«ä»½ä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§çš„é—®é¢˜ã€‚MOSAICå¼•å…¥äº†SemAlign-MSæ•°æ®é›†ï¼Œæä¾›äº†å¤šå‚è€ƒä¸»ä½“ä¸ç›®æ ‡å›¾åƒä¹‹é—´çš„ç»†ç²’åº¦è¯­ä¹‰å¯¹åº”å…³ç³»ã€‚é€šè¿‡è¯­ä¹‰å¯¹åº”æ³¨æ„åŠ›æŸå¤±å’Œå¤šå‚è€ƒè§£è€¦æŸå¤±ï¼ŒMOSAICåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œèƒ½å¤Ÿåœ¨4ä¸ªä»¥ä¸Šçš„å‚è€ƒä¸»ä½“ä¸‹ä¿æŒé«˜ä¿çœŸåº¦ã€‚'}}}, {'id': 'https://huggingface.co/papers/2509.00428', 'title': 'Mixture of Global and Local Experts with Diffusion Transformer for\n  Controllable Face Generation', 'url': 'https://huggingface.co/papers/2509.00428', 'abstract': 'Face-MoGLE, a novel framework using Diffusion Transformers, achieves high-quality, controllable face generation through semantic-decoupled latent modeling, expert specialization, and dynamic gating.  \t\t\t\t\tAI-generated summary \t\t\t\t Controllable face generation poses critical challenges in generative modeling due to the intricate balance required between semantic controllability and photorealism. While existing approaches struggle with disentangling semantic controls from generation pipelines, we revisit the architectural potential of Diffusion Transformers (DiTs) through the lens of expert specialization. This paper introduces Face-MoGLE, a novel framework featuring: (1) Semantic-decoupled latent modeling through mask-conditioned space factorization, enabling precise attribute manipulation; (2) A mixture of global and local experts that captures holistic structure and region-level semantics for fine-grained controllability; (3) A dynamic gating network producing time-dependent coefficients that evolve with diffusion steps and spatial locations. Face-MoGLE provides a powerful and flexible solution for high-quality, controllable face generation, with strong potential in generative modeling and security applications. Extensive experiments demonstrate its effectiveness in multimodal and monomodal face generation settings and its robust zero-shot generalization capability. Project page is available at https://github.com/XavierJiezou/Face-MoGLE.', 'score': 7, 'issue_id': 5711, 'pub_date': '2025-08-30', 'pub_date_card': {'ru': '30 Ğ°Ğ²Ğ³ÑƒÑÑ‚Ğ°', 'en': 'August 30', 'zh': '8æœˆ30æ—¥'}, 'hash': '5f17d4af79b3fc6f', 'authors': ['Xuechao Zou', 'Shun Zhang', 'Xing Fu', 'Yue Li', 'Kai Li', 'Yushe Cao', 'Congyan Lang', 'Pin Tao', 'Junliang Xing'], 'affiliations': ['Ant Group', 'Beijing Jiaotong University', 'Qinghai University', 'Tsinghua University'], 'pdf_title_img': 'assets/pdf/title_img/2509.00428.jpg', 'data': {'categories': ['#cv', '#diffusion', '#multimodal', '#architecture', '#security'], 'emoji': 'ğŸ­', 'ru': {'title': 'Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ½Ğ°Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ»Ğ¸Ñ† Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²', 'desc': 'Face-MoGLE - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ»Ğ¸Ñ†, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ñ‹. ĞĞ½Ğ° Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½ÑƒÑ Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ° ÑÑ‡ĞµÑ‚ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ². Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ¼ĞµÑÑŒ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ° Ñ†ĞµĞ»Ğ¾ÑÑ‚Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸ĞºĞ¸ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ĞµĞ¹ Ğ»Ğ¸Ñ†Ğ°. Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞµÑ‚ÑŒ Ğ³ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹, Ğ·Ğ°Ğ²Ğ¸ÑÑÑ‰Ğ¸Ğµ Ğ¾Ñ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸.'}, 'en': {'title': 'Face-MoGLE: Mastering Controllable Face Generation with Diffusion Transformers', 'desc': "Face-MoGLE is a new framework that uses Diffusion Transformers to generate high-quality and controllable faces. It addresses the challenge of balancing semantic control with photorealism by employing semantic-decoupled latent modeling, which allows for precise manipulation of facial attributes. The framework incorporates a mixture of global and local experts to enhance both overall structure and detailed features, ensuring fine-grained control over the generated images. Additionally, a dynamic gating network adapts coefficients during the generation process, improving the model's flexibility and effectiveness in various face generation tasks."}, 'zh': {'title': 'Face-MoGLEï¼šé«˜è´¨é‡å¯æ§é¢éƒ¨ç”Ÿæˆçš„æ–°æ¡†æ¶', 'desc': 'Face-MoGLEæ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œåˆ©ç”¨æ‰©æ•£å˜æ¢å™¨å®ç°é«˜è´¨é‡ã€å¯æ§çš„é¢éƒ¨ç”Ÿæˆã€‚è¯¥æ¡†æ¶é€šè¿‡è¯­ä¹‰è§£è€¦çš„æ½œåœ¨å»ºæ¨¡ã€ä¸“å®¶ä¸“é—¨åŒ–å’ŒåŠ¨æ€é—¨æ§æ¥è§£å†³ç”Ÿæˆå»ºæ¨¡ä¸­çš„æŒ‘æˆ˜ã€‚å®ƒå…è®¸ç²¾ç¡®çš„å±æ€§æ“æ§ï¼Œå¹¶ç»“åˆå…¨å±€å’Œå±€éƒ¨ä¸“å®¶ä»¥æ•æ‰æ•´ä½“ç»“æ„å’ŒåŒºåŸŸè¯­ä¹‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFace-MoGLEåœ¨å¤šæ¨¡æ€å’Œå•æ¨¡æ€é¢éƒ¨ç”Ÿæˆä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶å…·å¤‡å¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚'}}}, {'id': 'https://huggingface.co/papers/2509.02722', 'title': 'Planning with Reasoning using Vision Language World Model', 'url': 'https://huggingface.co/papers/2509.02722', 'abstract': 'The Vision Language World Model (VLWM) achieves state-of-the-art performance in visual planning by integrating language-based world modeling, action policy learning, and dynamics modeling with semantic and temporal abstraction.  \t\t\t\t\tAI-generated summary \t\t\t\t Effective planning requires strong world models, but high-level world models that can understand and reason about actions with semantic and temporal abstraction remain largely underdeveloped. We introduce the Vision Language World Model (VLWM), a foundation model trained for language-based world modeling on natural videos. Given visual observations, the VLWM first infers the overall goal achievements then predicts a trajectory composed of interleaved actions and world state changes. Those targets are extracted by iterative LLM Self-Refine conditioned on compressed future observations represented by Tree of Captions. The VLWM learns both an action policy and a dynamics model, which respectively facilitates reactive system-1 plan decoding and reflective system-2 planning via cost minimization. The cost evaluates the semantic distance between the hypothetical future states given by VLWM roll-outs and the expected goal state, and is measured by a critic model that we trained in a self-supervised manner. The VLWM achieves state-of-the-art Visual Planning for Assistance (VPA) performance on both benchmark evaluations and our proposed PlannerArena human evaluations, where system-2 improves the Elo score by +27% upon system-1. The VLWM models also outperforms strong VLM baselines on RoboVQA and WorldPrediction benchmark.', 'score': 6, 'issue_id': 5718, 'pub_date': '2025-09-02', 'pub_date_card': {'ru': '2 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ', 'en': 'September 2', 'zh': '9æœˆ2æ—¥'}, 'hash': '9d66073795d0c729', 'authors': ['Delong Chen', 'Theo Moutakanni', 'Willy Chung', 'Yejin Bang', 'Ziwei Ji', 'Allen Bolourchi', 'Pascale Fung'], 'affiliations': ['ISIR Sorbonne UniversitÃ©', 'Meta FAIR', 'University of Southern California'], 'pdf_title_img': 'assets/pdf/title_img/2509.02722.jpg', 'data': {'categories': ['#agents', '#rl', '#benchmark', '#cv', '#optimization', '#multimodal', '#reasoning'], 'emoji': 'ğŸ§ ', 'ru': {'title': 'VLWM: Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ', 'desc': 'VLWM (Vision Language World Model) - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑÑÑ‰Ğ°Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¸Ñ€Ğ°, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸ Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ†Ğ¸ĞµĞ¹. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑĞ°Ğ¼Ğ¾ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¾Ğ±ÑƒÑĞ»Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğµ ÑĞ¶Ğ°Ñ‚Ñ‹Ğ¼Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸, Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ´ĞµÑ€ĞµĞ²Ğ° Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞµĞ¹. VLWM Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ ĞºĞ°Ğº Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºÑƒ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹, Ñ‚Ğ°Ğº Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸, Ñ‡Ñ‚Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²ÑƒĞµÑ‚ Ñ€ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ»Ğ°Ğ½Ğ° Ğ¸ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ (VPA) ĞºĞ°Ğº Ğ½Ğ° ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ†ĞµĞ½ĞºĞ°Ñ…, Ñ‚Ğ°Ğº Ğ¸ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ñ†ĞµĞ½ĞºĞ°Ñ… PlannerArena.'}, 'en': {'title': 'Revolutionizing Visual Planning with Language Understanding', 'desc': 'The Vision Language World Model (VLWM) is a cutting-edge model that enhances visual planning by combining language understanding with world modeling. It learns to predict actions and changes in the world by analyzing natural videos, allowing it to infer goals and plan trajectories effectively. The model employs a two-system approach, where system-1 focuses on quick, reactive planning and system-2 engages in deeper, reflective planning to minimize costs based on expected outcomes. VLWM demonstrates superior performance in visual planning tasks, outperforming existing models in various benchmarks and evaluations.'}, 'zh': {'title': 'è§†è§‰è¯­è¨€ä¸–ç•Œæ¨¡å‹ï¼šæ™ºèƒ½è§„åˆ’çš„æ–°çªç ´', 'desc': 'è§†è§‰è¯­è¨€ä¸–ç•Œæ¨¡å‹ï¼ˆVLWMï¼‰é€šè¿‡ç»“åˆåŸºäºè¯­è¨€çš„ä¸–ç•Œå»ºæ¨¡ã€è¡ŒåŠ¨ç­–ç•¥å­¦ä¹ å’ŒåŠ¨æ€å»ºæ¨¡ï¼Œè¾¾åˆ°äº†è§†è§‰è§„åˆ’çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿç†è§£å’Œæ¨ç†å…·æœ‰è¯­ä¹‰å’Œæ—¶é—´æŠ½è±¡çš„é«˜å±‚æ¬¡ä¸–ç•Œæ¨¡å‹ï¼Œå¡«è¡¥äº†è¿™ä¸€é¢†åŸŸçš„ç©ºç™½ã€‚VLWMé¦–å…ˆæ ¹æ®è§†è§‰è§‚å¯Ÿæ¨æ–­æ•´ä½“ç›®æ ‡ï¼Œç„¶åé¢„æµ‹ç”±äº¤é”™çš„è¡ŒåŠ¨å’Œä¸–ç•ŒçŠ¶æ€å˜åŒ–ç»„æˆçš„è½¨è¿¹ã€‚é€šè¿‡è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼è®­ç»ƒçš„è¯„è®ºæ¨¡å‹è¯„ä¼°å‡è®¾æœªæ¥çŠ¶æ€ä¸æœŸæœ›ç›®æ ‡çŠ¶æ€ä¹‹é—´çš„è¯­ä¹‰è·ç¦»ï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„è§„åˆ’ã€‚'}}}, {'id': 'https://huggingface.co/papers/2509.00930', 'title': 'SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement\n  Fine-Tuning of LLMs', 'url': 'https://huggingface.co/papers/2509.00930', 'abstract': "SATQuest evaluates and enhances LLM logical reasoning by generating diverse SAT-based problems, offering insights into reasoning performance and enabling effective fine-tuning.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Large Language Models (LLMs) have demonstrated remarkable general reasoning capabilities. However, systematically evaluating and enhancing these reasoning capabilities is challenging due to the lack of controllable and scalable tools for fine-grained analysis. Existing benchmarks and datasets often lack the necessary variable control for multi-dimensional, systematic analysis and training, or have narrow problem types and formats. To address these limitations, we introduce SATQuest, a systematic verifier designed to evaluate and enhance logical reasoning in LLMs by generating diverse, Satisfiability-based logical reasoning problems directly from Conjunctive Normal Form (CNF) instances. SATQuest structures these problems along three orthogonal dimensions: instance scale, problem type, and question format, employing randomized, SAT-based problem generation and objective answer verification via PySAT. This design mitigates memorization issues, allows for nuanced insights into reasoning performance, and enables effective reinforcement fine-tuning. Our extensive evaluation of various LLMs using SATQuest identified significant limitations in their logical reasoning, particularly in generalizing beyond familiar mathematical formats. Furthermore, we show that reinforcement fine-tuning with SATQuest rewards substantially improves targeted task performance and generalizes to more complex instances, while highlighting remaining challenges in cross-format adaptation. Through these demonstrations, we showcase SATQuest's potential as a foundational tool and a valuable starting point for advancing LLM logical reasoning.", 'score': 1, 'issue_id': 5722, 'pub_date': '2025-08-31', 'pub_date_card': {'ru': '31 Ğ°Ğ²Ğ³ÑƒÑÑ‚Ğ°', 'en': 'August 31', 'zh': '8æœˆ31æ—¥'}, 'hash': '5bfb23a8accfba06', 'authors': ['Yanxiao Zhao', 'Yaqian Li', 'Zihao Bo', 'Rinyoichi Takezoe', 'Haojia Hui', 'Mo Guang', 'Lei Ren', 'Xiaolin Qin', 'Kaiwen Long'], 'affiliations': ['Chengdu Institute of Computer Applications, Chinese Academy of Sciences', 'Li Auto', 'School of Computer Science and Technology, University of Chinese Academy of Sciences'], 'pdf_title_img': 'assets/pdf/title_img/2509.00930.jpg', 'data': {'categories': ['#rl', '#reasoning', '#benchmark', '#training', '#dataset'], 'emoji': 'ğŸ§ ', 'ru': {'title': 'SATQuest: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°', 'desc': 'SATQuest - ÑÑ‚Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ½ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ±ÑƒĞ»ĞµĞ²Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ» (SAT). SATQuest ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾ Ñ‚Ñ€ĞµĞ¼ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸ÑĞ¼: Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±, Ñ‚Ğ¸Ğ¿ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ LLM Ğ² Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğ¸, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ğ¼Ğ¸ Ğ·Ğ½Ğ°ĞºĞ¾Ğ¼Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ².'}, 'en': {'title': 'Enhancing LLM Reasoning with SATQuest', 'desc': 'SATQuest is a tool designed to evaluate and improve the logical reasoning abilities of Large Language Models (LLMs) by generating a variety of SAT-based problems. It addresses the limitations of existing benchmarks by providing a systematic approach that allows for fine-grained analysis across different dimensions such as problem type and question format. By using randomized problem generation and objective verification methods, SATQuest helps to reduce memorization issues and offers deeper insights into the reasoning capabilities of LLMs. The results show that reinforcement fine-tuning with SATQuest significantly enhances performance on specific tasks and aids in generalizing to more complex reasoning scenarios.'}, 'zh': {'title': 'SATQuestï¼šæå‡LLMé€»è¾‘æ¨ç†çš„åˆ©å™¨', 'desc': 'SATQuest æ˜¯ä¸€ä¸ªç³»ç»ŸåŒ–çš„éªŒè¯å·¥å…·ï¼Œæ—¨åœ¨è¯„ä¼°å’Œå¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚å®ƒé€šè¿‡ç”Ÿæˆå¤šæ ·åŒ–çš„åŸºäºå¯æ»¡è¶³æ€§ï¼ˆSATï¼‰çš„é€»è¾‘æ¨ç†é—®é¢˜ï¼Œæ¥æä¾›å¯¹æ¨ç†æ€§èƒ½çš„æ·±å…¥è§è§£ã€‚SATQuest è®¾è®¡äº†ä¸‰ç§æ­£äº¤ç»´åº¦çš„é—®é¢˜ç»“æ„ï¼šå®ä¾‹è§„æ¨¡ã€é—®é¢˜ç±»å‹å’Œé—®é¢˜æ ¼å¼ï¼Œåˆ©ç”¨éšæœºåŒ–çš„ SAT é—®é¢˜ç”Ÿæˆå’Œå®¢è§‚ç­”æ¡ˆéªŒè¯ã€‚é€šè¿‡å¯¹ LLM çš„å¹¿æ³›è¯„ä¼°ï¼ŒSATQuest æ˜¾ç¤ºäº†è¿™äº›æ¨¡å‹åœ¨é€»è¾‘æ¨ç†æ–¹é¢çš„æ˜¾è‘—å±€é™æ€§ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å¾®è°ƒæ˜¾è‘—æé«˜äº†ç‰¹å®šä»»åŠ¡çš„è¡¨ç°ã€‚'}}}, {'id': 'https://huggingface.co/papers/2509.02530', 'title': 'Manipulation as in Simulation: Enabling Accurate Geometry Perception in\n  Robots', 'url': 'https://huggingface.co/papers/2509.02530', 'abstract': "Camera Depth Models (CDMs) enhance depth camera accuracy by denoising and improving metric depth prediction, enabling better generalization of robotic manipulation policies from simulation to real-world tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Modern robotic manipulation primarily relies on visual observations in a 2D color space for skill learning but suffers from poor generalization. In contrast, humans, living in a 3D world, depend more on physical properties-such as distance, size, and shape-than on texture when interacting with objects. Since such 3D geometric information can be acquired from widely available depth cameras, it appears feasible to endow robots with similar perceptual capabilities. Our pilot study found that using depth cameras for manipulation is challenging, primarily due to their limited accuracy and susceptibility to various types of noise. In this work, we propose Camera Depth Models (CDMs) as a simple plugin on daily-use depth cameras, which take RGB images and raw depth signals as input and output denoised, accurate metric depth. To achieve this, we develop a neural data engine that generates high-quality paired data from simulation by modeling a depth camera's noise pattern. Our results show that CDMs achieve nearly simulation-level accuracy in depth prediction, effectively bridging the sim-to-real gap for manipulation tasks. Notably, our experiments demonstrate, for the first time, that a policy trained on raw simulated depth, without the need for adding noise or real-world fine-tuning, generalizes seamlessly to real-world robots on two challenging long-horizon tasks involving articulated, reflective, and slender objects, with little to no performance degradation. We hope our findings will inspire future research in utilizing simulation data and 3D information in general robot policies.", 'score': 0, 'issue_id': 5724, 'pub_date': '2025-09-02', 'pub_date_card': {'ru': '2 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ', 'en': 'September 2', 'zh': '9æœˆ2æ—¥'}, 'hash': 'e632241ad7e3078d', 'authors': ['Minghuan Liu', 'Zhengbang Zhu', 'Xiaoshen Han', 'Peng Hu', 'Haotong Lin', 'Xinyao Li', 'Jingxiao Chen', 'Jiafeng Xu', 'Yichu Yang', 'Yunfeng Lin', 'Xinghang Li', 'Yong Yu', 'Weinan Zhang', 'Tao Kong', 'Bingyi Kang'], 'affiliations': ['ByteDance Seed', 'Shanghai Jiao Tong University', 'Tsinghua University', 'Zhejiang University'], 'pdf_title_img': 'assets/pdf/title_img/2509.02530.jpg', 'data': {'categories': ['#optimization', '#3d', '#transfer_learning', '#robotics'], 'emoji': 'ğŸ¤–', 'ru': {'title': 'Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ğµ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸: Ğ¾Ñ‚ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğº Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸', 'desc': 'Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Camera Depth Models (CDM) Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ğ¼ĞµÑ€ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ² Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞµ. CDM Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ RGB-Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹, Ğ²Ñ‹Ğ´Ğ°Ğ²Ğ°Ñ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚ ÑˆÑƒĞ¼Ğ° Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğµ. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ÑÑ Ğ½Ğ° ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… ÑˆÑƒĞ¼Ñ‹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ°Ğ¼ĞµÑ€. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° ÑĞ¸Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ CDM, ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑÑÑ‚ÑÑ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸.'}, 'en': {'title': 'Bridging the Sim-to-Real Gap with Camera Depth Models', 'desc': 'Camera Depth Models (CDMs) improve the accuracy of depth cameras by reducing noise and enhancing metric depth predictions. This allows robots to better generalize their manipulation skills from simulated environments to real-world scenarios. By using a neural data engine, CDMs generate high-quality training data that mimics the noise patterns of depth cameras, achieving near-simulation accuracy in depth perception. The study demonstrates that policies trained on simulated depth data can effectively transfer to real-world tasks without additional fine-tuning, marking a significant advancement in robotic manipulation.'}, 'zh': {'title': 'æå‡æ·±åº¦ç›¸æœºå‡†ç¡®æ€§çš„ç›¸æœºæ·±åº¦æ¨¡å‹', 'desc': 'æœ¬æ–‡æå‡ºäº†ç›¸æœºæ·±åº¦æ¨¡å‹ï¼ˆCDMsï¼‰ï¼Œæ—¨åœ¨æé«˜æ·±åº¦ç›¸æœºçš„å‡†ç¡®æ€§ï¼Œé€šè¿‡å»å™ªå’Œæ”¹è¿›åº¦é‡æ·±åº¦é¢„æµ‹ï¼Œå¸®åŠ©æœºå™¨äººä»æ¨¡æ‹Ÿç¯å¢ƒæ›´å¥½åœ°è¿ç§»åˆ°ç°å®ä»»åŠ¡ä¸­ã€‚ç°ä»£æœºå™¨äººæ“ä½œä¸»è¦ä¾èµ–äºäºŒç»´é¢œè‰²ç©ºé—´çš„è§†è§‰è§‚å¯Ÿï¼Œä½†åœ¨æŠ€èƒ½å­¦ä¹ ä¸­é¢ä¸´æ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ã€‚CDMsä½œä¸ºä¸€ç§ç®€å•çš„æ’ä»¶ï¼Œèƒ½å¤Ÿå°†RGBå›¾åƒå’ŒåŸå§‹æ·±åº¦ä¿¡å·ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºå»å™ªåçš„å‡†ç¡®æ·±åº¦ä¿¡æ¯ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒCDMsåœ¨æ·±åº¦é¢„æµ‹ä¸­è¾¾åˆ°äº†æ¥è¿‘æ¨¡æ‹Ÿçº§åˆ«çš„å‡†ç¡®æ€§ï¼ŒæˆåŠŸç¼©å°äº†æ¨¡æ‹Ÿä¸ç°å®ä¹‹é—´çš„å·®è·ã€‚'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (1)', '#agents (2)', '#agi', '#alignment (1)', '#architecture (1)', '#audio', '#benchmark (5)', '#cv (3)', '#data (1)', '#dataset (4)', '#diffusion (1)', '#ethics', '#games', '#graphs', '#hallucinations', '#healthcare', '#inference', '#interpretability (1)', '#leakage', '#long_context', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal (5)', '#open_source (1)', '#optimization (4)', '#plp', '#rag', '#reasoning (4)', '#rl (3)', '#rlhf', '#robotics (2)', '#science (1)', '#security (1)', '#small_models', '#story_generation', '#survey', '#synthetic (2)', '#training (4)', '#transfer_learning (1)', '#video'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            ğŸ”º ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = 'ğŸ”„ ' + getTimeDiff('2025-09-04 20:12',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ",
                    pub_date: "Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸",
                    issue_id: "Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "è¯„åˆ†",
                    pub_date: "å‘å¸ƒæ—¥æœŸ",
                    issue_id: "HFä¸Šä¼ æ—¥æœŸ"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-09-04 20:12')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-09-04 20:12')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    