
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 9 papers. March 20.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">20 марта</span> | <span id="title-articles-count">9 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-03-19.html">⬅️ <span id="prev-date">19.03</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-03-21.html">➡️ <span id="next-date">21.03</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-03.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '20 марта', 'en': 'March 20', 'zh': '3月20日'};
        let feedDateNext = {'ru': '21.03', 'en': '03/21', 'zh': '3月21日'};
        let feedDatePrev = {'ru': '19.03', 'en': '03/19', 'zh': '3月19日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2503.15475', 'title': 'Cube: A Roblox View of 3D Intelligence', 'url': 'https://huggingface.co/papers/2503.15475', 'abstract': 'Foundation models trained on vast amounts of data have demonstrated remarkable reasoning and generation capabilities in the domains of text, images, audio and video. Our goal at Roblox is to build such a foundation model for 3D intelligence, a model that can support developers in producing all aspects of a Roblox experience, from generating 3D objects and scenes to rigging characters for animation to producing programmatic scripts describing object behaviors. We discuss three key design requirements for such a 3D foundation model and then present our first step towards building such a model. We expect that 3D geometric shapes will be a core data type and describe our solution for 3D shape tokenizer. We show how our tokenization scheme can be used in applications for text-to-shape generation, shape-to-text generation and text-to-scene generation. We demonstrate how these applications can collaborate with existing large language models (LLMs) to perform scene analysis and reasoning. We conclude with a discussion outlining our path to building a fully unified foundation model for 3D intelligence.', 'score': 12, 'issue_id': 2800, 'pub_date': '2025-03-19', 'pub_date_card': {'ru': '19 марта', 'en': 'March 19', 'zh': '3月19日'}, 'hash': '89037dc780448ff8', 'authors': ['Foundation AI Team', 'Kiran Bhat', 'Nishchaie Khanna', 'Karun Channa', 'Tinghui Zhou', 'Yiheng Zhu', 'Xiaoxia Sun', 'Charles Shang', 'Anirudh Sudarshan', 'Maurice Chu', 'Daiqing Li', 'Kangle Deng', 'Jean-Philippe Fauconnier', 'Tijmen Verhulsdonck', 'Maneesh Agrawala', 'Kayvon Fatahalian', 'Alexander Weiss', 'Christian Reiser', 'Ravi Kiran Chirravuri', 'Ravali Kandur', 'Alejandro Pelaez', 'Akash Garg', 'Michael Palleschi', 'Jessica Wang', 'Skylar Litz', 'Leon Liu', 'Anying Li', 'David Harmon', 'Derek Liu', 'Liangjun Feng', 'Denis Goupil', 'Lukas Kuczynski', 'Jihyun Yoon', 'Naveen Marri', 'Peiye Zhuang', 'Yinan Zhang', 'Brian Yin', 'Haomiao Jiang', 'Marcel van Workum', 'Thomas Lane', 'Bryce Erickson', 'Salil Pathare', 'Kyle Price', 'Anupam Singh', 'David Baszucki'], 'affiliations': ['Foundation AI team, Roblox', 'Roblox'], 'pdf_title_img': 'assets/pdf/title_img/2503.15475.jpg', 'data': {'categories': ['#games', '#multimodal', '#3d', '#reasoning'], 'emoji': '🧊', 'ru': {'title': '3D-интеллект: фундаментальная модель для виртуальных миров', 'desc': 'Статья описывает разработку фундаментальной модели для 3D-интеллекта в Roblox. Модель призвана помочь разработчикам в создании всех аспектов игрового опыта, включая генерацию 3D-объектов, анимацию персонажей и программные скрипты. Авторы представляют решение для токенизации 3D-форм и демонстрируют его применение в генерации форм из текста, текста из форм и сцен из текста. Также обсуждается интеграция с существующими языковыми моделями для анализа и рассуждений о сценах.'}, 'en': {'title': 'Building the Future of 3D Intelligence in Roblox', 'desc': 'This paper presents a vision for creating a foundation model specifically designed for 3D intelligence, which can assist developers in various aspects of creating Roblox experiences. The authors emphasize the importance of 3D geometric shapes as a fundamental data type and introduce a novel 3D shape tokenizer to facilitate this process. They explore applications such as text-to-shape and shape-to-text generation, demonstrating how these can work alongside large language models for enhanced scene analysis and reasoning. The paper outlines the initial steps taken towards building a comprehensive model that integrates these capabilities into a unified framework for 3D content creation.'}, 'zh': {'title': '构建3D智能的基础模型', 'desc': '本论文探讨了如何为3D智能构建基础模型，该模型能够支持开发者在Roblox平台上生成3D对象、场景和动画角色。我们提出了三个关键设计要求，并介绍了构建3D形状标记器的初步步骤。我们的标记化方案可以应用于文本到形状生成、形状到文本生成和文本到场景生成等任务。最后，我们讨论了如何与现有的大型语言模型协作，以实现场景分析和推理。'}}}, {'id': 'https://huggingface.co/papers/2503.15485', 'title': 'TULIP: Towards Unified Language-Image Pretraining', 'url': 'https://huggingface.co/papers/2503.15485', 'abstract': 'Despite the recent success of image-text contrastive models like CLIP and SigLIP, these models often struggle with vision-centric tasks that demand high-fidelity image understanding, such as counting, depth estimation, and fine-grained object recognition. These models, by performing language alignment, tend to prioritize high-level semantics over visual understanding, weakening their image understanding. On the other hand, vision-focused models are great at processing visual information but struggle to understand language, limiting their flexibility for language-driven tasks. In this work, we introduce TULIP, an open-source, drop-in replacement for existing CLIP-like models. Our method leverages generative data augmentation, enhanced image-image and text-text contrastive learning, and image/text reconstruction regularization to learn fine-grained visual features while preserving global semantic alignment. Our approach, scaling to over 1B parameters, outperforms existing state-of-the-art (SOTA) models across multiple benchmarks, establishing a new SOTA zero-shot performance on ImageNet-1K, delivering up to a 2times enhancement over SigLIP on RxRx1 in linear probing for few-shot classification, and improving vision-language models, achieving over 3times higher scores than SigLIP on MMVP. Our code/checkpoints are available at https://tulip-berkeley.github.io', 'score': 11, 'issue_id': 2800, 'pub_date': '2025-03-19', 'pub_date_card': {'ru': '19 марта', 'en': 'March 19', 'zh': '3月19日'}, 'hash': 'd4b870742a020d5a', 'authors': ['Zineng Tang', 'Long Lian', 'Seun Eisape', 'XuDong Wang', 'Roei Herzig', 'Adam Yala', 'Alane Suhr', 'Trevor Darrell', 'David M. Chan'], 'affiliations': ['University of California, Berkeley'], 'pdf_title_img': 'assets/pdf/title_img/2503.15485.jpg', 'data': {'categories': ['#optimization', '#multimodal', '#benchmark', '#architecture', '#open_source', '#cv'], 'emoji': '🌷', 'ru': {'title': 'TULIP: Баланс между детальным зрением и языковым пониманием', 'desc': 'Статья представляет TULIP - новую модель для задач компьютерного зрения и обработки естественного языка. TULIP улучшает понимание визуальных деталей изображений, сохраняя при этом способность к семантическому сопоставлению с текстом. Модель использует генеративное расширение данных, улучшенное контрастивное обучение и регуляризацию реконструкции для достижения баланса между визуальным и языковым пониманием. TULIP превосходит существующие модели на нескольких бенчмарках, устанавливая новый state-of-the-art в задачах zero-shot классификации и few-shot обучения.'}, 'en': {'title': 'TULIP: Bridging Vision and Language for Enhanced Image Understanding', 'desc': 'This paper presents TULIP, a new model designed to improve image understanding in tasks like counting and depth estimation, which are challenging for existing image-text contrastive models. TULIP enhances visual feature learning by using generative data augmentation and advanced contrastive learning techniques, while still maintaining a connection to high-level semantics. It scales effectively to over 1 billion parameters and demonstrates superior performance on various benchmarks, setting new records in zero-shot classification and few-shot tasks. The model aims to bridge the gap between vision-centric and language-centric approaches, providing a more flexible solution for vision-language tasks.'}, 'zh': {'title': 'TULIP：提升图像理解的新方法', 'desc': '尽管像CLIP和SigLIP这样的图像-文本对比模型取得了成功，但它们在需要高保真图像理解的视觉任务中表现不佳。本文提出了TULIP，这是一种开源的替代方案，旨在通过生成数据增强和对比学习来提高图像理解能力。TULIP能够学习细粒度的视觉特征，同时保持全局语义的一致性。我们的实验表明，TULIP在多个基准测试中超越了现有的最先进模型，显著提升了零-shot性能和少-shot分类的效果。'}}}, {'id': 'https://huggingface.co/papers/2503.15417', 'title': 'Temporal Regularization Makes Your Video Generator Stronger', 'url': 'https://huggingface.co/papers/2503.15417', 'abstract': 'Temporal quality is a critical aspect of video generation, as it ensures consistent motion and realistic dynamics across frames. However, achieving high temporal coherence and diversity remains challenging. In this work, we explore temporal augmentation in video generation for the first time, and introduce FluxFlow for initial investigation, a strategy designed to enhance temporal quality. Operating at the data level, FluxFlow applies controlled temporal perturbations without requiring architectural modifications. Extensive experiments on UCF-101 and VBench benchmarks demonstrate that FluxFlow significantly improves temporal coherence and diversity across various video generation models, including U-Net, DiT, and AR-based architectures, while preserving spatial fidelity. These findings highlight the potential of temporal augmentation as a simple yet effective approach to advancing video generation quality.', 'score': 11, 'issue_id': 2801, 'pub_date': '2025-03-19', 'pub_date_card': {'ru': '19 марта', 'en': 'March 19', 'zh': '3月19日'}, 'hash': '8eb262eda880d162', 'authors': ['Harold Haodong Chen', 'Haojian Huang', 'Xianfeng Wu', 'Yexin Liu', 'Yajing Bai', 'Wen-Jie Shu', 'Harry Yang', 'Ser-Nam Lim'], 'affiliations': ['Everlyn AI', 'HKU', 'HKUST', 'UCF'], 'pdf_title_img': 'assets/pdf/title_img/2503.15417.jpg', 'data': {'categories': ['#benchmark', '#video'], 'emoji': '🎬', 'ru': {'title': 'FluxFlow: Улучшение временного качества видео с помощью аугментации', 'desc': 'В статье рассматривается проблема улучшения временного качества при генерации видео с помощью нейронных сетей. Авторы предлагают новый метод под названием FluxFlow, который применяет контролируемые временные возмущения на уровне данных. Эксперименты показывают, что FluxFlow значительно улучшает временную согласованность и разнообразие для различных архитектур генеративных моделей видео. Метод не требует изменений в архитектуре моделей и может быть легко интегрирован в существующие подходы.'}, 'en': {'title': 'Enhancing Video Generation with Temporal Augmentation', 'desc': 'This paper addresses the challenge of maintaining consistent motion and realistic dynamics in video generation, focusing on the aspect of temporal quality. It introduces a novel method called FluxFlow, which applies controlled temporal perturbations to enhance temporal coherence and diversity in generated videos. The approach operates at the data level, meaning it does not require changes to the underlying model architecture. Experimental results on standard benchmarks show that FluxFlow significantly improves the performance of various video generation models while maintaining high spatial fidelity.'}, 'zh': {'title': '提升视频生成的时间质量', 'desc': '本研究探讨了视频生成中的时间质量问题，强调了在帧之间保持一致运动和真实动态的重要性。我们首次引入了时间增强技术，并提出了FluxFlow策略，以提高视频生成的时间质量。FluxFlow在数据层面进行操作，通过控制时间扰动来增强时间一致性和多样性，而无需修改模型架构。实验结果表明，FluxFlow在多个视频生成模型上显著改善了时间一致性和多样性，同时保持了空间保真度。'}}}, {'id': 'https://huggingface.co/papers/2503.14868', 'title': 'Efficient Personalization of Quantized Diffusion Model without\n  Backpropagation', 'url': 'https://huggingface.co/papers/2503.14868', 'abstract': 'Diffusion models have shown remarkable performance in image synthesis, but they demand extensive computational and memory resources for training, fine-tuning and inference. Although advanced quantization techniques have successfully minimized memory usage for inference, training and fine-tuning these quantized models still require large memory possibly due to dequantization for accurate computation of gradients and/or backpropagation for gradient-based algorithms. However, memory-efficient fine-tuning is particularly desirable for applications such as personalization that often must be run on edge devices like mobile phones with private data. In this work, we address this challenge by quantizing a diffusion model with personalization via Textual Inversion and by leveraging a zeroth-order optimization on personalization tokens without dequantization so that it does not require gradient and activation storage for backpropagation that consumes considerable memory. Since a gradient estimation using zeroth-order optimization is quite noisy for a single or a few images in personalization, we propose to denoise the estimated gradient by projecting it onto a subspace that is constructed with the past history of the tokens, dubbed Subspace Gradient. In addition, we investigated the influence of text embedding in image generation, leading to our proposed time steps sampling, dubbed Partial Uniform Timestep Sampling for sampling with effective diffusion timesteps. Our method achieves comparable performance to prior methods in image and text alignment scores for personalizing Stable Diffusion with only forward passes while reducing training memory demand up to 8.2times.', 'score': 8, 'issue_id': 2802, 'pub_date': '2025-03-19', 'pub_date_card': {'ru': '19 марта', 'en': 'March 19', 'zh': '3月19日'}, 'hash': '8555fb94242b412c', 'authors': ['Hoigi Seo', 'Wongi Jeong', 'Kyungryeol Lee', 'Se Young Chun'], 'affiliations': ['Dept. of Electrical and Computer Engineering, INMC & IPAI Seoul National University, Republic of Korea'], 'pdf_title_img': 'assets/pdf/title_img/2503.14868.jpg', 'data': {'categories': ['#optimization', '#diffusion', '#cv', '#training', '#inference'], 'emoji': '🧠', 'ru': {'title': 'Память под контролем: персонализация диффузионных моделей на краевых устройствах', 'desc': "Статья представляет новый метод для эффективной тонкой настройки диффузионных моделей с персонализацией на устройствах с ограниченной памятью. Авторы предлагают использовать квантизацию модели и оптимизацию нулевого порядка для токенов персонализации, что позволяет избежать хранения градиентов и активаций. Для улучшения оценки градиента предложен метод 'Subspace Gradient', проецирующий градиент на подпространство, построенное на основе истории токенов. Также введена техника 'Partial Uniform Timestep Sampling' для эффективного выбора временных шагов диффузии."}, 'en': {'title': 'Efficient Personalization of Diffusion Models with Subspace Gradient', 'desc': 'This paper presents a method to improve the efficiency of training diffusion models for image synthesis, particularly for personalization on edge devices. It introduces a quantization technique that allows for fine-tuning without the need for dequantization, thus saving memory during gradient computation. The authors propose a novel approach called Subspace Gradient to reduce noise in gradient estimation by utilizing historical data from personalization tokens. Additionally, they explore the impact of text embeddings on image generation, leading to a new sampling method that optimizes diffusion timesteps, achieving significant memory savings while maintaining performance.'}, 'zh': {'title': '高效个性化扩散模型的内存优化', 'desc': '扩散模型在图像合成中表现出色，但训练和微调需要大量计算和内存资源。尽管先进的量化技术可以减少推理时的内存使用，但训练这些量化模型仍然需要大量内存。本文提出了一种通过文本反演对扩散模型进行量化的方法，并利用零阶优化在不去量化的情况下进行个性化微调，从而减少内存消耗。我们的方法在图像和文本对齐得分上与之前的方法相当，同时将训练内存需求降低了多达8.2倍。'}}}, {'id': 'https://huggingface.co/papers/2503.15265', 'title': 'DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement\n  Learning', 'url': 'https://huggingface.co/papers/2503.15265', 'abstract': 'Triangle meshes play a crucial role in 3D applications for efficient manipulation and rendering. While auto-regressive methods generate structured meshes by predicting discrete vertex tokens, they are often constrained by limited face counts and mesh incompleteness. To address these challenges, we propose DeepMesh, a framework that optimizes mesh generation through two key innovations: (1) an efficient pre-training strategy incorporating a novel tokenization algorithm, along with improvements in data curation and processing, and (2) the introduction of Reinforcement Learning (RL) into 3D mesh generation to achieve human preference alignment via Direct Preference Optimization (DPO). We design a scoring standard that combines human evaluation with 3D metrics to collect preference pairs for DPO, ensuring both visual appeal and geometric accuracy. Conditioned on point clouds and images, DeepMesh generates meshes with intricate details and precise topology, outperforming state-of-the-art methods in both precision and quality. Project page: https://zhaorw02.github.io/DeepMesh/', 'score': 5, 'issue_id': 2802, 'pub_date': '2025-03-19', 'pub_date_card': {'ru': '19 марта', 'en': 'March 19', 'zh': '3月19日'}, 'hash': '37236f5315cc8aef', 'authors': ['Ruowen Zhao', 'Junliang Ye', 'Zhengyi Wang', 'Guangce Liu', 'Yiwen Chen', 'Yikai Wang', 'Jun Zhu'], 'affiliations': ['Nanyang Technological University', 'ShengShu', 'Tsinghua University'], 'pdf_title_img': 'assets/pdf/title_img/2503.15265.jpg', 'data': {'categories': ['#optimization', '#data', '#alignment', '#rlhf', '#rl', '#3d'], 'emoji': '🔷', 'ru': {'title': 'DeepMesh: Революция в генерации 3D-сеток с учетом человеческих предпочтений', 'desc': 'DeepMesh - это новый фреймворк для оптимизации генерации трехмерных сеток. Он использует эффективную стратегию предварительного обучения с новым алгоритмом токенизации и улучшенной обработкой данных. DeepMesh также внедряет обучение с подкреплением для создания 3D-сеток, соответствующих предпочтениям человека, с помощью Direct Preference Optimization. Система генерирует сетки с детальной структурой и точной топологией на основе облаков точек и изображений, превосходя современные методы по точности и качеству.'}, 'en': {'title': 'DeepMesh: Elevating 3D Mesh Generation with Human-Centric Learning', 'desc': 'This paper introduces DeepMesh, a new framework for generating 3D triangle meshes that enhances both quality and precision. It utilizes a unique pre-training strategy with an innovative tokenization method, improving how data is curated and processed. Additionally, it incorporates Reinforcement Learning to align mesh generation with human preferences through Direct Preference Optimization. By conditioning on point clouds and images, DeepMesh produces detailed and accurately structured meshes, surpassing existing methods in performance.'}, 'zh': {'title': 'DeepMesh：优化3D网格生成的新方法', 'desc': '三角网格在3D应用中至关重要，能够高效地进行操作和渲染。传统的自回归方法通过预测离散的顶点标记生成结构化网格，但常常受到面数限制和网格不完整性的困扰。为了解决这些问题，我们提出了DeepMesh框架，通过两项关键创新来优化网格生成：一种高效的预训练策略和将强化学习引入3D网格生成。DeepMesh能够生成细节丰富、拓扑精确的网格，且在精度和质量上超越了现有的最先进方法。'}}}, {'id': 'https://huggingface.co/papers/2503.12769', 'title': 'ViSpeak: Visual Instruction Feedback in Streaming Videos', 'url': 'https://huggingface.co/papers/2503.12769', 'abstract': 'Recent advances in Large Multi-modal Models (LMMs) are primarily focused on offline video understanding. Instead, streaming video understanding poses great challenges to recent models due to its time-sensitive, omni-modal and interactive characteristics. In this work, we aim to extend the streaming video understanding from a new perspective and propose a novel task named Visual Instruction Feedback in which models should be aware of visual contents and learn to extract instructions from them. For example, when users wave their hands to agents, agents should recognize the gesture and start conversations with welcome information. Thus, following instructions in visual modality greatly enhances user-agent interactions. To facilitate research, we define seven key subtasks highly relevant to visual modality and collect the ViSpeak-Instruct dataset for training and the ViSpeak-Bench for evaluation. Further, we propose the ViSpeak model, which is a SOTA streaming video understanding LMM with GPT-4o-level performance on various streaming video understanding benchmarks. After finetuning on our ViSpeak-Instruct dataset, ViSpeak is equipped with basic visual instruction feedback ability, serving as a solid baseline for future research.', 'score': 4, 'issue_id': 2800, 'pub_date': '2025-03-17', 'pub_date_card': {'ru': '17 марта', 'en': 'March 17', 'zh': '3月17日'}, 'hash': '0913c8e386f3aae5', 'authors': ['Shenghao Fu', 'Qize Yang', 'Yuan-Ming Li', 'Yi-Xing Peng', 'Kun-Yu Lin', 'Xihan Wei', 'Jian-Fang Hu', 'Xiaohua Xie', 'Wei-Shi Zheng'], 'affiliations': ['Guangdong Province Key Laboratory of Information Security Technology, China', 'Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China', 'Pazhou Laboratory (Huangpu), China', 'Peng Cheng Laboratory, China', 'School of Computer Science and Engineering, Sun Yat-sen University, China', 'Tongyi Lab, Alibaba Group'], 'pdf_title_img': 'assets/pdf/title_img/2503.12769.jpg', 'data': {'categories': ['#dataset', '#multimodal', '#benchmark', '#video', '#agents'], 'emoji': '👁️', 'ru': {'title': 'ViSpeak: Революция в интерактивном понимании потокового видео', 'desc': "Статья представляет новую задачу под названием 'Визуальная инструктивная обратная связь' для потокового понимания видео. Авторы предлагают модель ViSpeak, способную распознавать визуальные инструкции и реагировать на них в режиме реального времени. Для обучения и оценки созданы наборы данных ViSpeak-Instruct и ViSpeak-Bench. Модель ViSpeak демонстрирует производительность на уровне GPT-4 в различных задачах потокового понимания видео."}, 'en': {'title': 'Enhancing User-Agent Interaction through Visual Instruction Feedback', 'desc': 'This paper introduces a new approach to understanding streaming video using Large Multi-modal Models (LMMs). It focuses on a task called Visual Instruction Feedback, where models learn to interpret visual cues, like hand gestures, to enhance interactions with users. The authors present the ViSpeak model, which achieves state-of-the-art performance in streaming video understanding after being trained on a newly created dataset. This work aims to improve user-agent communication by enabling agents to respond appropriately to visual instructions.'}, 'zh': {'title': '提升用户与代理互动的视觉指令反馈', 'desc': '近年来，大型多模态模型（LMM）在离线视频理解方面取得了显著进展。然而，流媒体视频理解由于其时间敏感性、全模态和交互特性，对现有模型提出了巨大挑战。本文提出了一种新任务，称为视觉指令反馈，模型需要理解视觉内容并从中提取指令，从而增强用户与代理之间的互动。我们定义了七个与视觉模态高度相关的子任务，并收集了ViSpeak-Instruct数据集用于训练，ViSpeak-Bench用于评估，同时提出了ViSpeak模型，展示了在流媒体视频理解基准上的先进性能。'}}}, {'id': 'https://huggingface.co/papers/2503.12532', 'title': 'STEVE: AStep Verification Pipeline for Computer-use Agent Training', 'url': 'https://huggingface.co/papers/2503.12532', 'abstract': 'Developing AI agents to autonomously manipulate graphical user interfaces is a long challenging task. Recent advances in data scaling law inspire us to train computer-use agents with a scaled instruction set, yet using behavior cloning to train agents still requires immense high-quality trajectories. To meet the scalability need, we designed STEVE, a step verification pipeline for computer-use agent training. First, we establish a large instruction set for computer-use agents and collect trajectory data with some suboptimal agents. GPT-4o is used to verify the correctness of each step in the trajectories based on the screens before and after the action execution, assigning each step with a binary label. Last, we adopt the Kahneman and Tversky Optimization to optimize the agent from the binary stepwise labels. Extensive experiments manifest that our agent outperforms supervised finetuning by leveraging both positive and negative actions within a trajectory. Also, STEVE enables us to train a 7B vision-language model as a computer-use agent, achieving leading performance in the challenging live desktop environment WinAgentArena with great efficiency at a reduced cost. Code and data: https://github.com/FanbinLu/STEVE.', 'score': 4, 'issue_id': 2800, 'pub_date': '2025-03-16', 'pub_date_card': {'ru': '16 марта', 'en': 'March 16', 'zh': '3月16日'}, 'hash': '185728a70d3b80d0', 'authors': ['Fanbin Lu', 'Zhisheng Zhong', 'Ziqin Wei', 'Shu Liu', 'Chi-Wing Fu', 'Jiaya Jia'], 'affiliations': ['CUHK', 'HKUST', 'SmartMore'], 'pdf_title_img': 'assets/pdf/title_img/2503.12532.jpg', 'data': {'categories': ['#optimization', '#games', '#agents', '#training', '#cv'], 'emoji': '🖥️', 'ru': {'title': 'STEVE: эффективное обучение ИИ-агентов для работы с компьютерным интерфейсом', 'desc': 'Статья представляет STEVE - новый метод обучения ИИ-агентов для автономного управления графическими интерфейсами. Авторы используют большой набор инструкций и субоптимальные траектории, которые затем верифицируются с помощью GPT-4. На основе бинарных оценок каждого шага применяется оптимизация Канемана-Тверски для улучшения агента. Эксперименты показывают, что данный подход превосходит обычное обучение с учителем и позволяет эффективно обучить модель размером 7 миллиардов параметров для работы в сложной среде рабочего стола.'}, 'en': {'title': 'STEVE: Optimizing AI Agents for GUI Manipulation Efficiently', 'desc': "This paper presents STEVE, a novel step verification pipeline designed to enhance the training of AI agents for manipulating graphical user interfaces. By utilizing a large instruction set and collecting trajectory data from suboptimal agents, STEVE verifies the correctness of each action using GPT-4o, which labels steps as correct or incorrect. The approach incorporates Kahneman and Tversky Optimization to refine the agent's learning process based on these binary labels, allowing the agent to learn from both successful and unsuccessful actions. The results demonstrate that STEVE significantly improves performance in complex environments like WinAgentArena while being more cost-effective than traditional supervised finetuning methods."}, 'zh': {'title': '智能代理训练的新突破：STEVE', 'desc': '本论文提出了一种名为STEVE的步骤验证管道，用于训练计算机使用代理。我们首先建立了一个大型指令集，并收集了一些次优代理的轨迹数据。通过使用GPT-4o验证每个步骤的正确性，并为每个步骤分配二元标签，最后采用卡尼曼和特沃斯优化方法来优化代理。实验结果表明，我们的代理在复杂的桌面环境中表现优于传统的监督微调方法，且训练效率高、成本低。'}}}, {'id': 'https://huggingface.co/papers/2503.14505', 'title': 'MusicInfuser: Making Video Diffusion Listen and Dance', 'url': 'https://huggingface.co/papers/2503.14505', 'abstract': 'We introduce MusicInfuser, an approach for generating high-quality dance videos that are synchronized to a specified music track. Rather than attempting to design and train a new multimodal audio-video model, we show how existing video diffusion models can be adapted to align with musical inputs by introducing lightweight music-video cross-attention and a low-rank adapter. Unlike prior work requiring motion capture data, our approach fine-tunes only on dance videos. MusicInfuser achieves high-quality music-driven video generation while preserving the flexibility and generative capabilities of the underlying models. We introduce an evaluation framework using Video-LLMs to assess multiple dimensions of dance generation quality. The project page and code are available at https://susunghong.github.io/MusicInfuser.', 'score': 1, 'issue_id': 2801, 'pub_date': '2025-03-18', 'pub_date_card': {'ru': '18 марта', 'en': 'March 18', 'zh': '3月18日'}, 'hash': '61ef56ac402491c0', 'authors': ['Susung Hong', 'Ira Kemelmacher-Shlizerman', 'Brian Curless', 'Steven M. Seitz'], 'affiliations': [], 'pdf_title_img': 'assets/pdf/title_img/2503.14505.jpg', 'data': {'categories': ['#benchmark', '#open_source', '#diffusion', '#multimodal', '#video'], 'emoji': '💃', 'ru': {'title': 'Танцуй под музыку: ИИ-генерация видео в ритме мелодии', 'desc': 'MusicInfuser - это новый подход к генерации высококачественных танцевальных видео, синхронизированных с заданной музыкальной дорожкой. Он адаптирует существующие модели диффузии видео для согласования с музыкальными входными данными, используя легковесное кросс-внимание между музыкой и видео и низкоранговый адаптер. В отличие от предыдущих работ, MusicInfuser не требует данных захвата движения и дообучается только на танцевальных видео. Для оценки качества генерации танцев по нескольким параметрам авторы представили систему оценки с использованием видео-LLM.'}, 'en': {'title': 'Syncing Dance with Music: Introducing MusicInfuser', 'desc': "MusicInfuser is a novel method for creating high-quality dance videos that match a chosen music track. It leverages existing video diffusion models by incorporating music-video cross-attention and a low-rank adapter, rather than building a new model from scratch. This approach allows for fine-tuning on dance videos without the need for motion capture data, enhancing the model's efficiency. Additionally, MusicInfuser includes a new evaluation framework using Video-LLMs to measure various aspects of dance generation quality."}, 'zh': {'title': '音乐与舞蹈的完美融合', 'desc': '我们介绍了MusicInfuser，这是一种生成高质量舞蹈视频的方法，能够与指定的音乐轨道同步。我们通过引入轻量级的音乐-视频交叉注意力机制和低秩适配器，展示了如何调整现有的视频扩散模型以适应音乐输入。与之前需要运动捕捉数据的工作不同，我们的方法仅在舞蹈视频上进行微调。MusicInfuser在保持底层模型的灵活性和生成能力的同时，实现了高质量的音乐驱动视频生成。'}}}, {'id': 'https://huggingface.co/papers/2503.15055', 'title': 'ELTEX: A Framework for Domain-Driven Synthetic Data Generation', 'url': 'https://huggingface.co/papers/2503.15055', 'abstract': "We present ELTEX (Efficient LLM Token Extraction), a domain-driven framework for generating high-quality synthetic training data in specialized domains. While Large Language Models (LLMs) have shown impressive general capabilities, their performance in specialized domains like cybersecurity remains limited by the scarcity of domain-specific training data. ELTEX addresses this challenge by systematically integrating explicit domain indicator extraction with dynamic prompting to preserve critical domain knowledge throughout the generation process. We demonstrate ELTEX's effectiveness in the context of blockchain-related cyberattack detection, where we fine-tune Gemma-2B using various combinations of real and ELTEX-generated data. Our results show that the ELTEX-enhanced model achieves performance competitive with GPT-4 across both standard classification metrics and uncertainty calibration, while requiring significantly fewer computational resources. We release a curated synthetic dataset of social media texts for cyberattack detection in blockchain. Our work demonstrates that domain-driven synthetic data generation can effectively bridge the performance gap between resource-efficient models and larger architectures in specialized domains.", 'score': 0, 'issue_id': 2802, 'pub_date': '2025-03-19', 'pub_date_card': {'ru': '19 марта', 'en': 'March 19', 'zh': '3月19日'}, 'hash': '785ffad4856eb286', 'authors': ['Arina Razmyslovich', 'Kseniia Murasheva', 'Sofia Sedlova', 'Julien Capitaine', 'Eugene Dmitriev'], 'affiliations': ['Distributed Networks Institute (DNI)', 'Technologies Mésozoïques'], 'pdf_title_img': 'assets/pdf/title_img/2503.15055.jpg', 'data': {'categories': ['#science', '#data', '#training', '#synthetic', '#dataset'], 'emoji': '🛡️', 'ru': {'title': 'ELTEX: Синтетические данные для повышения эффективности малых ЯМ в специализированных областях', 'desc': 'ELTEX - это фреймворк для генерации синтетических данных в специализированных областях, таких как кибербезопасность. Он объединяет извлечение индикаторов предметной области с динамическим промптингом для сохранения критических знаний. ELTEX был применен для обнаружения кибератак в блокчейне, где модель Gemma-2B, дообученная на сгенерированных данных, показала результаты, сравнимые с GPT-4. Этот подход демонстрирует, что синтетические данные могут эффективно улучшать производительность малых моделей в специализированных областях.'}, 'en': {'title': 'Bridging the Data Gap in Cybersecurity with ELTEX', 'desc': 'The paper introduces ELTEX, a framework designed to create high-quality synthetic training data specifically for specialized fields like cybersecurity. It tackles the issue of limited domain-specific data that affects the performance of Large Language Models (LLMs) in these areas. By combining domain indicator extraction with dynamic prompting, ELTEX ensures that essential domain knowledge is maintained during data generation. The framework is validated through its application in blockchain cyberattack detection, showing that it can enhance model performance while being more resource-efficient than larger models like GPT-4.'}, 'zh': {'title': '领域驱动的合成数据生成，提升模型性能！', 'desc': 'ELTEX（高效LLM令牌提取）是一个针对特定领域生成高质量合成训练数据的框架。大型语言模型（LLM）在通用能力上表现出色，但在网络安全等专业领域的表现受到领域特定训练数据稀缺的限制。ELTEX通过系统地整合显式领域指示符提取和动态提示，确保在生成过程中保留关键的领域知识。我们的实验表明，ELTEX增强的模型在区块链相关的网络攻击检测中，性能与GPT-4相当，同时显著减少了计算资源的需求。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (2)', '#agents (2)', '#agi', '#alignment (1)', '#architecture (1)', '#audio', '#benchmark (4)', '#cv (3)', '#data (2)', '#dataset (2)', '#diffusion (2)', '#ethics', '#games (2)', '#graphs', '#hallucinations', '#healthcare', '#inference (1)', '#interpretability', '#leakage', '#long_context', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal (4)', '#open_source (2)', '#optimization (4)', '#plp', '#rag', '#reasoning (1)', '#rl (1)', '#rlhf (1)', '#robotics', '#science (1)', '#security', '#small_models', '#story_generation', '#survey', '#synthetic (1)', '#training (3)', '#transfer_learning', '#video (3)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-03-20 05:11',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-03-20 05:11')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-03-20 05:11')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    