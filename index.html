
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 9 papers. July 9.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">9 июля</span> | <span id="title-articles-count">9 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-07-08.html">⬅️ <span id="prev-date">08.07</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-07-10.html">➡️ <span id="next-date">10.07</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-07.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '9 июля', 'en': 'July 9', 'zh': '7月9日'};
        let feedDateNext = {'ru': '10.07', 'en': '07/10', 'zh': '7月10日'};
        let feedDatePrev = {'ru': '08.07', 'en': '07/08', 'zh': '7月8日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2507.03112', 'title': 'RLVER: Reinforcement Learning with Verifiable Emotion Rewards for\n  Empathetic Agents', 'url': 'https://huggingface.co/papers/2507.03112', 'abstract': "An end-to-end reinforcement learning framework using simulated user emotion rewards enhances emotional intelligence in large language models while maintaining cognitive skills.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) excel at logical and algorithmic reasoning, yet their emotional intelligence (EQ) still lags far behind their cognitive prowess. While reinforcement learning from verifiable rewards (RLVR) has advanced in other domains, its application to dialogue-especially for emotional intelligence-remains underexplored. In this work, we introduce RLVER, the first end-to-end reinforcement learning framework that leverages verifiable emotion rewards from simulated users to cultivate higher-order empathetic abilities in LLMs. Within this framework, self-consistent affective simulated users engage in dialogue rollouts and produce deterministic emotion scores during conversations, serving as reward signals to guide the LLM's learning. Fine-tuning publicly available Qwen2.5-7B-Instruct model with PPO boosts its Sentient-Benchmark score from 13.3 to 79.2 while largely preserving mathematical and coding competence. Extensive experiments reveal that: (i) RLVER consistently improves multiple dialogue capabilities; (ii) Thinking and non-thinking models show distinct trends--thinking models excel in empathy and insight, while non-thinking models favor action; (iii) GRPO often yields stable gains, while PPO can push certain capabilities to a higher ceiling; (iv) More challenging environments are not always better-moderate ones can yield stronger outcomes. Our results show that RLVER is a practical route toward emotionally intelligent and broadly capable language agents.", 'score': 8, 'issue_id': 4715, 'pub_date': '2025-07-03', 'pub_date_card': {'ru': '3 июля', 'en': 'July 3', 'zh': '7月3日'}, 'hash': 'c1368a26272d7e57', 'authors': ['Peisong Wang', 'Ruotian Ma', 'Bang Zhang', 'Xingyu Chen', 'Zhiwei He', 'Kang Luo', 'Qingsong Lv', 'Qingxuan Jiang', 'Zheng Xie', 'Shanyi Wang', 'Yuan Li', 'Fanghua Ye', 'Jian Li', 'Yifan Yang', 'Zhaopeng Tu', 'Xiaolong Li'], 'affiliations': ['Hunyuan AI Digital Human, Tencent'], 'pdf_title_img': 'assets/pdf/title_img/2507.03112.jpg', 'data': {'categories': ['#reasoning', '#rl', '#alignment', '#agents', '#rlhf', '#training'], 'emoji': '🤖💕', 'ru': {'title': 'Эмоциональный интеллект ИИ: обучение с подкреплением открывает новые горизонты', 'desc': 'Статья представляет RLVER - первую систему обучения с подкреплением для развития эмоционального интеллекта у больших языковых моделей (LLM). Система использует симулированных пользователей для генерации эмоциональных наград в процессе диалога. Применение RLVER к модели Qwen2.5-7B-Instruct значительно повысило её показатели эмоционального интеллекта при сохранении когнитивных навыков. Эксперименты показали, что RLVER последовательно улучшает различные диалоговые способности модели.'}, 'en': {'title': 'Enhancing Emotional Intelligence in Language Models with RLVER', 'desc': 'This paper presents RLVER, a novel reinforcement learning framework designed to enhance emotional intelligence in large language models (LLMs) by using simulated user emotion rewards. The framework employs reinforcement learning from verifiable rewards (RLVR) to train LLMs in dialogue settings, focusing on developing empathetic abilities. By fine-tuning the Qwen2.5-7B-Instruct model with Proximal Policy Optimization (PPO), the authors demonstrate significant improvements in emotional understanding while maintaining cognitive skills. The findings indicate that RLVER effectively boosts dialogue capabilities and suggests that moderate training environments can lead to better outcomes than more challenging ones.'}, 'zh': {'title': '情感智能与认知能力的完美结合', 'desc': '本文提出了一种端到端的强化学习框架RLVER，旨在通过模拟用户的情感奖励来提升大型语言模型的情感智能。尽管大型语言模型在逻辑推理方面表现出色，但它们的情感智能仍然不足。RLVER利用可验证的情感奖励，指导模型学习更高层次的同理心能力。实验结果表明，RLVER显著提高了对话能力，并在保持数学和编码能力的同时，提升了模型的情感理解能力。'}}}, {'id': 'https://huggingface.co/papers/2507.06223', 'title': 'Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers', 'url': 'https://huggingface.co/papers/2507.06223', 'abstract': 'E\\textsuperscript{2}R-FLOPs evaluates LLM-based rerankers by measuring relevance and throughput per PetaFLOP, providing a hardware-agnostic metric for efficiency and effectiveness.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have recently been applied to reranking tasks in information retrieval, achieving strong performance. However, their high computational demands often hinder practical deployment. Existing studies evaluate the efficiency of LLM-based rerankers using proxy metrics such as latency, the number of forward passes, input tokens, and output tokens. However, these metrics depend on hardware and running-time choices (\\eg parallel or not, batch size, etc), and often fail to account for model size, making it difficult to interpret and obscuring the evaluation of the efficiency-effectiveness tradeoff. To address this issue, we propose E2R-FLOPs, for LLM-based rerankers: ranking metrics per PetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for hardware-agnostic throughput. Companied with the new metrics, an interpretable FLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even without running any experiments. Based on the proposed metrics, we conduct comprehensive experiments to evaluate a wide range of LLM-based rerankers with different architecture, studying the efficiency-effectiveness trade-off and bringing this issue to the attention of the research community.', 'score': 6, 'issue_id': 4715, 'pub_date': '2025-07-08', 'pub_date_card': {'ru': '8 июля', 'en': 'July 8', 'zh': '7月8日'}, 'hash': '6073d3ee8c07d225', 'authors': ['Zhiyuan Peng', 'Ting-ruen Wei', 'Tingyu Song', 'Yilun Zhao', 'Yi Fang'], 'affiliations': ['Independent Researcher, Beijing, China', 'Santa Clara University, Santa Clara, CA', 'Yale University, New Haven, CT'], 'pdf_title_img': 'assets/pdf/title_img/2507.06223.jpg', 'data': {'categories': ['#benchmark', '#optimization', '#interpretability', '#architecture', '#inference'], 'emoji': '🔬', 'ru': {'title': 'E2R-FLOPs: Новый взгляд на эффективность LLM-ранжировщиков', 'desc': 'Статья представляет новую метрику E2R-FLOPs для оценки эффективности ранжировщиков на основе больших языковых моделей (LLM). Метрика измеряет релевантность и пропускную способность на ПетаФЛОП, предоставляя аппаратно-независимый способ оценки эффективности и результативности. Авторы разработали интерпретируемый оценщик ФЛОП для расчета вычислительной сложности LLM-ранжировщиков без необходимости проведения экспериментов. На основе предложенной метрики были проведены комплексные эксперименты для оценки различных LLM-ранжировщиков, изучая компромисс между эффективностью и результативностью.'}, 'en': {'title': 'E2R-FLOPs: A New Standard for Evaluating LLM Efficiency', 'desc': 'The paper introduces E2R-FLOPs, a new metric for evaluating the efficiency of Large Language Model (LLM)-based rerankers in information retrieval. It measures relevance and throughput per PetaFLOP, providing a hardware-agnostic way to assess performance. Traditional metrics like latency and token counts are limited by hardware dependencies and do not adequately reflect model size, making comparisons challenging. By using E2R-FLOPs, researchers can better understand the trade-offs between efficiency and effectiveness in LLM-based reranking tasks.'}, 'zh': {'title': 'E2R-FLOPs：高效评估LLM重排序器的工具', 'desc': 'E2R-FLOPs 是一种评估基于大型语言模型（LLM）的重排序器的新方法，通过每 PetaFLOP 的相关性和吞吐量来衡量其效率和有效性。这种方法解决了现有评估指标依赖于硬件和运行时间选择的问题，使得评估更加通用和易于理解。我们还构建了一个可解释的 FLOPs 估算器，可以在不进行实验的情况下估算 LLM 重排序器的 FLOPs。通过这些新指标，我们对多种不同架构的 LLM 重排序器进行了全面实验，研究了效率与有效性之间的权衡。'}}}, {'id': 'https://huggingface.co/papers/2507.05791', 'title': 'GTA1: GUI Test-time Scaling Agent', 'url': 'https://huggingface.co/papers/2507.05791', 'abstract': 'GTA1 addresses task planning ambiguity and visual grounding in GUI interactions using test-time scaling and reinforcement learning, achieving state-of-the-art performance across benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.   This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements.   Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here.', 'score': 6, 'issue_id': 4715, 'pub_date': '2025-07-08', 'pub_date_card': {'ru': '8 июля', 'en': 'July 8', 'zh': '7月8日'}, 'hash': 'e20f930b7b567221', 'authors': ['Yan Yang', 'Dongxu Li', 'Yutong Dai', 'Yuhao Yang', 'Ziyang Luo', 'Zirui Zhao', 'Zhiyuan Hu', 'Junzhe Huang', 'Amrita Saha', 'Zeyuan Chen', 'Ran Xu', 'Liyuan Pan', 'Caiming Xiong', 'Junnan Li'], 'affiliations': ['Salesforce AI Research', 'The Australian National University', 'University of Hong Kong'], 'pdf_title_img': 'assets/pdf/title_img/2507.05791.jpg', 'data': {'categories': ['#benchmark', '#optimization', '#games', '#rl', '#agents', '#open_source'], 'emoji': '🖥️', 'ru': {'title': 'GTA1: Умный агент для автономного управления графическими интерфейсами', 'desc': 'Статья представляет GTA1 - агента для взаимодействия с графическим интерфейсом, решающего проблемы планирования задач и визуальной привязки действий. Метод использует масштабирование во время тестирования для выбора оптимальных действий и обучение с подкреплением для точного взаимодействия с визуальными элементами. GTA1 достигает наилучших результатов на нескольких бенчмарках, значительно улучшая точность и успешность выполнения задач. Авторы открыли исходный код и модели для дальнейших исследований.'}, 'en': {'title': 'GTA1: Mastering GUI Interactions with Smart Planning and Learning', 'desc': 'The paper presents GTA1, a novel approach to enhance task planning and visual grounding in graphical user interface (GUI) interactions using reinforcement learning. It addresses the challenges of ambiguity in action proposals by employing a test-time scaling method that samples multiple candidates and selects the best one through a judge model. Additionally, it improves the accuracy of grounding actions to visual elements by leveraging reinforcement learning, which aligns objectives with successful interactions. The results demonstrate that GTA1 achieves state-of-the-art performance on various benchmarks, showcasing its effectiveness in autonomous GUI task execution.'}, 'zh': {'title': 'GTA1：提升GUI交互的智能决策与视觉定位', 'desc': 'GTA1是一种图形用户界面（GUI）代理，旨在解决任务规划中的模糊性和视觉定位问题。它通过测试时缩放和强化学习的方法，优化了在复杂界面中与视觉元素的交互。该方法通过采样多个候选动作提案，并利用评判模型选择最合适的提案，从而提高决策质量。实验结果表明，GTA1在多个基准测试中达到了最先进的性能，展示了其在任务成功率和准确性方面的优势。'}}}, {'id': 'https://huggingface.co/papers/2507.03698', 'title': 'SAMed-2: Selective Memory Enhanced Medical Segment Anything Model', 'url': 'https://huggingface.co/papers/2507.03698', 'abstract': 'SAMed-2, an adaptation of SAM-2 for medical image segmentation, incorporates a temporal adapter and confidence-driven memory to improve performance across diverse medical datasets and tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent "segment anything" efforts show promise by learning from large-scale data, but adapting such models directly to medical images remains challenging due to the complexity of medical data, noisy annotations, and continual learning requirements across diverse modalities and anatomical structures. In this work, we propose SAMed-2, a new foundation model for medical image segmentation built upon the SAM-2 architecture. Specifically, we introduce a temporal adapter into the image encoder to capture image correlations and a confidence-driven memory mechanism to store high-certainty features for later retrieval. This memory-based strategy counters the pervasive noise in large-scale medical datasets and mitigates catastrophic forgetting when encountering new tasks or modalities. To train and evaluate SAMed-2, we curate MedBank-100k, a comprehensive dataset spanning seven imaging modalities and 21 medical segmentation tasks. Our experiments on both internal benchmarks and 10 external datasets demonstrate superior performance over state-of-the-art baselines in multi-task scenarios. The code is available at: https://github.com/ZhilingYan/Medical-SAM-Bench.', 'score': 6, 'issue_id': 4715, 'pub_date': '2025-07-04', 'pub_date_card': {'ru': '4 июля', 'en': 'July 4', 'zh': '7月4日'}, 'hash': '6eb9d67bc0e6c585', 'authors': ['Zhiling Yan', 'Sifan Song', 'Dingjie Song', 'Yiwei Li', 'Rong Zhou', 'Weixiang Sun', 'Zhennong Chen', 'Sekeun Kim', 'Hui Ren', 'Tianming Liu', 'Quanzheng Li', 'Xiang Li', 'Lifang He', 'Lichao Sun'], 'affiliations': ['Lehigh University, Bethlehem, PA, USA', 'Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA', 'University of Georgia, Athens, GA, USA', 'University of Notre Dame, Notre Dame, IN, USA'], 'pdf_title_img': 'assets/pdf/title_img/2507.03698.jpg', 'data': {'categories': ['#cv', '#benchmark', '#healthcare', '#data', '#dataset', '#training'], 'emoji': '🏥', 'ru': {'title': 'SAMed-2: Универсальный сегментатор для медицинских изображений', 'desc': 'SAMed-2 - это новая модель для сегментации медицинских изображений, основанная на архитектуре SAM-2. Она включает в себя временной адаптер для захвата корреляций между изображениями и механизм памяти, управляемый уверенностью, для хранения высокодостоверных признаков. Модель обучена на наборе данных MedBank-100k, охватывающем 7 модальностей визуализации и 21 задачу медицинской сегментации. Эксперименты показали превосходную производительность SAMed-2 по сравнению с современными базовыми моделями в многозадачных сценариях.'}, 'en': {'title': 'Enhancing Medical Image Segmentation with SAMed-2', 'desc': 'SAMed-2 is a new model designed for medical image segmentation, enhancing the original SAM-2 framework. It introduces a temporal adapter to the image encoder, which helps in understanding relationships between images over time. Additionally, a confidence-driven memory mechanism is implemented to retain important features, addressing issues like noisy data and preventing loss of knowledge when learning new tasks. The model is trained on a large dataset called MedBank-100k, showing improved performance in various medical imaging tasks compared to existing methods.'}, 'zh': {'title': '医学图像分割的新突破：SAMed-2', 'desc': 'SAMed-2是针对医学图像分割的SAM-2模型的改进版本。它引入了时间适配器和基于信心的记忆机制，以提高在不同医学数据集和任务中的表现。时间适配器帮助捕捉图像之间的相关性，而记忆机制则存储高置信度特征，以应对医学数据中的噪声和避免灾难性遗忘。通过构建MedBank-100k数据集并进行实验，SAMed-2在多任务场景中表现优于现有的最先进模型。'}}}, {'id': 'https://huggingface.co/papers/2507.06181', 'title': 'CriticLean: Critic-Guided Reinforcement Learning for Mathematical\n  Formalization', 'url': 'https://huggingface.co/papers/2507.06181', 'abstract': "CriticLean, a reinforcement learning framework with CriticLeanGPT and CriticLeanBench, enhances semantic evaluation in automated theorem proving by actively learning to distinguish correct from incorrect formalizations.  \t\t\t\t\tAI-generated summary \t\t\t\t Translating natural language mathematical statements into formal, executable code is a fundamental challenge in automated theorem proving. While prior work has focused on generation and compilation success, little attention has been paid to the critic phase-the evaluation of whether generated formalizations truly capture the semantic intent of the original problem. In this paper, we introduce CriticLean, a novel critic-guided reinforcement learning framework that elevates the role of the critic from a passive validator to an active learning component. Specifically, first, we propose the CriticLeanGPT, trained via supervised fine-tuning and reinforcement learning, to rigorously assess the semantic fidelity of Lean 4 formalizations. Then, we introduce CriticLeanBench, a benchmark designed to measure models' ability to distinguish semantically correct from incorrect formalizations, and demonstrate that our trained CriticLeanGPT models can significantly outperform strong open- and closed-source baselines. Building on the CriticLean framework, we construct FineLeanCorpus, a dataset comprising over 285K problems that exhibits rich domain diversity, broad difficulty coverage, and high correctness based on human evaluation. Overall, our findings highlight that optimizing the critic phase is essential for producing reliable formalizations, and we hope our CriticLean will provide valuable insights for future advances in formal mathematical reasoning.", 'score': 4, 'issue_id': 4715, 'pub_date': '2025-07-08', 'pub_date_card': {'ru': '8 июля', 'en': 'July 8', 'zh': '7月8日'}, 'hash': 'ad86fa3f7ff162ee', 'pdf_title_img': 'assets/pdf/title_img/2507.06181.jpg', 'data': {'categories': ['#benchmark', '#optimization', '#reasoning', '#rl', '#dataset'], 'emoji': '🧠', 'ru': {'title': 'Критик учится различать правильные и неправильные формализации теорем', 'desc': 'CriticLean - это фреймворк обучения с подкреплением для улучшения семантической оценки в автоматическом доказательстве теорем. Он включает в себя CriticLeanGPT - модель, обученную различать правильные и неправильные формализации, и CriticLeanBench - набор данных для оценки таких моделей. Фреймворк позволяет активно обучать критика, переводя его роль из пассивного валидатора в активный обучающийся компонент. Результаты показывают, что оптимизация фазы критики крайне важна для получения надежных формализаций в математических рассуждениях.'}, 'en': {'title': 'Empowering Theorem Proving with Active Semantic Evaluation', 'desc': 'CriticLean is a reinforcement learning framework designed to improve the evaluation of formalizations in automated theorem proving. It introduces CriticLeanGPT, a model that actively learns to assess the semantic accuracy of mathematical statements translated into formal code. The framework also includes CriticLeanBench, a benchmark for measuring the effectiveness of models in distinguishing correct from incorrect formalizations. By optimizing the critic phase, CriticLean aims to enhance the reliability of formalizations and contribute to advancements in formal mathematical reasoning.'}, 'zh': {'title': '优化评判阶段，提升自动定理证明的可靠性', 'desc': 'CriticLean是一个强化学习框架，旨在提高自动定理证明中的语义评估。它通过CriticLeanGPT和CriticLeanBench，主动学习区分正确和错误的形式化表达。CriticLeanGPT经过监督微调和强化学习训练，能够严格评估Lean 4形式化的语义准确性。我们的研究表明，优化评判阶段对于生成可靠的形式化表达至关重要。'}}}, {'id': 'https://huggingface.co/papers/2507.05101', 'title': 'PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to\n  Graphs', 'url': 'https://huggingface.co/papers/2507.05101', 'abstract': "Deep learning-based computational methods have achieved promising results in predicting protein-protein interactions (PPIs). However, existing benchmarks predominantly focus on isolated pairwise evaluations, overlooking a model's capability to reconstruct biologically meaningful PPI networks, which is crucial for biology research. To address this gap, we introduce PRING, the first comprehensive benchmark that evaluates protein-protein interaction prediction from a graph-level perspective. PRING curates a high-quality, multi-species PPI network dataset comprising 21,484 proteins and 186,818 interactions, with well-designed strategies to address both data redundancy and leakage. Building on this golden-standard dataset, we establish two complementary evaluation paradigms: (1) topology-oriented tasks, which assess intra and cross-species PPI network construction, and (2) function-oriented tasks, including protein complex pathway prediction, GO module analysis, and essential protein justification. These evaluations not only reflect the model's capability to understand the network topology but also facilitate protein function annotation, biological module detection, and even disease mechanism analysis. Extensive experiments on four representative model categories, consisting of sequence similarity-based, naive sequence-based, protein language model-based, and structure-based approaches, demonstrate that current PPI models have potential limitations in recovering both structural and functional properties of PPI networks, highlighting the gap in supporting real-world biological applications. We believe PRING provides a reliable platform to guide the development of more effective PPI prediction models for the community. The dataset and source code of PRING are available at https://github.com/SophieSarceau/PRING.", 'score': 4, 'issue_id': 4715, 'pub_date': '2025-07-07', 'pub_date_card': {'ru': '7 июля', 'en': 'July 7', 'zh': '7月7日'}, 'hash': 'c987593bed9476c8', 'authors': ['Xinzhe Zheng', 'Hao Du', 'Fanding Xu', 'Jinzhe Li', 'Zhiyuan Liu', 'Wenkang Wang', 'Tao Chen', 'Wanli Ouyang', 'Stan Z. Li', 'Yan Lu', 'Nanqing Dong', 'Yang Zhang'], 'affiliations': ['Fudan University', 'National University of Singapore', 'Shanghai Artificial Intelligence Laboratory', 'Shanghai Innovation Institute', 'The Chinese University of Hong Kong', 'Westlake University', 'Xian Jiaotong University'], 'pdf_title_img': 'assets/pdf/title_img/2507.05101.jpg', 'data': {'categories': ['#benchmark', '#data', '#open_source', '#dataset', '#graphs', '#leakage'], 'emoji': '🧬', 'ru': {'title': 'PRING: новый стандарт оценки предсказания белковых взаимодействий на уровне графов', 'desc': 'Статья представляет PRING - новый комплексный бенчмарк для оценки предсказания взаимодействий белок-белок (PPI) с точки зрения графов. PRING включает высококачественный набор данных PPI-сетей для нескольких видов, содержащий 21,484 белка и 186,818 взаимодействий. Бенчмарк предлагает две парадигмы оценки: задачи, ориентированные на топологию сети, и задачи, ориентированные на функции белков. Эксперименты показали, что современные модели PPI имеют ограничения в восстановлении структурных и функциональных свойств PPI-сетей.'}, 'en': {'title': 'Revolutionizing PPI Prediction with PRING: A Graph-Level Benchmark', 'desc': 'This paper introduces PRING, a new benchmark for evaluating protein-protein interaction (PPI) prediction models from a graph-level perspective. Unlike previous benchmarks that focused on pairwise evaluations, PRING assesses the ability of models to reconstruct meaningful PPI networks, which is essential for biological research. The benchmark includes a comprehensive dataset of 21,484 proteins and 186,818 interactions, addressing issues like data redundancy and leakage. The evaluation framework consists of topology-oriented and function-oriented tasks, revealing limitations in current PPI models and guiding future improvements in PPI prediction.'}, 'zh': {'title': 'PRING：蛋白质相互作用预测的新基准', 'desc': '本论文介绍了一种新的基准测试工具PRING，用于评估蛋白质-蛋白质相互作用（PPI）预测模型的能力。与以往的评估方法不同，PRING从图级别的角度出发，关注模型重建生物学意义的PPI网络。该基准数据集包含21,484个蛋白质和186,818个相互作用，旨在解决数据冗余和泄漏问题。通过拓扑导向和功能导向的评估任务，PRING帮助研究人员更好地理解PPI网络的结构和功能。'}}}, {'id': 'https://huggingface.co/papers/2507.06219', 'title': 'Is Diversity All You Need for Scalable Robotic Manipulation?', 'url': 'https://huggingface.co/papers/2507.06219', 'abstract': 'Investigation into data diversity in robotic manipulation reveals that task diversity is crucial, multi-embodiment data is optional, and expert diversity can be confounding, leading to a distribution debiasing method for improved performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Data scaling has driven remarkable success in foundation models for Natural Language Processing (NLP) and Computer Vision (CV), yet the principles of effective data scaling in robotic manipulation remain insufficiently understood. In this work, we investigate the nuanced role of data diversity in robot learning by examining three critical dimensions-task (what to do), embodiment (which robot to use), and expert (who demonstrates)-challenging the conventional intuition of "more diverse is better". Throughout extensive experiments on various robot platforms, we reveal that (1) task diversity proves more critical than per-task demonstration quantity, benefiting transfer from diverse pre-training tasks to novel downstream scenarios; (2) multi-embodiment pre-training data is optional for cross-embodiment transfer-models trained on high-quality single-embodiment data can efficiently transfer to different platforms, showing more desirable scaling property during fine-tuning than multi-embodiment pre-trained models; and (3) expert diversity, arising from individual operational preferences and stochastic variations in human demonstrations, can be confounding to policy learning, with velocity multimodality emerging as a key contributing factor. Based on this insight, we propose a distribution debiasing method to mitigate velocity ambiguity, the yielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to using 2.5 times pre-training data. Collectively, these findings provide new perspectives and offer practical guidance on how to scale robotic manipulation datasets effectively.', 'score': 2, 'issue_id': 4715, 'pub_date': '2025-07-08', 'pub_date_card': {'ru': '8 июля', 'en': 'July 8', 'zh': '7月8日'}, 'hash': 'd4781dc7e2730cb8', 'authors': ['Modi Shi', 'Li Chen', 'Jin Chen', 'Yuxiang Lu', 'Chiming Liu', 'Guanghui Ren', 'Ping Luo', 'Di Huang', 'Maoqing Yao', 'Hongyang Li'], 'affiliations': ['AgiBot', 'Beihang University', 'Shanghai AI Lab', 'Shanghai Innovation Institute', 'The University of Hong Kong'], 'pdf_title_img': 'assets/pdf/title_img/2507.06219.jpg', 'data': {'categories': ['#optimization', '#transfer_learning', '#robotics', '#data', '#dataset', '#training'], 'emoji': '🤖', 'ru': {'title': 'Ключ к эффективному обучению роботов: разнообразие задач важнее разнообразия платформ', 'desc': 'Исследование разнообразия данных в робототехнической манипуляции показало, что разнообразие задач имеет решающее значение, в то время как использование данных от нескольких роботов необязательно. Разнообразие экспертов может вносить путаницу, что привело к разработке метода дебиасинга распределения для улучшения производительности. Модели, обученные на высококачественных данных от одного робота, могут эффективно переноситься на другие платформы. Предложенный метод GO-1-Pro, снижающий неоднозначность скорости, позволяет достичь значительного прироста производительности в 15%.'}, 'en': {'title': 'Diversity in Data: Key to Better Robot Learning', 'desc': 'This paper explores the importance of data diversity in robotic manipulation, focusing on three key aspects: task diversity, embodiment diversity, and expert diversity. It finds that having a variety of tasks is more beneficial than simply increasing the number of demonstrations for each task. The study also shows that using data from a single robot can be just as effective as using data from multiple robots for training. Additionally, it highlights that differences in how experts demonstrate tasks can complicate learning, leading to the development of a new method to reduce confusion caused by these variations, resulting in significant performance improvements.'}, 'zh': {'title': '任务多样性是机器人操作的关键', 'desc': '本研究探讨了数据多样性在机器人操作中的重要性，发现任务多样性是关键，而多种机器人形态的数据是可选的。通过对不同机器人平台的广泛实验，我们发现任务多样性比每个任务的演示数量更为重要，有助于从多样的预训练任务转移到新的下游场景。我们还提出了一种分布去偏方法，以减少速度模糊，从而显著提高性能。整体而言，这些发现为有效扩展机器人操作数据集提供了新的视角和实用指导。'}}}, {'id': 'https://huggingface.co/papers/2507.04610', 'title': 'any4: Learned 4-bit Numeric Representation for LLMs', 'url': 'https://huggingface.co/papers/2507.04610', 'abstract': 'any4 is a learned 4-bit weight quantization method for LLMs that achieves high accuracy without preprocessing and uses a GPU-efficient lookup table strategy.  \t\t\t\t\tAI-generated summary \t\t\t\t We present any4, a learned 4-bit weight quantization solution for large language models (LLMs) providing arbitrary numeric representations without requiring pre-processing of weights or activations. any4 yields higher accuracy compared to other related 4-bit numeric representation types: int4, fp4 and nf4, as evaluated on a range of model sizes, generations and families (Llama 2, Llama 3, Mistral and Mixtral). While any4 does not require preprocessing of weights or activations, it is also competitive with orthogonal techniques that require such preprocessing (e.g., AWQ and GPTQ). We also experiment with any3 and any2 and show competitiveness at lower bits. Additionally, we show that we can calibrate using a single curated diverse sample rather than hundreds of samples from a dataset as done in most quantization approaches. We also open source tinygemm, a latency optimized GPU matrix multiplication library for LLMs, that implements any4 using a GPU-efficient lookup table strategy along with other common quantization methods. We open source our code at https://github.com/facebookresearch/any4 .', 'score': 2, 'issue_id': 4715, 'pub_date': '2025-07-07', 'pub_date_card': {'ru': '7 июля', 'en': 'July 7', 'zh': '7月7日'}, 'hash': '677d34e801c63489', 'authors': ['Mostafa Elhoushi', 'Jeff Johnson'], 'affiliations': ['FAIR at Meta'], 'pdf_title_img': 'assets/pdf/title_img/2507.04610.jpg', 'data': {'categories': ['#open_source', '#optimization', '#inference', '#training'], 'emoji': '🧠', 'ru': {'title': 'any4: Эффективная квантизация LLM без компромиссов', 'desc': 'Статья представляет any4 - метод обучаемой 4-битной квантизации весов для больших языковых моделей (LLM). Этот метод обеспечивает высокую точность без предварительной обработки весов или активаций, превосходя другие 4-битные представления. any4 использует эффективную для GPU стратегию поиска по таблице и конкурентоспособен с методами, требующими предобработки. Исследователи также экспериментировали с any3 и any2, показав их эффективность при меньшем количестве битов.'}, 'en': {'title': 'any4: Efficient 4-Bit Weight Quantization for High-Accuracy LLMs', 'desc': 'The paper introduces any4, a novel method for quantizing weights in large language models (LLMs) to 4 bits, which maintains high accuracy without the need for preprocessing. This method outperforms existing 4-bit representations like int4, fp4, and nf4 across various model sizes and families. Additionally, any4 allows for calibration using just one diverse sample, contrasting with traditional methods that require many samples. The authors also provide an open-source GPU-optimized library, tinygemm, to implement this quantization technique efficiently.'}, 'zh': {'title': 'any4：高效的4位权重量化方法', 'desc': 'any4是一种针对大型语言模型（LLMs）的学习型4位权重量化方法，能够在不需要预处理的情况下实现高精度的数值表示。与其他4位数值表示方法（如int4、fp4和nf4）相比，any4在多种模型规模和类型上表现出更高的准确性。该方法还可以使用单个多样化样本进行校准，而不是像大多数量化方法那样需要数百个样本。此外，我们开源了tinygemm，这是一个针对LLMs优化的GPU矩阵乘法库，采用了高效的查找表策略来实现any4。'}}}, {'id': 'https://huggingface.co/papers/2507.05578', 'title': 'The Landscape of Memorization in LLMs: Mechanisms, Measurement, and\n  Mitigation', 'url': 'https://huggingface.co/papers/2507.05578', 'abstract': 'The paper reviews recent studies on memorization in Large Language Models, exploring factors that influence memorization, detection methodologies, and mitigation strategies, while addressing privacy and ethical implications.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet they also exhibit memorization of their training data. This phenomenon raises critical questions about model behavior, privacy risks, and the boundary between learning and memorization. Addressing these concerns, this paper synthesizes recent studies and investigates the landscape of memorization, the factors influencing it, and methods for its detection and mitigation. We explore key drivers, including training data duplication, training dynamics, and fine-tuning procedures that influence data memorization. In addition, we examine methodologies such as prefix-based extraction, membership inference, and adversarial prompting, assessing their effectiveness in detecting and measuring memorized content. Beyond technical analysis, we also explore the broader implications of memorization, including the legal and ethical implications. Finally, we discuss mitigation strategies, including data cleaning, differential privacy, and post-training unlearning, while highlighting open challenges in balancing the minimization of harmful memorization with utility. This paper provides a comprehensive overview of the current state of research on LLM memorization across technical, privacy, and performance dimensions, identifying critical directions for future work.', 'score': 1, 'issue_id': 4715, 'pub_date': '2025-07-08', 'pub_date_card': {'ru': '8 июля', 'en': 'July 8', 'zh': '7月8日'}, 'hash': '9fd6f105854c8570', 'authors': ['Alexander Xiong', 'Xuandong Zhao', 'Aneesh Pappu', 'Dawn Song'], 'affiliations': ['Google DeepMind', 'University of California, Berkeley'], 'pdf_title_img': 'assets/pdf/title_img/2507.05578.jpg', 'data': {'categories': ['#healthcare', '#hallucinations', '#survey', '#data', '#training', '#ethics'], 'emoji': '🧠', 'ru': {'title': 'Запоминание в LLM: от технических аспектов до этических проблем', 'desc': 'Статья рассматривает недавние исследования запоминания в больших языковых моделях (LLM). Авторы изучают факторы, влияющие на запоминание, методологии его обнаружения и стратегии смягчения последствий. Рассматриваются такие аспекты, как дублирование обучающих данных, динамика обучения и процедуры тонкой настройки. Также обсуждаются правовые и этические последствия запоминания в LLM.'}, 'en': {'title': 'Understanding and Mitigating Memorization in Large Language Models', 'desc': 'This paper reviews how Large Language Models (LLMs) memorize information from their training data, which can lead to privacy concerns. It discusses factors that contribute to this memorization, such as data duplication and training methods. The paper also evaluates various techniques for detecting memorized data, like membership inference and adversarial prompting. Finally, it suggests strategies to reduce harmful memorization while maintaining model performance, highlighting the need for further research in this area.'}, 'zh': {'title': '大型语言模型的记忆现象与挑战', 'desc': '这篇论文回顾了关于大型语言模型（LLM）记忆现象的最新研究，探讨了影响记忆的因素、检测方法和缓解策略，同时关注隐私和伦理问题。研究表明，LLM在执行任务时会记住训练数据，这引发了关于模型行为和隐私风险的关键问题。论文分析了训练数据重复、训练动态和微调过程等关键驱动因素，并评估了前缀提取、成员推断和对抗性提示等检测方法的有效性。最后，论文讨论了数据清理、差分隐私和后训练遗忘等缓解策略，强调在减少有害记忆与保持模型效用之间的挑战。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents (2)', '#agi', '#alignment (1)', '#architecture (1)', '#audio', '#benchmark (5)', '#cv (1)', '#data (4)', '#dataset (4)', '#diffusion', '#ethics (1)', '#games (1)', '#graphs (1)', '#hallucinations (1)', '#healthcare (2)', '#inference (2)', '#interpretability (1)', '#leakage (1)', '#long_context', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal', '#open_source (3)', '#optimization (5)', '#plp', '#rag', '#reasoning (2)', '#rl (3)', '#rlhf (1)', '#robotics (1)', '#science', '#security', '#small_models', '#story_generation', '#survey (1)', '#synthetic', '#training (5)', '#transfer_learning (1)', '#video'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-07-09 02:49',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-07-09 02:49')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-07-09 02:49')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    