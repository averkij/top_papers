
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF (12 статей)</title>
    <link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0989eacf;
            --secondary-color: #fff;
            --background-color: #f5f5f5;
            --text-color: #333333;
            --header-color: #0989eacf;
            --body-color: #f5f5f5;
            --menu-color: #002370;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        header {
            padding: 3em 0;
            text-align: center;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2em;
            padding: 10px 0 20px 0;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.tags {
            color: #555;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
            transition: background-color 0.2s ease;
            display: flex;
            flex-direction: column;
            position: relative;
        }
        .article-content {
            padding: 1.5em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
        }
        body.dark-theme>div>main>article {
            background-color: #444;
        }
        body.light-theme>div>main>article {
            background-color: #fff;
        }
        body.dark-theme>div>main>article:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
        }
        .pub-date {
            font-size: 0.9em;
            margin-bottom: 0.8em;
            font-weight: 300;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 1em;
            position: absolute;
            bottom: 10px;
            font-weight: 300;
            font-family: 'Roboto Slab';
        }
        .background-digit {
            position: absolute;
            bottom: -20px;
            right: -10px;
            font-size: 12em;
            font-weight: bold;
            color: rgba(0, 0, 0, 0.03);
            z-index: 0;
            line-height: 1;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 80px;
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        a:hover {
            color: var(--secondary-color);
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 1em 0;
            margin-top: 2em;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
        }
        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
        }
        .update-info-container {
            flex: 1;
        }
        .sort-container {
            flex: 2;
        }
        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
                display: block;
                margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .category-toggle {
            display: inline-block;
            margin-bottom: 10px;
            margin-top: 15px;
            cursor: pointer;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }
        
        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .sort-container {
                margin-top: 0px;
                text-align: left;
                width: 100%;
            .sort-dropdown {
                float: right;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiffRu(dateString) {
        const timeUnits = {
            minute: ["минуту", "минуты", "минут"],
            hour: ["час", "часа", "часов"],
            day: ["день", "дня", "дней"]
        };

        function getRussianPlural(number, words) {
            if (number % 10 === 1 && number % 100 !== 11) {
                return words[0];
            } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                return words[1];
            } else {
                return words[2];
            }
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);

        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes == 0) {
            return 'только что';
        }
        else if (minutes < 60) {
            return `${minutes} ${getRussianPlural(minutes, timeUnits.minute)} назад`;
        } else if (hours < 24) {
            return `${hours} ${getRussianPlural(hours, timeUnits.hour)} назад`;
        } else {
            return `${days} ${getRussianPlural(days, timeUnits.day)} назад`;
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function formatArticlesTitle(number) {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;

        let word;

        if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
            word = "статей";
        } else if (lastDigit === 1) {
            word = "статья";
        } else if (lastDigit >= 2 && lastDigit <= 4) {
            word = "статьи";
        } else {
            word = "статей";
        }

        return `${number} ${word}`;
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p>25 октября | 12 статей</p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item" id="nav-prev"><a href="/d/2024-10-24.html">⬅️ 24.10</a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2024-10-28.html">➡️ 28.10</a></span>
            <!--<span class="nav-item" id="nav-weekly">Топ за неделю</span>
            <span class="nav-item" id="nav-weekly">Топ за месяц</span>-->
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 Сортировка по</label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="category-toggle">
            <div class="svg-container">
                <span id="category-toggle">🏷️ Фильтр</span>
                <svg height="3" width="200">
                    <line x1="0" y1="0" x2="200" y2="0" 
                        stroke="black" 
                        stroke-width="2" 
                        stroke-dasharray="3, 3" />
                </svg>
            </div>
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">градиент обреченный</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>    
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2410.17243', 'title': 'Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss', 'url': 'https://huggingface.co/papers/2410.17243', 'abstract': 'Contrastive loss is a powerful approach for representation learning, where larger batch sizes enhance performance by providing more negative samples to better distinguish between similar and dissimilar data. However, scaling batch sizes is constrained by the quadratic growth in GPU memory consumption, primarily due to the full instantiation of the similarity matrix. To address this, we propose a tile-based computation strategy that partitions the contrastive loss calculation into arbitrary small blocks, avoiding full materialization of the similarity matrix. Furthermore, we introduce a multi-level tiling strategy to leverage the hierarchical structure of distributed systems, employing ring-based communication at the GPU level to optimize synchronization and fused kernels at the CUDA core level to reduce I/O overhead. Experimental results show that the proposed method scales batch sizes to unprecedented levels. For instance, it enables contrastive training of a CLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GB without sacrificing any accuracy. Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed. The code will be made publicly available.', 'score': 12, 'issue_id': 257, 'pub_date': '2024-10-22', 'pub_date_ru': '22 октября', 'hash': '29bd02d560e09f69', 'data': {'desc': 'В статье представлен новый подход к вычислению контрастивной функции потерь, позволяющий значительно увеличить размер батча без роста потребления памяти GPU. Авторы предлагают стратегию вычислений на основе тайлинга, которая разбивает расчет контрастивной функции потерь на небольшие блоки. Также вводится многоуровневая стратегия тайлинга для оптимизации распределенных вычислений. Экспериментальные результаты показывают, что предложенный метод позволяет достичь беспрецедентных размеров батча при обучении моделей вроде CLIP-ViT-L/14.', 'emoji': '🧩', 'title': 'Эффективное масштабирование контрастивного обучения с помощью тайлинга', 'categories': ['#optimization', '#architecture'], 'embedding': [0.022229966375398383, -0.05951852785441825, 0.09505579954819926, 0.06585899033610607, -0.03510263889807038, -0.02786735312309707, 0.10011794159315522, -0.06923375304931241, -0.1591251432977343, 0.020619284447484475, -0.03484697481072402, -0.0009707234312733092, 0.0005668545194560283, -0.044076435607350424, 0.022076567518019848, 0.01330730045873404, 0.03566509867532025, 0.017474620020345923, -0.03295506096933159, -0.023227054898651723, -0.05568357059392986, -0.034412346064720545, 0.0646829391790492, -0.05726868874541878, 0.03484697481072402, -0.06181950464053558, 0.057882280125225775, -0.06688164263578439, 0.08528943870104082, -0.06928488060216238, 0.00429195577888257, -0.04136640195106892, -0.07480722326896111, -0.09986227548095526, 0.030296158915607215, 0.06631918893309525, -0.005602232657271193, 0.15196655695145025, -0.03211137332831037, 0.05108162512110951, 0.0213734938088843, -0.06074571466373939, 0.027023661432368694, 0.06432500783688141, -0.0496499078518527, 0.05466091829425153, 0.041928861728318785, 0.009261421085504982, -0.09730563460749156, 0.10062926166843365, -0.08569849759605856, 0.0704098021815157, -0.11811667066397959, 0.0008612673590416918, 0.020350837459498824, -0.01298772004582304, -0.00285384705930612, 0.014419437922535923, 0.09674317078053454, -0.012112071508467173, 0.04732336526445681, -0.09602732024532046, 0.05174635012832721, -0.09766356797451294, -0.03880976107760522, 0.0323414695895246, -0.04180102867221882, 0.03597189436522375, -0.02269016092268042, 0.08073862685563117, -0.0012231913682406073, -0.06253536125031041, 0.011677443977375848, -0.09689657368762024, -0.019558279396181148, -0.0019062931365927695, -0.014470569930063765, 0.04686317071717478, 0.09556712569803842, -0.018995819618931282, 0.04364181091105411, 0.019494362868131162, 0.09372634143434956, 0.027253759718436497, 0.025221231945158396, -0.08273280390213784, -0.051362857034588025, -0.039346655053576526, -0.06514313372633124, 0.019673327526788263, 0.07368229966475423, 0.015991769123678407, -0.027074795059779395, -0.017640801778363743, 0.0614615732983678, -0.01286628005992557, 0.09924868410114827, -0.04259358471068291, 0.07864218255430308, 0.04356510945751126, -0.03702011449103421, 0.02510618381455128, 0.04499682672676807, -0.10553800890571823, 0.0907095080384574, -0.05466091829425153, 0.019494362868131162, -0.0276116890357507, 0.012911021224589845, 0.08104542052068109, -8.11932267324766e-05, 0.0333641239140565, -0.014355521394485935, -0.039142124593640866, -0.015339827017099992, -0.11924159021847931, -0.014892415370457239, 0.06585899033610607, -0.019788377682248955, -0.027713954265718533, -0.0052155409023344965, -0.017653584679003027, 0.051695216500916505, -0.006420357129323503, 0.05742208557794374, -0.061103646005907175, 0.052078713644362847, -0.0693871559563981, -0.015940635496267706, 0.018395009114909995, -0.07005187893876222, 0.012054547240678257, 0.09689657368762024, 0.0267679993698759, -0.044076435607350424, 0.012425259863602456, -0.09403313914910663, 0.055632438991372726, -0.0013582138694553975, -0.030884184494135648, -0.00800227661961492, 0.029196805162386045, 0.046070614678710674, 0.00733755059997043, -0.09060724483334315, 0.03755701251671267, 0.006544992941623472, 0.050289067057791834, -0.13171798067221213, 0.1313089197523408, -0.032162504930867496, -0.02068320097553446, -0.029733699138357352, -0.052973536937648356, -0.09413540235422088, -0.11034449293788855, -0.05054473114513821, 0.05675736057072604, -0.022332231605366216, -0.11474191200048038, 0.048192624781317334, -0.019571062296820433, 0.09219235893512491, 0.07102339963588343, 0.08150561304310955, 0.0523599415081342, -0.03425894720734201, 0.0822214757274451, -0.1345814273598472, -0.1223095552169286, 0.061308174440989266, -0.005742847601583659, -0.02684469677371159, -0.10604933708041096, 0.06601239324319176, 0.021641938772016377, -0.13631992614503247, -0.06841563120956975, -0.020107956272791733, -0.012757623177152738, -0.021795337629394916, 0.10119172549539067, -0.0015795228735962386, 0.07189265307818321, -0.11975291839317206, -0.06887582373199821, -0.02620553959262603, 0.02041475196269523, 0.022229966375398383, 0.006417161100435646, -0.09495352419396354, 0.028659909161561165, 0.04502239455290022, 0.08094315731556684, 0.058240211467393554, -0.04412757125961471, 0.13192251113214779, 0.036380957309948656, -0.030270591089475076, -0.028046315756900593, 0.008583911152794424, 0.03937222287970867, 0.06442727104199567, -0.03464244030108119, 0.055836969451308394, -0.17968050514260805, -0.05021236762910256, -0.022140484046069837, -0.05614376919091905, 0.053126933770173315, -0.014381088208191287, 0.1028279772742903, 0.04062497549030838, -0.06795543666228773, 0.006691999741226295, -0.11576456025045155, -0.12271861411194636, 0.06386481328959938, 0.02005682467023461, 0.07787519231711756, -0.03893759615855878, -0.037326912205791284, -0.022830776879419677, -0.043820771520004055, -0.14296719646574524, 0.00011245211848067555, 0.09270368913467124, -0.1285477484189414, 0.08753927983489385, -0.07853991124977451, 0.01856119087292781, -0.004563598390785363, -0.05023793343038113, -0.0008724526502077607, 0.05941626262445041, -0.10962863025355297, -0.022140484046069837, -0.07020527779614076, -0.009913363192083401, -0.0767502646632035, -0.043820771520004055, 0.06575672510613823, -0.014534486053143036, -0.0838065878043733, -0.05292240331023765, 0.07276191259504373, -0.11668495541957635, -0.045329190242803706, 0.018983034693438424, -0.0010162636031595489, -0.055376774904026364, 0.009644916204097749, -0.10032246395367657, -0.04660750865468198, -0.07639233939559646, 0.005551099637316561]}}, {'id': 'https://huggingface.co/papers/2410.18975', 'title': 'Unbounded: A Generative Infinite Game of Character Life Simulation', 'url': 'https://huggingface.co/papers/2410.18975', 'abstract': "We introduce the concept of a generative infinite game, a video game that transcends the traditional boundaries of finite, hard-coded systems by using generative models. Inspired by James P. Carse's distinction between finite and infinite games, we leverage recent advances in generative AI to create Unbounded: a game of character life simulation that is fully encapsulated in generative models. Specifically, Unbounded draws inspiration from sandbox life simulations and allows you to interact with your autonomous virtual character in a virtual world by feeding, playing with and guiding it - with open-ended mechanics generated by an LLM, some of which can be emergent. In order to develop Unbounded, we propose technical innovations in both the LLM and visual generation domains. Specifically, we present: (1) a specialized, distilled large language model (LLM) that dynamically generates game mechanics, narratives, and character interactions in real-time, and (2) a new dynamic regional image prompt Adapter (IP-Adapter) for vision models that ensures consistent yet flexible visual generation of a character across multiple environments. We evaluate our system through both qualitative and quantitative analysis, showing significant improvements in character life simulation, user instruction following, narrative coherence, and visual consistency for both characters and the environments compared to traditional related approaches.", 'score': 8, 'issue_id': 257, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '2d7a29df8d1696c4', 'data': {'desc': 'Статья представляет концепцию генеративной бесконечной игры, которая использует генеративные модели для создания видеоигры, выходящей за рамки традиционных конечных систем. Авторы разработали игру Unbounded - симулятор жизни персонажа, полностью основанный на генеративных моделях. В игре используется специализированная языковая модель для генерации игровых механик и нарратива, а также новый адаптер для визуальных моделей, обеспечивающий согласованную генерацию изображений персонажа. Результаты показывают значительные улучшения в симуляции жизни персонажа, следовании инструкциям пользователя и согласованности повествования по сравнению с традиционными подходами.', 'emoji': '🎮', 'title': 'Бесконечная игра: новый уровень генеративных видеоигр', 'categories': ['#games', '#multimodal', '#cv', '#rl'], 'embedding': [0.02503823369079383, 0.012018353158676257, 0.12064136691370886, 0.06386895968012177, -0.032821549409989804, -0.10450244028840984, 0.017483841804416114, -0.005182914748267926, 0.02047412338275822, 0.06295327463109056, 0.04192115865985548, -0.08561645645956881, -0.06329665832386959, -0.07153781348290862, 0.010108293063643022, -0.032564014210966004, -0.020974887069478882, -0.07731806828587685, 0.040547632114532856, -0.013420493743587308, 0.06535695225475027, -0.025524691694411714, -0.01736937988800698, 0.04071932293269818, 0.008362770225466802, -0.05322413512321651, 0.017812916729419814, 0.1716907564718774, -0.002144345911337761, -0.050877692570658106, 0.09242685411508064, -0.023650400434144243, -0.029731114683013895, -0.06587202059634951, 0.005436873783572087, 0.07680299994427761, 0.030475108913879775, 0.0619231358914437, -0.006674478345495149, 0.002375055563922642, -0.039231338583863164, -0.10421629166673212, 0.018056145217116668, 0.0774325281458376, -0.10124031063037185, 0.14605159566348727, -0.007468547711164072, 0.026197147227521887, -0.03296462269260448, 0.13037050847803128, -0.11096946042048776, 0.0235073250950812, 0.04094824676551644, 0.059290542660759206, -0.04000394623738295, -0.05024816025620136, -0.04784449085833513, 0.003809388614234972, -0.03161971368283251, -0.0029115889079884103, -0.015695396981455494, -0.026755141872447114, 0.04890324713353264, 0.1212136723828578, -0.10805071651167718, -0.035683062360595826, -0.15841333868428764, 0.035253836343406696, -0.02706991008612386, 0.1049030508264967, 0.034309533758824826, -0.028443434574998115, 0.013642261547359215, 0.029173120038088668, -0.06169421205862543, 0.06255266614945208, 0.006484903007124521, -0.010065370050634435, -0.09248408712973358, -0.029988651938486075, 0.046957423344854574, 0.030360649053919015, -0.040747938411800466, -0.013849721200290304, -0.018342295895242756, 0.03825842463307575, 0.07434209753175844, -0.014922788299711514, -0.039288569542067726, 0.020631505433148224, 0.008749075286095722, -0.023693324681021855, -0.0678178505543727, 0.06615816510513048, 0.052623218287862046, 0.04335191616338267, 0.0345384575916431, -0.03788642751764282, 0.13403323839191425, 0.0639834215965309, 0.013577877233491168, 0.023807784540982615, 0.06083575796779879, -0.03347969925999721, 0.09214070549340292, 0.03379446336077722, -0.041835314278997005, 0.021590112672608675, -0.009070995415922085, -0.014357639270898625, -0.18279341841217733, -0.007014282789881973, 0.003122625752863332, 0.035139376483445936, 0.004077655389090275, -0.04289407261064288, -0.03911687666745403, -0.041291626345398735, 0.02545315505310438, -0.06032068345685443, -0.012340273699792294, 0.12922592016066553, 0.029473579483990087, -0.05371059209861022, 0.11497557608359814, -0.09586066842193884, 0.011803739738792014, 0.01659677223448719, 0.002269537141485181, 0.000345169944399801, -0.0009720200538088792, 0.03765750574127292, -0.07583008188059345, -0.07651684515325477, -0.12602101117859024, -0.017727070292112967, -0.10307168072843427, 0.01716907564718774, -0.00010859216291654949, -0.03499630114438289, -0.03273570502913133, -0.0447826716104615, -0.03179140552922202, 0.004174231345780249, -0.019315209846030162, 0.03153386827374984, 0.01244757999844474, 0.10896639744781164, 0.020001973118691476, 0.021790416913427913, 0.01069490318767053, -0.09196901878813434, -0.05459765961209077, 0.01716907564718774, -0.005215106596734693, -0.10393013481926092, -0.06444126103637395, 0.12796683908016507, -0.031905864360958595, 0.0015550532121018765, 0.018800137391534175, 0.0868755210884823, 0.04867433152650786, 0.024279934805049364, -0.010780748596753195, -0.05831762665352343, -0.05765947885996439, 0.058775468149814845, -0.1116562216367007, 0.05754501900000363, 0.001350276196072614, -0.007071512925507192, -0.1259065513186295, -0.07273965126651429, 0.03342246830179264, -0.09797819331102409, -0.06438403419106611, -0.058203164737114295, -0.031018794791029675, -0.042808228229784404, -0.004217154153143999, 0.026225762706624176, -0.09431545517134764, -0.020531352284514418, -0.019014750400128747, 0.04137747278270558, -0.005858946856387419, 0.04927524630541395, 0.004367383670449872, -0.07520055367903344, -0.05494104124842142, 0.05848931952813713, 0.12212936360123412, 0.09299915547133283, 0.12922592016066553, -0.08641767753574252, 0.13975628074471327, 0.0025860919975078897, 0.12441856491334609, -0.0209462715903766, 0.12018353158676257, 0.003888080256364484, 0.14341901271504465, -0.12201490168482498, -0.016611081002262516, 0.035511371542430496, 0.039546104741091534, 0.0481592570155635, -0.05488381234666523, -0.03396615623539091, 0.10982485153863827, -0.0193581320364594, 0.028586509914061163, -0.10793625665171641, -0.046270658015744884, 0.011939661722191582, 0.10255661033038665, 0.09013764869007193, 0.04855986961009873, 0.07834821525131719, -0.046356504453051735, 0.07560116010422356, -0.03682766507310019, 0.019057672590557982, 0.03224924805373763, -0.04212146701357146, -0.04163500798172939, -0.0732547216645619, 0.03362277254261188, 0.0008034590678084453, 0.07016429105048273, -0.02897281579726943, -0.061350828365846405, -0.16344960131283837, -0.04349499150244572, -0.035339680724265174, 0.012862499304306921, 0.09740588784187518, 0.0346242999160532, -0.035253836343406696, 0.03651289891587182, 0.040633476495391334, 0.03782919655943825, -0.0009881160397357135, -0.019615669291931582, 0.053882278803878796, -0.06793231041433345, -0.028071437459565175, 0.11131283588747329, 0.04295130356884745, -0.052737678147822806, -0.09689081950027593, -0.042178695915327656, 0.02789974869784822, 0.03542552716157202, -0.06369726886195644]}}, {'id': 'https://huggingface.co/papers/2410.18693', 'title': 'Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch', 'url': 'https://huggingface.co/papers/2410.18693', 'abstract': 'The availability of high-quality data is one of the most important factors in improving the reasoning capability of LLMs. Existing works have demonstrated the effectiveness of creating more instruction data from seed questions or knowledge bases. Recent research indicates that continually scaling up data synthesis from strong models (e.g., GPT-4) can further elicit reasoning performance. Though promising, the open-sourced community still lacks high-quality data at scale and scalable data synthesis methods with affordable costs. To address this, we introduce ScaleQuest, a scalable and novel data synthesis method that utilizes "small-size" (e.g., 7B) open-source models to generate questions from scratch without the need for seed data with complex augmentation constraints. With the efficient ScaleQuest, we automatically constructed a mathematical reasoning dataset consisting of 1 million problem-solution pairs, which are more effective than existing open-sourced datasets. It can universally increase the performance of mainstream open-source models (i.e., Mistral, Llama3, DeepSeekMath, and Qwen2-Math) by achieving 29.2% to 46.4% gains on MATH. Notably, simply fine-tuning the Qwen2-Math-7B-Base model with our dataset can even surpass Qwen2-Math-7B-Instruct, a strong and well-aligned model on closed-source data, and proprietary models such as GPT-4-Turbo and Claude-3.5 Sonnet.', 'score': 7, 'issue_id': 258, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': 'd898ba7b025b60e6', 'data': {'desc': 'Статья представляет ScaleQuest - новый метод синтеза данных для улучшения способностей ЯБМ к рассуждениям. Используя небольшие модели с открытым исходным кодом, ScaleQuest генерирует вопросы с нуля без необходимости в исходных данных. С помощью этого метода был создан набор данных из 1 миллиона пар задача-решение для математических рассуждений. Применение этого набора данных значительно повысило производительность открытых моделей на тесте MATH, позволив некоторым из них превзойти даже проприетарные модели.', 'emoji': '🧮', 'title': 'ScaleQuest: Масштабируемый синтез данных для повышения математических способностей ЯБМ', 'categories': ['#dataset', '#data', '#training', '#math'], 'embedding': [0.0852959909632398, -0.011005341540181665, 0.16598139317102004, -0.03543780970321843, 0.037056425728729275, 0.016774715081450575, -0.0635182920100605, 0.0787724913007622, -0.12164120503212313, 0.01876119485652982, 0.06817793767614287, -0.05351232232567685, -0.10378741454125823, -0.03663951089131677, 0.10565127241950593, -0.021863534475053993, 0.020330757853270327, -0.06783459558864405, -0.06194872707239376, 0.06214492560099146, 0.05414995735375662, 0.018785718459525636, -0.009840430802985257, -0.050765585625686276, 0.07901773509442529, 0.0037430420864278183, -0.011569403236069892, -0.03318156447240652, 0.03732619312538817, -0.055719520350497126, 0.10388551865787268, -0.04556640516628611, -0.10780942712018705, -0.028987884731580753, 0.0077742461156413275, 0.04036722470688593, -0.0035652400448831427, -0.017044484419035718, 0.015609804150161546, 0.001018530544584027, 0.03325513528139396, -0.09088756459798289, -0.05547427655683403, 0.03330418636923806, -0.01091337482641907, -0.08269640364492906, 0.07298472690112635, -0.0017320383201675136, 0.010661998870404974, 0.10417980771660115, -0.022292713054890636, 0.07955727765144804, -0.013463916103293916, -0.0277126146754212, 0.016603044037701166, -0.07857629859494322, -0.006480582483818108, 0.010459672837679236, -0.06307685356965219, -0.018123559828450046, 0.06371449442051066, -0.120856424504216, -0.003022636841278347, 0.051010829419349375, -0.003359847930981902, -0.03266654940023205, -0.014837284453289197, -0.014555253508298773, -0.058073865816071005, 0.10231595566113216, -0.03428516154389042, 0.06548024818214393, 0.07411285145745855, 0.006109650323962722, 0.009245712759472339, -0.0067871381963600895, 0.053806615266257796, 0.12056213544548752, -0.047160493706948664, -0.04740573944153799, -0.0071488734713373294, -0.03590377756940127, 0.03614902136306435, -0.10898660276436335, -0.002719147015819246, 0.046620956972704616, 0.020441116978140845, 0.033966345000313654, -0.08652221381340772, -0.13086239030674718, -0.05851530619740555, -0.06150729251383792, 0.04539473218161046, -0.044389229522109816, 0.0833340367320826, 0.03914100185671801, 0.054983787028581615, 0.04873005864461541, 0.07391665292886085, 0.04034269722203764, -0.09412479082622587, -0.04951483917252254, 0.04073509233830681, -0.03428516154389042, 0.03739976587530186, 0.031244133844245143, 0.020392069772149215, 0.07592766018878838, -0.03742429336015014, 0.06185063071948426, -0.1573487937775579, -0.0618996837482546, -0.10751513612053233, -0.08666936319508756, -0.04865648395377549, -0.14204554145808587, -0.047920750631859986, -0.043457303494375314, 0.06170348133780443, 0.020710888256652224, 0.03386824670647792, 0.030189582037826627, 0.030116009287912946, 0.04757740854436117, 0.15568113054605542, -0.022942611825394556, 0.04657190394393428, -0.061801575749787695, 0.08186257397010406, 0.005364720699446941, -0.024781944159720203, 0.05547427655683403, 0.12193549797270409, 0.026363769928421737, -0.11085045481983234, -0.021728651747187657, -0.1783417044391251, 0.00988334856392261, 0.0033843723103482107, -0.06587264135748686, 0.005904258015968857, -0.011299634286669998, -0.03585473036340964, 0.11654012480748493, -0.10937898817600133, -0.04514948838794737, 0.029110506628412303, -0.020330757853270327, -0.03014053289090876, 0.09809774649453189, -0.03502089486580593, -0.05037319633219583, -0.03914100185671801, 0.05464044688200904, -0.005413769264086935, -0.0930947645637294, -0.07838009812541928, 0.0029107439964958927, 0.0592510414602473, -0.08848416804456491, 0.04926959537885946, 0.12105262303281371, -0.01797641238769645, -0.053414224031841116, 0.02485551885056012, 0.12124881573863268, -0.11840398462665887, -0.031489379578834464, -0.17137676051346049, -0.10525888312601549, -0.0099507901219484, 0.0075044777485193045, -0.016529471287787485, -0.016075769104955027, 0.0004337759935848113, -0.027884283778244378, -0.10447410453903459, -0.05993772563524494, -0.005444425029433758, -0.05164846638835538, -0.09348715773907233, 0.03193081607831655, -0.12252409355849718, 0.07695768645128484, -0.03330418636923806, 0.020134563206525104, -0.055768569497414995, 0.009938528320450493, 0.04355539984728481, 0.0011978655296701428, -0.05993772563524494, 0.033377759119151744, 0.1267422891386138, 0.07901773509442529, 0.052580392416089874, -0.0709737235230513, 0.08652221381340772, 0.05066748927277679, 0.03107246280049573, 0.0018761194856529821, -0.003546846663312099, -0.016026718987574046, 0.024585747572048743, -0.12909664236789264, -0.012985689929280397, -0.022415335922185302, -0.02859549349716407, -0.08465836175793873, -0.10908469911727285, -0.06557834647597967, 0.039410771194303154, 0.04676810053160574, 0.04429113316920032, 0.0132064095376698, 0.010655868260794956, -0.01188822075010978, -0.07676148986361338, 0.03315703892848447, 0.053953760766085164, 0.07622194924751687, -0.06263540930646516, 0.02501492518142227, 0.05086368003766954, -0.0700417916725381, -0.031219608300323092, -0.01227448156900907, 0.055670473144505496, 0.023886802566016312, 0.027467368940831877, -0.08353023526068029, 0.007737460322962359, -0.0431139614068765, -0.05846625899141392, 0.028154055056755757, 0.025726134900341962, -0.022194615731518024, 0.0457135526070397, -0.004307104558686538, -0.027222125147168787, -0.05856435534432342, 0.06175253436657477, -0.008841059917650369, 0.013954405243361086, 0.03686022914105781, 0.09127995583239958, 0.09059326777554946, -0.04080866508822048, -0.0917213942728079, 0.03443230898464402, -0.03825812109404891, 0.05616096073183168, -0.06655932165063203, -0.017216155462785127, -0.10241405201404166, -0.055719520350497126, -0.052629441563007744]}}, {'id': 'https://huggingface.co/papers/2410.18533', 'title': 'LOGO -- Long cOntext aliGnment via efficient preference Optimization', 'url': 'https://huggingface.co/papers/2410.18533', 'abstract': "Long-context models(LCMs) have shown great potential in processing long input sequences(even more than 100M tokens) conveniently and effectively. With significant progress, recent research has pointed out that LCMs can accurately locate token-level salient information within the context. Yet, the generation performance of these LCMs is far from satisfactory and might result in misaligned responses, such as hallucinations. To enhance the generation capability of LCMs, existing works have investigated the effects of data size and quality for both pre-training and instruction tuning. Though achieving meaningful improvement, previous methods fall short in either effectiveness or efficiency. In this paper, we introduce LOGO(Long cOntext aliGnment via efficient preference Optimization), a training strategy that first introduces preference optimization for long-context alignment. To overcome the GPU memory-bound issue caused by the long sequence, LOGO employs a reference-free preference optimization strategy and adopts a position synthesis method to construct the training data. By training with only 0.3B data on a single 8timesA800 GPU machine for 16 hours, LOGO allows the Llama-3-8B-Instruct-80K model to achieve comparable performance with GPT-4 in real-world long-context tasks while preserving the model's original capabilities on other tasks, e.g., language modeling and MMLU. Moreover, LOGO can extend the model's context window size while enhancing its generation performance.", 'score': 6, 'issue_id': 258, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '3094f5b6fc1c0168', 'data': {'desc': 'Эта статья представляет новый метод обучения под названием LOGO для улучшения генеративных способностей моделей с длинным контекстом (LCM). LOGO использует оптимизацию предпочтений без эталона и метод синтеза позиций для создания обучающих данных. Авторы обучили модель Llama-3-8B-Instruct-80K всего на 0.3B данных за 16 часов, достигнув производительности, сравнимой с GPT-4 на задачах с длинным контекстом. LOGO также позволяет расширить размер контекстного окна модели, сохраняя при этом ее исходные возможности в других задачах.', 'emoji': '🚀', 'title': 'LOGO: Эффективное улучшение генерации для моделей с длинным контекстом', 'categories': ['#training', '#alignment', '#hallucination'], 'embedding': [0.048512824375524, 0.009356783357077658, 0.0942283273904845, -0.0033088697541577322, -0.04405782631827572, 0.0058245172022745595, 0.038126466746331654, 0.045326982960862815, -0.07138352370594425, 0.08754582534147848, 0.022754145100919033, -0.02724799258274761, -0.04392832228058107, -0.06392399544551693, 0.015281668223450342, -0.04149361540196809, 0.03615798274148385, -0.07532049171563986, -0.0050312948962336545, 0.06682492122738819, 0.005057196299348615, -0.013585144285964034, -0.020371240432959944, 0.04838331835257591, 0.02678177169423588, -0.03382688028417865, -0.007893370459423248, 0.07521688530907863, 0.08127775884498455, -0.09044675707911007, 0.08578455414975311, -0.06775736498966507, -0.06734294134867364, -0.009473339571832308, -0.07506147966974369, 0.07205694946656464, 0.03553635422838373, 0.0011048451563173448, 0.007401248564847246, 0.031366269818671924, -0.08961791376763407, -0.08246920472689041, -0.028128631156490454, 0.030045313943311096, 0.07159073453381323, 0.10059999830828621, -0.011415924754394631, 0.13655077419240796, -0.08537013050876167, 0.09345128728228912, -0.03913661134302259, 0.12132090242237652, -0.07433624673533579, 0.02384199251727744, -0.04089788849050828, -0.03709042253325386, -0.02539606082214757, -0.0024298499560704012, 0.03970643665284209, 0.07247137112230265, 0.01939994823872947, -0.08930710645947106, 0.05185406745901324, 0.012620326797304935, -0.04201163552325355, -0.013008843674997125, -0.06998485905515561, 0.00931145684462186, -0.02560326966476313, 0.013352034437284204, -0.027170287777826697, -0.04338439857240187, -0.015527729270001012, -0.007899845562045307, -0.01608460477162709, 0.024398866033650074, 0.05946900135877552, 0.060401441150545535, 0.04470535643301614, -0.04413552913794319, -0.010541761283273844, 0.0340081875251539, 0.06527085292251805, -0.07407723865994652, 0.057189702104750925, 0.039991350300378564, -0.027869619110594285, 0.10650545826384342, -0.03659830202835527, -0.05874377040962106, -0.008333689547769326, -0.012361315545510142, -0.02570687507869763, 0.02442476763529038, 0.05162095701475738, -0.007239366631738174, 0.059572603794829856, -0.09086117873484806, 0.06558167015694827, 0.10163604649187089, -0.03193609711374487, -0.06552986099790734, 0.13251018786463045, -0.06915602169943995, 0.0013662847701207542, 0.02565507286804374, -0.023816090915637134, -0.034396703608744715, -0.02529245640083979, 0.010010788177389452, -0.10888836392442922, 0.045067972900220084, -0.1244290350616099, 0.08847826910375538, 0.03563995864969151, -0.09650761671824189, -0.07873944754506379, 0.013727600117105552, 0.04377291267073924, 0.005138137067377808, 0.007194039722231687, 0.03289443850715519, 0.022922502533700855, -0.08770123892182718, 0.020591402061649097, -0.03962873383317462, 0.051543254195089906, -0.08252100991542445, 0.09604140377074392, -0.0832980381120992, 0.027584707448311253, 0.08314263644327113, 0.027532904245030642, -0.01762572128305035, -0.1902179220021875, -0.04263326602160711, -0.09112018681023736, -0.022611689269777517, -0.08682059240707059, 0.014103166988078964, 0.009149575308563473, -0.09070576316924592, 0.006070578248825232, 0.016227058617515163, -0.06573707381102978, 0.03501833212184484, -0.020565500460008792, 0.03408588835956794, -0.09086117873484806, 0.1169695127569429, -0.07252317035507637, -0.13769042878255386, -0.06257713399800889, -9.495395737558054e-05, -0.011273468129151738, -0.1316813644056889, -0.06257713399800889, -0.03867039045451086, 0.033490163433361565, -0.06698032686672313, 0.017276055616666553, 0.02060435186984253, 0.06532266009630554, 0.02263758888616438, 0.04600041070673666, 0.11437940420950185, -0.09267425511510749, 0.052320290332778414, -0.13344263162690737, -0.09655942389202937, 0.06304335885702751, -0.05465139080483017, -0.15250586897058008, -0.10578022731468895, 0.02443771942873725, -0.012315988238952968, -0.07563130696481664, -0.03981004107414988, -0.0680163750503078, -0.04612991672968474, -0.047191864529656284, 0.06449382075533641, -0.085162925636653, 0.0468551476788392, -0.08645797792512008, -0.0012804872780743282, 0.004856462360829773, 0.020526647064921612, 0.09469453835272904, 0.05522121611464968, -0.10091081554271644, 0.06449382075533641, 0.11966323565195892, -0.0074530507755011365, -0.02101876955507365, -0.09469453835272904, 0.10940638404571468, 0.027921422313874896, 0.008495572076454431, -0.022987255545174896, 0.0404575711888903, 0.07754799372214416, 0.03486292449725644, -0.16286632102762522, -0.05879557361290167, -0.06811998145686902, -0.05301961769503912, -0.00253507335155904, -0.04177852706425112, -0.04669974402475769, 0.0643384171012549, -0.0023845228480385717, 0.10723068921299787, 0.002865312915975279, -0.08060432712860381, -0.11396498652427073, -0.07620113425988959, -0.04973017582957704, 0.03297214132682267, 0.053304531342575595, 0.015760839714256878, 0.009648172305761534, 0.07780700576804034, 0.05584284264249636, -0.04773578823783549, 0.05156915579673021, -0.02390674552875148, 0.026729968490955273, 0.032298713580948823, -0.081588568138401, 0.054288774337626224, -0.031418073021952535, -0.05672347923098576, -0.01933519522725543, 0.04843511758534964, -0.06485643722254038, 0.010107916900499139, -0.03587306909394737, 0.02704078374013205, 0.0135980946897335, -0.0008296456318015072, -0.03421539438251602, 0.03372327387761743, -0.08417868462685581, 0.007634358810577766, 0.06837899151751174, -0.1430778507495446, -0.08723501406280859, 0.08018991142862614, 0.0005997730962022926, -0.07014027462075778, -0.08676879714480373, -0.05110293292296504, -0.09200082339872677, -0.0420375391101473, 0.05009279229678099]}}, {'id': 'https://huggingface.co/papers/2410.18775', 'title': 'Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances', 'url': 'https://huggingface.co/papers/2410.18775', 'abstract': 'Current image watermarking methods are vulnerable to advanced image editing techniques enabled by large-scale text-to-image models. These models can distort embedded watermarks during editing, posing significant challenges to copyright protection. In this work, we introduce W-Bench, the first comprehensive benchmark designed to evaluate the robustness of watermarking methods against a wide range of image editing techniques, including image regeneration, global editing, local editing, and image-to-video generation. Through extensive evaluations of eleven representative watermarking methods against prevalent editing techniques, we demonstrate that most methods fail to detect watermarks after such edits. To address this limitation, we propose VINE, a watermarking method that significantly enhances robustness against various image editing techniques while maintaining high image quality. Our approach involves two key innovations: (1) we analyze the frequency characteristics of image editing and identify that blurring distortions exhibit similar frequency properties, which allows us to use them as surrogate attacks during training to bolster watermark robustness; (2) we leverage a large-scale pretrained diffusion model SDXL-Turbo, adapting it for the watermarking task to achieve more imperceptible and robust watermark embedding. Experimental results show that our method achieves outstanding watermarking performance under various image editing techniques, outperforming existing methods in both image quality and robustness. Code is available at https://github.com/Shilin-LU/VINE.', 'score': 3, 'issue_id': 258, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '1464291ab9f836a5', 'data': {'desc': 'Статья представляет новый бенчмарк W-Bench для оценки устойчивости методов водяных знаков к современным техникам редактирования изображений. Авторы предлагают метод VINE, который значительно повышает робастность водяных знаков, сохраняя высокое качество изображений. VINE использует анализ частотных характеристик редактирования изображений и предобученную диффузионную модель SDXL-Turbo для улучшения встраивания водяных знаков. Экспериментальные результаты показывают превосходство VINE над существующими методами по качеству изображений и устойчивости водяных знаков.', 'emoji': '🔐', 'title': 'VINE: Новый рубеж в защите авторских прав на изображения', 'categories': ['#benchmark', '#cv', '#optimization'], 'embedding': [8.350707128480195e-05, 0.12652636437435036, 0.016585144728485438, -0.06457486144979602, -0.08944627046883394, 0.008059245085334434, 0.12410480571206021, 0.033119841580345005, -0.1588138013665844, 0.01870400777457232, 0.13560720570199244, 0.07960869427890771, -0.12471019903357876, -0.020242705615677606, 0.0546868332050199, 0.06457486144979602, 0.03206040901274556, 0.032691024183465034, -0.05433369180130276, -0.0056723719496145734, 0.062203752753243746, 0.05128152005740513, -0.02548941222060093, 0.05564536793025559, 0.07310075524343342, -0.0763799486994835, -0.0007594955820126598, -0.07491693102976503, 0.06765225713200658, -0.005426432074816218, 0.04699334399949348, -0.014377995809191269, -0.024316469841481263, -0.08505719239033453, 0.02656145466824484, 0.10493415298958654, 0.027040722030862684, 0.03062260901400403, -0.05337515916517907, 0.008702471180654378, 0.10392516620950096, 0.028882115488171232, 0.013671708405710576, 0.005038604935617579, -0.01929678494871039, 0.05493908094459729, -0.004139980301998725, 0.06427216583359276, -0.06407037014886524, 0.07410973993440698, -0.0477753069783146, 0.11724372945109279, -2.486737076553793e-05, -0.1306631863568244, -0.011760948491307842, 0.03829087428121751, 0.042503374345966335, 0.009080839238530066, -0.03533960037968364, 0.03511257866753119, 0.0546868332050199, 0.0029654616878734994, 0.02538851437823717, -0.0814753158527532, -0.13247936632138002, -0.048834737456802044, -0.06629013103731587, 0.029083911172898748, 0.006246230334373138, -0.05937860063238657, -0.0044552868428024625, -0.01492032385323626, 0.05221482666610387, -0.008538511403396275, -0.07784297472564997, -0.05725973967541169, 0.019675152379852474, -0.03402792633984281, 0.007643040075433338, 0.01725359580667432, 0.05282021580939841, -0.008437613561032519, -0.08076902468887091, 0.04595913745931898, -0.13480001460663438, 0.04439521359078876, -0.08319058126204906, 0.02555247415549528, -0.05998398977568111, -0.009307860950682516, -0.10796109452783521, 0.09015255745449224, 0.08546078793801357, 0.044344767803274884, -0.045807789651217345, 0.03728189167935595, 0.030698282918054848, -0.01841392412752552, 0.042024109072460486, -0.018628333870521502, -0.04926355694279401, 0.02000307193436868, 0.022424630596658834, -0.08465360728821551, 0.08369507047386783, -0.09524792251864993, 0.0634649810055707, 0.015487876880150188, -0.04172141554536923, 0.05148331365302064, -0.060084891796268865, -0.09333085306817857, -0.12440750341737548, -0.06760180925538072, 0.08197980506457198, -0.21733477138343504, -0.044344767803274884, -0.02572904590190985, -0.05413189402746324, -0.04136826996342807, -0.057562435291614956, 0.03367478075790166, 0.05342560495269295, -0.034936009010228614, 0.10725480545306493, -0.11018085332717385, 0.059025457139557425, -0.008525900060973405, 0.02493447304304427, -0.096458698716127, 0.0005707055387072865, 0.03294326774481843, 0.15457607109618662, -0.05080225269478728, -0.005104819340523044, -0.01490771230190219, -0.023383161143670516, 0.20411708509308693, -0.05302201358323793, 0.06694596596812429, -0.003074242585465849, -0.05271932005614666, 0.018287802346848826, 0.029664075333324345, -0.03173248945822935, -0.10523684442756581, 0.006627751697904741, -0.0001572593265516395, 0.01205103004924264, 0.13258026207463175, -0.04081333078587141, 0.023988550286965053, 0.018552659966470687, 0.032968491683131367, -0.06896393535007142, -0.013078931649394908, 0.014441057744085616, 0.08682291403270427, -0.002878752467494172, -0.026939826277610927, -0.0366765025360614, 0.018994089332507118, -0.030723507900923788, 0.06180016138378872, -0.07183953116933048, -0.0858643834856926, 0.015109507986629703, 0.04512672660387199, -0.12259133807660388, -0.07506827674875467, 0.05781467885296835, 0.032464000382200583, 0.04966714831224903, -0.08636887269751138, 0.06401991809401536, -0.06291003764979004, -0.0335738829155379, -0.08308968133057329, 0.07088100062231878, -0.02281560999695739, -0.050474335229383084, 0.060690278850451404, -0.012416786973606656, 0.08308968133057329, -0.055090426663586926, -0.08298878766643354, 0.08197980506457198, -0.028655093776018783, -0.06800540062483573, -0.04126737212106432, -0.07582501370015085, 0.026107413333051936, 0.08616707910189587, 0.03511257866753119, 0.047321265643121696, -0.020457113269561587, 0.004414297211854737, 0.09534881409367768, -0.026864150284448107, -0.11260241198946401, 0.037105319932941375, -0.0036544073726250477, -0.06240555052708326, -0.050600459099171775, -0.00574804543584299, 0.01460501689461012, 0.030168567678811126, 0.0508779245097261, -0.11522576215825767, 0.076178153014756, 0.05857141371525252, 0.07320165726402118, 0.10997905555333434, -0.07885195732751153, -0.0040390816239901685, -0.003931877379225777, -0.04459701136462827, -0.0043070925492679464, 0.023521896982615684, 0.06518025059309056, -0.08692381396418004, 0.0009404029043473596, 0.03672695250179929, 0.025716433932753382, -0.029865872062607858, 0.009894331513508749, -0.014995997548375876, -0.010392516829861297, -0.008998859767723412, -0.1552823580818449, 0.01178617242962078, 0.005908851907445177, -0.024001164345233524, -0.10594312723500009, -0.004546726021665668, -0.042528596195167266, -0.037155769898679254, 0.00705026290129527, 0.05968129624858984, -0.025085820851145905, -0.020394051334667235, 0.03084963072615648, 0.00338639665625847, -0.035667522023311846, -0.07330255719549693, 0.12763624899679968, -0.03521348068811894, -0.004203041192337072, 0.0036134173238549215, -0.00020928496323483633, 0.003244508347302188, -0.022399404569233894, -0.09948564443259969, -0.02746954151685465, 0.06492800285351316, -0.007661958655901643]}}, {'id': 'https://huggingface.co/papers/2410.18978', 'title': 'Framer: Interactive Frame Interpolation', 'url': 'https://huggingface.co/papers/2410.18978', 'abstract': 'We propose Framer for interactive frame interpolation, which targets producing smoothly transitioning frames between two images as per user creativity. Concretely, besides taking the start and end frames as inputs, our approach supports customizing the transition process by tailoring the trajectory of some selected keypoints. Such a design enjoys two clear benefits. First, incorporating human interaction mitigates the issue arising from numerous possibilities of transforming one image to another, and in turn enables finer control of local motions. Second, as the most basic form of interaction, keypoints help establish the correspondence across frames, enhancing the model to handle challenging cases (e.g., objects on the start and end frames are of different shapes and styles). It is noteworthy that our system also offers an "autopilot" mode, where we introduce a module to estimate the keypoints and refine the trajectory automatically, to simplify the usage in practice. Extensive experimental results demonstrate the appealing performance of Framer on various applications, such as image morphing, time-lapse video generation, cartoon interpolation, etc. The code, the model, and the interface will be released to facilitate further research.', 'score': 3, 'issue_id': 257, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': 'ccd15b8785ec7920', 'data': {'desc': "Предложен метод Framer для интерактивной интерполяции кадров, позволяющий создавать плавные переходы между двумя изображениями с учетом пользовательских предпочтений. Система поддерживает настройку процесса перехода путем задания траектории выбранных ключевых точек, что обеспечивает более точный контроль локальных движений. Framer также включает 'автопилотный' режим с автоматическим определением ключевых точек и траекторий. Метод показал высокую эффективность в различных приложениях, таких как морфинг изображений, создание таймлапс-видео и интерполяция мультипликации.", 'emoji': '🎞️', 'title': 'Интерактивная интерполяция кадров с пользовательским контролем', 'categories': ['#video', '#multimodal'], 'embedding': [0.019970577318548323, 0.09124195531263429, -0.032072770376020444, -0.03452187253909838, -0.06299915744218139, -0.04900802998521658, 0.09181514900286508, 0.11484710402526081, 0.037961030609881014, 0.05836150217845191, 0.020218092313125016, -0.03222909777817523, -0.10807299936746194, -0.0751925482685806, -0.038768713368042954, -0.006650345328739588, 0.03316705201459882, -0.054713910963631276, 0.020882474613428223, 0.018654838644587456, -0.04137413886267361, -0.12328867383536364, -0.005259700249483124, -0.011704867694665479, 0.04747083020527113, -0.07613049639910106, -0.07998652482856176, -0.10338323836184926, -0.0002540288534319213, -0.04705396188189411, -0.06305126521936563, -0.05440126022992376, -0.028138582316084418, -0.10531124850597753, 0.050675501243423654, 0.02691403326984649, -0.09614015149758601, 0.09728654294864965, -0.07675579583121504, -0.02941523913950659, 0.03543377085162879, -0.012636307543055558, 0.022641136517008758, -0.06633410402919764, 0.05106631567820857, 0.013470043579219304, 0.015137514837426381, 0.008988713275283368, -0.004943792423523915, 0.15236521242317266, -0.04601179412640309, 0.06435398000198199, -0.047496882058562215, -0.004041664166567965, -0.01961884473430211, 0.03176012167761397, -0.018172834582079606, -0.07404615478221592, 0.00784232711600242, -0.013105284254207136, 0.084780505459145, -0.037961030609881014, 0.0023595373161739257, 0.027851985470969023, -0.10395642798147796, 0.05700668165395233, -0.13954652827056258, 0.07680790564370032, 0.050519177911870945, 0.07576573585290827, 0.06049795157252129, -0.00995923477068204, 0.01348307031998526, -0.038195517642511126, -0.0763389315784401, -0.03222909777817523, 0.004888427147027771, 0.033662082003752196, 0.10181997858740859, -0.03540771492773564, 0.0068066708991234475, 0.008851928630168858, 0.06706362105098113, -0.007327755387459268, -0.11859890875914889, -0.04392745250951795, 0.05638138222183835, -0.014160480785765147, -0.1026016074569784, -0.1144302316312817, -0.03853422633541284, 0.10161154951397267, -0.07206603279030133, 0.1250603647185413, 0.054974449849552465, 0.009105957809248945, -0.05424493282776897, -0.09879769087530402, 0.1086982967642749, 0.05971632473825251, 0.031838283343390325, 0.0022667190405600878, -0.06732416604280543, -0.049685441265116884, 0.14892605028178796, -0.04270290346328002, 0.04304161012088068, 0.04293739049591013, -0.018224942359263845, 0.07024223820054153, 0.01595822352223386, -0.043067661974171764, -0.10541546609564706, 0.021937671348516336, 0.055599753352268536, -0.11474288440029026, -0.018211916432618307, 0.000570750718394435, -0.043666911588295707, -0.054453368007108004, 0.015971249448879402, -0.02455612276979253, 0.006021786972602971, 0.0706591085592196, 0.06305126521936563, -0.11297119555241367, 0.033740243669528554, -0.018915379565809687, -0.07435880755122447, -0.12849952482462496, 0.009685664259272397, -0.04595968227861678, 0.006549385034851872, 0.001871020290343308, -0.09608804779100384, -0.0031981582783598543, 0.008265708199172115, 0.0346000321695737, -0.06497928553999908, 0.05700668165395233, -0.009907125772317178, -0.13027121367250155, 0.02324038409583166, -0.017000393313025913, -0.05007625569990179, 0.1026016074569784, -0.009907125772317178, 0.04072277943606439, -0.045777303023170894, 0.005601662167564556, -0.027982254913929624, -0.0925967778724349, -0.06946061136627275, -0.00815497825677014, -0.03014475819659113, 0.07602627880943155, -0.03428738550646827, -0.02531169775077023, -0.010604077163366416, 0.04444853842256449, -0.0888449609267406, 0.019136840671794265, -0.001931270696391737, 0.004539951858563361, -0.0005491746142047823, -0.021859509682739975, -0.07727687970896055, 0.08352989845371289, -0.12193385331086408, 0.04192127866431227, -0.02037441767997877, -0.11359650109043076, -0.12203806886523257, 0.07404615478221592, 0.04395350639811006, -0.01595822352223386, 0.018876297715270992, -0.1574718315756572, -0.005041496032220143, 0.03142141705531434, -0.027226684003554002, 0.15184412243952405, -0.0603416241703665, 0.037752595430541984, 0.03248964276999954, -0.08014284816011448, -0.01681801405758004, 0.03603301639515066, 0.0045920604498680155, 0.022888651511585447, -0.04840878444169471, 0.17758571444031687, -0.02120815432673283, 0.02240664948437864, 0.06800157121680263, -0.05893469586868269, 0.08806334426897701, 0.0050903475312731004, 0.03644988268322666, 0.021950699310462913, 0.014108373008580909, -0.0049763602930893245, 0.024152282408362077, 0.004334774585596439, -0.06800157121680263, 0.06414554482264297, 0.05862204309967414, 0.026197540139407487, -0.0734208533148009, 0.04853905591995635, 0.06649042329014827, 0.0665946469857209, 0.07613049639910106, 0.009828963292420405, -0.047522937982455375, -0.06101903341496576, 0.020335335829440075, 0.10286215041350168, -0.030222921897668526, 0.01722185441901049, -0.09952720789708752, 0.004917738534931795, 0.16257848329295835, 0.007751136877689171, 0.003911393095366536, -0.017352125897272128, 0.02286259762299333, -0.08910550795386593, -0.008063787407866578, -0.03973271945775761, 0.030848221329782512, 0.02127329006586365, -0.03441765291412782, -0.055130777251707265, 0.05492234207236823, -0.0714407313228863, -0.028373071384015573, -0.14475737518922183, 0.08108080036123701, -0.012278061384896266, -0.03350575663689845, 0.004054691314394128, -0.03736178506635915, -0.0462462811590332, -0.015059352153999504, 0.137774839422686, -0.1015594356308853, -0.018550621054917938, 0.06987748172495081, 0.020530743046832528, 0.060237408615998016, -0.057058793501738654, -0.0836341221492855, 0.04147835441704209, 0.024295581848570294, -0.06028951639318226]}}, {'id': 'https://huggingface.co/papers/2410.18745', 'title': 'Why Does the Effective Context Length of LLMs Fall Short?', 'url': 'https://huggingface.co/papers/2410.18745', 'abstract': 'Advancements in distributed training and efficient attention mechanisms have significantly expanded the context window sizes of large language models (LLMs). However, recent work reveals that the effective context lengths of open-source LLMs often fall short, typically not exceeding half of their training lengths. In this work, we attribute this limitation to the left-skewed frequency distribution of relative positions formed in LLMs pretraining and post-training stages, which impedes their ability to effectively gather distant information. To address this challenge, we introduce ShifTed Rotray position embeddING (STRING). STRING shifts well-trained positions to overwrite the original ineffective positions during inference, enhancing performance within their existing training lengths. Experimental results show that without additional training, STRING dramatically improves the performance of the latest large-scale models, such as Llama3.1 70B and Qwen2 72B, by over 10 points on popular long-context benchmarks RULER and InfiniteBench, establishing new state-of-the-art results for open-source LLMs. Compared to commercial models, Llama 3.1 70B with \\method even achieves better performance than GPT-4-128K and clearly surpasses Claude 2 and Kimi-chat.', 'score': 2, 'issue_id': 257, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '8694d1d100403e2f', 'data': {'desc': 'Статья представляет новый метод под названием STRING (ShifTed Rotray position embeddING) для улучшения эффективной длины контекста больших языковых моделей (LLM). Авторы обнаружили, что существующие LLM часто не могут эффективно использовать весь заявленный контекст из-за особенностей распределения относительных позиций при обучении. STRING решает эту проблему, смещая хорошо обученные позиции для перезаписи неэффективных позиций во время вывода. Эксперименты показывают значительное улучшение производительности современных моделей, таких как Llama 3.1 70B и Qwen2 72B, на бенчмарках длинного контекста без дополнительного обучения.', 'emoji': '🧵', 'title': 'STRING: Расширение горизонтов контекста для языковых моделей', 'categories': ['#architecture', '#benchmark'], 'embedding': [0.05127664148621837, -0.013681435688615665, 0.09642155022250433, 0.02958562648249697, -0.0007836326744652802, 0.01999201385269438, 0.07031057681339378, 0.05188981669625077, -0.1351025767364959, 0.1269269395200499, 0.016606784744156576, 0.03306027568580505, -0.028103788971637542, 0.0637189549157804, 0.03369899921790909, -0.04292215440503599, 0.042973252984218405, -0.04136366805788334, -0.04008622486375361, 0.12682475010184172, 0.010500598381256636, -0.04665229263417785, 0.010277044661260433, 0.05503232997247103, 0.06790898035756407, 0.024041514815407845, -0.03627943779831853, 0.05319280821245214, 0.07506266534075327, -0.011305388909385003, 0.04167025566289955, -0.0780774408766937, -0.09136286634997197, -0.04882394645120624, -0.011567264725480815, 0.09647264880168674, -0.036202792832103634, 0.03967744010037256, -0.07046386674582354, 0.05319280821245214, -0.011809979396774866, -0.084515757361564, -0.07521595914326136, 0.04573253175416841, -0.008852693874372874, 0.08308502036492614, -0.027720556400406455, 0.14348263149014154, -0.0799169568315951, 0.08952334458995308, -0.050331332284137296, 0.07792414320410729, -0.1240654616566959, 0.025101794369369993, -0.040418360790841434, -0.015150497490407944, 0.01668343164541063, 0.003733332978800297, -0.00868662591082896, -0.03901317018123606, -0.009587225065524889, -0.06591616092495875, 0.028972453207503728, 0.007294211203794646, -0.04184909778747927, -0.0005409181386239718, -0.1698490881199684, 0.032881433561225325, 0.01805029880438898, 0.026724148619142962, -0.012250698111466073, -0.023862672690828115, 0.03339240967785372, 0.013400398340710256, -0.002799201530445406, 0.020911774732703822, 0.006186027626804591, 0.006067863686288583, -0.017322153242475498, 0.021346105883117337, -0.028487023477907797, -0.0682155602224236, -0.012448700993839736, -0.05288622447751427, 0.024309778969797025, -0.013719759139242688, -0.014128541387072821, 0.04655009547581301, -0.045528139372477884, -0.06428103348166955, -0.05452135385584263, -0.028487023477907797, -0.0013572853288020118, -0.04468502732876165, 0.017194409697078188, -0.019378840577701142, 0.040111773185825234, -0.050689018468335914, 0.06591616092495875, 0.005847504522446895, -0.05814929686165881, 0.027567263565417933, 0.04213013707042385, -0.079865862122491, 0.04026506698833334, 0.008450298610308691, 0.02589381170398213, -0.02843592683376454, -0.044199597599165724, 0.001450698531688676, -0.11629859372331762, -0.036253889476246894, -0.07260997611085863, -0.033162470909130735, 0.05061236963204271, -0.05676965650916423, -0.0014890218275125681, 0.10945148473490965, 0.050970055816241325, 0.04808302963081569, 0.016134130143116043, 0.048721753162919726, 0.029662271448711856, -0.03594730187123069, 0.07654450672169102, -0.07659560336583428, -0.0326770411795348, -0.10398401996907457, 0.06034650093579799, -0.03773572698710632, 0.007805189448966124, 0.04902833883289676, 0.05564550324746427, -0.014703391985454702, -0.1286642563815473, -0.016287422978104562, -0.14961436424007396, -0.010251496919700552, -0.07480718212003698, -0.06867544937010457, -0.023734929145430808, -0.042027939912059005, -0.0851289325715964, 0.019417164028328163, -0.04310099459457655, 0.017782034649999803, 0.003166466739013581, 0.014550098763458351, -0.06698921754251545, 0.10183791834419613, -0.09483751942335839, -0.0915672587316625, -0.04849181052411841, 0.09984510471670832, -0.08538442159743016, -0.0244247493216781, -0.03822115671670225, 0.03290698575337528, 0.11752494027330412, -0.09974290949338264, 0.016606784744156576, 0.07153692142834109, -0.014703391985454702, 0.0380423107220442, 0.015469860223979543, 0.06438322289987775, -0.015048302267082266, 0.04356087406706169, -0.15349778466148895, -0.16341076776501978, -0.01187385116947352, -0.036918161330422555, -0.05020359067377915, -0.10388182281070973, 0.009944909314684352, 0.016019161726274128, 0.004474250960214345, -0.0640766430350182, -0.008929340775626926, -0.048210773176213, -0.04144031689417656, 0.19049260837347887, -0.019596006152907894, -0.007096207160397487, -0.07879280743997345, -0.03668822256169957, -0.014856685013947138, 0.05993772197753444, 0.05127664148621837, 0.06877763878831275, -0.0890634670525071, 0.13489817854968789, 0.1765939960799332, 0.042717762023345464, 0.00820119714875261, -0.014741715436081729, 0.08170538388250989, 0.039805187515848196, 0.015252694648772786, -0.049769257588326475, 0.09381555557986661, 0.08538442159743016, -0.03433772275001312, -0.16739638727983877, -0.07465388444745054, -0.10638561835994345, -0.0018363272038643716, 0.0009309380532238747, -0.10710099266337986, 0.036611573725406354, 0.0890634670525071, 0.0020359278480750805, 0.08885907273577742, -0.0599888186216777, -0.02576606622354566, 0.0004926147235127817, -0.08068342390909644, -0.013809180588540386, -0.0005377245112882558, -0.010711376392185692, 0.060244305712472315, 0.004151696186039144, 0.05017803848162919, 0.08732613858077473, -0.09207823871836922, 0.05099560413831296, 0.03778682556628874, 0.017437123594356573, 0.0622371212749993, -0.07031057681339378, 0.04695887636911572, -0.061112971883377665, -0.07378522021158437, -0.08778601805325988, -0.006163671925848314, -0.10229779588164212, -0.08778601805325988, -0.07112813666496004, -0.01457564766604173, -0.040980435486652256, 0.04984590255454136, -0.020784031187306512, 0.06862434498580465, -0.02443752251519433, 0.027899398524986182, 0.04565588678795352, -0.05574770040582911, -0.07383632266084511, 0.10536366419164749, -0.014345707542791327, -0.04391855831622115, -0.03083752328959424, -0.10945148473490965, -0.04087824026332658, -0.10567025179666369, 0.009357284361762738]}}, {'id': 'https://huggingface.co/papers/2410.18451', 'title': 'Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs', 'url': 'https://huggingface.co/papers/2410.18451', 'abstract': 'In this report, we introduce a collection of methods to enhance reward modeling for LLMs, focusing specifically on data-centric techniques. We propose effective data selection and filtering strategies for curating high-quality open-source preference datasets, culminating in the Skywork-Reward data collection, which contains only 80K preference pairs -- significantly smaller than existing datasets. Using this curated dataset, we developed the Skywork-Reward model series -- Skywork-Reward-Gemma-27B and Skywork-Reward-Llama-3.1-8B -- with the former currently holding the top position on the RewardBench leaderboard. Notably, our techniques and datasets have directly enhanced the performance of many top-ranked models on RewardBench, highlighting the practical impact of our contributions in real-world preference learning applications.', 'score': 2, 'issue_id': 257, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '2ea2a42b9bcfc599', 'data': {'desc': 'В этой работе представлен набор методов для улучшения моделирования вознаграждений для больших языковых моделей (LLM), с акцентом на техники, ориентированные на данные. Авторы предлагают эффективные стратегии отбора и фильтрации данных для курирования высококачественных открытых наборов данных предпочтений. Результатом стала коллекция данных Skywork-Reward, содержащая всего 80 тысяч пар предпочтений, что значительно меньше существующих наборов. Используя этот куриро  ванный набор данных, исследователи разработали серию моделей Skywork-Reward, которые показывают высокие результаты в бенчмарке RewardBench.', 'emoji': '🚀', 'title': 'Малые данные, большие результаты: революция в моделировании вознаграждений для LLM', 'categories': ['#dataset', '#data', '#rlhf', '#benchmark'], 'embedding': [0.05962752820190416, -0.07085756887970002, 0.10449068514744185, -0.08510888617668096, -0.011842847900766784, -0.0023479050625068803, -0.05005064024781514, 0.08624899528387284, -0.04588925452143816, 0.04124332185564674, -0.04375155692689102, -0.08510888617668096, -0.0389916147983823, -0.02448376948742154, 0.0887002245894714, 0.013488875214054013, 0.08835819206417125, -0.06601212017129686, -0.0385640756931877, 0.06002656649285003, -0.07119960140500017, -0.007389309797458359, 0.00021555123617406029, -0.014001923174574597, 0.07273874052884145, 0.0013565476375497145, -0.09531284169002106, 0.016160998034667588, -0.01509214861682178, -0.1325942855876061, 0.056463733031456555, -0.059741537664621466, -0.06378891185970702, -0.0032261428219051897, -0.07735617031181001, 0.03956166624911707, 0.0042718337250289545, 0.030469324200155416, 0.05044967647018689, -0.023742700739749635, -0.05680576555675671, -0.06344687933440686, 0.05729030835902291, 0.026877991993087325, -0.03269253147745819, 0.06002656649285003, 0.06646816215931431, -0.024369760024704236, -0.0012541162117346992, 0.08168857126655, -0.20179871415504402, 0.08362675281848539, -0.03203696930968073, -0.15037993139458353, 0.02539585553203058, -0.09941721337645584, -0.013880787060293226, 0.020550404755053292, 0.0018152620164749945, -0.04708636525712752, -0.00020330400520053197, -0.03135290632765454, -0.0036233984156729807, -0.007339430062804478, 0.022844867170839084, -0.060140575955567335, -0.10443368145037027, 0.01062435948581675, 0.036397873147243576, 0.08533690923926379, 0.07302376935707001, -0.003944053054855051, 0.06789329182043828, 0.031096382450822954, 0.009263358311611729, -0.07518996569729176, 0.0660691197312202, 0.08938428136577523, 0.06475799953281353, -0.05284389794156561, 0.012384397502965754, -0.011116031215078547, -0.016075490213628668, -0.05583667581507608, -0.02804659881166677, -0.01972382942748694, -0.009256233108049546, 0.02820336363290542, -0.0069831471303799545, -0.007474818032212103, -0.10506073866675074, -0.02667847284761439, -0.04779893112197657, 0.0444926236059888, 0.08619198538107889, 0.013916415146678265, -0.02593740409994249, -0.047456896528102296, 0.03220798660661787, 0.12757782371941404, -0.04440711702609435, -0.03893460903273659, 0.03545728421981168, -0.05546614247552718, 0.07923734609809968, 0.02714876731133034, -0.025210585759394954, -0.031324403444831686, -0.018726234734409333, 0.005248049083986596, -0.1636051614585346, 6.802779050983099e-05, -0.19552812130549804, 0.031010873802354382, 0.027120264428507485, -0.0654990744862078, -0.15995682762296903, 0.030526328931514066, -0.01627500749738489, -0.061850730307771634, -0.01728685156329981, 0.07570301758810319, 0.02472604295712876, -0.09622491739175949, 0.023429171097272338, 0.013574383448807759, 0.01165045561371533, -0.0930896313098571, 0.13327835477535466, -0.08117552351288683, 0.006765814665715443, 0.01536292434877962, 0.12016714244841736, -0.03329108787958993, -0.1039206336967071, -0.0406732724734861, -0.02226056427869289, 0.05996956072720432, -0.06230677643293733, -0.09542684908416425, -0.022673851942476068, -0.028630904806674146, -0.04332401368454818, 0.048482996172576884, -0.11537869329993755, -0.05520961653012148, 0.006156570975383955, 0.04634529444088149, -0.10443368145037027, 0.09947422327924979, -0.05062069376712402, 0.001246990677200656, -0.02464053430866019, 0.11777291477131627, -0.0369964274808012, -0.08436781949758317, -0.025595371574642332, 0.012220507064450097, -0.03197996354403502, -0.12609569036121848, 0.07872429420728827, 0.07273874052884145, -0.06401693285371575, -0.006851322279896952, 0.03602733980769469, 0.015391427024745063, -0.15927276050379463, 0.04640230020652721, -0.14787171080335812, -0.06321886040897225, 0.05566566058671306, 0.004104380374446087, -0.036454878912889295, -0.06869136840233002, -0.046231282909590075, -0.025481361077637966, -0.03873509092155072, 0.037053433246446915, 0.0336046154534931, -0.05324293623251148, -0.051475771977513234, -0.02080692863188488, -0.08664802943767047, -0.008743185354386371, -0.012505534651534188, 0.006594798816780189, 0.012826188670144022, 0.006641115639366859, 0.02961424495547915, -0.07672910895828128, 0.011550695730692747, 0.07211168124388684, 0.11144533063614342, 0.08334172192168271, -0.048939036092020216, 0.026307937439491377, -0.008073373400056786, 0.08476685778852903, -0.051475771977513234, 0.025438608821977803, -0.041984392671892766, 0.06281982418660051, 0.05196031477977943, -0.07587403074789208, -0.007296676565999843, -0.026763981496082962, -0.0381365365879931, 0.02585189545147392, -0.09770705902425154, -0.06458698637302464, 0.09508481655886408, 0.08550792860477506, 0.08818717269865999, -0.02180452125638837, -0.03896311398413357, 0.03075435199409692, -0.018555219506046314, -0.01513490252734124, 0.052473364602016716, 0.03862108145883341, 0.04517668865658911, 0.017486370708772743, 0.07296676565999842, 0.05962752820190416, -0.08265766514537888, 0.006267018353463698, 0.030383816585973906, -0.12028115191113467, 0.08653401997495316, -0.1127564508345501, 0.01584746942647735, -0.048768020863657204, -0.016788057319622185, -0.03007028901207073, -0.03887760326709088, 0.0045996137746306225, -0.030925365153885817, 0.012811937228732594, 0.10129838502559727, -0.12107922021872992, 0.01879749090717941, 0.0210492021015921, 0.009092343083248711, 0.08493787508546619, 0.07256772323190432, 0.0654990744862078, -0.08921327027456045, -0.03833605263060485, -0.01147943893735043, -0.022061045133219957, 0.03423167473844771, 0.0473998928310307, -0.07154163599887445, -0.08704706772861634, -0.02332941307596646, 0.01932479113654107]}}, {'id': 'https://huggingface.co/papers/2410.18785', 'title': 'Should We Really Edit Language Models? On the Evaluation of Edited Language Models', 'url': 'https://huggingface.co/papers/2410.18785', 'abstract': 'Model editing has become an increasingly popular alternative for efficiently updating knowledge within language models. Current methods mainly focus on reliability, generalization, and locality, with many methods excelling across these criteria. Some recent works disclose the pitfalls of these editing methods such as knowledge distortion or conflict. However, the general abilities of post-edited language models remain unexplored. In this paper, we perform a comprehensive evaluation on various editing methods and different language models, and have following findings. (1) Existing editing methods lead to inevitable performance deterioration on general benchmarks, indicating that existing editing methods maintain the general abilities of the model within only a few dozen edits. When the number of edits is slightly large, the intrinsic knowledge structure of the model is disrupted or even completely damaged. (2) Instruction-tuned models are more robust to editing, showing less performance drop on general knowledge after editing. (3) Language model with large scale is more resistant to editing compared to small model. (4) The safety of the edited model, is significantly weakened, even for those safety-aligned models. Our findings indicate that current editing methods are only suitable for small-scale knowledge updates within language models, which motivates further research on more practical and reliable editing methods. The details of code and reproduction can be found in https://github.com/lqinfdim/EditingEvaluation.', 'score': 2, 'issue_id': 257, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '8ee1a0454341105c', 'data': {'desc': 'В статье рассматривается влияние методов редактирования на общие способности языковых моделей. Исследование показывает, что существующие методы редактирования приводят к неизбежному ухудшению производительности на общих бенчмарках, особенно при большом количестве правок. Модели, настроенные на инструкции, и крупномасштабные языковые модели оказываются более устойчивыми к редактированию. Однако безопасность отредактированных моделей значительно снижается, даже для моделей, ориентированных на безопасность.', 'emoji': '✏️', 'title': 'Редактирование языковых моделей: компромисс между обновлением знаний и сохранением общих способностей', 'categories': ['#interpretability', '#alignment'], 'embedding': [-0.0017435554171842417, 0.106200565488824, 0.12178434728046772, -0.07676453611190104, -0.061180760335404163, 0.09533039712904576, 0.020898615165890203, 0.06839547383078752, -0.15401005539588308, 0.14977741711590287, 0.07431153516761083, -0.10100596487477961, -0.01840954138596595, 0.08498931306562518, 0.03775699454385776, -0.027007072979624246, 0.03893539790182412, 0.038983493010953905, -0.02592486685758877, 0.05285979316342044, 0.00954145650738096, 0.003706558348967134, 0.09566708695354165, 0.025395787573853475, 0.10418044458728926, -0.025852718178747246, 0.027079220655941295, 0.009120598738121242, 0.04215796871336566, -0.006595449315494411, 0.04814617772650602, -0.03001320276726358, -0.032345958921057995, 0.006655571911247197, -0.08811568563871135, 0.09566708695354165, 0.0768607343503564, 0.008381090569756092, 0.04593366636320738, -0.03556852973259954, 0.05449512512123163, -0.00842918908746909, -0.06276799718408557, 0.03600141579050183, -0.01349151181025765, 0.07397485336331074, 0.04338446918551076, 0.0986972632932214, -0.05213832041034784, 0.055408990341117056, -0.07445582851519598, 0.07181043309904399, -0.03362055851243079, -0.15853128037103364, 0.05940112901486098, -0.01498255182401795, 0.052763594924965074, -0.06680823497705717, 0.025395787573853475, 0.00183223632612156, 0.04843477043682316, -0.07248380272279101, 0.028450014475671546, 0.03968091921198609, -0.12726751453919294, -0.04400974169507905, -0.1262093619868692, 0.00905446420360101, -0.038406319620613305, -0.012054581450958213, -0.0001497428621023229, -0.09840867459300215, -0.02642989658171022, -0.023519962024952823, -0.004509195282973689, -0.07700502769794154, 0.05637095067013227, 0.05516850076012549, 0.002600302466812921, -0.017086842675365484, -0.019599969022477005, 0.0013520069722432393, -0.037131722034289466, -0.04434642951452598, -0.041532692193699476, 0.059064443200462995, -0.03932018083040084, 0.006992258728169656, -0.05146494878155187, -0.13284690409696093, -0.13005721934332165, 0.016822304537284553, 0.039656866644798824, 0.008549434479479558, 0.12361206970004279, -0.016870401651463283, 0.0198885557176473, -0.03895944445386454, 0.057477208356830546, 0.08181483936826238, -0.015908439317399117, -0.02216119047871831, 0.03426988358918633, -0.08652844879002995, 0.033836999536332985, -0.09321408400420249, 0.00880796087929794, -0.011790041909343015, -0.026069161207698394, -0.015427460155415981, -0.12245771890926369, -0.026790629950673092, -0.12601698556044794, -0.07637975318332432, -0.03835822050138562, -0.1107217844488277, -0.04622225305837768, 0.009445260273974543, 0.007503300792068342, 0.036145709138086984, -0.016365371927341832, 0.018084877845063702, 0.08152625267309208, -0.053292673206175895, 0.0038478465291881406, -0.08571077980355093, 0.054206538426061324, -0.049396730765838386, -0.0029760686902678382, -0.04292753657556805, 0.03549638406133144, 0.00037614202977935096, 0.04600581403952443, -0.042109869594137976, -0.1053348013932152, 0.04501980515341984, -0.04898789727512335, 0.039969505907156394, -0.07435963228178957, -0.0020817452789500305, -0.0005587644344289301, -0.012433354646321329, -0.10283369731959943, 0.08893335061509249, -0.11437723530312469, -0.04542863864413488, 0.0704636878364031, 0.02246180345748224, -0.04848286554595295, 0.14419805562882015, 0.005017231377488653, -0.018132976964291385, -0.03095111654423838, 0.04328827495715329, -0.08369066291211408, -0.013683904477575377, -0.03186497975907487, 0.0033007308276358236, 0.04174913522265062, -0.0649805085473842, 0.06377805262223057, 0.11630116398135093, -0.0506472818001218, -0.006093425560756683, 0.00818869810294326, 0.01832536742605527, -0.056948130075619725, 0.006324897835111765, -0.06459571960366063, -0.16228292745873704, 0.0345825228515439, 0.007575447866870707, 0.04362496077155127, -0.11582018080926988, -0.0010153203959266544, -0.05738101212342413, -0.04213391815122734, -0.09585947741530554, -0.09292549329893429, 0.04893979615084672, -0.09937063492201736, 0.06858786228750245, -0.1649764179840188, 0.1426589118842196, -0.09744671426398693, -0.04061883098391194, -0.04249465653281259, 0.060122601767933576, -0.10225652392925882, -0.05098396761451979, -0.009048451863823772, -0.004761710145034415, 0.09205973120837443, 0.045596980548809396, 0.02216119047871831, 0.041604837864967575, 0.06911694457881117, 0.08354636755947999, -0.04018594693105859, -0.03782914021512586, 0.06618295645234204, 0.055408990341117056, -0.045308391848590146, -0.11014460905343815, 0.056034264855734296, -0.005170544036759239, -0.06825118048320238, 0.022594074531571657, -0.08109336862023873, -0.023664255372537975, 0.05622665732254713, 0.0948013208528839, 0.08893335061509249, 0.06772210019694261, 0.0626236998264025, 0.03015749811989768, -0.025660327716983358, -0.00443704800766643, -0.07815938450386749, 0.01966009041520042, 0.002137358519617442, -0.04494765547205385, 0.10831688061871624, 0.039296132273311475, -0.03400534344605645, 0.048555013222269995, 0.07936183641892323, -0.0050112188372065216, 0.047881639588425076, -0.04586152069193928, 0.007274834888106774, 0.00830293115517649, -0.11639735419961049, -0.08917384220113299, 0.033885098655560664, -0.011976422637893296, 0.013190898630988821, -0.05160924212913702, 0.007779864612228225, -0.01724316230654427, 0.03484706098962483, 0.03350031171688605, -0.013118751957196246, -0.02249787829816524, 0.009427223655652624, 0.10264130886288449, -0.02433762900638289, -0.054398930892874155, 0.03345221660775627, 0.042831342347210574, 0.07392675023398516, -0.036338101604899815, 0.025155297992861907, -0.09739861113466135, -0.035857120437867734, 0.015728073134179916]}}, {'id': 'https://huggingface.co/papers/2410.18958', 'title': 'Stable Consistency Tuning: Understanding and Improving Consistency Models', 'url': 'https://huggingface.co/papers/2410.18958', 'abstract': 'Diffusion models achieve superior generation quality but suffer from slow generation speed due to the iterative nature of denoising. In contrast, consistency models, a new generative family, achieve competitive performance with significantly faster sampling. These models are trained either through consistency distillation, which leverages pretrained diffusion models, or consistency training/tuning directly from raw data. In this work, we propose a novel framework for understanding consistency models by modeling the denoising process of the diffusion model as a Markov Decision Process (MDP) and framing consistency model training as the value estimation through Temporal Difference~(TD) Learning. More importantly, this framework allows us to analyze the limitations of current consistency training/tuning strategies. Built upon Easy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT), which incorporates variance-reduced learning using the score identity. SCT leads to significant performance improvements on benchmarks such as CIFAR-10 and ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID 1.55, a new SoTA for consistency models.', 'score': 2, 'issue_id': 257, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '1e70afdddccea2fd', 'data': {'desc': 'Статья представляет новый подход к пониманию моделей согласованности, рассматривая процесс шумоподавления как марковский процесс принятия решений. Авторы предлагают метод Stable Consistency Tuning (SCT), который использует обучение с временной разницей и снижение дисперсии для улучшения производительности. SCT достигает значительных улучшений на таких бенчмарках, как CIFAR-10 и ImageNet-64, устанавливая новый рекорд для моделей согласованности. Этот метод позволяет преодолеть ограничения существующих стратегий обучения моделей согласованности.', 'emoji': '🚀', 'title': 'Революция в генеративных моделях: SCT устанавливает новые стандарты', 'categories': ['#diffusion', '#rl', '#benchmark'], 'embedding': [0.09830301019130254, -0.0010906883856625653, 0.0626137119899089, -0.006803271663153024, -0.1264870529638261, 0.03844471478908221, 0.06130160683826918, 0.021098670722914277, -0.13058082442154587, 0.06439817880381825, 0.023421097052854303, 0.03296011017832241, -0.05345521295455791, -0.03534814705428797, 0.061983904901725694, 0.025363015638809463, 0.05621063588837872, -0.036109166773012555, 0.05264170437593741, 0.130265914531322, -0.01497113310708683, -0.008679583299224261, 0.040412876747296614, -0.006731105562506228, 0.060461861233521694, -0.0848670382077945, -0.00807601450639451, 0.09389433095873634, 0.03970433742695826, -0.08266269647613397, 0.04148880212549021, -0.01043124547473408, -0.03466584899083145, -0.09011545881435333, 0.03120188885204972, 0.08833100046195365, -0.029417424153517776, 0.1455913162408893, -0.13173547568576235, 0.019550385797828453, -0.030099720101596877, -0.0072034636286342655, -0.03605668002849407, 0.05773267955658272, 0.06035688985986214, 0.009276592095140168, 0.03198915405841096, -0.013777116149868242, -0.01070022692505135, 0.06361091571283442, -0.017031140522076334, 0.0916899871116984, -0.0188287269067379, -0.13268019477954682, 0.058205039103474944, -0.013331000609848485, 0.02994226621417366, -0.036319101058822, -0.006439161901844214, -0.04172498189893632, 0.09483904793714339, -0.051828200028071765, -0.012419086789076788, 0.055633307083204346, 0.08654653153266688, 0.0008180162786700369, -0.07982854765629027, 0.0324090268607847, -0.022227080730248944, 0.050358638873631414, -0.029076275121789518, -0.11588523403091659, -0.06208887204463042, -0.060461861233521694, -0.05883484830703555, 0.0016606345236448747, 0.02154478478216984, 0.06943666512456764, 0.039100769480279476, -0.031096919593767574, 0.08528691524092308, -0.02675384879184949, -0.024142755943944855, -0.0276854430264382, 0.0017073783146238095, -0.04088523417881142, -0.031910426057010645, -0.03225157508873891, -0.005615815125923765, -0.028551433061133634, 0.008935443909562876, 0.12963610321238397, -0.013271955349180343, 0.07751924089710245, 0.07925122519724814, -0.034193489443939226, 0.06455563269124147, -0.08135059343987168, 0.1282715155469806, 0.035610568084615914, -0.07122113405385441, 0.010601819355984985, 0.03952064228265322, -0.009243788937504821, 0.11913925565313405, -0.014853043220363772, -0.07158851799633224, -0.04117389646602119, -0.10659551813426939, 0.09048285333371825, -0.013606543326306049, -0.0695416364982272, 0.013134184414027042, -0.0050909726421923965, -0.031910426057010645, -0.1237578712868871, -0.10607067607361349, 0.02464135674771891, -0.046789711591944956, 0.007971046094263334, -0.05678796257817567, 0.0383397497615549, -0.013554058697164976, 0.07337298692561903, 0.010824877020225993, -0.002286345394994049, 0.07311056166453625, -0.16427570460020136, -0.07416025424735768, -0.06565779932631688, 0.05731280463883156, 0.02403778668566271, 0.05668299543527095, 0.026609516590555892, -0.041882435786359536, -0.115150451338319, -0.12669698724963555, 0.021741601612604508, -0.002666856100507307, 0.006252186653313378, -0.04427046631619284, 0.012865202963709773, -0.018120187586399553, 0.07715184849311493, 0.029076275121789518, 0.01707050346508779, 0.013960811294173286, 0.02510059460848152, -0.05925472322478671, 0.10108467015125035, -0.115150451338319, -0.05678796257817567, -0.0425647275036838, -0.043509446597468256, -0.05636808766042451, -0.11966409771378991, -0.007636458751750853, 0.09604618383050095, 0.028708884833179432, -0.04269594013422519, -0.021033064407643583, 0.09515394936585755, -0.049046533721991706, -0.03687018860711455, 0.057417771781736286, 0.02878761283457975, -0.10580825081253072, 0.03634534654645867, -0.1104268685616612, -0.035426870824933454, 0.06838697888787845, 0.08796361228872097, -0.020048986601602505, -0.08413225551519692, 0.11756472947116638, -0.02697690687916598, -0.1412876231896246, -0.055633307083204346, -0.006849195026153802, 0.004858073819123041, -0.07258571960388036, 0.05479356147845686, -0.05038488224589066, 0.06256122947614523, -0.0060750521405354046, -0.01707050346508779, -0.051434570597957266, -0.04602868975784296, 0.1519943944577969, -0.02011459080149578, -0.1390832729964544, 0.05169698951290779, 0.07426522139026241, 0.048967809951346225, -0.021439817639265116, -0.01617827069274633, 0.11284114034837633, 0.10475856669121895, 0.0970958658364353, -0.030204687244501604, 0.004769506562734055, 0.03198915405841096, -0.02700314813604781, -0.1323652996969649, -0.048521691661335825, -0.009709587429794497, -0.007531490339619676, -0.054426173305224194, -0.03248775380449631, 0.053140305179711474, 0.032881385349988225, 0.05327151781025287, 0.06618264984848245, -0.04797060834379811, -0.11158152617200995, -0.017700314784025815, -0.07363540372519213, -0.01776591898391909, 0.051355840481179534, 0.11179145622706456, -0.03626661854505835, -0.04539888055428235, 0.05269419112045591, 0.033957311785870525, -0.08444716329004334, 0.00025360555454871246, 0.028997551351144037, -0.050096219958680896, 0.05335024158089834, -0.04867914554875904, 0.022725681534023, -0.05673548006441202, -0.09552134176984507, -0.013921448985775063, 0.010536214098403, -0.06250874696238158, -0.05130335796741588, 0.016650628547336628, 0.0070066478558883085, -0.06891182517928916, -0.02475944557675326, 0.045293911296000196, -0.07248075246097563, -0.07158851799633224, -0.010569016409887378, 0.11000699575928746, -0.04644856467559411, -0.05474107684931579, 0.01737228743842718, -0.002276504447703445, -0.010378760845593008, 0.0508834809342873, -0.0848670382077945, -0.10313155588011022, -0.039100769480279476, -0.012635583821790728]}}, {'id': 'https://huggingface.co/papers/2410.18234', 'title': 'Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits', 'url': 'https://huggingface.co/papers/2410.18234', 'abstract': 'We consider multi-draft speculative sampling, where the proposal sequences are sampled independently from different draft models. At each step, a token-level draft selection scheme takes a list of valid tokens as input and produces an output token whose distribution matches that of the target model. Previous works have demonstrated that the optimal scheme (which maximizes the probability of accepting one of the input tokens) can be cast as a solution to a linear program. In this work we show that the optimal scheme can be decomposed into a two-step solution: in the first step an importance sampling (IS) type scheme is used to select one intermediate token; in the second step (single-draft) speculative sampling is applied to generate the output token. For the case of two identical draft models we further 1) establish a necessary and sufficient condition on the distributions of the target and draft models for the acceptance probability to equal one and 2) provide an explicit expression for the optimal acceptance probability. Our theoretical analysis also motives a new class of token-level selection scheme based on weighted importance sampling. Our experimental results demonstrate consistent improvements in the achievable block efficiency and token rates over baseline schemes in a number of scenarios.', 'score': 0, 'issue_id': 258, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': 'e421e5808ba5b485', 'data': {'desc': 'Статья рассматривает мультимодельное спекулятивное сэмплирование в контексте языковых моделей. Авторы предлагают оптимальную двухэтапную схему выбора токенов, использующую важностную выборку. Для случая двух идентичных черновых моделей установлены условия для 100% вероятности принятия и получено выражение для оптимальной вероятности. Экспериментальные результаты показывают улучшение эффективности блоков и скорости генерации токенов по сравнению с базовыми методами.', 'emoji': '🎲', 'title': 'Оптимизация выбора токенов при мультимодельном сэмплировании', 'categories': ['#math', '#training', '#optimization'], 'embedding': [0.08981071599646184, -0.001276407107621459, 0.09590122193239498, -0.04142507149026201, -0.07956320852978027, -0.06341855324704082, -0.030500840917267506, 0.013171916864022843, -0.016942227213974436, 0.013824470003263046, 0.06709218170781808, -0.054234458854939, -0.1217133446772074, 0.0577147453629079, 0.07274765006198218, -0.03499621107426415, -0.03750975144229077, -0.05814978294467696, -0.04171509452389135, -0.014658288700529522, -0.01871862208411046, 0.0628868386262175, 0.09536951135333839, 0.020845464400336834, 0.09710964955511445, -0.12210003868724092, 0.05698968676839287, 0.005262724223527701, 0.05201094556230844, -0.06356356375341381, 0.00806628823144867, -0.016422601517410044, -0.02781812229876685, -0.03598712697919084, -0.014658288700529522, 0.09430609221610856, 0.031105058770393955, 0.07332769612924085, -0.048989860338442916, -0.033497754355265266, 0.0232864974942936, -0.04376943158693124, -0.07941819802340729, 0.10614873344084326, 0.08541202085763608, 0.07216760399472348, 0.10315181394019542, -0.14423852892950936, -0.045195385073626984, 0.10498862918102574, -0.09396772763162704, 0.06085667132816202, 0.0425126624133596, -0.06825228394675226, 0.10015490252308101, -0.09449943618980028, -0.016386346869933434, -0.036035462467392934, -0.007407692650962366, -0.018851549728874605, 0.035334573637862306, -0.0848803143203462, 0.005169070830156524, 0.09010074105097453, -0.0546211589276226, 0.016531359397189787, -0.055297880013052185, 0.05911652908461925, 0.003289957894338492, 0.12461358309703426, -0.032482668685354175, 0.04442198694914313, 0.06540037293159404, -0.051962606032339625, -0.03900820816128965, 0.009486196245573276, -0.011202171553368348, 0.10547200427188023, -0.06535204350604203, 0.05307436672042163, -0.00993331729521618, 0.013848638757805773, 0.05563624257665034, -0.08768387570111882, -0.0731343440720157, -0.07859645834807126, 0.0035014338398002454, -0.0027839268822244844, -0.005619212292069134, -0.09329100250443075, -0.07603458451272592, 0.05350940228130733, -0.018053983860289714, 0.03920156021851481, 0.089037317871978, 0.08314016803503672, 0.05022246378879686, 0.05698968676839287, 0.04391444209330422, 0.04026497935574464, 0.061630071473529224, -0.04572709363180021, 0.021546355250750826, 0.016881804822396783, 0.1217133446772074, -0.07424610273921432, 0.00016936940583104937, 0.10740549857264817, -0.05002911577333841, 0.03760642646046167, -0.06341855324704082, -0.039829941773975586, -0.09469278622614208, 0.1160095367930745, -0.05326771473588007, -0.1346677465900241, -0.06970239911489896, 0.031588429819481734, -0.016060071209710845, 0.03555209141830515, -0.03639799479597549, -0.07743637025532062, -0.010869852037281306, 0.014029903911655369, -0.07700133469443493, -0.0013534445959192025, 0.08362354312589122, -0.18532524998147337, -0.010465027268007765, 0.09382271712525406, -0.008990739101463273, 0.04384193684011773, 0.03847649758223305, -0.013208169894792763, -0.005631296164119656, -0.08270513651591775, -0.08990739505639946, 0.03424698271476471, -0.020277501194686992, 0.04246432692515752, 0.07787140581620632, -0.0464279844822142, -0.07458446732369584, 0.034029464934321865, -0.09633625345151395, -0.05911652908461925, -0.05727970980202221, 0.020809211773743584, -0.07743637025532062, 0.04265767494061595, -0.0996715274322265, -0.0977380371732253, -0.013353181411607433, 0.0068155604886814625, 0.0042295142612033395, -0.116492911883929, -0.1305107288922088, 0.0549595194703374, -0.008646336521679052, -0.007951486899981146, -0.013123579152849056, 0.091309168673694, -0.07105584330664148, -0.003413822483498497, 0.01771562331757492, -0.012434772982838932, -0.08081998174511863, 0.0008844216974337077, -0.07936985849343847, 0.015322926722261928, -0.01925033266316705, 0.005987784232661089, -0.04427697644277014, -0.056457976189336276, -0.05486284445216649, -0.08052995871148928, -0.11310930645678108, -0.1421116906550497, 0.07245762702835283, -0.018102321369375167, -0.015395432581713433, 0.06375690974798888, 0.03156426207538069, 0.03100838375222305, 0.023878630464927844, -0.043334396026045545, -0.008090456985991396, 0.040337484608931135, 0.05742472232927856, -0.05002911577333841, 0.07787140581620632, 0.1290606036196453, 0.03212014241942169, -0.01309941039830633, -0.04809562147257048, -0.08125501730600432, 0.048772342558000066, 0.20011645905158693, 0.10121832368119421, 0.027383084716997796, -0.04543706857728751, 0.005078438657408396, -0.026077978034340716, 0.005794434802584295, 0.03618047297376592, -0.0002896462197180553, 0.04147341304111418, -0.05916486457282134, -0.06685049820415755, 0.007147879398503498, 0.033014381285294124, 0.02837400062192449, 0.0316609370935516, 0.0010241467046318818, 0.012990651508084906, 0.026126314532984488, 0.03422281294978031, 0.06888065741867958, 0.05781142038107881, 0.06022828573093453, 0.01766728782937283, 0.0031419251569007704, 0.020108319912887914, 0.021413427605986673, -0.0012824491446908881, 0.10344183697382475, -0.0038971955534696403, -0.04811979123755489, 0.0701857721848701, -0.1011216486630233, -0.056264626152994476, 0.028833203926911227, 0.017292672639181432, -0.05408944834856601, -0.05911652908461925, -0.03866984761857486, 0.01863403194843176, -0.07086249124941632, -0.022778956680221406, -0.2088171702693008, -0.02393905184606382, 0.02114757231645838, 0.03320773132163593, 0.018597779321838512, -0.041231725495686926, 0.019516187952695347, -0.015600865883840747, 0.0020633987040256725, -0.05051248480154284, 0.07816142278718557, 0.024084063362878487, -0.07651795960358042, 0.002557345642000822, 0.011697628293301678, -0.04824063197894347, 0.035890449940136585]}}, {'id': 'https://huggingface.co/papers/2410.18505', 'title': 'CCI3.0-HQ: a large-scale Chinese dataset of high quality designed for pre-training large language models', 'url': 'https://huggingface.co/papers/2410.18505', 'abstract': 'We present CCI3.0-HQ (https://huggingface.co/datasets/BAAI/CCI3-HQ), a high-quality 500GB subset of the Chinese Corpora Internet 3.0 (CCI3.0)(https://huggingface.co/datasets/BAAI/CCI3-Data), developed using a novel two-stage hybrid filtering pipeline that significantly enhances data quality. To evaluate its effectiveness, we trained a 0.5B parameter model from scratch on 100B tokens across various datasets, achieving superior performance on 10 benchmarks in a zero-shot setting compared to CCI3.0, SkyPile, and WanjuanV1. The high-quality filtering process effectively distills the capabilities of the Qwen2-72B-instruct model into a compact 0.5B model, attaining optimal F1 scores for Chinese web data classification. We believe this open-access dataset will facilitate broader access to high-quality language models.', 'score': 0, 'issue_id': 257, 'pub_date': '2024-10-24', 'pub_date_ru': '24 октября', 'hash': '4f06cfa8b602eba9', 'data': {'desc': 'Представлен CCI3.0-HQ - высококачественный набор данных объемом 500 ГБ, полученный из Chinese Corpora Internet 3.0. Для его создания использовался новый двухэтапный гибридный конвейер фильтрации, значительно улучшающий качество данных. Модель с 0.5 миллиардами параметров, обученная на этом наборе, превзошла аналоги на 10 бенчмарках в режиме zero-shot. Процесс фильтрации эффективно дистиллировал возможности модели Qwen2-72B-instruct в компактную модель размером 0.5B.', 'emoji': '🧠', 'title': 'Высококачественные данные для компактных и мощных языковых моделей', 'categories': ['#dataset', '#data', '#benchmark'], 'embedding': [-0.007816975049872412, -0.07501137546195091, 0.0908558759991497, -0.00708660079708521, -0.02387204134456358, -0.06953686390631254, -0.016976259183972667, 0.1727630397497069, -0.056850728192528024, 0.02635925979655107, 0.07243203864023756, -0.0445593898690081, -0.1151753625567003, 0.038453198403602805, -0.012422936636539409, 0.03008350802869585, -0.001030583887398697, -0.019384518157907243, -0.08711847500334735, 0.025898663862578268, -0.038611119402380434, -0.00790909444093415, -0.04466466713040687, 0.005852861352647694, 0.02703041433866499, -0.036716093971782146, 0.0186344041377404, 0.008376269820743416, 0.04053246057365278, -0.10238394549617343, -0.023977320648634136, -0.052086847854022365, -0.1194918017675625, -0.0355053860603143, -0.1194918017675625, -0.009975197106509659, -0.049849664685194764, 0.07227411559878816, -0.022134934870071135, -0.008461809765968694, -0.028899117900573847, 0.016634101445743347, 0.018397525703581642, -0.0358212198871824, -0.015225992592204224, -0.046586010344350996, 0.06553625035163128, 0.0368740108852162, -0.04613857534472291, 0.021726978588133612, -0.10554231849027484, 0.12138682924083256, -0.06106189218466325, -0.05358707385168426, -0.012337396487046954, -0.0062246280270113466, -0.002056232884019278, 0.04482258608651271, -0.06037757670820461, -0.07748543706493725, -0.026898817251248583, -0.06964214116771132, -0.0075998365873604715, 0.016489343423982224, -0.03245228828493986, -0.0843812130975128, 0.032083814806036476, -0.05627168997746816, 0.0036354195853371654, -0.030688864027101567, 0.0341893947594323, 0.055482097239610756, -0.07943310010489904, -0.005859441207018514, 0.056219050325432875, -0.054797781763152115, -0.06290427592055446, 0.09854126519630053, -0.05816671336539465, -0.11064836065235341, -0.03479474871516623, 0.040453503138271646, -0.06827351021479405, -0.1318094558317565, -0.010409472805930464, -0.046586010344350996, 0.013936324385614735, 0.03650553536364103, -0.08590776504920772, 0.01181758145520241, -0.1112800283060896, 0.03974286783579537, -0.03924278909878842, -0.07569568685306596, 0.047007129603305026, -0.023279846280502576, -0.03495266971394386, 0.0197529957221542, 0.07722223676208907, 0.057008645105962076, 0.0149627955576309, -0.015397071665586064, 0.04147997431028781, 0.07011589395068527, 0.014936475118811724, -0.003727538976398905, 0.001171230215113185, -0.08522344548740549, -0.04937590985954904, 0.0726425931630351, -0.0664837681736099, 0.03450523267164398, -0.08953989286895485, 0.019910914678260037, -0.009132964103815436, 0.011837321222582048, -0.03905855235933673, -0.020805786720188006, -0.07722223676208907, 0.018476485181634562, 0.03116261987408319, 0.02287188795589326, 0.037058249667339685, -0.05737712062753724, 0.05108669446535205, -0.04074302122446568, 0.014120562554936678, -0.08585512131182885, -0.04611225347603348, -0.08343370548889315, 0.01616034662009762, -0.0066523242805956884, 0.06264107766037806, 0.048823193513178605, -0.10896388770188087, 0.0020990025502311484, -0.09527760677011318, 0.07511665272334968, -0.12822996766404463, -0.13517840173270157, 0.008422329414140697, -0.07022117325475581, 0.06006173879599293, -0.015120713696668023, -0.07016853360272055, -0.08522344548740549, -0.07269523690041396, -0.017923770877935914, -0.07906462254065208, 0.11264865925900687, -0.056324329629503435, -0.032136452415399974, -0.038268959621479325, 0.010784530224548243, -0.08074908323509387, 0.010067316089037041, -0.0031485036210795437, 0.054534583502975714, 0.023477243954298982, -0.16718324888999794, 0.013252008909156099, 0.05058661777101689, -0.051428850160909576, -0.09543552572621902, 0.05521889897943435, 0.08396010200924593, -0.05382395228584302, -0.005461354706637222, -0.15244416674683753, -0.16434070768009287, -0.012896692279253854, 0.008422329414140697, -0.007520877109307552, -0.11738622385683847, -0.07058965081900277, -0.05363971146104775, -0.04727032582080964, -0.0025645335792492457, -0.06690488130454857, -0.09401425920661005, 0.09154019760362368, -0.002890240864482797, 0.0034215714585449945, -0.058693111928419237, -0.07037909221086165, -0.049586464382346575, 0.04453306800031867, 0.12086043067780798, 0.039795505445158856, 0.0016342939008758143, -0.04595433860527122, 0.06858934404166214, 0.17349998670751363, 0.09254035099229402, 0.022858730085556233, -0.024490555213306325, 0.044585707652353944, 0.0577455981917842, 0.02367464264943128, 0.05953534431831192, -0.026425060382931066, 0.059430062971569574, -0.09275090755776334, -0.06395706487591647, 0.012969072311470311, -0.07074756977510861, 0.021529580914337206, 0.07948573158624715, -0.11928124724476497, -0.04061142005170569, 0.09575135955308713, 0.0646940179617386, 0.048954794685938594, 0.05921950640610025, -0.05606113341199882, 0.03303132445732794, -0.04903375007864793, 0.023069287672361456, 0.027898967575911215, -0.07227411559878816, 0.06837878543352102, 0.02821480650945879, 0.15286528396311977, 0.04216428978674645, -0.08159131766765836, 0.06579945065447948, -0.04419091230476114, -0.0005584728610227537, 0.029004399247316195, -0.14486407728047512, 0.04611225347603348, -0.01802905018200647, -0.09011892495599935, -0.0002794420356404266, -0.08343370548889315, -0.02989926924657237, 0.03645289571160575, -0.03411043323870759, 0.03495266971394386, -0.055482097239610756, -0.05224476272478463, 0.015436551608879702, -0.024424755648262225, 0.053244916113454936, 0.06732600056350259, 0.007823554904243232, -0.03134685763487077, -0.14844355319215624, 0.0909611655165792, -0.08085436253916442, 0.006876042801745628, -0.008632887613747458, -0.05371867298177246, -0.045059462477999676, -0.038479520272292234, -0.005214606490922231]}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            const themeToggle = document.getElementById('theme-toggle');
            let settingSortBy = localStorage.getItem('sort_by');
            const sortDropdown = document.getElementById('sort-dropdown');
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }
            
            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents', '#agi', '#alignment (2)', '#architecture (2)', '#audio', '#benchmark (5)', '#cv (2)', '#data (3)', '#dataset (3)', '#diffusion (1)', '#edge_computing', '#ethics', '#games (1)', '#graphs', '#hallucination (1)', '#inference', '#interpretability (1)', '#math (2)', '#medicine', '#multilingual', '#multimodal (2)', '#optimization (3)', '#plp', '#quantum', '#rag', '#reasoning', '#rl (2)', '#rlhf (1)', '#robotics', '#security', '#story_generation', '#survey', '#training (3)', '#transfer_learning', '#video (1)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = '🏷️ Фильтр';
            } else {
                categoryToggle.textContent = `🏷️ Фильтр (${formatArticlesTitle(selectedArticles.length)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles = selectedCategories.length === 0
                ? articlesData
                : articlesData.filter(article => 
                    article.data && article.data.categories && 
                    article.data.categories.some(cat => selectedCategories.includes(cat))
                );

            console.log('filteredArticles', filteredArticles)

            //if (filteredArticles.length === 0) {
            //    selectedArticles = articlesData;
            //    selectedCategories = [];
            //    cleanCategorySelection();
            //} else {
            //    selectedArticles = filteredArticles;
            //}

            selectedArticles = filteredArticles;

            console.log('selectedArticles', selectedArticles)

            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                const explanation = item["data"]["desc"];
                const cats = item["data"]["categories"].join(" ");
                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="background-digit">${index + 1}</div>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <h2>${item['data']['emoji']} ${item['title']}</h2>
                            <p class="meta"><svg class="text-sm peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path transform="translate(0, 2)" fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg> ${item['score']}. ${item['data']['title']}</p>
                            <p class="pub-date">📅 Статья от ${item['pub_date_ru']}</p>
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>
                            <div class="links">
                                <a href="${item['url']}" target="_blank">Статья</a>
                            </div>
                            <p class="tags">${cats}</p>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            }
            if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
        });

        clearCategoriesButton.addEventListener('click', clearAllCategories);
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiffRu('2024-10-25 04:17');
        } 
        function hideNextLink() {
            if (isToday('2024-10-25 04:17')) {
                const element = document.getElementById('nav-next');
                if (element) {    
                    element.style.display = 'none';
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink(); 
    </script>
</body>
</html>
    