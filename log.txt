[30.10.2024 12:23] [Experimental] Generating an image for paper CLEAR: Character Unlearning in Textual and Visual Modalities.
[30.10.2024 12:23] [Experimental] Image for paper CLEAR: Character Unlearning in Textual and Visual Modalities already exists.
[30.10.2024 12:23] [Experimental] Generating an image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions.
[30.10.2024 12:23] [Experimental] Image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions already exists.
[30.10.2024 12:23] [Experimental] Generating an image for paper SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.
[30.10.2024 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Write a text with image prompt in style of surrealism and modern art based on the following paper. Use key themes and elements from it. Add instruction to write a text that reads as brief paper title as a label on some object on an image. Style: linear art on white background. Return only prompt and nothing else. Title: 'SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization' Text: 'Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To address these issues, we first present a simple yet well-crafted framework named {\name}, which combines the perception capability of Vision Foundation Models (VFMs) and the reasoning capability of Large Language Models (LLMs) within a modular framework, providing a strong baseline for social relation recognition. Specifically, we instruct VFMs to translate image content into a textual social story, and then utilize LLMs for text-based reasoning. {\name} introduces systematic design principles to adapt VFMs and LLMs separately and bridge their gaps. Without additional model training, it achieves competitive zero-shot results on two databases while offering interpretable answers, as LLMs can generate language-based explanations for the decisions. The manual prompt design process for LLMs at the reasoning phase is tedious and an automated prompt optimization method is desired. As we essentially convert a visual classification task into a generative task of LLMs, automatic prompt optimization encounters a unique long prompt optimization issue. To address this issue, we further propose the Greedy Segment Prompt Optimization (GSPO), which performs a greedy search by utilizing gradient information at the segment level. Experimental results show that GSPO significantly improves performance, and our method also generalizes to different image styles. The code is available at https://github.com/Mengzibin/SocialGPT.'
[30.10.2024 12:23] Response: **Prompt:** Create a linear art piece on a white background that depicts a surreal scene blending the worlds of visual perception and textual reasoning. Visualize a giant eye made of interwoven threads representing Vision Foundation Models, looking at a cluster of abstract human figures symbolizing social relations (friends, spouses, colleagues). Each figure is connected by colorful, flowing lines to a central book that represents Large Language Models, from which whimsical text bubbles emanate, giving language-based explanations. Place a label beneath the central book that reads: "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization."
[30.10.2024 12:23] Generating image by prompt: **Prompt:** Create a linear art piece on a white background that depicts a surreal scene blending the worlds of visual perception and textual reasoning. Visualize a giant eye made of interwoven threads representing Vision Foundation Models, looking at a cluster of abstract human figures symbolizing social relations (friends, spouses, colleagues). Each figure is connected by colorful, flowing lines to a central book that represents Large Language Models, from which whimsical text bubbles emanate, giving language-based explanations. Place a label beneath the central book that reads: "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.".
[30.10.2024 12:23] Saving generated image from https://fal.media/files/elephant/GbnJ5wEUskVTzo_yYIOLi.png to ad99b3e3b4ef165c.jpg.
[30.10.2024 12:23] [Experimental] Generating an image for paper OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization.
[30.10.2024 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Write a text with image prompt in style of surrealism and modern art based on the following paper. Use key themes and elements from it. Add instruction to write a text that reads as brief paper title as a label on some object on an image. Style: linear art on white background. Return only prompt and nothing else. Title: 'OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization' Text: 'The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with the ability to explore environments and continuously improve over time, they are building text-only agents in synthetic environments where the reward signals are clearly defined. Such agents struggle to generalize to realistic settings that require multimodal perception abilities and lack ground-truth signals. In this paper, we introduce an open-source framework designed to facilitate the development of multimodal web agent that can autonomously conduct real-world exploration and improve itself. We first train the base model with imitation learning to gain the basic abilities. We then let the agent explore the open web and collect feedback on its trajectories. After that, it further improves its policy by learning from well-performing trajectories judged by another general-purpose model. This exploration-feedback-optimization cycle can continue for several iterations. Experimental results show that our web agent successfully improves itself after each iteration, demonstrating strong performance across multiple test sets.'
[30.10.2024 12:23] Response: **Prompt:** Create a piece of linear art on a white background depicting a surreal landscape where a large, abstract figure represents a web agent. This figure is intertwined with various digital elements symbolizing multimodal perception—like distorted screens displaying text, images, and audio waves. In the background, a labyrinth of pathways represents the open web, with feedback loops illustrated as swirling arrows guiding the agent's exploration. Above the figure, inscribe the title: "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization" in a modern, minimalist font, as if it were a label on an art piece.
[30.10.2024 12:23] Generating image by prompt: **Prompt:** Create a piece of linear art on a white background depicting a surreal landscape where a large, abstract figure represents a web agent. This figure is intertwined with various digital elements symbolizing multimodal perception—like distorted screens displaying text, images, and audio waves. In the background, a labyrinth of pathways represents the open web, with feedback loops illustrated as swirling arrows guiding the agent's exploration. Above the figure, inscribe the title: "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization" in a modern, minimalist font, as if it were a label on an art piece..
[30.10.2024 12:23] Saving generated image from https://fal.media/files/elephant/x1htojugc1YaDe9myJ7Jr.png to c9775abc4b4ddd0d.jpg.
