
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 9 papers. March 2025.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #7a30efcf;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: #7a30efcf;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #7a30ef17;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ", "Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹", "Ğ¼Ğ¸Ğ½ÑƒÑ‚"],
                hour: ["Ñ‡Ğ°Ñ", "Ñ‡Ğ°ÑĞ°", "Ñ‡Ğ°ÑĞ¾Ğ²"],
                day: ["Ğ´ĞµĞ½ÑŒ", "Ğ´Ğ½Ñ", "Ğ´Ğ½ĞµĞ¹"],
                justNow: "Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾",
                ago: "Ğ½Ğ°Ğ·Ğ°Ğ´"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["åˆ†é’Ÿ", "åˆ†é’Ÿ", "åˆ†é’Ÿ"],
                hour: ["å°æ—¶", "å°æ—¶", "å°æ—¶"],
                day: ["å¤©", "å¤©", "å¤©"],
                justNow: "åˆšåˆš",
                ago: "å‰"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            } else if (lastDigit === 1) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒÑ";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒĞ¸";
            } else {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "ç¯‡è®ºæ–‡"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">ğŸ”º</h1><h1 class="title-text" id="doomgrad">hf monthly</h1></a>
            <p><span id="title-date">ĞœĞ°Ñ€Ñ‚ 2025</span> | <span id="title-articles-count">9 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/m/2025-02.html">â¬…ï¸ <span id="prev-date">02.2025</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/m/2025-04.html">â¡ï¸ <span id="next-date">04.2025</span></a></span>
            <span class="nav-item" id="nav-daily"><a href="https://hfday.ru">ğŸ“ˆ <span id='top-day-label'>Ğ”ĞµĞ½ÑŒ</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">ğŸ”€ <span id="sort-label-text">Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ</option>
                    <option value="pub_date">Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸</option>
                    <option value="issue_id">Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">ğŸ·ï¸ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> AâˆªB</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> Aâˆ©B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">ğŸ§¹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> âœ–ï¸ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': 'ĞœĞ°Ñ€Ñ‚ 2025', 'en': 'March 2025', 'zh': '3æœˆ2025å¹´'};
        let feedDateNext = {'ru': '04.2025', 'en': '04/2025', 'zh': '4æœˆ2025å¹´'};
        let feedDatePrev = {'ru': '02.2025', 'en': '02/2025', 'zh': '2æœˆ2025å¹´'};
        let filterLabel = {'ru': 'Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€', 'en': 'Topics', 'zh': 'ä¸»é¢˜ç­›é€‰'}
        let publishedLabel = {'ru': 'ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ñ‚ ', 'en': 'published on ', 'zh': 'å‘è¡¨äº'}
        let sortLabel = {'ru': 'Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾', 'en': 'Sort by', 'zh': 'æ’åºæ–¹å¼'}
        let paperLabel = {'ru': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ', 'en': 'Paper', 'zh': 'è®ºæ–‡'}
        let topMonthLabel = {'ru': 'ĞœĞµÑÑÑ†', 'en': 'Month', 'zh': 'æœˆåº¦è®ºæ–‡'}
        let topDayLabel = {'ru': 'Ğ”ĞµĞ½ÑŒ', 'en': 'Day', 'zh': 'æ—¥åº¦è®ºæ–‡'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf moonly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf monthly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2502.20730', 'title': 'DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking', 'url': 'https://huggingface.co/papers/2502.20730', 'abstract': "Designing solutions for complex engineering challenges is crucial in human production activities. However, previous research in the retrieval-augmented generation (RAG) field has not sufficiently addressed tasks related to the design of complex engineering solutions. To fill this gap, we introduce a new benchmark, SolutionBench, to evaluate a system's ability to generate complete and feasible solutions for engineering problems with multiple complex constraints. To further advance the design of complex engineering solutions, we propose a novel system, SolutionRAG, that leverages the tree-based exploration and bi-point thinking mechanism to generate reliable solutions. Extensive experimental results demonstrate that SolutionRAG achieves state-of-the-art (SOTA) performance on the SolutionBench, highlighting its potential to enhance the automation and reliability of complex engineering solution design in real-world applications.", 'score': 14, 'issue_id': 2486, 'pub_date': '2025-02-28', 'pub_date_card': {'ru': '28 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 28', 'zh': '2æœˆ28æ—¥'}, 'hash': 'e9ef168e304ec240', 'authors': ['Zhuoqun Li', 'Haiyang Yu', 'Xuanang Chen', 'Hongyu Lin', 'Yaojie Lu', 'Fei Huang', 'Xianpei Han', 'Yongbin Li', 'Le Sun'], 'affiliations': ['Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences', 'Tongyi Lab', 'University of Chinese Academy of Sciences'], 'pdf_title_img': 'assets/pdf/title_img/2502.20730.jpg', 'data': {'categories': ['#rag', '#benchmark'], 'emoji': 'ğŸ”§', 'ru': {'title': 'Ğ£Ğ¼Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº SolutionBench Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ SolutionRAG, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰ÑƒÑ Ğ´Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ğ¾Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ´Ğ²ÑƒÑ…Ñ‚Ğ¾Ñ‡ĞµÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ SolutionRAG Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ½Ğ° SolutionBench. Ğ­Ñ‚Ğ¾ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ….'}, 'en': {'title': 'Revolutionizing Engineering Design with SolutionRAG', 'desc': 'This paper addresses the need for effective solutions in complex engineering design tasks, which have been overlooked in previous research on retrieval-augmented generation (RAG). It introduces a new benchmark called SolutionBench, aimed at evaluating the generation of feasible solutions under multiple constraints. The authors propose a novel system named SolutionRAG, which utilizes tree-based exploration and bi-point thinking to improve solution reliability. Experimental results show that SolutionRAG outperforms existing methods, indicating its potential to automate and enhance the design process in engineering applications.'}, 'zh': {'title': 'æå‡å¤æ‚å·¥ç¨‹è®¾è®¡çš„è‡ªåŠ¨åŒ–ä¸å¯é æ€§', 'desc': 'æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œç§°ä¸ºSolutionBenchï¼Œç”¨äºè¯„ä¼°ç³»ç»Ÿåœ¨ç”Ÿæˆå¤æ‚å·¥ç¨‹é—®é¢˜çš„å®Œæ•´å’Œå¯è¡Œè§£å†³æ–¹æ¡ˆæ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°ç³»ç»ŸSolutionRAGï¼Œåˆ©ç”¨æ ‘å½¢æ¢ç´¢å’ŒåŒç‚¹æ€ç»´æœºåˆ¶æ¥ç”Ÿæˆå¯é çš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å¤§é‡å®éªŒç»“æœï¼ŒSolutionRAGåœ¨SolutionBenchä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­æé«˜å¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡çš„è‡ªåŠ¨åŒ–å’Œå¯é æ€§çš„æ½œåŠ›ã€‚æ­¤ç ”ç©¶å¡«è¡¥äº†ä»¥å¾€åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é¢†åŸŸä¸­å¯¹å¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡ä»»åŠ¡çš„ç ”ç©¶ç©ºç™½ã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.18600', 'title': 'Chain of Draft: Thinking Faster by Writing Less', 'url': 'https://huggingface.co/papers/2502.18600', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning. However, humans typically employ a more efficient strategy: drafting concise intermediate thoughts that capture only essential information. In this work, we propose Chain of Draft (CoD), a novel paradigm inspired by human cognitive processes, where LLMs generate minimalistic yet informative intermediate reasoning outputs while solving tasks. By reducing verbosity and focusing on critical insights, CoD matches or surpasses CoT in accuracy while using as little as only 7.6% of the tokens, significantly reducing cost and latency across various reasoning tasks.', 'score': 8, 'issue_id': 2491, 'pub_date': '2025-02-25', 'pub_date_card': {'ru': '25 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 25', 'zh': '2æœˆ25æ—¥'}, 'hash': '739d903f5735d9eb', 'authors': ['Silei Xu', 'Wenhao Xie', 'Lingxiao Zhao', 'Pengcheng He'], 'affiliations': ['Zoom Communications'], 'pdf_title_img': 'assets/pdf/title_img/2502.18600.jpg', 'data': {'categories': ['#reasoning', '#training', '#rl'], 'emoji': 'âœï¸', 'ru': {'title': 'Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ: ĞºÑ€Ğ°Ñ‚ĞºĞ¾ÑÑ‚ÑŒ - ÑĞµÑÑ‚Ñ€Ğ° Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ - Chain of Draft (CoD). Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Chain-of-Thought (CoT), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, CoD Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´, Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¼Ñ‹ÑĞ»Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ´Ğ¾ÑÑ‚Ğ¸Ñ‡ÑŒ Ñ‚Ğ¾Ğ¹ Ğ¶Ğµ Ğ¸Ğ»Ğ¸ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¸ CoT, Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ². CoD Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, ÑĞ½Ğ¸Ğ¶Ğ°Ñ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ¸ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸.'}, 'en': {'title': 'Streamlining Reasoning: Less is More with Chain of Draft', 'desc': 'This paper introduces Chain of Draft (CoD), a new approach for Large Language Models (LLMs) that mimics human reasoning by generating concise intermediate thoughts. Unlike the traditional Chain-of-Thought (CoT) prompting, which relies on verbose explanations, CoD focuses on delivering essential information in a minimalistic format. The authors demonstrate that CoD can achieve comparable or even superior accuracy to CoT while using significantly fewer tokens, leading to reduced computational costs and faster processing times. This innovative method enhances the efficiency of LLMs in tackling complex reasoning tasks.'}, 'zh': {'title': 'è‰ç¨¿é“¾ï¼šé«˜æ•ˆæ¨ç†çš„æ–°æ–¹æ³•', 'desc': 'å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§£å†³å¤æ‚æ¨ç†ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯é€šè¿‡é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºï¼Œå¼ºè°ƒé€æ­¥æ¨ç†çš„è¯¦ç»†è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œäººç±»é€šå¸¸é‡‡ç”¨æ›´é«˜æ•ˆçš„ç­–ç•¥ï¼šè‰æ‹Ÿç®€æ´çš„ä¸­é—´æ€è€ƒï¼Œåªæ•æ‰å…³é”®ä¿¡æ¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°èŒƒå¼â€”â€”è‰ç¨¿é“¾ï¼ˆCoDï¼‰ï¼Œçµæ„Ÿæ¥æºäºäººç±»çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œä½¿LLMsåœ¨è§£å†³ä»»åŠ¡æ—¶ç”Ÿæˆç®€çº¦è€Œä¿¡æ¯ä¸°å¯Œçš„ä¸­é—´æ¨ç†è¾“å‡ºã€‚é€šè¿‡å‡å°‘å†—é•¿å¹¶ä¸“æ³¨äºå…³é”®è§è§£ï¼ŒCoDåœ¨å‡†ç¡®æ€§ä¸Šä¸CoTç›¸åŒ¹é…æˆ–è¶…è¶Šï¼ŒåŒæ—¶ä»…ä½¿ç”¨7.6%çš„æ ‡è®°ï¼Œæ˜¾è‘—é™ä½äº†å„ç§æ¨ç†ä»»åŠ¡çš„æˆæœ¬å’Œå»¶è¿Ÿã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.18017', 'title': 'ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents', 'url': 'https://huggingface.co/papers/2502.18017', 'abstract': "Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehension, and reasoning within dense visual documents. To bridge this gap, we introduce ViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich documents requiring complex reasoning. Based on it, we identify key limitations in current RAG approaches: (i) purely visual retrieval methods struggle to effectively integrate both textual and visual features, and (ii) previous approaches often allocate insufficient reasoning tokens, limiting their effectiveness. To address these challenges, we propose ViDoRAG, a novel multi-agent RAG framework tailored for complex reasoning across visual documents. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy to effectively handle multi-modal retrieval. To further elicit the model's reasoning capabilities, we introduce an iterative agent workflow incorporating exploration, summarization, and reflection, providing a framework for investigating test-time scaling in RAG domains. Extensive experiments on ViDoSeek validate the effectiveness and generalization of our approach. Notably, ViDoRAG outperforms existing methods by over 10% on the competitive ViDoSeek benchmark.", 'score': 4, 'issue_id': 2487, 'pub_date': '2025-02-25', 'pub_date_card': {'ru': '25 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 25', 'zh': '2æœˆ25æ—¥'}, 'hash': '4202273d8c895c2a', 'authors': ['Qiuchen Wang', 'Ruixue Ding', 'Zehui Chen', 'Weiqi Wu', 'Shihang Wang', 'Pengjun Xie', 'Feng Zhao'], 'affiliations': ['MoE Key Laboratory of Brain-inspired Intelligent Perception and Cognition, USTC', 'Shanghai Jiao Tong University', 'Tongyi Lab, Alibaba Group'], 'pdf_title_img': 'assets/pdf/title_img/2502.18017.jpg', 'data': {'categories': ['#reasoning', '#agents', '#rag', '#games', '#benchmark', '#multimodal', '#dataset'], 'emoji': 'ğŸ”', 'ru': {'title': 'ViDoRAG: ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ· Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ViDoSeek Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ (RAG) Ğ½Ğ° Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾ Ğ½Ğ°ÑÑ‹Ñ‰ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ»ÑÑÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² RAG Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ”Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ViDoRAG, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ³Ğ°ÑƒÑÑĞ¾Ğ²Ñ‹Ñ… ÑĞ¼ĞµÑĞµĞ¹ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°. ViDoRAG Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ Ğ½Ğ° 10% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ ViDoSeek.'}, 'en': {'title': 'Enhancing RAG for Complex Visual Reasoning with ViDoRAG', 'desc': 'This paper addresses the challenges of understanding complex information in visually rich documents using Retrieval-Augmented Generation (RAG) methods. It introduces ViDoSeek, a new dataset that tests RAG performance on documents that require advanced reasoning skills. The authors highlight limitations in current RAG techniques, such as difficulties in integrating visual and textual data and inadequate reasoning capabilities. To overcome these issues, they propose ViDoRAG, a multi-agent framework that enhances retrieval and reasoning through a hybrid strategy and an iterative workflow, demonstrating significant improvements in performance on the ViDoSeek benchmark.'}, 'zh': {'title': 'æå‡è§†è§‰æ–‡æ¡£ç†è§£çš„RAGæ–°æ¡†æ¶', 'desc': 'ç†è§£è§†è§‰ä¸°å¯Œæ–‡æ¡£ä¸­çš„ä¿¡æ¯å¯¹ä¼ ç»Ÿçš„å¢å¼ºæ£€ç´¢ç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•æ¥è¯´ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰çš„åŸºå‡†ä¸»è¦é›†ä¸­åœ¨åŸºäºå›¾åƒçš„é—®é¢˜å›ç­”ï¼ˆQAï¼‰ï¼Œè€Œå¿½è§†äº†åœ¨å¯†é›†è§†è§‰æ–‡æ¡£ä¸­é«˜æ•ˆæ£€ç´¢ã€ç†è§£å’Œæ¨ç†çš„åŸºæœ¬æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ViDoSeekï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°RAGåœ¨éœ€è¦å¤æ‚æ¨ç†çš„è§†è§‰ä¸°å¯Œæ–‡æ¡£ä¸Šçš„è¡¨ç°ã€‚æˆ‘ä»¬æå‡ºçš„ViDoRAGæ¡†æ¶é‡‡ç”¨æ··åˆç­–ç•¥ï¼Œç»“åˆå¤šæ¨¡æ€æ£€ç´¢å’Œè¿­ä»£ä»£ç†å·¥ä½œæµï¼Œä»¥æé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨ViDoSeekåŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.20545', 'title': 'SoS1: O1 and R1-Like Reasoning LLMs are Sum-of-Square Solvers', 'url': 'https://huggingface.co/papers/2502.20545', 'abstract': "Large Language Models (LLMs) have achieved human-level proficiency across diverse tasks, but their ability to perform rigorous mathematical problem solving remains an open challenge. In this work, we investigate a fundamental yet computationally intractable problem: determining whether a given multivariate polynomial is nonnegative. This problem, closely related to Hilbert's Seventeenth Problem, plays a crucial role in global polynomial optimization and has applications in various fields. First, we introduce SoS-1K, a meticulously curated dataset of approximately 1,000 polynomials, along with expert-designed reasoning instructions based on five progressively challenging criteria. Evaluating multiple state-of-the-art LLMs, we find that without structured guidance, all models perform only slightly above the random guess baseline 50%. However, high-quality reasoning instructions significantly improve accuracy, boosting performance up to 81%. Furthermore, our 7B model, SoS-7B, fine-tuned on SoS-1K for just 4 hours, outperforms the 671B DeepSeek-V3 and GPT-4o-mini in accuracy while only requiring 1.8% and 5% of the computation time needed for letters, respectively. Our findings highlight the potential of LLMs to push the boundaries of mathematical reasoning and tackle NP-hard problems.", 'score': 4, 'issue_id': 2486, 'pub_date': '2025-02-27', 'pub_date_card': {'ru': '27 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 27', 'zh': '2æœˆ27æ—¥'}, 'hash': 'fb32f9423103ece9', 'authors': ['Kechen Li', 'Wenqi Zhu', 'Coralia Cartis', 'Tianbo Ji', 'Shiwei Liu'], 'affiliations': ['Mathematical Institute, University of Oxford', 'Nanjing University of Aeronautics and Astronautics', 'School of Transportation and Civil Engineering, Nantong University'], 'pdf_title_img': 'assets/pdf/title_img/2502.20545.jpg', 'data': {'categories': ['#dataset', '#optimization', '#training', '#math', '#reasoning'], 'emoji': 'ğŸ§®', 'ru': {'title': 'Ğ‘Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ²Ğ°ÑÑ‚ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ', 'desc': 'Ğ’ ÑÑ‚Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ÑÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ€ĞµÑˆĞ°Ñ‚ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ² Ñ‡Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»Ğ¸Ğ½Ğ¾Ğ¼Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ SoS-1K Ğ¸Ğ· 1000 Ğ¿Ğ¾Ğ»Ğ¸Ğ½Ğ¾Ğ¼Ğ¾Ğ² Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ±ĞµĞ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ»ÑƒÑ‡ÑˆĞµ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ³Ğ°Ğ´Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ½Ğ¾ Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ÑÑ Ğ´Ğ¾ 81%. ĞœĞ¾Ğ´ĞµĞ»ÑŒ SoS-7B, Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° SoS-1K, Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾ÑˆĞ»Ğ° Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹.'}, 'en': {'title': 'Unlocking Mathematical Reasoning in LLMs with Structured Guidance', 'desc': 'This paper explores the limitations of Large Language Models (LLMs) in solving complex mathematical problems, specifically the challenge of determining if a multivariate polynomial is nonnegative. The authors introduce a new dataset called SoS-1K, which contains around 1,000 polynomials and structured reasoning instructions to guide the models. They demonstrate that LLMs perform poorly without guidance, achieving only slightly above random guessing, but can significantly improve their accuracy with high-quality instructions. Notably, their fine-tuned model, SoS-7B, surpasses larger models in performance while being more computationally efficient, showcasing the potential of LLMs in addressing NP-hard problems.'}, 'zh': {'title': 'æ¨åŠ¨æ•°å­¦æ¨ç†çš„è¾¹ç•Œ', 'desc': 'å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¾¾åˆ°äº†äººç±»æ°´å¹³çš„èƒ½åŠ›ï¼Œä½†åœ¨ä¸¥æ ¼çš„æ•°å­¦é—®é¢˜è§£å†³æ–¹é¢ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¸€ä¸ªåŸºæœ¬ä½†è®¡ç®—ä¸Šéš¾ä»¥å¤„ç†çš„é—®é¢˜ï¼šåˆ¤æ–­ç»™å®šçš„å¤šå˜é‡å¤šé¡¹å¼æ˜¯å¦éè´Ÿã€‚æˆ‘ä»¬å¼•å…¥äº†SoS-1Kæ•°æ®é›†ï¼ŒåŒ…å«çº¦1000ä¸ªå¤šé¡¹å¼ï¼Œå¹¶è®¾è®¡äº†åŸºäºäº”ä¸ªé€æ­¥æŒ‘æˆ˜æ ‡å‡†çš„æ¨ç†æŒ‡å¯¼ã€‚å®éªŒè¡¨æ˜ï¼Œç»è¿‡é«˜è´¨é‡çš„æ¨ç†æŒ‡å¯¼åï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡æ˜¾è‘—æé«˜ï¼Œæœ€é«˜å¯è¾¾81%ã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.17941', 'title': 'Optimal Brain Apoptosis', 'url': 'https://huggingface.co/papers/2502.17941', 'abstract': 'The increasing complexity and parameter count of Convolutional Neural Networks (CNNs) and Transformers pose challenges in terms of computational efficiency and resource demands. Pruning has been identified as an effective strategy to address these challenges by removing redundant elements such as neurons, channels, or connections, thereby enhancing computational efficiency without heavily compromising performance. This paper builds on the foundational work of Optimal Brain Damage (OBD) by advancing the methodology of parameter importance estimation using the Hessian matrix. Unlike previous approaches that rely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel pruning method that calculates the Hessian-vector product value directly for each parameter. By decomposing the Hessian matrix across network layers and identifying conditions under which inter-layer Hessian submatrices are non-zero, we propose a highly efficient technique for computing the second-order Taylor expansion of parameters. This approach allows for a more precise pruning process, particularly in the context of CNNs and Transformers, as validated in our experiments including VGG19, ResNet32, ResNet50, and ViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at https://github.com/NEU-REAL/OBA.', 'score': 3, 'issue_id': 2495, 'pub_date': '2025-02-25', 'pub_date_card': {'ru': '25 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 25', 'zh': '2æœˆ25æ—¥'}, 'hash': '3748780b9de1393e', 'authors': ['Mingyuan Sun', 'Zheng Fang', 'Jiaxu Wang', 'Junjie Jiang', 'Delei Kong', 'Chenming Hu', 'Yuetong Fang', 'Renjing Xu'], 'affiliations': ['Hunan University', 'Northeastern University', 'The Hong Kong University of Science and Technology (Guangzhou)'], 'pdf_title_img': 'assets/pdf/title_img/2502.17941.jpg', 'data': {'categories': ['#optimization', '#inference', '#training', '#architecture'], 'emoji': 'âœ‚ï¸', 'ru': {'title': 'Ğ¢Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ° Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑ‡ĞµÑ‚Ğ° Ğ“ĞµÑÑĞ¸Ğ°Ğ½Ğ°', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ñ€ÑƒĞ½Ğ¸Ğ½Ğ³Ğ° Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Optimal Brain Apoptosis (OBA). OBA Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ñ€Ğ°ÑÑ‡ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ“ĞµÑÑĞ¸Ğ°Ğ½Ğ° Ğ½Ğ° Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ². ĞœĞµÑ‚Ğ¾Ğ´ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ğº ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¼ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¼ ÑĞµÑ‚ÑĞ¼ Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ°Ğ¼, Ñ€Ğ°Ğ·Ğ»Ğ°Ğ³Ğ°Ñ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñƒ Ğ“ĞµÑÑĞ¸Ğ°Ğ½Ğ° Ğ¿Ğ¾ ÑĞ»Ğ¾ÑĞ¼ ÑĞµÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ñ… Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ… Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°.'}, 'en': {'title': 'Efficient Neural Network Pruning with Optimal Brain Apoptosis', 'desc': 'This paper addresses the challenges of high computational demands in Convolutional Neural Networks (CNNs) and Transformers by introducing a new pruning method called Optimal Brain Apoptosis (OBA). OBA improves upon previous methods by directly calculating the Hessian-vector product for each parameter, allowing for more accurate estimation of parameter importance. The authors decompose the Hessian matrix across layers to identify non-zero conditions, which enhances the efficiency of the pruning process. Experimental results demonstrate the effectiveness of OBA on various architectures and datasets, confirming its potential to optimize neural networks without significant performance loss.'}, 'zh': {'title': 'é«˜æ•ˆå‰ªæï¼šæœ€ä¼˜è„‘å‡‹äº¡æ–¹æ³•', 'desc': 'éšç€å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œå˜æ¢å™¨ï¼ˆTransformersï¼‰æ¨¡å‹çš„å¤æ‚æ€§å’Œå‚æ•°æ•°é‡çš„å¢åŠ ï¼Œè®¡ç®—æ•ˆç‡å’Œèµ„æºéœ€æ±‚é¢ä¸´æŒ‘æˆ˜ã€‚å‰ªæè¢«è®¤ä¸ºæ˜¯ä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥ï¼Œé€šè¿‡å»é™¤å†—ä½™å…ƒç´ ï¼ˆå¦‚ç¥ç»å…ƒã€é€šé“æˆ–è¿æ¥ï¼‰æ¥æé«˜è®¡ç®—æ•ˆç‡ï¼Œè€Œä¸ä¼šä¸¥é‡å½±å“æ€§èƒ½ã€‚æœ¬æ–‡åœ¨æœ€ä¼˜è„‘æŸä¼¤ï¼ˆOBDï¼‰çš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å‰ªææ–¹æ³•â€”â€”æœ€ä¼˜è„‘å‡‹äº¡ï¼ˆOBAï¼‰ï¼Œé€šè¿‡ç›´æ¥è®¡ç®—æ¯ä¸ªå‚æ•°çš„Hessian-å‘é‡ä¹˜ç§¯å€¼æ¥ä¼°è®¡å‚æ•°çš„é‡è¦æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼ŒåŒ…æ‹¬VGG19ã€ResNet32ã€ResNet50å’ŒViT-B/16ï¼Œå±•ç¤ºäº†åœ¨CNNå’ŒTransformersä¸­çš„é«˜æ•ˆå‰ªæè¿‡ç¨‹ã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.19577', 'title': 'Tell me why: Visual foundation models as self-explainable classifiers', 'url': 'https://huggingface.co/papers/2502.19577', 'abstract': 'Visual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, self-explainable models (SEM) aim to provide interpretable classifiers that decompose predictions into a weighted sum of interpretable concepts. Despite their promise, recent studies have shown that these explanations often lack faithfulness. In this work, we combine VFMs with a novel prototypical architecture and specialized training objectives. By training only a lightweight head (approximately 1M parameters) on top of frozen VFMs, our approach (ProtoFM) offers an efficient and interpretable solution. Evaluations demonstrate that our approach achieves competitive classification performance while outperforming existing models across a range of interpretability metrics derived from the literature. Code is available at https://github.com/hturbe/proto-fm.', 'score': 2, 'issue_id': 2493, 'pub_date': '2025-02-26', 'pub_date_card': {'ru': '26 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 26', 'zh': '2æœˆ26æ—¥'}, 'hash': '7d2bd5235959eba5', 'authors': ['Hugues TurbÃ©', 'Mina Bjelogrlic', 'Gianmarco Mengaldo', 'Christian Lovis'], 'affiliations': ['Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore, Singapore', 'Department of Radiology and Medical Informatics, University of Geneva, Geneva, Switzerland', 'Division of Medical Information Sciences, Geneva University Hospitals, Geneva, Switzerland'], 'pdf_title_img': 'assets/pdf/title_img/2502.19577.jpg', 'data': {'categories': ['#cv', '#small_models', '#architecture', '#interpretability', '#open_source', '#training', '#optimization'], 'emoji': 'ğŸ”', 'ru': {'title': 'ProtoFM: Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹-Ğ¾ÑĞ½Ğ¾Ğ² (VFM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ VFM Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾Ñ‚Ğ¸Ğ¿Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ¾Ğ¹ Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ†ĞµĞ»ÑĞ¼Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ½ÑƒÑ ProtoFM. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ»ĞµĞ³ĞºĞ¾Ğ²ĞµÑĞ½ÑƒÑ Ğ²ĞµÑ€Ñ…ÑƒÑˆĞºÑƒ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ… Ğ·Ğ°Ğ¼Ğ¾Ñ€Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… VFM, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ProtoFM Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ñ€ÑĞ´Ñƒ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸.'}, 'en': {'title': 'ProtoFM: Interpretable and Efficient Visual Foundation Models', 'desc': 'This paper introduces ProtoFM, a new approach that combines visual foundation models (VFMs) with a prototypical architecture to enhance interpretability in machine learning. The method focuses on creating self-explainable models (SEMs) that break down predictions into understandable components, addressing the issue of faithfulness in explanations. By training a lightweight head on top of frozen VFMs, ProtoFM maintains high classification performance while improving interpretability metrics. The results show that ProtoFM outperforms existing models, making it a promising solution for applications requiring both accuracy and clarity.'}, 'zh': {'title': 'é«˜æ•ˆå¯è§£é‡Šçš„è§†è§‰åŸºç¡€æ¨¡å‹', 'desc': 'è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMï¼‰å› å…¶å“è¶Šçš„æ€§èƒ½è€Œå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä½†åœ¨å…³é”®åº”ç”¨ä¸­å¯è§£é‡Šæ€§ä»ç„¶è‡³å…³é‡è¦ã€‚è‡ªè§£é‡Šæ¨¡å‹ï¼ˆSEMï¼‰æ—¨åœ¨æä¾›å¯è§£é‡Šçš„åˆ†ç±»å™¨ï¼Œå°†é¢„æµ‹åˆ†è§£ä¸ºå¯è§£é‡Šæ¦‚å¿µçš„åŠ æƒå’Œã€‚å°½ç®¡æœ‰æ½œåŠ›ï¼Œè¿‘æœŸç ”ç©¶è¡¨æ˜è¿™äº›è§£é‡Šå¾€å¾€ç¼ºä¹å¯ä¿¡åº¦ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆVFMå’Œæ–°å‹åŸå‹æ¶æ„çš„æ–¹æ¡ˆï¼ˆProtoFMï¼‰ï¼Œé€šè¿‡åœ¨å†»ç»“çš„VFMä¸Šè®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„å¤´éƒ¨æ¨¡å‹ï¼Œæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯è§£é‡Šçš„è§£å†³æ–¹æ¡ˆã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.20396', 'title': 'Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids', 'url': 'https://huggingface.co/papers/2502.20396', 'abstract': 'Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited. This work investigates the key challenges in applying reinforcement learning to solve a collection of contact-rich manipulation tasks on a humanoid embodiment. We introduce novel techniques to overcome the identified challenges with empirical validation. Our main contributions include an automated real-to-sim tuning module that brings the simulated environment closer to the real world, a generalized reward design scheme that simplifies reward engineering for long-horizon contact-rich manipulation tasks, a divide-and-conquer distillation process that improves the sample efficiency of hard-exploration problems while maintaining sim-to-real performance, and a mixture of sparse and dense object representations to bridge the sim-to-real perception gap. We show promising results on three humanoid dexterous manipulation tasks, with ablation studies on each technique. Our work presents a successful approach to learning humanoid dexterous manipulation using sim-to-real reinforcement learning, achieving robust generalization and high performance without the need for human demonstration.', 'score': 2, 'issue_id': 2486, 'pub_date': '2025-02-27', 'pub_date_card': {'ru': '27 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 27', 'zh': '2æœˆ27æ—¥'}, 'hash': '41439b4f54e02c9b', 'authors': ['Toru Lin', 'Kartik Sachdev', 'Linxi Fan', 'Jitendra Malik', 'Yuke Zhu'], 'affiliations': ['NVIDIA', 'UC Berkeley', 'UT Austin'], 'pdf_title_img': 'assets/pdf/title_img/2502.20396.jpg', 'data': {'categories': ['#robotics', '#rl', '#games', '#optimization'], 'emoji': 'ğŸ¤–', 'ru': {'title': 'Ğ›Ğ¾Ğ²ĞºĞ¾ÑÑ‚ÑŒ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°: Ğ¾Ñ‚ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğº Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ¾Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ñ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸, Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ½ÑƒÑ ÑÑ…ĞµĞ¼Ñƒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´ Ğ¸ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ². Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ñ‚Ñ€ĞµÑ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ»Ğ¾Ğ²ĞºĞ¾Ğ¹ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ¾Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğ¼ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸ÑĞ¼ Ğ±ĞµĞ· Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸ÑÑ… Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°.'}, 'en': {'title': 'Reinforcement Learning for Dexterous Robot Manipulation: Bridging Sim and Real Worlds', 'desc': 'This paper addresses the challenges of using reinforcement learning for complex robot manipulation tasks that involve physical contact. The authors propose innovative methods to enhance the performance of humanoid robots in these tasks, including a system to align simulated environments with real-world conditions. They also introduce a new reward design that simplifies the process of creating effective rewards for long tasks and a technique to improve learning efficiency in difficult scenarios. The results demonstrate that their approach allows robots to learn dexterous manipulation effectively, achieving high performance without requiring human guidance.'}, 'zh': {'title': 'çªç ´ç±»äººæœºå™¨äººçµå·§æ“ä½œçš„å¼ºåŒ–å­¦ä¹ æŒ‘æˆ˜', 'desc': 'æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨ç±»äººæœºå™¨äººçµå·§æ“ä½œä»»åŠ¡ä¸­åº”ç”¨å¼ºåŒ–å­¦ä¹ çš„å…³é”®æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†æ–°æŠ€æœ¯æ¥å…‹æœè¿™äº›æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–çš„çœŸå®åˆ°æ¨¡æ‹Ÿè°ƒä¼˜æ¨¡å—ï¼Œä»¥ç¼©å°æ¨¡æ‹Ÿç¯å¢ƒä¸ç°å®ä¸–ç•Œçš„å·®è·ã€‚æˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ç§é€šç”¨çš„å¥–åŠ±æœºåˆ¶ï¼Œç®€åŒ–äº†é•¿æ—¶é—´æ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡çš„å¥–åŠ±å·¥ç¨‹ã€‚é€šè¿‡å¯¹ä¸‰é¡¹ç±»äººçµå·§æ“ä½œä»»åŠ¡çš„å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨ä¸éœ€è¦äººç±»ç¤ºèŒƒçš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ°çœŸå®çš„å¼ºåŒ–å­¦ä¹ å®ç°äº†ç¨³å¥çš„æ³›åŒ–å’Œé«˜æ€§èƒ½ã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.20583', 'title': 'LiteASR: Efficient Automatic Speech Recognition with Low-Rank Approximation', 'url': 'https://huggingface.co/papers/2502.20583', 'abstract': "Modern automatic speech recognition (ASR) models, such as OpenAI's Whisper, rely on deep encoder-decoder architectures, and their encoders are a critical bottleneck for efficient deployment due to high computational intensity. We introduce LiteASR, a low-rank compression scheme for ASR encoders that significantly reduces inference costs while maintaining transcription accuracy. Our approach leverages the strong low-rank properties observed in intermediate activations: by applying principal component analysis (PCA) with a small calibration dataset, we approximate linear transformations with a chain of low-rank matrix multiplications, and further optimize self-attention to work in the reduced dimension. Evaluation results show that our method can compress Whisper large-v3's encoder size by over 50%, matching Whisper medium's size with better transcription accuracy, thereby establishing a new Pareto-optimal frontier of efficiency and performance. The code of LiteASR is available at https://github.com/efeslab/LiteASR.", 'score': 2, 'issue_id': 2486, 'pub_date': '2025-02-27', 'pub_date_card': {'ru': '27 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 27', 'zh': '2æœˆ27æ—¥'}, 'hash': '3c7268c0881fa426', 'authors': ['Keisuke Kamahori', 'Jungo Kasai', 'Noriyuki Kojima', 'Baris Kasikci'], 'affiliations': ['Kotoba Technologies Inc.', 'University of Washington'], 'pdf_title_img': 'assets/pdf/title_img/2502.20583.jpg', 'data': {'categories': ['#inference', '#optimization', '#audio'], 'emoji': 'ğŸ™ï¸', 'ru': {'title': 'LiteASR: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ² ASR Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸', 'desc': 'LiteASR - ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ¶Ğ°Ñ‚Ğ¸Ñ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ² Ğ´Ğ»Ñ ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑ‡Ğ¸ (ASR), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ (PCA) Ğ´Ğ»Ñ Ğ°Ğ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¾Ğ¹ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ† Ğ½Ğ¸Ğ·ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°Ğ½Ğ³Ğ°. LiteASR Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¶Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Whisper large-v3 Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ Ğ½Ğ° 50%, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°Ñ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Whisper medium Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸. Ğ­Ñ‚Ğ¾ ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ ĞŸĞ°Ñ€ĞµÑ‚Ğ¾-Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ASR.'}, 'en': {'title': 'LiteASR: Efficient ASR with Low-Rank Compression', 'desc': "This paper presents LiteASR, a novel low-rank compression technique designed to enhance the efficiency of automatic speech recognition (ASR) models, particularly focusing on the encoder component. By utilizing principal component analysis (PCA) on intermediate activations, LiteASR reduces the computational load during inference while preserving transcription accuracy. The method achieves over 50% reduction in the encoder size of OpenAI's Whisper large-v3 model, aligning its performance with that of the medium version but with improved accuracy. This work sets a new standard for balancing efficiency and performance in ASR systems."}, 'zh': {'title': 'LiteASRï¼šé«˜æ•ˆçš„ä½ç§©å‹ç¼©æ–¹æ¡ˆ', 'desc': 'ç°ä»£è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹ï¼Œå¦‚OpenAIçš„Whisperï¼Œä¾èµ–äºæ·±åº¦ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œè€Œç¼–ç å™¨çš„è®¡ç®—å¼ºåº¦æ˜¯é«˜æ•ˆéƒ¨ç½²çš„ç“¶é¢ˆã€‚æˆ‘ä»¬æå‡ºäº†LiteASRï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ASRç¼–ç å™¨çš„ä½ç§©å‹ç¼©æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½æ¨ç†æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒè½¬å½•å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨äº†ä¸­é—´æ¿€æ´»ä¸­çš„å¼ºä½ç§©ç‰¹æ€§ï¼Œé€šè¿‡ä½¿ç”¨å°å‹æ ¡å‡†æ•°æ®é›†çš„ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ï¼Œç”¨ä½ç§©çŸ©é˜µä¹˜æ³•é“¾æ¥è¿‘ä¼¼çº¿æ€§å˜æ¢ï¼Œå¹¶è¿›ä¸€æ­¥ä¼˜åŒ–è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»¥é€‚åº”é™ç»´åçš„æ•°æ®ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å°†Whisper large-v3çš„ç¼–ç å™¨å¤§å°å‹ç¼©è¶…è¿‡50%ï¼Œå¹¶åœ¨è½¬å½•å‡†ç¡®æ€§ä¸Šä¼˜äºWhisper mediumï¼Œä»è€Œå»ºç«‹äº†æ•ˆç‡ä¸æ€§èƒ½çš„æ–°å¸•ç´¯æ‰˜æœ€ä¼˜è¾¹ç•Œã€‚'}}}, {'id': 'https://huggingface.co/papers/2502.20811', 'title': 'HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models', 'url': 'https://huggingface.co/papers/2502.20811', 'abstract': 'Recent Multi-modal Large Language Models (MLLMs) have made great progress in video understanding. However, their performance on videos involving human actions is still limited by the lack of high-quality data. To address this, we introduce a two-stage data annotation pipeline. First, we design strategies to accumulate videos featuring clear human actions from the Internet. Second, videos are annotated in a standardized caption format that uses human attributes to distinguish individuals and chronologically details their actions and interactions. Through this pipeline, we curate two datasets, namely HAICTrain and HAICBench. HAICTrain comprises 126K video-caption pairs generated by Gemini-Pro and verified for training purposes. Meanwhile, HAICBench includes 500 manually annotated video-caption pairs and 1,400 QA pairs, for a comprehensive evaluation of human action understanding. Experimental results demonstrate that training with HAICTrain not only significantly enhances human understanding abilities across 4 benchmarks, but can also improve text-to-video generation results. Both the HAICTrain and HAICBench are released at https://huggingface.co/datasets/KuaishouHAIC/HAIC.', 'score': 1, 'issue_id': 2486, 'pub_date': '2025-02-28', 'pub_date_card': {'ru': '28 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ', 'en': 'February 28', 'zh': '2æœˆ28æ—¥'}, 'hash': '806f6aacd5ee2f8a', 'authors': ['Xiao Wang', 'Jingyun Hua', 'Weihong Lin', 'Yuanxing Zhang', 'Fuzheng Zhang', 'Jianlong Wu', 'Di Zhang', 'Liqiang Nie'], 'affiliations': ['Kuaishou Technology'], 'pdf_title_img': 'assets/pdf/title_img/2502.20811.jpg', 'data': {'categories': ['#dataset', '#data', '#video', '#multimodal', '#benchmark', '#synthetic'], 'emoji': 'ğŸ¬', 'ru': {'title': 'Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑĞ¼Ğ¸ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ ÑĞ±Ğ¾Ñ€ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¸Ñ… ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ. Ğ’ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ Ğ±Ñ‹Ğ»Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ Ğ´Ğ²Ğ° Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: HAICTrain Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ HAICBench Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° HAICTrain Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾.'}, 'en': {'title': 'Enhancing Video Understanding with Curated Human Action Datasets', 'desc': 'This paper presents a solution to improve video understanding in Multi-modal Large Language Models (MLLMs) by addressing the scarcity of high-quality data on human actions. The authors introduce a two-stage data annotation pipeline that first collects videos with clear human actions from the Internet and then annotates them using a standardized caption format. This results in two curated datasets: HAICTrain, which contains 126K video-caption pairs for training, and HAICBench, which includes 500 annotated pairs for evaluation. Experimental results show that using HAICTrain significantly boosts human action understanding and enhances text-to-video generation capabilities across multiple benchmarks.'}, 'zh': {'title': 'æå‡è§†é¢‘ç†è§£çš„åˆ›æ–°æ•°æ®æ ‡æ³¨æµç¨‹', 'desc': 'æœ€è¿‘çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†é¢‘ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨æ¶‰åŠäººç±»åŠ¨ä½œçš„è§†é¢‘ä¸Šçš„è¡¨ç°ä»ç„¶å—åˆ°é«˜è´¨é‡æ•°æ®ç¼ºä¹çš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ•°æ®æ ‡æ³¨æµç¨‹ï¼Œé¦–å…ˆä»äº’è”ç½‘æ”¶é›†åŒ…å«æ¸…æ™°äººç±»åŠ¨ä½œçš„è§†é¢‘ï¼Œç„¶åä½¿ç”¨æ ‡å‡†åŒ–çš„å­—å¹•æ ¼å¼å¯¹è§†é¢‘è¿›è¡Œæ ‡æ³¨ã€‚é€šè¿‡è¿™ä¸ªæµç¨‹ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸¤ä¸ªæ•°æ®é›†HAICTrainå’ŒHAICBenchï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨HAICTrainè¿›è¡Œè®­ç»ƒæ˜¾è‘—æå‡äº†äººç±»åŠ¨ä½œç†è§£èƒ½åŠ›ï¼Œå¹¶æ”¹å–„äº†æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆçš„æ•ˆæœã€‚'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf moonly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents (1)', '#agi', '#alignment', '#architecture (2)', '#audio (1)', '#benchmark (3)', '#cv (1)', '#data (1)', '#dataset (3)', '#diffusion', '#ethics', '#games (2)', '#graphs', '#hallucinations', '#healthcare', '#inference (2)', '#interpretability (1)', '#leakage', '#long_context', '#low_resource', '#machine_translation', '#math (1)', '#multilingual', '#multimodal (2)', '#open_source (1)', '#optimization (5)', '#plp', '#rag (2)', '#reasoning (3)', '#rl (2)', '#rlhf', '#robotics (1)', '#science', '#security', '#small_models (1)', '#story_generation', '#survey', '#synthetic (1)', '#training (4)', '#transfer_learning', '#video (1)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            ğŸ”º ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = 'ğŸ”„ ' + getTimeDiff('2025-03-03 13:20',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ",
                    pub_date: "Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸",
                    issue_id: "Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "è¯„åˆ†",
                    pub_date: "å‘å¸ƒæ—¥æœŸ",
                    issue_id: "HFä¸Šä¼ æ—¥æœŸ"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-03-03 13:20')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-03-03 13:20')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('monthly'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    