
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Table-R1: Inference-Time Scaling for Table Reasoning</h1>
                <div><p class='zh-text'>1. 这篇文章介绍了两种后训练策略，蒸馏和强化学习与可验证奖励（RLVR），用于表格推理任务的推理时缩放。</p>
<p class='zh-text'>2. 这些策略创建了一个名为Table-R1-Zero的模型，该模型使用较少的参数匹配GPT-4.1的性能，并展示出强大的泛化能力。</p>
<p class='zh-text'>3. 研究团队评估了这些模型在多种表格推理任务中的表现，包括短答问答、事实验证和自由形式问答。</p>
<p class='zh-text'>4. 结果显示，Table-R1-Zero模型在使用较少参数的情况下，性能匹配或超越了GPT-4.1和DeepSeek-R1。</p></div>
                <div class="pinyin">
                    <p>1. Zhè piān wénzhāng jièshào le liǎng zhǒng hòu xùnliàn cèlüè, zhēngliú hé qiángzhì xuéxí yǔ kě yànzhèng jiǎnglì (RLVR), yòngyú biǎogé tuīlǐ rènwù de tuīlǐ shí suōfàng</p>
<p>2.  Zhèxiē cèlüè chuàngjiàn le yīgè míngyǐ Table-R1-Zero de móxíng, gāi móxíng shǐyòng jiào shǎo de cānshù pǐpèi GPT-4</p>
<p>3. 1 de xíngnéng, bìng zhànshì chū qiángdà de fànhuà nénglì</p>
<p>4.  Yánjiū tuánduì pínggū le zhèxiē móxíng zài duō zhǒng biǎogé tuīlǐ rènwù zhōng de biǎoxiàn, bāokuò duǎn dá wèndá, shìshí yànzhèng hé zìyóu xíngshì wèndá</p>
<p>5.  Jiéguǒ xiǎnshì, Table-R1-Zero móxíng zài shǐyòng jiào shǎo cānshù de qíngkuàng xià, xíngnéng pǐpèi huò chāoyuè le GPT-4</p>
<p>6. 1 hé DeepSeek-R1</p>
                </div>
                <div><p>1. This article introduces two post-training strategies, distillation and reinforcement learning with verifiable rewards (RLVR), for scaling inference-time reasoning in table reasoning tasks.</p>
<p>2.  These strategies create a model called Table-R1-Zero, which matches the performance of GPT-4.</p>
<p>3. 1 with fewer parameters and demonstrates strong generalization capabilities.</p>
<p>4.  The research team evaluated the performance of these models on various table reasoning tasks, including short answer question-answering, fact verification, and free-form question-answering.</p>
<p>5.  The results show that the Table-R1-Zero model matches or outperforms GPT-4.</p>
<p>6. 1 and DeepSeek-R1 with fewer parameters.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">蒸馏</td>
                            <td>zhēngliú</td>
                            <td>distillation</td>
                        </tr>
            
                        <tr>
                            <td class="zh">强化学习</td>
                            <td>qiáng huà xué xí</td>
                            <td>reinforcement learning</td>
                        </tr>
            
                        <tr>
                            <td class="zh">可验证奖励</td>
                            <td>kě yàn zhèng jiǎng lì</td>
                            <td>verifiable reward</td>
                        </tr>
            
                        <tr>
                            <td class="zh">表格推理</td>
                            <td>biǎo gé tuī lǐ</td>
                            <td>table reasoning</td>
                        </tr>
            
                        <tr>
                            <td class="zh">推理时缩放</td>
                            <td>tuī lǐ shí suō fàng</td>
                            <td>inference-time scaling</td>
                        </tr>
            
                        <tr>
                            <td class="zh">泛化能力</td>
                            <td>fàn huà néng lì</td>
                            <td>generalization capability</td>
                        </tr>
            
                        <tr>
                            <td class="zh">短答问答</td>
                            <td>duǎn dá wèn dá</td>
                            <td>short answer Q&A</td>
                        </tr>
            
                        <tr>
                            <td class="zh">事实验证</td>
                            <td>shì shí yàn zhèng</td>
                            <td>fact verification</td>
                        </tr>
            
                        <tr>
                            <td class="zh">自由形式问答</td>
                            <td>zì yóu xíng shì wèn dá</td>
                            <td>free-form Q&A</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        