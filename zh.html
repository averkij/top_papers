
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>MoCha: Towards Movie-Grade Talking Character Synthesis</h1>
                <div><p class='zh-text'>1. 这篇文章介绍了一种新的视频生成任务，称为 Talking Characters。</p>
<p class='zh-text'>2. 它能通过语音和文本直接生成说话的动画角色。</p>
<p class='zh-text'>3. 与之前的 talking head 不同，Talking Characters 生成的是一个或多个角色的全身像，而不仅仅是面部。</p>
<p class='zh-text'>4. 研究提出了 MoCha 模型，并使用语音-视频窗口注意力机制来精确同步语音和视频。</p>
<p class='zh-text'>5. 为了解决大规模语音标注视频数据集稀缺的问题，研究还提出了一种联合训练策略，提升了模型的泛化能力。</p></div>
                <div class="pinyin">
                    <p>1. 这篇文章介绍了一种新的视频生成任务，称为 Talking Characters。它能通过语音和文本直接生成说话的动画角色。与之前的 talking head 不同，Talking Characters 生成的是一个或多个角色的全身像，而不仅仅是面部。研究提出了 MoCha 模型，并使用语音-视频窗口注意力机制来精确同步语音和视频。为了解决大规模语音标注视频数据集稀缺的问题，研究还提出了一种联合训练策略，提升了模型的泛化能力。

zhè piān wén zhāng jiè shào le yī zhǒng xīn de shì pǐn shēng chéng rèn wù, chēng wéi Talking Characters</p>
<p>2.  tā néng tōng guò yǔ yīn hé wén běn zhí jiē shēng chéng shuō huà de dòng huà jué sè</p>
<p>3.  yǔ zhī qián de talking head bù tóng, Talking Characters shēng chéng de shì yī gè huò duō gè jué sè de quán shēn xiàng, ér bù jǐn jǐn shì miàn bù</p>
<p>4.  yán jiū tí chū le MoCha mó xíng, bìng shǐ yòng yǔ yīn-shì pǐn chuāng kǒu zhù yì lì jī zhī lái jīng xiào tóng bù yǔ yīn hé shì pǐn</p>
<p>5.  wèi le jiě jué dà guī mó yǔ yīn biāo zhù shì pǐn shù jù jí xī quē de wèn tí, yán jiū hái tí chū le yī zhǒng lián hé xùn liàn cè lüè, tí shēng le mó xíng de fàn huà néng lì</p>
                </div>
                <div><p>1. This article introduces a new video generation task called Talking Characters, which can directly generate speaking animated characters from speech and text.</p>
<p>2.  Unlike previous talking head approaches, Talking Characters generates full-body images of one or more characters, not just the face.</p>
<p>3.  The research proposes the MoCha model and employs a speech-video window attention mechanism to precisely synchronize speech and video.</p>
<p>4.  To address the scarcity of large-scale speech-annotated video datasets, the research also proposes a joint training strategy that enhances the model's generalization capability.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">视频生成</td>
                            <td>shìpín shēngchéng</td>
                            <td>video generation</td>
                        </tr>
            
                        <tr>
                            <td class="zh">称为</td>
                            <td>chēngwéi</td>
                            <td>called</td>
                        </tr>
            
                        <tr>
                            <td class="zh">Talking Characters</td>
                            <td>Talking Characters</td>
                            <td>Talking Characters</td>
                        </tr>
            
                        <tr>
                            <td class="zh">语音</td>
                            <td>yǔyīn</td>
                            <td>audio</td>
                        </tr>
            
                        <tr>
                            <td class="zh">文本</td>
                            <td>wénběn</td>
                            <td>text</td>
                        </tr>
            
                        <tr>
                            <td class="zh">动画角色</td>
                            <td>dònghuà juésè</td>
                            <td>animated character</td>
                        </tr>
            
                        <tr>
                            <td class="zh">talking head</td>
                            <td>talking head</td>
                            <td>talking head</td>
                        </tr>
            
                        <tr>
                            <td class="zh">全身像</td>
                            <td>quánshēn xiàng</td>
                            <td>full-body image</td>
                        </tr>
            
                        <tr>
                            <td class="zh">面部</td>
                            <td>miànbù</td>
                            <td>face</td>
                        </tr>
            
                        <tr>
                            <td class="zh">MoCha</td>
                            <td>MoCha</td>
                            <td>MoCha</td>
                        </tr>
            
                        <tr>
                            <td class="zh">模型</td>
                            <td>móxíng</td>
                            <td>model</td>
                        </tr>
            
                        <tr>
                            <td class="zh">语音-视频窗口注意力机制</td>
                            <td>yǔyīn shìpín chuāngkǒu zhùyìlì jīzhì</td>
                            <td>audio-video window attention mechanism</td>
                        </tr>
            
                        <tr>
                            <td class="zh">精确同步</td>
                            <td>jīngquè tóngbù</td>
                            <td>precise synchronization</td>
                        </tr>
            
                        <tr>
                            <td class="zh">大规模</td>
                            <td>dàguīmó</td>
                            <td>large-scale</td>
                        </tr>
            
                        <tr>
                            <td class="zh">语音标注</td>
                            <td>yǔyīn biāozhù</td>
                            <td>audio annotation</td>
                        </tr>
            
                        <tr>
                            <td class="zh">视频数据集</td>
                            <td>shìpín shùjùjí</td>
                            <td>video dataset</td>
                        </tr>
            
                        <tr>
                            <td class="zh">稀缺</td>
                            <td>xīquē</td>
                            <td>scarce</td>
                        </tr>
            
                        <tr>
                            <td class="zh">联合训练策略</td>
                            <td>liánhé xùnliàn cèlüè</td>
                            <td>joint training strategy</td>
                        </tr>
            
                        <tr>
                            <td class="zh">提升</td>
                            <td>tíshēng</td>
                            <td>improve</td>
                        </tr>
            
                        <tr>
                            <td class="zh">泛化能力</td>
                            <td>fànhuà nénglì</td>
                            <td>generalization capability</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        