
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>SynCamMaster: Synchronizing Multi-Camera Video Generation from Diverse Viewpoints</h1>
                <div><p class='zh-text'>1. 最近的视频扩散模型在模拟现实世界动态和维持3D一致性方面表现出色。</p>
<p class='zh-text'>2. 这激发了我们研究这些模型在确保不同视角动态一致性方面的潜力，这对虚拟拍摄等应用非常有用。</p>
<p class='zh-text'>3. 我们提出了一个插播模块，增强预训练的文本到视频模型，用于多摄像头视频生成，确保不同视角的内容一致。</p>
<p class='zh-text'>4. 我们引入了多视角同步模块，维持外观和几何一致性。</p>
<p class='zh-text'>5. 由于高质量训练数据的稀缺，我们设计了混合训练方案，利用多摄像头图像和单目视频补充虚幻引擎渲染的多摄像头视频。</p>
<p class='zh-text'>6. 我们还发布了一个多视角同步视频数据集，命名为SynCamVideo-Dataset。</p></div>
                <div class="pinyin">
                    <p>1. Zùijìn de shìpín kuòsàn móxíng zài mónǐ xiànshì shìjiè dòngtài hé wéichí 3D yīzhìxìng fāngmiàn biǎoxiàn chūsè</p>
<p>2.  Zhè jīfāle wǒmen yánjiū zhèxiē móxíng zài quèshǒu bùtóng shìjiǎo dòngtài yīzhìxìng fāngmiàn de qiánlì, zhè duì xūnǐ pāishè děng yìngyòng fēicháng yǒuyòng</p>
<p>3.  Wǒmen tíchūle yīgè chābō mókuài, zēngqiáng yùjiàoxùn de wénběn dào shìpín móxíng, yòngyú duō shèxiàngtóu shìpín shēngchéng, quèshǒu bùtóng shìjiǎo de nèiróng yīzhì</p>
<p>4.  Wǒmen yǐnrùle duō shìjiǎo tóngbù mókuài, wéichí wàiguǎn hé jǐhé yīzhìxìng</p>
<p>5.  Yóuyú gāo zhìliàng xùnliàn shùjù de xīquē, wǒmen shèjìle hùn hé xùnliàn fāng'àn, lìyòng duō shèxiàngtóu túxiàng hé dānmù shìpín bǔchōng xūhuàn yǐnqíng xuànchǔ de duō shèxiàngtóu shìpín</p>
<p>6.  Wǒmen hái fābùle yīgè duō shìjiǎo tóngbù shìpín shùjùjí, mìngmíng wéi SynCamVideo-Dataset</p>
                </div>
                <div><p>1. Recent video diffusion models have shown excellent performance in simulating real-world dynamics and maintaining 3D consistency.</p>
<p>2.  This has inspired us to explore the potential of these models in ensuring dynamic consistency across different viewpoints, which is particularly useful for applications such as virtual cinematography.</p>
<p>3.  We propose an interpolation module that enhances pre-trained text-to-video models for multi-camera video generation, ensuring content consistency across different viewpoints.</p>
<p>4.  We introduce a multi-view synchronization module to maintain consistency in appearance and geometry.</p>
<p>5.  Due to the scarcity of high-quality training data, we designed a hybrid training scheme that utilizes multi-camera images and monocular videos to supplement Unreal Engine-rendered multi-camera videos.</p>
<p>6.  Additionally, we release a multi-view synchronized video dataset named SynCamVideo-Dataset.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        