
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 1 paper. December 13.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">13 декабря</span> | <span id="title-articles-count">1 paper</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2024-12-12.html">⬅️ <span id="prev-date">12.12</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2024-12-16.html">➡️ <span id="next-date">16.12</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2024-12.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '13 декабря', 'en': 'December 13', 'zh': '12月13日'};
        let feedDateNext = {'ru': '16.12', 'en': '12/16', 'zh': '12月16日'};
        let feedDatePrev = {'ru': '12.12', 'en': '12/12', 'zh': '12月12日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': '2412.08905', 'title': 'Phi-4 Technical Report', 'url': 'https://huggingface.co/papers/2412.08905', 'abstract': 'We present phi-4, a 14-billion parameter language model developed with a\ntraining recipe that is centrally focused on data quality. Unlike most language\nmodels, where pre-training is based primarily on organic data sources such as\nweb content or code, phi-4 strategically incorporates synthetic data throughout\nthe training process. While previous models in the Phi family largely distill\nthe capabilities of a teacher model (specifically GPT-4), phi-4 substantially\nsurpasses its teacher model on STEM-focused QA capabilities, giving evidence\nthat our data-generation and post-training techniques go beyond distillation.\nDespite minimal changes to the phi-3 architecture, phi-4 achieves strong\nperformance relative to its size -- especially on reasoning-focused benchmarks\n-- due to improved data, training curriculum, and innovations in the\npost-training scheme.', 'score': 1, 'issue_id': 1, 'pub_date': '2024-12-12', 'pub_date_card': {'ru': '12 декабря', 'en': 'December 12', 'zh': '12月12日'}, 'hash': '5b5d18f4e7e9fad9', 'authors': ['Marah Abdin', 'Jyoti Aneja', 'Harkirat Behl', 'Sébastien Bubeck', 'Ronen Eldan', 'Suriya Gunasekar', 'Michael Harrison', 'Russell J. Hewett', 'Mojan Javaheripi', 'Piero Kauffmann', 'James R. Lee', 'Yin Tat Lee', 'Yuanzhi Li', 'Weishung Liu', 'Caio C. T. Mendes', 'Anh Nguyen', 'Eric Price', 'Gustavo de Rosa', 'Olli Saarikivi', 'Adil Salim', 'Shital Shah', 'Xin Wang', 'Rachel Ward', 'Yue Wu', 'Dingli Yu', 'Cyril Zhang', 'Yi Zhang'], 'affiliations': ['Microsoft Research'], 'pdf_title_img': 'assets\\pdf\\title_img\\2412.08905.jpg', 'data': {'categories': ['#data', '#reasoning', '#synthetic', '#training', '#benchmark', '#architecture'], 'emoji': '🧠', 'ru': {'title': 'Качество данных - ключ к превосходству языковой модели', 'desc': ''}, 'en': {'title': 'Elevating Language Models with Quality Data', 'desc': ''}, 'zh': {'title': '数据质量驱动的语言模型phi-4', 'desc': ''}}, 'clean_sections': [{'title': 'Abstract', 'content': 'We present phi-4, a 14-billion parameter language model developed with a training recipe that is centrally focused on data quality. Unlike most language models, where pre-training is based primarily on organic data sources such as web content or code, phi-4 strategically incorporates synthetic data throughout the training process. While previous models in the Phi family largely distill the capabilities of a teacher model (specifically GPT-4), phi-4 substantially surpasses its teacher model on STEM-focused QA capabilities, giving evidence that our data-generation and post-training techniques go beyond distillation. Despite minimal changes to the phi-3 architecture, phi-4 achieves strong performance relative to its size -- especially on reasoning-focused benchmarks -- due to improved data, training curriculum, and innovations in the post-training scheme.', 'summary': '<p>В этой статье представлен phi-4, языковая модель с 14 миллиардами параметров. Главная особенность phi-4 – это подход к обучению, в котором ключевую роль играет качество данных. В отличие от большинства языковых моделей, которые обучаются на "органических" данных, таких как веб-контент или код, phi-4 активно использует синтетические данные на протяжении всего процесса обучения.</p>\n<p>Предыдущие модели семейства Phi в основном "перенимали" способности у модели-учителя (GPT-4). Однако phi-4 значительно превосходит своего учителя в решении задач, связанных с точными науками (STEM), что свидетельствует о том, что методы генерации данных и постобработки выходят за рамки простого "перенимания" знаний.</p>\n<p>Несмотря на минимальные изменения в архитектуре по сравнению с phi-3, phi-4 демонстрирует высокую производительность относительно своего размера, особенно в задачах, требующих рассуждений. Это достигается благодаря улучшению качества данных, учебной программы и инновациям в схеме постобработки.</p>\n<p><em>Комментарий: Авторы подчеркивают, что phi-4 не просто "скопировал" способности более крупной модели, а действительно улучшил их за счет более продуманного подхода к данным и обучению.</em></p>'}, {'title': 'Introduction', 'content': 'Recent advancements in Large Language Models (LLMs) have shown that significant improvements in data quality can rival, and sometimes surpass, the performance gains traditionally achieved by scaling compute with model and dataset size. Building on the success of the Phi family [GZA+23, LBE+23, JBA+23, AAA+24], we introduce phi-4, 14-billion parameter model that further advances performance of small language models by introducing innovative synthetic data generation methods for reasoningfocused tasks, by optimizing the training curriculum and data mixture, and by introducing new techniques in post-training. Synthetic data constitutes the bulk of the training data for phi-4 and is generated using diverse array of techniques, including multi-agent prompting, self-revision workflows, and instruction reversal. These methods enable the construction of datasets that induce stronger reasoning and problem-solving abilities in the model, addressing some of the weaknesses in traditional unsupervised datasets. Synthetic data in phi-4 also plays crucial role in post-training, where techniques such as rejection sampling and novel approach to Direct Preference Optimization (DPO) are employed to refine the models outputs. The development of phi-4 is guided by three core pillars: 1. Synthetic Data for Pretraining and Midtraining: High-quality synthetic datasets are designed to prioritize reasoning and problem-solving, carefully generated to ensure diversity and 1 Small models Large models phi-4 14b phi-3 14b Qwen 2.5 14b instruct GPT 4o-mini Llama-3.3 70b instruct Qwen 2.5 72b instruct GPT 4o v - m MMLU GPQA MATH HumanEval MGSM SimpleQA DROP MMLUPro HumanEval+ ArenaHard LiveBench IFEval PhiBench (internal) 84.8 56.1 80.4 82.6 80.6 3.0 75.5 70.4 82.8 75.4 47.6 63.0 77.9 31.2 44.6 67.8 53.5 7.6 68.3 51.3 69.2 45.8 28.1 57.9 56. 43.9 79.9 42.9 75.6 72.1 79.6 5.4 85.5 63.2 79.1 70.2 46.6 78.7 49.8 81.8 40.9 73.0 86.2 86.5 9.9 79.3 63.4 82.0 76.2 48.1 80. 58.7 86.3 49.1 66.31 78.91 89.1 20.9 90.2 64.4 77.9 65.5 57.6 89.3 57.1 85.3 49.0 80.0 80.4 87.3 10.2 76.7 69.6 78.4 78.4 55.3 85. 64.6 88.1 50.6 74.6 90.6 90.4 39.4 80.9 73.0 88.0 75.6 57.6 84.8 72.4 Table 1: Performance of phi-4 on set of standard benchmarks. The first set of benchmarks uses OpenAIs simple-evals framework [Ope24b], specifying the prompts/extraction/temperature=0.5. We compare to small models of similar inference cost, as well as to larger models. relevance. We change our training curriculum and create new pretraining and midtraining data mixtures to increase the allocation of synthetic tokens, compared to older generations of phi. 2. Curation and Filtering of High-Quality Organic Data: We meticulously curate and filter organic2 data sources, including web content, licensed books, and code repositories to extract seeds for the synthetic data pipeline that encourage high-depth reasoning and prioritize educational value (to the model). These seeds form the foundation of the synthetic generation pipeline. To complement these synthetic datasets, we also filter the web for high-quality data (in terms of knowledge and reasoning) to use directly in pretraining. 3. Post-Training: We further advance the post-training recipe in phi-4 by creating new refined versions of SFT datasets, as well as by developing new technique to create DPO pairs, based on pivotal token search. With these innovations, the performance of phi-4 on reasoning-related tasks is comparable to or surpasses much larger models. For example, its performance on many widely used reasoning-related benchmarks meets or exceeds that of Llama-3.1-405B. In Table 1 we compare the performance of our model on academic benchmarks to several contemporary foundation models. We find that phi4 significantly exceeds its teacher GPT-4o on the GPQA (graduate-level STEM Q&A) and MATH (math competition) benchmarks. 1These scores are lower than those reported by Meta, perhaps because simple-evals has strict formatting requirement that Llama models have particular trouble following. We use the simple-evals framework because it is reproducible, but Meta reports 77 for MATH and 88 for HumanEval on Llama-3.3. 2We use organic to refer to human-generated or otherwise non-synthetic data. Figure 1: Average performance of different models on the November 2024 AMC-10 and AMC-12 tests. This is the average score (with maximum score 150) over the four tests on 100 runs with temperature = 0.5. We chose = 0.5 to follow simple-evals [Ope24b]. Error bars are 2σ of the estimate. On competition math, phi-4 scores well above its weight-class even compared to nonopen-weight models.', 'summary': '<p>В статье описывается модель phi-4, которая является развитием семейства моделей Phi и демонстрирует значительное улучшение производительности малых языковых моделей. Ключевым фактором успеха phi-4 является инновационный подход к созданию синтетических данных, а также оптимизация процесса обучения и пост-тренинга.</p>\n<p><strong>Основные принципы разработки phi-4:</strong></p>\n<ol>\n<li>\n<p><strong>Синтетические данные для предварительного и промежуточного обучения:</strong> Основная часть обучающих данных phi-4 состоит из синтетических данных, сгенерированных с использованием различных методов, таких как многоагентное подсказывание (multi-agent prompting), рабочие процессы саморедактирования (self-revision workflows) и обращение инструкций (instruction reversal). Эти методы позволяют создавать наборы данных, которые способствуют развитию способностей к рассуждению и решению проблем. В процессе обучения также используются новые стратегии смешивания данных, которые увеличивают долю синтетических токенов по сравнению с предыдущими поколениями Phi.</p>\n</li>\n<li>\n<p><strong>Отбор и фильтрация высококачественных органических данных:</strong> Для создания основы для синтетических данных, используются тщательно отобранные и отфильтрованные органические данные, включая веб-контент, лицензированные книги и репозитории кода. Эти данные служат "затравкой" для генерации синтетических данных, которые направлены на развитие глубокого мышления и обладают образовательной ценностью для модели. Кроме того, веб-контент также фильтруется для поиска высококачественных данных (с точки зрения знаний и рассуждений), которые используются непосредственно в предварительном обучении.</p>\n</li>\n<li>\n<p><strong>Пост-тренинг:</strong> В phi-4 усовершенствован процесс пост-тренинга путем создания новых версий SFT (Supervised Fine-Tuning) наборов данных, а также разработки новых методов создания пар для DPO (Direct Preference Optimization), основанных на поиске ключевых токенов. Эти инновации позволяют повысить качество выходных данных модели.</p>\n</li>\n</ol>\n<p>Благодаря этим нововведениям phi-4 демонстрирует производительность, сравнимую или превосходящую гораздо более крупные модели в задачах, связанных с рассуждением. Например, на многих широко используемых тестах, связанных с рассуждением, производительность phi-4 соответствует или превосходит производительность Llama-3.1-405B. В таблице 1 показано сравнение производительности phi-4 с другими современными моделями на стандартных академических тестах. При этом phi-4 значительно превосходит своего "учителя" GPT-4o на тестах GPQA (вопросы и ответы по STEM на уровне выпускников) и MATH (математические соревнования).</p>\n<p>В заключение, статья подчеркивает, что качество данных играет ключевую роль в обучении языковых моделей, и что инновационные методы генерации синтетических данных могут привести к значительным улучшениям производительности, сравнимым с увеличением вычислительных мощностей.</p>'}, {'title': 'Addressing Overfitting and Data Contamination', 'content': 'Decontamination: One pitfall of foundation models is overfitting to benchmarks, such as through the leakage of benchmark test sets via the web corpus. We improved the data decontamination process for phi-4 compared to previous Phi models to ensure no unfair influence on evaluation results. More details of the decontamination method are given in Appendix B. AMC Benchmark: The surest way to guard against overfitting to the test set is to test on fresh data. We tested our model on the November 2024 AMC-10 and AMC-12 math competitions [Com24], which occurred after all our training data was collected, and we only measured our performance after choosing all the hyperparameters in training our final model. These contests are the entry points to the Math Olympiad track in the United States and over 150,000 students take the tests each year. In Figure 1 we plot the average score over the four versions of the test, all of which have maximum score of 150. phi-4 outperforms not only similar-size or open-weight models but also much larger frontier models. Such strong performance on fresh test set suggests that phi-4s top-tier performance on the MATH benchmark is not due to overfitting or contamination. We provide further details in Appendix C. Relying on Contamination-Proof Benchmarks: We give significant weight to benchmarks which were designed in such way that the questions are original and do not appear on the web, such as GPQA [RHS+23]. While optimizing our model, we relied on an internal benchmark composed primarily of original prompts written by the team (see Section 5 for further details). Long Chain-of-Thought Models: style of LLM that scales inference-time compute by generating long chains of thought has emerged over the past few months, as pioneered by OpenAI O1 [Ope24a] and followed by DeepSeek-R1-Lite-Preview [Dee24] and Qwen/QwQ-32B-Preview [Tea24]. These models perform well on reasoning benchmarks, where QwQ, the only such model with open weights, averages 124.5 points in the AMC-10/12 setting of Figure 1. However, QwQ also uses 4X more tokens on this task than phi-4 and has more than twice as many parameters. Thus, the inference cost of QwQ is an order of magnitude higher than phi-4. Consequently, these models are not in the same class as phi-4 with respect to cost or latency.', 'summary': '<p>В статье рассматриваются важные аспекты обучения и оценки больших языковых моделей (LLM), а именно:</p>\n<p><strong>1. Очистка данных от "загрязнения" (Decontamination):</strong></p>\n<p>Одной из проблем при обучении LLM является переобучение на тестовых наборах данных. Это происходит, когда данные из тестовых наборов случайно "просачиваются" в обучающий корпус, например, через веб-корпус. Чтобы избежать этого, для модели phi-4 был усовершенствован процесс очистки данных по сравнению с предыдущими моделями Phi. Это гарантирует, что результаты оценки модели не будут искажены "загрязнением" данными. Подробности метода очистки приведены в Приложении B.</p>\n<p><strong>2. Бенчмарк AMC (American Mathematics Competitions):</strong></p>\n<p>Чтобы убедиться в отсутствии переобучения, модель протестировали на новых данных, а именно на математических конкурсах AMC-10 и AMC-12, которые проводились в ноябре 2024 года, после завершения сбора обучающих данных. Производительность модели измерялась только после выбора всех гиперпараметров. Эти конкурсы являются отборочными этапами для математической олимпиады в США, и в них ежегодно участвуют более 150 000 школьников. На графике (Рисунок 1) показан средний балл по четырем вариантам теста, максимальный балл в каждом из которых равен 150. phi-4 превосходит не только модели аналогичного размера или с открытыми весами, но и гораздо более крупные модели. Такие высокие результаты на новых тестовых данных говорят о том, что производительность phi-4 на бенчмарке MATH не является следствием переобучения или "загрязнения" данными. Дополнительные детали приведены в Приложении C.</p>\n<p><strong>3. Использование бенчмарков, защищенных от "загрязнения":</strong></p>\n<p>В статье также подчеркивается важность бенчмарков, разработанных таким образом, чтобы вопросы были оригинальными и не встречались в интернете, например, GPQA. При оптимизации модели также использовался внутренний бенчмарк, состоящий в основном из оригинальных запросов, написанных командой разработчиков (подробности в Разделе 5).</p>\n<p><strong>4. Модели с длинной цепочкой рассуждений (Long Chain-of-Thought Models):</strong></p>\n<p>В последнее время появились LLM, которые масштабируют вычислительные ресурсы во время вывода, генерируя длинные цепочки рассуждений. Эти модели, такие как OpenAI O1, DeepSeek-R1-Lite-Preview и Qwen/QwQ-32B-Preview, показывают хорошие результаты на бенчмарках, проверяющих способность к рассуждению. QwQ, единственная модель с открытыми весами в этой группе, набирает в среднем 124,5 балла в тесте AMC-10/12. Однако QwQ использует в 4 раза больше токенов и имеет более чем в два раза больше параметров, чем phi-4. Следовательно, вычислительные затраты на вывод QwQ на порядок выше, чем у phi-4. Таким образом, эти модели не относятся к тому же классу, что и phi-4, с точки зрения стоимости или задержки.</p>'}, {'title': 'Purpose of Synthetic Data', 'content': 'Synthetic data as substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by language model is by definition predicted by the preceding tokens, making it easier for model to follow the resulting reasoning patterns. In this way, synthetic data may act as form of spoonfeeding, presenting challenges in digestible and progression-oriented manner. simple example to illustrate this is that human-written solution to math problem might start with the final answer. This answer is much too hard to output immediately, for either human or an LLMthe human produced it by nonlinear editing, but pretraining expects the LLM to learn to produce it linearly. Synthetic solutions to math problems will not have such roadblocks. Alignment with Inference Contexts. Synthetic data is typically closer to the format of outputs we expect our models to generate. Training on such data helps align the models pretraining experience with the scenarios it encounters during inference. This alignment ensures that the context seen during generation remains in-distribution with respect to the data the model was pretrained on. For example, web forums are very different in style from LLM interactions. If fact only appears in web forum data, the pretrained model will think it is very unlikely to occur in the chats it produces. Rewriting facts from the web forum into the language style of an LLM makes the facts more accessible during the LLM chat context of inference. Principles. Our approach to generating synthetic data for phi-4 is guided by the following principles: 1. Diversity: The data should comprehensively cover subtopics and skills within each domain. This requires curating diverse seeds from organic sources. 2. Nuance and Complexity: Effective training requires nuanced, non-trivial examples that reflect the complexity and the richness of the domain. Data must go beyond basics to include edge cases and advanced examples. 3. Accuracy: Code should execute correctly, proofs should be valid, and explanations should adhere to established knowledge, etc. 4. Chain-of-Thought: Data should encourage systematic reasoning, teaching the model various approaches to the problems in step-by-step manner. This fosters coherent outputs for complex tasks.', 'summary': '<h2>Преимущества синтетических данных в предварительном обучении языковых моделей</h2>\n<p>В последнее время синтетические данные становятся всё более важным компонентом предварительного обучения языковых моделей, и серия моделей Phi наглядно демонстрирует это. Синтетические данные не просто дешёвая замена "органическим" данным, они обладают рядом прямых преимуществ.</p>\n<p><strong>Структурированное и постепенное обучение.</strong> В органических наборах данных связи между токенами часто сложны и непрямы. Модели может потребоваться выполнить множество логических шагов, чтобы связать текущий токен со следующим, что затрудняет эффективное обучение на основе предсказания следующего токена. В отличие от этого, каждый токен, сгенерированный языковой моделью, по определению предсказывается предыдущими токенами. Это облегчает модели отслеживание получаемых логических цепочек. Таким образом, синтетические данные можно рассматривать как своего рода "кормление с ложечки", когда сложные задачи представляются в доступной и ориентированной на прогресс форме. Простой пример: решение математической задачи, написанное человеком, может начинаться с окончательного ответа. Этот ответ слишком сложен для немедленного вывода как человеком, так и LLM. Человек получил его путем нелинейного редактирования, но предварительное обучение предполагает, что LLM научится выдавать его линейно. Синтетические решения математических задач не будут иметь таких препятствий.</p>\n<p><strong>Соответствие контекстам вывода.</strong> Синтетические данные обычно ближе к формату выходных данных, которые мы ожидаем от наших моделей. Обучение на таких данных помогает согласовать опыт предварительного обучения модели со сценариями, с которыми она сталкивается во время вывода. Это гарантирует, что контекст, наблюдаемый во время генерации, остаётся в пределах распределения данных, на которых модель была предварительно обучена. Например, веб-форумы сильно отличаются по стилю от взаимодействия с LLM. Если какой-либо факт встречается только в данных веб-форумов, предварительно обученная модель будет считать, что он маловероятен в чатах, которые она генерирует. Переписывание фактов с веб-форума на языковой стиль LLM делает факты более доступными в контексте чата LLM во время вывода.</p>\n<p><strong>Принципы генерации синтетических данных для phi-4.</strong> Наш подход к генерации синтетических данных для phi-4 основывается на следующих принципах:</p>\n<ol>\n<li><strong>Разнообразие:</strong> Данные должны всесторонне охватывать подтемы и навыки в каждой области. Это требует подбора разнообразных "семян" из органических источников.</li>\n<li><strong>Нюансы и сложность:</strong> Эффективное обучение требует нюансированных, нетривиальных примеров, отражающих сложность и богатство предметной области. Данные должны выходить за рамки основ и включать пограничные случаи и продвинутые примеры.</li>\n<li><strong>Точность:</strong> Код должен выполняться правильно, доказательства должны быть обоснованными, а объяснения должны соответствовать общепринятым знаниям и т.д.</li>\n<li><strong>Цепочка рассуждений:</strong> Данные должны поощрять систематическое рассуждение, обучая модель различным подходам к решению проблем шаг за шагом. Это способствует формированию связных выходных данных для сложных задач.</li>\n</ol>'}, {'title': 'Synthetic Data for Pretraining and Midtraining', 'content': 'We created 50 broad types of synthetic datasets, each one relying on different set of seeds and different multi-stage prompting procedure, spanning an array of topics, skills, and natures of interaction, accumulating to total of about 400B unweighted tokens. In Appendix D, we give few examples of transcripts taken from our synthetic generations. Here, we highlight novel methodologies used in generating synthetic datasets for phi-4: Seed Curation: The synthetic dataset generation begins with high-quality seeds sourced from multiple domains. These curated seeds provide the foundation for synthetic data generation, enabling the creation of exercises, discussions, and reasoning tasks tailored to the models training objectives. 1. Web and Code-based Seeds: Excerpts and snippets are extracted from web pages, books, and code repositories with focus on content that demonstrates high complexity, reasoning depth, and educational value. To ensure quality, we employ two-stage filtering process: first, identifying pages with strong educational potential, and second, segmenting the selected pages into passages, scoring each for its factual and reasoning content. 2. Question Datasets: large set of questions was collected from websites, forums, and Q&A platforms. These questions were then filtered using plurality-based technique to balance difficulty. Specifically, we generated multiple independent answers for each question and applied majority voting to assess the consistency of responses. We discarded questions where all answers agreed (indicating the question was too easy) or where answers were entirely inconsistent (indicating the question was too difficult or ambiguous). This filtering process produces dataset of questions that challenge the models reasoning and problem-solving abilities while remaining approachable. The plurality answers were used in place of the ground truth in our rejection-sampling based generations. 3. Creating Question-Answer pairs from Diverse Sources: Another technique we use for seed curation involves leveraging language models to extract question-answer pairs from organic sources such as books, scientific papers, and code. This approach does not rely on merely identifying explicit Q&A pairs within the text. Instead, it involves pipeline designed to detect deduction chains or logical progressions in the text. The language model identifies key steps in reasoning or problem-solving processes and reformulates them into questions and corresponding answers. Our experiments show that, if done correctly, training on the resulting content can be far more effective (in terms of improvement on academic and internal benchmarks) than training on the original content. Rewrite and Augment: Seeds are transformed into synthetic data through multi-step prompting workflows. This includes rewriting most of the useful content in given passages into exercises, discussions, or structured reasoning tasks. Self-revision: The initial responses are then iteratively refined through feedback loop where model critiques and subsequently improves its own outputs, guided by the rubrics focused on reasoning and factual accuracy. 5 Instruction Reversal for Code and Other Tasks: To enhance the models ability to generate outputs from instructions, we used an instruction reversal technique. For example, we take existing code snippets from the code data corpus and use it to generate corresponding instructions that include the problem description or task prompt. The resulting synthetic data pairs were structured with the instruction appearing before the code. Only data with high fidelity between the original and regenerated code are retained, ensuring alignment between the instructions and the outputs. This method can be generalized to other targeted use cases. Validation of Code and Other Scientific Data: When appropriate, we incorporate tests for validating our reasoning-heavy synthetic datasets. The synthetic code data is validated through execution loops and tests. For scientific datasets, the questions are extracted from scientific materials using method designed to ensure high relevance, groundedness, and difficulty balance.', 'summary': '<p>В статье описывается процесс создания синтетических данных для обучения модели phi-4. Было сгенерировано 50 различных типов синтетических наборов данных, охватывающих широкий спектр тем, навыков и типов взаимодействия, общим объемом около 400 миллиардов токенов.</p>\n<p><strong>Курирование исходных данных:</strong> Процесс начинается с отбора высококачественных исходных данных из разных источников. Эти данные служат основой для генерации синтетических примеров, включая упражнения, дискуссии и задачи на рассуждение, которые соответствуют целям обучения модели.</p>\n<ol>\n<li><strong>Исходные данные из интернета и кода:</strong> Использовались фрагменты веб-страниц, книг и репозиториев кода, с акцентом на материалы, демонстрирующие сложность, глубину рассуждений и образовательную ценность. Для обеспечения качества применялся двухэтапный процесс фильтрации: сначала определялись страницы с высоким образовательным потенциалом, а затем выбранные страницы разделялись на фрагменты, каждый из которых оценивался на предмет фактического содержания и глубины рассуждений.</li>\n<li><strong>Наборы вопросов:</strong> Была собрана большая коллекция вопросов с веб-сайтов, форумов и платформ вопросов и ответов. Эти вопросы были отфильтрованы с использованием метода на основе множественности ответов для балансировки сложности. Для каждого вопроса генерировалось несколько независимых ответов, и применялось голосование большинством для оценки согласованности ответов. Вопросы, на которые все ответы были одинаковыми (слишком легкие) или полностью противоречивыми (слишком сложные или неоднозначные), отбрасывались. В результате получился набор вопросов, которые бросают вызов способностям модели к рассуждению и решению проблем, оставаясь при этом доступными. Множественные ответы использовались вместо "истинных" ответов при генерации данных на основе отклонения.</li>\n<li><strong>Создание пар "вопрос-ответ" из разных источников:</strong> Для отбора исходных данных также использовались языковые модели для извлечения пар "вопрос-ответ" из книг, научных статей и кода. Этот подход не просто ищет явные пары "вопрос-ответ" в тексте. Вместо этого языковая модель выявляет цепочки умозаключений или логические последовательности в тексте. Модель определяет ключевые шаги в процессе рассуждения или решения проблем и переформулирует их в вопросы и соответствующие ответы. Эксперименты показали, что обучение на таком контенте может быть более эффективным (с точки зрения улучшения результатов на академических и внутренних тестах), чем обучение на исходном контенте.</li>\n</ol>\n<p><strong>Переписывание и расширение:</strong> Исходные данные преобразуются в синтетические с помощью многоступенчатых подсказок. Это включает переписывание большей части полезного контента в упражнения, дискуссии или структурированные задачи на рассуждение.</p>\n<p><strong>Саморедактирование:</strong> Первоначальные ответы затем итеративно улучшаются с помощью цикла обратной связи, в котором модель критикует и улучшает свои собственные результаты, опираясь на критерии, ориентированные на рассуждения и точность фактов.</p>\n<p><strong>Обращение инструкций для кода и других задач:</strong> Для улучшения способности модели генерировать ответы на основе инструкций использовался метод обращения инструкций. Например, существующие фрагменты кода из корпуса данных кода использовались для генерации соответствующих инструкций, включающих описание проблемы или запрос задачи. Полученные пары синтетических данных были структурированы так, чтобы инструкция предшествовала коду. Сохранялись только данные с высокой точностью соответствия между исходным и регенерированным кодом, что гарантировало соответствие между инструкциями и ответами. Этот метод может быть обобщен на другие целевые варианты использования.</p>\n<p><strong>Проверка кода и других научных данных:</strong> Когда это уместно, в синтетические наборы данных включаются тесты для проверки. Синтетические данные кода проверяются посредством циклов выполнения и тестов. Для научных наборов данных вопросы извлекаются из научных материалов с использованием метода, обеспечивающего высокую релевантность, обоснованность и сбалансированную сложность.</p>'}, {'title': 'Curation and Filtering of Web and Q&A Data', 'content': 'Q&A datasets. We collected tens-of-millions high-quality organic problems and solutions by reviewing public websites, relying on existing datasets, and acquiring external datasets. Our experience from previous models showed that question-answer data contributed significantly to various capabilities, such as mathematical reasoning and academic performance. Our ablation studies showed that organic questions are substantially more effective than synthetic questions. We used several ways to synthetically augment the dataset of organic questions to obtain larger dataset. While these rewritten questions improved the models capabilities, the gains were not as pronounced. significant portion of the collected questions lacked accurate solutions. To address this, we replaced the answers with synthetically generated ones and used majority-voting to increase accuracy. All collected questions and solutions underwent thorough decontamination process to ensure there is no overlap with test sets3. Targeting High-quality Web Data. We collected wide variety of high-quality organic data sources for phi-4, prioritizing reasoning-dense and nuanced material (e.g., academic papers, educational forums, and programming tutorials). In addition to directly training on this text, we used various web sources as seeds for specialized synthetic data generation pipelines. We found clean and correct natural data to be absolutely crucial for seeding synthetic data: minor errors can result in severe quality degradations for derived synthetic documents. We therefore invested heavily in the perfectionistic curation of our web data. We discuss the main techniques and considerations below: Targeted Acquisitions: We included major repositories of reasoning-dense documents that are publicly permissible for use (e.g., arXiv, PubMed Central, GitHub) or explicitly licensed (e.g., licensed books) aiming for level of comprehensiveness, recency, and cleanliness above the typical standard of externally available corpora. Filtering Web Dumps: To capture the long tail of information-rich web sources (e.g., forums, blogs, course material, domain-specific wikis), we took the approach of selecting small fraction of highest-quality documents from bulk web dumps, using small (non-LLM) classifiers trained on 106 LLM-generated annotations. This approach tends to over-index on STEM-related keywords, so we created specialized pipeline to amplify high-quality non-STEM content (e.g., arts, history, travel, culture, and entertainment). These topic classifications were also obtained by distilling an 3This step is crucial to the reliability of some of the academic benchmarks: for instance, some test benchmark variants can be found on platforms like Hugging Face. Moreover, benchmarks such as MMLU are frequently compiled from websourced questions. LLM annotator. Finally, we removed corrupted text and binary files by detecting outliers according to n-gram statistics and compression ratios. Multilingual Data: We incorporated multilingual datasets to ensure that our model could handle wide range of languages, including German, Spanish, French, Portuguese, Italian, Hindi and Japanese. This involved sourcing and processing high-quality multilingual documents from CommonCrawl and Wikipedia. Our multilingual processing pipeline consists of language identification model, based on fastText used to categorize documents into 176 languages, then uses the same classifiers for filtering web dumps to filter for quality. Note that the classifiers were trained on multilingual LLM-generated annotations. Custom Extraction and Cleaning Pipelines: To ensure sufficient cleanliness and uniformity between heterogeneous organic data sources, we needed collection of customized heuristics and parsers. For each targeted data source, we built custom pipelines to ingest variety of file formats (e.g., multi-file TeX source, ePub and other XML-like formats, Microsoft Word documents, and PDFs). For general web data, we built custom HTML-to-text extractor, taking significant care to preserve fragile content that is frequently corrupted by naıve parsers (e.g., TeX/MathML equations, code blocks, tables, and forum thread structure). This extractor prunes and normalizes the DOM tree, using variety of signals (e.g., HTML tag names, CSS classes, content length, and tree depth) to distinguish elements such as boilerplate, advertisements, equations, and syntaxhighlighter artifacts.', 'summary': '<p><strong>Наборы данных "вопрос-ответ" и высококачественные веб-данные</strong></p>\n<p>Для обучения модели были собраны десятки миллионов высококачественных вопросов и ответов, полученных из открытых веб-сайтов, существующих наборов данных и внешних источников. Опыт предыдущих моделей показал, что данные типа "вопрос-ответ" значительно улучшают различные возможности, такие как математическое мышление и академическая успеваемость. Исследования показали, что "органические" вопросы (то есть, вопросы, созданные людьми, а не сгенерированные) гораздо эффективнее синтетических. Для увеличения объема данных использовались различные методы синтетического расширения набора органических вопросов. Хотя эти перефразированные вопросы и улучшили возможности моделей, прирост был не таким значительным. Значительная часть собранных вопросов не имела точных ответов, поэтому ответы были заменены на синтетически сгенерированные, а для повышения точности использовалось голосование большинством. Все собранные вопросы и решения прошли тщательную очистку, чтобы исключить любое пересечение с тестовыми наборами.</p>\n<p>Для обучения модели также был собран широкий спектр высококачественных органических данных, причем приоритет отдавался материалам, требующим рассуждений и содержащим нюансы (например, научные статьи, образовательные форумы и учебники по программированию). Веб-источники использовались не только для обучения модели, но и в качестве основы для специализированных конвейеров синтетической генерации данных. Было обнаружено, что чистые и корректные естественные данные крайне важны для запуска синтетических данных: даже незначительные ошибки могут привести к серьезному ухудшению качества производных синтетических документов. Поэтому значительные усилия были вложены в тщательную курацию веб-данных.</p>\n<p>Процесс сбора и обработки данных включал следующие этапы:</p>\n<ul>\n<li><strong>Целевые приобретения:</strong> Были включены крупные репозитории документов, требующих рассуждений, которые разрешены для публичного использования (например, arXiv, PubMed Central, GitHub) или лицензированы (например, лицензированные книги). Целью было достижение уровня полноты, актуальности и чистоты выше типичного стандарта общедоступных корпусов.</li>\n<li><strong>Фильтрация веб-дампов:</strong> Для охвата более широкого спектра информационно насыщенных веб-источников (например, форумов, блогов, учебных материалов, тематических вики) был применен подход выбора небольшой части самых качественных документов из массовых веб-дампов. Для этого использовались небольшие классификаторы (не на основе LLM), обученные на основе аннотаций, сгенерированных LLM. Этот подход, как правило, переиндексирует STEM-связанные ключевые слова, поэтому был создан специализированный конвейер для усиления высококачественного контента не-STEM тематики (например, искусства, истории, путешествий, культуры и развлечений). Эти тематические классификации также были получены путем дистилляции LLM-аннотатором. Наконец, поврежденный текст и двоичные файлы были удалены путем обнаружения выбросов по статистике n-грамм и коэффициентам сжатия.</li>\n<li><strong>Многоязычные данные:</strong> Для обеспечения возможности модели обрабатывать широкий спектр языков, были включены многоязычные наборы данных, включая немецкий, испанский, французский, португальский, итальянский, хинди и японский. Это включало поиск и обработку высококачественных многоязычных документов из CommonCrawl и Wikipedia. Конвейер многоязычной обработки состоит из модели идентификации языка, основанной на fastText, используемой для классификации документов на 176 языков, а затем использует те же классификаторы для фильтрации веб-дампов для повышения качества. Важно отметить, что классификаторы были обучены на многоязычных LLM-сгенерированных аннотациях.</li>\n<li><strong>Специализированные конвейеры извлечения и очистки:</strong> Для обеспечения достаточной чистоты и единообразия между разнородными органическими источниками данных потребовался набор специализированных эвристик и парсеров. Для каждого целевого источника данных были созданы индивидуальные конвейеры для приема различных форматов файлов (например, многофайловый исходный код TeX, ePub и другие XML-подобные форматы, документы Microsoft Word и PDF). Для общих веб-данных был создан собственный экстрактор HTML-в-текст, который уделяет особое внимание сохранению "хрупкого" контента, который часто повреждается простыми парсерами (например, уравнения TeX/MathML, блоки кода, таблицы и структура потока форума). Этот экстрактор обрезает и нормализует дерево DOM, используя различные сигналы (например, имена HTML-тегов, классы CSS, длину содержимого и глубину дерева) для различения таких элементов, как шаблонный текст, реклама, уравнения и артефакты подсветки синтаксиса.</li>\n</ul>'}, {'title': 'Pretraining Details', 'content': 'The phi-4 model is based on decoder-only transformer architecture [VSP+17] with 14B parameters and default context length of 4096. This is later extended to 16K context length during midtraining. The architecture closely follows phi-3-medium, except that we now use the tiktoken tokenizer (for better multilingual support) with padded vocabulary size of 100,352 (including unused tokens) and we use full attention over the 4K context length, rather than 2K sliding window used in phi-3-medium. The model was pretrained for approximately 10T tokens using linear warm-up and decay schedules with peak learning rate of 0.0003, constant weight decay of 0.1, and global batch size of 5760. The training hyperparameters are tuned using interpolations from shorter horizon runs and further adjusted by stress testing the learning rate warm-up stage for stability. Pretraining is followed by shorter midtraining stage to increase the original context length of 4k to 16k. Since pre-trained models are not good at instruction following, it is not very informative to use 0-shot evaluations that require the answer to be in specific format, for example simple-evals. We 7 MMLU MMLU pro GSM8k Human-Eval ARCC MBPP MATH TQA phi-4 (4k) phi-4 (16k) +3.0 +2.7 +10.3 +8.9 +2.2 +1.2 +7.8 +9.0 +1.1 +0.9 +6.8 +9. +8.9 +8.4 -0.7 -1.5 Table 2: Pretraining benchmarks for phi-4 compared to its predecessor, phi-3-medium after pretraining. therefore use an internal implementation of benchmarks for pretraining which uses mixture of loglikelihood and/or few-shot prompts for various tasks. Specifically, we used log-likelihood evaluations for MMLU (5-shot), MMLU-pro, and ARCC (1-shot). We used 1, 3, 4, and 8 few-shot examples for TriviaQA (TQA), MBPP, MATH, and GSM8k to help the model adhere to the answer format for easier extraction of the solution. We use this evaluation method throughout Section 3. Table 2 summarizes the performance boost of pretrained phi-4 compared with its predecessor phi-3-medium.', 'summary': '<p>Модель phi-4 основана на архитектуре transformer только с декодером, она имеет 14 миллиардов параметров и стандартную длину контекста в 4096 токенов. В процессе обучения длина контекста была увеличена до 16 тысяч токенов. Архитектура модели очень похожа на phi-3-medium, за исключением нескольких ключевых изменений. Во-первых, в phi-4 используется токенизатор tiktoken, который обеспечивает лучшую поддержку многоязычности. Размер словаря токенизатора составляет 100 352, включая неиспользуемые токены. Во-вторых, в phi-4 используется полноценное внимание (full attention) ко всей длине контекста в 4096 токенов, в то время как в phi-3-medium применялось скользящее окно размером 2048 токенов.</p>\n<p>Модель phi-4 была предварительно обучена на примерно 10 триллионах токенов. При обучении использовались линейные графики нарастания и спада скорости обучения, с пиковым значением 0.0003, постоянным весовым распадом 0.1 и глобальным размером батча 5760. Гиперпараметры обучения были настроены с использованием интерполяции результатов более коротких запусков и дополнительно скорректированы путем стресс-тестирования этапа нарастания скорости обучения для обеспечения стабильности. После предварительного обучения был проведен более короткий этап дообучения, чтобы увеличить исходную длину контекста с 4 тысяч до 16 тысяч токенов.</p>\n<p>Поскольку предварительно обученные модели плохо справляются с выполнением инструкций, использование оценок "0-shot", требующих ответа в определенном формате, например, simple-evals, не является информативным. Поэтому для оценки предварительного обучения использовалась внутренняя реализация бенчмарков, которая применяет смесь логарифмического правдоподобия и/или few-shot подсказок для разных задач. Конкретно, для MMLU (5-shot), MMLU-pro и ARCC (1-shot) использовались оценки логарифмического правдоподобия. Для TriviaQA (TQA), MBPP, MATH и GSM8k применялись 1, 3, 4 и 8 few-shot примеров, чтобы помочь модели придерживаться формата ответа для упрощения извлечения решения. Этот метод оценки используется на протяжении всего раздела 3. В таблице 2 показано улучшение производительности предварительно обученной модели phi-4 по сравнению с её предшественницей, phi-3-medium.</p>'}, {'title': 'Data Composition in Pretraining', 'content': 'The phi-3 model family were trained using two-phase strategy. Most of the training tokens were used in phase 1 of the training, which consisted largely of filtered web data. Phase 2 was trained with data mixture consisting primarily of synthetic tokens and much smaller allocation for ultra-filtered and reasoning-heavy web data. As the size and complexity of our synthetic data grew, we observed marginal drop in the benefit from using non-synthetic tokens for the phi-3 family of model sizes. We note two key observations. Web datasets showed small benefits on reasoning heavy benchmarks. Prioritizing more epochs over our synthetic data led to better performance with respect to adding fresh web tokens. Models trained only with synthetic data underperformed on the knowledge-heavy benchmarks and demonstrated increased hallucinations. Figure 2 demonstrates the first phenomenon using smaller scale phase 2 pretraining exercises. In this example, we conduct two training runs per model scale, using the same number of training tokens on top of phase 1 pretrained checkpoints. For all runs, the number of unique synthetic tokens is fixed (a subsample of full synthetic data) but the number of repetitions on this data changes, namely 4 and 12 epochs. The rest of the training tokens are fresh unique tokens supplied from web sources. As seen, performing more iterations on the synthetic data is more beneficial than supplying more web tokens. Inspired by this scaling behavior of our synthetic data, we trained 13B parameter model solely on synthetic4 data, for ablation purposes only the model sees over 20 repetitions of each data source. For the sake of ablations, we partitioned our synthetic data into web rewrites, which includes more direct rewrites of our filtered web content relative to all other types of synthetic data. Table 3 compares the previous phi-3-medium model with the new model trained entirely on the synthetic data. Throughout training, all benchmarks consistently improved, despite the increase in epochs, and the majority of the benchmarks showed improvements over phi-3. However, knowledge-related benchmarks, like 1-shot triviaqa (TQA), show large gap where synthetic models are subpar. These observations led us to rethink the role of web data in our data mixture. 4This is an updated mixture of synthetic data that contains new sources compared to phi-3. 8 Figure 2: 5-shot MMLU score for phase 2 pretraining runs with 4 and 12 epochs of synthetic data. All models are trained for the same token horizon, thus the model with 4 epochs of synthetic has seen more (unique) web tokens. We see that despite many epochs on synthetic data, we do not see overfitting behavior and in fact the 12 epoch models perform better than those that have seen more unique web tokens. MMLU MMLU pro GSM8k Human-Eval ARCC MBPP MATH TQA Synthetic Synthetic + Web Rewrites +0.8 +0.3 +4.0 +4.1 +2.2 +1.8 +12.1 +13.3 0.0 +3.0 +5.0 +7. +4.9 +8.1 -14.8 -7.7 Table 3: Benchmark performance of 13B models (used for ablations only) trained on data mixtures containing no web data. The respective training tokens are either from synthetic sources, or an equal share of synthetic data and web rewrites. All numbers are reported relative to the performance of phi-3-medium, which has seen combination of web and synthetic data.', 'summary': '<p>Семейство моделей phi-3 обучалось в два этапа. На первом этапе использовалась большая часть обучающих токенов, которые в основном представляли собой отфильтрованные веб-данные. Второй этап обучения проходил на смеси данных, состоящей преимущественно из синтетических токенов, с гораздо меньшей долей ультра-отфильтрованных и ориентированных на рассуждения веб-данных.</p>\n<p>По мере роста размера и сложности наших синтетических данных, мы наблюдали незначительное снижение пользы от использования несинтетических токенов для моделей phi-3. Были сделаны два ключевых наблюдения: веб-данные показали небольшую пользу на тестах, требующих рассуждений, а приоритезация большего количества эпох обучения на синтетических данных давала лучшие результаты, чем добавление новых веб-токенов.</p>\n<p>Модели, обученные только на синтетических данных, показали более низкие результаты на тестах, требующих знаний, и демонстрировали усиление галлюцинаций. Рисунок 2 демонстрирует первое явление на примере небольших экспериментов по предварительному обучению на втором этапе. В этом примере для каждого размера модели проводилось два запуска обучения, используя одинаковое количество обучающих токенов поверх контрольных точек, предварительно обученных на первом этапе. Для всех запусков количество уникальных синтетических токенов было фиксированным (подвыборка полных синтетических данных), но количество повторений этих данных менялось, а именно 4 и 12 эпох. Остальные обучающие токены были новыми уникальными токенами, полученными из веб-источников. Как видно, выполнение большего количества итераций на синтетических данных более выгодно, чем предоставление большего количества веб-токенов.</p>\n<p>Вдохновленные таким масштабированием наших синтетических данных, мы обучили модель с 13 миллиардами параметров исключительно на синтетических данных, при этом для целей абляции модель видела более 20 повторений каждого источника данных. Для целей абляции мы разделили наши синтетические данные на "переписанные веб-данные", которые включают более прямые переписывания нашего отфильтрованного веб-контента, относительно всех других типов синтетических данных.</p>\n<p>В таблице 3 сравнивается предыдущая модель phi-3-medium с новой моделью, обученной полностью на синтетических данных. На протяжении всего обучения все тесты последовательно улучшались, несмотря на увеличение количества эпох, и большинство тестов показали улучшения по сравнению с phi-3. Однако тесты, связанные со знаниями, такие как 1-shot triviaqa (TQA), показывают большой разрыв, где синтетические модели работают хуже. Эти наблюдения заставили нас переосмыслить роль веб-данных в нашей смеси данных.</p>\n<p><em>Примечание: Авторы статьи выяснили, что для обучения моделей phi-3 большее количество эпох на синтетических данных более выгодно, чем добавление новых веб-данных. Однако, модели обученные только на синтетических данных, показали более низкие результаты на тестах, требующих знаний.</em></p>'}, {'title': 'Data Mixture', 'content': 'To design our pretraining data mixture for given training token budget, we search over different allocation of tokens coming from various sources, namely, 1) synthetic, 2) web rewrites5, 3) filtered web (divided into reasoning and knowledge-heavy portions), 4) targeted acquisitions and organic data (e.g., academic data, books, and forums), and 5) code data. We conducted ablations using shorter token horizon of 1T tokens to derive the data mixture. These ablations rely on our established result on the high-rank correlation of short training with longer training, up to the over-fitting saturation threshold of data sources. In addition we observe high rank correlation between the performance of the 7B and 14B models on different data mixtures, given large enough distance between the data mixtures. This allowed us to conduct the experiments at 7B scale and transfer the findings to phi-4. Among the numerous ablations, we highlight few that show best insights on our data composition. Specifically, we freeze the ratio of tokens coming from targeted acquisitions and code categories, and change the ratio of tokens for the synthetic, web, and web rewrites clusters. Table 4 summarizes the results for the hand-picked ablations, as compared with the data mixture that was used for the final training run. uniform allocation of tokens among the three categories is suboptimal due to the higher quality of synthetic data and the only benchmark that shows clear benefit from web data is TQA. While the synthetic-heavy variations on rows 2 and 3 of the table are marginally better than the chosen final data mixture, we decided to integrate the targeted and knowledge-heavy filtered web data sources to improve knowledge benchmarks (see Section 3.1) to balance all model 5Web rewrites is sub-category of synthetic data that is substantially large and contains direct rewrites of web content. 9 MMLU MATH GSM8k Human-Eval ARCC MBPP TQA MMLU pro Average Uniform + WR + -3.3 +3.3 +0.6 -0.6 -5.4 +4.0 +1.2 -0.7 -5.8 +2.1 +1.5 -0.7 -1.2 -6.1 -1.2 -4.3 +0.6 +1.9 +1.6 +0. -2.0 +0.4 +1.6 -2.0 +3.3 -3.0 -3.7 +6.9 -3.6 +3.7 +1.2 +0.9 -2.2 +0.8 +0.4 0.0 Table 4: Ablations on the allocation of 75% of training tokens to synthetic (S), filtered web (W), and web rewrite (WR) categories, while other data sources are held constant in the remaining 25% token budget. All benchmark numbers are measured relative to the final data mixture used for training phi-4. capabilities. We also note that we observed the gap between the chosen data mixture and the synthetic heavy runs largely closes as the model goes through the post-training stage. An end-to-end optimization of pretraining data mixture that also takes into account the effects of post-training is an interesting future area of investigation. Data Source Fraction of Training Unique Token Count Number of Epochs Web Web rewrites Synthetic Code data Acquired sources 15% 15% 40% 20% 10% 1.3T 290B 290B 820B 580B 1.2 5.2 13.8 2.4 1.7 Table 5: Data mixture for pretraining. The final data mixture used for phi-4 allocates 30% of the training tokens to web and web rewrites data sources, divided equally between them. The remaining tokens are largely sourced from synthetic data which accounts for 40% of the data mixture tokens. Finally we allocate 20% of tokens to code data (mixture of synthetic and raw code) and 10% to targeted acquired sources like academic data and books. In terms of total number of unique tokens in each data mixture cluster, filtered web data is the largest cluster with 1.3T tokens. Code and targeted acquisitions are the second and third largest clusters with 820B and 580B tokens, respectively. Finally, web rewrites and synthetic data have similar token count of 290B tokens. The total number of epochs on each data source is determined using the ratio of allocated tokens in the mixture and the number of unique tokens in that source.', 'summary': '<p>Для определения оптимального соотношения данных для предварительного обучения модели, мы исследовали различные комбинации токенов из разных источников. Эти источники включают: 1) синтетические данные, 2) переписанный веб-контент, 3) отфильтрованный веб (разделенный на части, ориентированные на рассуждения и знания), 4) целевые и органические данные (например, академические работы, книги и форумы) и 5) данные кода.</p>\n<p>Для определения оптимального соотношения мы провели эксперименты с меньшим объемом токенов (1 триллион). Это было возможно благодаря тому, что мы ранее установили высокую корреляцию между результатами обучения на коротких и длинных периодах, вплоть до насыщения переобучением. Кроме того, мы заметили высокую корреляцию между производительностью моделей с 7 и 14 миллиардами параметров при использовании разных наборов данных, если эти наборы достаточно отличаются. Это позволило нам проводить эксперименты на модели с 7 миллиардами параметров и переносить результаты на модель phi-4.</p>\n<p>Среди множества экспериментов, мы выделили несколько, которые дали наиболее ценные сведения о составе данных. В частности, мы зафиксировали соотношение токенов из целевых приобретений и кода, а затем изменяли соотношение токенов для синтетических данных, веб-данных и переписанного веб-контента.</p>\n<p>Таблица 4 показывает результаты этих экспериментов по сравнению с окончательным набором данных, использованным для обучения. Равномерное распределение токенов между тремя категориями оказалось неоптимальным из-за более высокого качества синтетических данных. Единственный тест, где веб-данные показали явное преимущество, — это TQA. Хотя варианты с преобладанием синтетических данных (строки 2 и 3 таблицы) были незначительно лучше, чем финальный набор, мы решили включить целевые и ориентированные на знания веб-данные, чтобы улучшить результаты на тестах, связанных со знаниями, и сбалансировать возможности модели. Важно отметить, что разница между выбранным и синтетическим наборами данных уменьшается по мере прохождения модели этапа постобработки. Оптимизация набора данных для предварительного обучения с учетом эффектов постобработки является интересной темой для будущих исследований.</p>\n<p>Финальный набор данных для предварительного обучения модели phi-4 распределяет 30% токенов между веб-данными и переписанным веб-контентом (поровну). Остальные токены в основном поступают из синтетических данных (40%). Также 20% токенов выделено для данных кода (смесь синтетического и исходного кода) и 10% для целевых данных (академические работы и книги).</p>\n<p>По количеству уникальных токенов отфильтрованные веб-данные являются самым большим кластером (1.3 триллиона токенов). Код и целевые данные занимают второе и третье места (820 и 580 миллиардов токенов соответственно). Переписанный веб-контент и синтетические данные имеют примерно одинаковое количество токенов (290 миллиардов). Количество эпох обучения для каждого источника определяется соотношением выделенных токенов и общего количества уникальных токенов в этом источнике.</p>'}, {'title': 'Midtraining Details', 'content': 'phi-4 includes midtraining stage where the context length is increased from the original 4K to 16K. We conduct several ablations to study the role of data on long-context performance. Specifically, we try data sources that are inherently long context, and compare them with artificially created long context data where samples are padded together to fill the sequence. We observe the former to perform better in longer context tasks. Inspired by this, we further filter our high-quality non-synthetic datasets (i.e., academic, books, and code data) to separate samples above 8K context. We then up-weight the data subsets that are 16K or higher in length. We also create new synthetic datasets that satisfy the > 4K sequence requirement. The final data mixture includes 30% of the newly curated longer context data and 70% portion of recall 10 Model Max Length Recall RAG ICL Re-rank QA Summ phi-4 Qwen-2.5-14B Llama-3.3-70B GPT-4o-mini GPT-4o phi-4 Qwen-2.5-14B Llama-3.3-70B GPT-4o-mini GPT-4o 8K 8K 8K 8K 8K 16K 16K 16K 16K 16K 100.0 100.0 92.0 99.2 100.0 99.0 100.0 92.0 100.0 100.0 58.1 62.2 65.3 65.8 66. 57.1 59.1 62.2 63.6 66.7 68.0 67.8 69.4 74.4 83.0 77.0 67.6 70.0 78.4 85.6 65.3 58.2 64.4 69.4 75.1 54.4 50.3 63.3 63.9 73.8 26.7 24.7 30.0 31.3 37. 36.0 29.7 36.7 36.0 43.7 38.3 37.2 37.8 38.5 43.0 40.5 42.3 41.9 45.2 46.3 Table 6: Evaluation results on the long-context benchmark HELMET [YGH+24]. tokens from the pretraining stage. To accommodate longer context, we increase the base frequency of rope position encoding to 250K following [AI23b]. We drop the maximum learning rate by factor of 10 compared to the pretraining stage and train for total of 250B tokens. To effectively evaluate the long-context capability of our model, it is essential to have comprehensive evaluation framework with practical scenarios. While synthetic benchmarks like needle-in-a-haystack and RULER are preferred for their simplicity and control, our emphasis is on diverse range of tasks that reflect real-world applications, such as reasoning across entire documents. We report the performance of phi-4 and other models on the tasks we selected from the HELMET [YGH+24] evaluation suite in Table 6 and outline our evaluation methods below. Note that results are average across 5 runs for each categories. Recall: The task involves retrieving the corresponding value from randomly-generated long JSON file given specific key (Metric: SubEM) RAG: Answer questions based on many retrieved and shuffled Wikipedia documents. The datasets used for this task are NaturalQuestions, HotpotQA, and PopQA. Final results are average of all datasets (Metric: SubEM) Re-rank: The task is to re-rank the top-10 documents given query and many retrieved and shuffled documents. This uses the MSMARCO dataset (Metric: nDCG@10) ICL: The task involves many-shot in-context learning with datasets such as TREC coarse, TREC fine, Banking77, NLU and CLINC150. Final results are average of all datasets (Metric: F1) QA: Answer questions given lengthy document. The dataset associated with this task is NarrativeQAv2 (Metric: GPT-4o scoring) Summ: The task involves summarizing lengthy legal document, and the dataset used is MultiLexSum (Metric: GPT-4o scoring) Dataset Name Sample Count unknown + safety data generic multiple-choice Q&A math data python data cpp, go, java, js, rust data 3,000 132,859 76,552 16,080 21,806 Table 7: Data Mixture for Pivotal Token DPO', 'summary': '<p><strong>Увеличение длины контекста и обучение phi-4</strong></p>\n<p>В процессе обучения модели phi-4 был добавлен этап, на котором длина контекста была увеличена с исходных 4K токенов до 16K токенов. Чтобы изучить влияние данных на производительность модели при работе с длинным контекстом, были проведены эксперименты с различными источниками данных. Использовались как данные, изначально имеющие длинный контекст, так и искусственно созданные данные, где короткие фрагменты были объединены для заполнения длинной последовательности. Результаты показали, что данные, изначально имеющие длинный контекст, лучше подходят для задач, требующих обработки длинных последовательностей.</p>\n<p>Основываясь на этих наблюдениях, высококачественные несинтетические наборы данных (академические тексты, книги и код) были отфильтрованы, чтобы выделить фрагменты длиной более 8K токенов. Затем подмножества данных длиной 16K и более были усилены. Кроме того, были созданы новые синтетические наборы данных, соответствующие требованию длины последовательности &gt; 4K. В итоговой смеси данных 30% занимали недавно собранные данные с длинным контекстом, а 70% - данные, использовавшиеся на этапе предварительного обучения.</p>\n<p>Для обработки более длинного контекста базовая частота позиционного кодирования RoPE была увеличена до 250K. Скорость обучения была снижена в 10 раз по сравнению с этапом предварительного обучения, а общее количество обученных токенов составило 250 миллиардов.</p>\n<p><strong>Оценка производительности на длинном контексте</strong></p>\n<p>Для оценки способности модели работать с длинным контекстом был использован комплексный набор задач, отражающих реальные сценарии. Хотя синтетические тесты, такие как "иголка в стоге сена", просты и удобны для контроля, основное внимание уделялось разнообразным задачам, имитирующим реальные приложения, например, рассуждение на основе целых документов. Производительность phi-4 и других моделей оценивалась на задачах, выбранных из набора HELMET.</p>\n<p>Оценка проводилась по следующим задачам:</p>\n<ul>\n<li><strong>Recall:</strong> извлечение значения из длинного JSON-файла по заданному ключу.</li>\n<li><strong>RAG (Retrieval-Augmented Generation):</strong> ответы на вопросы на основе множества извлеченных и перемешанных документов Wikipedia.</li>\n<li><strong>Re-rank:</strong> переранжирование 10 лучших документов по запросу.</li>\n<li><strong>ICL (In-Context Learning):</strong> обучение с несколькими примерами на основе наборов данных TREC, Banking77, NLU и CLINC150.</li>\n<li><strong>QA (Question Answering):</strong> ответы на вопросы по длинному документу.</li>\n<li><strong>Summ (Summarization):</strong> обобщение длинного юридического документа.</li>\n</ul>\n<p>Результаты оценки представлены в таблице 6 и являются средними значениями по 5 запускам для каждой категории.</p>\n<p><strong>Состав данных для обучения DPO</strong></p>\n<p>В таблице 7 представлен состав данных, использованных для обучения DPO (Direct Preference Optimization) модели. Данные включают различные категории, такие как:</p>\n<ul>\n<li>Неизвестные данные и данные по безопасности</li>\n<li>Общие вопросы и ответы с множественным выбором</li>\n<li>Математические данные</li>\n<li>Данные на языке Python</li>\n<li>Данные на языках C++, Go, Java, JavaScript и Rust</li>\n</ul>\n<p>Количество примеров для каждой категории также указано в таблице.</p>'}, {'title': 'Direct Preference Optimization', 'content': 'We use DPO [RSM+23] to align the model with human preferences, and also to steer the model away from unwanted behavior through pairs of desired and undesired outputs. DPO data covers chat format data, reasoning, and Responsible AI (RAI) data and improves the model in math, coding, reasoning, robustness, and safety. We do two rounds of DPO on the SFT model. We introduce technique, Pivotal Token Search (PTS), to generate pairs for DPO for the first DPO round. Details of the data mixture for first round are provided in Table 7. For the second round, which we call judge-guided DPO, we gather approximately 850k pairs of desired and undesired outputs. The prompts are sourced from various publicly available instruction tuning datasets and also include prompts related to safety and Responsible AI (RAI). Next, for each of these prompts, we generate responses from GPT-4o, GPT-4t and our model. From these responses, we create various combinations of DPO pairs and use GPT-4o as judge to label positive or negative for given pair. For given pair of responses, each assistant response is given score based on accuracy, style, and detail. We label the response with higher accuracy or overall (average of accuracy, style, and detail) score as the positive response. We provide the prompt we used in Appendix A. The data mixture for this round is provided in Table 8. Both stages also include small amount of data for safety and mitigating hallucinations. 12 Suppose that the roots of x3 + 3x2 + 4x 11 = 0 are a, b, and c, and that the roots User: of x3 + rx2 + sx + = 0 are + b, + c, and + a. AI: To solve the problem, we need to dealdealdealdealdeal dealdealdealdealdeal with the roots of the two cubic equations deal deal deal deal deal deal deal First, consider the cubic polynomial polynomial polynomial polynomial polynomial polynomial polynomial given. polynomial ( xˆ3 + 3xˆ2 + 4x - 11 = 0 ), polynomial polynomial polynomial polynomial polynomial polynomial polynomial polynomial polynomial By Vietas formulas, we have: [ + with roots ( ), ( ), and ( ). + = -3, ] [ ab + bc + ca = 4, ] [ abc = 11. ] Now, consider the other other other other other other other other other other other other other other other other other polynomial ( xˆ3 + rxˆ2 + sx + = 0 ) with roots ( a+b ), ( b+c ), and ( c+a ). We need to find the value of ( ), which corresponds corresponds corresponds corresponds corresponds corresponds corresponds corresponds to the negative corresponds corresponds corresponds corresponds corresponds corresponds corresponds corresponds corresponds Find t. of 0.42 0.93 according to Vietas formulas::::::::::::::::: [ the product of the roots according according according according according according according according according according according according according according according according (a 0.95 0.71 +b)(b+c)(c+a). ] First notenotenotenotenote the important First, notenotenotenotenote important important First First important important First First important important First First important identity: [ (a+b)(b+c)(c+a) = (a+b+c)(ab+bc+ca) - important important First First note important important note First First note important important note First First note important important note First First important note First abc. ] PlugPlugPlugPlugPlug known values from ourourourourourourourourourourourourourourourourour Vietas results forforforforforforforforforforforforforforforforfor ( ), ( ), and PlugPlugPlugPlugPlugging in known known known known known known known known known known known Plug Plug known known Plug Plug known known Plug Plug known Plug ( ), we have: Substitute these into the identity: [ (a+b)(b+c)(c+a) = (-3)(4) - 11 = -12 - 11 = -23. ] Thus, ( = -(a+b)(b+c)(c+a) = 23 ). Therefore, the value of ( ) is (boxed23). [ +++++++++++++++++ + = -3, ] [ ab + bc + ca = 4, ] [ abc = 11. ] ) c ( 1 0 Figure 3: Illustration of pivotal tokens for GPT-4o at temperature 1 on problem from the MATH benchmark [HBK+21], where the initial success probability is 0.31. Each token is colorized by the probability of success for an independent completion (N = 529) continued from after the token, with red for p(success) = 0 and blue for p(success) = 1. The line plot shows the same probabilities. The tokens that changes p(success) by 0.2 are shown boxed , with subscripts showing the change in probability. Tokens with probability 0.1 are underlined to illustrate that pivotal tokens are distinct from low-probability tokens. The token probabilities of negative and (a were 0.31 and 0.12, respectively. The greedy tokens for the same prefixes are product with 0.66 probability and with 0.88 probability. procedure PivotalTokenSearch(Q, Tfull, pgap) procedure Subdivide(Tprefix, ) if 1 or p(success Tprefix) p(success Tprefix + ) < pgap then Base cases. return [T ] Tleft, Tright Split(T ) return Subdivide(Tprefix, Tleft) Subdivide(Tprefix + Tleft, Tright) We split at the cumulative midpoint of token log probabilities. Tprefix ϵ for all Subdivide(ϵ, Tfull) do if = 1 and p(success Tprefix) p(success Tprefix + ) pgap then yield (Q, Tprefix, ) Tprefix Tprefix + Output pivotal tokens and context for postprocessing. Figure 4: Pseudocode for Pivotal Token Search (PTS). Note that estimating p(success . . . ) involves sampling the language model and invoking the oracle. In an efficient implementation p(success . . . ) should be memoized.', 'summary': '<p>Для обучения модели с учётом предпочтений человека и для отсеивания нежелательного поведения используется метод DPO (Direct Preference Optimization). Данные для DPO включают в себя форматы чатов, рассуждения, а также данные, связанные с ответственным ИИ (RAI). Это улучшает модель в математике, кодировании, рассуждениях, устойчивости и безопасности.</p>\n<p>Обучение DPO проводится в два этапа поверх модели, обученной с учителем (SFT). На первом этапе DPO используется техника Pivotal Token Search (PTS) для генерации пар желаемых и нежелаемых ответов. На втором этапе, который называется DPO с оценками, собирается около 850 тысяч пар желаемых и нежелаемых ответов. Подсказки берутся из различных открытых наборов данных для обучения с инструкциями, а также включают подсказки, связанные с безопасностью и ответственным ИИ (RAI).</p>\n<p>Затем для каждой подсказки генерируются ответы от GPT-4o, GPT-4t и собственной модели. Из этих ответов создаются различные комбинации пар для DPO, и GPT-4o используется в качестве судьи для оценки каждой пары как положительной или отрицательной. Каждому ответу ассистента присваивается оценка на основе точности, стиля и детализации. Ответ с более высокой точностью или общей (средней) оценкой считается положительным. Оба этапа также включают небольшое количество данных для безопасности и снижения галлюцинаций.</p>\n<p>В статье также приведён пример использования PTS, где показано, как алгоритм определяет "ключевые" токены, влияющие на успешность ответа модели. На рисунке 3 показано, как вероятность успеха ответа меняется в зависимости от токена, а также выделены токены, которые значительно влияют на эту вероятность. Рисунок 4 представляет псевдокод алгоритма PTS.</p>'}, {'title': 'Pivotal Token Search', 'content': 'Consider generative model producing token-by-token response to given prompt. For each token produced, which corresponds to prefix of the model response, one can consider the conditional probability of the models answer being correct given that prefix, as well as the increment in this probability with respect to that token (in other words, the difference in the probability of being correct before and after producing that token). It is often the case that the overall correctness is highly dependent on successful generation of small number of key tokens. For example, we can see in Figure 3 where the model outputs math solution and fortunate sampling of crucial token negative shifts the solution from possible failure to likely success, while sampling of the token (a subsequently risks failure again. We refer to these tokens as pivotal tokens as they have an outsized effect on the course of the solution. Now, consider how the solution from Figure 3 would be used in DPO as full-length accepted response. As the figure shows, there are many tokens with probabilities much lower than the 0.31 of negative , which would contribute to noise in the gradients diluting the signal from the pivotal token. Even worse, the token (a that contributed to the lack of robustness would receive strong positive learning signal thanks to its low probability of 0.12. Moreover, intuition suggests that when two texts substantially deviate from each other, comparison of their individual next-token log probabilities (as done in DPO) is not very meaningful. Rather, it makes more sense that the signal should come from the first tokens after the two texts starts diverging from each other. To alleviate these effects, we employ method we call Pivotal Token Search (PTS) for generating preference data that specifically targets pivotal tokens in isolation, creating DPO pairs in which the preference optimization takes effect with respect to single token. PTS identifies points of completion token sequence Tfull = t1, t2, . . . for some user query where the next token ti has significant impact on the probability of success p(success t1, . . . , ti). PTS estimates these probabilities by sampling completions starting from + t1, . . . , ti, which are checked for correctness with an oracle6 for Q. Figure 4 shows basic instantiation of the algorithm. The procedure Subdivide recursively splits the sequence into segments ti, . . . , tj until the change in probability p(success t1, . . . , ti1) p(success t1, . . . , tj) for each segment is below threshold pgap or the segment is just single token. Tokens with sharp change in success probability are kept as pivotal. We turn pivotal tokens into preference data by taking + t1, . . . , ti1 as the query, and single tokens tacc and trej that increase/decrease p(success t1, . . . , ti1, tacc/rej) as the accepted and rejected completions, respectively.7 The binary-search algorithm for PTS is not always guaranteed to find all pivotal tokens, but it only finds pivotal tokens and it finds all of them if the success probability is near-monotone over the course of the solution. We used PTS to generate preference data for tasks where ground-truth is readily available, such as mathematics, various forms of question answering and coding. To improve sample efficiency, we filter the target questions to only include those with 0.2 p(success) 0.8, as pivotal tokens are rare for tasks that are very easy or hard. See Figure 5 for examples of preference data we generated using PTS. The math question answering example shows how pivotal tokens often are not actual mistakes, but choices that drive the model down less advantageous path. Here, multiplying both sides by the denominators separately is equally valid to directly cross-multiplying, but for the model doing the latter here is more robust. By generating DPO data targeting such choices, we believe PTS helps phi-4 work better in the modes it is especially 6For coding, comprehensive test suite can be used. For math problems, answers can be compared to the ground truth. 7We find drawing tacc and trej from rollouts PTS already used to estimate p(success t1, . . . , ti1) to be effective. 14 Find the product of all real values of for which 1 User: solution. AI: To solve the problem, we need to determine the values of such that the equation 2x = rx has exactly one real 7 has exactly one real solution for x. First, clear the fractions by Good: cross-multiplying Bad: multiplying both sides by 1 2x = 7 Adopt the axial channeling approximation to model the interaction Consider 1 keV helium atom impinging at one-degree incidence angle on LiF User: crystal surface. between the helium atom and the crystal as 2D potential energy landscape. Newtons equations to compute the helium atoms trajectory and determine the subsequent momentum transfers from binary collisions with surface atoms. energy transferred across all collisions and compute the probability, Pe, that the helium atom remains elastically scattered assuming vibrational frequency for surface atoms of ω = 1 1014Hz. 1. Pe = exp( Eloss AI: To determine the probability Pe that the helium atom remains elastically scattered, we need to calculate the total virtual energy transferred, Eloss, during the helium atoms interaction with the LiF crystal surface. Given Good: What is Pe? 2hω ), 2. Pe = exp( Eloss hω ), or 4. Pe = 1 exp( Eloss hω ) Bad: that the potential interactions hω ), 3. Pe = exp( Eloss the vibrational frequency Sum the total virtual Apply User: function described. Read the following function signature and docstring, and fully implement the Your response should only contain the code for this function. def reorder_sequence(n: int, sequence: list[int]) -> list[int]: """ Given sequence of integer numbers that Polycarp wrote down on the board, this function rearranges (reorders) elements of this sequence to match the order Polycarp could have possibly written them. Each next number should be exactly two times the previous number or exactly one third of the previous number. :param n: The number of elements in the sequence (2 <= <= 100). :param sequence: list of integer numbers in arbitrary order (1 <= elements <= 3 * 10ˆ18). :return: reordered list of integer numbers representing valid sequence Polycarp could have written. """ AI: ... from collections import defaultdict # Create adjacency list where each number can point to its possible predecessor and successors graph = defaultdict(list) for num in sequence: for other in sequence: if num != other: Good: other % if num == other * 2 or ( Bad: num * 2 Figure 5: Preference data generated by Pivotal Token Search in answering math and physics questions, and implementing function in Python. The tokens that form the actual pair for DPO are underlined. 15 Figure 6: The post-training process described in Appendix A.1 decreases hallucinations. One measure is that the problems in SimpleQAwhich the model very rarely gets correctare increasingly not attempted during the course of post-training. We believe the final result is better behavior, even though the simple-evals score for SimpleQA (the F1 score) actually gives our base model higher score than our final model. stronger. In [LLX+24] contrastive estimation approach involving model trained on incorrect Related Work: trajectories is used to score which tokens likely contributed to failure, which is further employed to weigh rejected responses in DPO. In comparison, our PTS avoids complications from learned proxies by directly estimating p(success). They also report difficulties applying their method to accepted responses in DPO, while our method generates both positive and negative preference data directly targeting pivotal tokens. Automated process supervision methods [WLS+24, LLL+24] have applied search and rollouts to generate data for training process reward models. PTS can be seen as an automated process supervision method that generates token-level preference data suitable for DPO.', 'summary': '<p>В этом разделе описывается метод Pivotal Token Search (PTS), который нацелен на улучшение обучения моделей путем выявления и использования ключевых токенов.</p>\n<p><strong>Проблема:</strong> Модели, генерирующие текст по токенам, часто показывают, что их общая правильность зависит от небольшого числа "ключевых" токенов. Эти токены, названные "опорными" (pivotal), могут существенно влиять на ход решения. Например, в задаче по математике выбор определенного токена может привести к правильному решению, в то время как другой выбор может привести к ошибке. Проблема заключается в том, что при использовании таких решений для обучения с помощью DPO (Direct Preference Optimization), множество токенов с низкой вероятностью могут создать "шум" в градиентах, размывая сигнал от ключевых токенов. Более того, токены, приводящие к ошибке, могут получить положительный обучающий сигнал из-за своей низкой вероятности.</p>\n<p><strong>Решение: Pivotal Token Search (PTS)</strong>. PTS – это метод, который нацелен на генерацию данных для обучения с учетом именно опорных токенов. Он работает следующим образом:</p>\n<ol>\n<li><strong>Идентификация опорных токенов:</strong> Метод анализирует последовательность токенов, сгенерированных моделью в ответ на запрос. Он рекурсивно разделяет последовательность на сегменты, пока изменение вероятности успеха (p(success)) для каждого сегмента не станет меньше заданного порога или сегмент не будет состоять из одного токена. Токены, которые вызывают резкое изменение вероятности успеха, определяются как опорные. Вероятность успеха оценивается путем выборки завершений, начиная с префикса последовательности токенов, и проверки их правильности с помощью "оракула" (например, для задач кодирования это может быть набор тестов, а для математических задач — сравнение с правильным ответом).</li>\n<li><strong>Генерация данных предпочтений:</strong> Для каждого опорного токена PTS создает пару данных для DPO. Запрос — это префикс последовательности токенов до опорного токена. "Принятое" завершение — это опорный токен, который увеличивает вероятность успеха, а "отвергнутое" завершение — это токен, который уменьшает вероятность успеха. Эти токены берутся из тех же выборок, которые PTS использовал для оценки вероятности успеха.</li>\n</ol>\n<p><strong>Преимущества PTS:</strong></p>\n<ul>\n<li><strong>Целенаправленное обучение:</strong> PTS фокусируется на обучении модели на опорных токенах, которые оказывают наибольшее влияние на результат.</li>\n<li><strong>Уменьшение шума:</strong> PTS уменьшает влияние "шума" от неключевых токенов, что приводит к более эффективному обучению.</li>\n<li><strong>Устранение нежелательных сигналов:</strong> Метод предотвращает получение положительных обучающих сигналов токенами, которые приводят к ошибкам.</li>\n<li><strong>Применимость:</strong> PTS подходит для задач, где есть возможность проверить правильность ответа (например, математика, ответы на вопросы, кодирование).</li>\n</ul>\n<p><strong>Ограничения:</strong></p>\n<ul>\n<li>Алгоритм поиска опорных токенов не всегда гарантирует нахождение всех опорных токенов, но гарантирует нахождение только опорных токенов и находит все из них, если вероятность успеха является почти монотонной на протяжении решения.</li>\n</ul>\n<p><strong>Улучшение эффективности:</strong> Для повышения эффективности выборки PTS фильтрует целевые вопросы, включая только те, у которых вероятность успеха находится в диапазоне от 0.2 до 0.8, поскольку опорные токены редки для очень легких или сложных задач.</p>\n<p><strong>Примеры:</strong> В статье приводятся примеры данных предпочтений, сгенерированных с помощью PTS для задач по математике, физике и кодированию. Эти примеры показывают, что опорные токены часто являются не фактическими ошибками, а выборами, которые направляют модель по менее выгодному пути.</p>\n<p><strong>Связь с другими работами:</strong> Метод PTS сравнивается с другими работами, в том числе с подходом контрастной оценки, где используются модели, обученные на неправильных траекториях, а также с методами автоматического контроля процесса. В отличие от этих подходов, PTS напрямую оценивает вероятность успеха и генерирует данные предпочтений, нацеленные на опорные токены.</p>'}, {'title': 'Benchmarking Considerations', 'content': 'While academic benchmarks are widely used to measure the progress in LLM advancement, they suffer from several limitations that can fail to reveal models true capabilities and weaknesses. These limitations include: Data Contamination: Many benchmarks rely on datasets that overlap with pretraining corpora, creating risk of data contamination. Although we took extensive measures to deduplicate and 16 SFT DPO stage 1 DPO stage 2 only phi-4 (stage 1 + 2) v - m MMLU GPQA MATH HumanEval MGSM SimpleQA DROP 82.8 47.3 77.1 79.5 80.8 3.7 82.8 MMLUPro 61.9 HumanEval+ 77.9 56.7 66.2 ArenaHard IFEval 84.8 53.6 80.5 81.6 80.8 2.9 86.1 70.0 81.9 66.5 63.0 PhiBench (internal) 48. 54.5 84.2 52.4 77.6 81.5 81.5 2.9 71.8 67.2 81.4 69.8 63.0 53.0 84.8 56.1 80.4 82.6 80.6 3.0 75.5 70.4 82.8 75.4 63. 56.2 Table 9: Performance through the post-training process. DPO stage 1 is pivotal token DPO, and DPO stage 2 is more standard judge-guided DPO. Each also has 1-5% hallucination and safety data mixed in. decontaminate our training data, including standard n-gram deduplication and decontamination, these methods are not effective against all scenarios, including rephrasing, which leaves some uncertainty about the true extent of generalization. Limited Skill Scope: Most benchmarks evaluate models on narrowly defined skills, such as solving specific style of math problems at certain grade level or implementing isolated Python functions. This narrow scope can fail to capture models broader capabilities and weaknesses. Bias in Generation-Based Benchmarks: Some benchmarks use LLM-as-judge for evaluating generated outputs. These judgments sometimes may prioritize style, fluency, or surface-level qualities over accuracy and validity of the reasoning chain, leading to potential biases in scoring. Limitations of Multiple-Choice Tasks: Benchmarks that rely on multiple-choice questions often test models ability to make clever guesses that can be achieved by pattern matching rather than effectively utilizing the underlying concepts through reasoning. To address these issues, we maintain an internal benchmark called PhiBench, which is tailored to evaluate the diverse skills and reasoning abilities that we found critical to phi-4s development. This benchmark was designed with the following goals: 1. Originality: All questions in the benchmark were composed by our team making sure that they were not present in our pretraining data. Our goal for the internal benchmark is to reveal models generalization ability in various domains. 2. Skill Diversity: Our benchmark includes wide range of tasks to assess multiple dimensions of model performance. For instance, in coding, it goes beyond isolated function implementation to include debugging, extending incomplete code, and explaining code snippets. Similarly, in 17 mathematics, it incorporates tasks like identifying the errors in proofs or generating related problems, rather than simply solving equations. This ensures that the benchmark captures broader spectrum of skills and reasoning processes. 3. Rigorous Scoring for Generation Tasks: For tasks requiring judgment of model-generated outputs, we addressed the common pitfalls of LLM-based scoring by carefully curating detailed judge instructions (or judge notes). These rubrics specify exactly how to evaluate responses, focusing on achieving accuracy, logical structure, and adherence to task requirements, while minimizing tendencies towards stylistic biases. We observed significantly improved consistency and reduction of adverse impact due to subjective preferences in the scoring outcomes. PhiBench played central role in optimizing phi-4. We used it to guide decisions about dataset mixtures and hyperparameter choices for more effective post-training techniques. PhiBench was also used to perform high-signal studies that identify weaknesses in the model and provide feedback for new incoming data sources.', 'summary': '<p><strong>Ограничения академических бенчмарков и разработка внутреннего бенчмарка PhiBench</strong></p>\n<p>Академические бенчмарки, хотя и широко используются для измерения прогресса в развитии больших языковых моделей (LLM), имеют ряд ограничений, которые могут не выявить истинные возможности и слабые стороны моделей. Эти ограничения включают:</p>\n<ol>\n<li>\n<p><strong>Загрязнение данных:</strong> Многие бенчмарки используют наборы данных, которые пересекаются с корпусами, используемыми для предварительного обучения моделей. Это создает риск "загрязнения" данных, когда модель может "помнить" ответы из обучающих данных, а не демонстрировать истинное понимание. Хотя принимаются меры для дедупликации и очистки данных, включая стандартную дедупликацию n-грамм, эти методы не эффективны против всех сценариев, например, перефразирования, что оставляет некоторую неопределенность относительно истинной способности к обобщению.</p>\n</li>\n<li>\n<p><strong>Ограниченный набор навыков:</strong> Большинство бенчмарков оценивают модели по узко определенным навыкам, таким как решение математических задач определенного типа или реализация изолированных функций на Python. Такой узкий охват может не выявить более широкие возможности и слабые стороны моделей.</p>\n</li>\n<li>\n<p><strong>Предвзятость в бенчмарках, основанных на генерации:</strong> Некоторые бенчмарки используют LLM в качестве "судьи" для оценки сгенерированных результатов. Эти оценки иногда могут отдавать приоритет стилю, беглости речи или поверхностным качествам, а не точности и обоснованности цепочки рассуждений, что приводит к потенциальным искажениям в оценке.</p>\n</li>\n<li>\n<p><strong>Ограничения задач с множественным выбором:</strong> Бенчмарки, основанные на вопросах с множественным выбором, часто проверяют способность моделей делать "умные" предположения, которые могут быть достигнуты путем сопоставления с образцом, а не эффективного использования основных концепций посредством рассуждений.</p>\n</li>\n</ol>\n<p>Чтобы решить эти проблемы, был разработан внутренний бенчмарк под названием PhiBench, специально предназначенный для оценки разнообразных навыков и способностей к рассуждению, которые оказались критически важными для развития модели phi-4. Этот бенчмарк был разработан со следующими целями:</p>\n<ol>\n<li>\n<p><strong>Оригинальность:</strong> Все вопросы в бенчмарке были составлены командой разработчиков, чтобы гарантировать их отсутствие в данных предварительного обучения. Цель внутреннего бенчмарка — выявить способность моделей к обобщению в различных областях.</p>\n</li>\n<li>\n<p><strong>Разнообразие навыков:</strong> Бенчмарк включает широкий спектр задач для оценки различных аспектов производительности модели. Например, в области программирования он выходит за рамки реализации изолированных функций, включая отладку, расширение неполного кода и объяснение фрагментов кода. Аналогично, в математике он включает такие задачи, как выявление ошибок в доказательствах или генерация связанных задач, а не просто решение уравнений. Это гарантирует, что бенчмарк охватывает более широкий спектр навыков и процессов рассуждения.</p>\n</li>\n<li>\n<p><strong>Строгая оценка задач генерации:</strong> Для задач, требующих оценки сгенерированных моделью результатов, были устранены распространенные недостатки оценки на основе LLM путем тщательной разработки подробных инструкций для судей. Эти инструкции точно определяют, как оценивать ответы, уделяя особое внимание достижению точности, логической структуры и соответствия требованиям задания, сводя к минимуму тенденции к стилистическим искажениям. Наблюдалось значительное повышение согласованности и снижение негативного влияния субъективных предпочтений в результатах оценки.</p>\n</li>\n</ol>\n<p>PhiBench сыграл центральную роль в оптимизации модели phi-4. Он использовался для принятия решений о сочетании наборов данных и выборе гиперпараметров для более эффективных методов постобработки. PhiBench также использовался для проведения исследований, выявляющих слабые места модели и предоставляющих обратную связь для новых источников данных.</p>'}, {'title': 'Performance on Key Benchmarks', 'content': 'Our benchmark results were presented in Table 1, along with comparisons to other models. We first report the values from OpenAIs simple-evals benchmark, which is framework (including prompts, temperature, and extraction) for evaluating MMLU [HBB+20], GPQA diamond [RHS+23], MATH [HBK+21], HumanEval [CTJ+21], MGSM [SSF+22], and the SimpleQA [WKC+24] F1-score. We also consider MMLU-pro [WMZ+24], HumanEval+ [LXWZ23], ArenaHard [CZS+24], and IFEval [ZLM+23], for which we use an internal framework and prompting and extraction. Finally, we use PhiBench, our internal collection of evaluations (see Section 5). phi-4 outperforms the closest in-class contemporary model, Qwen-2.5-14B-Instruct, in 9 out of 12 benchmarks. While phi-4 underperforms relative to Qwen-2.5-14B-Instruct on the benchmark numbers for SimpleQA, DROP, and IFEval, we consider phi-4s behavior on SimpleQA to actually be better than Qwens. In fact, our base model gets higher benchmark score than Qwen-2.5-14B-Instruct on SimpleQA, and we intentionally modified the models behavior in post-training to optimize for better user experience rather than higher benchmark score. See Figure 6 and Appendix A.1 for details. Our model excels at STEM Q&A tasks. For example, on GPQA (graduate-level STEM questions) and MATH (math competitions), it even outscores its teacher model, GPT-4o. It also scores higher at coding, as measured by HumanEval and HumanEval+, than any other open-weight model we benchmark against, including much larger Llama models. phi-4s weakest benchmark scores are on SimpleQA, DROP, and IFEval. We believe for the first two that the number reported by simple-evals is reductive and does not accurately reflect model performance on the benchmark problems. However, IFEval reveals real weakness of our model it has trouble strictly following instructions. While strict instruction following was not an emphasis of our synthetic data generations for this model, we are confident that phi-4s instruction-following performance could be significantly improved with targeted synthetic data.', 'summary': '<p>В таблице 1 представлены результаты тестирования модели phi-4 на различных бенчмарках, а также сравнение с другими моделями. В качестве бенчмарков использовались:</p>\n<ul>\n<li><strong>OpenAI simple-evals:</strong> Это фреймворк для оценки моделей на задачах MMLU, GPQA, MATH, HumanEval, MGSM и SimpleQA (с использованием F1-меры). Фреймворк включает в себя готовые промпты, температуру и методы извлечения ответов.</li>\n<li><strong>MMLU-pro, HumanEval+, ArenaHard и IFEval:</strong> Для этих бенчмарков использовался внутренний фреймворк с собственными промптами и методами извлечения.</li>\n<li><strong>PhiBench:</strong> Это внутренний набор тестов, разработанный авторами статьи.</li>\n</ul>\n<p>Результаты показали, что phi-4 превосходит ближайшую по размеру модель Qwen-2.5-14B-Instruct на 9 из 12 бенчмарков. Несмотря на то, что phi-4 показала более низкие результаты на SimpleQA, DROP и IFEval, авторы считают, что поведение phi-4 на SimpleQA фактически лучше, чем у Qwen. Базовая модель phi-4 даже показала более высокий результат на SimpleQA, чем Qwen-2.5-14B-Instruct, но в процессе дообучения поведение модели было изменено для улучшения пользовательского опыта, а не для повышения оценки на бенчмарке. Подробности можно найти на рисунке 6 и в приложении A.1.</p>\n<p>Модель phi-4 особенно хорошо справляется с задачами STEM Q&amp;A (вопросы и ответы в области науки, технологий, инженерии и математики). Например, на GPQA (вопросы STEM уровня магистратуры) и MATH (математические соревнования) она даже превосходит свою обучающую модель GPT-4o. Phi-4 также показывает более высокие результаты в программировании (HumanEval и HumanEval+) по сравнению с другими открытыми моделями, включая более крупные модели Llama.</p>\n<p>Самые слабые результаты phi-4 показала на бенчмарках SimpleQA, DROP и IFEval. Авторы считают, что оценка SimpleQA, полученная с помощью simple-evals, является заниженной и неточно отражает производительность модели. Однако IFEval выявил реальную слабость модели – проблемы со строгим следованием инструкциям. Хотя строгое следование инструкциям не было приоритетом при генерации синтетических данных для этой модели, авторы уверены, что производительность phi-4 в этой области может быть значительно улучшена с помощью целенаправленных синтетических данных.</p>'}, {'title': 'Safety', 'content': 'We developed phi-4 in accordance with Microsofts Responsible AI principles. Our overall approach to RAI consisted of safety alignment in post-training, red-teaming, and automated testing and evaluations across dozens of RAI harm categories. We leveraged helpfulness and harmlessness preference datasets 18 phi-3 (3B-4K) phi-3 (7B-8K) phi-3 (14B-4K) Mistral (7B-v0.1) Mistral (7B-v0.2) Llama-3 (8B) Gemma (7B) phi-4 Grounding 4. 4.701 4.787 4.065 4.692 4.672 4. 4.619 3P Content Harms (DR1) Books, News, Recipes, Songs 0.251 0.253 0.26 0.562 0. 0.373 0.383 0.121 Harmful Content Continuation (DR3) Harmful Content Summarization (DR3) Jailbreak(DR1) Hate/Fairness, Self-Harm, Sexual, Violence 0.007 0.003 0.01 0.026 0. 0.013 0.013 0.036 Hate/Fairness, Self-Harm, Sexual, Violence 0.105 0. 0.112 0.223 0.16 0.082 0.103 0. See text for covered topics 0.117 0.107 0.111 0.156 0. 0.13 0.114 0.073 Table 10: Performance comparison across models. Lower scores are better, except for Grounding, where higher score is better. phi-4 values are bold for readability. [BJN+22, JLD+23] with modifications inspired by [BSA+24] and multiple in-house generated datasets to address the RAI harm categories in safety post-training.', 'summary': '<p>В процессе разработки модели phi-4 мы придерживались принципов ответственного искусственного интеллекта (RAI) Microsoft. Наш подход к RAI включал в себя несколько этапов: выравнивание безопасности после обучения, тестирование "красной командой" (имитация атак) и автоматизированное тестирование и оценка по десяткам категорий вреда RAI.</p>\n<p>Для обучения безопасности мы использовали наборы данных, содержащие примеры предпочтений в отношении полезности и безвредности, основываясь на наборах данных, использованных в моделях phi-3 (3B-4K, 7B-8K, 14B-4K). Мы также использовали данные из моделей Mistral (7B-v0.1, 7B-v0.2), Llama-3 (8B), Gemma (7B). Кроме того, мы применили модификации, вдохновленные работой [BSA+24], и использовали собственные наборы данных для решения проблем, связанных с категориями вреда RAI, в процессе обучения безопасности после основной тренировки.</p>\n<p>В таблице 10 представлены сравнительные результаты производительности различных моделей, включая phi-4. Оценка "Grounding" (способность модели обосновывать свои ответы) является исключением, где более высокий показатель лучше, а для всех остальных показателей более низкий балл считается лучше. Показатели phi-4 выделены жирным шрифтом для наглядности.</p>\n<p>В таблице приводятся результаты по следующим категориям:\n*   <strong>Grounding:</strong> Способность модели обосновывать свои ответы.\n*   <strong>3P Content Harms (DR1):</strong> Вред, связанный с контентом третьих сторон, включая книги, новости, рецепты и песни.\n*   <strong>Harmful Content Continuation (DR3):</strong> Продолжение вредоносного контента.\n*   <strong>Harmful Content Summarization (DR3):</strong> Создание вредоносных резюме.\n*   <strong>Jailbreak (DR1):</strong> Устойчивость модели к обходу ограничений безопасности.</p>\n<p>Вред оценивался по следующим категориям: ненависть/справедливость, причинение вреда себе, сексуальный контент и насилие. В таблице видно, что phi-4 демонстрирует хорошие результаты по большинству показателей, особенно в плане снижения вредоносного контента.</p>'}, {'title': 'RAI Benchmarks', 'content': 'Table 10 shows the results of in-house RAI benchmarks [MHJ+23] for phi-4 compared to the phi-3 models [AAA+24], Mistral-7b-v0.1 [JSM+23], Mistral-7b-v0.2, Gemma 7b [TMH+24], and Llama-3-instruct8b [AI23b]. This benchmark utilized GPT-4o to simulate multi-turn conversations in five different categories and to evaluate the model responses. Grounding is scored between 0 (not grounded) and 5 (fully grounded), and measures if the information in response is based on given prompt. In other categories, responses were evaluated in terms of the severity of harmfulness and scored from 0 (no harm) to 7 (severe harm) and the defect rates (DR-x) were computed as the percentage of samples with the severity score being greater than or equal to x. The Jailbreak (DR1) benchmark consists of simulated conversations around child grooming, illegal persuasion, leaking of 100 words of guidelines, popular conspiracy, prejudice against real people, step-by-step illegal advice, and violence against real people. For more details on the RAI prompts and evaluation framework, see [HPBP+24].', 'summary': '<p>В таблице 10 представлены результаты внутреннего тестирования моделей phi-4 по сравнению с моделями phi-3, Mistral-7b-v0.1, Mistral-7b-v0.2, Gemma 7b и Llama-3-instruct8b. Для этого тестирования использовался GPT-4o, который имитировал многоходовые диалоги в пяти различных категориях и оценивал ответы моделей. </p>\n<p>Оценка "заземления" (grounding) показывает, насколько информация в ответе основана на предоставленном запросе. Она варьируется от 0 (не заземлено) до 5 (полностью заземлено). В других категориях ответы оценивались по степени вредоносности (от 0 - нет вреда, до 7 - серьезный вред). Также были рассчитаны показатели дефектности (DR-x), которые представляют собой процент образцов, где оценка вредоносности равна или превышает значение x.</p>\n<p>Тест "Jailbreak" (DR1) включал имитацию разговоров на темы, связанные с совращением детей, незаконным убеждением, утечкой 100 слов из инструкций, популярными теориями заговора, предрассудками против реальных людей, пошаговыми незаконными советами и насилием против реальных людей. Более подробную информацию о запросах и системе оценки можно найти в работе [HPBP+24].</p>'}, {'title': 'Red Teaming', 'content': 'In addition to RAI benchmarking, we collaborated with the Microsoft AI Red Team (AIRT), an independent group tasked with identifying safety and security vulnerabilities in Microsofts GenAI products. AIRT conducted two-week red-teaming exercise that tested phi-4 for risky behaviors by emulating both average and adversarial users in single and multi-turn scenarios. Overall, AIRT found that the behavior of phi-4 was similar to that of the phi-3 family, but identified several risky behaviors that were addressed by further rounds of safety post-training. In addition, the adversarial user scenario tested wide range of techniques aimed at intentionally subverting the models safety training including jailbreaks, prompt encodings, and multi-turn attacks. phi-4 showed strong defenses against these techniques. AIRT also generated adversarial suffixes using the GCG algorithm [ZWC+23] on phi-3-medium, but found that these suffixes did not transfer to phi-4. Further red teaming is required to identify possible risks across broader range of scenarios and harm categories.', 'summary': '<p>В дополнение к сравнительному анализу RAI (ответственного искусственного интеллекта), мы сотрудничали с Microsoft AI Red Team (AIRT), независимой группой, задачей которой является выявление уязвимостей в безопасности и защите продуктов Microsoft GenAI. AIRT провела двухнедельное тестирование phi-4, имитируя поведение как обычных, так и злонамеренных пользователей в однократных и многократных сценариях, чтобы выявить рискованное поведение. В целом, AIRT обнаружила, что поведение phi-4 аналогично поведению семейства phi-3, но выявила несколько рискованных ситуаций, которые были устранены в ходе дальнейшего обучения модели после её создания.</p>\n<p>Кроме того, сценарий с злонамеренным пользователем тестировал широкий спектр техник, направленных на преднамеренное обхождение обучения модели безопасности, включая "побеги из тюрьмы" (jailbreaks), кодирование запросов и многоходовые атаки. Phi-4 продемонстрировала сильную защиту от этих техник. AIRT также сгенерировала вредоносные суффиксы с использованием алгоритма GCG на phi-3-medium, но обнаружила, что эти суффиксы не переносятся на phi-4. Требуется дальнейшее тестирование, чтобы выявить возможные риски в более широком диапазоне сценариев и категорий ущерба.</p>\n<p><em>Комментарий: "Побег из тюрьмы" (jailbreak) - это техника, при которой пользователь пытается заставить модель сгенерировать ответ, который она обычно не должна давать, например, вредоносный или оскорбительный контент.</em></p>'}, {'title': 'Weaknesses', 'content': 'While phi-4 achieves similar level of language understanding and reasoning ability as much larger models, it is still fundamentally limited by its size for certain tasks, specifically in hallucinations around factual knowledge. For example, if is plausible human name, the model sometimes responds to prompts of the form Who is X? with hallucinated biography of the person X. This limitation would be improved by augmenting the model with search engine, but factual hallucinations cannot be eliminated completely. While phi-4 demonstrates relatively strong performance in answering questions and performing reasoning tasks, it is less proficient at rigorously following detailed instructions, particularly those involving specific formatting requirements. For instance, when tasked with generating outputs in strict tabular formats, adhering to predefined bullet structures, or precisely matching stylistic constraints, the model may produce outputs that deviate from the specified guidelines. This limitation arises in part from the models training focus, which prioritized synthetic datasets tailored toward Q&A and reasoning tasks over instruction-following scenarios. Even on reasoning tasks, phi-4 can make mistakes. For example, when asked which number is smaller, 9.9 or 9.11?, the model can conclude incorrectly that 9.9 is smaller than 9.11. Moreover, as our data contains lot of chain-of-thought examples, phi-4 sometimes gives long elaborate answers even for simple problemsthis might make user interactions tedious. We also note that while phi-4 can function as chat bot, it has been fine-tuned to maximize performance on single-turn queries. Despite diligent RAI efforts, we acknowledge challenges around reproduction or amplification of biases, inappropriate content generation, and safety issues. The use of carefully curated training data, as well as targeted post-training, and improvements from red-teaming insights, have resulted in mitigating these issues across all dimensions, but have not resolved the issues completely.', 'summary': '<p>Модель phi-4, хотя и демонстрирует уровень понимания языка и рассуждений, сравнимый с гораздо более крупными моделями, все же имеет ограничения из-за своего размера. Это особенно проявляется в склонности к галлюцинациям, когда дело касается фактических знаний. Например, если в запросе фигурирует правдоподобное человеческое имя, модель может выдать вымышленную биографию этого человека. Улучшить ситуацию можно, подключив к модели поисковую систему, но полностью исключить галлюцинации не удастся.</p>\n<p>Также, несмотря на хорошие результаты в ответах на вопросы и решении задач на рассуждение, phi-4 хуже справляется с четким следованием подробным инструкциям, особенно если они касаются форматирования. Например, при генерации таблиц, списков с заданными маркерами или соблюдении стилистических требований, модель может отклоняться от заданных правил. Это связано с тем, что при обучении приоритет отдавался синтетическим данным, ориентированным на вопросы и ответы и задачи на рассуждение, а не на следование инструкциям.</p>\n<p>Даже в задачах на рассуждение phi-4 может допускать ошибки. Например, при сравнении чисел 9.9 и 9.11 модель может ошибочно заключить, что 9.9 меньше, чем 9.11. Кроме того, из-за большого количества примеров рассуждений в обучающих данных, phi-4 иногда дает слишком длинные и подробные ответы даже на простые вопросы, что может утомлять пользователей.</p>\n<p>Также стоит отметить, что хотя phi-4 может работать как чат-бот, она была дообучена для максимизации производительности в одноходовых запросах.</p>\n<p>Несмотря на усилия по ответственному использованию искусственного интеллекта, мы признаем наличие проблем, связанных с воспроизведением или усилением предвзятостей, генерацией неприемлемого контента и вопросами безопасности. Использование тщательно отобранных обучающих данных, целенаправленное дообучение и улучшения, основанные на результатах тестирования, позволили снизить остроту этих проблем, но не устранили их полностью.</p>'}]}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents', '#agi', '#alignment', '#architecture (1)', '#audio', '#benchmark (1)', '#cv', '#data (1)', '#dataset', '#diffusion', '#ethics', '#games', '#graphs', '#hallucinations', '#healthcare', '#inference', '#interpretability', '#leakage', '#long_context', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal', '#open_source', '#optimization', '#plp', '#rag', '#reasoning (1)', '#rl', '#rlhf', '#robotics', '#science', '#security', '#small_models', '#story_generation', '#survey', '#synthetic (1)', '#training (1)', '#transfer_learning', '#video'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            
            <div class="summaries">
                <div class="summary_title">Abstract</div>
                <div class="summary_text"><p>В этой статье представлен phi-4, языковая модель с 14 миллиардами параметров. Главная особенность phi-4 – это подход к обучению, в котором ключевую роль играет качество данных. В отличие от большинства языковых моделей, которые обучаются на "органических" данных, таких как веб-контент или код, phi-4 активно использует синтетические данные на протяжении всего процесса обучения.</p>
<p>Предыдущие модели семейства Phi в основном "перенимали" способности у модели-учителя (GPT-4). Однако phi-4 значительно превосходит своего учителя в решении задач, связанных с точными науками (STEM), что свидетельствует о том, что методы генерации данных и постобработки выходят за рамки простого "перенимания" знаний.</p>
<p>Несмотря на минимальные изменения в архитектуре по сравнению с phi-3, phi-4 демонстрирует высокую производительность относительно своего размера, особенно в задачах, требующих рассуждений. Это достигается благодаря улучшению качества данных, учебной программы и инновациям в схеме постобработки.</p>
<p><em>Комментарий: Авторы подчеркивают, что phi-4 не просто "скопировал" способности более крупной модели, а действительно улучшил их за счет более продуманного подхода к данным и обучению.</em></p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Introduction</div>
                <div class="summary_text"><p>В статье описывается модель phi-4, которая является развитием семейства моделей Phi и демонстрирует значительное улучшение производительности малых языковых моделей. Ключевым фактором успеха phi-4 является инновационный подход к созданию синтетических данных, а также оптимизация процесса обучения и пост-тренинга.</p>
<p><strong>Основные принципы разработки phi-4:</strong></p>
<ol>
<li>
<p><strong>Синтетические данные для предварительного и промежуточного обучения:</strong> Основная часть обучающих данных phi-4 состоит из синтетических данных, сгенерированных с использованием различных методов, таких как многоагентное подсказывание (multi-agent prompting), рабочие процессы саморедактирования (self-revision workflows) и обращение инструкций (instruction reversal). Эти методы позволяют создавать наборы данных, которые способствуют развитию способностей к рассуждению и решению проблем. В процессе обучения также используются новые стратегии смешивания данных, которые увеличивают долю синтетических токенов по сравнению с предыдущими поколениями Phi.</p>
</li>
<li>
<p><strong>Отбор и фильтрация высококачественных органических данных:</strong> Для создания основы для синтетических данных, используются тщательно отобранные и отфильтрованные органические данные, включая веб-контент, лицензированные книги и репозитории кода. Эти данные служат "затравкой" для генерации синтетических данных, которые направлены на развитие глубокого мышления и обладают образовательной ценностью для модели. Кроме того, веб-контент также фильтруется для поиска высококачественных данных (с точки зрения знаний и рассуждений), которые используются непосредственно в предварительном обучении.</p>
</li>
<li>
<p><strong>Пост-тренинг:</strong> В phi-4 усовершенствован процесс пост-тренинга путем создания новых версий SFT (Supervised Fine-Tuning) наборов данных, а также разработки новых методов создания пар для DPO (Direct Preference Optimization), основанных на поиске ключевых токенов. Эти инновации позволяют повысить качество выходных данных модели.</p>
</li>
</ol>
<p>Благодаря этим нововведениям phi-4 демонстрирует производительность, сравнимую или превосходящую гораздо более крупные модели в задачах, связанных с рассуждением. Например, на многих широко используемых тестах, связанных с рассуждением, производительность phi-4 соответствует или превосходит производительность Llama-3.1-405B. В таблице 1 показано сравнение производительности phi-4 с другими современными моделями на стандартных академических тестах. При этом phi-4 значительно превосходит своего "учителя" GPT-4o на тестах GPQA (вопросы и ответы по STEM на уровне выпускников) и MATH (математические соревнования).</p>
<p>В заключение, статья подчеркивает, что качество данных играет ключевую роль в обучении языковых моделей, и что инновационные методы генерации синтетических данных могут привести к значительным улучшениям производительности, сравнимым с увеличением вычислительных мощностей.</p></div>
                <div class="images"><img class="summary_image" src='https://arxiv.org/html/2412.08905/x1.png'/></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Addressing Overfitting and Data Contamination</div>
                <div class="summary_text"><p>В статье рассматриваются важные аспекты обучения и оценки больших языковых моделей (LLM), а именно:</p>
<p><strong>1. Очистка данных от "загрязнения" (Decontamination):</strong></p>
<p>Одной из проблем при обучении LLM является переобучение на тестовых наборах данных. Это происходит, когда данные из тестовых наборов случайно "просачиваются" в обучающий корпус, например, через веб-корпус. Чтобы избежать этого, для модели phi-4 был усовершенствован процесс очистки данных по сравнению с предыдущими моделями Phi. Это гарантирует, что результаты оценки модели не будут искажены "загрязнением" данными. Подробности метода очистки приведены в Приложении B.</p>
<p><strong>2. Бенчмарк AMC (American Mathematics Competitions):</strong></p>
<p>Чтобы убедиться в отсутствии переобучения, модель протестировали на новых данных, а именно на математических конкурсах AMC-10 и AMC-12, которые проводились в ноябре 2024 года, после завершения сбора обучающих данных. Производительность модели измерялась только после выбора всех гиперпараметров. Эти конкурсы являются отборочными этапами для математической олимпиады в США, и в них ежегодно участвуют более 150 000 школьников. На графике (Рисунок 1) показан средний балл по четырем вариантам теста, максимальный балл в каждом из которых равен 150. phi-4 превосходит не только модели аналогичного размера или с открытыми весами, но и гораздо более крупные модели. Такие высокие результаты на новых тестовых данных говорят о том, что производительность phi-4 на бенчмарке MATH не является следствием переобучения или "загрязнения" данными. Дополнительные детали приведены в Приложении C.</p>
<p><strong>3. Использование бенчмарков, защищенных от "загрязнения":</strong></p>
<p>В статье также подчеркивается важность бенчмарков, разработанных таким образом, чтобы вопросы были оригинальными и не встречались в интернете, например, GPQA. При оптимизации модели также использовался внутренний бенчмарк, состоящий в основном из оригинальных запросов, написанных командой разработчиков (подробности в Разделе 5).</p>
<p><strong>4. Модели с длинной цепочкой рассуждений (Long Chain-of-Thought Models):</strong></p>
<p>В последнее время появились LLM, которые масштабируют вычислительные ресурсы во время вывода, генерируя длинные цепочки рассуждений. Эти модели, такие как OpenAI O1, DeepSeek-R1-Lite-Preview и Qwen/QwQ-32B-Preview, показывают хорошие результаты на бенчмарках, проверяющих способность к рассуждению. QwQ, единственная модель с открытыми весами в этой группе, набирает в среднем 124,5 балла в тесте AMC-10/12. Однако QwQ использует в 4 раза больше токенов и имеет более чем в два раза больше параметров, чем phi-4. Следовательно, вычислительные затраты на вывод QwQ на порядок выше, чем у phi-4. Таким образом, эти модели не относятся к тому же классу, что и phi-4, с точки зрения стоимости или задержки.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Purpose of Synthetic Data</div>
                <div class="summary_text"><h2>Преимущества синтетических данных в предварительном обучении языковых моделей</h2>
<p>В последнее время синтетические данные становятся всё более важным компонентом предварительного обучения языковых моделей, и серия моделей Phi наглядно демонстрирует это. Синтетические данные не просто дешёвая замена "органическим" данным, они обладают рядом прямых преимуществ.</p>
<p><strong>Структурированное и постепенное обучение.</strong> В органических наборах данных связи между токенами часто сложны и непрямы. Модели может потребоваться выполнить множество логических шагов, чтобы связать текущий токен со следующим, что затрудняет эффективное обучение на основе предсказания следующего токена. В отличие от этого, каждый токен, сгенерированный языковой моделью, по определению предсказывается предыдущими токенами. Это облегчает модели отслеживание получаемых логических цепочек. Таким образом, синтетические данные можно рассматривать как своего рода "кормление с ложечки", когда сложные задачи представляются в доступной и ориентированной на прогресс форме. Простой пример: решение математической задачи, написанное человеком, может начинаться с окончательного ответа. Этот ответ слишком сложен для немедленного вывода как человеком, так и LLM. Человек получил его путем нелинейного редактирования, но предварительное обучение предполагает, что LLM научится выдавать его линейно. Синтетические решения математических задач не будут иметь таких препятствий.</p>
<p><strong>Соответствие контекстам вывода.</strong> Синтетические данные обычно ближе к формату выходных данных, которые мы ожидаем от наших моделей. Обучение на таких данных помогает согласовать опыт предварительного обучения модели со сценариями, с которыми она сталкивается во время вывода. Это гарантирует, что контекст, наблюдаемый во время генерации, остаётся в пределах распределения данных, на которых модель была предварительно обучена. Например, веб-форумы сильно отличаются по стилю от взаимодействия с LLM. Если какой-либо факт встречается только в данных веб-форумов, предварительно обученная модель будет считать, что он маловероятен в чатах, которые она генерирует. Переписывание фактов с веб-форума на языковой стиль LLM делает факты более доступными в контексте чата LLM во время вывода.</p>
<p><strong>Принципы генерации синтетических данных для phi-4.</strong> Наш подход к генерации синтетических данных для phi-4 основывается на следующих принципах:</p>
<ol>
<li><strong>Разнообразие:</strong> Данные должны всесторонне охватывать подтемы и навыки в каждой области. Это требует подбора разнообразных "семян" из органических источников.</li>
<li><strong>Нюансы и сложность:</strong> Эффективное обучение требует нюансированных, нетривиальных примеров, отражающих сложность и богатство предметной области. Данные должны выходить за рамки основ и включать пограничные случаи и продвинутые примеры.</li>
<li><strong>Точность:</strong> Код должен выполняться правильно, доказательства должны быть обоснованными, а объяснения должны соответствовать общепринятым знаниям и т.д.</li>
<li><strong>Цепочка рассуждений:</strong> Данные должны поощрять систематическое рассуждение, обучая модель различным подходам к решению проблем шаг за шагом. Это способствует формированию связных выходных данных для сложных задач.</li>
</ol></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Synthetic Data for Pretraining and Midtraining</div>
                <div class="summary_text"><p>В статье описывается процесс создания синтетических данных для обучения модели phi-4. Было сгенерировано 50 различных типов синтетических наборов данных, охватывающих широкий спектр тем, навыков и типов взаимодействия, общим объемом около 400 миллиардов токенов.</p>
<p><strong>Курирование исходных данных:</strong> Процесс начинается с отбора высококачественных исходных данных из разных источников. Эти данные служат основой для генерации синтетических примеров, включая упражнения, дискуссии и задачи на рассуждение, которые соответствуют целям обучения модели.</p>
<ol>
<li><strong>Исходные данные из интернета и кода:</strong> Использовались фрагменты веб-страниц, книг и репозиториев кода, с акцентом на материалы, демонстрирующие сложность, глубину рассуждений и образовательную ценность. Для обеспечения качества применялся двухэтапный процесс фильтрации: сначала определялись страницы с высоким образовательным потенциалом, а затем выбранные страницы разделялись на фрагменты, каждый из которых оценивался на предмет фактического содержания и глубины рассуждений.</li>
<li><strong>Наборы вопросов:</strong> Была собрана большая коллекция вопросов с веб-сайтов, форумов и платформ вопросов и ответов. Эти вопросы были отфильтрованы с использованием метода на основе множественности ответов для балансировки сложности. Для каждого вопроса генерировалось несколько независимых ответов, и применялось голосование большинством для оценки согласованности ответов. Вопросы, на которые все ответы были одинаковыми (слишком легкие) или полностью противоречивыми (слишком сложные или неоднозначные), отбрасывались. В результате получился набор вопросов, которые бросают вызов способностям модели к рассуждению и решению проблем, оставаясь при этом доступными. Множественные ответы использовались вместо "истинных" ответов при генерации данных на основе отклонения.</li>
<li><strong>Создание пар "вопрос-ответ" из разных источников:</strong> Для отбора исходных данных также использовались языковые модели для извлечения пар "вопрос-ответ" из книг, научных статей и кода. Этот подход не просто ищет явные пары "вопрос-ответ" в тексте. Вместо этого языковая модель выявляет цепочки умозаключений или логические последовательности в тексте. Модель определяет ключевые шаги в процессе рассуждения или решения проблем и переформулирует их в вопросы и соответствующие ответы. Эксперименты показали, что обучение на таком контенте может быть более эффективным (с точки зрения улучшения результатов на академических и внутренних тестах), чем обучение на исходном контенте.</li>
</ol>
<p><strong>Переписывание и расширение:</strong> Исходные данные преобразуются в синтетические с помощью многоступенчатых подсказок. Это включает переписывание большей части полезного контента в упражнения, дискуссии или структурированные задачи на рассуждение.</p>
<p><strong>Саморедактирование:</strong> Первоначальные ответы затем итеративно улучшаются с помощью цикла обратной связи, в котором модель критикует и улучшает свои собственные результаты, опираясь на критерии, ориентированные на рассуждения и точность фактов.</p>
<p><strong>Обращение инструкций для кода и других задач:</strong> Для улучшения способности модели генерировать ответы на основе инструкций использовался метод обращения инструкций. Например, существующие фрагменты кода из корпуса данных кода использовались для генерации соответствующих инструкций, включающих описание проблемы или запрос задачи. Полученные пары синтетических данных были структурированы так, чтобы инструкция предшествовала коду. Сохранялись только данные с высокой точностью соответствия между исходным и регенерированным кодом, что гарантировало соответствие между инструкциями и ответами. Этот метод может быть обобщен на другие целевые варианты использования.</p>
<p><strong>Проверка кода и других научных данных:</strong> Когда это уместно, в синтетические наборы данных включаются тесты для проверки. Синтетические данные кода проверяются посредством циклов выполнения и тестов. Для научных наборов данных вопросы извлекаются из научных материалов с использованием метода, обеспечивающего высокую релевантность, обоснованность и сбалансированную сложность.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Curation and Filtering of Web and Q&A Data</div>
                <div class="summary_text"><p><strong>Наборы данных "вопрос-ответ" и высококачественные веб-данные</strong></p>
<p>Для обучения модели были собраны десятки миллионов высококачественных вопросов и ответов, полученных из открытых веб-сайтов, существующих наборов данных и внешних источников. Опыт предыдущих моделей показал, что данные типа "вопрос-ответ" значительно улучшают различные возможности, такие как математическое мышление и академическая успеваемость. Исследования показали, что "органические" вопросы (то есть, вопросы, созданные людьми, а не сгенерированные) гораздо эффективнее синтетических. Для увеличения объема данных использовались различные методы синтетического расширения набора органических вопросов. Хотя эти перефразированные вопросы и улучшили возможности моделей, прирост был не таким значительным. Значительная часть собранных вопросов не имела точных ответов, поэтому ответы были заменены на синтетически сгенерированные, а для повышения точности использовалось голосование большинством. Все собранные вопросы и решения прошли тщательную очистку, чтобы исключить любое пересечение с тестовыми наборами.</p>
<p>Для обучения модели также был собран широкий спектр высококачественных органических данных, причем приоритет отдавался материалам, требующим рассуждений и содержащим нюансы (например, научные статьи, образовательные форумы и учебники по программированию). Веб-источники использовались не только для обучения модели, но и в качестве основы для специализированных конвейеров синтетической генерации данных. Было обнаружено, что чистые и корректные естественные данные крайне важны для запуска синтетических данных: даже незначительные ошибки могут привести к серьезному ухудшению качества производных синтетических документов. Поэтому значительные усилия были вложены в тщательную курацию веб-данных.</p>
<p>Процесс сбора и обработки данных включал следующие этапы:</p>
<ul>
<li><strong>Целевые приобретения:</strong> Были включены крупные репозитории документов, требующих рассуждений, которые разрешены для публичного использования (например, arXiv, PubMed Central, GitHub) или лицензированы (например, лицензированные книги). Целью было достижение уровня полноты, актуальности и чистоты выше типичного стандарта общедоступных корпусов.</li>
<li><strong>Фильтрация веб-дампов:</strong> Для охвата более широкого спектра информационно насыщенных веб-источников (например, форумов, блогов, учебных материалов, тематических вики) был применен подход выбора небольшой части самых качественных документов из массовых веб-дампов. Для этого использовались небольшие классификаторы (не на основе LLM), обученные на основе аннотаций, сгенерированных LLM. Этот подход, как правило, переиндексирует STEM-связанные ключевые слова, поэтому был создан специализированный конвейер для усиления высококачественного контента не-STEM тематики (например, искусства, истории, путешествий, культуры и развлечений). Эти тематические классификации также были получены путем дистилляции LLM-аннотатором. Наконец, поврежденный текст и двоичные файлы были удалены путем обнаружения выбросов по статистике n-грамм и коэффициентам сжатия.</li>
<li><strong>Многоязычные данные:</strong> Для обеспечения возможности модели обрабатывать широкий спектр языков, были включены многоязычные наборы данных, включая немецкий, испанский, французский, португальский, итальянский, хинди и японский. Это включало поиск и обработку высококачественных многоязычных документов из CommonCrawl и Wikipedia. Конвейер многоязычной обработки состоит из модели идентификации языка, основанной на fastText, используемой для классификации документов на 176 языков, а затем использует те же классификаторы для фильтрации веб-дампов для повышения качества. Важно отметить, что классификаторы были обучены на многоязычных LLM-сгенерированных аннотациях.</li>
<li><strong>Специализированные конвейеры извлечения и очистки:</strong> Для обеспечения достаточной чистоты и единообразия между разнородными органическими источниками данных потребовался набор специализированных эвристик и парсеров. Для каждого целевого источника данных были созданы индивидуальные конвейеры для приема различных форматов файлов (например, многофайловый исходный код TeX, ePub и другие XML-подобные форматы, документы Microsoft Word и PDF). Для общих веб-данных был создан собственный экстрактор HTML-в-текст, который уделяет особое внимание сохранению "хрупкого" контента, который часто повреждается простыми парсерами (например, уравнения TeX/MathML, блоки кода, таблицы и структура потока форума). Этот экстрактор обрезает и нормализует дерево DOM, используя различные сигналы (например, имена HTML-тегов, классы CSS, длину содержимого и глубину дерева) для различения таких элементов, как шаблонный текст, реклама, уравнения и артефакты подсветки синтаксиса.</li>
</ul></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Pretraining Details</div>
                <div class="summary_text"><p>Модель phi-4 основана на архитектуре transformer только с декодером, она имеет 14 миллиардов параметров и стандартную длину контекста в 4096 токенов. В процессе обучения длина контекста была увеличена до 16 тысяч токенов. Архитектура модели очень похожа на phi-3-medium, за исключением нескольких ключевых изменений. Во-первых, в phi-4 используется токенизатор tiktoken, который обеспечивает лучшую поддержку многоязычности. Размер словаря токенизатора составляет 100 352, включая неиспользуемые токены. Во-вторых, в phi-4 используется полноценное внимание (full attention) ко всей длине контекста в 4096 токенов, в то время как в phi-3-medium применялось скользящее окно размером 2048 токенов.</p>
<p>Модель phi-4 была предварительно обучена на примерно 10 триллионах токенов. При обучении использовались линейные графики нарастания и спада скорости обучения, с пиковым значением 0.0003, постоянным весовым распадом 0.1 и глобальным размером батча 5760. Гиперпараметры обучения были настроены с использованием интерполяции результатов более коротких запусков и дополнительно скорректированы путем стресс-тестирования этапа нарастания скорости обучения для обеспечения стабильности. После предварительного обучения был проведен более короткий этап дообучения, чтобы увеличить исходную длину контекста с 4 тысяч до 16 тысяч токенов.</p>
<p>Поскольку предварительно обученные модели плохо справляются с выполнением инструкций, использование оценок "0-shot", требующих ответа в определенном формате, например, simple-evals, не является информативным. Поэтому для оценки предварительного обучения использовалась внутренняя реализация бенчмарков, которая применяет смесь логарифмического правдоподобия и/или few-shot подсказок для разных задач. Конкретно, для MMLU (5-shot), MMLU-pro и ARCC (1-shot) использовались оценки логарифмического правдоподобия. Для TriviaQA (TQA), MBPP, MATH и GSM8k применялись 1, 3, 4 и 8 few-shot примеров, чтобы помочь модели придерживаться формата ответа для упрощения извлечения решения. Этот метод оценки используется на протяжении всего раздела 3. В таблице 2 показано улучшение производительности предварительно обученной модели phi-4 по сравнению с её предшественницей, phi-3-medium.</p></div>
                <div class="images"><img class="summary_image" src='https://arxiv.org/html/2412.08905/extracted/6060244/figures/mmlu_synth_epochs.png'/></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Data Composition in Pretraining</div>
                <div class="summary_text"><p>Семейство моделей phi-3 обучалось в два этапа. На первом этапе использовалась большая часть обучающих токенов, которые в основном представляли собой отфильтрованные веб-данные. Второй этап обучения проходил на смеси данных, состоящей преимущественно из синтетических токенов, с гораздо меньшей долей ультра-отфильтрованных и ориентированных на рассуждения веб-данных.</p>
<p>По мере роста размера и сложности наших синтетических данных, мы наблюдали незначительное снижение пользы от использования несинтетических токенов для моделей phi-3. Были сделаны два ключевых наблюдения: веб-данные показали небольшую пользу на тестах, требующих рассуждений, а приоритезация большего количества эпох обучения на синтетических данных давала лучшие результаты, чем добавление новых веб-токенов.</p>
<p>Модели, обученные только на синтетических данных, показали более низкие результаты на тестах, требующих знаний, и демонстрировали усиление галлюцинаций. Рисунок 2 демонстрирует первое явление на примере небольших экспериментов по предварительному обучению на втором этапе. В этом примере для каждого размера модели проводилось два запуска обучения, используя одинаковое количество обучающих токенов поверх контрольных точек, предварительно обученных на первом этапе. Для всех запусков количество уникальных синтетических токенов было фиксированным (подвыборка полных синтетических данных), но количество повторений этих данных менялось, а именно 4 и 12 эпох. Остальные обучающие токены были новыми уникальными токенами, полученными из веб-источников. Как видно, выполнение большего количества итераций на синтетических данных более выгодно, чем предоставление большего количества веб-токенов.</p>
<p>Вдохновленные таким масштабированием наших синтетических данных, мы обучили модель с 13 миллиардами параметров исключительно на синтетических данных, при этом для целей абляции модель видела более 20 повторений каждого источника данных. Для целей абляции мы разделили наши синтетические данные на "переписанные веб-данные", которые включают более прямые переписывания нашего отфильтрованного веб-контента, относительно всех других типов синтетических данных.</p>
<p>В таблице 3 сравнивается предыдущая модель phi-3-medium с новой моделью, обученной полностью на синтетических данных. На протяжении всего обучения все тесты последовательно улучшались, несмотря на увеличение количества эпох, и большинство тестов показали улучшения по сравнению с phi-3. Однако тесты, связанные со знаниями, такие как 1-shot triviaqa (TQA), показывают большой разрыв, где синтетические модели работают хуже. Эти наблюдения заставили нас переосмыслить роль веб-данных в нашей смеси данных.</p>
<p><em>Примечание: Авторы статьи выяснили, что для обучения моделей phi-3 большее количество эпох на синтетических данных более выгодно, чем добавление новых веб-данных. Однако, модели обученные только на синтетических данных, показали более низкие результаты на тестах, требующих знаний.</em></p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Data Mixture</div>
                <div class="summary_text"><p>Для определения оптимального соотношения данных для предварительного обучения модели, мы исследовали различные комбинации токенов из разных источников. Эти источники включают: 1) синтетические данные, 2) переписанный веб-контент, 3) отфильтрованный веб (разделенный на части, ориентированные на рассуждения и знания), 4) целевые и органические данные (например, академические работы, книги и форумы) и 5) данные кода.</p>
<p>Для определения оптимального соотношения мы провели эксперименты с меньшим объемом токенов (1 триллион). Это было возможно благодаря тому, что мы ранее установили высокую корреляцию между результатами обучения на коротких и длинных периодах, вплоть до насыщения переобучением. Кроме того, мы заметили высокую корреляцию между производительностью моделей с 7 и 14 миллиардами параметров при использовании разных наборов данных, если эти наборы достаточно отличаются. Это позволило нам проводить эксперименты на модели с 7 миллиардами параметров и переносить результаты на модель phi-4.</p>
<p>Среди множества экспериментов, мы выделили несколько, которые дали наиболее ценные сведения о составе данных. В частности, мы зафиксировали соотношение токенов из целевых приобретений и кода, а затем изменяли соотношение токенов для синтетических данных, веб-данных и переписанного веб-контента.</p>
<p>Таблица 4 показывает результаты этих экспериментов по сравнению с окончательным набором данных, использованным для обучения. Равномерное распределение токенов между тремя категориями оказалось неоптимальным из-за более высокого качества синтетических данных. Единственный тест, где веб-данные показали явное преимущество, — это TQA. Хотя варианты с преобладанием синтетических данных (строки 2 и 3 таблицы) были незначительно лучше, чем финальный набор, мы решили включить целевые и ориентированные на знания веб-данные, чтобы улучшить результаты на тестах, связанных со знаниями, и сбалансировать возможности модели. Важно отметить, что разница между выбранным и синтетическим наборами данных уменьшается по мере прохождения модели этапа постобработки. Оптимизация набора данных для предварительного обучения с учетом эффектов постобработки является интересной темой для будущих исследований.</p>
<p>Финальный набор данных для предварительного обучения модели phi-4 распределяет 30% токенов между веб-данными и переписанным веб-контентом (поровну). Остальные токены в основном поступают из синтетических данных (40%). Также 20% токенов выделено для данных кода (смесь синтетического и исходного кода) и 10% для целевых данных (академические работы и книги).</p>
<p>По количеству уникальных токенов отфильтрованные веб-данные являются самым большим кластером (1.3 триллиона токенов). Код и целевые данные занимают второе и третье места (820 и 580 миллиардов токенов соответственно). Переписанный веб-контент и синтетические данные имеют примерно одинаковое количество токенов (290 миллиардов). Количество эпох обучения для каждого источника определяется соотношением выделенных токенов и общего количества уникальных токенов в этом источнике.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Midtraining Details</div>
                <div class="summary_text"><p><strong>Увеличение длины контекста и обучение phi-4</strong></p>
<p>В процессе обучения модели phi-4 был добавлен этап, на котором длина контекста была увеличена с исходных 4K токенов до 16K токенов. Чтобы изучить влияние данных на производительность модели при работе с длинным контекстом, были проведены эксперименты с различными источниками данных. Использовались как данные, изначально имеющие длинный контекст, так и искусственно созданные данные, где короткие фрагменты были объединены для заполнения длинной последовательности. Результаты показали, что данные, изначально имеющие длинный контекст, лучше подходят для задач, требующих обработки длинных последовательностей.</p>
<p>Основываясь на этих наблюдениях, высококачественные несинтетические наборы данных (академические тексты, книги и код) были отфильтрованы, чтобы выделить фрагменты длиной более 8K токенов. Затем подмножества данных длиной 16K и более были усилены. Кроме того, были созданы новые синтетические наборы данных, соответствующие требованию длины последовательности &gt; 4K. В итоговой смеси данных 30% занимали недавно собранные данные с длинным контекстом, а 70% - данные, использовавшиеся на этапе предварительного обучения.</p>
<p>Для обработки более длинного контекста базовая частота позиционного кодирования RoPE была увеличена до 250K. Скорость обучения была снижена в 10 раз по сравнению с этапом предварительного обучения, а общее количество обученных токенов составило 250 миллиардов.</p>
<p><strong>Оценка производительности на длинном контексте</strong></p>
<p>Для оценки способности модели работать с длинным контекстом был использован комплексный набор задач, отражающих реальные сценарии. Хотя синтетические тесты, такие как "иголка в стоге сена", просты и удобны для контроля, основное внимание уделялось разнообразным задачам, имитирующим реальные приложения, например, рассуждение на основе целых документов. Производительность phi-4 и других моделей оценивалась на задачах, выбранных из набора HELMET.</p>
<p>Оценка проводилась по следующим задачам:</p>
<ul>
<li><strong>Recall:</strong> извлечение значения из длинного JSON-файла по заданному ключу.</li>
<li><strong>RAG (Retrieval-Augmented Generation):</strong> ответы на вопросы на основе множества извлеченных и перемешанных документов Wikipedia.</li>
<li><strong>Re-rank:</strong> переранжирование 10 лучших документов по запросу.</li>
<li><strong>ICL (In-Context Learning):</strong> обучение с несколькими примерами на основе наборов данных TREC, Banking77, NLU и CLINC150.</li>
<li><strong>QA (Question Answering):</strong> ответы на вопросы по длинному документу.</li>
<li><strong>Summ (Summarization):</strong> обобщение длинного юридического документа.</li>
</ul>
<p>Результаты оценки представлены в таблице 6 и являются средними значениями по 5 запускам для каждой категории.</p>
<p><strong>Состав данных для обучения DPO</strong></p>
<p>В таблице 7 представлен состав данных, использованных для обучения DPO (Direct Preference Optimization) модели. Данные включают различные категории, такие как:</p>
<ul>
<li>Неизвестные данные и данные по безопасности</li>
<li>Общие вопросы и ответы с множественным выбором</li>
<li>Математические данные</li>
<li>Данные на языке Python</li>
<li>Данные на языках C++, Go, Java, JavaScript и Rust</li>
</ul>
<p>Количество примеров для каждой категории также указано в таблице.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Direct Preference Optimization</div>
                <div class="summary_text"><p>Для обучения модели с учётом предпочтений человека и для отсеивания нежелательного поведения используется метод DPO (Direct Preference Optimization). Данные для DPO включают в себя форматы чатов, рассуждения, а также данные, связанные с ответственным ИИ (RAI). Это улучшает модель в математике, кодировании, рассуждениях, устойчивости и безопасности.</p>
<p>Обучение DPO проводится в два этапа поверх модели, обученной с учителем (SFT). На первом этапе DPO используется техника Pivotal Token Search (PTS) для генерации пар желаемых и нежелаемых ответов. На втором этапе, который называется DPO с оценками, собирается около 850 тысяч пар желаемых и нежелаемых ответов. Подсказки берутся из различных открытых наборов данных для обучения с инструкциями, а также включают подсказки, связанные с безопасностью и ответственным ИИ (RAI).</p>
<p>Затем для каждой подсказки генерируются ответы от GPT-4o, GPT-4t и собственной модели. Из этих ответов создаются различные комбинации пар для DPO, и GPT-4o используется в качестве судьи для оценки каждой пары как положительной или отрицательной. Каждому ответу ассистента присваивается оценка на основе точности, стиля и детализации. Ответ с более высокой точностью или общей (средней) оценкой считается положительным. Оба этапа также включают небольшое количество данных для безопасности и снижения галлюцинаций.</p>
<p>В статье также приведён пример использования PTS, где показано, как алгоритм определяет "ключевые" токены, влияющие на успешность ответа модели. На рисунке 3 показано, как вероятность успеха ответа меняется в зависимости от токена, а также выделены токены, которые значительно влияют на эту вероятность. Рисунок 4 представляет псевдокод алгоритма PTS.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Pivotal Token Search</div>
                <div class="summary_text"><p>В этом разделе описывается метод Pivotal Token Search (PTS), который нацелен на улучшение обучения моделей путем выявления и использования ключевых токенов.</p>
<p><strong>Проблема:</strong> Модели, генерирующие текст по токенам, часто показывают, что их общая правильность зависит от небольшого числа "ключевых" токенов. Эти токены, названные "опорными" (pivotal), могут существенно влиять на ход решения. Например, в задаче по математике выбор определенного токена может привести к правильному решению, в то время как другой выбор может привести к ошибке. Проблема заключается в том, что при использовании таких решений для обучения с помощью DPO (Direct Preference Optimization), множество токенов с низкой вероятностью могут создать "шум" в градиентах, размывая сигнал от ключевых токенов. Более того, токены, приводящие к ошибке, могут получить положительный обучающий сигнал из-за своей низкой вероятности.</p>
<p><strong>Решение: Pivotal Token Search (PTS)</strong>. PTS – это метод, который нацелен на генерацию данных для обучения с учетом именно опорных токенов. Он работает следующим образом:</p>
<ol>
<li><strong>Идентификация опорных токенов:</strong> Метод анализирует последовательность токенов, сгенерированных моделью в ответ на запрос. Он рекурсивно разделяет последовательность на сегменты, пока изменение вероятности успеха (p(success)) для каждого сегмента не станет меньше заданного порога или сегмент не будет состоять из одного токена. Токены, которые вызывают резкое изменение вероятности успеха, определяются как опорные. Вероятность успеха оценивается путем выборки завершений, начиная с префикса последовательности токенов, и проверки их правильности с помощью "оракула" (например, для задач кодирования это может быть набор тестов, а для математических задач — сравнение с правильным ответом).</li>
<li><strong>Генерация данных предпочтений:</strong> Для каждого опорного токена PTS создает пару данных для DPO. Запрос — это префикс последовательности токенов до опорного токена. "Принятое" завершение — это опорный токен, который увеличивает вероятность успеха, а "отвергнутое" завершение — это токен, который уменьшает вероятность успеха. Эти токены берутся из тех же выборок, которые PTS использовал для оценки вероятности успеха.</li>
</ol>
<p><strong>Преимущества PTS:</strong></p>
<ul>
<li><strong>Целенаправленное обучение:</strong> PTS фокусируется на обучении модели на опорных токенах, которые оказывают наибольшее влияние на результат.</li>
<li><strong>Уменьшение шума:</strong> PTS уменьшает влияние "шума" от неключевых токенов, что приводит к более эффективному обучению.</li>
<li><strong>Устранение нежелательных сигналов:</strong> Метод предотвращает получение положительных обучающих сигналов токенами, которые приводят к ошибкам.</li>
<li><strong>Применимость:</strong> PTS подходит для задач, где есть возможность проверить правильность ответа (например, математика, ответы на вопросы, кодирование).</li>
</ul>
<p><strong>Ограничения:</strong></p>
<ul>
<li>Алгоритм поиска опорных токенов не всегда гарантирует нахождение всех опорных токенов, но гарантирует нахождение только опорных токенов и находит все из них, если вероятность успеха является почти монотонной на протяжении решения.</li>
</ul>
<p><strong>Улучшение эффективности:</strong> Для повышения эффективности выборки PTS фильтрует целевые вопросы, включая только те, у которых вероятность успеха находится в диапазоне от 0.2 до 0.8, поскольку опорные токены редки для очень легких или сложных задач.</p>
<p><strong>Примеры:</strong> В статье приводятся примеры данных предпочтений, сгенерированных с помощью PTS для задач по математике, физике и кодированию. Эти примеры показывают, что опорные токены часто являются не фактическими ошибками, а выборами, которые направляют модель по менее выгодному пути.</p>
<p><strong>Связь с другими работами:</strong> Метод PTS сравнивается с другими работами, в том числе с подходом контрастной оценки, где используются модели, обученные на неправильных траекториях, а также с методами автоматического контроля процесса. В отличие от этих подходов, PTS напрямую оценивает вероятность успеха и генерирует данные предпочтений, нацеленные на опорные токены.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Benchmarking Considerations</div>
                <div class="summary_text"><p><strong>Ограничения академических бенчмарков и разработка внутреннего бенчмарка PhiBench</strong></p>
<p>Академические бенчмарки, хотя и широко используются для измерения прогресса в развитии больших языковых моделей (LLM), имеют ряд ограничений, которые могут не выявить истинные возможности и слабые стороны моделей. Эти ограничения включают:</p>
<ol>
<li>
<p><strong>Загрязнение данных:</strong> Многие бенчмарки используют наборы данных, которые пересекаются с корпусами, используемыми для предварительного обучения моделей. Это создает риск "загрязнения" данных, когда модель может "помнить" ответы из обучающих данных, а не демонстрировать истинное понимание. Хотя принимаются меры для дедупликации и очистки данных, включая стандартную дедупликацию n-грамм, эти методы не эффективны против всех сценариев, например, перефразирования, что оставляет некоторую неопределенность относительно истинной способности к обобщению.</p>
</li>
<li>
<p><strong>Ограниченный набор навыков:</strong> Большинство бенчмарков оценивают модели по узко определенным навыкам, таким как решение математических задач определенного типа или реализация изолированных функций на Python. Такой узкий охват может не выявить более широкие возможности и слабые стороны моделей.</p>
</li>
<li>
<p><strong>Предвзятость в бенчмарках, основанных на генерации:</strong> Некоторые бенчмарки используют LLM в качестве "судьи" для оценки сгенерированных результатов. Эти оценки иногда могут отдавать приоритет стилю, беглости речи или поверхностным качествам, а не точности и обоснованности цепочки рассуждений, что приводит к потенциальным искажениям в оценке.</p>
</li>
<li>
<p><strong>Ограничения задач с множественным выбором:</strong> Бенчмарки, основанные на вопросах с множественным выбором, часто проверяют способность моделей делать "умные" предположения, которые могут быть достигнуты путем сопоставления с образцом, а не эффективного использования основных концепций посредством рассуждений.</p>
</li>
</ol>
<p>Чтобы решить эти проблемы, был разработан внутренний бенчмарк под названием PhiBench, специально предназначенный для оценки разнообразных навыков и способностей к рассуждению, которые оказались критически важными для развития модели phi-4. Этот бенчмарк был разработан со следующими целями:</p>
<ol>
<li>
<p><strong>Оригинальность:</strong> Все вопросы в бенчмарке были составлены командой разработчиков, чтобы гарантировать их отсутствие в данных предварительного обучения. Цель внутреннего бенчмарка — выявить способность моделей к обобщению в различных областях.</p>
</li>
<li>
<p><strong>Разнообразие навыков:</strong> Бенчмарк включает широкий спектр задач для оценки различных аспектов производительности модели. Например, в области программирования он выходит за рамки реализации изолированных функций, включая отладку, расширение неполного кода и объяснение фрагментов кода. Аналогично, в математике он включает такие задачи, как выявление ошибок в доказательствах или генерация связанных задач, а не просто решение уравнений. Это гарантирует, что бенчмарк охватывает более широкий спектр навыков и процессов рассуждения.</p>
</li>
<li>
<p><strong>Строгая оценка задач генерации:</strong> Для задач, требующих оценки сгенерированных моделью результатов, были устранены распространенные недостатки оценки на основе LLM путем тщательной разработки подробных инструкций для судей. Эти инструкции точно определяют, как оценивать ответы, уделяя особое внимание достижению точности, логической структуры и соответствия требованиям задания, сводя к минимуму тенденции к стилистическим искажениям. Наблюдалось значительное повышение согласованности и снижение негативного влияния субъективных предпочтений в результатах оценки.</p>
</li>
</ol>
<p>PhiBench сыграл центральную роль в оптимизации модели phi-4. Он использовался для принятия решений о сочетании наборов данных и выборе гиперпараметров для более эффективных методов постобработки. PhiBench также использовался для проведения исследований, выявляющих слабые места модели и предоставляющих обратную связь для новых источников данных.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Performance on Key Benchmarks</div>
                <div class="summary_text"><p>В таблице 1 представлены результаты тестирования модели phi-4 на различных бенчмарках, а также сравнение с другими моделями. В качестве бенчмарков использовались:</p>
<ul>
<li><strong>OpenAI simple-evals:</strong> Это фреймворк для оценки моделей на задачах MMLU, GPQA, MATH, HumanEval, MGSM и SimpleQA (с использованием F1-меры). Фреймворк включает в себя готовые промпты, температуру и методы извлечения ответов.</li>
<li><strong>MMLU-pro, HumanEval+, ArenaHard и IFEval:</strong> Для этих бенчмарков использовался внутренний фреймворк с собственными промптами и методами извлечения.</li>
<li><strong>PhiBench:</strong> Это внутренний набор тестов, разработанный авторами статьи.</li>
</ul>
<p>Результаты показали, что phi-4 превосходит ближайшую по размеру модель Qwen-2.5-14B-Instruct на 9 из 12 бенчмарков. Несмотря на то, что phi-4 показала более низкие результаты на SimpleQA, DROP и IFEval, авторы считают, что поведение phi-4 на SimpleQA фактически лучше, чем у Qwen. Базовая модель phi-4 даже показала более высокий результат на SimpleQA, чем Qwen-2.5-14B-Instruct, но в процессе дообучения поведение модели было изменено для улучшения пользовательского опыта, а не для повышения оценки на бенчмарке. Подробности можно найти на рисунке 6 и в приложении A.1.</p>
<p>Модель phi-4 особенно хорошо справляется с задачами STEM Q&amp;A (вопросы и ответы в области науки, технологий, инженерии и математики). Например, на GPQA (вопросы STEM уровня магистратуры) и MATH (математические соревнования) она даже превосходит свою обучающую модель GPT-4o. Phi-4 также показывает более высокие результаты в программировании (HumanEval и HumanEval+) по сравнению с другими открытыми моделями, включая более крупные модели Llama.</p>
<p>Самые слабые результаты phi-4 показала на бенчмарках SimpleQA, DROP и IFEval. Авторы считают, что оценка SimpleQA, полученная с помощью simple-evals, является заниженной и неточно отражает производительность модели. Однако IFEval выявил реальную слабость модели – проблемы со строгим следованием инструкциям. Хотя строгое следование инструкциям не было приоритетом при генерации синтетических данных для этой модели, авторы уверены, что производительность phi-4 в этой области может быть значительно улучшена с помощью целенаправленных синтетических данных.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Safety</div>
                <div class="summary_text"><p>В процессе разработки модели phi-4 мы придерживались принципов ответственного искусственного интеллекта (RAI) Microsoft. Наш подход к RAI включал в себя несколько этапов: выравнивание безопасности после обучения, тестирование "красной командой" (имитация атак) и автоматизированное тестирование и оценка по десяткам категорий вреда RAI.</p>
<p>Для обучения безопасности мы использовали наборы данных, содержащие примеры предпочтений в отношении полезности и безвредности, основываясь на наборах данных, использованных в моделях phi-3 (3B-4K, 7B-8K, 14B-4K). Мы также использовали данные из моделей Mistral (7B-v0.1, 7B-v0.2), Llama-3 (8B), Gemma (7B). Кроме того, мы применили модификации, вдохновленные работой [BSA+24], и использовали собственные наборы данных для решения проблем, связанных с категориями вреда RAI, в процессе обучения безопасности после основной тренировки.</p>
<p>В таблице 10 представлены сравнительные результаты производительности различных моделей, включая phi-4. Оценка "Grounding" (способность модели обосновывать свои ответы) является исключением, где более высокий показатель лучше, а для всех остальных показателей более низкий балл считается лучше. Показатели phi-4 выделены жирным шрифтом для наглядности.</p>
<p>В таблице приводятся результаты по следующим категориям:
*   <strong>Grounding:</strong> Способность модели обосновывать свои ответы.
*   <strong>3P Content Harms (DR1):</strong> Вред, связанный с контентом третьих сторон, включая книги, новости, рецепты и песни.
*   <strong>Harmful Content Continuation (DR3):</strong> Продолжение вредоносного контента.
*   <strong>Harmful Content Summarization (DR3):</strong> Создание вредоносных резюме.
*   <strong>Jailbreak (DR1):</strong> Устойчивость модели к обходу ограничений безопасности.</p>
<p>Вред оценивался по следующим категориям: ненависть/справедливость, причинение вреда себе, сексуальный контент и насилие. В таблице видно, что phi-4 демонстрирует хорошие результаты по большинству показателей, особенно в плане снижения вредоносного контента.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">RAI Benchmarks</div>
                <div class="summary_text"><p>В таблице 10 представлены результаты внутреннего тестирования моделей phi-4 по сравнению с моделями phi-3, Mistral-7b-v0.1, Mistral-7b-v0.2, Gemma 7b и Llama-3-instruct8b. Для этого тестирования использовался GPT-4o, который имитировал многоходовые диалоги в пяти различных категориях и оценивал ответы моделей. </p>
<p>Оценка "заземления" (grounding) показывает, насколько информация в ответе основана на предоставленном запросе. Она варьируется от 0 (не заземлено) до 5 (полностью заземлено). В других категориях ответы оценивались по степени вредоносности (от 0 - нет вреда, до 7 - серьезный вред). Также были рассчитаны показатели дефектности (DR-x), которые представляют собой процент образцов, где оценка вредоносности равна или превышает значение x.</p>
<p>Тест "Jailbreak" (DR1) включал имитацию разговоров на темы, связанные с совращением детей, незаконным убеждением, утечкой 100 слов из инструкций, популярными теориями заговора, предрассудками против реальных людей, пошаговыми незаконными советами и насилием против реальных людей. Более подробную информацию о запросах и системе оценки можно найти в работе [HPBP+24].</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Red Teaming</div>
                <div class="summary_text"><p>В дополнение к сравнительному анализу RAI (ответственного искусственного интеллекта), мы сотрудничали с Microsoft AI Red Team (AIRT), независимой группой, задачей которой является выявление уязвимостей в безопасности и защите продуктов Microsoft GenAI. AIRT провела двухнедельное тестирование phi-4, имитируя поведение как обычных, так и злонамеренных пользователей в однократных и многократных сценариях, чтобы выявить рискованное поведение. В целом, AIRT обнаружила, что поведение phi-4 аналогично поведению семейства phi-3, но выявила несколько рискованных ситуаций, которые были устранены в ходе дальнейшего обучения модели после её создания.</p>
<p>Кроме того, сценарий с злонамеренным пользователем тестировал широкий спектр техник, направленных на преднамеренное обхождение обучения модели безопасности, включая "побеги из тюрьмы" (jailbreaks), кодирование запросов и многоходовые атаки. Phi-4 продемонстрировала сильную защиту от этих техник. AIRT также сгенерировала вредоносные суффиксы с использованием алгоритма GCG на phi-3-medium, но обнаружила, что эти суффиксы не переносятся на phi-4. Требуется дальнейшее тестирование, чтобы выявить возможные риски в более широком диапазоне сценариев и категорий ущерба.</p>
<p><em>Комментарий: "Побег из тюрьмы" (jailbreak) - это техника, при которой пользователь пытается заставить модель сгенерировать ответ, который она обычно не должна давать, например, вредоносный или оскорбительный контент.</em></p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Weaknesses</div>
                <div class="summary_text"><p>Модель phi-4, хотя и демонстрирует уровень понимания языка и рассуждений, сравнимый с гораздо более крупными моделями, все же имеет ограничения из-за своего размера. Это особенно проявляется в склонности к галлюцинациям, когда дело касается фактических знаний. Например, если в запросе фигурирует правдоподобное человеческое имя, модель может выдать вымышленную биографию этого человека. Улучшить ситуацию можно, подключив к модели поисковую систему, но полностью исключить галлюцинации не удастся.</p>
<p>Также, несмотря на хорошие результаты в ответах на вопросы и решении задач на рассуждение, phi-4 хуже справляется с четким следованием подробным инструкциям, особенно если они касаются форматирования. Например, при генерации таблиц, списков с заданными маркерами или соблюдении стилистических требований, модель может отклоняться от заданных правил. Это связано с тем, что при обучении приоритет отдавался синтетическим данным, ориентированным на вопросы и ответы и задачи на рассуждение, а не на следование инструкциям.</p>
<p>Даже в задачах на рассуждение phi-4 может допускать ошибки. Например, при сравнении чисел 9.9 и 9.11 модель может ошибочно заключить, что 9.9 меньше, чем 9.11. Кроме того, из-за большого количества примеров рассуждений в обучающих данных, phi-4 иногда дает слишком длинные и подробные ответы даже на простые вопросы, что может утомлять пользователей.</p>
<p>Также стоит отметить, что хотя phi-4 может работать как чат-бот, она была дообучена для максимизации производительности в одноходовых запросах.</p>
<p>Несмотря на усилия по ответственному использованию искусственного интеллекта, мы признаем наличие проблем, связанных с воспроизведением или усилением предвзятостей, генерацией неприемлемого контента и вопросами безопасности. Использование тщательно отобранных обучающих данных, целенаправленное дообучение и улучшения, основанные на результатах тестирования, позволили снизить остроту этих проблем, но не устранили их полностью.</p></div>
                <div class="images"></div>
            </div>

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2024-12-13 10:04',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2024-12-13 10:04')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2024-12-13 10:04')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    