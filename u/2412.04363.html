
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 1 paper. December 6.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">6 декабря</span> | <span id="title-articles-count">1 paper</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2024-12-05.html">⬅️ <span id="prev-date">05.12</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2024-12-09.html">➡️ <span id="next-date">09.12</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2024-12.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '6 декабря', 'en': 'December 6', 'zh': '12月6日'};
        let feedDateNext = {'ru': '09.12', 'en': '12/09', 'zh': '12月9日'};
        let feedDatePrev = {'ru': '05.12', 'en': '12/05', 'zh': '12月5日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': '2412.04363', 'title': 'Challenges in Trustworthy Human Evaluation of Chatbots', 'url': 'https://huggingface.co/papers/2412.04363', 'abstract': 'Open community-driven platforms like Chatbot Arena that collect user\npreference data from site visitors have gained a reputation as one of the most\ntrustworthy publicly available benchmarks for LLM performance. While now\nstandard, it is tricky to implement effective guardrails to collect\nhigh-quality annotations from humans. In this paper, we demonstrate that three\nsources of bad annotations, both malicious and otherwise, can corrupt the\nreliability of open leaderboard rankings. In particular, we show that only 10\\%\nof poor quality votes by apathetic (site visitors not appropriately\nincentivized to give correct votes) or adversarial (bad actors seeking to\ninflate the ranking of a target model) annotators can change the rankings of\nmodels by up to 5 places on the leaderboard. Finally, we discuss open\nchallenges in ensuring high-quality human annotations.', 'score': 1, 'issue_id': 1, 'pub_date': '2024-12-05', 'pub_date_card': {'ru': '5 декабря', 'en': 'December 5', 'zh': '12月5日'}, 'hash': '4fa16cf75a2af540', 'authors': ['Wenting Zhao', 'Alexander M. Rush', 'Tanya Goyal'], 'affiliations': [], 'pdf_title_img': 'assets\\pdf\\title_img\\2412.04363.jpg', 'data': {'categories': ['#rlhf', '#data', '#security', '#benchmark', '#ethics'], 'emoji': '🎭', 'ru': {'title': 'Осторожно: ненадежные оценки могут исказить рейтинги ИИ!', 'desc': 'В статье рассматриваются проблемы открытых платформ для оценки языковых моделей, таких как Chatbot Arena. Авторы демонстрируют, что даже небольшое количество некачественных оценок может значительно искажать рейтинги моделей. Исследование выявляет три источника плохих аннотаций: апатичные пользователи, злоумышленники и другие факторы. Статья подчеркивает важность обеспечения высокого качества человеческих аннотаций для достоверности открытых рейтингов языковых моделей.'}, 'en': {'title': 'Guarding Against Bad Votes: Ensuring Trustworthy LLM Rankings', 'desc': 'This paper examines the reliability of user-generated annotations on community-driven platforms like Chatbot Arena, which are used to evaluate the performance of large language models (LLMs). It identifies three main sources of poor-quality annotations: apathetic users who lack motivation to provide accurate feedback, adversarial users who intentionally skew results, and other malicious behaviors. The authors demonstrate that even a small percentage of these low-quality votes can significantly impact the rankings of models, potentially shifting them by several places. The paper concludes by highlighting the ongoing challenges in maintaining high-quality human annotations to ensure trustworthy leaderboard results.'}, 'zh': {'title': '确保高质量注释，提升模型排名的可靠性', 'desc': '本文探讨了开放社区平台（如Chatbot Arena）在收集用户偏好数据时面临的挑战。我们发现，来自无动机或恶意用户的低质量注释会严重影响大型语言模型（LLM）的排名。具体来说，仅10%的低质量投票就可能导致模型在排行榜上排名变化多达5位。最后，文章讨论了确保高质量人类注释的开放性挑战。'}}, 'clean_sections': [{'title': 'Abstract', 'content': 'Open community-driven platforms like Chatbot Arena that collect user preference data from site visitors have gained a reputation as one of the most trustworthy publicly available benchmarks for LLM performance. While now standard, it is tricky to implement effective guardrails to collect high-quality annotations from humans. In this paper, we demonstrate that three sources of bad annotations, both malicious and otherwise, can corrupt the reliability of open leaderboard rankings. In particular, we show that only 10\\% of poor quality votes by apathetic (site visitors not appropriately incentivized to give correct votes) or adversarial (bad actors seeking to inflate the ranking of a target model) annotators can change the rankings of models by up to 5 places on the leaderboard. Finally, we discuss open challenges in ensuring high-quality human annotations.', 'summary': '<p>Платформы с открытым сообществом, такие как Chatbot Arena, которые собирают данные о предпочтениях пользователей от посетителей сайта, завоевали репутацию одной из самых надежных общедоступных оценок производительности LLM. Хотя сейчас это стало стандартом, сложно реализовать эффективные меры предосторожности для сбора высококачественных аннотаций от людей. В этой статье мы демонстрируем, что три источника некачественных аннотаций, как злонамеренных, так и других, могут испортить надежность открытых рейтинговых списков лидеров. В частности, мы показываем, что всего 10% некачественных голосов от апатичных (посетители сайтов, которые недостаточно мотивированы давать правильные голоса) или враждебно настроенных (злоумышленники, стремящиеся к раздуванию рейтинга целевой модели) аннотаторов могут изменить рейтинги моделей до 5 мест в рейтинге. Наконец, мы обсуждаем открытые проблемы обеспечения высокого качества человеческих аннотаций.</p>'}, {'title': 'Introduction', 'content': 'Reliable evaluation of free-form text generation quality is long-standing challenge in NLP (Gehrmann et al., 2023; Celikyilmaz et al., 2020; Goyal et al., 2022a). Despite limitations, human annotation is widely accepted as the gold standard, especially for open-ended text generation tasks without an objective notion of correctness. As result, platforms such as Chatbot Arena (Zheng et al., 2023; Chiang et al., 2024b) and WildVision Arena (Lu et al., 2024) that allow users to interact with available large language models (LLMs) and submit preference judgments for model pairs, have become extremely valuable resource in the NLP evaluation landscape. By providing free and easy access to available LLMs, these community-driven platforms are able to incentivize millions of user interactions1 and collect large-scale and diverse dataset of user queries and preferences. Deservedly, 1As of October 6, 2024, Chatbot Arena has collected 2,011,939 pairwise preference judgments. these peer production and community-driven platforms have emerged as one of the most trusted benchmarks in NLP today.2 Moreover, such benchmarks play crucial role in auditing automatic evaluators by providing the necessary ground truth rankings that any evaluator can be validated against. In fact, the most popular automatic evaluation benchmarks today, including AlpacaEval (Li et al., 2023), WildBench (Lin et al., 2024), MixEval (Ni et al., 2024) and Arena-Hard (Li et al., 2024), validate their metric by reporting high correlation with Chatbot Arena judgments. Given its far-reaching impact, both on human and automatic benchmarking of LLMs, and consequently on LLM research more broadly, it is crucial to ensure that the model rankings on these open community leaderboards are trustworthy. However, challenges with obtaining high-quality human judgments from non-expert crowdworkers like Chatbot Arena users are widely discussed in literature (Karpinska et al., 2021; Clark et al., 2021; Hosking et al., 2024). Moreover, these platforms typically implement minimal quality controls for verifying annotation quality such as attention checks, user verification, etc. This sits in direct opposition to the goals of trustworthiness. In this paper, we play devils advocate and ask: is it even possible to ensure the reliability of community-driven open platform, like Chatbot Arena, without sacrificing user scale? We approach this thought experiment from two angles. First, using Chatbot Arena as case study, we consider three different sources of poor quality preference judgments or votes in the collected dataset: un-incentivized or apathetic users providing random judgments (Section 3.1), malicious actors launching adversarial attacks to detect and artificially inflate target models ranking (Sec2As an example, Googles Chief Scientist used high performance on Chatbot Arena to declare the success of their recent model release: https://tinyurl.com/55xs2pz4. trol measures employed by Chatbot Arena. Notation Assume there are different models = {m1, m2, ..., mk} that need to be ranked on the leaderboard. Each new user on the platform submits query and receives outputs from two different models yi mi(x) and yj mj(x).3 The user has the option to submit preference label {i, j, tie}. In order to ensure that this annotation is unbiased, the names of the models that the two outputs are sampled from is only revealed to end users after they have submitted their preference annotation. This arena logs data points of the form: (x, yi, yj, mi, mj, l). These preferences are then used to estimate the pairwise win matrix between model pairs, i.e. p(mi > mj). Next, they estimate the coefficients of the Bradley-Terry model (Bradley and Terry, 1952) to obtain scores si for each model mi M. Models are sorted by si to obtain the final ranking. Quality control measures The arena employs list of filtering strategies: detecting malicious users according to certain distribution (Section 5.1; Chiang et al. (2024a)), bot detection by Cloudflare and Google reCAPTCHA v3, automatic categorization pipelines to filter out low-quality data45, placing limits on the number of votes each IP can provide in day, and deduplicating top 0.1% occurring prompts. However, these filtering strategies focus more on filtering bots than differentiating user votes with varying qualities. Therefore, we present results and discussions in this paper assuming minimal quality control checks in the backend to filter out bad quality user annotations6. Released Artifacts We conduct our experiments using the largest publicly released dataset by Chatbot Arena. It consists of 55k preference annotations7; it includes response pairs sampled from two of 64 unique models and the corresponding pairwise preference annotation. 3The arena employs an adaptive sampling strategy that favors model pairs with higher uncertainty in relative performance, and also newly introduced models. However, exact details are not publicly shared, possibly to mitigate gaming. 4https://blog.lmarena.ai/blog/2024/ hard-prompts/ 5https://blog.lmarena.ai/blog/2024/ arena-category/ 6https://github.com/lm-sys/FastChat/ 7https://huggingface.co/datasets/lmsys/ lmsys-arena-human-preference-55k Figure 1: Our characterization of sources of poor-quality votes on open data annotation platforms: (1) Apathetic: Users who lack intrinsic motivation may submit random votes. (2) Adversarial: Malicious users aim to manipulate rankings by upvoting target model. (3) Arbitrary: Users voting based on subjective preferences in response to open-ended questions. tion 3.2), and the inherent arbitrariness of preference votes for open-ended and subjective queries (Section 3.3). For the former two sources of votes, we show that small fractions of poor-quality judgments (either apathetic or adversarial) can have non-trivial impact on the target models rankings. Concerningly, poor annotations from either apathetic or adversarial voting are not easy to detect in post-hoc manner. Moreover, even carefully recruited and onboarded human annotators exhibit low inter-annotator agreement on subjective queries, making inter-annotator-based techniques to filter out low-quality annotations ineffective. Finally, we discuss open challenges in ensuring the reliability and human annotation quality in open-source community-driven benchmarks (Section 4). We strongly believe that open data collection platforms offer an invaluable resource for the academic community and have facilitated essential work in developing new automatic evaluators (Li et al., 2023; Lin et al., 2024; Ni et al., 2024), training and evaluating reward models (Lambert et al., 2024), etc. However, critical questions exist about their reliability, especially against adversarial attacks. We hope that our work will spur future research on quality control mechanisms for open platforms that power LLM evaluations.', 'summary': '<p>Оценка качества генерации свободного текста является давней проблемой в области обработки естественного языка (NLP). Несмотря на ограничения, человеческая аннотация широко признана золотым стандартом для оценки открытых задач генерации текста без объективного понятия правильности. В результате платформы, такие как Chatbot Arena и WildVision Arena, которые позволяют пользователям взаимодействовать с доступными большими языковыми моделями (LLM) и предоставлять предпочтения между парами моделей, стали ценным ресурсом для оценки в области NLP. Эти платформы предоставляют свободный и легкий доступ к доступным моделям, что позволяет собирать большие объемы данных о предпочтениях пользователей. Такие платформы сегодня являются одними из самых надежных эталонов в NLP благодаря своим возможностям по проверке автоматических оценщиков путем предоставления необходимых истинных рейтинговых оценок. Однако существуют проблемы с получением качественных человеческих оценок от неквалифицированных пользователей, таких как пользователи Chatbot Arena. Кроме того, эти платформы обычно реализуют минимальные меры контроля качества для проверки качества аннотаций, что противоречит целям обеспечения надежности. В данной работе рассматривается возможность обеспечения надежности таких платформ, как Chatbot Arena, без ущерба для масштабируемости пользователей.</p>'}, {'title': 'Background', 'content': 'In this paper, we run experiments with Chatbot Arena (Zheng et al., 2023; Chiang et al., 2024a) as case study, although our insights are broadly applicable to other similar community-driven preference collection platforms. Below, we describe the preference collection pipeline and quality conModel Leaderboard Ranking Orig. r=1 r= r=10 Llama-2-7b-chat Llama-2-13b-chat Mistral-7b-instruct-v0.2 21 39 36 21 39 382 201 412 382 21 345 41 existing studies characterizing the incentives or behaviors of an average user on open platforms like Chatbot Arena. Therefore, we have no way of estimating the fraction of apathetic. Table 1: Change in leaderboard rankings for 3 test models based on different percentages (r) of arbitrary votes. The subscripts denote gain () or loss () in rankings. We find that only 10% poor quality annotations can change the rank of 2/3 systems by 5 places.', 'summary': '<p>В данной работе мы проводим эксперименты с платформой для сбора предпочтений Chatbot Arena в качестве примера, хотя наши выводы применимы и к другим подобным платформам, управляемым сообществом. Ниже описывается процесс сбора предпочтений и модель оценки качества. Мы отмечаем отсутствие существующих исследований, характеризующих стимулы или поведение среднего пользователя на открытых платформах, таких как Chatbot Arena. Поэтому у нас нет возможности оценить долю безразличных пользователей. В Таблице 1 показано изменение позиций в рейтинге для трех тестовых моделей на основе различных процентов (r) произвольных голосов. Подстрочные индексы обозначают увеличение (+) или уменьшение (-) в рейтинге. Мы обнаружили, что всего 10% некачественных аннотаций могут изменить рейтинг 2/3 систем на 5 позиций.</p>'}, {'title': 'Votes and Their Impact', 'content': 'For our thought experiment, we hypothesize that there exist three potential sources of poor quality votes on open platforms: (a) apathetic votes by users that are un-incentivized, (b) adversarial votes that aim to inflate the ranking of target model, and (c) arbitrary votes on difficult to meaningfully distinguish response pairs. For each of these, we study their impact on model rankings and the challenges in mitigating them. 3.1 Apathetic Voting The main attraction of open community platforms for end users is that they expose free and easy-touse API endpoint for LLMs. This incentivizes diverse users to interact with the platform and submit queries to explore their use cases. However, these platforms do not explicitly incentivize high-quality preference annotation. We hypothesize that at least r% of users on the arena are apathetic and provide random or low-quality votes on the platform. Setup We run experiments on Chatbot Arenas dataset of 55k preferences (discussed in Section 2). We assume that this dataset reflects true rankings of models based on gold human preferences. We study the change in model rankings for 3 arbitrarily selected models: Llama-2-7b-chat, Mistral-7binstruct-v0.2, and Llama-2-13b-chat, assuming r% of these preferences were instead assigned random labels by apathetic users during data collection. Results Table 1 summarizes our results. We find that only 10% of apathetic votes in the dataset can change the leaderboard rankings of 2/3 models by 5 places (namely Llama-2-13b-chat and Mistral-7b-instruct-v0.2).8 Note that there are no 8Note that model frequency also impacts its susceptibility to ranking changes. All three models we inspect collectively occur in less than 10% of all data samples. Discussion: Can we detect and remove apathetic votes? major challenge in detecting apathetic votes is that they are often indistinguishable from arbitrary votes. Multiple past studies have found that output-level comparisons using single label is ill-defined as an annotation task (Krishna et al., 2023; Goyal et al., 2022a) as users often rely on different criteria and disagree with each other. This ambiguity makes it hard to ascertain whether observed disagreements are due to personal variations in quality assessment (arbitrary voting, discussed further in Section 3.3) or due to apathetic or low-quality annotations by certain annotators. Despite challenges with detecting individual apathetic votes, detecting apathetic users may be viable by computing agreements between model rankings by individual users. This strategy is based on the intuition that while annotators might disagree on specific examples, their aggregate systemlevel judgments tend to be more aligned (Goyal et al., 2022a). Finally, requesting additional justifications for votes, such as free-text rationales, can also help discourage apathetic votes. We discuss this more in Section 4. 3.2 Adversarial Voting We assume there exists malicious developer who seeks to inflate the rankings of their own target model mT on the arena leaderboard A. We argue that due to the lack of quality controls (e.g. user verification, attention checks, etc.), it is straightforward to inject preference votes for mT using simple attack methodology. Our main component is target model attribution algorithm which, given query-output pair (q, y), predicts whether is sampled from the target model mT (q). Given such an algorithm, we can inflate the ranking of the target model mT using the following strategy: (1) Enter prompt on the arena, (2) Detect if any of the two shown outputs y1, y2 are sampled from mT , (3) If yes, vote for the target model mT , (4) Repeat. Target model attribution algorithm We assume that the attribution algorithm has access to the target model logits. This is reasonable assumption for our setting where model developer seeks to Model Leaderboard Ranking Orig. r=1 r=5 r=10 r=100 Llama-2-7b-chat Llama-2-13b-chat Mistral-7b-instruct-v0.2 21 39 232 174 21 363 325 289 342 342 297 121 139 234 Table 2: Change in leaderboard rankings for 3 test models based on different percentages (r) of adversarial votes (upvoting the target model). We find that only 10% adversarial annotations can change the rank of all systems by more than 4 places. Model TPR TNR #Tokens Llama-2-7b-chat Llama-2-13b-chat Mistral-7b-instruct-v0. 91.13 88.46 100.00 89.93 91.28 86.69 328.06 326.53 319.46 Table 3: Intrinsic eval. of model attribution algorithm inflate rankings. Our simple attribution algorithm is outlined in Algorithm 1 in Appendix A. Essentially, we use teacher-forcing to determine the probability distribution over the vocabulary for all tokens at time step t, i.e. PmT (.x, y1, ...yt1). We sort the tokens in descending order of probability to identify the smallest subset of tokens that cover cumulative probability mass of at least p. We compute the fraction of generation time steps for which the actual generated token yt falls within this top-p probability subset. We compare this against threshold to classify generations = y1...yN as being sampled from mT or not. Intrinsic Evaluation of Detector Algorithm For all three test models, we report the true positive rate (TPR) and true negative rate (TNR) on the arena dataset in Table 3. We find that our detector algorithm reports very high performance (e.g. TPR=91.13%, and TNR=88.46% for Llama-2-7bchat). We also find positive correlation between the number of tokens and TPRs, which can be leveraged in the attack. Note that malicious actors can always improve the detector accuracy further using watermarking techniques (Kirchenbauer et al., 2023). Next, we use these highly performant models to cast adversarial votes. Can we influence voting on the live Chatbot Arena platform? We also implement proofof-concept of real attack on Chatbot Arena to demonstrate that current guardrails, such as bot detection, can be bypassed easily. On October 13, 2024, we programmatically launched 100 queries into Chatbot Arena, extracted the two model responses, and successfully submitted preference vote. To avoid contaminating the dataset, we only cast tie votes but note that it would be trivial to instead use the vote from the attribution algorithm. Interestingly, post-hoc analysis of this data revealed that yi-lightning family of models, released just 2 days later, were the most common (20% of the responses) in this set.9 We assume that Chatbot Arena had early access to these models and sampled them more frequently than others in order to collect enough votes. However, this knowledge of when particular models will be up-sampled can be easily exploited by adversaries to log large fraction of upvotes for their model. Impact of adversarial voting on leaderboard rankings Similar to Section 3.1, we run experiments on the 55k preference dataset from Chatbot Arena, assumed to reflect "true" votes. For 3 target models, we report the change in leaderboard rankings if adversarial voting was conducted on r% of the data samples during data collection. Table 2 summarizes our results. Across all models, we show that adversarial attacks can substantially change leaderboard rankings if adversaries get to contribute 10% votes for their model.10. Note that, in this work, we only report results using the most simplistic version of this attack. We can further boost these numbers by not only upvoting the target model but also downvoting open-source competitor models or those ranked higher than the target model in the leaderboard. Discussion: Can we detect and remove adversarial votes? Open platforms can employ two types of mitigation strategies to address this issue: recognizing bot-like behavior to prevent votes from being cast, or detecting abnormal users post-hoc to filter out their votes. Platforms like Chatbot Arena already implement measures from both categories. For example, Chatbot Arena uses Cloudflare and Google reCAPTCHA to detect bots on their platform; however, we were able to bypass both programmatically. We did not find public information indicating that similar measures have been incorporated into the Wildvision Arena platform. There are also opportunities to detect anomalous users post-hoc based on behaviors across multiple 9Evenly distributed between yi-lightning and yi-lightning-lite. 10We assume that adversaries can get 10% votes towards their own model because newly released models will be sampled more frequently. Th Org Re Per WS GPT-3.5 vs GPT-4o 5.51 Llama-3-8b vs Llama-3-70b 10.15 -10.78 Llama-3-8b vs GPT-3.5 Llama-3-70b vs GPT-4o 9.91 17.18 20.06 8.50 5.78 27.16 7.45 3.53 7.19 -12.15 -4.66 2.75 4.56 -1. 11.34 3.15 -0.36 Table 4: Fleiss Kappa between four annotators on different evaluation axis: Th(esis), Org(anization), Re(asoning), Per(spectives), WS (Writing Style). sessions or votes. Chatbot Arena implements version of this strategy by comparing the distribution of ratings from user (uniquely identified by IP address) against historical distributions to identify anomalies. Because committed adversaries may bypass these checks using IP rotation or similar techniques, we encourage further exploration of these approaches to make them more robust. 3.3 Arbitrary Voting We assume an idealized scenario where all users genuinely make their best effort to rank model outputs. However, we argue that holistically rating response to an open-ended and inherently subjective query is ill-defined and liable to always be arbitrary. To demonstrate this, we conduct small-scale annotation study for outputs of subjective Researchy questions prompts (Rosset et al., 2024). Setup We use these prompts and generate generate responses from four language models: Llama3-8B, Llama-3-70B, GPT-4o, and GPT-3.5. We recruit four undergraduate CS students who are passionate about NLP and committed to providing thoughtful annotations. They evaluate responses on four dimensions: thesis, organization, reasoning, perspectives, and writing style. We offer them unlimited time and allow them to seek clarification from the authors when needed. Note that this dimension-wise rating is different from Chatbot Arenas setup of pairwise preferences. However, there already exist multiple prior works that argue that the task is under-defined in this latter setting and report low agreement between annotators (Goyal et al., 2022a,b; Krishna et al., 2023). Therefore, we opt to run this study using more welldefined task description. Results Table 4 shows the inter-annotator agreement between the annotators. Overall, we find very 11Representative question: How can the education system be improved?. low agreement between these well-intentioned annotators with clear guidelines, irrespective of the performance difference between the model pairs. More concerningly, the results highlight that traditional approaches like filtering out low-quality users/annotations using inter-annotator agreement may not be viable strategy for open-ended queries as it is difficult to disentangle between of low interannotator agreement due to bad annotation (apathetic votes) or inherent subjectivity. Adversarial users can also hide their votes from similar scrutiny by using open-ended prompts for which vote choice is expected to be ambiguous. Discussion We argue that arbitrary votes are not noise and provide useful signals about models relative performance. If most frontier models perform similarly well on substantial fraction of real-world queries, this information should not be discarded but inform leaderboard Elo scores. Arbitrary votes become problematic when the majority of the leaderboard is dominated by openended queries that fail to meaningfully distinguish models, despite the existence of legitimate topics or skills along where models exhibit distinct behaviors. Identifying which test examples (or type of test examples) are most informative and up-weighting them when deriving aggregate scores are potential ways of addressing this (Rodriguez et al., 2021).', 'summary': '<p>В данном разделе рассматривается гипотеза о существовании трех возможных источников некачественных голосов на открытых платформах: апатичные голоса пользователей без стимулов, враждебные голоса, направленные на искусственное завышение рейтинга целевой модели, и произвольные голоса в случае трудноразличимых пар ответов. Для каждого из этих случаев исследуется их влияние на рейтинги моделей и трудности в смягчении этого влияния.</p>\n<p><strong>Апатичное голосование</strong></p>\n<p>Основная привлекательность открытых платформ для конечных пользователей заключается в том, что они предоставляют бесплатный и простой в использовании интерфейс для взаимодействия с языковыми моделями (LLM). Однако эти платформы явно не стимулируют высококачественную аннотацию предпочтений. Предполагается, что по крайней мере r% пользователей на платформе апатичны и предоставляют случайные или низкокачественные голоса.</p>\n<p>Эксперименты проводились на наборе данных Chatbot Arena, содержащем 55 тысяч предпочтений. Результаты показали, что всего лишь 10% апатичных голосов могут изменить рейтинговую позицию двух из трех произвольно выбранных моделей (Llama-2-13b-chat и Mistral-7b-instruct-v0.2) на пять мест.</p>\n<p>Обнаружить апатичные голоса сложно, так как они часто неотличимы от произвольных голосов. Несмотря на сложности с обнаружением отдельных апатичных голосов, возможно обнаружить апатичных пользователей путем вычисления согласованности между рейтингами моделей отдельными пользователями. Запрос дополнительных обоснований для голосов также может помочь предотвратить апатичное голосование.</p>\n<p><strong>Враждебное голосование</strong></p>\n<p>Предполагается, что существует злоумышленник, стремящийся искусственно повысить рейтинг своей целевой модели на лидерборде. Из-за отсутствия мер контроля качества (например, проверки пользователя, проверок внимания и др.) легко внедрить предпочтения голосующих за целевую модель.</p>\n<p>Для этого используется алгоритм атрибуции целевой модели, который предсказывает, был ли ответ получен от целевой модели. Стратегия состоит в следующем:</p>\n<ol>\n<li>Ввести запрос на арене,</li>\n<li>Определить, какой из двух показанных результатов принадлежит целевой модели,</li>\n<li>Если да, проголосовать за целевую модель,</li>\n<li>Повторять процесс.</li>\n</ol>\n<p>Алгоритм атрибуции имеет доступ к логитам целевой модели, что является разумным предположением, когда разработчик модели пытается повысить ее рейтинг.</p>\n<p>Результаты показывают, что даже 10% враждебных голосов могут значительно изменить позиции всех систем более чем на четыре места.</p>\n<p>Таким образом, исследование выявило серьезные проблемы с качеством голосования на открытых платформах и предложило методы обнаружения и устранения этих проблем.</p>'}, {'title': 'Conclusion & Future Directions', 'content': 'Our experiments in Section 3 lay convincing case for the need for stronger guardrails in open community-driven platforms. Although these are broadly accepted as the ground truth rankings of LLMs, we are concerned that it is easy to intentionally (adversarial) or unintentionally (apathetic, arbitrary settings) corrupt these leaderboards. The key challenge in mitigating the issue of poor quality annotations is: how can community-driven platforms strike the right balance between implementing necessary quality controls while also providing the right incentives and experience to users to continue to use these platforms. Richer feedback We encourage the community to explore ideas from past research, such as soliciting fine-grained annotations (Krishna et al., 2023; Goyal et al., 2022b) or rationales (McDonnell et al., 2016) in addition to the binary preference feedback. Rationales can be useful in encouraging apathetic users to think more critically about their votes (or abstain) and also for filtering out low-quality annotations from both apathetic and adversarial users. Past work in generation evaluation has discussed how binary preference, or even single Likert rating, for the whole output, cannot meaningfully capture the nuances of human preferences (Gehrmann et al., 2023). Instead, fine-grained preference annotation is recommended, both along multiple dimensions or quality (Gehrmann et al.) or for smaller units within the whole output (Krishna et al., 2023; Goyal et al., 2022b). More recent work proposes providing added context during evaluation to encourage higher agreement between annotators (Malaviya et al., 2024). Future work must explore how these strategies can be incorporated into open platforms without inordinately increasing the annotation burden on users. Stronger Guardrails Other guardrails could include reputation-based systems (Adler and de Alfaro, 2007), CAPTCHA (Von Ahn et al., 2003, 2008), machine learning based anomaly detection (Kumar et al., 2014; Wu et al., 2016) and techniques that use annotator behavior traces on the platform to estimate quality (Goyal et al., 2018). Open access to collected dataset Public release of the collected data on open platforms will spur research to address the annotation issues we discuss It would provide more detailed in this work. overview into which types of queries are most wellequipped to distinguish between models, and what are the limitations of different families of models.', 'summary': '<p>В разделе 3 представлены эксперименты, которые убедительно доказывают необходимость более строгих мер защиты в открытых платформах с участием сообщества. Несмотря на то что такие платформы широко признаны как эталонные для ранжирования языковых моделей (LLM), существует опасение, что их легко намеренно или ненамеренно испортить. Основная проблема заключается в том, как сообществу достичь правильного баланса между внедрением необходимых механизмов контроля качества и обеспечением мотивации и удобства использования этих платформ пользователями. </p>\n<p>Для улучшения качества аннотаций предлагается исследовать идеи из предыдущих исследований, например, получение детальных аннотаций (Krishna et al., 2023; Goyal et al., 2022b) или обоснование решений (McDonnell et al., 2016) вместо бинарных предпочтений. Обоснования могут помочь пользователям принимать более обоснованные решения при голосовании и отсеивать некачественные аннотации от апатичных или враждебно настроенных пользователей. В прошлом обсуждались недостатки бинарной оценки предпочтений или единой оценки Лайкерта для всего вывода, так как они не способны адекватно отразить нюансы человеческих предпочтений (Gehrmann et al., 2023). Вместо этого рекомендуется использовать детализированную оценку по нескольким критериям качества (Gehrmann et al.) или для отдельных частей вывода (Krishna et al., 2023; Goyal et al., 2022b).</p>\n<p>Также предлагаются другие меры безопасности, включая системы репутации (Adler and de Alfaro, 2007), CAPTCHA (Von Ahn et al., 2003, 2008), методы обнаружения аномалий на основе машинного обучения (Kumar et al., 2014; Wu et al., 2016) и техники, использующие поведение пользователя на платформе для оценки качества (Goyal et al., 2018). Открытый доступ к собранным данным позволит исследователям лучше понять, какие типы запросов наиболее эффективно различают модели, и выявить ограничения различных семейств моделей.</p>'}]}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents', '#agi', '#alignment', '#architecture', '#audio', '#benchmark (1)', '#cv', '#data (1)', '#dataset', '#diffusion', '#ethics (1)', '#games', '#graphs', '#hallucinations', '#healthcare', '#inference', '#interpretability', '#leakage', '#long_context', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal', '#open_source', '#optimization', '#plp', '#rag', '#reasoning', '#rl', '#rlhf (1)', '#robotics', '#science', '#security (1)', '#small_models', '#story_generation', '#survey', '#synthetic', '#training', '#transfer_learning', '#video'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            
            <div class="summaries">
                <div class="summary_title">Abstract</div>
                <div class="summary_text"><p>Платформы с открытым сообществом, такие как Chatbot Arena, которые собирают данные о предпочтениях пользователей от посетителей сайта, завоевали репутацию одной из самых надежных общедоступных оценок производительности LLM. Хотя сейчас это стало стандартом, сложно реализовать эффективные меры предосторожности для сбора высококачественных аннотаций от людей. В этой статье мы демонстрируем, что три источника некачественных аннотаций, как злонамеренных, так и других, могут испортить надежность открытых рейтинговых списков лидеров. В частности, мы показываем, что всего 10% некачественных голосов от апатичных (посетители сайтов, которые недостаточно мотивированы давать правильные голоса) или враждебно настроенных (злоумышленники, стремящиеся к раздуванию рейтинга целевой модели) аннотаторов могут изменить рейтинги моделей до 5 мест в рейтинге. Наконец, мы обсуждаем открытые проблемы обеспечения высокого качества человеческих аннотаций.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Introduction</div>
                <div class="summary_text"><p>Оценка качества генерации свободного текста является давней проблемой в области обработки естественного языка (NLP). Несмотря на ограничения, человеческая аннотация широко признана золотым стандартом для оценки открытых задач генерации текста без объективного понятия правильности. В результате платформы, такие как Chatbot Arena и WildVision Arena, которые позволяют пользователям взаимодействовать с доступными большими языковыми моделями (LLM) и предоставлять предпочтения между парами моделей, стали ценным ресурсом для оценки в области NLP. Эти платформы предоставляют свободный и легкий доступ к доступным моделям, что позволяет собирать большие объемы данных о предпочтениях пользователей. Такие платформы сегодня являются одними из самых надежных эталонов в NLP благодаря своим возможностям по проверке автоматических оценщиков путем предоставления необходимых истинных рейтинговых оценок. Однако существуют проблемы с получением качественных человеческих оценок от неквалифицированных пользователей, таких как пользователи Chatbot Arena. Кроме того, эти платформы обычно реализуют минимальные меры контроля качества для проверки качества аннотаций, что противоречит целям обеспечения надежности. В данной работе рассматривается возможность обеспечения надежности таких платформ, как Chatbot Arena, без ущерба для масштабируемости пользователей.</p></div>
                <div class="images"><img class="summary_image" src='https://arxiv.org/html/2412.04363/x1.png'/></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Background</div>
                <div class="summary_text"><p>В данной работе мы проводим эксперименты с платформой для сбора предпочтений Chatbot Arena в качестве примера, хотя наши выводы применимы и к другим подобным платформам, управляемым сообществом. Ниже описывается процесс сбора предпочтений и модель оценки качества. Мы отмечаем отсутствие существующих исследований, характеризующих стимулы или поведение среднего пользователя на открытых платформах, таких как Chatbot Arena. Поэтому у нас нет возможности оценить долю безразличных пользователей. В Таблице 1 показано изменение позиций в рейтинге для трех тестовых моделей на основе различных процентов (r) произвольных голосов. Подстрочные индексы обозначают увеличение (+) или уменьшение (-) в рейтинге. Мы обнаружили, что всего 10% некачественных аннотаций могут изменить рейтинг 2/3 систем на 5 позиций.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Votes and Their Impact</div>
                <div class="summary_text"><p>В данном разделе рассматривается гипотеза о существовании трех возможных источников некачественных голосов на открытых платформах: апатичные голоса пользователей без стимулов, враждебные голоса, направленные на искусственное завышение рейтинга целевой модели, и произвольные голоса в случае трудноразличимых пар ответов. Для каждого из этих случаев исследуется их влияние на рейтинги моделей и трудности в смягчении этого влияния.</p>
<p><strong>Апатичное голосование</strong></p>
<p>Основная привлекательность открытых платформ для конечных пользователей заключается в том, что они предоставляют бесплатный и простой в использовании интерфейс для взаимодействия с языковыми моделями (LLM). Однако эти платформы явно не стимулируют высококачественную аннотацию предпочтений. Предполагается, что по крайней мере r% пользователей на платформе апатичны и предоставляют случайные или низкокачественные голоса.</p>
<p>Эксперименты проводились на наборе данных Chatbot Arena, содержащем 55 тысяч предпочтений. Результаты показали, что всего лишь 10% апатичных голосов могут изменить рейтинговую позицию двух из трех произвольно выбранных моделей (Llama-2-13b-chat и Mistral-7b-instruct-v0.2) на пять мест.</p>
<p>Обнаружить апатичные голоса сложно, так как они часто неотличимы от произвольных голосов. Несмотря на сложности с обнаружением отдельных апатичных голосов, возможно обнаружить апатичных пользователей путем вычисления согласованности между рейтингами моделей отдельными пользователями. Запрос дополнительных обоснований для голосов также может помочь предотвратить апатичное голосование.</p>
<p><strong>Враждебное голосование</strong></p>
<p>Предполагается, что существует злоумышленник, стремящийся искусственно повысить рейтинг своей целевой модели на лидерборде. Из-за отсутствия мер контроля качества (например, проверки пользователя, проверок внимания и др.) легко внедрить предпочтения голосующих за целевую модель.</p>
<p>Для этого используется алгоритм атрибуции целевой модели, который предсказывает, был ли ответ получен от целевой модели. Стратегия состоит в следующем:</p>
<ol>
<li>Ввести запрос на арене,</li>
<li>Определить, какой из двух показанных результатов принадлежит целевой модели,</li>
<li>Если да, проголосовать за целевую модель,</li>
<li>Повторять процесс.</li>
</ol>
<p>Алгоритм атрибуции имеет доступ к логитам целевой модели, что является разумным предположением, когда разработчик модели пытается повысить ее рейтинг.</p>
<p>Результаты показывают, что даже 10% враждебных голосов могут значительно изменить позиции всех систем более чем на четыре места.</p>
<p>Таким образом, исследование выявило серьезные проблемы с качеством голосования на открытых платформах и предложило методы обнаружения и устранения этих проблем.</p></div>
                <div class="images"></div>
            </div>
            <div class="summaries">
                <div class="summary_title">Conclusion & Future Directions</div>
                <div class="summary_text"><p>В разделе 3 представлены эксперименты, которые убедительно доказывают необходимость более строгих мер защиты в открытых платформах с участием сообщества. Несмотря на то что такие платформы широко признаны как эталонные для ранжирования языковых моделей (LLM), существует опасение, что их легко намеренно или ненамеренно испортить. Основная проблема заключается в том, как сообществу достичь правильного баланса между внедрением необходимых механизмов контроля качества и обеспечением мотивации и удобства использования этих платформ пользователями. </p>
<p>Для улучшения качества аннотаций предлагается исследовать идеи из предыдущих исследований, например, получение детальных аннотаций (Krishna et al., 2023; Goyal et al., 2022b) или обоснование решений (McDonnell et al., 2016) вместо бинарных предпочтений. Обоснования могут помочь пользователям принимать более обоснованные решения при голосовании и отсеивать некачественные аннотации от апатичных или враждебно настроенных пользователей. В прошлом обсуждались недостатки бинарной оценки предпочтений или единой оценки Лайкерта для всего вывода, так как они не способны адекватно отразить нюансы человеческих предпочтений (Gehrmann et al., 2023). Вместо этого рекомендуется использовать детализированную оценку по нескольким критериям качества (Gehrmann et al.) или для отдельных частей вывода (Krishna et al., 2023; Goyal et al., 2022b).</p>
<p>Также предлагаются другие меры безопасности, включая системы репутации (Adler and de Alfaro, 2007), CAPTCHA (Von Ahn et al., 2003, 2008), методы обнаружения аномалий на основе машинного обучения (Kumar et al., 2014; Wu et al., 2016) и техники, использующие поведение пользователя на платформе для оценки качества (Goyal et al., 2018). Открытый доступ к собранным данным позволит исследователям лучше понять, какие типы запросов наиболее эффективно различают модели, и выявить ограничения различных семейств моделей.</p></div>
                <div class="images"></div>
            </div>

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2024-12-06 15:40',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2024-12-06 15:40')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2024-12-06 15:40')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    