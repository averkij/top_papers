
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF (18 —Å—Ç–∞—Ç–µ–π)</title>
    <link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0989eacf;
            --secondary-color: #03dac6;
            --background-color: #f5f5f5;
            --text-color: #333333;
            --header-color: #0989eacf;
            --body-color: #f5f5f5;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        header {
            padding: 1.6em 0;
            text-align: center;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2em;
            padding: 10px 0 20px 0;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.tags {
            color: #555;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        body.dark-theme>div>main>article {
            background-color: #444;
        }
        body.light-theme>div>main>article {
            background-color: #fff;
        }
        body.dark-theme>div>main>article:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article:hover {
            background-color: #fafafa;
        }
        article {
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
            transition: background-color 0.2s ease;
            display: flex;
            flex-direction: column;
            position: relative;
        }
        .article-content {
            padding: 1.5em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
        }
        .pub-date {
            font-size: 0.9em;
            margin-bottom: 0.8em;
            font-weight: 300;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 1em;
            position: absolute;
            bottom: 10px;
            font-weight: 300;
            font-family: 'Roboto Slab';
        }
        .background-digit {
            position: absolute;
            bottom: -20px;
            right: -10px;
            font-size: 12em;
            font-weight: bold;
            color: rgba(0, 0, 0, 0.03);
            z-index: 0;
            line-height: 1;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 80px;
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        a:hover {
            color: var(--secondary-color);
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 1em 0;
            margin-top: 2em;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
        }
        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
        }
        .update-info-container {
            flex: 1;
        }
        .sort-container {
            flex: 2;
        }
        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .category-toggle {
            display: none;
            margin-bottom: 10px;
            margin-top: 15px;
            cursor: pointer;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }

        .svg-container span {
            position: relative;
            z-index: 1;
        }

        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .sort-container {
                margin-top: 0px;
                text-align: left;
                width: 100%;
            .sort-dropdown {
                float: right;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiffRu(dateString) {
        const timeUnits = {
            minute: ["–º–∏–Ω—É—Ç—É", "–º–∏–Ω—É—Ç—ã", "–º–∏–Ω—É—Ç"],
            hour: ["—á–∞—Å", "—á–∞—Å–∞", "—á–∞—Å–æ–≤"],
            day: ["–¥–µ–Ω—å", "–¥–Ω—è", "–¥–Ω–µ–π"]
        };

        function getRussianPlural(number, words) {
            if (number % 10 === 1 && number % 100 !== 11) {
                return words[0];
            } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                return words[1];
            } else {
                return words[2];
            }
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);

        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes == 0) {
            return '—Ç–æ–ª—å–∫–æ —á—Ç–æ';
        }
        else if (minutes < 60) {
            return `${minutes} ${getRussianPlural(minutes, timeUnits.minute)} –Ω–∞–∑–∞–¥`;
        } else if (hours < 24) {
            return `${hours} ${getRussianPlural(hours, timeUnits.hour)} –Ω–∞–∑–∞–¥`;
        } else {
            return `${days} ${getRussianPlural(days, timeUnits.day)} –Ω–∞–∑–∞–¥`;
        }
    }
    function formatArticlesTitle(number) {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;

        let word;

        if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
            word = "—Å—Ç–∞—Ç–µ–π";
        } else if (lastDigit === 1) {
            word = "—Å—Ç–∞—Ç—å—è";
        } else if (lastDigit >= 2 && lastDigit <= 4) {
            word = "—Å—Ç–∞—Ç—å–∏";
        } else {
            word = "—Å—Ç–∞—Ç–µ–π";
        }

        return `${number} ${word}`;
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">
            <h1 class="title-sign" id="doomgrad-icon">üî∫</h1><h1 class="title-text" id="doomgrad">—Ö—Ñ –¥—ç–π–ª–∏</h1>
            <p>16 –æ–∫—Ç—è–±—Ä—è | 18 —Å—Ç–∞—Ç–µ–π</p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">üîÄ –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ</label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">—Ä–µ–π—Ç–∏–Ω–≥—É</option>
                    <option value="pub_date">–¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏</option>
                    <option value="issue_id">–¥–æ–±–∞–≤–ª–µ–Ω–∏—é –Ω–∞ HF</option>
                </select>
            </div>
        </div>
        <div class="category-toggle">
            <div class="svg-container">
                <span id="category-toggle">üîç –§–∏–ª—å—Ç—Ä</span>
                <svg height="3" width="200">
                    <line x1="0" y1="0" x2="200" y2="0" 
                        stroke="black" 
                        stroke-width="2" 
                        stroke-dasharray="3, 3" />
                </svg>
            </div>
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">üßπ</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">–≥—Ä–∞–¥–∏–µ–Ω—Ç –æ–±—Ä–µ—á–µ–Ω–Ω—ã–π</a> ‚úñÔ∏è <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>    
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "—Ö—Ñ –Ω–∞–π—Ç–ª–∏";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "—Ö—Ñ –¥—ç–π–ª–∏";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2410.11779', 'title': 'MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation', 'url': 'https://huggingface.co/papers/2410.11779', 'abstract': 'Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood. In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the objects in the final output, they are actually able to recognize visual objects in the preceding layers. We speculate that this may be due to the strong knowledge priors of the language model suppressing the visual information, leading to hallucinations. Motivated by this, we propose a novel dynamic correction decoding method for MLLMs (DeCo), which adaptively selects the appropriate preceding layers and proportionally integrates knowledge into the final layer to adjust the output logits. Note that DeCo is model agnostic and can be seamlessly incorporated with various classic decoding strategies and applied to different MLLMs. We evaluate DeCo on widely-used benchmarks, demonstrating that it can reduce hallucination rates by a large margin compared to baselines, highlighting its potential to mitigate hallucinations. Code is available at https://github.com/zjunlp/DeCo.', 'score': 16, 'issue_id': 121, 'pub_date': '2024-10-15', 'pub_date_ru': '15 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (MLLM). –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ MLLM —Å–ø–æ—Å–æ–±–Ω—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—è—Ö, –Ω–æ –≤ –∏—Ç–æ–≥–æ–≤–æ–º –≤—ã–≤–æ–¥–µ –º–æ–≥—É—Ç –∏—Ö –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —ç—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ–º –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–∏–ª—å–Ω—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –ø—Ä–∏–æ—Ä–∞–º–∏ –º–æ–¥–µ–ª–∏. –î–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è DeCo, –∞–¥–∞–ø—Ç–∏–≤–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—â–∏–π –∑–Ω–∞–Ω–∏—è –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–ª–æ–µ–≤ –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π.', 'categories': ['#multimodal', '#nlp', '#cv', '#code'], 'emoji': 'üîç', 'title': '–ë–æ—Ä—å–±–∞ —Å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö', 'embedding': [0.03247479333420629, 0.04238699545387423, -0.04501564790079551, 0.00994643192840189, -0.03170810321628497, 0.07119262924505257, 0.05678981664780065, 0.04542637551724215, -0.10766515991710686, 0.09594575843424231, 0.00925504223169056, -0.04512517383240219, -0.06609961969612593, 0.04863004232885147, -0.042852488185292845, -0.07184979558053584, 0.05919940863483404, -0.03463795304970895, -0.03827973218441954, 0.04151078155351484, -0.017962448357841804, 0.02907945076936369, -0.012670919243103726, 0.027751436490913002, 0.05941846479638468, 0.018003521119486464, 0.011965838052732538, 0.09523383128212434, 0.06987830517076056, 0.07141168325743456, 0.03619871584303758, -0.04936934988928681, -0.11111526759692143, -0.024246567994463716, -0.08000957204865364, 0.06084231910062063, -0.006472368325561398, 0.025656729945372363, -0.07842142239950177, 0.03852616445595027, -0.011917920189008535, -0.06724965272383929, -0.047534772266941465, 0.027655598614296364, -0.00787910729559665, 0.13066586345474648, -0.0011757052768053859, 0.03370696973604034, -0.04030598126166089, 0.10782945096368553, -0.12343707030029728, 0.08471923009111373, -0.017182066961177488, 0.10120306117891624, -0.0727260094808952, -0.04036074637663287, 0.0824191618865184, 0.010391385914912685, 0.0027997870911612363, -0.03732136846243357, 0.019783335776028466, -0.026984744223823055, -0.017305286320695796, 0.001033662208944189, -0.026437108118283734, -0.06889256748796312, -0.09830059605214687, -0.0483562232014975, 0.04298939667438552, 0.06182806108175532, -0.021658988309187104, -0.01956428176364646, -0.007872261978600447, 0.014608180059061907, -0.09972445035638282, -0.022863787526456743, -0.021700061070831767, 0.056406467290502735, 0.008905924832295225, -0.018879737169014473, 0.008111852801638507, 0.030339014027020987, -0.020152990630830446, -0.07814760542131644, 0.027285943759494384, -0.047835971802612794, 0.025738873319493063, 0.020194064467059424, -0.07289030052747388, -0.06029468299508131, 0.055092145365379354, 0.007160335686149922, -0.06171853515014864, 0.04975269494824747, -0.01579928778267169, 0.04501564790079551, 0.04301677708270288, -0.08855268282988897, 0.05761126758235669, 0.023438805114897734, -0.06330667835179463, 0.030421159550310314, 0.05446236158738208, -0.11927504191587061, 0.030585448447720348, -0.0391833286422649, -0.01664812342388234, -0.03006519489966701, -0.01071996714840255, 0.04293463370858217, -0.013759345062601847, 0.031215231151133307, -0.04419419696623947, -0.021303025807712428, 0.04441324882945284, -0.18028164776473266, -0.056625521302884736, 0.07387604895611444, 0.01881128399905245, 0.009823213643467898, -0.06987830517076056, -0.007064499743785051, 0.044248959932042815, -0.07245219250270987, -0.013314390646257326, -0.014717707924920359, 0.05925417589897465, -0.08345966468428781, 0.02687521829221637, -0.021125044556975094, -0.043345359175860194, 0.03272122775490565, 0.06790681691015392, -0.07732615233759176, -0.12288943419475797, 0.005757019482071203, -0.08395253997319242, 0.011582493853439329, -0.06905684993786727, 0.02621805625507036, 0.04416681225958485, -0.03233788269594499, 0.06155424410356998, 0.07091881656520448, -0.10799374630860144, 0.06319715242018793, 0.08110483566305778, -0.01849639425922244, -0.0743689134991759, 0.07250695761768185, -0.07721662640598509, -0.062375699336463274, -0.013540291050219843, 0.002375369485472774, -0.13230876317468993, -0.02650556558658301, -0.017058849750827807, -0.01897557504563111, 0.11095098084868003, -0.08773123404450156, 0.04947888011923076, 0.09183848871728174, 0.14829972757026233, -0.02230246229134306, -0.027655598614296364, 0.11281293458100547, -0.11905598145598273, 0.14939499978134096, -0.04162030533595291, -0.1341707276528585, -0.07683327919785579, 0.043619178303214164, -0.03014734257212497, -0.07414986378513116, 0.028312760651442368, -0.01304057280840453, -0.03814282154615824, -0.21894472715728147, -0.029380650305035023, -0.09578146953683228, -0.03485700921125958, 0.07683327919785579, -0.06845445301569324, 0.05145036623066877, -0.08762169736705173, -0.08088578379984439, -0.06845445301569324, 0.09769819698080422, 0.009453559648333368, 0.034583190083905604, -0.06264951416547998, 0.037211842530826884, 0.10766515991710686, 0.062211406140715984, 0.007913334740245113, -0.06735917865544597, 0.14118045604908258, 0.06401860335474398, -0.017140995274117138, -0.059473227762188025, -0.02946279797749298, 0.09309805197493905, 0.0009344032857059229, -0.16943845588389023, 0.05260040355671938, 0.03455580752641962, 0.06467576754105861, 0.015676069282820834, 0.04112743649455419, 0.030339014027020987, 0.05295636605819405, -0.024506692619321754, 0.1424947908692177, 0.005031402125794547, -0.023479875727373766, -0.04622044604348083, -0.09112656371433239, -0.012390255873337863, 0.007749043908583316, -0.002043365400059631, -0.047233572731270136, 0.058925593805817335, -0.012465556294547852, 0.055092145365379354, -0.08920984486703498, -0.006951549541803792, 0.0806667233399565, -0.07404033570435585, 0.037704713521394234, 0.025259694682253024, 0.050711058670233435, -0.12168463820124126, -0.015210579775155157, -0.005674874173698737, 0.023945368458792384, -0.027997870911612363, 0.03129737559983833, -0.023548333195673045, 0.014060544598273177, -0.06467576754105861, 0.09605528651501762, 0.02383584037801707, 0.0650043474850473, -0.05739221142080606, -0.015279034019701494, 0.07666899030044574, -0.09134562417422028, -0.018085666642775795, 0.04400252336217483, -0.04167507045092488, 0.00946040518024643, 0.029380650305035023, -0.06149948113776664, -0.024465622006845714, -0.08313108903863638, 0.08838839393247894]}}, {'id': 'https://huggingface.co/papers/2410.11710', 'title': 'MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models', 'url': 'https://huggingface.co/papers/2410.11710', 'abstract': 'Large Language Models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users. Recently, many tool-use benchmark datasets have been proposed. However, existing datasets have the following limitations: (1). Insufficient evaluation scenarios (e.g., only cover limited tool-use scenes). (2). Extensive evaluation costs (e.g., GPT API costs). To address these limitations, in this work, we propose a multi-granularity tool-use benchmark for large language models called MTU-Bench. For the "multi-granularity" property, our MTU-Bench covers five tool usage scenes (i.e., single-turn and single-tool, single-turn and multiple-tool, multiple-turn and single-tool, multiple-turn and multiple-tool, and out-of-distribution tasks). Besides, all evaluation metrics of our MTU-Bench are based on the prediction results and the ground truth without using any GPT or human evaluation metrics. Moreover, our MTU-Bench is collected by transforming existing high-quality datasets to simulate real-world tool usage scenarios, and we also propose an instruction dataset called MTU-Instruct data to enhance the tool-use abilities of existing LLMs. Comprehensive experimental results demonstrate the effectiveness of our MTU-Bench. Code and data will be released at https: //github.com/MTU-Bench-Team/MTU-Bench.git.', 'score': 16, 'issue_id': 121, 'pub_date': '2024-10-15', 'pub_date_ru': '15 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ MTU-Bench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–∞–≤—ã–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (LLM). MTU-Bench –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –ø—è—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –æ—Ç –ø—Ä–æ—Å—Ç—ã—Ö –¥–æ —Å–ª–æ–∂–Ω—ã—Ö –∏ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á. –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API GPT –∏–ª–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã, —á—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç –∑–∞—Ç—Ä–∞—Ç—ã. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö MTU-Instruct –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π LLM –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.', 'categories': ['#benchmark', '#nlp', '#dataset', '#rlhf'], 'emoji': 'üõ†Ô∏è', 'title': '–ú–Ω–æ–≥–æ–≥—Ä–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ LLM –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤', 'embedding': [-0.027825905545227552, -0.00598734934856303, 0.12383590192401733, -0.05639525478511897, -0.04678363350831473, -0.021904935453124316, 0.023683882397844493, 0.13233237287956254, -0.05528009634613364, 0.07567159741562754, 0.06462619288525875, -0.09951479019133007, -0.03552582258205096, -0.04086266138677993, 0.0331361932967907, 0.0001733103607738907, -0.021719076051532026, -0.05735110487567783, -0.08453977499776791, 0.09054040636709484, 0.06770615969998811, 0.03202103485780538, 0.003833363856504123, -0.026936433087583242, 0.04253540411883683, -0.017829288923940027, -0.007779571211036647, 0.03164931402518922, 0.029950022269398063, 0.00654492937982832, 0.045562266797802994, -0.038818199851538435, -0.10179821526392706, 0.035632028824145796, 0.042243336445718135, 0.04951843257302532, 0.09229279819978609, 0.06425448219980043, 0.07338817640189367, 0.033985839174686276, -0.005678688434138847, -0.059050396631468986, 0.005516061153330855, 0.012240212069988437, -0.05926280911565866, 0.029418993088355435, 0.06021866326508064, 0.03366722450726489, -0.07142336802614964, 0.023351990174408636, -0.049173262793574986, 0.09781549640610734, -0.07503436199249007, -0.08268117692298184, 0.0071157857494491454, -0.11406497229878661, -0.023723709992309005, -0.002918998797168974, 0.03042794731467749, -0.03316274637938808, -0.03042794731467749, -0.0526249504409205, 0.012837619898661392, 0.041738862376704454, -0.08682320209979645, -0.04842982315777424, -0.022794408925484407, 0.034994795430439894, 0.01785584200653741, -0.027241775272569067, -0.03576478611940646, -0.0436240135340879, 0.0026816951318905497, -0.04333194789040078, 0.06653790524296585, -0.011271085438130891, 0.0070958719522168905, 0.10572782389768887, 0.0007840971663037858, 0.0010189114293529162, -0.016780509132585025, -0.0601124570229858, -0.03849958518411705, -0.005340157940053641, -0.01611672265628174, 0.0018685575101916516, -0.012266764137870036, -0.011470221381021876, -0.08257497271031856, -0.11587047638496731, -0.03616305800518843, -0.04383642195941445, 0.022502343281797278, 0.01194150917036774, 0.15081216565021244, -0.03483548708201342, 0.04973084302778343, -0.011868492455031222, 0.005018222107876017, 0.08007913718296346, -0.05233288276780181, 0.012200385287296552, 0.08889421671763532, -0.05204081509468311, 0.09123073780826926, -0.03008277956465872, 0.030295190019416832, 0.003395265188030268, -0.010627212759059862, 0.024480424139976874, -0.2400250112412901, 0.011782199807225483, -0.11268430332814311, 0.02628592315257865, 0.004102197176463797, -0.06568825530620713, -0.013780196695012058, 0.03385308187942562, 0.023219231864432196, -0.06988338664821653, -0.0028841500071630517, 0.02681695334833706, 0.06913994295355265, -0.1142773847829763, 0.07466264115987391, -0.007441040716951443, 0.0027762847047637677, -0.019488755114698237, 0.010554196246666502, 0.06112140921987629, -0.059900044538796125, 0.039800605054126234, 0.007261818368349555, -0.05259839735832312, -0.0671220365303401, -0.03345481405250678, -0.1293586062186333, 0.08172532480299143, -0.06590066779039681, -0.04118128011306445, 0.003587763063215064, -0.04333194789040078, -0.025715067391787295, 0.08268117692298184, -0.14263431545038335, 0.01700619612864183, -0.018293941486783892, 0.0747688453725372, 0.014377603306026075, 0.09999271726604106, -0.05650146102721381, -0.07721158488185534, -0.053872866175166484, 0.0023464831643005475, -0.06478550326311679, -0.09404519815020357, -0.04001301753831591, 0.11438359305450269, 0.03687994861725491, -0.173965024955309, 0.10418783846089262, 0.027985215923085588, 0.016899991915978557, 0.07954810800192084, 0.015107767821130219, 0.16599958723966957, -0.03988026024305526, 0.014404154968021363, -0.11470220975135566, -0.07057372620711719, 0.011403842124562079, -0.009697912301064732, -0.026511611163351236, -0.06048417379673883, 0.021825282293626864, -0.10535610509450428, -0.11629529729448353, -0.0463057084630353, 0.03122449108624143, -0.0593690153577535, -0.05798834029881529, 0.10100166337463685, -0.13764264439567314, -0.012021163344580978, -0.10498438223245657, -0.06473240318621672, -0.008383616904472637, 0.053235634810892156, -0.03082621920045946, 0.005436406979117617, -0.034994795430439894, 0.10928572184599236, 0.15463558224790036, 0.1365805921218826, 0.10355060912604984, -0.030958976495720117, 0.10737401151771682, 0.055970429816739616, -0.047553624197281284, 0.04885464406729047, 0.08507080823767366, 0.03090587438938848, -0.025715067391787295, -0.11172844714928956, 0.04067680198518763, 0.036455125678307124, -0.015745002838381372, 0.026949708614166155, -0.07784881218726654, -0.061068307113544655, -0.010613937232476953, 0.1094981302713189, 0.05968763205460645, -0.00443409041461544, -0.0300562285114929, -0.02305992351600572, -0.07073303658497523, -0.05480216927142265, 0.01910375977021496, 0.09160245864088543, -0.003737115020383303, 0.032233443283131914, 0.07275094097875622, 0.040437838447832136, -0.029286237822526342, 0.02510438505124721, 0.0408095592804483, -0.09101832532407958, 0.10694919669649529, -0.06675031772715552, 0.0019565090153586804, -0.07009579507354306, -0.05429768911411428, -0.12064972683776157, 0.017630155010480607, -0.03576478611940646, 0.025807998107299224, -0.00988377271737281, -0.005323563278146059, -0.08570804163137957, 0.09685964834498005, 0.016793785673883718, 0.032658268251511274, -0.018307215998651018, 0.037145459148913096, -0.018904623827323976, -0.03918992068415459, -0.009173521796557763, 0.04550916266203979, 0.03557892468838259, 0.008834991302472558, -0.07423782430922081, -0.06037796755464398, -0.06356414467033132, -0.008848266829055467, 0.004161937959331092]}}, {'id': 'https://huggingface.co/papers/2410.09342', 'title': 'LLM$\\times$MapReduce: Simplified Long-Sequence Processing using Large Language Models', 'url': 'https://huggingface.co/papers/2410.09342', 'abstract': 'Enlarging the context window of large language models (LLMs) has become a crucial research area, particularly for applications involving extremely long texts. In this work, we propose a novel training-free framework for processing long texts, utilizing a divide-and-conquer strategy to achieve comprehensive document understanding. The proposed LLMtimesMapReduce framework splits the entire document into several chunks for LLMs to read and then aggregates the intermediate answers to produce the final output. The main challenge for divide-and-conquer long text processing frameworks lies in the risk of losing essential long-range information when splitting the document, which can lead the model to produce incomplete or incorrect answers based on the segmented texts. Disrupted long-range information can be classified into two categories: inter-chunk dependency and inter-chunk conflict. We design a structured information protocol to better cope with inter-chunk dependency and an in-context confidence calibration mechanism to resolve inter-chunk conflicts. Experimental results demonstrate that LLMtimesMapReduce can outperform representative open-source and commercial long-context LLMs, and is applicable to several different models.', 'score': 15, 'issue_id': 125, 'pub_date': '2024-10-12', 'pub_date_ru': '12 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ LLM√óMapReduce, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–∑–¥–µ–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∞ –∑–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –î–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –ø–æ—Ç–µ—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –ø—Ä–æ—Ç–æ–∫–æ–ª —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –º–µ—Ö–∞–Ω–∏–∑–º –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ LLM√óMapReduce –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –ø—Ä–∏–º–µ–Ω–∏–º –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º LLM.', 'categories': ['#nlp', '#rag', '#benchmark'], 'emoji': 'üìÑ', 'title': '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è LLM', 'embedding': [0.00915309708275282, 0.06845138927568167, 0.17312147522446034, -0.02031150997756016, -0.005490012879244443, -0.01400030128081017, 0.0704197976795912, 0.004711876569259529, -0.06638455646072372, 0.13385175151158302, 0.02161557904858036, 0.0052900966875649375, -0.010198813498587474, 0.061463539441802856, 0.036710808751206754, 0.012966887267842965, 0.06505588378122451, -0.015292069744846754, 0.03799027221832147, 0.2133754230935572, 0.0036107984425794394, 0.016916006478529467, 0.04551943336556217, -0.008119683069785614, -0.011699724806797164, -0.014787664642373981, -0.025859958921225352, 0.08134445833500964, 0.07002611400338281, -0.08149208796758961, -0.01395109127025508, -0.042837478411805296, -0.11170714699046845, 0.030707165114709178, -0.016202457933255643, 0.10471930713372203, -0.03348754248408801, 0.12095867047969619, -0.03609568262155489, 0.041262753684104155, -0.014283259938986503, -0.01787560507657874, -0.03936815810105814, 0.06200485075516474, -0.01365583000966865, 0.09384384970440865, 0.014799967444326725, 0.12460022004064938, -3.332741350004716e-05, 0.09674724910703549, -0.0017792562410539265, 0.011355253735198294, -0.02721323920005653, -0.08247629616039732, 0.016940612082434952, -0.07765369756624547, 0.04049999393101936, -0.03186360255772293, 0.02780376172122939, -0.010973874656826485, 0.06013486476687717, -0.10412877663084326, -0.022550574038150625, 0.03319227723264862, -0.08911966753959931, 0.0188967166866785, -0.07539002590632304, -0.025490882844348934, -0.06412088679622777, -0.011668968699857219, 0.0028495779614800976, -0.03501305799940464, 0.024838847311125595, 0.00014378604209722837, 0.048324414343420004, -0.0020283829421451414, -0.03437332227499434, 0.05103097490108236, -0.030731769720901428, 0.012284096026764975, 0.05772356347437475, -0.02563851447235539, 0.02829586382220677, -0.03508687281569464, 0.038014877822226956, 0.017432714183412336, -0.0024097620205169503, 0.12253339919825029, -0.02220610156975322, -0.10343983568490141, -0.015611935412082787, 0.04987453745806862, -0.02802520816552583, 0.026794953910795612, 0.0712071530594491, -0.06594166556755732, -0.027508502456069436, -0.10629402787057021, 0.042419193122544385, 0.06815612601966876, -0.02168939386487035, -0.026229036993528243, 0.08597021608877055, -0.1244033811956849, 0.07194531519033433, 0.0005147848121569337, -0.0033063103299567622, -0.08887361748682386, -0.08488759745289974, -0.01551351499188731, -0.09468042626920992, -0.005566903645450926, -0.057871195102381215, 0.008968558046601372, 0.08877519706662838, -0.15333897475602254, -0.10511298681907745, 0.03274938833490869, -0.005004062279014757, 0.03447174269518981, -0.025195621583762505, 0.010530982167318896, -0.013212938517874303, -0.0360218678052649, 0.019942433900683745, -0.0866591570347124, 0.053737539449597686, -0.0766202761702003, 0.04094288482418576, 0.01812165712478067, 0.025441671636537957, 0.005736063730190485, 0.061069855765594476, -0.016682256234567042, -0.16318100879386427, -0.009337635719818972, -0.1414301118940758, 0.03641554749062032, -0.06412088679622777, -0.02568772368473989, -0.024605099062589647, -0.024469771234249173, 0.007596824462782991, -0.008218103090895795, 0.034422533482805315, 0.021738605072681327, 0.0007381529519234246, 0.030830189143383663, -0.06126669860141191, -0.01750652899970232, -0.05442648039553954, -0.15973630406415498, -0.034619372327769786, 0.0345455575114798, -0.006846368708906822, -0.043501817744694624, 0.007049361050045471, -0.021197293759319447, 0.10678612598069463, -0.06968164552583836, 0.0428866876241898, 0.04303431925219625, -0.009190004490897814, 0.05427884876753308, -0.0010380276385279778, 0.05393437829456215, 0.005551525492209629, 0.003955269713720959, -0.1012745884360274, -0.09802671656500317, -0.10176669053700478, -0.1123960979135427, -0.04495351844372128, -0.059052240144726924, -0.016042524501009684, -0.06505588378122451, -0.07981894481511947, -0.030854794747289156, -0.04684810804048786, -0.0645637836756736, -0.07278188377342969, 0.14802426807461386, -0.08040946534086585, 0.057428304209214805, -0.08705284669720022, -0.05196596989065263, 0.009343786821481372, 0.09079281667834889, -0.010438713447413765, 0.04170564258184408, -0.0760789668522649, 0.15835841419056537, 0.0701245344235783, 0.016177854324776635, 0.06028249439945714, 0.031592948896468465, 0.16820045421468652, 0.037202910852184135, -0.010900059042365904, -0.020619073042386093, 0.028172839793532283, 0.10294773757477699, -0.048275205131035503, -0.10570350734482384, -0.0201023673329297, 0.0029618388592725945, 0.024678913878879636, 0.05703462053300642, -0.020459139610140138, -0.11623449031031333, 0.06554798388677541, 0.020176182149219693, 0.14211905284001766, 0.009817434420215666, -0.027016400355092052, -0.1168250108360597, -0.055705943862654254, 0.0029233933763980293, 0.08552732719103062, -0.019733289260626806, 0.0496530890183457, 0.008617935673797452, 0.07711238425745712, 0.11593922705430042, -0.018269286757360646, -0.005723761127780389, 0.009811283318553266, -0.03203583779420839, 0.075586866746714, -0.03014124819744181, 0.053196224145382845, -0.06874664654541515, -0.029058621579865093, -0.05211359952323261, 0.05629646837925359, -0.10816401784971075, -0.03282320315119868, -0.004681120262776934, 0.009602139875752216, -0.010272629113048054, 0.023153398363562987, 0.027508502456069436, 0.045716274205953124, -0.02374392088473585, -0.02632745741372372, 0.04896414807240384, -0.08710205590958472, -0.10255405788942155, 0.07824421609656537, -0.015119833311105405, -0.021590974442388115, -0.035357528472375575, -0.041804064997466035, -0.08685599787510336, -0.08705284669720022, 0.04805376068216555]}}, {'id': 'https://huggingface.co/papers/2406.15786', 'title': 'What Matters in Transformers? Not All Attention is Needed', 'url': 'https://huggingface.co/papers/2406.15786', 'abstract': 'While scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks, it also introduces redundant architectures, posing efficiency challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy across different architectures in transformers, such as MLP and Attention layers, is under-explored. In this work, we investigate redundancy across different modules within Transformers, including Blocks, MLP, and Attention layers, using a similarity-based metric. Surprisingly, despite the critical role of attention layers in distinguishing transformers from other architectures, we found that a large portion of these layers exhibit excessively high similarity and can be pruned without degrading performance. For instance, Llama-2-70B achieved a 48.4\\% speedup with only a 2.4\\% performance drop by pruning half of the attention layers. Furthermore, by tracing model checkpoints throughout the training process, we observed that attention layer redundancy is inherent and consistent across training stages. Additionally, we further propose a method that jointly drops Attention and MLP layers, allowing us to more aggressively drop additional layers. For instance, when dropping 31 layers (Attention + MLP), Llama-2-13B still retains 90\\% of the performance on the MMLU task. Our work provides valuable insights for future network architecture design. The code is released at: https://github.com/Shwai-He/LLM-Drop.', 'score': 14, 'issue_id': 121, 'pub_date': '2024-06-22', 'pub_date_ru': '22 –∏—é–Ω—è', 'data': {'desc': '–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –Ω–∞ –±–∞–∑–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è —á–∞—Å—Ç—å —Å–ª–æ–µ–≤ –≤–Ω–∏–º–∞–Ω–∏—è (attention layers) –æ–±–ª–∞–¥–∞–µ—Ç –≤—ã—Å–æ–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç—å—é –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞ –±–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–æ—Ç–µ—Ä–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–¥–µ–ª—å Llama-2-70B –¥–æ—Å—Ç–∏–≥–ª–∞ —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ 48.4% –ø—Ä–∏ —Å–Ω–∏–∂–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—Å–µ–≥–æ –Ω–∞ 2.4% –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ–ª–æ–≤–∏–Ω—ã —Å–ª–æ–µ–≤ –≤–Ω–∏–º–∞–Ω–∏—è. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –º–µ—Ç–æ–¥ —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–µ–≤ –≤–Ω–∏–º–∞–Ω–∏—è –∏ MLP, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –µ—â–µ –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ —Å–æ–∫—Ä–∞—â–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏.', 'categories': ['#nlp', '#benchmark', '#code'], 'emoji': '‚úÇÔ∏è', 'title': '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è LLM: –º–µ–Ω—å—à–µ —Å–ª–æ–µ–≤, —Ç–∞ –∂–µ –º–æ—â–Ω–æ—Å—Ç—å', 'embedding': [0.07973888359077871, 0.01813971157876565, 0.060676386777125876, -0.035748502926044506, 0.061889910692635525, 0.08929541357829962, 0.003909202489554159, 0.07999169738717994, -0.08191311561485319, 0.12640912990402067, -0.05673242198845783, -0.05339521714700099, -0.06815980101063218, 0.06492373455521495, 0.03610244706631088, -0.05334465599615564, 0.1036554941613627, -0.10931862453214812, 0.005609405629560923, 0.08039621072046613, 0.00690193888280499, 0.029276355941404767, 0.05334465599615564, 0.027582472945253667, 0.11002651080213727, -0.00976510579274786, 0.015978115821315295, -0.06598557300764493, 0.06315400179062138, -0.11629640514122114, 0.05329409283476667, -0.05208056288762618, -0.08166029980790834, 0.057844817570645926, -0.03511645637177978, 0.05931116734581848, 0.07185095803452984, 0.060170749131605375, -0.03372595636504971, 0.08343003056195833, 0.07660393742650859, -0.04611405153796332, -0.05971567665801745, 0.043914534917378956, -0.0031791897849665117, 0.08833470144864758, 0.05101872644573981, 0.05779425843034419, -0.027582472945253667, 0.09642488769262676, -0.07043517343128987, 0.05703580095679163, -0.059968492464962275, -0.022551389128732967, -0.04426847905764533, -0.10446450876467338, 0.018228197613832247, 0.02090807130451445, -0.0017634073933245145, 0.01910041968733047, -0.029301638527371054, -0.08120522733432042, 0.04836413735156752, -0.01588962777570508, -0.06800811152646527, -0.039793596048034105, -0.14531994125459385, 0.025357673738703006, 0.011629640112013392, 0.045608415902986435, -0.044420172562899464, -0.013032782014889688, 0.02327192171806429, -0.023828122524973763, 0.08393566217584798, 0.04778265395869175, 0.01528286461162409, 0.1559383056734575, 0.03051516445342432, 0.042397626001904665, 0.0836322852180578, 0.028897129215172096, 0.06371020661861808, -0.0644686580605398, 0.02877071829588426, 0.00540083022644269, 0.0018044904394571581, -0.019745106529306538, -0.024864676380893836, -0.07801971599811772, 0.026065564029779376, 0.02117353142025785, -0.061940475864568106, 0.034181030849181254, 0.007584548196349963, 0.02266515774976585, 0.03868119443421515, 0.029478610597504246, 0.07599716943712292, 0.12489222500963361, 0.058653840216131084, 0.060474130110482784, 0.03511645637177978, -0.05728862078482369, -0.01717900145965722, -0.09192472008650562, 0.07427800586554915, -0.10871185252167523, -0.061889910692635525, 0.027734164439964185, -0.050917598112418264, 0.013020140922960905, -0.05197943455430463, 0.03544512395771071, 0.030363474969257422, -0.06881713618249403, -0.10350380266665218, 0.0735701175850164, 0.012419697701681219, 0.027683599268031604, 0.01655959619837563, -0.0078879295773361, 0.07235658964841951, -0.017431819277145665, 0.0012949036841668703, -0.03385236728433754, 0.09248092491450233, -0.04975463735829758, 0.014132541330453684, -0.0009678199240745688, 0.03359954745630549, 0.06269893132757706, 0.08459299533716623, -0.05079119121421766, -0.0068892977908762065, -0.02990840048512588, -0.049653509024976034, 0.03223433003554171, -0.08853696213637789, 0.017659356519211435, 0.07822196864367358, -0.002711476018395441, 0.0033877647859760223, 0.04457186204706636, -0.0012253785631977498, 0.09025612168686444, 0.07822196864367358, 0.023562662409230363, -0.10982425614603779, 0.09824517959752209, -0.0013667987937391987, -0.06325513012394292, -0.08393566217584798, -0.029958963646514847, -0.1290384384227703, -0.07008122124884904, 0.02596443569645783, 0.06942389612970525, 0.1633205996158167, -0.1163975334745427, 0.02689986524014359, 0.05364803898557667, 0.021502192974557938, 0.01687562048077981, -0.00812178736536626, 0.09930701603940845, -0.12337532011524656, -0.023828122524973763, -0.15876987487993746, -0.15209546519702377, -0.0611314592507138, -0.047100044243038056, 0.015131173519022299, -0.10158238443897892, -0.010618367032570353, 0.00017005978097185087, -0.09369445486164282, -0.0461646146993523, -0.02023810187657209, -0.013475213396548832, -0.016155087891448483, 0.001189035896380246, -0.05339521714700099, 0.08019395003273579, -0.09237979457063718, -0.048288291604212254, -0.05688410946208111, 0.07169926251873211, 0.013626904690204984, 0.058047074237289026, -0.03587491384533235, 0.0960203763698842, 0.03984416121996669, 0.02408094034246221, 0.0772106973737198, 0.00046692376366818967, 0.06219329569260017, 0.03789746040632714, -0.029074101285305284, -0.08732343017869379, 0.0073317299767527945, 0.12772379421611357, 0.06694628111620976, -0.13773540672994047, 0.0828232686042035, -0.0349394863121902, -0.026444790756012047, 0.0032123719978528944, -0.00883599880557011, -0.049173153965421816, 0.06942389612970525, 0.005767416866018384, 0.0013217655521432223, -0.05991792930357331, 0.05208056288762618, -0.06815980101063218, -0.09875081925358621, 0.07230602447648694, 0.036734495631119225, 0.04664497176945013, 0.0946046018193623, -0.0014789869264358534, 0.04664497176945013, 0.013500495379352039, -0.08873921679247739, -0.0029737749564120166, 0.03913626690780308, -0.13884780030158497, 0.058754966538909006, -0.012640912990402068, -0.02978199157638166, 0.004180982347044504, -0.05223225438233669, -0.032866376589806436, 0.037214848680129836, -0.1347015768357302, 0.05541776370799579, -0.02319607798125265, -0.015952833235349, -0.0848458151651983, 0.0565807284832037, 0.010529880394340675, -0.024940524138792712, -0.04613933412392962, 0.04191727094235045, 0.06735078640732148, -0.03681033936793087, -0.047453988383304425, 0.04464770578387801, 0.06780586491254026, -0.005508277899402461, 0.02286741240586533, -0.09516079860518453, -0.07250828114313003, -0.09162134312871545, 0.0480101891902139]}}, {'id': 'https://huggingface.co/papers/2410.11096', 'title': 'SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI', 'url': 'https://huggingface.co/papers/2410.11096', 'abstract': "Existing works have established multiple benchmarks to highlight the security risks associated with Code GenAI. These risks are primarily reflected in two areas: a model potential to generate insecure code (insecure coding) and its utility in cyberattacks (cyberattack helpfulness). While these benchmarks have made significant strides, there remain opportunities for further improvement. For instance, many current benchmarks tend to focus more on a model ability to provide attack suggestions rather than its capacity to generate executable attacks. Additionally, most benchmarks rely heavily on static evaluation metrics, which may not be as precise as dynamic metrics such as passing test cases. Conversely, expert-verified benchmarks, while offering high-quality data, often operate at a smaller scale. To address these gaps, we develop SecCodePLT, a unified and comprehensive evaluation platform for code GenAIs' risks. For insecure code, we introduce a new methodology for data creation that combines experts with automatic generation. Our methodology ensures the data quality while enabling large-scale generation. We also associate samples with test cases to conduct code-related dynamic evaluation. For cyberattack helpfulness, we set up a real environment and construct samples to prompt a model to generate actual attacks, along with dynamic metrics in our environment. We conduct extensive experiments and show that SecCodePLT outperforms the state-of-the-art (SOTA) benchmark CyberSecEval in security relevance. Furthermore, it better identifies the security risks of SOTA models in insecure coding and cyberattack helpfulness. Finally, we apply SecCodePLT to the SOTA code agent, Cursor, and, for the first time, identify non-trivial security risks in this advanced coding agent.", 'score': 12, 'issue_id': 121, 'pub_date': '2024-10-14', 'pub_date_ru': '14 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SecCodePLT - –Ω–æ–≤—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π AI –¥–ª—è –∫–æ–¥–∞. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö, —Å–æ—á–µ—Ç–∞—é—â—É—é —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –∞ —Ç–∞–∫–∂–µ –≤–Ω–µ–¥—Ä–∏–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏. SecCodePLT –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–¥, —Ç–∞–∫ –∏ –∏—Ö –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å –¥–ª—è –∫–∏–±–µ—Ä–∞—Ç–∞–∫. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ SecCodePLT –Ω–∞–¥ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞–º–∏ –≤ –≤—ã—è–≤–ª–µ–Ω–∏–∏ —Ä–∏—Å–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.', 'categories': ['#code', '#benchmark', '#dataset', '#rlhf'], 'emoji': 'üõ°Ô∏è', 'title': 'SecCodePLT: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ AI-–∫–æ–¥–æ–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤', 'embedding': [0.08386529588367087, 0.02522823610500497, 0.17837106110636208, -0.0017296143234627663, -8.184383661526759e-05, -0.05694945368100336, 0.04402069650169448, -0.014930997095150975, 0.040960130865253366, -0.008488071303535995, 0.006492981470993424, -0.09839584414627313, -0.040445266260447255, -0.1122971205256148, -0.01367244483482687, -0.1077777697187723, -0.0005179904516883597, -0.08026126276108465, -0.07791577765192109, -0.04219007812078776, 0.04384907921366058, 0.0584082282341511, 0.04158940487196469, 0.03644078430531233, -0.019822185359400283, -0.059151918013119816, 0.03418111421051791, 0.0021166548387192073, 0.08878508490580843, -0.0033966588353574055, 0.06601674543532297, -0.027330588228984244, -0.09513505197010692, -0.02894668287639786, 0.031950044873611735, 0.03761352792161948, 0.043706060560064194, -0.058208005941327474, 0.035153631287099966, 0.07185184789481536, 0.03686983601920003, 0.05869426341789314, -0.03106333750277199, 0.08815580877564637, -0.0690487081904251, 0.015045410743957646, 0.08443735775735202, -0.17402334032825786, -0.020222633130223627, 0.04530785164335758, -0.10903631773219494, 0.01915000490722975, 0.03918671400012315, -0.05068529950762328, -0.051800833114351005, 0.07105095235316866, -0.06206947136631674, 0.023082977535566485, -0.06899150030429639, -0.04147499122315802, 0.07053608987181327, -0.010168523920377832, 0.010876459035947458, 0.07025005681152198, -0.03386647614543688, -0.055519279885743886, -0.029776183422834265, -0.01613234146934638, -0.05134317639567359, 0.0035718547749073208, 0.014265966301589826, 0.10285797857318402, 0.05377447227230484, -0.07991802181466465, -0.04982719607984788, -0.019621960943125925, 0.05832241959013414, 0.11429935194765398, 0.006346389049817712, 0.008337903416020373, 0.017819944381832816, -0.0045050421464405245, -0.02830310530556631, 0.029432942476414252, -0.09267515533558741, -0.002399113706741047, -0.13947038866033318, -0.07402570722214209, -0.1288299044571577, -0.01623245367748356, -0.07871667107011705, 0.06624557485638703, 0.030548476083141974, 0.0950206340743988, 0.03850023210728313, 0.06590232966306557, 0.037184476207731784, -0.051486195049269975, 0.07820181071221238, 0.10566111827757425, -0.003511072484164076, -0.01963626450724615, 0.06681763885351893, 0.03615474912157029, 0.10480301697324959, -0.010068411712240655, 0.01459490686906571, -0.015560273225313028, -0.006400019983190992, -0.022696832267137996, -0.09444856158346399, -0.05054228085402689, -0.13878389827369023, 0.01679022048084742, -0.024098398934157026, -0.037413301381894394, -0.013794010265693652, -0.004755322454438397, 0.09965439215969576, 0.04150359622794774, -0.021080737619724385, 0.09055849540058646, 0.05720688385995568, -0.049026298414750466, 0.07682884692653234, -0.05251592001198074, 0.01097657060704942, -0.07127977752733126, 0.006139013913208611, -0.04219007812078776, -0.04725288579652171, 0.008745502544213687, 0.0732248116804954, 0.0542893326302095, -0.03961576571401085, 0.020122521983811814, -0.08455177352960944, 0.0035146479505039855, -0.0561485602628074, 0.03612614836368203, -0.05769314558342282, 0.06984960373207179, -0.06452936587738552, 0.12413894060918275, -0.11275476662703857, -0.10302959586121793, -0.04087431797433495, 0.07963198450747186, -0.03512502840576099, 0.20914837510437106, -0.017705531794751515, -0.011806070516450608, -0.02266822726234828, 0.008109076118407034, -0.04510762935053395, -0.04104594163272105, -0.08535267119470685, 0.1290587275078696, -0.022139065463774137, -0.05200105753062536, 0.05065669450283357, 0.14736493255144414, -0.07946035872563503, 0.05995281355476651, 0.025528572729416502, 0.07253832978765537, -0.06801898959806653, -0.052487315007191025, -0.11899031579562892, 0.009961149208458876, 0.04470717839453451, -0.0317212175759984, 0.01079779898881452, 0.012385290967234217, 0.031120546450626056, -0.07076491716942662, -0.12917314752702844, 0.002048721615296143, -0.026129244916514204, -0.11664483705681755, -0.06859105571864915, 0.03332301078274251, -0.05703526232502032, 0.0721950909646861, -0.029718977660156295, -0.10875029104225584, 0.0664743957836482, 0.008616787454737523, -0.052372903481835084, 0.010790648905514993, -0.03232188870137073, 0.02630086538972421, 0.12047769747701711, 0.05654900697190538, 0.09587873750217418, -0.10537508309383221, 0.020565875138369005, 0.05077111239854169, 0.004580126090198335, -0.12745694067147767, 0.05088552392389764, -0.06281315902183474, -0.001681346164909205, -0.005767169023724248, 0.024355831236560082, 0.01034014460593291, -0.02860344192997784, -0.06304198844289881, -0.05832241959013414, 0.05303078249333612, 0.05071390238896226, 0.012185066126269715, 0.07065049715026775, 0.005520464394411359, 0.01975067603260209, 0.010082713152910146, 0.03335161578753223, 0.07831622860792052, 0.07522705371978822, 0.04593712989697036, -0.07871667107011705, 0.10039808830901668, 0.00705074869904743, -0.015731893698523035, 0.011877578993868508, 0.08672563498038689, -0.003105261089140719, -0.05837962747626284, 0.12985962941986848, -0.12265155892779457, 0.021681408745096723, -0.006664601944203429, -0.07871667107011705, -0.09353325876336281, -0.0559197287182926, 0.02103783329771591, 0.0559197287182926, -0.007830192716725103, 0.013150432694862105, -0.009868187295966297, 0.023140185421695183, 0.03910090535610619, 0.004033085261164059, -0.030777305504206046, 0.02808857944862246, 0.049512560138217594, 0.003589731894261796, -0.03981599225373593, 0.018649443866543863, 0.03852883498862211, 0.025800306472489053, -0.0040759904325528284, 0.12860108140644583, -0.017834246884227675, -0.014673565642128211, -0.04493600781559858]}}, {'id': 'https://huggingface.co/papers/2410.10626', 'title': 'Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts', 'url': 'https://huggingface.co/papers/2410.10626', 'abstract': 'Adapting medical Large Language Models to local languages can reduce barriers to accessing healthcare services, but data scarcity remains a significant challenge, particularly for low-resource languages. To address this, we first construct a high-quality medical dataset and conduct analysis to ensure its quality. In order to leverage the generalization capability of multilingual LLMs to efficiently scale to more resource-constrained languages, we explore the internal information flow of LLMs from a multilingual perspective using Mixture of Experts (MoE) modularity. Technically, we propose a novel MoE routing method that employs language-specific experts and cross-lingual routing. Inspired by circuit theory, our routing analysis revealed a Spread Out in the End information flow mechanism: while earlier layers concentrate cross-lingual information flow, the later layers exhibit language-specific divergence. This insight directly led to the development of the Post-MoE architecture, which applies sparse routing only in the later layers while maintaining dense others. Experimental results demonstrate that this approach enhances the generalization of multilingual models to other languages while preserving interpretability. Finally, to efficiently scale the model to 50 languages, we introduce the concept of language family experts, drawing on linguistic priors, which enables scaling the number of languages without adding additional parameters.', 'score': 12, 'issue_id': 121, 'pub_date': '2024-10-14', 'pub_date_ru': '14 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ü–µ–ª–µ–π –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–∞—Ö. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –∏—Å—Å–ª–µ–¥—É—é—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö LLM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥—É–ª—å–Ω–æ—Å—Ç–∏ Mixture of Experts (MoE). –û–Ω–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ MoE —Å —è–∑—ã–∫–æ–≤–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏ –∏ –∫—Ä–æ—Å—Å-—è–∑—ã–∫–æ–≤–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π. –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Post-MoE, –ø—Ä–∏–º–µ–Ω—è—é—â–∞—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –≤ –ø–æ–∑–¥–Ω–∏—Ö —Å–ª–æ—è—Ö –º–æ–¥–µ–ª–∏.', 'categories': ['#nlp', '#dataset', '#multimodal'], 'emoji': 'üè•', 'title': '–ú–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ LLM: –ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –±–∞—Ä—å–µ—Ä–æ–≤ –≤ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏', 'embedding': [0.027926801633037828, 0.037439522828982434, 0.09742590695806506, 0.04262383315726325, -0.0643147909544701, 0.036754801643578285, -0.001386252783215639, 0.02526128521715111, -0.1666804626504423, 0.07199343841285567, 0.02188659184413999, -0.12853175477978285, -0.07013491496699086, 0.05805449134691886, 0.026166093189501416, -0.09781717505193133, 0.023292713830252353, -0.033233384756505474, 0.0010989148472907325, 0.08304677621254514, 0.07551485934220481, 0.015345069052049175, 0.04494699201215513, -0.0058048377403988796, 0.05252782244707413, -0.05986410729161947, 0.09145905842091352, 0.05184310328280815, -0.002925344640333566, -0.03726834253263139, 0.07786246790540248, -0.026875268125487663, -0.06720039819957929, 0.07717774671999832, -0.07629739957221368, 0.036608077118947514, 0.018597490640442544, 0.051060563052799275, 0.05546233517220937, 0.04961775943024468, -0.020492697743887754, -0.08739964487306734, -0.03986049870734088, 0.0711619906816826, -0.036241264796801495, 0.04340637136613396, 0.07844936600392557, 0.006810520314022237, 0.02870933984190854, 0.052625639470540705, -0.029002792933446406, 0.05365271922750876, -0.006296980435538207, -0.05917939014849165, -0.01812063138783167, -0.09004070652780288, 0.1042731046641394, 0.022644674281290442, 0.023133761419761447, -0.02483333447627352, 0.028146891451691226, -0.10505564489414826, 0.005728418304504644, -0.016164286876223965, 0.002041933649214145, 0.014000083059302594, -0.06905892164544411, -0.04000722323197166, 0.03037223126197838, 0.035165275517531076, -0.039738225912154056, -0.037048252713978, 0.08285114822902646, -0.026752997351438993, -0.030249960487929706, -0.0623584464428624, -0.13479206853530118, 0.07590612743607109, -0.009249836808487987, -0.04538716760718561, -0.009567741831583614, -0.015650748008309012, 0.06852092902694706, -0.041181029534708646, 0.017044642108561246, -0.034015922965376186, 0.03673034587185803, 0.02496783313618232, -0.09292631377291206, -0.134009524263016, 0.022241180322702194, -0.05590251480951618, -0.011132817036642147, 0.04428672659847125, 0.08011226550854805, 0.04876185996962766, -0.012728459935212847, -0.059472843240029515, 0.10124077491553758, 0.12647761143495198, 0.05243000542360757, -0.0421347480399304, 0.027315445741656307, -0.12882522404042598, 0.08930708188351084, -0.10212112610559855, -0.03548317831737473, -0.05076710996126141, -0.07287379364519296, 0.019111029508357493, -0.021972180981746428, 0.035776631408912594, 0.05252782244707413, 0.03543427081621052, 0.09072543175548334, -0.0421347480399304, -0.10055604968785713, 0.0020021952434206946, 0.015393977968010092, 0.015308387415606941, -0.012233260066494674, 0.03460282712731376, 0.06690694915031774, -0.010882160737159474, 0.11943476755511556, -0.06294534858366181, -0.004793041628073089, 0.004410942831691383, -0.003359408515685958, 0.002263550639860258, 0.010570368646424832, 0.036925981939929325, 0.09679009327382512, -0.09185032853591796, -0.13665058591775153, 0.016800098539325743, -0.061233549662427764, -0.015993108601011084, -0.030836864649867284, -0.048297228602876906, 0.021311915568062546, -0.026043821404883667, 0.004401772725751548, -0.028000166927060453, -0.049911212521782544, -0.01695905297095481, 0.0019318891441150764, 0.048712952468463445, -0.05438634993521527, 0.06543968369262841, -0.0648527855941053, -0.10593599608420923, 0.0021840740303871735, 0.10730543845501753, -0.09811062410119288, -0.02187436395827986, -0.025579191048702002, 0.037048252713978, 0.12667323739733247, -0.0313993130400846, -0.01311972782696531, 0.11200066366596549, 0.010172985801173227, -0.040447400848140296, 0.0643147909544701, 0.05546233517220937, -0.10896832987508735, -0.032719841846314206, -0.11082685736322849, -0.15083407655292383, -0.07615066494189211, -0.039933859959087194, -0.07893846122694921, -0.02741326276512288, -0.028782703114793008, -0.06294534858366181, 0.0041664004751387745, -0.15063845059054334, 0.02861152281844197, 0.009763376686972016, -0.03389365017018935, 0.11053340225055247, -0.0701838204470169, 0.08691055773459633, -0.026801905863172278, 0.0023139873341553353, -0.039102414249052274, 0.08876908724387562, 0.04122993905701102, -0.026215002711803784, -0.015968652829290823, 0.11601116769150932, 0.10319712144828345, 0.05629378492452061, 0.10172985801173226, 0.014953800351841448, 0.14936681917978714, 0.05570688076258303, -0.02314598930562158, -0.04037403555411767, 0.003747620244428651, 0.03445609856040667, 0.0014114713324769935, -0.1847766342242774, 0.04147448262624652, 0.024221976563753845, -0.050278024843928563, 0.07737338278806963, 0.06045101145355705, -0.035263092540997645, 0.03638798730029411, 0.07756901885614091, 0.13870474947396394, 0.046120798314892124, 0.01571188339533335, 0.039151321750216475, -0.11708715494964157, 0.026924175626651867, 0.09434466768716089, 0.0029314583811498153, 0.028440344543229093, -0.02858706704672171, 0.06514623868564318, -0.0005574814431923104, -0.03293993368610577, -0.0211774189292919, 0.03418710124058906, -0.09884425076662308, 0.06172263477976061, -0.04929985258812471, 0.06597768035340178, -0.037855246694568974, 0.02447874801884948, -0.08808436201619517, 0.11366355508603533, -0.022889217850525945, 0.07854718909080662, -0.0009063372463267051, 0.007110085933693458, -0.029149517458077184, 0.03487182242599321, 0.039567047636941174, 0.023720664571129944, -0.07874282515887791, -0.0023094021801285105, 0.058396853960759096, -0.030445594534862848, -0.056000331832982746, 0.06054882847702362, -0.004579066358691201, -0.04656097390992261, -0.08896472129080878, -0.0007668713564335565, -0.08691055773459633, -0.0565383244514798, 0.07571049338913795]}}, {'id': 'https://huggingface.co/papers/2410.09704', 'title': 'EchoPrime: A Multi-Video View-Informed Vision-Language Model for Comprehensive Echocardiography Interpretation', 'url': 'https://huggingface.co/papers/2410.09704', 'abstract': 'Echocardiography is the most widely used cardiac imaging modality, capturing ultrasound video data to assess cardiac structure and function. Artificial intelligence (AI) in echocardiography has the potential to streamline manual tasks and improve reproducibility and precision. However, most echocardiography AI models are single-view, single-task systems that do not synthesize complementary information from multiple views captured during a full exam, and thus lead to limited performance and scope of applications. To address this problem, we introduce EchoPrime, a multi-view, view-informed, video-based vision-language foundation model trained on over 12 million video-report pairs. EchoPrime uses contrastive learning to train a unified embedding model for all standard views in a comprehensive echocardiogram study with representation of both rare and common diseases and diagnoses. EchoPrime then utilizes view-classification and a view-informed anatomic attention model to weight video-specific interpretations that accurately maps the relationship between echocardiographic views and anatomical structures. With retrieval-augmented interpretation, EchoPrime integrates information from all echocardiogram videos in a comprehensive study and performs holistic comprehensive clinical echocardiography interpretation. In datasets from two independent healthcare systems, EchoPrime achieves state-of-the art performance on 23 diverse benchmarks of cardiac form and function, surpassing the performance of both task-specific approaches and prior foundation models. Following rigorous clinical evaluation, EchoPrime can assist physicians in the automated preliminary assessment of comprehensive echocardiography.', 'score': 10, 'issue_id': 127, 'pub_date': '2024-10-13', 'pub_date_ru': '13 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': 'EchoPrime - —ç—Ç–æ –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è –º–æ–¥–µ–ª—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç—Ö–æ–∫–∞—Ä–¥–∏–æ–≥—Ä–∞–º–º, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –±–æ–ª–µ–µ —á–µ–º 12 –º–∏–ª–ª–∏–æ–Ω–∞—Ö –ø–∞—Ä –≤–∏–¥–µ–æ-–æ—Ç—á–µ—Ç–æ–≤. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –µ–¥–∏–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ü–∏–π –≤ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–º —ç—Ö–æ–∫–∞—Ä–¥–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏. EchoPrime –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø—Ä–æ–µ–∫—Ü–∏–π –∏ –∞–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –º–µ–∂–¥—É —ç—Ö–æ–∫–∞—Ä–¥–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–æ–µ–∫—Ü–∏—è–º–∏ –∏ –∞–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∏–º–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏. –ú–æ–¥–µ–ª—å –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–¥—Ö–æ–¥—ã –≤ 23 —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –æ—Ü–µ–Ω–∫–∏ —Ñ–æ—Ä–º—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Å–µ—Ä–¥—Ü–∞, —á—Ç–æ –±—ã–ª–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ –≤ –¥–≤—É—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö.', 'categories': ['#cv', '#multimodal', '#dataset', '#benchmark', '#rag'], 'emoji': '‚ù§Ô∏è', 'title': 'EchoPrime: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —ç—Ö–æ–∫–∞—Ä–¥–∏–æ–≥—Ä–∞–º–º', 'embedding': [0.048974926672118446, -0.0587892518992495, 0.05390626515805745, 0.06633129271963487, 0.03961989672157691, 0.024185297139047494, -0.0008589044710247132, 0.10278449639259617, -0.008980348214280662, -0.012213515853519858, 0.08069018474727875, -0.0659445210342087, -0.022493173279908876, -0.04723445509418997, 0.012896408761375112, 0.002447537942582958, -0.06183507766386899, -0.07203616853749056, 0.05443807396091757, 0.04295579873404283, -0.012509637075948944, -0.055501695592594893, 0.09456560965191677, -0.04252068134280535, 0.09611269236766433, -0.09848166416007556, -0.04904745026328179, 0.036332340414922296, -0.0017767310787146094, -0.021175733170009682, 0.030216515026288405, -0.02094608855118275, -0.014721485827718034, -0.0332381689444915, -0.03732344046841483, -0.03099005839714074, -0.07527538719024804, 0.05898263874845187, -0.06347885581719628, 0.046460913736316174, 0.19618980105312717, 0.03340737790834183, 0.04288327715585803, 0.032851397259065336, -0.0745985291920827, -0.09214828410178001, -0.02779919350210876, -0.07421176153261362, -0.03464021454280513, 0.12241314684685828, -0.0998837137843463, 0.1288915700615234, -0.07687081359882839, -0.014733573160011209, 0.0125217236030507, -0.004106424506409775, -0.02003959398610466, 0.025333526272117806, -0.06425239516209154, 0.1318890460943745, 0.05361618287127537, -0.07029569897254064, 0.04421280721492252, 0.11535456912352172, -0.14629628584080825, -0.05685539548509721, -0.0423756401994143, 0.06961885305224656, 0.015821367241998483, -0.12976181088293404, 0.05173067417591294, 0.04145705971112802, 0.017984870287956256, 0.06517098571527055, 0.060529723477177985, -0.024185297139047494, -0.017972784364748064, 0.16592493025613472, 0.10355804378940561, 0.010243398851573023, 0.04559067895384121, 0.011192196966049752, -0.011820701206489596, -0.0072157037834465225, -0.02242065371470263, 0.017271758546123426, 0.06753995549470324, -0.08900576893851646, -0.036791631665554714, -0.020607664584546447, -0.07063412897811258, -0.044309498626545145, -0.03120761709275948, -0.032005332310028195, 0.027291556545665032, 0.15171108742379605, -0.020051679909312854, -0.04788713319402474, 0.01620813892742465, 0.10858606563505305, -0.053132719774226574, 0.03050659328711339, -0.03986162726361203, -0.02828265861213611, 0.08919915176176171, -0.09055285366724257, -0.049434217922750864, 0.028016752197727507, 0.06652468359479431, 0.07807947234793966, -0.04921665922713212, -0.040659342480880746, -0.10713567634390665, 0.017162979198314058, 0.02646966746900138, -0.0847512803988286, -0.07010232017525247, -0.0888607318210825, -0.1090695387969946, 0.0056232934206261465, -0.0891508060559504, 0.05559838700421752, 0.07604892049620764, -0.05289098721921289, 0.08320419969605958, -0.07208452028223752, -0.008382061600031267, 0.01651030512443638, -0.07474357033547374, -0.08354261561078169, 0.028234310893346246, 0.10462166139512584, 0.06154499940304399, -0.014818179252319213, -0.03374580590093523, 0.015265383170658451, 0.02738824997026621, 0.04762122879259468, -0.08286577170346618, -0.009602808486627135, 0.04679933770295248, 0.08160876724854359, -0.03930564258837843, -0.00502802788458309, -0.04520390726841504, 0.02526100670691156, -0.03993414682881828, -0.013138141316388784, -0.03609060785990862, 0.02891116285257595, -0.03872548807970701, 0.00917373385569589, -0.03398753644297036, -0.11777188662174427, -0.04660595085375012, -0.014322628219083672, -0.017078375722878167, 0.0368158035119711, -0.04994185689217315, 0.028886987986691745, -0.0293221063844185, 0.09369537486944178, 0.07237459854306251, 0.042641544600844364, -0.12105944695435597, 0.013669951327036028, -0.0546798045029527, 0.0029899241425266434, -0.07667743278856168, -0.07643569419461237, -0.1472632100219273, 0.003538353907967989, -0.04757288308678337, -0.05753224341836982, 0.03304478209528914, -0.05994956494254946, -0.045034694278607616, -0.022964550453749483, -0.06376893206504272, -0.08828056926049689, -0.05579177385341988, 0.04549398351626149, -0.042327294493602986, 0.08165711094137634, 0.01571258789418911, 0.04411611177734279, -0.079143093979617, -0.0519240610251153, -0.024281990563648676, -0.021103213604803436, -0.009820367383543731, 0.13498321555182674, 0.06691145528022048, 0.10249442618368537, 0.053036028362603946, 0.00724592020184984, 0.02726738469924865, 0.06101318657422678, 0.021671286216223773, -0.07358326333110943, 0.11583803222057053, 0.06115822771761783, -0.04203721824575654, -0.03609060785990862, 0.038314542534885906, 0.02598620336546331, 0.07082750777540074, 0.0217679776278464, -0.10326795948964498, -0.01379081740324501, 0.04254485318922173, -0.015108257513144202, 0.10423489373565677, 0.02646966746900138, -0.14881030481554616, -0.05975618010632565, -0.017936524582144942, -0.0067141097886068875, 0.024076517791238122, 0.04215808150379556, -0.01580928131879029, 0.0018568048290408283, 0.0995936355235213, 0.005741137613437371, -0.09998040720894746, 0.014564360774097347, 0.11051993010111955, -0.05472815020876401, 0.007650821778577571, -0.09751473997895652, 0.042327294493602986, 0.03297226051710435, -0.08518639980304464, -0.0007535243595718955, 0.0423756401994143, -0.05081209368762666, 0.08803884475739741, -0.043439261831091626, 0.028234310893346246, -0.036332340414922296, -0.022323962303079998, 0.023834787249202998, 0.05380956972047773, -0.029177067254006008, -0.11429094346588729, 0.07662908506977181, -0.019024318060238653, -0.10123741568982715, -0.043245876994867816, 0.08726529736058797, 0.04631587460590368, -0.0605780691829893, -0.011730051347386077, 0.005747181380232886, 0.04235146835299791, 0.004604997020447362]}}, {'id': 'https://huggingface.co/papers/2410.10814', 'title': 'Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free', 'url': 'https://huggingface.co/papers/2410.10814', 'abstract': 'While large language models (LLMs) excel on generation tasks, their decoder-only architecture often limits their potential as embedding models if no further representation finetuning is applied. Does this contradict their claim of generalists? To answer the question, we take a closer look at Mixture-of-Experts (MoE) LLMs. Our study shows that the expert routers in MoE LLMs can serve as an off-the-shelf embedding model with promising performance on a diverse class of embedding-focused tasks, without requiring any finetuning. Moreover, our extensive analysis shows that the MoE routing weights (RW) is complementary to the hidden state (HS) of LLMs, a widely-used embedding. Compared to HS, we find that RW is more robust to the choice of prompts and focuses on high-level semantics. Motivated by the analysis, we propose MoEE combining RW and HS, which achieves better performance than using either separately. Our exploration of their combination and prompting strategy shed several novel insights, e.g., a weighted sum of RW and HS similarities outperforms the similarity on their concatenation. Our experiments are conducted on 6 embedding tasks with 20 datasets from the Massive Text Embedding Benchmark (MTEB). The results demonstrate the significant improvement brought by MoEE to LLM-based embedding without further finetuning.', 'score': 10, 'issue_id': 124, 'pub_date': '2024-10-14', 'pub_date_ru': '14 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –º–æ–¥–µ–ª—è—Ö Mixture-of-Experts (MoE) LLM –º–æ–≥—É—Ç —Å–ª—É–∂–∏—Ç—å –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª—å—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –º–Ω–æ–≥–æ–æ–±–µ—â–∞—é—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, –Ω–µ —Ç—Ä–µ–±—É—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏. –ê–Ω–∞–ª–∏–∑ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, —á—Ç–æ –≤–µ—Å–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ MoE (RW) –¥–æ–ø–æ–ª–Ω—è—é—Ç —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (HS) LLM, —à–∏—Ä–æ–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ MoEE, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π RW –∏ HS, –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —á–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø—Ä–æ–≤–æ–¥–∏–ª–∏—Å—å –Ω–∞ 6 –∑–∞–¥–∞—á–∞—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å 20 –Ω–∞–±–æ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Massive Text Embedding Benchmark (MTEB).', 'categories': ['#nlp', '#benchmark', '#dataset'], 'emoji': 'üß†', 'title': 'MoE LLM: –°–∫—Ä—ã—Ç—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏', 'embedding': [0.08637327886249895, -0.029413892819731103, 0.07169302301517033, -0.020312133779083162, 0.0006956438757852448, 0.06630136326102971, 0.1161608540933941, 0.08968301036660775, -0.025743828857898946, 0.15598437362763748, 0.03472547361843745, -0.057333066377410924, -0.04900535960684655, 0.024395913400233542, -0.0022153839698459093, -0.0913912603585175, -0.0069397570264843, -0.019578120986716734, 0.03336421651341531, 0.06982463380108093, 0.04529526032033924, -0.015214082671974792, -0.014813711774794786, 0.06544724241811681, 0.0715328796399487, 0.012985352901730167, 0.05012639645773378, 0.09859793027819463, 0.04230582387275766, -0.03541944900960773, 0.09875807157689528, -0.03822204632812826, -0.04713696208667319, 0.02687821358570588, -0.06683519527697837, 0.07158626284154357, 0.02666468077932642, 0.020632430912131367, 0.0028359582894316466, 0.06101647821616278, 0.04457459125185054, -0.03226986918680452, -0.055571435260427286, 0.05135419971181074, -0.0013662646353880203, 0.03226986918680452, 0.06026911754687664, 0.0480978534858178, 0.03379127797313225, 0.10292193223000093, -0.030508238069820896, 0.08343722976955423, 0.04105133109440426, -0.04121147862266787, -0.007934010434800512, -0.024943087063538937, 0.02105949237184831, -0.03325745011022557, -0.05242185543762408, 0.014706946409865551, 0.07660423603147816, -0.09160478901185498, 0.0017733080174631868, -0.010676548952049541, 0.04940572946576606, -0.04163854008238481, -0.1011603011130173, 0.012551618334161766, -0.007346800200907368, -0.0024122327606841344, -0.016949021149900496, -0.058827785639462206, 0.07772528118844935, -0.027065051676506427, -0.03365781996914508, -0.08306355358795313, -0.011897678890622942, 0.023541790480799657, -0.011383870558922737, -0.027518805775281298, -0.010402962120396845, -0.0473771844173291, 0.022033727494870644, -0.04142500935252634, -0.003673400100453684, -0.08183574410431321, 0.023915468738921735, -0.025303421597783288, -0.10756622716181344, -0.08920256570529593, -0.0483380758164737, -0.09881145893153212, -0.023568480005076102, -0.030828535202869097, 0.06213751506705, 0.05925484709917914, -0.03325745011022557, -0.11178346478695098, 0.03307061098116454, 0.12149912649289789, -0.02003187404723111, -0.05711953564755245, -0.045402022570486984, -0.028106014763261845, 0.10585797924642468, -0.12139235801318718, -0.06897050257556309, -0.03387135069900356, -0.10046632156880504, -0.025129926192599975, -0.05535790453056881, 0.02422242007157122, -0.04137162615093147, 0.04908543440923885, 0.10516400800829637, -0.04462797652996639, -0.0712659615554534, 0.022367370428317563, -0.07788542248714998, 0.03843557705798674, -0.04572232178005618, -0.014640217823176167, 0.08882888952369485, -0.043800541058287956, 0.04849822334473731, 0.05952176103063248, -0.05306244970372049, -0.014146427984421938, 0.008167560280561256, -0.012378124174891047, 0.04601592315926497, 0.04214567634449405, 0.08455826454392046, -0.03827542537668115, -0.11391877623857768, -0.03469878201764002, -0.11690820853311727, 0.04887190367938038, -0.04759071514718756, -0.024195729509034283, 0.007373491386400603, -0.03742130245724727, -0.006118996946830411, -0.03635364880795491, -0.08562592442277578, -0.013132155460203453, -0.02312807274496044, 0.01637515588579767, -0.06865020751903587, 0.019578120986716734, -0.06187060113559667, -0.15235434499048048, -0.07729821557569043, 0.08274325022534196, -0.1459484230947263, -0.08914918458022206, -0.057599980308864256, 0.003303057357996839, 0.09203184631852994, -0.0639525293856285, 0.05888116468801509, 0.10745946698818667, -0.014600181044936314, 0.034218341509370184, 0.06304502326459974, 0.13078773089216986, -0.06646151701885629, 0.017883220948247673, -0.05589173446999648, -0.1363395298684901, -0.03168265812230298, 0.011377197658723378, -0.09107096530199028, -0.040997947892809396, 0.03485893162242461, -0.04665651950188236, -0.026144198716818463, -0.13420422256990538, 0.06913065425686866, -0.03960999503394785, -0.036754018666874416, 0.11199699344028846, -0.06870359072063074, 0.07596364799494473, -0.08370414162448657, 0.051861335973919974, 0.03216310382187529, 0.07292083457533126, 0.06614122196232908, -0.021486553831565253, -0.044601282852647965, 0.12053823509375328, 0.12939977180374532, 0.05695938811928884, 0.0443076773203972, 0.033417597638489185, 0.12705092754573916, 0.0513275081110133, 0.01088340781996915, -0.07425540215607696, -0.012204630223272428, 0.023221495424272442, 0.023782011773195066, -0.13591247256181516, 0.024809630097812268, 0.06790285100279171, -0.0025990723050493716, 0.09000330749965595, -0.0646465006237568, 0.06827652926091379, 0.0550376094740416, 0.036567181614334365, 0.2018935324602337, -0.018750689668080276, -0.06555400882130655, 0.03128228826338347, -0.0746824636157939, 0.004497496318729103, 0.057333066377410924, 0.08840182806397791, -0.07030507015630878, 0.009228542483218952, 0.0586676360346776, 0.005451712741153364, -0.11989764705721984, 0.01275847616382088, -0.0527421504941513, -0.10975491973851402, 0.02765226170274747, -0.02166004923674857, 0.020725850476661888, -0.045508791050197714, -0.08978978092283946, -0.09875807157689528, 0.026611297577731553, 0.03392473390059842, -0.032696932723042464, -0.028426311896310046, 0.009268579261458803, -0.014159773784820653, 0.018443738335430792, 0.012778494033810558, 0.023168110146156586, -0.10783314524630876, -0.07943352495079613, 0.06427282444215571, -0.022834469289230656, -0.07873954540658387, 0.000495875662557637, -0.018190170204376167, 0.012618345882590655, 0.034672094569884564, 0.016281737359527648, -0.06534048224449004, -0.01533419300669435, 0.09229876647954625]}}, {'id': 'https://huggingface.co/papers/2410.11795', 'title': 'Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices', 'url': 'https://huggingface.co/papers/2410.11795', 'abstract': 'As one of the most popular and sought-after generative models in the recent years, diffusion models have sparked the interests of many researchers and steadily shown excellent advantage in various generative tasks such as image synthesis, video generation, molecule design, 3D scene rendering and multimodal generation, relying on their dense theoretical principles and reliable application practices. The remarkable success of these recent efforts on diffusion models comes largely from progressive design principles and efficient architecture, training, inference, and deployment methodologies. However, there has not been a comprehensive and in-depth review to summarize these principles and practices to help the rapid understanding and application of diffusion models. In this survey, we provide a new efficiency-oriented perspective on these existing efforts, which mainly focuses on the profound principles and efficient practices in architecture designs, model training, fast inference and reliable deployment, to guide further theoretical research, algorithm migration and model application for new scenarios in a reader-friendly way. https://github.com/ponyzym/Efficient-DMs-Survey', 'score': 10, 'issue_id': 124, 'pub_date': '2024-10-15', 'pub_date_ru': '15 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –æ–±–∑–æ—Ä –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–¥–Ω–æ–≥–æ –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∏ –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ª–µ—Ç. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ —Ä–∞–±–æ—Ç—ã –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ —Å–∏–Ω—Ç–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –∏ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–π –¥–∏–∑–∞–π–Ω. –û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–µ—Ç—Å—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –º–æ–¥–µ–ª–µ–π, –º–µ—Ç–æ–¥–∞–º –æ–±—É—á–µ–Ω–∏—è, –±—ã—Å—Ç—Ä–æ–º—É –≤—ã–≤–æ–¥—É –∏ –Ω–∞–¥–µ–∂–Ω–æ–º—É —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é. –°—Ç–∞—Ç—å—è –ø—Ä–∏–∑–≤–∞–Ω–∞ –ø–æ–º–æ—á—å –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è–º –∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º –±—ã—Å—Ç—Ä–æ –ø–æ–Ω—è—Ç—å –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –Ω–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö.', 'categories': ['#cv', '#video', '#multimodal', '#benchmark'], 'emoji': 'üåÄ', 'title': '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: –æ—Ç —Ç–µ–æ—Ä–∏–∏ –∫ –ø—Ä–∞–∫—Ç–∏–∫–µ', 'embedding': [0.08395502400454966, 0.0881918005160918, 0.10073488611836341, 0.012570955791380631, -0.022396369979509813, 0.012947248007120677, -0.07637343723901242, 0.019344218990730657, -0.06416483121137756, 0.061823457608774446, -0.010766144934731122, -0.10736877661072673, -0.06271541143121205, -0.0146196589371693, 0.055496171320643224, -0.020877263845850955, -0.0010705171447942684, -0.02171346899999753, 0.09750155869332268, 0.06572575040064338, 0.042562859547962094, 0.009595458133429569, 0.008264497485885262, -0.018521950485527277, -0.011839275607933948, -0.053768012344059035, -0.02288415580129909, 0.1692479953229017, -0.011449046743250703, -0.06483380072324224, 0.05379588356942718, -0.02172740461268161, -0.05438122697007796, -0.036486430868290176, -0.02401303265577105, 0.07732113143966808, -0.055468295950238576, 0.06962804111999406, -0.07146769121560556, 0.09270730586146142, 0.053600770484222425, -0.037545626550564405, 0.0038744184577234105, 0.10625384469527094, -0.04089044923966894, -0.02675857529528162, 0.0601510473004813, 0.0014502937611097122, -0.018521950485527277, 0.13245495196030643, -0.0643878217395052, 0.068457350173656, 0.05128726810698746, -0.10781476181201852, -0.05636024770015795, -0.05056255821690471, -0.06957229659673951, -0.11517336219446458, -0.05680622461137675, 0.0004237645311190751, 0.0881918005160918, -0.05421398925527784, 0.005679228485365618, 0.0230513976611357, 0.008229655759901356, -0.04495998181885624, -0.07509125310112881, 0.06288264914601217, 0.01718402182438911, 0.02464018807576967, -0.023121081942110808, -0.029908282826663156, 0.07007401803121287, -0.02164378471902242, -0.04089044923966894, -0.062994144410076, 0.007853362715154012, 0.012452492720974769, -0.016738044913170307, 0.042730099335280464, 0.07252688897039804, -0.011811401688292079, -0.0860734153690981, -0.06784413347511883, -0.10162683786828278, 0.011198184989754906, 0.03796372601886032, 0.00979754047573914, -0.0775441198952775, -0.15107445587965873, 0.0017290290197437283, 0.09850499948975114, -0.013874042312031244, 0.0888607700279565, 0.054297609148937026, -0.030521499525200328, 0.012557019142437433, 0.047607963770727936, 0.11628830861754809, 0.09694408444552181, -0.005463208872357376, -0.006703580576389514, 0.04208900726633865, 0.04214475593462968, 0.09588489083576583, -0.008362054650243117, -0.009992655011706673, -0.10034465994795388, -0.04618641521593059, 0.03932953005040313, -0.06366310770438596, -0.04788669882211013, 0.038437576227965516, 0.05226283975056601, -0.059983803368126434, -0.07040850175088609, -0.067007934538527, 0.005222799864633757, 0.021671658016908818, 0.04167090572552448, -0.09265156548324335, 0.097947531459505, -0.03336460077983153, 0.09081191538763185, 0.06750965597300035, -0.0772653806988588, 0.021755277910568, -0.1882019705268177, -0.028486732199347557, -0.016515056457560906, 0.07347458524357195, 0.01772755631446942, 0.10798199745430039, -0.07520274214763788, 0.014208523959186224, -0.0893067427941388, -0.0912021436305596, 0.015846093163250943, -0.06879183803836572, 0.01602727063577163, 0.004055596344747747, -0.0227029783287784, -0.07241539370633422, 0.09298604920291659, 0.015414053937234457, 0.008410833439673868, -0.0309117277681281, 0.041141306848128244, -0.021183870122601298, 0.07007401803121287, -0.0634401213212948, -0.04936399397268027, 0.002895361460211072, -0.07832458052616952, -0.03765711766959173, -0.13947906862307927, 0.05047893832324552, 0.11829519642795971, 0.011950769628486823, -0.002431964204129876, -0.04479273788650138, 0.11550785005917429, -0.1007906285690997, -0.010431663494827966, -0.04699474499967252, 0.017769365225039892, -0.15018250620225762, 0.03361545838829083, -0.06488954110146031, 0.010508314960389639, -0.0038395767317395044, -0.03381057147349559, -0.03311373695381748, -0.018786749924225396, 0.09014295209332188, 0.0022769176634064242, -0.06622747598015322, -0.08707686445559953, -0.02561575971934821, -0.07648492214048502, -0.08061020338796335, 0.12844115768681894, -0.012515208159348716, -0.028333428024713267, 0.020542782198695975, -0.025671508387639246, -0.07520274214763788, 0.025769064930241628, -0.005745428241414235, 0.005870859118162134, -0.05020020119934509, 0.09733431268844958, 0.051538129860483256, -0.021323238684551514, 0.0060067425334303865, 0.014536038629006466, 0.10848372096129197, 0.060095298632190264, 0.043064578909917196, -0.02937868394926692, 0.1192986475869794, 0.028626100761297776, -0.041336422005851255, -0.17036292723835747, -0.0451829682019474, -0.01825715311934741, 0.04769158366438712, -0.04944761801137595, -0.05254157687446645, -0.050646176038045644, 0.046771758616581366, 0.011093659604551366, 0.0956061578569019, 0.0012595344149836881, -0.0735303297668265, -0.0054353355744709815, -0.05663898067902189, 0.10486016529332348, 0.0551338143030836, 0.15018250620225762, -0.08133491742308259, 0.009442153337039802, 0.11483887847479135, -0.0019372092495868877, -0.02727423441495729, 0.017407010279998514, 0.016724109300486234, -0.048778650572029486, 0.03551085922471162, 0.0038709345545523913, 0.11188428610113282, -0.05959357512519867, -0.057865416148614485, -0.12654575685039815, 0.03146919787089248, -0.10251879376323862, 0.05507806563479257, 0.031775808292679314, 0.05909185161820708, -0.048778650572029486, -0.0003601780962271887, 0.023943349411055064, -0.019901690129754162, 0.024654123688453742, 0.019190915852355488, 0.08579468239023415, -0.08005273743023546, -0.03116259159414214, 0.008598979754795715, 0.038437576227965516, 0.03676516591967237, 0.0017778076019226558, -0.004348268459576784, -0.0427579747056851, 0.039273781382112086, -0.05585852419316635]}}, {'id': 'https://huggingface.co/papers/2410.10816', 'title': 'LVD-2M: A Long-take Video Dataset with Temporally Dense Captions', 'url': 'https://huggingface.co/papers/2410.10816', 'abstract': 'The efficacy of video generation models heavily depends on the quality of their training datasets. Most previous video generation models are trained on short video clips, while recently there has been increasing interest in training long video generation models directly on longer videos. However, the lack of such high-quality long videos impedes the advancement of long video generation. To promote research in long video generation, we desire a new dataset with four key features essential for training long video generation models: (1) long videos covering at least 10 seconds, (2) long-take videos without cuts, (3) large motion and diverse contents, and (4) temporally dense captions. To achieve this, we introduce a new pipeline for selecting high-quality long-take videos and generating temporally dense captions. Specifically, we define a set of metrics to quantitatively assess video quality including scene cuts, dynamic degrees, and semantic-level quality, enabling us to filter high-quality long-take videos from a large amount of source videos. Subsequently, we develop a hierarchical video captioning pipeline to annotate long videos with temporally-dense captions. With this pipeline, we curate the first long-take video dataset, LVD-2M, comprising 2 million long-take videos, each covering more than 10 seconds and annotated with temporally dense captions. We further validate the effectiveness of LVD-2M by fine-tuning video generation models to generate long videos with dynamic motions. We believe our work will significantly contribute to future research in long video generation.', 'score': 10, 'issue_id': 123, 'pub_date': '2024-10-14', 'pub_date_ru': '14 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç LVD-2M –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ. –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç 2 –º–∏–ª–ª–∏–æ–Ω–∞ –≤–∏–¥–µ–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –±–æ–ª–µ–µ 10 —Å–µ–∫—É–Ω–¥, —Å–Ω—è—Ç—ã—Ö –æ–¥–Ω–∏–º –∫–∞–¥—Ä–æ–º –∏ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞–µ–º—ã—Ö –ø–ª–æ—Ç–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–µ—Ç–æ–¥–∏–∫—É –æ—Ç–±–æ—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏ –ø–æ –¥–æ–æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ.', 'categories': ['#dataset', '#video', '#benchmark', '#multimodal'], 'emoji': 'üé•', 'title': 'LVD-2M: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ', 'embedding': [0.03350044880537811, 0.036083366872931004, 0.01366363713911428, -0.06483124652043631, -0.03685824488593277, -0.00040802036008987945, 0.05971706848740797, -0.06643265416667757, -0.036729094229205984, 0.09680776727054301, 0.08415147824623206, -0.09530968447090965, -0.10166365911441048, -0.11943413697481595, 0.02474435621067566, -0.03822718567129231, 0.06700089761075621, -0.046931622324530534, -0.02027590553392231, 0.052252434926481975, -0.05563605681715551, -0.03799472529225032, 0.030168482856168802, -0.04651835534729754, 0.052278262897214094, -0.046879964222453066, -0.030788384402324915, 0.09060877341511431, 0.09520636394552823, -0.12697625876916477, 0.03135662568579031, -0.06415968471158949, -0.16654657237937723, -0.02792134353242607, -0.03980276966802795, 0.08642443905886718, 0.032467280281989, 0.050728511192437056, -0.05263987393298286, -0.03701321703155193, 0.06632933580190939, -0.046105088370064544, 0.03311301087918384, 0.020857064043673632, 0.012204287869187449, -0.018222488954349886, 0.004487820142373162, 0.029161146624738295, -0.028773707618237415, 0.06612270555421276, -0.04662167371206572, 0.07945056719043674, -0.02298797209758875, -0.01181039338243281, 0.0698421040280832, -0.033552106907455574, -0.015859117280472918, -0.08849077178441891, -0.0304526034979015, -0.0663809960646001, -0.005821251681171876, -0.0810519705154515, -0.020159675344401315, 0.02446023556894296, 0.018041684516772124, -0.033629594060571776, -0.10827593075013837, 0.03084004250440238, 0.04721574512687648, 0.0002899729219806846, 0.00580510844324967, 0.02965189967478087, 0.05054770891547254, 0.01589786139718433, -0.07051366583693003, -0.00749691960464776, 0.011203407766194674, -0.008988555134357678, -0.059820384691562915, -0.020211333446478786, 0.05429293968130159, 0.09055711315242361, -0.07557618792849415, 0.022458472770221515, -0.12325685381345458, 0.011196950341388996, -0.019191082149375604, -0.02934195106231606, -0.049514542552696675, 0.022277668332643753, -0.06824070070306844, 0.11488820022525302, -0.026862349198918094, 0.04512357794875291, 0.019333141389935332, 0.0032060471377745657, 0.05147755907409346, -0.0928300782862852, 0.0876642464724059, 0.07304492580240546, -0.08286001489122913, -0.007645437782442435, 0.019901384834013974, -0.0009072499712279558, -0.04904961531277297, -0.004691225026617482, 0.0012123572543821719, 0.05413796537506919, -0.031382453656522424, 0.0049204591779618626, -0.00708365284347609, -0.06137013423572671, -0.07221838968732623, 0.012572353520964676, 0.01873907213573782, -0.15332202046546844, -0.06793074560876389, 0.024641037845907477, 0.07381980381540723, 0.044942775671788386, 0.0023197834622700067, 0.10734608059151744, 0.05687585774885449, -0.09660113702284637, 0.10579632888674041, -0.04972117280039331, 0.05191665402205857, -0.05723746446339677, 0.037219847279248555, -0.056307612144162605, -0.01703434396411513, 0.0055532740613000574, 0.06483124652043631, 0.026578228557185397, -0.112098647588777, 0.019513945827513094, -0.15249547786854947, 0.005843852343899759, -0.058787218328787055, 0.10026888171586584, 0.009046670661240822, -0.08626946259202153, 0.020133847373669207, 0.07857237297328003, 0.007438804077764614, -0.018777814091835987, -0.009033756243752118, 0.007690638891836876, -0.06359144342812408, 0.06648431226875504, -0.10899914850044942, -0.03796889732151821, 0.009104786836307941, 0.044942775671788386, -0.05408630727299171, -0.11592136658802889, -0.07283829123348236, 0.032751400923721696, 0.06090520915641624, -0.0876642464724059, 0.012759616031532089, 0.03381039957845616, 0.02996185044785893, 0.06369475963227902, -0.028489586976504715, 0.1184009706120401, -0.0961362162647624, 0.0029994138652193933, -0.09892576674062516, -0.08487469383592987, 0.02307837431637763, -0.0019775466454701883, -0.013011449981359053, -0.043496342331779535, 0.10879250961029982, -0.0669492373480655, -0.1638603251439899, 0.007031994525337298, -0.006244204687582723, -0.04285061065427807, -0.06116350182741684, 0.1096190435647658, -0.11003231918445178, -0.013076023365170525, -0.07666101239334748, 0.056307612144162605, 0.010409160503634421, 0.07743589040634923, 0.09851249544216568, -0.02957441360197129, -0.10693281145367121, 0.00471382547328404, 0.07686764480165735, 0.011784564331394074, 0.020766662905191375, -0.030478433629246855, 0.09675610700785228, 0.050806001586473123, 0.1494993122692828, -0.07423306647141373, 0.07976051148167505, 0.06715587191698862, -0.029471095237203107, -0.1551817251039368, -0.011261522428832521, -0.037607288446362686, -0.05269153203506033, 0.049282075691814954, -0.1361714398299926, -0.060388625975028316, 0.04217905316665773, 0.03585090433327577, 0.09530968447090965, 0.058115656519940224, 0.04026769474733841, -0.01356031985465272, -0.10037219575940753, 0.03029763135228234, 0.08564956104586542, -0.0011090405316800558, -0.011358382720611052, 0.0011009688479005557, 0.04158498391246022, 0.01642735964424494, -0.027895515561693958, -0.051555045146903046, -0.042514834071081135, -0.024963904764964833, 0.010544763399695093, -0.07893397752720907, 0.03512768658296472, -0.03740065603805281, -0.031098334095096346, -0.08084533594652839, -0.026009985113106752, -0.06545114590597917, 0.06715587191698862, 0.024421490371924925, 0.07635105945965617, -0.01522630174895075, 0.10527974786596572, 0.04525272644486645, -0.04832639756246192, 0.002674934480497206, -0.01972058039643621, 0.10083712515994449, -0.08482302709139944, -0.08601117640286068, 0.014076903036040651, -0.021464050524157067, -0.00564367584796629, -0.13865104601461706, -0.037478142110862395, -0.11664458433833994, -0.020572944482247554, -0.03267391485091212]}}, {'id': 'https://huggingface.co/papers/2410.11805', 'title': 'NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models', 'url': 'https://huggingface.co/papers/2410.11805', 'abstract': 'Large language models (LLMs) combined with tool learning have gained impressive results in real-world applications. During tool learning, LLMs may call multiple tools in nested orders, where the latter tool call may take the former response as its input parameters. However, current research on the nested tool learning capabilities is still under-explored, since the existing benchmarks lack of relevant data instances. To address this problem, we introduce NesTools to bridge the current gap in comprehensive nested tool learning evaluations. NesTools comprises a novel automatic data generation method to construct large-scale nested tool calls with different nesting structures. With manual review and refinement, the dataset is in high quality and closely aligned with real-world scenarios. Therefore, NesTools can serve as a new benchmark to evaluate the nested tool learning abilities of LLMs. We conduct extensive experiments on 22 LLMs, and provide in-depth analyses with NesTools, which shows that current LLMs still suffer from the complex nested tool learning task.', 'score': 8, 'issue_id': 127, 'pub_date': '2024-10-15', 'pub_date_ru': '15 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç NesTools –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ –æ–±—É—á–µ–Ω–∏—é –≤–ª–æ–∂–µ–Ω–Ω–æ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤. NesTools –≤–∫–ª—é—á–∞–µ—Ç –º–µ—Ç–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã—Ö –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏. –î–∞—Ç–∞—Å–µ—Ç –ø—Ä–æ—à–µ–ª —Ä—É—á–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∏ –¥–æ—Ä–∞–±–æ—Ç–∫—É, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –µ–≥–æ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–µ–∞–ª—å–Ω—ã–º —Å—Ü–µ–Ω–∞—Ä–∏—è–º. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ 22 LLM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NesTools –ø–æ–∫–∞–∑–∞–ª–∏, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤—Å–µ –µ—â–µ –∏—Å–ø—ã—Ç—ã–≤–∞—é—Ç —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å–æ —Å–ª–æ–∂–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º.', 'categories': ['#benchmark', '#dataset', '#nlp', '#rlhf'], 'emoji': 'üõ†Ô∏è', 'title': 'NesTools: –Ω–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –≤ LLM', 'embedding': [-0.0011571742166324825, 0.05000139322181262, 0.15168618066821116, -0.14108446730191207, 0.013150214059183324, -0.012959076306909158, 0.050434637057632736, 0.07742315868049222, -0.07538436333418881, 0.08761712339353857, 0.04933878688757335, -0.12151204720079554, -0.031040619135977388, -0.06177542027201026, 0.0534673399022166, -0.012691485056188091, 0.05841141426030675, -0.0466883555413809, -0.06590397929588887, 0.07563921300286154, 0.05372218756781088, -0.021636688596124352, 0.0689621653045694, -0.06789180030168514, 0.09459998107946142, -0.05316152190227209, 0.03784509066706666, 0.05127563956209784, 0.042177525019110866, -0.030199618634590735, 0.07100095864779436, -0.031448379807700835, -0.14353101530762513, 0.05876820059152305, 0.037615724162490594, 0.056066800914058815, 0.09990084978108169, 0.03787057583424178, -0.03040349596583478, 0.1230411472159104, 0.013570714309876646, -0.004937701163371834, -0.025727014861544155, 0.044114377693635354, -0.048574235878476694, 0.03483787298965791, -0.01673084299033611, 0.045031833696547355, -0.0363669669955374, 0.04908393521582217, 0.002919615044284751, 0.0372589378312743, -0.015864357321774342, -0.09194955373942587, -0.0379725144998638, -0.09893241743458407, 0.022146385930391366, 0.007537162175214047, 0.030428983136088352, 0.02400678510646895, -0.0690131376419981, -0.08980882373365734, 0.03562790315669432, 0.04949169588754561, -0.07202035131324994, -0.10056345611532094, -0.030021222464364904, 0.02068100384091044, 0.018170739912641915, -0.006059037101529873, -0.04880360037997431, 0.0033544511271682517, -0.0189862572499319, -0.010372357878654506, 0.06294772193743808, 0.011875967718898109, 0.003188799343300588, 0.0426362540221061, -0.018285422163390724, 0.04148943151461802, 0.054486738576907535, -0.009639666833914042, 0.01819622708289549, -0.0480900237113848, -0.022350265264713863, -0.07976776401442634, 0.04329886235942382, -0.07166356898819055, -0.10459006645818528, -0.07920710235504445, -0.051428548562070096, -0.08838167039647833, 0.06468070529303234, 0.05104627506060022, 0.11733252385180205, 0.03519465932087421, 0.03305392931510568, -0.11855579985773704, 0.07976776401442634, 0.09526258541062223, 0.012513090889040715, 0.02552313753030011, 0.035092720655252194, -0.09816787043164434, 0.0563216485796531, -0.007518048199678786, 0.028721492959983025, -0.05708619958874975, -0.0808891013547393, 0.029537010297273007, -0.18033122413590422, -0.06019535392870207, -0.099442118775008, -0.05061303122478011, 0.02823728079289113, -0.056372620917081784, -0.03394590015084257, 0.04013873367896435, 0.011990649969646914, -0.004077585684910697, -0.001922517923996676, -0.055251285579847285, 0.09500774375426332, -0.005262633739775149, 0.07930904102066647, 0.0030008482885395026, 0.016947465909785395, -0.026835608616730323, 0.04100521934752612, -0.048829087550227884, -0.04921136105169776, 0.03236583380753438, -0.0181834834977687, -0.026147517115315932, -0.10785213981350211, -0.014781247732224065, -0.14954545066244265, 0.08292789670104271, -0.04001130784308876, -0.01743167807687729, 0.016080978238145173, 0.005310417777228, -0.013252152724805344, 0.06595494362100374, -0.07966582534880433, 0.05040915189045761, 0.01670535782316099, 0.033079410476123894, -0.02570153069590826, 0.13578360060337027, -0.0894520353993626, -0.07023641364793307, -0.01892254533353333, 0.019827259754397003, -0.13068662726070016, -0.04332434352044203, -0.0582075329229058, 0.05723910858872201, 0.04360468035936834, -0.04024067234458638, 0.02737079312125091, 0.03618857082531157, -0.0031187156343386252, 0.15668121734833773, -0.057137167920021534, 0.14077863728349685, -0.043120466189197994, 0.04454762152945546, -0.14220580063606814, -0.02681012445109443, 0.010487040129403312, -0.0725300546567523, 0.026784640285458537, -0.002847938687643708, 0.012213642678581138, -0.02884891879585862, -0.12161398386333912, -0.08685256837828502, 0.02269431201696028, -0.04816647921291016, -0.061010875272148955, 0.11988101452929403, -0.1243663618874674, 0.011041337006996397, -0.128138122561659, -0.017979602160367755, 0.011162390048769372, -0.022605114933386596, -0.0016246630222320681, -0.03562790315669432, -0.07813673134292481, 0.06911508031377703, 0.11580342984592257, 0.10754632381663605, 0.019546926921627607, -0.0823162546919183, 0.08302983536666472, 0.09021658039922388, -0.0418717090222448, -0.006670675104497361, 0.08496668203195386, 0.004558613157567967, 0.027039489954131274, -0.07084804764474364, 0.08486474536941029, 0.017240540324603124, -0.025879925864594866, 0.04426728669360761, -0.0153673999670929, -0.09719944209130361, 0.029715404464420385, 0.09567035209158103, 0.0593288682601403, -0.027702096288370545, -0.05112272855904712, 0.010283161195696507, -0.06850343630157417, -0.02000565392154438, 0.02391758802289526, 0.14322519730768063, 0.0354495109926254, 0.010391472254805459, 0.047784205711440285, 0.026529790616785804, -0.03384396148522055, -0.024350830857176143, 0.004555427862209806, -0.1243663618874674, 0.08929912039015497, -0.05937983859449054, 0.02997025413309312, 0.029154736795803136, 0.02050260967376306, -0.08960494439933485, -0.04467504736533105, -0.012003392753542319, -0.05484352490812384, -0.06396712261520747, -0.019266592085779754, -0.019151909835030945, 0.08517057138166861, 0.033563626649372694, -0.007396995157905812, -0.038176391831107846, -0.017087633327709323, 0.028925372294305522, 0.017240540324603124, 0.02790597662423227, 0.09149082874258754, -0.07798383035526638, 0.05407897790518409, -0.05718813825437177, -0.00666430411316535, -0.05948177726011256, -0.012716970223363211, 0.06289675761232322]}}, {'id': 'https://huggingface.co/papers/2410.11419', 'title': 'GS^3: Efficient Relighting with Triple Gaussian Splatting', 'url': 'https://huggingface.co/papers/2410.11419', 'abstract': 'We present a spatial and angular Gaussian based representation and a triple splatting process, for real-time, high-quality novel lighting-and-view synthesis from multi-view point-lit input images. To describe complex appearance, we employ a Lambertian plus a mixture of angular Gaussians as an effective reflectance function for each spatial Gaussian. To generate self-shadow, we splat all spatial Gaussians towards the light source to obtain shadow values, which are further refined by a small multi-layer perceptron. To compensate for other effects like global illumination, another network is trained to compute and add a per-spatial-Gaussian RGB tuple. The effectiveness of our representation is demonstrated on 30 samples with a wide variation in geometry (from solid to fluffy) and appearance (from translucent to anisotropic), as well as using different forms of input data, including rendered images of synthetic/reconstructed objects, photographs captured with a handheld camera and a flash, or from a professional lightstage. We achieve a training time of 40-70 minutes and a rendering speed of 90 fps on a single commodity GPU. Our results compare favorably with state-of-the-art techniques in terms of quality/performance. Our code and data are publicly available at https://GSrelight.github.io/.', 'score': 7, 'issue_id': 121, 'pub_date': '2024-10-15', 'pub_date_ru': '15 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –æ—Å–≤–µ—â–µ–Ω–∏—è –∏ —Ä–∞–∫—É—Ä—Å–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –ê–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏ —É–≥–ª–æ–≤—ã—Ö –≥–∞—É—Å—Å–∏–∞–Ω–æ–≤, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ—Ü–µ—Å—Å —Ç—Ä–æ–π–Ω–æ–≥–æ —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥–∞. –î–ª—è –æ–ø–∏—Å–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç—Ä–∞–∂–µ–Ω–∏—è, —Å–æ—Å—Ç–æ—è—â–∞—è –∏–∑ –ª–∞–º–±–µ—Ä—Ç–æ–≤—Å–∫–æ–π —Å–æ—Å—Ç–∞–≤–ª—è—é—â–µ–π –∏ —Å–º–µ—Å–∏ —É–≥–ª–æ–≤—ã—Ö –≥–∞—É—Å—Å–∏–∞–Ω–æ–≤. –ú–µ—Ç–æ–¥ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö –ø—Ä–∏ –±—ã—Å—Ç—Ä–æ–º –æ–±—É—á–µ–Ω–∏–∏ –∏ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–µ.', 'categories': ['#cv', '#rl', '#multimodal'], 'emoji': 'üé®', 'title': '–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –æ—Å–≤–µ—â–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–∞—É—Å—Å–∏–∞–Ω–æ–≤', 'embedding': [-0.0240430555213835, -0.02645137684060785, 0.08552210666143689, -0.03684728906669504, -0.03093352697206664, -0.10141701435194758, 0.05908410631040403, -0.0684497923751615, -0.05212673939547591, -0.005391959901418043, 0.03933588450913436, 0.022718481507553855, -0.03615155107356523, -0.07931399237551856, 0.04310892232728335, 0.051939422984130956, -0.02448458163892338, -0.06497111108709244, -0.07235662546059045, 0.05303654894849566, -0.051002856113171215, -0.11335157215175436, 0.02437754585897841, 0.058174296757384274, 0.0019149485051508572, -0.04642704886073745, 0.09156965751516025, 0.025073281682713222, 0.01830322900973505, -0.032003890195003847, -0.005682965150100714, -0.021193212423409272, -0.02790974829111246, -0.11720488409311833, -0.017473695749325276, 0.07728029954019411, 0.018410264789680025, 0.17479047646792273, -0.13379552760736382, 0.05977984213413884, 0.01875813378624493, 0.05913762094628401, 0.08969652160384575, 0.06877090622318141, 0.10329014592447208, 0.03872042497800954, -0.01594842753293869, 0.010957853650300038, -0.00492033039108892, 0.021099553133039295, -0.0835954452672674, 0.09884813610871328, 0.010068113170432779, -0.01542662425503083, -0.0403259725241591, -0.10382532916298694, -0.02253116726560391, 0.012202152673156701, 0.01564069733349727, -0.020724928987929398, -0.019025724320804856, -0.07995620705518838, -0.011479656060449896, 0.05078878238388627, 0.007311925457917524, -0.0573180040096395, -0.044393358194808, 0.06202760869874823, 0.04005838198959918, 0.012978166308077991, 0.03601775580628526, 0.05758559454419943, 0.07749437326947906, -0.08525451178808695, -0.06941311873345624, -0.0159082885188757, 0.012362707427771657, 0.019159519588084824, 2.6968161440120834e-05, 0.026826005324507747, -0.0020989174315398074, 0.08755579515797132, -0.024243748422303448, -0.05726448720436452, -0.05747855876425446, -0.08723469215692642, 0.02750836031987756, -0.0942990883436145, -0.162695370421686, 0.10066775955354278, 0.04872833006122683, 0.03965699618775928, -0.02188894824714408, -0.02911390569663213, 0.03700784382131, 0.06604147322533215, 0.03989782940437922, 0.026665448400497792, 0.16301647559212593, 0.057103934619144564, 0.007994283056561339, 0.0662020258105521, 0.029435015205862045, -0.09553000957525917, 0.16729793716145477, -0.05020008234009642, 0.055712460802279935, 0.07845769528898379, 0.07187496336614058, 0.07257068834290038, -0.06331204456627289, -0.02048409577130946, 0.0403259725241591, 0.03556285319917039, -0.013740801067089786, -0.07872528365414873, -0.058388370486669214, -0.0058702791751111625, -0.015185793207805895, -0.01867785640893745, -0.10666179794078116, 0.014142187085869177, 0.04787204165227206, -0.034867113036645574, 0.07669160166579927, -0.06390074461006272, 0.06684424482901193, -0.13507996781367848, 0.020577750722889435, 0.0037395850964179887, 0.0447679823399179, -0.0654527731815423, 0.007091163266905583, -0.06946663553873121, -0.09462019568344943, -0.004448701314638797, 0.02940825788792205, 0.03310101290527605, -0.040433010473499065, 0.06673721121846196, -0.02892659362407718, 0.10200571222634243, 0.024912726928098265, 0.04902268442191175, 0.02483245063548829, 0.04904944173985174, -0.11228120784411964, 0.05432098481602031, -0.03446572723480568, 0.0820969400092478, -0.04110198680989889, -0.016282915918078098, -0.13754181244636282, -0.05464209215585522, -0.062455753987923114, -0.1543465101653383, -0.036392382120790163, 0.09403149780905458, -0.05870947782650413, -0.06716535650763684, 0.04832694425938694, 0.008295323058759758, 0.02863224360218226, 0.02972936739715196, -0.1138867510514792, 0.012295809794131677, -0.1246974320771663, 0.036231829535570206, -0.11602748834432863, -0.13625735705428316, -0.05156479450023106, -0.05116340869839117, -0.03350240087651094, -0.07208903492603051, 0.07572827096871453, 0.02693303893505772, 0.016630784480764004, -0.0008157346065676232, -0.04185124160830368, -0.019146140929114822, -0.06791460696725163, 0.0876628287685213, -0.018249710035065068, 0.03427841516225073, -0.03136167226124152, 0.07530012351014465, 0.002664203628964905, -0.023347319697648687, 0.009579759794042412, 0.0769056667175042, -0.11859636007937793, 0.10462809859727171, -0.01815605399878759, 0.1013099720638176, 0.004672808929681487, -0.04998600861081149, 0.06909201139362132, -0.00011613033936131704, -0.014490055214676082, 0.002023657430990203, 0.08343489485144245, 0.08627135929044667, 0.005465547298422023, -0.1176330315516882, 0.03088000799739665, -0.0004137208516507975, 0.043724377519618184, -0.10468161757194169, -0.11217417423356968, 0.0454904776509877, 0.04990573014880651, 0.007666483567027927, 0.07246365907114041, -0.0020671410013259413, -0.06138538968028841, 0.005492306568817515, -0.0014324484168000754, 0.014262603260300145, 0.029301219938582077, 0.0414230941497338, -0.05303654894849566, 0.0551237585890951, 0.03631210799757518, -0.04096819154261892, 0.029622329447811995, 0.05389284169624043, 0.10612661253287131, -0.1298351798860549, 0.07246365907114041, -0.08541506220391192, 0.01927993619639479, 0.012583469401844098, -0.028899834136742186, -0.02115307210770928, 0.02283889811586383, -0.06572036588549723, 0.013232377749788924, -0.12116523398382226, -0.036552939044800115, -0.02964909110454199, 0.009265340698994996, 0.012529951077992613, 0.035696648466450355, -0.07706622581090916, 0.034385453111590705, 0.0917302144391702, -0.06534573740159734, -0.02452472086992587, 0.05070850609127629, 0.004054004625344404, -0.04059356305871902, -0.07540716362887961, -0.05343793475033555, -0.08921485734000088, -0.0377303413017748, -0.010529708361125153]}}, {'id': 'https://huggingface.co/papers/2410.09754', 'title': 'SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning', 'url': 'https://huggingface.co/papers/2410.09754', 'abstract': "Recent advances in CV and NLP have been largely driven by scaling up the number of network parameters, despite traditional theories suggesting that larger networks are prone to overfitting. These large networks avoid overfitting by integrating components that induce a simplicity bias, guiding models toward simple and generalizable solutions. However, in deep RL, designing and scaling up networks have been less explored. Motivated by this opportunity, we present SimBa, an architecture designed to scale up parameters in deep RL by injecting a simplicity bias. SimBa consists of three components: (i) an observation normalization layer that standardizes inputs with running statistics, (ii) a residual feedforward block to provide a linear pathway from the input to output, and (iii) a layer normalization to control feature magnitudes. By scaling up parameters with SimBa, the sample efficiency of various deep RL algorithms-including off-policy, on-policy, and unsupervised methods-is consistently improved. Moreover, solely by integrating SimBa architecture into SAC, it matches or surpasses state-of-the-art deep RL methods with high computational efficiency across DMC, MyoSuite, and HumanoidBench. These results demonstrate SimBa's broad applicability and effectiveness across diverse RL algorithms and environments.", 'score': 6, 'issue_id': 125, 'pub_date': '2024-10-13', 'pub_date_ru': '13 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É SimBa –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL). SimBa –≤–∫–ª—é—á–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞–±–ª—é–¥–µ–Ω–∏–π, —Ä–µ–∑–∏–¥—É–∞–ª—å–Ω—ã–π –±–ª–æ–∫ –ø—Ä—è–º–æ–π —Å–≤—è–∑–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Å–ª–æ–µ–≤ –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Å–º–µ—â–µ–Ω–∏—è –∫ –ø—Ä–æ—Å—Ç–æ—Ç–µ. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ SimBa —É–ª—É—á—à–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ RL, –≤–∫–ª—é—á–∞—è off-policy, on-policy –∏ unsupervised –º–µ—Ç–æ–¥—ã. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è SimBa –≤ –∞–ª–≥–æ—Ä–∏—Ç–º SAC –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–æ—Å—Ç–∏—á—å –∏–ª–∏ –ø—Ä–µ–≤–∑–æ–π—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã RL –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö —Å –≤—ã—Å–æ–∫–æ–π –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é.', 'categories': ['#rl', '#deeplearning', '#architecture', '#scalability'], 'emoji': 'ü§ñ', 'title': 'SimBa: –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º', 'embedding': [0.05562089720289916, -0.023483124144785164, 0.09150807997460408, 0.004806570104994543, 0.021918522634977233, 0.009317135016108546, -0.015082199762322538, 0.029995252624533602, -0.08259970862075855, 0.05925754092284945, -0.003233158399186959, -0.10182599280336581, -0.08868897194057779, 0.04090518169403498, 0.04648700431351979, -0.08851982504046631, -0.015927930082180936, 0.06709464160815733, 0.02779635337483187, -0.04473916067698268, -0.02160842346868868, -0.03196862406765302, 0.08620815979712394, 0.05937030273579111, 0.021030506635265712, -0.05477516688304076, 0.038367988644110305, 0.06410639921611651, -0.009634283467985547, -0.10086749439951728, 0.06726379477931727, -0.05429591663594174, -0.15538893048064337, -0.06997012845830497, 0.003992554358578413, 0.08288161942416118, -0.027274819538229227, -0.004024269350090577, -0.025639739804983262, 0.04011583228064742, 0.09094425627744933, -0.08767409263025842, -0.0661925303818281, 0.10921204414655755, -0.06957546002265966, 0.02004382195888075, -0.0023574746253324503, -0.05353476185648858, 0.0037282633200702397, 0.13001702088489148, -0.11406089616877613, 0.05206882902335409, -0.08406564145389304, -0.07589024278766322, 0.010092387112528911, 0.053675716213015146, 0.07464984403215952, -0.05040555883687271, 0.01694280730215081, 0.04879866955686217, -0.005345723915526593, -0.04338599174713934, -0.030840982944391995, 0.03684567281415549, -0.021974905631797555, 0.04586679970989421, -0.15065284654241493, 0.05254807299940463, 0.02004382195888075, 0.036648335460808604, 0.009613140419024037, -0.05863733422887437, 0.060497945949401624, -0.021622518695306386, -0.05483154987986108, -0.013214544400150465, -0.021918522634977233, 0.13869985189005773, 0.0006444292876136906, -0.019761911155478117, 0.011459652732234598, -0.08237418499487523, 0.026302227998112476, -0.1437742379899071, -0.030728219041100843, -0.07295838130209323, -0.08181036338806996, -0.05184330121677178, -0.036028135037882006, 0.0036472139902213527, 0.08970384707019817, -0.00833044824937409, -0.08682836022005053, 0.05387305565671153, 0.10193875670665697, 0.05863733422887437, 0.07808914412771445, 0.010092387112528911, 0.11310240612632556, 0.11129817531226914, -0.019888769240212233, -0.02586526761156557, 0.04192005682365536, -0.0019892293151384135, 0.0559309984595372, -0.08158483140078868, 0.029600577917839817, 0.0010139960540454431, -0.07538281044872676, -0.05254807299940463, -0.04775559979330739, -0.015223154118849109, -0.027472154801226625, 0.033857424151066205, 0.02414561651861336, -0.09573673157389608, -0.01854969449181186, 0.04268121578380752, -0.12674686350874903, 0.017633488038864928, -0.018070448425411834, -0.03774778404048472, 0.016618610818895055, -0.07893487862827182, 0.030305353881171643, -0.021509754792015234, 0.014814385021677413, -0.02633042054169738, -0.10278448284581639, 0.016407178238930457, -0.0396365841238979, 0.008351591507370549, 0.064275541935529, -0.05669215532933986, -0.11671085103164247, -0.04017221527746774, -0.16226755157524814, -0.02170709005501263, -0.018056353198794128, -0.0833326750373258, 0.0018729413752543891, 0.009895051013391715, -0.059144774929208804, -0.05494431169280274, -0.05717140348608938, 0.07132330365919676, 0.010134674882731527, 0.07904764253156298, -0.13757221285714621, 0.05125128706638162, -0.020706310152009962, 0.01491305286221106, -0.13655734817927329, -0.020001533143503388, -0.09669521952599715, -0.08987299187996016, -0.07081585668781387, 0.0721690235273077, 0.10120579238043921, -0.07278923440198176, 0.0475864549835454, 0.03690205581097581, 0.0017020333138897691, 0.034393053214286554, 0.05953945172625208, 0.05328103941597187, -0.08141568450067721, 0.01754891458880919, -0.1251681625916244, -0.0866028365941672, 0.0424274975239898, 0.006646034804896251, -0.026851952287950537, -0.04293493613397473, 0.0010351393956558824, -0.004013697407539923, -0.06416277594188835, -0.1540357761832465, -0.017985874975356093, -0.08085186498422144, 0.002628813277149477, -0.009140940711723165, -0.08705389220733183, 0.034280289310995395, -0.11242581852587966, -0.03856532808780668, -0.1268596211409917, 0.05612833581288409, 0.019705528158657795, 0.003742358755722897, 0.027204341314791197, 0.09043681348676541, 0.02022706199526044, 0.05615652626611951, 0.04679710557015784, 0.014370375976646907, 0.059032013116267136, 0.050602896190219605, -0.015533255375487153, -0.08152845258466734, -0.005204768513825279, -0.02139699088872408, 0.07769446524032168, -0.10323554682037896, 0.03326541418137501, -0.0866028365941672, -0.033462749444372414, 0.04237111243681998, -0.09663884280022529, -0.05858095750310253, -0.03374465815742555, -0.018338264002196753, 0.08761771381413709, -0.05178691821995146, -0.1294531971877367, 0.055057077686443384, -0.03960839367066248, 0.006822228482176784, -0.039100955060677546, 0.0932559215207917, 0.07769446524032168, -0.04411895816370658, 0.0571995918489753, -0.0424274975239898, -0.13204677114413224, -0.05111033480020454, 0.056720347872924765, -0.09043681348676541, 0.10013452798295004, -0.027415773894755795, 0.08801238852083086, 0.052717221989865594, -0.046571577763575525, 0.005617061940238772, -0.008478451264384259, -0.035718031690894464, -0.006054023371960424, 0.039185528510733286, 0.07487536765804285, -0.029544197011368987, -0.013588075012707992, 0.07295838130209323, 0.024300666101757636, 0.007787771363809934, 0.026626424481368226, 0.08688474948791934, 0.006903277812025671, -0.03938286586408018, -0.05858095750310253, 0.07549556808096944, 0.006290123121093385, -0.06004689033623701, -0.034223908404524564, -0.014588856378955309, -0.05068746754992585, 0.026908335284770858]}}, {'id': 'https://huggingface.co/papers/2410.10934', 'title': 'Agent-as-a-Judge: Evaluate Agents with Agents', 'url': 'https://huggingface.co/papers/2410.10934', 'abstract': 'Contemporary evaluation techniques are inadequate for agentic systems. These approaches either focus exclusively on final outcomes -- ignoring the step-by-step nature of agentic systems, or require excessive manual labour. To address this, we introduce the Agent-as-a-Judge framework, wherein agentic systems are used to evaluate agentic systems. This is an organic extension of the LLM-as-a-Judge framework, incorporating agentic features that enable intermediate feedback for the entire task-solving process. We apply the Agent-as-a-Judge to the task of code generation. To overcome issues with existing benchmarks and provide a proof-of-concept testbed for Agent-as-a-Judge, we present DevAI, a new benchmark of 55 realistic automated AI development tasks. It includes rich manual annotations, like a total of 365 hierarchical user requirements. We benchmark three of the popular agentic systems using Agent-as-a-Judge and find it dramatically outperforms LLM-as-a-Judge and is as reliable as our human evaluation baseline. Altogether, we believe that Agent-as-a-Judge marks a concrete step forward for modern agentic systems -- by providing rich and reliable reward signals necessary for dynamic and scalable self-improvement.', 'score': 5, 'issue_id': 127, 'pub_date': '2024-10-14', 'pub_date_ru': '14 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ - Agent-as-a-Judge. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–≥–µ–Ω—Ç–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥—Ä—É–≥–∏—Ö –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∞—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç Agent-as-a-Judge –∫ –∑–∞–¥–∞—á–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ DevAI, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 55 —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ò–ò. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ Agent-as-a-Judge –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç LLM-as-a-Judge –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º —Å –æ—Ü–µ–Ω–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞.', 'categories': ['#rl', '#code', '#benchmark', '#rlhf'], 'emoji': 'ü§ñ', 'title': '–ê–≥–µ–Ω—Ç —Å—É–¥–∏—Ç –∞–≥–µ–Ω—Ç–∞: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –ò–ò-—Å–∏—Å—Ç–µ–º', 'embedding': [-0.012691625155356014, 0.042267129704319936, 0.05757173797887448, -0.025986247269249425, 0.003359547772439315, 0.03876401210190981, 0.026000602672148616, -0.04335826844070366, 0.0628838434675224, 0.0437315494861636, 0.09446933417714747, -0.14380012710368667, -0.026273387356244546, -0.08740567736073045, -0.012375770205554415, -0.021320207510157365, -0.016711595768464326, -0.12255170941962981, 0.016941309973327844, -0.020688497183500684, 0.04792380329736202, -0.016323957184837774, 0.11353548506477402, 0.0677078076053775, 0.024162901844845014, -0.12909851834999045, -0.02558424901218884, 0.01919536446059122, -3.092933157095056e-05, -0.05943815174724387, 0.09556047718406603, -0.021650418076384896, -0.0298339329760537, -0.03919472543530362, 0.04933079506180665, 0.10360041243153387, -0.014134508202896271, 0.013789938390288192, 0.012863909421079827, 0.07683888799503133, 0.018635439689500172, -0.026273387356244546, 0.019410720059654413, 0.06696123910865535, -0.047866375279962986, 0.01788887546331287, 0.04709109597744246, -0.005538228814282601, -0.07448433501113652, 0.013775581706228548, -0.14150299786665604, 0.05251805963615587, 0.11566032597907275, -0.08889880581310507, -0.008729081492013013, -0.026560527443239664, -0.08022715169791084, 0.030953782518235794, 0.04350183955183493, 0.05022093466966008, 0.07293377427082803, -0.04476525806988087, -0.038534297897046293, 0.054097331182262724, -0.10210728397915926, -0.05355176608460571, -0.051168495889110245, 0.0501347894406604, -0.007659481838726863, -0.034370759162181096, 0.03167163593862472, 0.061792709001673544, 0.0027978287361309258, -0.04453554386501735, -0.0841896955747806, -0.05208734843802947, 0.1232408456284181, 0.11347806131790986, -0.0352896095758329, 0.039682864650829035, -0.019539934700252788, 0.009705359923063836, -0.05872029832685495, 0.009497182666030463, 0.024607970581138016, -0.016596740160719763, -0.0475505243871695, -0.07838944660007238, -0.11991001421347246, -0.061333282727213924, -0.04054428704708181, 0.11795745735137081, -0.0012284243462063174, 0.09337819971129858, 0.060529290483627596, 0.021334562913056552, -0.04668909985564929, -0.03675402722240914, 0.12415970244787215, 0.07034950281153485, -0.017860160386979643, -0.05335076695607542, 0.06357297967631069, 0.08361541326552292, 0.08872651749037314, -0.06047185819569373, -0.016955665376227034, 0.01334487050810216, -0.06747810194158368, -0.027594233891689506, -0.14104357372746387, -0.03339448073113027, -0.18974266059788125, -0.01689823735882801, -0.03442818717958013, -0.14138815037292768, -0.05435576259872689, -0.006090975029817085, 0.030063645045649793, -0.07270406220123195, -0.022827697771233436, 0.06776523989331137, -0.015275892130587602, -0.027536805874290485, 0.1125592066337232, -0.07235949409683781, 0.058863869437986216, -0.06914351444615537, -0.07770031039128411, -0.020229073044308495, -0.028800224392336427, 0.04327212534697141, 0.0168551668795956, -0.06282641545012338, -0.0994655887730019, -0.06391754991597226, -0.014170401194205831, -0.019123578905025584, -0.07080892695072705, -0.03661045824654529, 0.03132706463132945, 0.0002103082325709843, -0.11192750057760135, 0.0925167751797784, -0.08556797226289199, 0.035433180686964175, -0.009023400988671663, 0.03014978813938204, -0.05567660699890443, 0.12657167917863113, -0.05521718285971224, -0.03560546260389382, -0.08281141461613432, 0.017228451127956675, -0.06506611453448757, 0.005566943250035597, -0.09699617334850677, 0.004242505835361783, 0.027350164283926802, -0.10090128707271007, 0.11732574275417927, 0.023588619535587354, 0.02205241633344548, 0.08775023905932232, -0.027637306506189344, 0.07925087326686002, -0.05085264286104933, 0.0049639473591319115, -0.0730486303056261, 0.06357297967631069, 0.014471897751733848, -0.11319091909564731, -0.005692566797878376, 0.025957532192916202, 0.07580517514077921, -0.07034950281153485, -0.08281141461613432, -0.03411232774571694, 0.0007200954084799747, -0.038620440990778535, -0.06977522263754463, 0.03592131990248958, 0.0003640856017042902, 0.007609232376884403, 0.06397498220390613, -0.07103863902032313, -0.012849552523493443, 0.04772280630409915, 0.021033066355528533, -0.011815845647990111, -0.01752994768548469, 0.056021177238566, 0.0711535035961909, 0.0886116614555751, 0.1356453187392814, -0.013682260483993222, 0.07293377427082803, 0.0651809684340182, 0.03167163593862472, -0.06592753693074035, 0.0501347894406604, -0.08091628790669912, 0.10199242794436121, -0.05254677471248909, 0.003905115432417235, 0.003696938175383862, 0.060644144383158224, -0.10124586158290648, -0.030264644174180087, -0.05292005575794903, 0.11709603709038545, -0.03655303022914627, 0.10716096232187787, 0.05892130172592009, -0.11370777338750594, -0.027034310188232175, -0.012483448111849383, 0.06736324590678563, -0.01597938694517621, 0.08097371805936557, -0.03612231903101988, 0.0569687405932836, -0.06242441932833022, -0.042697843037713755, -0.10428955077558957, 0.04970407824253401, -0.02818287373911378, -0.0950436143511377, 0.049187223950675374, -0.05030707135759005, -0.002144583169858037, 0.027852661037618826, -0.13989501337948337, -0.02400497319554713, 0.02716352269356312, 0.022526198010804282, 0.0005015991513245198, 0.008779331380908957, 0.048182232578558755, -0.00587203025973898, 0.008477832901640258, -0.03701245436833846, 0.04321469732957239, -0.11640689661106232, -0.04163542151293068, 0.09567533321886407, -0.04180770770039518, 0.004156363595736504, 0.08016971940997697, -0.02001371637761159, -0.030034932104583995, -0.059897580156970914, -0.00589356592640867, -0.04335826844070366, -0.03796001985832348, 0.0420948477873903]}}, {'id': 'https://huggingface.co/papers/2410.08001', 'title': 'Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation', 'url': 'https://huggingface.co/papers/2410.08001', 'abstract': 'The increasing demand for versatile robotic systems to operate in diverse and dynamic environments has emphasized the importance of a generalist policy, which leverages a large cross-embodiment data corpus to facilitate broad adaptability and high-level reasoning. However, the generalist would struggle with inefficient inference and cost-expensive training. The specialist policy, instead, is curated for specific domain data and excels at task-level precision with efficiency. Yet, it lacks the generalization capacity for a wide range of applications. Inspired by these observations, we introduce RoboDual, a synergistic dual-system that supplements the merits of both generalist and specialist policy. A diffusion transformer-based specialist is devised for multi-step action rollouts, exquisitely conditioned on the high-level task understanding and discretized action output of a vision-language-action (VLA) based generalist. Compared to OpenVLA, RoboDual achieves 26.7% improvement in real-world setting and 12% gain on CALVIN by introducing a specialist policy with merely 20M trainable parameters. It maintains strong performance with 5% of demonstration data only, and enables a 3.8 times higher control frequency in real-world deployment. Code would be made publicly available. Our project page is hosted at: https://opendrivelab.com/RoboDual/', 'score': 3, 'issue_id': 122, 'pub_date': '2024-10-10', 'pub_date_ru': '10 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': 'RoboDual - —ç—Ç–æ —Å–∏–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –¥–≤–æ–π–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –æ–±–æ–±—â–µ–Ω–Ω–æ–π –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫ –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤. –û–±–æ–±—â–µ–Ω–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ vision-language-action –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–¥–∞—á, –∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç —Ç–æ—á–Ω—ã–µ –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è. RoboDual –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å OpenVLA –∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö, —Ç–∞–∫ –∏ –≤ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö. –°–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—ã—Å–æ–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∞–∂–µ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –≤—Å–µ–≥–æ 5% –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —á–∞—Å—Ç–æ—Ç—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ.', 'categories': ['#rl', '#multimodal', '#nlp', '#cv'], 'emoji': 'ü§ñ', 'title': 'RoboDual: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω –æ–±–æ–±—â–µ–Ω–Ω–æ–π –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫ –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö —Ä–æ–±–æ—Ç–æ–≤', 'embedding': [0.05827261376776874, 0.05928278856167894, 0.08993436079824421, 0.011155207988757625, -0.005545134045120047, 0.03674147572931303, -0.004408688139728053, 0.03685692204886128, 0.04222527603201631, 0.11198501676011394, 0.05330833138847945, -0.050537564914517316, 0.0018065880872919116, -0.0376650610408386, 0.0976694033278644, -0.016855476727729756, 0.004650408943361429, 0.0341150208435711, 0.03685692204886128, 0.08572048898146543, 0.028530202639901373, -0.06072589390449559, 0.00899054934216952, 0.016076199631821053, 0.041590311789054056, -0.10771342494537664, 0.05838806430307115, 0.10182555093093053, 0.0027689593909452992, -0.06638287106409103, 0.08583593740889077, -0.030997913303087123, -0.1059239637808986, -0.034374780859216636, -0.0010273109913832101, 0.06753735533834435, 0.08999208079620273, 0.07550330104644645, -0.025514110892506763, 0.1232989626477965, 0.05651202630347096, -0.10551990482429531, -0.009329678939640653, 0.13842270664051504, -0.03284509024976952, -0.06072589390449559, 0.02515333402983333, 0.07827406330465442, 0.0007716106626700116, 0.03804027159178655, -0.10863700604114805, -0.0005767913886928363, -0.05628112944862029, 0.04814200899150314, -0.00464319283698115, 0.013442530747575926, 0.07348295145862606, -0.05506891885277723, 0.014041419728329473, -0.005891479748971459, -0.04349521084157205, -0.050479840700804655, 0.10632803749264141, 0.0057183066862580454, -0.04008947801677059, 0.019611808459478835, -0.12179813309126718, 0.14234797425174708, -0.04903673746586507, 0.0678836964048662, -0.04444766142176957, 0.0022728918107839885, 0.04078217279707673, -0.03570243777460796, 0.028587926853614044, -0.0600332033399436, 0.026553148847211827, 0.13715278447822177, -0.022829933900929245, 0.00444115787819911, -0.029352774266214673, -0.05555957572327343, 0.025701716167980733, 0.016177216689636658, -0.04124396650677806, -0.10257595938556395, 0.028198287884084277, -0.128609596632993, -0.0364239936078319, -0.11186956200905737, 0.09605312534390975, -0.034057298737735504, -0.07492605890931978, 0.013168340205471491, 0.09784257386112534, 0.05385671247268832, 0.037318717866439685, 0.05850351062261941, 0.04337976241414671, 0.1133126694597511, -0.10736707544734649, -0.026784045702062494, 0.0061331999202417125, -0.02636554567961493, 0.049787154352006806, -0.013933187618072126, 0.059225064347966275, 0.0735983977781743, 0.0595136854165296, -0.043726107696422704, -0.12168268466384184, 0.005465763198568204, -0.003412945558578415, 0.03232557127241698, 0.0770618569245655, -0.07105852815906284, 0.006353273247885081, -0.04277365500834811, 0.014171299314576823, -0.06320803720201731, -0.0825456572272688, -0.010015154240963197, 0.035442679866839494, -0.10523127743210076, -0.006880007066891649, 0.0012392671795116053, 0.02845804789972981, -0.09593767902436151, -0.0064326443052246315, -0.01975611793982196, -0.04643914574091802, 0.016913200941442424, 0.03815571791133481, -0.0344613661258471, -0.08387330992690596, -0.016480268284658886, -0.02938163531913247, -0.0862977311185921, -0.10026699505281146, 0.04750704474854089, -0.08543186580502501, 0.03365322713386977, -0.05174977551036039, 0.03402843768481771, -0.055270954654710096, -0.015628836448578622, -0.07100080394535017, -0.0059455961202816935, -0.06315031088042757, 0.11008011349184178, -0.12526158591402717, -0.04903673746586507, -0.10967604188797606, -0.049700564869622196, -0.0298434290288338, -0.06297714034716666, -0.05573274836441143, 0.10551990482429531, 0.0639584498724049, -0.06771052587160528, -0.051201396534028595, 0.12583882805115382, -0.07394474938408152, 0.08445055206403262, 0.06251534663746532, -0.020088034803516137, -0.0006845733407219375, 0.08537414369918943, -0.1938379855307078, -0.05010463647348794, -0.044591970902112706, 0.00864420427068123, -0.09680353801429734, 0.014654739235541916, -0.013940402881301574, -0.10003609398220666, -0.040580134887266785, -0.1268778638979818, 0.0037232130491932146, -0.07925537704564682, -0.04384155401597097, 0.016364820489596678, -0.011948916454276055, 0.009654378432228303, -0.10061333611933332, -0.06291941402557691, -0.0539432956314417, -0.005314237190269382, -0.004650408943361429, 0.07290570932149938, 0.03336460606530644, 0.13761456764853772, 0.060956790759346256, -0.0024568877683415753, 0.13899996985641247, -0.03451909244743683, 0.0250811803436003, 0.04029151381870346, 0.0775813748479795, -0.03200808809699732, -0.02946822269364001, 0.024431781358425, 0.04649686995463068, -0.14373334484146572, 0.00954614526803242, -0.04205210549875539, 0.02604806039631819, 0.10476947950664527, -0.047939977405324415, -0.07492605890931978, 0.017144097796293088, -0.056771786319116495, 0.07105852815906284, 0.05945596120281693, -0.047564766854376474, -0.052240432380856586, -0.03636626939411924, 0.06805687326175835, 0.02964139533477801, 0.04880584061101441, -0.02041994745145616, 0.0386752358347488, -0.03169060386763912, -0.05301971031991612, -0.05004691225977527, 0.043812692963053165, 0.019395344238964142, -0.10321092784428036, 0.03821344212504747, -0.08889532284353914, 0.06407390040770732, 0.0554441272958481, -0.0043004553971075846, -0.06442024358210623, 0.02026120533677706, -0.041590311789054056, -0.003645646123842588, -0.008074177396784017, 0.06245762031587558, -0.04707411209175735, -0.051663192351607, 0.06442024358210623, 0.07631143582266962, -0.07267480825089458, -0.03838661476618547, 0.0030972660935722593, -0.03694351153124589, -0.04456310774131783, -0.009344110098462671, 0.02382567816838054, 0.08929939023165073, -0.023594781313529878, 0.018500617872479277, -0.06903818700275074, -0.02173317384038859, 0.04363952242979225]}}, {'id': 'https://huggingface.co/papers/2410.09745', 'title': 'Empirical Study of Mutual Reinforcement Effect and Application in Few-shot Text Classification Tasks via Prompt', 'url': 'https://huggingface.co/papers/2410.09745', 'abstract': "The Mutual Reinforcement Effect (MRE) investigates the synergistic relationship between word-level and text-level classifications in text classification tasks. It posits that the performance of both classification levels can be mutually enhanced. However, this mechanism has not been adequately demonstrated or explained in prior research. To address this gap, we employ empirical experiment to observe and substantiate the MRE theory. Our experiments on 21 MRE mix datasets revealed the presence of MRE in the model and its impact. Specifically, we conducted compare experiments use fine-tune. The results of findings from comparison experiments corroborates the existence of MRE. Furthermore, we extended the application of MRE to prompt learning, utilizing word-level information as a verbalizer to bolster the model's prediction of text-level classification labels. In our final experiment, the F1-score significantly surpassed the baseline in 18 out of 21 MRE Mix datasets, further validating the notion that word-level information enhances the language model's comprehension of the text as a whole.", 'score': 2, 'issue_id': 125, 'pub_date': '2024-10-13', 'pub_date_ru': '13 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–∑–∞–∏–º–æ—É—Å–∏–ª–∏–≤–∞—é—â–∏–π —ç—Ñ—Ñ–µ–∫—Ç (MRE) –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞ –≤ –∑–∞–¥–∞—á–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ 21 –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö MRE Mix –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ç–µ–æ—Ä–∏–∏ MRE. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ MRE. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ MRE –∫ –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ—Ä–±–∞–ª–∏–∑–∞—Ç–æ—Ä–∞, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–æ F1-–º–µ—Ä—É –Ω–∞ 18 –∏–∑ 21 –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.', 'categories': ['#nlp', '#classification', '#finetuning', '#promptlearning'], 'emoji': 'üîÑ', 'title': '–í–∑–∞–∏–º–Ω–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–ª–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞ —É–ª—É—á—à–∞–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ —è–∑—ã–∫–∞', 'embedding': [0.0482350874175379, 0.12184057477672086, 0.08602968396380986, 0.007347498374008819, -0.05058420096116788, 0.11484544991984637, 0.0987670861566691, 0.07162180098579161, -0.11672473572115825, 0.12267582194528975, -0.00045473252233926896, -0.02959880315858084, -0.06373922093032065, 0.05191536536709143, -0.0027177914463645853, -0.059980645455702974, 0.0778338925121157, -0.026205643238220017, -0.01142581729859366, 0.002370318518335801, -0.018062055944559507, 0.0261142893496558, -0.036567836584421795, 0.05181095705102413, -0.01652208265048918, 0.029102882049232243, -0.04048302066114653, 0.11641152626093201, 0.04646020606029941, 0.039230161524274984, 0.08274092267953155, -0.03672444131453492, -0.06838524579554392, -0.02931169093737902, -0.01932796757293719, 0.05606545944298129, 0.013533491886909697, -0.0010636255011894431, -0.012959264734110312, -0.016991906520813352, -0.07919116190105152, -0.014956010181397464, -0.06765440887903931, 0.0778338925121157, -0.038864744034021154, -0.03774238851624438, 0.03354009221831784, -0.05507361335229017, 0.049879465155681625, 0.1452272825369837, -0.13583084385043948, 0.04669511605946454, 0.019066954526756757, -0.014499238415380034, 0.05063640124720761, -0.0458337735878682, 0.023595518584406568, -0.007451903979680385, -0.04267552560266946, -0.06979470772653162, 0.08002639938963559, -0.05154994594084065, -0.008809167560625322, -0.0034323127484865213, -0.11035603946472104, -0.022760279159825536, -0.04951405153742173, 0.0182447656576849, 0.043380257536161794, 0.026022933525094626, 0.08247991737733897, -0.05888439298494151, -0.02158572335600903, -0.03434923246787748, -0.047086634660736704, -0.03307026834799366, 0.07611121144091694, 0.04820898630651956, -0.0652008928273329, -0.034427533864935564, 0.019693385063191012, -0.03032963813908848, -0.01465584546868951, -0.03860373292383769, -0.05862338187475804, -0.03340958472722914, -0.042075196177253554, -0.025226845767041112, -0.07391870649939401, -0.022773329715334707, -0.09944572085113701, -0.0012887486485210163, -0.028580855956871376, 0.015817350716996845, 0.008639510339006064, -0.08571646869559274, -0.11505425687199618, -0.09605255318678833, -0.08054842161000254, 0.06645375390020142, -0.07767728971799955, 0.0014820609070792293, 0.019419321461501406, -0.037794594610275005, 0.03489735386326581, -0.12257141362922244, 0.008848320001551627, -0.0773640705777885, -0.050270983756953797, -0.018910347860646673, -0.012117499838174998, -0.03387940472555939, 0.009168059773124558, 0.02015015644200905, 0.05322042479000272, -0.07062995102310658, -0.1109824641931644, 0.00025673013690507754, -0.07564138950658973, 0.06045046932602715, -0.0015367103647934914, 0.051419440385748916, 0.06624494501205463, -0.04105724897554409, 0.04306704420394163, -0.015543289051304197, 0.04116165148362051, -0.04027421177299975, 0.018114260102593163, 0.0170180076318317, -0.023882632741605347, 0.05836236689258065, 0.04103114786452575, -0.02248621652613441, -0.1820822371505982, 0.006525309698536656, -0.06723678723075183, 0.019093055637775105, -0.11338377802283411, 0.015243124338596243, -0.00707996101807228, -0.09072790330708198, -0.0726136432044888, 0.02873746359097994, -0.17435627344122215, -0.10033315862576081, 0.03860373292383769, 0.00406200543979883, 0.004845042642343167, -0.07762508555996589, -0.03432312942086217, -0.08780456725704532, -0.08112264798840313, 0.06332160121803014, -0.04301484198190493, -0.0652530950493696, -0.06232975706333599, 0.0014192547844118406, 0.03716816407384074, -0.07616341172695669, 0.04711273770775201, 0.07099536657736344, -0.056117661665017984, -0.028293743735669556, 0.057422724959923184, 0.09934130866307578, -0.11641152626093201, -0.022394861669571713, -0.08362837013414015, -0.025814124636947846, -0.030120829250941707, -0.011066925279694122, -0.044398204737871254, -0.08905742832991384, -0.04625139523615567, -0.01778799427886686, -0.16475101037855547, -0.03836882292467256, -0.003549768522467868, -0.0778338925121157, 0.0075628333143089675, 0.10826793315928061, -0.03933456596834837, 0.12288463857742438, -0.05851897549468769, -0.07423191983161417, 0.031686905592027345, 0.12110975528418892, -0.03346178694926583, 0.03742917518402422, -0.002897237455814354, 0.02881576789203346, 0.09088451578118294, 0.03742917518402422, -0.05549123306458068, -0.023739076631004438, 0.055595637508654074, 0.004375220127216868, -0.08044401910192611, -0.05987624294762655, -0.045651067746736725, 0.08294973543967225, 0.049200834333207634, 0.01710936152039591, 0.0026166491571692494, 0.017579185390720082, -0.05201976787516786, 0.043484663916232145, -0.057840344672213696, 0.03607191160307928, 0.10576221682153447, 0.026283947539273537, 0.026022933525094626, 0.043354154489146486, -0.10435275295454981, -0.08696932783246429, -0.10920758283592592, 0.047347645770920176, 0.07532817036637868, 0.05679629635948589, -0.0603460629459568, -0.036228518269189366, 0.11787319428595033, -0.016091414318686447, -0.08529884898330223, 0.13760572714367494, 0.09657458508714008, -0.10038536278379447, -0.018401374259791943, -0.08884861169777922, 0.031086576166611434, -0.0312692820077429, 0.006665603460659817, -0.04794797519633608, 0.014146871867834778, 0.009840166479442134, -0.06916828299808826, -0.030590649249271955, 0.05862338187475804, 0.025448707146694022, 0.014186022759963515, 0.14846384353522227, -0.030460143694180215, 0.020815738644970827, -0.00581078839641472, 0.13436917582542116, -0.05228077898535133, -0.040117603170892704, 0.031608598386978375, -0.034140421643733744, 0.12716523240041508, 0.05324652590102106, -0.022316560272513632, -0.05987624294762655, -0.036854948805623615, -0.026166491571692492]}}, {'id': 'https://huggingface.co/papers/2410.06593', 'title': 'Towards Natural Image Matting in the Wild via Real-Scenario Prior', 'url': 'https://huggingface.co/papers/2410.06593', 'abstract': 'Recent approaches attempt to adapt powerful interactive segmentation models, such as SAM, to interactive matting and fine-tune the models based on synthetic matting datasets. However, models trained on synthetic data fail to generalize to complex and occlusion scenes. We address this challenge by proposing a new matting dataset based on the COCO dataset, namely COCO-Matting. Specifically, the construction of our COCO-Matting includes accessory fusion and mask-to-matte, which selects real-world complex images from COCO and converts semantic segmentation masks to matting labels. The built COCO-Matting comprises an extensive collection of 38,251 human instance-level alpha mattes in complex natural scenarios. Furthermore, existing SAM-based matting methods extract intermediate features and masks from a frozen SAM and only train a lightweight matting decoder by end-to-end matting losses, which do not fully exploit the potential of the pre-trained SAM. Thus, we propose SEMat which revamps the network architecture and training objectives. For network architecture, the proposed feature-aligned transformer learns to extract fine-grained edge and transparency features. The proposed matte-aligned decoder aims to segment matting-specific objects and convert coarse masks into high-precision mattes. For training objectives, the proposed regularization and trimap loss aim to retain the prior from the pre-trained model and push the matting logits extracted from the mask decoder to contain trimap-based semantic information. Extensive experiments across seven diverse datasets demonstrate the superior performance of our method, proving its efficacy in interactive natural image matting. We open-source our code, models, and dataset at https://github.com/XiaRho/SEMat.', 'score': 1, 'issue_id': 126, 'pub_date': '2024-10-09', 'pub_date_ru': '9 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': '–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç COCO-Matting –¥–ª—è –∑–∞–¥–∞—á–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –º–∞—Ç—Ç–∏–Ω–≥–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ö –∏–∑ COCO. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É SEMat, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ SAM, –∏—Å–ø–æ–ª—å–∑—É—è feature-aligned transformer –∏ matte-aligned decoder. –í–≤–µ–¥–µ–Ω—ã –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, –≤–∫–ª—é—á–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∏ trimap loss. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ —Å–µ–º–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ –≤ –∑–∞–¥–∞—á–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –º–∞—Ç—Ç–∏–Ω–≥–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.', 'categories': ['#cv', '#dataset', '#benchmark'], 'emoji': '‚úÇÔ∏è', 'title': '–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º –º–∞—Ç—Ç–∏–Ω–≥–µ: –æ—Ç —Å–∏–Ω—Ç–µ—Ç–∏–∫–∏ –∫ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏', 'embedding': [0.06896135535924419, 0.041528201695645424, 0.06922237360063092, 0.028999267311730074, -0.07089290084503316, 0.03134844198373785, 0.08686729071459144, 0.054918504675758664, 0.00813075769741888, 0.010603917504019145, 0.08979070971746088, -0.11745877559849692, -0.04108447068528794, -0.0070018483436671336, 0.03090470887347497, -0.03273184496280384, 0.03865698844095874, 0.030487077587350767, -0.03677764870335252, 0.05841616590958435, 0.029390796773715602, -0.046774693546383965, 0.019237137835994008, 0.004864751307771902, -0.04082345034399579, -0.011922065922738449, -0.037012565120600596, 0.03518542693136632, 0.034376270383067384, 0.00841787944286863, -0.0007618506773815627, -0.04272889400564609, -0.11829403397093452, -0.07261563173771274, 0.05121202884882357, 0.08853781795899367, -0.11067226982386034, 0.02127309061833768, -0.1573425518738788, 0.03257523401797179, 0.08086384176402053, -0.014277767100733597, 0.026754497836371596, 0.03369761875565103, 0.02543634941765229, 0.026062799496696702, 0.0519167802004732, -0.023439551471422033, 0.0705274648075647, 0.09260971932387022, -0.05272593884867754, 0.10247625714611368, -0.02222581034925743, -0.06394977992575372, -0.04766216186681512, -0.037482400055002155, -0.018884762160169193, 0.03273184496280384, -0.016496432652048, -0.019928839325527, -0.06394977992575372, -0.00565433484781547, -0.031165729214767124, 0.02785078074991216, -0.049358788835450626, 0.035394245724286524, -0.09850875887798104, 0.007660922553026785, 0.024196508571254417, -0.02991283535639451, 0.07068407575239674, -0.004877802009850699, -0.009116106388436294, -0.05946024097503677, -0.048001485580617904, -0.08634525423181794, -0.08091605381191948, 0.09715146402276992, -0.06039991504365068, 0.0007630742082627084, 0.05144694736597705, -0.007432530121879596, 0.09120021452066554, -0.07569565958550882, -0.09908300740865349, -0.04805369132880065, -0.07256342808943538, 0.013573014699131263, -0.16266734499722257, 0.04888895390104906, -0.04479094861212844, 0.13030093607188717, -0.04732283395320154, 0.040614637850791786, 0.036412221065505665, 0.022669545559425713, -0.11140312719945945, -0.09407143617497384, 0.16298057528650825, 0.11850285696366554, -0.06128737916427104, -0.06655997703895905, 0.019028322192931903, -0.033227783821249475, 0.05121202884882357, 0.012835633967402886, 0.06421079816714048, -0.02210835214063339, -0.11150753869582494, 0.0327840507109866, 0.06415859451886312, -0.12664665969341862, 0.023648367114484134, 0.038865805133973544, 0.06488944979455682, -0.030095550225270638, -0.08149028764325413, 0.014173359804178897, -0.023282940526589982, 0.03281015253512527, 0.03487220504170222, -0.002841849857478645, 0.06922237360063092, 0.023413449647283355, 0.059616858219585026, 0.03669934323093649, 0.04244177184021526, -0.058781593547431205, -0.01620931132657933, -0.02491431293487879, 0.03766511282397288, -0.04967201282502012, 0.07026645286589414, -0.014290818012802936, -0.09662941914037482, -0.07110171333823716, -0.1545235548669019, 0.052230002090137305, -0.08697169801114615, 0.03166166597330736, -0.03818715350655719, -0.022591237987104284, -0.008835509469049593, 0.025462453341696372, -0.06447181640852723, -0.04823640199786598, 0.0055792922084120485, 0.03510712145895029, -0.13875796909092597, 0.0662989545977615, -0.07533022564794575, -0.08932087478305932, 0.020020195710012366, 0.023034971097367164, -0.06494165344283419, -0.046748593822150686, -0.008515761493379202, 0.04439941915014291, -0.00592840568119588, -0.035994589779381456, 0.026206357429554013, 0.036464424713783014, 0.03369761875565103, 0.06896135535924419, -0.04301601617107692, 0.04181532386107625, -0.13124060594069029, 0.11380449922002837, -0.10216303525644957, -0.046800799570333444, 0.12800396504815675, -0.07355529740670504, 0.005644546558768197, -0.13447724893312923, -0.056014787589299224, -0.01075400404276923, -0.025788726143429808, -0.03333218901789878, -0.06739523541139666, -0.045469596039733995, -0.09010393370703039, 0.06410639297049117, -0.057841923678628095, 0.11818963507400143, -0.053508997772648594, -0.02046393092018065, 0.06494165344283419, 0.07120612273469726, 0.09662941914037482, 0.00946848248424219, -0.06645556554259356, 0.041136672233659896, 0.08916426383822727, -0.022800053630166385, 0.03706477086878335, -0.005569503919364776, 0.11338687633352577, 0.0999182699809019, 0.03615120282411891, -0.032418623073139745, 0.0001150117201359218, 0.05695445535819693, 0.04860183173561824, 0.027041621051755126, 0.04056243210260904, 0.03497661443816232, -0.024744648978071996, -0.0588860008439859, -0.057633106985613296, -0.04930658518717327, 0.11547502856433599, 0.06969220643512708, 0.10184981126688009, 0.0206205418650127, -0.03672544295516977, -0.03168776779744603, -0.05622360218240863, -0.07788822121277914, 0.011112905174628715, 0.11234279706826256, -0.020568336116829948, 0.007993722490719215, 0.10586951108338467, -0.026362970474291467, 0.04873234295621701, -0.012822583055333549, 0.006701675896138588, -0.07893230047804235, -0.00830042060427297, -0.0995006365948723, -0.05408324210351025, 0.021977843019940015, -0.06447181640852723, 0.011850284856404391, 0.026963314529386398, -0.040405819057871585, 0.0009869799815293912, -0.1244540980661483, 0.08081164021564857, 0.0621748474847022, 0.04129328527839735, 0.039387843716652444, -0.011830708698290927, 0.08008078284004946, -0.019419851654917435, 0.08937307633143128, 0.0037586807351556854, -0.08905985444176717, -0.012913939439818911, -0.05343069230023257, 0.16016156987990973, -0.0005615997504874798, 0.013357672550081792, -0.07715736383718003, -0.004682037488848475, 0.01325979049957122]}}, {'id': 'https://huggingface.co/papers/2410.11619', 'title': 'MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieval', 'url': 'https://huggingface.co/papers/2410.11619', 'abstract': 'Efficiently retrieving and synthesizing information from large-scale multimodal collections has become a critical challenge. However, existing video retrieval datasets suffer from scope limitations, primarily focusing on matching descriptive but vague queries with small collections of professionally edited, English-centric videos. To address this gap, we introduce MultiVENT 2.0, a large-scale, multilingual event-centric video retrieval benchmark featuring a collection of more than 218,000 news videos and 3,906 queries targeting specific world events. These queries specifically target information found in the visual content, audio, embedded text, and text metadata of the videos, requiring systems leverage all these sources to succeed at the task. Preliminary results show that state-of-the-art vision-language models struggle significantly with this task, and while alternative approaches show promise, they are still insufficient to adequately address this problem. These findings underscore the need for more robust multimodal retrieval systems, as effective video retrieval is a crucial step towards multimodal content understanding and generation tasks.', 'score': 0, 'issue_id': 130, 'pub_date': '2024-10-15', 'pub_date_ru': '15 –æ–∫—Ç—è–±—Ä—è', 'data': {'desc': 'MultiVENT 2.0 - —ç—Ç–æ –Ω–æ–≤—ã–π –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–∏–¥–µ–æ, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Å–æ–±—ã—Ç–∏—è. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç –±–æ–ª–µ–µ 218 000 –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –≤–∏–¥–µ–æ –∏ 3 906 –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–∞—Ü–µ–ª–µ–Ω–Ω—ã—Ö –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–∏—Ä–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è. –ë–µ–Ω—á–º–∞—Ä–∫ —Ç—Ä–µ–±—É–µ—Ç –æ—Ç —Å–∏—Å—Ç–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∞—É–¥–∏–æ, –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç—É–ø–∞—é—Ç –≤ —ç—Ç–æ–π –∑–∞–¥–∞—á–µ, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –ø–æ–∏—Å–∫–∞.', 'categories': ['#multimodal', '#benchmark', '#video', '#dataset'], 'emoji': 'üé•', 'title': 'MultiVENT 2.0: –ù–æ–≤—ã–π –≤—ã–∑–æ–≤ –≤ –º–∏—Ä–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤–∏–¥–µ–æ', 'embedding': [0.021813343868390643, 0.003003569748697959, 0.10596542238467484, -0.03859685057970808, -0.05420759201114238, 0.007798856619574405, 0.11873547757773831, 0.038492604587665145, -0.06093141801651371, 0.07323237263718364, 0.05248754166483351, -0.12071614077355461, -0.0308045084823964, -0.04112479671135019, 0.010463629024732718, 0.05212268708448294, -0.0010864323065227829, 0.012581113593685444, -0.043965487210920834, -0.0185817372904587, -0.030726323988364196, 0.004182845502704012, -0.08798310167906293, -0.060045335606548345, 0.057282831731609814, -0.07875738251766062, -0.022829735899009575, 0.09543664323693511, 0.14083549792424702, -0.015324069853695992, 0.06166113783021436, -0.030856630413117918, -0.09178805056023152, -0.035521612989840544, -0.06082717841627047, 0.107372732624255, -0.059628353768976496, 0.01872507552951774, -0.0489692628699833, 0.06765524828308483, 0.07005288905527318, -0.04545098407513308, 0.003883140193120479, 0.05420759201114238, 0.047092845666209936, -0.017604437506855863, -0.004062311926644326, 0.009531936010408712, -0.07662034820318, 0.10831094229144161, -0.09705244759120105, 0.0013918386753261594, -0.05058506722424922, -0.020575429104680465, 0.05738707772365275, -0.11008311137257214, -0.009434206884288388, -0.04075994213099962, -0.07073048374235248, 0.0027608735398929264, -0.04834379117892548, -0.1121680226910313, 0.024041589164709016, -0.061869627683700336, -0.04404366744375322, -0.0675510022910419, 0.06343330691134488, 0.09611423153221471, 0.015610743988154178, -0.04169815179818625, -0.03195120693776905, 0.07635973322307266, 0.013773419883636874, -0.016978965815798042, 0.014854965233162664, 0.05957622864235512, -0.07505666684493555, 0.038414420093632946, -0.12426048532761536, -0.04980322654512699, 0.026895306152085217, -0.09256989336995365, -0.10403688218488, 0.04975110567970543, -0.09512390313020641, 0.009988009455816689, -0.059367738788869154, -0.0056618267793535895, -0.03737196443440337, -0.018685983282501636, -0.09481116302347768, 0.08511634328968186, -0.021709097876347703, 0.08099865430178456, 0.07781916858927417, 0.021565761767888568, 0.03346276316939213, -0.0450861231029828, 0.11956944338348191, 0.09006800021392265, -0.11404444202540455, -0.06051443830954176, 0.03450521882862171, -0.018959626881014446, -0.034453095832600235, -0.0019236529445138535, 0.039352629760819574, 0.014346769430913188, 0.0235333942146995, -0.07073048374235248, -0.12884728341030577, -0.010939249019768728, -0.08136351527393483, 0.026895306152085217, 0.11195953070694542, -0.07291963253045494, -0.005205753547005601, -0.03338457867535993, -0.00564553834309688, 0.028563231371772704, -0.024745245349799043, 0.055093678682307544, 0.013851604164609089, -0.016496830233199363, 0.12050764665886883, -0.04920381848267981, 0.04109873734393936, 0.040655696138956685, 0.019272364857143256, -0.05994108961450541, 0.015363162100712093, 0.0148810267311734, 0.07667247119920147, 0.036772556371956186, -0.11727603795033699, -0.03666831037991325, -0.16012088926919585, 0.03468764931469685, -0.11883972143918133, 0.06510123426163228, -0.02603528097893078, -0.0498814131697591, 0.02591800423788248, 0.12259255797732797, -0.06285996034690844, -0.020262693259151553, -0.013604020998807063, 0.02335096372862436, 0.002029527013166497, 0.04016052980735263, -0.11977793749816769, -0.08193685970777138, -0.07271115332996847, 0.04928200084611211, -0.08542908126581068, -0.09366446776400487, -0.042349682856654906, 0.0460764557661909, 0.047144968662231404, -0.05008990302324507, 0.07490030211807096, -0.008841310787384043, 0.023259748485586793, 0.006652157525021779, 0.022060925968892718, 0.06426727271708849, -0.11550387526100617, 0.0332803348139169, -0.09856400169222422, -0.11946519739143896, -0.0004177958971826999, -0.009642697376954331, -0.02989236137852045, -0.020731798092744873, 0.016158032889659717, -0.0967918326110937, -0.0006254722450137952, -0.006495789602257324, 0.034739772310718314, -0.05900288207791868, -0.07172081427496066, 0.025983157982909316, -0.011356230644280586, 0.026764998662031542, -0.04542492257712234, 0.02529253361212461, -0.09512390313020641, 0.05436396099920678, -0.024641001488356008, -0.030048728235984954, -0.04612857876221237, 0.10622603736478219, 0.09126682060001684, 0.07771492259723124, 0.0774543076171239, 0.009597089755435547, 0.036954984727431424, 0.04492975411491839, 0.023012166385084718, -0.06504911126561082, 0.009851188082680266, 0.028615354367794173, 0.0016280195096285083, -0.1444840884703507, -0.008196292120578211, -0.054572452983292656, -0.02827655702425453, 0.10262956981469996, -0.08892130282384995, 0.03614708468089837, 0.05827316439481792, 0.0919965425443174, 0.11811000801728037, -0.010672119517398663, -0.0373980259324141, 0.03786713289660732, -0.12227982000119916, 0.040655696138956685, -0.09147531258410271, -0.0686976996811146, 0.04453883590595718, 0.009844672708177581, 0.12770058388963318, -0.003440097283657877, -0.0680722322512566, 0.01451616788962302, -0.03262880162484834, -0.05243542079941195, 0.004896274962608051, -0.1775298719327709, 0.052539666791454886, -0.008437359911877555, -0.047066788429399, -0.004922336460618786, -0.057543446711717156, -0.043261826764631, 0.06301632720437295, -0.016496830233199363, -0.05277422027355149, -0.017917173352384776, 0.07286751166503337, 0.011134708976489296, -0.0438612412188779, -0.011304107648259117, -0.04847409866897915, 0.03249849413479467, -0.05334756896858785, -0.06874982267713607, 0.1048708415988239, -0.04787468634533216, 0.07208567311651104, -0.07922648095945423, -0.06041019231749882, -0.0539991000270565, 0.02950144103895934, 0.028068067170768554]}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'default';        

        function loadSettings() {
            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            const themeToggle = document.getElementById('theme-toggle');
            let settingSortBy = localStorage.getItem('sort_by');
            const sortDropdown = document.getElementById('sort-dropdown');
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "—Ö—Ñ –Ω–∞–π—Ç–ª–∏";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'default';
            }
            
            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            return Array.from(categories);
        }
        
        function createCategoryButtons() {
            const categories = getUniqueCategories(articlesData);
            categories.forEach(category => {
                const button = document.createElement('span');
                button.textContent = category;
                button.className = 'category-button';
                button.onclick = () => toggleCategory(category, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if (selectedArticles.length === articlesData.length) {
                categoryToggle.textContent = 'üè∑Ô∏è –§–∏–ª—å—Ç—Ä';
            } else {
                categoryToggle.textContent = `üè∑Ô∏è –§–∏–ª—å—Ç—Ä (${formatArticlesTitle(selectedArticles.length)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const savedCategories = localStorage.getItem('selectedCategories');
            if (savedCategories) {
                if (savedCategories != '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);
                    updateCategoryButtonStates();
                }
            }
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles = selectedCategories.length === 0
                ? articlesData
                : articlesData.filter(article => 
                    article.data && article.data.categories && 
                    article.data.categories.some(cat => selectedCategories.includes(cat))
                );

            console.log('filteredArticles', filteredArticles)

            if (filteredArticles.length === 0) {
                selectedArticles = articlesData;
                selectedCategories = [];
                cleanCategorySelection();
            } else {
                selectedArticles = filteredArticles;
            }

            console.log('selectedArticles', selectedArticles)

            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
        }

        function renderArticles(articles) {
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                const explanation = item["data"]["desc"];
                const cats = item["data"]["categories"].join(" ");
                const articleHTML = `
                    <article>
                        <div class="background-digit">${index + 1}</div>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <h2>${item['data']['emoji']} ${item['title']}</h2>
                            <p class="meta"><svg class="text-sm peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path transform="translate(0, 2)" fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg> ${item['score']}. ${item['data']['title']}</p>
                            <p class="pub-date">üìÖ –°—Ç–∞—Ç—å—è –æ—Ç ${item['pub_date_ru']}</p>
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>
                            <div class="links">
                                <a href="${item['url']}" target="_blank">–°—Ç–∞—Ç—å—è</a>
                            </div>
                            <p class="tags">${cats}</p>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            }
            if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
        });

        clearCategoriesButton.addEventListener('click', clearAllCategories);
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = 'üîÑ ' + getTimeDiffRu('2024-10-16 18:16');
        } 

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();  
    </script>
</body>
</html>
    