
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF (6 статей)</title>
    <link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0989eacf;
            --secondary-color: #03dac6;
            --background-color: #f5f5f5;
            --text-color: #333333;
            --header-color: #0989eacf;
            --body-color: #f5f5f5;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        header {
            padding: 1.6em 0;
            text-align: center;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2em;
            padding: 10px 0 20px 0;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.tags {
            color: #555;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        body.dark-theme>div>main>article {
            background-color: #444;
        }
        body.light-theme>div>main>article {
            background-color: #fff;
        }
        body.dark-theme>div>main>article:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article:hover {
            background-color: #fafafa;
        }
        article {
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
            transition: background-color 0.2s ease;
            display: flex;
            flex-direction: column;
            position: relative;
        }
        .article-content {
            padding: 1.5em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
        }
        .pub-date {
            font-size: 0.9em;
            margin-bottom: 0.8em;
            font-weight: 300;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 1em;
            position: absolute;
            bottom: 10px;
            font-weight: 300;
            font-family: 'Roboto Slab';
        }
        .background-digit {
            position: absolute;
            bottom: -20px;
            right: -10px;
            font-size: 12em;
            font-weight: bold;
            color: rgba(0, 0, 0, 0.03);
            z-index: 0;
            line-height: 1;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 80px;
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        a:hover {
            color: var(--secondary-color);
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 1em 0;
            margin-top: 2em;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
        }
        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
        }
        .update-info-container {
            flex: 1;
        }
        .sort-container {
            flex: 2;
        }
        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .category-toggle {
            display: none;
            margin-bottom: 10px;
            margin-top: 15px;
            cursor: pointer;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }

        .svg-container span {
            position: relative;
            z-index: 1;
        }

        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .sort-container {
                margin-top: 0px;
                text-align: left;
                width: 100%;
            .sort-dropdown {
                float: right;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiffRu(dateString) {
        const timeUnits = {
            minute: ["минуту", "минуты", "минут"],
            hour: ["час", "часа", "часов"],
            day: ["день", "дня", "дней"]
        };

        function getRussianPlural(number, words) {
            if (number % 10 === 1 && number % 100 !== 11) {
                return words[0];
            } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                return words[1];
            } else {
                return words[2];
            }
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);

        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes == 0) {
            return 'только что';
        }
        else if (minutes < 60) {
            return `${minutes} ${getRussianPlural(minutes, timeUnits.minute)} назад`;
        } else if (hours < 24) {
            return `${hours} ${getRussianPlural(hours, timeUnits.hour)} назад`;
        } else {
            return `${days} ${getRussianPlural(days, timeUnits.day)} назад`;
        }
    }
    function formatArticlesTitle(number) {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;

        let word;

        if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
            word = "статей";
        } else if (lastDigit === 1) {
            word = "статья";
        } else if (lastDigit >= 2 && lastDigit <= 4) {
            word = "статьи";
        } else {
            word = "статей";
        }

        return `${number} ${word}`;
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">
            <h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">хф дэйли</h1>
            <p>16 октября | 6 статей</p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 Сортировка по</label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="category-toggle">
            <div class="svg-container">
                <span id="category-toggle">🔍 Фильтр</span>
                <svg height="3" width="200">
                    <line x1="0" y1="0" x2="200" y2="0" 
                        stroke="black" 
                        stroke-width="2" 
                        stroke-dasharray="3, 3" />
                </svg>
            </div>
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">градиент обреченный</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>    
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "хф найтли";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "хф дэйли";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2410.11779', 'title': 'MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation', 'url': 'https://huggingface.co/papers/2410.11779', 'abstract': 'Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood. In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the objects in the final output, they are actually able to recognize visual objects in the preceding layers. We speculate that this may be due to the strong knowledge priors of the language model suppressing the visual information, leading to hallucinations. Motivated by this, we propose a novel dynamic correction decoding method for MLLMs (DeCo), which adaptively selects the appropriate preceding layers and proportionally integrates knowledge into the final layer to adjust the output logits. Note that DeCo is model agnostic and can be seamlessly incorporated with various classic decoding strategies and applied to different MLLMs. We evaluate DeCo on widely-used benchmarks, demonstrating that it can reduce hallucination rates by a large margin compared to baselines, highlighting its potential to mitigate hallucinations. Code is available at https://github.com/zjunlp/DeCo.', 'score': 8, 'issue_id': 121, 'pub_date': '2024-10-15', 'pub_date_ru': '15 октября', 'data': {'desc': 'Статья исследует проблему галлюцинаций в мультимодальных больших языковых моделях (MLLM). Авторы обнаружили, что MLLM способны распознавать визуальные объекты в промежуточных слоях, но в итоговом выводе могут их некорректно генерировать. Предполагается, что это связано с подавлением визуальной информации сильными языковыми приорами модели. Для решения проблемы предложен метод декодирования DeCo, адаптивно интегрирующий знания из предыдущих слоев в финальный слой.', 'categories': ['#multimodal', '#nlp', '#cv', '#code'], 'emoji': '🔍', 'title': 'Борьба с галлюцинациями в мультимодальных моделях', 'embedding': [0.03247479333420629, 0.04238699545387423, -0.04501564790079551, 0.00994643192840189, -0.03170810321628497, 0.07119262924505257, 0.05678981664780065, 0.04542637551724215, -0.10766515991710686, 0.09594575843424231, 0.00925504223169056, -0.04512517383240219, -0.06609961969612593, 0.04863004232885147, -0.042852488185292845, -0.07184979558053584, 0.05919940863483404, -0.03463795304970895, -0.03827973218441954, 0.04151078155351484, -0.017962448357841804, 0.02907945076936369, -0.012670919243103726, 0.027751436490913002, 0.05941846479638468, 0.018003521119486464, 0.011965838052732538, 0.09523383128212434, 0.06987830517076056, 0.07141168325743456, 0.03619871584303758, -0.04936934988928681, -0.11111526759692143, -0.024246567994463716, -0.08000957204865364, 0.06084231910062063, -0.006472368325561398, 0.025656729945372363, -0.07842142239950177, 0.03852616445595027, -0.011917920189008535, -0.06724965272383929, -0.047534772266941465, 0.027655598614296364, -0.00787910729559665, 0.13066586345474648, -0.0011757052768053859, 0.03370696973604034, -0.04030598126166089, 0.10782945096368553, -0.12343707030029728, 0.08471923009111373, -0.017182066961177488, 0.10120306117891624, -0.0727260094808952, -0.04036074637663287, 0.0824191618865184, 0.010391385914912685, 0.0027997870911612363, -0.03732136846243357, 0.019783335776028466, -0.026984744223823055, -0.017305286320695796, 0.001033662208944189, -0.026437108118283734, -0.06889256748796312, -0.09830059605214687, -0.0483562232014975, 0.04298939667438552, 0.06182806108175532, -0.021658988309187104, -0.01956428176364646, -0.007872261978600447, 0.014608180059061907, -0.09972445035638282, -0.022863787526456743, -0.021700061070831767, 0.056406467290502735, 0.008905924832295225, -0.018879737169014473, 0.008111852801638507, 0.030339014027020987, -0.020152990630830446, -0.07814760542131644, 0.027285943759494384, -0.047835971802612794, 0.025738873319493063, 0.020194064467059424, -0.07289030052747388, -0.06029468299508131, 0.055092145365379354, 0.007160335686149922, -0.06171853515014864, 0.04975269494824747, -0.01579928778267169, 0.04501564790079551, 0.04301677708270288, -0.08855268282988897, 0.05761126758235669, 0.023438805114897734, -0.06330667835179463, 0.030421159550310314, 0.05446236158738208, -0.11927504191587061, 0.030585448447720348, -0.0391833286422649, -0.01664812342388234, -0.03006519489966701, -0.01071996714840255, 0.04293463370858217, -0.013759345062601847, 0.031215231151133307, -0.04419419696623947, -0.021303025807712428, 0.04441324882945284, -0.18028164776473266, -0.056625521302884736, 0.07387604895611444, 0.01881128399905245, 0.009823213643467898, -0.06987830517076056, -0.007064499743785051, 0.044248959932042815, -0.07245219250270987, -0.013314390646257326, -0.014717707924920359, 0.05925417589897465, -0.08345966468428781, 0.02687521829221637, -0.021125044556975094, -0.043345359175860194, 0.03272122775490565, 0.06790681691015392, -0.07732615233759176, -0.12288943419475797, 0.005757019482071203, -0.08395253997319242, 0.011582493853439329, -0.06905684993786727, 0.02621805625507036, 0.04416681225958485, -0.03233788269594499, 0.06155424410356998, 0.07091881656520448, -0.10799374630860144, 0.06319715242018793, 0.08110483566305778, -0.01849639425922244, -0.0743689134991759, 0.07250695761768185, -0.07721662640598509, -0.062375699336463274, -0.013540291050219843, 0.002375369485472774, -0.13230876317468993, -0.02650556558658301, -0.017058849750827807, -0.01897557504563111, 0.11095098084868003, -0.08773123404450156, 0.04947888011923076, 0.09183848871728174, 0.14829972757026233, -0.02230246229134306, -0.027655598614296364, 0.11281293458100547, -0.11905598145598273, 0.14939499978134096, -0.04162030533595291, -0.1341707276528585, -0.07683327919785579, 0.043619178303214164, -0.03014734257212497, -0.07414986378513116, 0.028312760651442368, -0.01304057280840453, -0.03814282154615824, -0.21894472715728147, -0.029380650305035023, -0.09578146953683228, -0.03485700921125958, 0.07683327919785579, -0.06845445301569324, 0.05145036623066877, -0.08762169736705173, -0.08088578379984439, -0.06845445301569324, 0.09769819698080422, 0.009453559648333368, 0.034583190083905604, -0.06264951416547998, 0.037211842530826884, 0.10766515991710686, 0.062211406140715984, 0.007913334740245113, -0.06735917865544597, 0.14118045604908258, 0.06401860335474398, -0.017140995274117138, -0.059473227762188025, -0.02946279797749298, 0.09309805197493905, 0.0009344032857059229, -0.16943845588389023, 0.05260040355671938, 0.03455580752641962, 0.06467576754105861, 0.015676069282820834, 0.04112743649455419, 0.030339014027020987, 0.05295636605819405, -0.024506692619321754, 0.1424947908692177, 0.005031402125794547, -0.023479875727373766, -0.04622044604348083, -0.09112656371433239, -0.012390255873337863, 0.007749043908583316, -0.002043365400059631, -0.047233572731270136, 0.058925593805817335, -0.012465556294547852, 0.055092145365379354, -0.08920984486703498, -0.006951549541803792, 0.0806667233399565, -0.07404033570435585, 0.037704713521394234, 0.025259694682253024, 0.050711058670233435, -0.12168463820124126, -0.015210579775155157, -0.005674874173698737, 0.023945368458792384, -0.027997870911612363, 0.03129737559983833, -0.023548333195673045, 0.014060544598273177, -0.06467576754105861, 0.09605528651501762, 0.02383584037801707, 0.0650043474850473, -0.05739221142080606, -0.015279034019701494, 0.07666899030044574, -0.09134562417422028, -0.018085666642775795, 0.04400252336217483, -0.04167507045092488, 0.00946040518024643, 0.029380650305035023, -0.06149948113776664, -0.024465622006845714, -0.08313108903863638, 0.08838839393247894]}}, {'id': 'https://huggingface.co/papers/2410.11096', 'title': 'SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI', 'url': 'https://huggingface.co/papers/2410.11096', 'abstract': "Existing works have established multiple benchmarks to highlight the security risks associated with Code GenAI. These risks are primarily reflected in two areas: a model potential to generate insecure code (insecure coding) and its utility in cyberattacks (cyberattack helpfulness). While these benchmarks have made significant strides, there remain opportunities for further improvement. For instance, many current benchmarks tend to focus more on a model ability to provide attack suggestions rather than its capacity to generate executable attacks. Additionally, most benchmarks rely heavily on static evaluation metrics, which may not be as precise as dynamic metrics such as passing test cases. Conversely, expert-verified benchmarks, while offering high-quality data, often operate at a smaller scale. To address these gaps, we develop SecCodePLT, a unified and comprehensive evaluation platform for code GenAIs' risks. For insecure code, we introduce a new methodology for data creation that combines experts with automatic generation. Our methodology ensures the data quality while enabling large-scale generation. We also associate samples with test cases to conduct code-related dynamic evaluation. For cyberattack helpfulness, we set up a real environment and construct samples to prompt a model to generate actual attacks, along with dynamic metrics in our environment. We conduct extensive experiments and show that SecCodePLT outperforms the state-of-the-art (SOTA) benchmark CyberSecEval in security relevance. Furthermore, it better identifies the security risks of SOTA models in insecure coding and cyberattack helpfulness. Finally, we apply SecCodePLT to the SOTA code agent, Cursor, and, for the first time, identify non-trivial security risks in this advanced coding agent.", 'score': 6, 'issue_id': 121, 'pub_date': '2024-10-14', 'pub_date_ru': '14 октября', 'data': {'desc': 'Статья представляет SecCodePLT - новую платформу для оценки рисков безопасности генеративных моделей AI для кода. Авторы разработали методологию создания данных, сочетающую экспертную оценку и автоматическую генерацию, а также внедрили динамические метрики оценки. SecCodePLT позволяет оценивать как потенциал моделей генерировать небезопасный код, так и их полезность для кибератак. Эксперименты показали превосходство SecCodePLT над существующими бенчмарками в выявлении рисков безопасности современных моделей кодогенерации.', 'categories': ['#code', '#benchmark', '#dataset', '#rlhf'], 'emoji': '🛡️', 'title': 'SecCodePLT: Новый стандарт оценки безопасности AI-кодогенераторов', 'embedding': [0.08386529588367087, 0.02522823610500497, 0.17837106110636208, -0.0017296143234627663, -8.184383661526759e-05, -0.05694945368100336, 0.04402069650169448, -0.014930997095150975, 0.040960130865253366, -0.008488071303535995, 0.006492981470993424, -0.09839584414627313, -0.040445266260447255, -0.1122971205256148, -0.01367244483482687, -0.1077777697187723, -0.0005179904516883597, -0.08026126276108465, -0.07791577765192109, -0.04219007812078776, 0.04384907921366058, 0.0584082282341511, 0.04158940487196469, 0.03644078430531233, -0.019822185359400283, -0.059151918013119816, 0.03418111421051791, 0.0021166548387192073, 0.08878508490580843, -0.0033966588353574055, 0.06601674543532297, -0.027330588228984244, -0.09513505197010692, -0.02894668287639786, 0.031950044873611735, 0.03761352792161948, 0.043706060560064194, -0.058208005941327474, 0.035153631287099966, 0.07185184789481536, 0.03686983601920003, 0.05869426341789314, -0.03106333750277199, 0.08815580877564637, -0.0690487081904251, 0.015045410743957646, 0.08443735775735202, -0.17402334032825786, -0.020222633130223627, 0.04530785164335758, -0.10903631773219494, 0.01915000490722975, 0.03918671400012315, -0.05068529950762328, -0.051800833114351005, 0.07105095235316866, -0.06206947136631674, 0.023082977535566485, -0.06899150030429639, -0.04147499122315802, 0.07053608987181327, -0.010168523920377832, 0.010876459035947458, 0.07025005681152198, -0.03386647614543688, -0.055519279885743886, -0.029776183422834265, -0.01613234146934638, -0.05134317639567359, 0.0035718547749073208, 0.014265966301589826, 0.10285797857318402, 0.05377447227230484, -0.07991802181466465, -0.04982719607984788, -0.019621960943125925, 0.05832241959013414, 0.11429935194765398, 0.006346389049817712, 0.008337903416020373, 0.017819944381832816, -0.0045050421464405245, -0.02830310530556631, 0.029432942476414252, -0.09267515533558741, -0.002399113706741047, -0.13947038866033318, -0.07402570722214209, -0.1288299044571577, -0.01623245367748356, -0.07871667107011705, 0.06624557485638703, 0.030548476083141974, 0.0950206340743988, 0.03850023210728313, 0.06590232966306557, 0.037184476207731784, -0.051486195049269975, 0.07820181071221238, 0.10566111827757425, -0.003511072484164076, -0.01963626450724615, 0.06681763885351893, 0.03615474912157029, 0.10480301697324959, -0.010068411712240655, 0.01459490686906571, -0.015560273225313028, -0.006400019983190992, -0.022696832267137996, -0.09444856158346399, -0.05054228085402689, -0.13878389827369023, 0.01679022048084742, -0.024098398934157026, -0.037413301381894394, -0.013794010265693652, -0.004755322454438397, 0.09965439215969576, 0.04150359622794774, -0.021080737619724385, 0.09055849540058646, 0.05720688385995568, -0.049026298414750466, 0.07682884692653234, -0.05251592001198074, 0.01097657060704942, -0.07127977752733126, 0.006139013913208611, -0.04219007812078776, -0.04725288579652171, 0.008745502544213687, 0.0732248116804954, 0.0542893326302095, -0.03961576571401085, 0.020122521983811814, -0.08455177352960944, 0.0035146479505039855, -0.0561485602628074, 0.03612614836368203, -0.05769314558342282, 0.06984960373207179, -0.06452936587738552, 0.12413894060918275, -0.11275476662703857, -0.10302959586121793, -0.04087431797433495, 0.07963198450747186, -0.03512502840576099, 0.20914837510437106, -0.017705531794751515, -0.011806070516450608, -0.02266822726234828, 0.008109076118407034, -0.04510762935053395, -0.04104594163272105, -0.08535267119470685, 0.1290587275078696, -0.022139065463774137, -0.05200105753062536, 0.05065669450283357, 0.14736493255144414, -0.07946035872563503, 0.05995281355476651, 0.025528572729416502, 0.07253832978765537, -0.06801898959806653, -0.052487315007191025, -0.11899031579562892, 0.009961149208458876, 0.04470717839453451, -0.0317212175759984, 0.01079779898881452, 0.012385290967234217, 0.031120546450626056, -0.07076491716942662, -0.12917314752702844, 0.002048721615296143, -0.026129244916514204, -0.11664483705681755, -0.06859105571864915, 0.03332301078274251, -0.05703526232502032, 0.0721950909646861, -0.029718977660156295, -0.10875029104225584, 0.0664743957836482, 0.008616787454737523, -0.052372903481835084, 0.010790648905514993, -0.03232188870137073, 0.02630086538972421, 0.12047769747701711, 0.05654900697190538, 0.09587873750217418, -0.10537508309383221, 0.020565875138369005, 0.05077111239854169, 0.004580126090198335, -0.12745694067147767, 0.05088552392389764, -0.06281315902183474, -0.001681346164909205, -0.005767169023724248, 0.024355831236560082, 0.01034014460593291, -0.02860344192997784, -0.06304198844289881, -0.05832241959013414, 0.05303078249333612, 0.05071390238896226, 0.012185066126269715, 0.07065049715026775, 0.005520464394411359, 0.01975067603260209, 0.010082713152910146, 0.03335161578753223, 0.07831622860792052, 0.07522705371978822, 0.04593712989697036, -0.07871667107011705, 0.10039808830901668, 0.00705074869904743, -0.015731893698523035, 0.011877578993868508, 0.08672563498038689, -0.003105261089140719, -0.05837962747626284, 0.12985962941986848, -0.12265155892779457, 0.021681408745096723, -0.006664601944203429, -0.07871667107011705, -0.09353325876336281, -0.0559197287182926, 0.02103783329771591, 0.0559197287182926, -0.007830192716725103, 0.013150432694862105, -0.009868187295966297, 0.023140185421695183, 0.03910090535610619, 0.004033085261164059, -0.030777305504206046, 0.02808857944862246, 0.049512560138217594, 0.003589731894261796, -0.03981599225373593, 0.018649443866543863, 0.03852883498862211, 0.025800306472489053, -0.0040759904325528284, 0.12860108140644583, -0.017834246884227675, -0.014673565642128211, -0.04493600781559858]}}, {'id': 'https://huggingface.co/papers/2410.11710', 'title': 'MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models', 'url': 'https://huggingface.co/papers/2410.11710', 'abstract': 'Large Language Models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users. Recently, many tool-use benchmark datasets have been proposed. However, existing datasets have the following limitations: (1). Insufficient evaluation scenarios (e.g., only cover limited tool-use scenes). (2). Extensive evaluation costs (e.g., GPT API costs). To address these limitations, in this work, we propose a multi-granularity tool-use benchmark for large language models called MTU-Bench. For the "multi-granularity" property, our MTU-Bench covers five tool usage scenes (i.e., single-turn and single-tool, single-turn and multiple-tool, multiple-turn and single-tool, multiple-turn and multiple-tool, and out-of-distribution tasks). Besides, all evaluation metrics of our MTU-Bench are based on the prediction results and the ground truth without using any GPT or human evaluation metrics. Moreover, our MTU-Bench is collected by transforming existing high-quality datasets to simulate real-world tool usage scenarios, and we also propose an instruction dataset called MTU-Instruct data to enhance the tool-use abilities of existing LLMs. Comprehensive experimental results demonstrate the effectiveness of our MTU-Bench. Code and data will be released at https: //github.com/MTU-Bench-Team/MTU-Bench.git.', 'score': 5, 'issue_id': 121, 'pub_date': '2024-10-15', 'pub_date_ru': '15 октября', 'data': {'desc': 'В этой статье представлен новый бенчмарк MTU-Bench для оценки навыков использования инструментов большими языковыми моделями (LLM). MTU-Bench охватывает пять сценариев использования инструментов, от простых до сложных и нестандартных задач. Оценка производится без использования API GPT или человеческой экспертизы, что снижает затраты. Авторы также предлагают набор данных MTU-Instruct для улучшения способностей LLM в использовании инструментов.', 'categories': ['#benchmark', '#nlp', '#dataset', '#rlhf'], 'emoji': '🛠️', 'title': 'Многогранная оценка навыков LLM в использовании инструментов', 'embedding': [-0.027825905545227552, -0.00598734934856303, 0.12383590192401733, -0.05639525478511897, -0.04678363350831473, -0.021904935453124316, 0.023683882397844493, 0.13233237287956254, -0.05528009634613364, 0.07567159741562754, 0.06462619288525875, -0.09951479019133007, -0.03552582258205096, -0.04086266138677993, 0.0331361932967907, 0.0001733103607738907, -0.021719076051532026, -0.05735110487567783, -0.08453977499776791, 0.09054040636709484, 0.06770615969998811, 0.03202103485780538, 0.003833363856504123, -0.026936433087583242, 0.04253540411883683, -0.017829288923940027, -0.007779571211036647, 0.03164931402518922, 0.029950022269398063, 0.00654492937982832, 0.045562266797802994, -0.038818199851538435, -0.10179821526392706, 0.035632028824145796, 0.042243336445718135, 0.04951843257302532, 0.09229279819978609, 0.06425448219980043, 0.07338817640189367, 0.033985839174686276, -0.005678688434138847, -0.059050396631468986, 0.005516061153330855, 0.012240212069988437, -0.05926280911565866, 0.029418993088355435, 0.06021866326508064, 0.03366722450726489, -0.07142336802614964, 0.023351990174408636, -0.049173262793574986, 0.09781549640610734, -0.07503436199249007, -0.08268117692298184, 0.0071157857494491454, -0.11406497229878661, -0.023723709992309005, -0.002918998797168974, 0.03042794731467749, -0.03316274637938808, -0.03042794731467749, -0.0526249504409205, 0.012837619898661392, 0.041738862376704454, -0.08682320209979645, -0.04842982315777424, -0.022794408925484407, 0.034994795430439894, 0.01785584200653741, -0.027241775272569067, -0.03576478611940646, -0.0436240135340879, 0.0026816951318905497, -0.04333194789040078, 0.06653790524296585, -0.011271085438130891, 0.0070958719522168905, 0.10572782389768887, 0.0007840971663037858, 0.0010189114293529162, -0.016780509132585025, -0.0601124570229858, -0.03849958518411705, -0.005340157940053641, -0.01611672265628174, 0.0018685575101916516, -0.012266764137870036, -0.011470221381021876, -0.08257497271031856, -0.11587047638496731, -0.03616305800518843, -0.04383642195941445, 0.022502343281797278, 0.01194150917036774, 0.15081216565021244, -0.03483548708201342, 0.04973084302778343, -0.011868492455031222, 0.005018222107876017, 0.08007913718296346, -0.05233288276780181, 0.012200385287296552, 0.08889421671763532, -0.05204081509468311, 0.09123073780826926, -0.03008277956465872, 0.030295190019416832, 0.003395265188030268, -0.010627212759059862, 0.024480424139976874, -0.2400250112412901, 0.011782199807225483, -0.11268430332814311, 0.02628592315257865, 0.004102197176463797, -0.06568825530620713, -0.013780196695012058, 0.03385308187942562, 0.023219231864432196, -0.06988338664821653, -0.0028841500071630517, 0.02681695334833706, 0.06913994295355265, -0.1142773847829763, 0.07466264115987391, -0.007441040716951443, 0.0027762847047637677, -0.019488755114698237, 0.010554196246666502, 0.06112140921987629, -0.059900044538796125, 0.039800605054126234, 0.007261818368349555, -0.05259839735832312, -0.0671220365303401, -0.03345481405250678, -0.1293586062186333, 0.08172532480299143, -0.06590066779039681, -0.04118128011306445, 0.003587763063215064, -0.04333194789040078, -0.025715067391787295, 0.08268117692298184, -0.14263431545038335, 0.01700619612864183, -0.018293941486783892, 0.0747688453725372, 0.014377603306026075, 0.09999271726604106, -0.05650146102721381, -0.07721158488185534, -0.053872866175166484, 0.0023464831643005475, -0.06478550326311679, -0.09404519815020357, -0.04001301753831591, 0.11438359305450269, 0.03687994861725491, -0.173965024955309, 0.10418783846089262, 0.027985215923085588, 0.016899991915978557, 0.07954810800192084, 0.015107767821130219, 0.16599958723966957, -0.03988026024305526, 0.014404154968021363, -0.11470220975135566, -0.07057372620711719, 0.011403842124562079, -0.009697912301064732, -0.026511611163351236, -0.06048417379673883, 0.021825282293626864, -0.10535610509450428, -0.11629529729448353, -0.0463057084630353, 0.03122449108624143, -0.0593690153577535, -0.05798834029881529, 0.10100166337463685, -0.13764264439567314, -0.012021163344580978, -0.10498438223245657, -0.06473240318621672, -0.008383616904472637, 0.053235634810892156, -0.03082621920045946, 0.005436406979117617, -0.034994795430439894, 0.10928572184599236, 0.15463558224790036, 0.1365805921218826, 0.10355060912604984, -0.030958976495720117, 0.10737401151771682, 0.055970429816739616, -0.047553624197281284, 0.04885464406729047, 0.08507080823767366, 0.03090587438938848, -0.025715067391787295, -0.11172844714928956, 0.04067680198518763, 0.036455125678307124, -0.015745002838381372, 0.026949708614166155, -0.07784881218726654, -0.061068307113544655, -0.010613937232476953, 0.1094981302713189, 0.05968763205460645, -0.00443409041461544, -0.0300562285114929, -0.02305992351600572, -0.07073303658497523, -0.05480216927142265, 0.01910375977021496, 0.09160245864088543, -0.003737115020383303, 0.032233443283131914, 0.07275094097875622, 0.040437838447832136, -0.029286237822526342, 0.02510438505124721, 0.0408095592804483, -0.09101832532407958, 0.10694919669649529, -0.06675031772715552, 0.0019565090153586804, -0.07009579507354306, -0.05429768911411428, -0.12064972683776157, 0.017630155010480607, -0.03576478611940646, 0.025807998107299224, -0.00988377271737281, -0.005323563278146059, -0.08570804163137957, 0.09685964834498005, 0.016793785673883718, 0.032658268251511274, -0.018307215998651018, 0.037145459148913096, -0.018904623827323976, -0.03918992068415459, -0.009173521796557763, 0.04550916266203979, 0.03557892468838259, 0.008834991302472558, -0.07423782430922081, -0.06037796755464398, -0.06356414467033132, -0.008848266829055467, 0.004161937959331092]}}, {'id': 'https://huggingface.co/papers/2410.11419', 'title': 'GS^3: Efficient Relighting with Triple Gaussian Splatting', 'url': 'https://huggingface.co/papers/2410.11419', 'abstract': 'We present a spatial and angular Gaussian based representation and a triple splatting process, for real-time, high-quality novel lighting-and-view synthesis from multi-view point-lit input images. To describe complex appearance, we employ a Lambertian plus a mixture of angular Gaussians as an effective reflectance function for each spatial Gaussian. To generate self-shadow, we splat all spatial Gaussians towards the light source to obtain shadow values, which are further refined by a small multi-layer perceptron. To compensate for other effects like global illumination, another network is trained to compute and add a per-spatial-Gaussian RGB tuple. The effectiveness of our representation is demonstrated on 30 samples with a wide variation in geometry (from solid to fluffy) and appearance (from translucent to anisotropic), as well as using different forms of input data, including rendered images of synthetic/reconstructed objects, photographs captured with a handheld camera and a flash, or from a professional lightstage. We achieve a training time of 40-70 minutes and a rendering speed of 90 fps on a single commodity GPU. Our results compare favorably with state-of-the-art techniques in terms of quality/performance. Our code and data are publicly available at https://GSrelight.github.io/.', 'score': 4, 'issue_id': 121, 'pub_date': '2024-10-15', 'pub_date_ru': '15 октября', 'data': {'desc': 'Статья представляет новый метод синтеза изображений с изменением освещения и ракурса в реальном времени. Авторы используют представление на основе пространственных и угловых гауссианов, а также процесс тройного сплаттинга. Для описания сложных визуальных эффектов применяется функция отражения, состоящая из ламбертовской составляющей и смеси угловых гауссианов. Метод демонстрирует высокое качество результатов на разнообразных объектах при быстром обучении и рендеринге.', 'categories': ['#cv', '#rl', '#multimodal'], 'emoji': '🎨', 'title': 'Реалистичный рендеринг с динамическим освещением на основе гауссианов', 'embedding': [-0.0240430555213835, -0.02645137684060785, 0.08552210666143689, -0.03684728906669504, -0.03093352697206664, -0.10141701435194758, 0.05908410631040403, -0.0684497923751615, -0.05212673939547591, -0.005391959901418043, 0.03933588450913436, 0.022718481507553855, -0.03615155107356523, -0.07931399237551856, 0.04310892232728335, 0.051939422984130956, -0.02448458163892338, -0.06497111108709244, -0.07235662546059045, 0.05303654894849566, -0.051002856113171215, -0.11335157215175436, 0.02437754585897841, 0.058174296757384274, 0.0019149485051508572, -0.04642704886073745, 0.09156965751516025, 0.025073281682713222, 0.01830322900973505, -0.032003890195003847, -0.005682965150100714, -0.021193212423409272, -0.02790974829111246, -0.11720488409311833, -0.017473695749325276, 0.07728029954019411, 0.018410264789680025, 0.17479047646792273, -0.13379552760736382, 0.05977984213413884, 0.01875813378624493, 0.05913762094628401, 0.08969652160384575, 0.06877090622318141, 0.10329014592447208, 0.03872042497800954, -0.01594842753293869, 0.010957853650300038, -0.00492033039108892, 0.021099553133039295, -0.0835954452672674, 0.09884813610871328, 0.010068113170432779, -0.01542662425503083, -0.0403259725241591, -0.10382532916298694, -0.02253116726560391, 0.012202152673156701, 0.01564069733349727, -0.020724928987929398, -0.019025724320804856, -0.07995620705518838, -0.011479656060449896, 0.05078878238388627, 0.007311925457917524, -0.0573180040096395, -0.044393358194808, 0.06202760869874823, 0.04005838198959918, 0.012978166308077991, 0.03601775580628526, 0.05758559454419943, 0.07749437326947906, -0.08525451178808695, -0.06941311873345624, -0.0159082885188757, 0.012362707427771657, 0.019159519588084824, 2.6968161440120834e-05, 0.026826005324507747, -0.0020989174315398074, 0.08755579515797132, -0.024243748422303448, -0.05726448720436452, -0.05747855876425446, -0.08723469215692642, 0.02750836031987756, -0.0942990883436145, -0.162695370421686, 0.10066775955354278, 0.04872833006122683, 0.03965699618775928, -0.02188894824714408, -0.02911390569663213, 0.03700784382131, 0.06604147322533215, 0.03989782940437922, 0.026665448400497792, 0.16301647559212593, 0.057103934619144564, 0.007994283056561339, 0.0662020258105521, 0.029435015205862045, -0.09553000957525917, 0.16729793716145477, -0.05020008234009642, 0.055712460802279935, 0.07845769528898379, 0.07187496336614058, 0.07257068834290038, -0.06331204456627289, -0.02048409577130946, 0.0403259725241591, 0.03556285319917039, -0.013740801067089786, -0.07872528365414873, -0.058388370486669214, -0.0058702791751111625, -0.015185793207805895, -0.01867785640893745, -0.10666179794078116, 0.014142187085869177, 0.04787204165227206, -0.034867113036645574, 0.07669160166579927, -0.06390074461006272, 0.06684424482901193, -0.13507996781367848, 0.020577750722889435, 0.0037395850964179887, 0.0447679823399179, -0.0654527731815423, 0.007091163266905583, -0.06946663553873121, -0.09462019568344943, -0.004448701314638797, 0.02940825788792205, 0.03310101290527605, -0.040433010473499065, 0.06673721121846196, -0.02892659362407718, 0.10200571222634243, 0.024912726928098265, 0.04902268442191175, 0.02483245063548829, 0.04904944173985174, -0.11228120784411964, 0.05432098481602031, -0.03446572723480568, 0.0820969400092478, -0.04110198680989889, -0.016282915918078098, -0.13754181244636282, -0.05464209215585522, -0.062455753987923114, -0.1543465101653383, -0.036392382120790163, 0.09403149780905458, -0.05870947782650413, -0.06716535650763684, 0.04832694425938694, 0.008295323058759758, 0.02863224360218226, 0.02972936739715196, -0.1138867510514792, 0.012295809794131677, -0.1246974320771663, 0.036231829535570206, -0.11602748834432863, -0.13625735705428316, -0.05156479450023106, -0.05116340869839117, -0.03350240087651094, -0.07208903492603051, 0.07572827096871453, 0.02693303893505772, 0.016630784480764004, -0.0008157346065676232, -0.04185124160830368, -0.019146140929114822, -0.06791460696725163, 0.0876628287685213, -0.018249710035065068, 0.03427841516225073, -0.03136167226124152, 0.07530012351014465, 0.002664203628964905, -0.023347319697648687, 0.009579759794042412, 0.0769056667175042, -0.11859636007937793, 0.10462809859727171, -0.01815605399878759, 0.1013099720638176, 0.004672808929681487, -0.04998600861081149, 0.06909201139362132, -0.00011613033936131704, -0.014490055214676082, 0.002023657430990203, 0.08343489485144245, 0.08627135929044667, 0.005465547298422023, -0.1176330315516882, 0.03088000799739665, -0.0004137208516507975, 0.043724377519618184, -0.10468161757194169, -0.11217417423356968, 0.0454904776509877, 0.04990573014880651, 0.007666483567027927, 0.07246365907114041, -0.0020671410013259413, -0.06138538968028841, 0.005492306568817515, -0.0014324484168000754, 0.014262603260300145, 0.029301219938582077, 0.0414230941497338, -0.05303654894849566, 0.0551237585890951, 0.03631210799757518, -0.04096819154261892, 0.029622329447811995, 0.05389284169624043, 0.10612661253287131, -0.1298351798860549, 0.07246365907114041, -0.08541506220391192, 0.01927993619639479, 0.012583469401844098, -0.028899834136742186, -0.02115307210770928, 0.02283889811586383, -0.06572036588549723, 0.013232377749788924, -0.12116523398382226, -0.036552939044800115, -0.02964909110454199, 0.009265340698994996, 0.012529951077992613, 0.035696648466450355, -0.07706622581090916, 0.034385453111590705, 0.0917302144391702, -0.06534573740159734, -0.02452472086992587, 0.05070850609127629, 0.004054004625344404, -0.04059356305871902, -0.07540716362887961, -0.05343793475033555, -0.08921485734000088, -0.0377303413017748, -0.010529708361125153]}}, {'id': 'https://huggingface.co/papers/2406.15786', 'title': 'What Matters in Transformers? Not All Attention is Needed', 'url': 'https://huggingface.co/papers/2406.15786', 'abstract': 'While scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks, it also introduces redundant architectures, posing efficiency challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy across different architectures in transformers, such as MLP and Attention layers, is under-explored. In this work, we investigate redundancy across different modules within Transformers, including Blocks, MLP, and Attention layers, using a similarity-based metric. Surprisingly, despite the critical role of attention layers in distinguishing transformers from other architectures, we found that a large portion of these layers exhibit excessively high similarity and can be pruned without degrading performance. For instance, Llama-2-70B achieved a 48.4\\% speedup with only a 2.4\\% performance drop by pruning half of the attention layers. Furthermore, by tracing model checkpoints throughout the training process, we observed that attention layer redundancy is inherent and consistent across training stages. Additionally, we further propose a method that jointly drops Attention and MLP layers, allowing us to more aggressively drop additional layers. For instance, when dropping 31 layers (Attention + MLP), Llama-2-13B still retains 90\\% of the performance on the MMLU task. Our work provides valuable insights for future network architecture design. The code is released at: https://github.com/Shwai-He/LLM-Drop.', 'score': 1, 'issue_id': 121, 'pub_date': '2024-06-22', 'pub_date_ru': '22 июня', 'data': {'desc': 'Это исследование посвящено проблеме избыточности в архитектуре больших языковых моделей (LLM) на базе трансформеров. Авторы обнаружили, что значительная часть слоев внимания (attention layers) обладает высокой схожестью и может быть удалена без существенной потери производительности. Например, модель Llama-2-70B достигла ускорения на 48.4% при снижении производительности всего на 2.4% после удаления половины слоев внимания. Исследователи также предложили метод совместного удаления слоев внимания и MLP, что позволяет еще более агрессивно сокращать архитектуру модели.', 'categories': ['#nlp', '#benchmark', '#code'], 'emoji': '✂️', 'title': 'Оптимизация LLM: меньше слоев, та же мощность', 'embedding': [0.07973888359077871, 0.01813971157876565, 0.060676386777125876, -0.035748502926044506, 0.061889910692635525, 0.08929541357829962, 0.003909202489554159, 0.07999169738717994, -0.08191311561485319, 0.12640912990402067, -0.05673242198845783, -0.05339521714700099, -0.06815980101063218, 0.06492373455521495, 0.03610244706631088, -0.05334465599615564, 0.1036554941613627, -0.10931862453214812, 0.005609405629560923, 0.08039621072046613, 0.00690193888280499, 0.029276355941404767, 0.05334465599615564, 0.027582472945253667, 0.11002651080213727, -0.00976510579274786, 0.015978115821315295, -0.06598557300764493, 0.06315400179062138, -0.11629640514122114, 0.05329409283476667, -0.05208056288762618, -0.08166029980790834, 0.057844817570645926, -0.03511645637177978, 0.05931116734581848, 0.07185095803452984, 0.060170749131605375, -0.03372595636504971, 0.08343003056195833, 0.07660393742650859, -0.04611405153796332, -0.05971567665801745, 0.043914534917378956, -0.0031791897849665117, 0.08833470144864758, 0.05101872644573981, 0.05779425843034419, -0.027582472945253667, 0.09642488769262676, -0.07043517343128987, 0.05703580095679163, -0.059968492464962275, -0.022551389128732967, -0.04426847905764533, -0.10446450876467338, 0.018228197613832247, 0.02090807130451445, -0.0017634073933245145, 0.01910041968733047, -0.029301638527371054, -0.08120522733432042, 0.04836413735156752, -0.01588962777570508, -0.06800811152646527, -0.039793596048034105, -0.14531994125459385, 0.025357673738703006, 0.011629640112013392, 0.045608415902986435, -0.044420172562899464, -0.013032782014889688, 0.02327192171806429, -0.023828122524973763, 0.08393566217584798, 0.04778265395869175, 0.01528286461162409, 0.1559383056734575, 0.03051516445342432, 0.042397626001904665, 0.0836322852180578, 0.028897129215172096, 0.06371020661861808, -0.0644686580605398, 0.02877071829588426, 0.00540083022644269, 0.0018044904394571581, -0.019745106529306538, -0.024864676380893836, -0.07801971599811772, 0.026065564029779376, 0.02117353142025785, -0.061940475864568106, 0.034181030849181254, 0.007584548196349963, 0.02266515774976585, 0.03868119443421515, 0.029478610597504246, 0.07599716943712292, 0.12489222500963361, 0.058653840216131084, 0.060474130110482784, 0.03511645637177978, -0.05728862078482369, -0.01717900145965722, -0.09192472008650562, 0.07427800586554915, -0.10871185252167523, -0.061889910692635525, 0.027734164439964185, -0.050917598112418264, 0.013020140922960905, -0.05197943455430463, 0.03544512395771071, 0.030363474969257422, -0.06881713618249403, -0.10350380266665218, 0.0735701175850164, 0.012419697701681219, 0.027683599268031604, 0.01655959619837563, -0.0078879295773361, 0.07235658964841951, -0.017431819277145665, 0.0012949036841668703, -0.03385236728433754, 0.09248092491450233, -0.04975463735829758, 0.014132541330453684, -0.0009678199240745688, 0.03359954745630549, 0.06269893132757706, 0.08459299533716623, -0.05079119121421766, -0.0068892977908762065, -0.02990840048512588, -0.049653509024976034, 0.03223433003554171, -0.08853696213637789, 0.017659356519211435, 0.07822196864367358, -0.002711476018395441, 0.0033877647859760223, 0.04457186204706636, -0.0012253785631977498, 0.09025612168686444, 0.07822196864367358, 0.023562662409230363, -0.10982425614603779, 0.09824517959752209, -0.0013667987937391987, -0.06325513012394292, -0.08393566217584798, -0.029958963646514847, -0.1290384384227703, -0.07008122124884904, 0.02596443569645783, 0.06942389612970525, 0.1633205996158167, -0.1163975334745427, 0.02689986524014359, 0.05364803898557667, 0.021502192974557938, 0.01687562048077981, -0.00812178736536626, 0.09930701603940845, -0.12337532011524656, -0.023828122524973763, -0.15876987487993746, -0.15209546519702377, -0.0611314592507138, -0.047100044243038056, 0.015131173519022299, -0.10158238443897892, -0.010618367032570353, 0.00017005978097185087, -0.09369445486164282, -0.0461646146993523, -0.02023810187657209, -0.013475213396548832, -0.016155087891448483, 0.001189035896380246, -0.05339521714700099, 0.08019395003273579, -0.09237979457063718, -0.048288291604212254, -0.05688410946208111, 0.07169926251873211, 0.013626904690204984, 0.058047074237289026, -0.03587491384533235, 0.0960203763698842, 0.03984416121996669, 0.02408094034246221, 0.0772106973737198, 0.00046692376366818967, 0.06219329569260017, 0.03789746040632714, -0.029074101285305284, -0.08732343017869379, 0.0073317299767527945, 0.12772379421611357, 0.06694628111620976, -0.13773540672994047, 0.0828232686042035, -0.0349394863121902, -0.026444790756012047, 0.0032123719978528944, -0.00883599880557011, -0.049173153965421816, 0.06942389612970525, 0.005767416866018384, 0.0013217655521432223, -0.05991792930357331, 0.05208056288762618, -0.06815980101063218, -0.09875081925358621, 0.07230602447648694, 0.036734495631119225, 0.04664497176945013, 0.0946046018193623, -0.0014789869264358534, 0.04664497176945013, 0.013500495379352039, -0.08873921679247739, -0.0029737749564120166, 0.03913626690780308, -0.13884780030158497, 0.058754966538909006, -0.012640912990402068, -0.02978199157638166, 0.004180982347044504, -0.05223225438233669, -0.032866376589806436, 0.037214848680129836, -0.1347015768357302, 0.05541776370799579, -0.02319607798125265, -0.015952833235349, -0.0848458151651983, 0.0565807284832037, 0.010529880394340675, -0.024940524138792712, -0.04613933412392962, 0.04191727094235045, 0.06735078640732148, -0.03681033936793087, -0.047453988383304425, 0.04464770578387801, 0.06780586491254026, -0.005508277899402461, 0.02286741240586533, -0.09516079860518453, -0.07250828114313003, -0.09162134312871545, 0.0480101891902139]}}, {'id': 'https://huggingface.co/papers/2410.10626', 'title': 'Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts', 'url': 'https://huggingface.co/papers/2410.10626', 'abstract': 'Adapting medical Large Language Models to local languages can reduce barriers to accessing healthcare services, but data scarcity remains a significant challenge, particularly for low-resource languages. To address this, we first construct a high-quality medical dataset and conduct analysis to ensure its quality. In order to leverage the generalization capability of multilingual LLMs to efficiently scale to more resource-constrained languages, we explore the internal information flow of LLMs from a multilingual perspective using Mixture of Experts (MoE) modularity. Technically, we propose a novel MoE routing method that employs language-specific experts and cross-lingual routing. Inspired by circuit theory, our routing analysis revealed a Spread Out in the End information flow mechanism: while earlier layers concentrate cross-lingual information flow, the later layers exhibit language-specific divergence. This insight directly led to the development of the Post-MoE architecture, which applies sparse routing only in the later layers while maintaining dense others. Experimental results demonstrate that this approach enhances the generalization of multilingual models to other languages while preserving interpretability. Finally, to efficiently scale the model to 50 languages, we introduce the concept of language family experts, drawing on linguistic priors, which enables scaling the number of languages without adding additional parameters.', 'score': 1, 'issue_id': 121, 'pub_date': '2024-10-14', 'pub_date_ru': '14 октября', 'data': {'desc': 'Статья посвящена адаптации больших языковых моделей (LLM) для медицинских целей в различных языках. Авторы создают качественный медицинский датасет и исследуют внутренние механизмы многоязычных LLM с использованием модульности Mixture of Experts (MoE). Они предлагают новый метод маршрутизации MoE с языково-специфичными экспертами и кросс-языковой маршрутизацией. На основе анализа информационного потока разработана архитектура Post-MoE, применяющая разреженную маршрутизацию только в поздних слоях модели.', 'categories': ['#nlp', '#dataset', '#multimodal'], 'emoji': '🏥', 'title': 'Многоязычные медицинские LLM: преодоление языковых барьеров в здравоохранении', 'embedding': [0.027926801633037828, 0.037439522828982434, 0.09742590695806506, 0.04262383315726325, -0.0643147909544701, 0.036754801643578285, -0.001386252783215639, 0.02526128521715111, -0.1666804626504423, 0.07199343841285567, 0.02188659184413999, -0.12853175477978285, -0.07013491496699086, 0.05805449134691886, 0.026166093189501416, -0.09781717505193133, 0.023292713830252353, -0.033233384756505474, 0.0010989148472907325, 0.08304677621254514, 0.07551485934220481, 0.015345069052049175, 0.04494699201215513, -0.0058048377403988796, 0.05252782244707413, -0.05986410729161947, 0.09145905842091352, 0.05184310328280815, -0.002925344640333566, -0.03726834253263139, 0.07786246790540248, -0.026875268125487663, -0.06720039819957929, 0.07717774671999832, -0.07629739957221368, 0.036608077118947514, 0.018597490640442544, 0.051060563052799275, 0.05546233517220937, 0.04961775943024468, -0.020492697743887754, -0.08739964487306734, -0.03986049870734088, 0.0711619906816826, -0.036241264796801495, 0.04340637136613396, 0.07844936600392557, 0.006810520314022237, 0.02870933984190854, 0.052625639470540705, -0.029002792933446406, 0.05365271922750876, -0.006296980435538207, -0.05917939014849165, -0.01812063138783167, -0.09004070652780288, 0.1042731046641394, 0.022644674281290442, 0.023133761419761447, -0.02483333447627352, 0.028146891451691226, -0.10505564489414826, 0.005728418304504644, -0.016164286876223965, 0.002041933649214145, 0.014000083059302594, -0.06905892164544411, -0.04000722323197166, 0.03037223126197838, 0.035165275517531076, -0.039738225912154056, -0.037048252713978, 0.08285114822902646, -0.026752997351438993, -0.030249960487929706, -0.0623584464428624, -0.13479206853530118, 0.07590612743607109, -0.009249836808487987, -0.04538716760718561, -0.009567741831583614, -0.015650748008309012, 0.06852092902694706, -0.041181029534708646, 0.017044642108561246, -0.034015922965376186, 0.03673034587185803, 0.02496783313618232, -0.09292631377291206, -0.134009524263016, 0.022241180322702194, -0.05590251480951618, -0.011132817036642147, 0.04428672659847125, 0.08011226550854805, 0.04876185996962766, -0.012728459935212847, -0.059472843240029515, 0.10124077491553758, 0.12647761143495198, 0.05243000542360757, -0.0421347480399304, 0.027315445741656307, -0.12882522404042598, 0.08930708188351084, -0.10212112610559855, -0.03548317831737473, -0.05076710996126141, -0.07287379364519296, 0.019111029508357493, -0.021972180981746428, 0.035776631408912594, 0.05252782244707413, 0.03543427081621052, 0.09072543175548334, -0.0421347480399304, -0.10055604968785713, 0.0020021952434206946, 0.015393977968010092, 0.015308387415606941, -0.012233260066494674, 0.03460282712731376, 0.06690694915031774, -0.010882160737159474, 0.11943476755511556, -0.06294534858366181, -0.004793041628073089, 0.004410942831691383, -0.003359408515685958, 0.002263550639860258, 0.010570368646424832, 0.036925981939929325, 0.09679009327382512, -0.09185032853591796, -0.13665058591775153, 0.016800098539325743, -0.061233549662427764, -0.015993108601011084, -0.030836864649867284, -0.048297228602876906, 0.021311915568062546, -0.026043821404883667, 0.004401772725751548, -0.028000166927060453, -0.049911212521782544, -0.01695905297095481, 0.0019318891441150764, 0.048712952468463445, -0.05438634993521527, 0.06543968369262841, -0.0648527855941053, -0.10593599608420923, 0.0021840740303871735, 0.10730543845501753, -0.09811062410119288, -0.02187436395827986, -0.025579191048702002, 0.037048252713978, 0.12667323739733247, -0.0313993130400846, -0.01311972782696531, 0.11200066366596549, 0.010172985801173227, -0.040447400848140296, 0.0643147909544701, 0.05546233517220937, -0.10896832987508735, -0.032719841846314206, -0.11082685736322849, -0.15083407655292383, -0.07615066494189211, -0.039933859959087194, -0.07893846122694921, -0.02741326276512288, -0.028782703114793008, -0.06294534858366181, 0.0041664004751387745, -0.15063845059054334, 0.02861152281844197, 0.009763376686972016, -0.03389365017018935, 0.11053340225055247, -0.0701838204470169, 0.08691055773459633, -0.026801905863172278, 0.0023139873341553353, -0.039102414249052274, 0.08876908724387562, 0.04122993905701102, -0.026215002711803784, -0.015968652829290823, 0.11601116769150932, 0.10319712144828345, 0.05629378492452061, 0.10172985801173226, 0.014953800351841448, 0.14936681917978714, 0.05570688076258303, -0.02314598930562158, -0.04037403555411767, 0.003747620244428651, 0.03445609856040667, 0.0014114713324769935, -0.1847766342242774, 0.04147448262624652, 0.024221976563753845, -0.050278024843928563, 0.07737338278806963, 0.06045101145355705, -0.035263092540997645, 0.03638798730029411, 0.07756901885614091, 0.13870474947396394, 0.046120798314892124, 0.01571188339533335, 0.039151321750216475, -0.11708715494964157, 0.026924175626651867, 0.09434466768716089, 0.0029314583811498153, 0.028440344543229093, -0.02858706704672171, 0.06514623868564318, -0.0005574814431923104, -0.03293993368610577, -0.0211774189292919, 0.03418710124058906, -0.09884425076662308, 0.06172263477976061, -0.04929985258812471, 0.06597768035340178, -0.037855246694568974, 0.02447874801884948, -0.08808436201619517, 0.11366355508603533, -0.022889217850525945, 0.07854718909080662, -0.0009063372463267051, 0.007110085933693458, -0.029149517458077184, 0.03487182242599321, 0.039567047636941174, 0.023720664571129944, -0.07874282515887791, -0.0023094021801285105, 0.058396853960759096, -0.030445594534862848, -0.056000331832982746, 0.06054882847702362, -0.004579066358691201, -0.04656097390992261, -0.08896472129080878, -0.0007668713564335565, -0.08691055773459633, -0.0565383244514798, 0.07571049338913795]}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'default';        

        function loadSettings() {
            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            const themeToggle = document.getElementById('theme-toggle');
            let settingSortBy = localStorage.getItem('sort_by');
            const sortDropdown = document.getElementById('sort-dropdown');
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "хф найтли";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'default';
            }
            
            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            return Array.from(categories);
        }
        
        function createCategoryButtons() {
            const categories = getUniqueCategories(articlesData);
            categories.forEach(category => {
                const button = document.createElement('span');
                button.textContent = category;
                button.className = 'category-button';
                button.onclick = () => toggleCategory(category, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if (selectedArticles.length === articlesData.length) {
                categoryToggle.textContent = '🏷️ Фильтр';
            } else {
                categoryToggle.textContent = `🏷️ Фильтр (${formatArticlesTitle(selectedArticles.length)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const savedCategories = localStorage.getItem('selectedCategories');
            if (savedCategories) {
                if (savedCategories != '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);
                    updateCategoryButtonStates();
                }
            }
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles = selectedCategories.length === 0
                ? articlesData
                : articlesData.filter(article => 
                    article.data && article.data.categories && 
                    article.data.categories.some(cat => selectedCategories.includes(cat))
                );

            console.log('filteredArticles', filteredArticles)

            if (filteredArticles.length === 0) {
                selectedArticles = articlesData;
                selectedCategories = [];
                cleanCategorySelection();
            } else {
                selectedArticles = filteredArticles;
            }

            console.log('selectedArticles', selectedArticles)

            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
        }

        function renderArticles(articles) {
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                const explanation = item["data"]["desc"];
                const cats = item["data"]["categories"].join(" ");
                const articleHTML = `
                    <article>
                        <div class="background-digit">${index + 1}</div>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <h2>${item['data']['emoji']} ${item['title']}</h2>
                            <p class="meta"><svg class="text-sm peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path transform="translate(0, 2)" fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg> ${item['score']}. ${item['data']['title']}</p>
                            <p class="pub-date">📅 Статья от ${item['pub_date_ru']}</p>
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>
                            <div class="links">
                                <a href="${item['url']}" target="_blank">Статья</a>
                            </div>
                            <p class="tags">${cats}</p>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            }
            if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
        });

        clearCategoriesButton.addEventListener('click', clearAllCategories);
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiffRu('2024-10-16 04:59');
        } 

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();  
    </script>
</body>
</html>
    