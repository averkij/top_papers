[07.11.2024 08:15] Read previous papers.
[07.11.2024 08:15] Generating top page (month).
[07.11.2024 08:15] Writing top page (month).
[07.11.2024 10:12] Read previous papers.
[07.11.2024 10:12] Get feed.
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02959
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00871
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2410.23054
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02359
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02393
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.01493
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.01602
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.03047
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.03312
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02657
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02844
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 0. Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial systems such as ChatGPT and Perplexity have used Web search engines as their...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 1. Large Language Models (LLMs) have demonstrated remarkable generalization and instruction-following capabilities with instruction tuning. The advancements in LLMs and instruction tuning have led to the development of Large Vision-Language Models (LVLMs). However, the competency of the LLMs and instru...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 2. The increasing capabilities of large generative models and their ever more widespread deployment have raised concerns about their reliability, safety, and potential misuse. To address these issues, recent works have proposed to control model generation by steering model activations in order to effec...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 3. MLLMs have demonstrated remarkable comprehension and reasoning capabilities with complex language and visual data. These advances have spurred the vision of establishing a generalist robotic MLLM proficient in understanding complex human instructions and accomplishing various embodied tasks. However...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 4. Current vision systems typically assign fixed-length representations to images, regardless of the information content. This contrasts with human intelligence - and even large language models - which allocate varying representational capacities based on entropy, context and familiarity. Inspired by t...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 5. We study methods for efficiently aligning large language models (LLMs) with human preferences given budgeted online feedback. We first formulate the LLM alignment problem in the frame of contextual dueling bandits. This formulation, subsuming recent paradigms such as online RLHF and online DPO, inhe...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 6. We introduce DreamPolish, a text-to-3D generation model that excels in producing refined geometry and high-quality textures. In the geometry construction phase, our approach leverages multiple neural representations to enhance the stability of the synthesis process. Instead of relying solely on a vi...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 7. Neural implicit functions have brought impressive advances to the state-of-the-art of clothed human digitization from multiple or even single images. However, despite the progress, current arts still have difficulty generalizing to unseen images with complex cloth deformation and body poses. In this...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 8. Vision Language Models (VLMs) have demonstrated strong capabilities across various visual understanding and reasoning tasks. However, their real-world deployment is often constrained by high latency during inference due to substantial compute required to process the large number of input tokens (pre...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 9. Rare diseases present unique challenges in healthcare, often suffering from delayed diagnosis and fragmented information landscapes. The scarcity of reliable knowledge in these conditions poses a distinct challenge for Large Language Models (LLMs) in supporting clinical management and delivering pre...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 10. As object detection techniques continue to evolve, understanding their relationships with complementary visual tasks becomes crucial for optimising model architectures and computational resources. This paper investigates the correlations between object detection accuracy and two fundamental visual t...
[07.11.2024 10:12] Read previous papers.
[07.11.2024 10:12] Generating reviews via LLM API.
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#rag", "#data", "#training"], "emoji": "ğŸŒ", "ru": {"title": "HtmlRAG: Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ RAG-ÑĞ¸ÑÑ‚ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ²ĞµĞ±-Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ (RAG), Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ HtmlRAG. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ RAG, Ğ¸ÑĞ¿Ğ¾
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#multimodal", "#dataset", "#agents", "#architecture", "#training"], "emoji": "ğŸ§¬", "ru": {"title": "LLaMo: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğ¸ Ğ¼Ğ¾Ğ»ĞµĞºÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ LLaMo - Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ¼Ğ¾Ğ»ĞµĞºÑƒĞ»ÑÑ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ°Ğ¼Ğ¸, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ ÑĞ·Ñ‹ĞºĞ¾
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#cv", "#rlhf"], "emoji": "ğŸ›ï¸", "ru": {"title": "AcT: Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ¾Ğ²", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ AcT (Activation Transport) - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#agents", "#inference", "#robots", "#optimization", "#benchmark"], "emoji": "ğŸ¤–", "ru": {"title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ²: Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ², Ñ‚Ğ° Ğ¶Ğµ Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Dynamic Early-Exit Framework Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ·Ñ€ĞµĞ½Ğ¸Ñ, ÑĞ·Ñ‹ĞºĞ° Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#cv", "#architecture", "#training"], "emoji": "ğŸ–¼ï¸", "ru": {"title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€-Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#rlhf", "#alignment", "#agents"], "emoji": "ğŸ¯", "ru": {"title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ñ… Ğ´ÑƒÑĞ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ°Ğ½Ğ´Ğ¸Ñ‚Ğ¾Ğ²", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸Ğ·ÑƒÑ‡Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¿Ñ€Ğ¸ Ğ¾Ğ³Ñ€Ğ°
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#3d", "#cv"], "emoji": "ğŸ¨", "ru": {"title": "DreamPolish: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 3D-Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ñ Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸ĞµĞ¹ Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸", "desc": "DreamPolish - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 3D-Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¸ ÑƒÑ‚Ğ¾Ğ½Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#dataset", "#3d", "#cv"], "emoji": "ğŸ‘š", "ru": {"title": "GarVerseLOD: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² 3D-Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹ Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ", "desc": "GarVerseLOD - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ 3D-Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹ Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ 6000 Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ 
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#inference", "#cv", "#training"], "emoji": "ğŸ”¬", "ru": {"title": "ĞœĞµĞ½ÑŒÑˆĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ VLM", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LLM) Ğ² vision-language Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (VLM).
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#rag", "#medicine", "#training", "#alignment"], "emoji": "ğŸ¦“", "ru": {"title": "Zebra-Llama: Ğ˜Ğ˜-ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ñ€ĞµĞ´ĞºĞ¸Ğ¼ Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°Ğ½Ğ¸ÑĞ¼", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Zebra-Llama - ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ñ€ĞµĞ´ĞºĞ¸Ñ… Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°Ğ½Ğ¸Ğ¹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ÑĞ¸Ğ½Ğ´Ñ€Ğ¾Ğ¼ Ğ­Ğ»ĞµÑ€ÑĞ°-Ğ”Ğ°Ğ½Ğ»Ğ¾ÑĞ° (EDS) ĞºĞ°Ğº Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€. ĞœĞ¾
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#cv", "#architecture", "#dataset"], "emoji": "ğŸ‘ï¸", "ru": {"title": "Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñƒ Ğ² ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ·ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼
[07.11.2024 10:12] Trying to get texts in Chinese.
[07.11.2024 10:12] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial systems such as ChatGPT and Perplexity have used Web search engines as their major retrieval systems. Typically, such RAG systems retrieve search results, download HTML sources of the results, and then extract plain texts from the HTML sources. Plain text documents or chunks are fed into the LLMs to augment the generation. However, much of the structural and semantic information inherent in HTML, such as headings and table structures, is lost during this plain-text-based RAG process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG. We believe HTML is better than plain text in modeling knowledge in external documents, and most LLMs possess robust capacities to understand HTML. However, utilizing HTML presents new challenges. HTML contains additional content such as tags, JavaScript, and CSS specifications, which bring extra input tokens and noise to the RAG system. To address this issue, we propose HTML cleaning, compression, and pruning strategies, to shorten the HTML while minimizing the loss of information. Specifically, we design a two-step block-tree-based pruning method that prunes useless HTML blocks and keeps only the relevant part of the HTML. Experiments on six QA datasets confirm the superiority of using HTML in RAG systems.
[07.11.2024 10:12] Mistral response. {"id": "4a1aacf1ed26437f8624e79af4cb98d7", "object": "chat.completion", "created": 1730974365, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u79f0\u4e3aHtmlRAG\u3002\u4f20\u7edf\u7684RAG\u7cfb\u7edf\u4ece\u7f51\u9875\u68c0\u7d22\u4fe1\u606f\uff0c\u63d0\u53d6\u7eaf\u6587\u672c\u5582\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u7136\u800c\uff0c\u8fd9\u4f1a\u4e22\u5931HTML\u4e2d\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3002HtmlRAG\u76f4\u63a5\u4f7f\u7528HTML\u683c\u5f0f\u7684\u77e5\u8bc6\uff0c\u4fdd\u7559\u66f4\u591a\u4fe1\u606f\u3002\u4f46HTML\u5305\u542b\u989d\u5916\u7684\u6807\u7b7e\u548c\u566a\u58f0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6e05\u7406\u548c\u538b\u7f29\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cHtmlRAG\u5728\u516d\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 358, "total_tokens": 522, "completion_tokens": 164}}
[07.11.2024 10:12] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ”¹è¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œç§°ä¸ºHtmlRAGã€‚ä¼ ç»Ÿçš„RAGç³»ç»Ÿä»ç½‘é¡µæ£€ç´¢ä¿¡æ¯ï¼Œæå–çº¯æ–‡æœ¬å–‚ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œè¿™ä¼šä¸¢å¤±HTMLä¸­çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚HtmlRAGç›´æ¥ä½¿ç”¨HTMLæ ¼å¼çš„çŸ¥è¯†ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯ã€‚ä½†HTMLåŒ…å«é¢å¤–çš„æ ‡ç­¾å’Œå™ªå£°ï¼Œä½œè€…æå‡ºäº†æ¸…ç†å’Œå‹ç¼©ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHtmlRAGåœ¨å…­ä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ã€‚
[07.11.2024 10:12] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ”¹è¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œç§°ä¸ºHtmlRAGã€‚ä¼ ç»Ÿçš„RAGç³»ç»Ÿä»ç½‘é¡µæ£€ç´¢ä¿¡æ¯ï¼Œæå–çº¯æ–‡æœ¬å–‚ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œè¿™ä¼šä¸¢å¤±HTMLä¸­çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚HtmlRAGç›´æ¥ä½¿ç”¨HTMLæ ¼å¼çš„çŸ¥è¯†ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯ã€‚ä½†HTMLåŒ…å«é¢å¤–çš„æ ‡ç­¾å’Œå™ªå£°ï¼Œä½œè€…æå‡ºäº†æ¸…ç†å’Œå‹ç¼©ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHtmlRAGåœ¨å…­ä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ã€‚
[07.11.2024 10:13] Mistral response. {"id": "3c8f339939134a09a2461ab275170619", "object": "chat.completion", "created": 1730974371, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u79f0\u4e3aHtmlRAG\u3002\u4f20\u7edf\u7684RAG\u7cfb\u7edf\u4ece\u7f51\u9875\u68c0\u7d22\u4fe1\u606f\uff0c\u63d0\u53d6\u7eaf\u6587\u672c\u5582\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u7136\u800c\uff0c\u8fd9\u4f1a\u4e22\u5931HTML\u4e2d\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3002HtmlRAG\u76f4\u63a5\u4f7f\u7528HTML\u683c\u5f0f\u7684\u77e5\u8bc6\uff0c\u4fdd\u7559\u66f4\u591a\u4fe1\u606f\u3002\u4f46HTML\u5305\u542b\u989d\u5916\u7684\u6807\u7b7e\u548c\u566a\u58f0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6e05\u7406\u548c\u538b\u7f29\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cHtmlRAG\u5728\u516d\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u3002\n\nzh\u00e8 pi\u0101n w\u00e9n zh\u0101ng ji\u00e8 sh\u00e0o le y\u012b zh\u01d2ng g\u01cei j\u00ecn de ji\u01cen su\u01d2 z\u0113ng qi\u00e1ng sh\u0113ng ch\u00e9ng (RAG) f\u0101ng f\u01ce, ch\u0113ng w\u00e9i HtmlRAG. chu\u00e1nt\u01d2ng de RAG x\u00ec t\u01d2ng c\u00f3ng w\u01ceng y\u00e8 ji\u01cen su\u01d2 x\u00ecn x\u012b, t\u012b q\u01d4 ch\u00fan w\u00e9n b\u011bn w\u00e8i g\u011bi d\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00ecng (LLMs). r\u00e1n \u00e9r, zh\u00e8 hu\u00ec di\u016b sh\u012b HTML zh\u014dng de ji\u00e8 g\u00f2u h\u00e9 y\u01d4 y\u00ec x\u00ecn x\u012b. HtmlRAG zh\u00ed ji\u0113 sh\u01d0 y\u00f2ng HTML g\u0113 sh\u00ec de zh\u012b sh\u00ec, b\u01ceo li\u00fa g\u00e8ng du\u014d x\u00ecn x\u012b. d\u00e0n HTML b\u0101o h\u00e1n \u00e9 xi\u01ceo de bi\u01ceo qi\u0101n h\u00e9 z\u00e0o sh\u0113ng, zu\u00f2 zh\u011b t\u00ed ch\u016b le q\u012bng l\u01d0 h\u00e9 y\u0101 su\u014d c\u00e8 l\u00fc\u00e8 l\u00e1i ji\u011b ju\u00e9 zh\u00e8 g\u00e8 w\u00e8n t\u00ed. sh\u00ed y\u00e0n zh\u00e8ng m\u00edng, HtmlRAG z\u00e0i li\u00f9 g\u00e8 w\u00e8n d\u00e1 sh\u00f9 j\u00f9 zh\u014dng bi\u01ceo xi\u00e0n g\u00e8ng h\u01ceo.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 180, "total_tokens": 685, "completion_tokens": 505}}
[07.11.2024 10:13] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ”¹è¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œç§°ä¸ºHtmlRAGã€‚ä¼ ç»Ÿçš„RAGç³»ç»Ÿä»ç½‘é¡µæ£€ç´¢ä¿¡æ¯ï¼Œæå–çº¯æ–‡æœ¬å–‚ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œè¿™ä¼šä¸¢å¤±HTMLä¸­çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚HtmlRAGç›´æ¥ä½¿ç”¨HTMLæ ¼å¼çš„çŸ¥è¯†ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯ã€‚ä½†HTMLåŒ…å«é¢å¤–çš„æ ‡ç­¾å’Œå™ªå£°ï¼Œä½œè€…æå‡ºäº†æ¸…ç†å’Œå‹ç¼©ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHtmlRAGåœ¨å…­ä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ã€‚

zhÃ¨ piÄn wÃ©n zhÄng jiÃ¨ shÃ o le yÄ« zhÇ’ng gÇi jÃ¬n de jiÇn suÇ’ zÄ“ng qiÃ¡ng shÄ“ng chÃ©ng (RAG) fÄng fÇ, chÄ“ng wÃ©i HtmlRAG. chuÃ¡ntÇ’ng de RAG xÃ¬ tÇ’ng cÃ³ng wÇng yÃ¨ jiÇn suÇ’ xÃ¬n xÄ«, tÄ« qÇ” chÃºn wÃ©n bÄ›n wÃ¨i gÄ›i dÃ  yÇ” yÃ¡n mÃ³ xÃ¬ng (LLMs). rÃ¡n Ã©r, zhÃ¨ huÃ¬ diÅ« shÄ« HTML zhÅng de jiÃ¨ gÃ²u hÃ© yÇ” yÃ¬ xÃ¬n xÄ«. HtmlRAG zhÃ­ jiÄ“ shÇ yÃ²ng HTML gÄ“ shÃ¬ de zhÄ« shÃ¬, bÇo liÃº gÃ¨ng duÅ xÃ¬n xÄ«. dÃ n HTML bÄo hÃ¡n Ã© xiÇo de biÇo qiÄn hÃ© zÃ o shÄ“ng, zuÃ² zhÄ› tÃ­ chÅ« le qÄ«ng lÇ hÃ© yÄ suÅ cÃ¨ lÃ¼Ã¨ lÃ¡i jiÄ› juÃ© zhÃ¨ gÃ¨ wÃ¨n tÃ­. shÃ­ yÃ n zhÃ¨ng mÃ­ng, HtmlRAG zÃ i liÃ¹ gÃ¨ wÃ¨n dÃ¡ shÃ¹ jÃ¹ zhÅng biÇo xiÃ n gÃ¨ng hÇo.
[07.11.2024 10:13] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ”¹è¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œç§°ä¸ºHtmlRAGã€‚ä¼ ç»Ÿçš„RAGç³»ç»Ÿä»ç½‘é¡µæ£€ç´¢ä¿¡æ¯ï¼Œæå–çº¯æ–‡æœ¬å–‚ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œè¿™ä¼šä¸¢å¤±HTMLä¸­çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚HtmlRAGç›´æ¥ä½¿ç”¨HTMLæ ¼å¼çš„çŸ¥è¯†ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯ã€‚ä½†HTMLåŒ…å«é¢å¤–çš„æ ‡ç­¾å’Œå™ªå£°ï¼Œä½œè€…æå‡ºäº†æ¸…ç†å’Œå‹ç¼©ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHtmlRAGåœ¨å…­ä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ã€‚
[07.11.2024 10:13] Mistral response. {"id": "43874f8a8c3042db9f52d0c62ae74729", "object": "chat.completion", "created": 1730974388, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\n    {\"word\": \"\u6539\u8fdb\", \"pinyin\": \"g\u01cei j\u00ecn\", \"trans\": \"improvement\"},\n    {\"word\": \"\u68c0\u7d22\", \"pinyin\": \"ji\u01cen su\u01d2\", \"trans\": \"retrieval\"},\n    {\"word\": \"\u589e\u5f3a\", \"pinyin\": \"z\u0113ng qi\u00e1ng\", \"trans\": \"enhancement\"},\n    {\"word\": \"\u751f\u6210\", \"pinyin\": \"sh\u0113ng ch\u00e9ng\", \"trans\": \"generation\"},\n    {\"word\": \"\u65b9\u6cd5\", \"pinyin\": \"f\u0101ng f\u01ce\", \"trans\": \"method\"},\n    {\"word\": \"\u79f0\u4e3a\", \"pinyin\": \"ch\u0113ng w\u00e9i\", \"trans\": \"called\"},\n    {\"word\": \"\u4f20\u7edf\", \"pinyin\": \"chu\u00e1n t\u01d2ng\", \"trans\": \"traditional\"},\n    {\"word\": \"\u7cfb\u7edf\", \"pinyin\": \"x\u00ec t\u01d2ng\", \"trans\": \"system\"},\n    {\"word\": \"\u7f51\u9875\", \"pinyin\": \"w\u01ceng y\u00e8\", \"trans\": \"webpage\"},\n    {\"word\": \"\u63d0\u53d6\", \"pinyin\": \"t\u00ed qu\", \"trans\": \"extract\"},\n    {\"word\": \"\u7eaf\u6587\u672c\", \"pinyin\": \"ch\u00fan w\u00e9n b\u011bn\", \"trans\": \"pure text\"},\n    {\"word\": \"\u5582\u7ed9\", \"pinyin\": \"w\u00e8i g\u011bi\", \"trans\": \"feed\"},\n    {\"word\": \"\u5927\u8bed\u8a00\u6a21\u578b\", \"pinyin\": \"d\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00edng\", \"trans\": \"large language model\"},\n    {\"word\": \"\u4e22\u5931\", \"pinyin\": \"di\u016b sh\u012b\", \"trans\": \"lose\"},\n    {\"word\": \"\u7ed3\u6784\", \"pinyin\": \"ji\u00e9 g\u00f2u\", \"trans\": \"structure\"},\n    {\"word\": \"\u8bed\u4e49\", \"pinyin\": \"y\u01d4 y\u00ec\", \"trans\": \"semantics\"},\n    {\"word\": \"\u4fe1\u606f\", \"pinyin\": \"x\u00ecn x\u012b\", \"trans\": \"information\"},\n    {\"word\": \"\u76f4\u63a5\", \"pinyin\": \"zh\u00ed ji\u0113\", \"trans\": \"directly\"},\n    {\"word\": \"\u683c\u5f0f\", \"pinyin\": \"g\u00e9 sh\u00ec\", \"trans\": \"format\"},\n    {\"word\": \"\u77e5\u8bc6\", \"pinyin\": \"zh\u012b sh\u00ec\", \"trans\": \"knowledge\"},\n    {\"word\": \"\u4fdd\u7559\", \"pinyin\": \"b\u01ceo li\u00fa\", \"trans\": \"retain\"},\n    {\"word\": \"\u989d\u5916\", \"pinyin\": \"\u00e9 w\u00e0i\", \"trans\": \"extra\"},\n    {\"word\": \"\u6807\u7b7e\", \"pinyin\": \"bi\u0101o qi\u0101n\", \"trans\": \"tag\"},\n    {\"word\": \"\u566a\u58f0\", \"pinyin\": \"z\u00e0o sh\u0113ng\", \"trans\": \"noise\"},\n    {\"word\": \"\u63d0\u51fa\", \"pinyin\": \"t\u00ed ch\u016b\", \"trans\": \"propose\"},\n    {\"word\": \"\u6e05\u7406\", \"pinyin\": \"q\u012bng l\u01d0\", \"trans\": \"clean\"},\n    {\"word\": \"\u538b\u7f29\", \"pinyin\": \"y\u0101 su\u014d\", \"trans\": \"compress\"},\n    {\"word\": \"\u7b56\u7565\", \"pinyin\": \"c\u00e8 l\u00fc\u00e8\", \"trans\": \"strategy\"},\n    {\"word\": \"\u89e3\u51b3\", \"pinyin\": \"ji\u011b ju\u00e9\", \"trans\": \"solve\"},\n    {\"word\": \"\u95ee\u9898\", \"pinyin\": \"w\u00e8n t\u00ed\", \"trans\": \"problem\"},\n    {\"word\": \"\u5b9e\u9a8c\", \"pinyin\": \"sh\u00ed y\u00e0n\", \"trans\": \"experiment\"},\n    {\"word\": \"\u8bc1\u660e\", \"pinyin\": \"zh\u00e8ng m\u00edng\", \"trans\": \"prove\"},\n    {\"word\": \"\u8868\u73b0\", \"pinyin\": \"bi\u01ceo xi\u00e0n\", \"trans\": \"performance\"},\n    {\"word\": \"\u6570\u636e\u96c6\", \"pinyin\": \"sh\u00f9 j\u00f9 j\u00ed\", \"trans\": \"dataset\"}\n]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 212, "total_tokens": 1182, "completion_tokens": 970}}
[07.11.2024 10:13] Response: [
    {"word": "æ”¹è¿›", "pinyin": "gÇi jÃ¬n", "trans": "improvement"},
    {"word": "æ£€ç´¢", "pinyin": "jiÇn suÇ’", "trans": "retrieval"},
    {"word": "å¢å¼º", "pinyin": "zÄ“ng qiÃ¡ng", "trans": "enhancement"},
    {"word": "ç”Ÿæˆ", "pinyin": "shÄ“ng chÃ©ng", "trans": "generation"},
    {"word": "æ–¹æ³•", "pinyin": "fÄng fÇ", "trans": "method"},
    {"word": "ç§°ä¸º", "pinyin": "chÄ“ng wÃ©i", "trans": "called"},
    {"word": "ä¼ ç»Ÿ", "pinyin": "chuÃ¡n tÇ’ng", "trans": "traditional"},
    {"word": "ç³»ç»Ÿ", "pinyin": "xÃ¬ tÇ’ng", "trans": "system"},
    {"word": "ç½‘é¡µ", "pinyin": "wÇng yÃ¨", "trans": "webpage"},
    {"word": "æå–", "pinyin": "tÃ­ qu", "trans": "extract"},
    {"word": "çº¯æ–‡æœ¬", "pinyin": "chÃºn wÃ©n bÄ›n", "trans": "pure text"},
    {"word": "å–‚ç»™", "pinyin": "wÃ¨i gÄ›i", "trans": "feed"},
    {"word": "å¤§è¯­è¨€æ¨¡å‹", "pinyin": "dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng", "trans": "large language model"},
    {"word": "ä¸¢å¤±", "pinyin": "diÅ« shÄ«", "trans": "lose"},
    {"word": "ç»“æ„", "pinyin": "jiÃ© gÃ²u", "trans": "structure"},
    {"word": "è¯­ä¹‰", "pinyin": "yÇ” yÃ¬", "trans": "semantics"},
    {"word": "ä¿¡æ¯", "pinyin": "xÃ¬n xÄ«", "trans": "information"},
    {"word": "ç›´æ¥", "pinyin": "zhÃ­ jiÄ“", "trans": "directly"},
    {"word": "æ ¼å¼", "pinyin": "gÃ© shÃ¬", "trans": "format"},
    {"word": "çŸ¥è¯†", "pinyin": "zhÄ« shÃ¬", "trans": "knowledge"},
    {"word": "ä¿ç•™", "pinyin": "bÇo liÃº", "trans": "retain"},
    {"word": "é¢å¤–", "pinyin": "Ã© wÃ i", "trans": "extra"},
    {"word": "æ ‡ç­¾", "pinyin": "biÄo qiÄn", "trans": "tag"},
    {"word": "å™ªå£°", "pinyin": "zÃ o shÄ“ng", "trans": "noise"},
    {"word": "æå‡º", "pinyin": "tÃ­ chÅ«", "trans": "propose"},
    {"word": "æ¸…ç†", "pinyin": "qÄ«ng lÇ", "trans": "clean"},
    {"word": "å‹ç¼©", "pinyin": "yÄ suÅ", "trans": "compress"},
    {"word": "ç­–ç•¥", "pinyin": "cÃ¨ lÃ¼Ã¨", "trans": "strategy"},
    {"word": "è§£å†³", "pinyin": "jiÄ› juÃ©", "trans": "solve"},
    {"word": "é—®é¢˜", "pinyin": "wÃ¨n tÃ­", "trans": "problem"},
    {"word": "å®éªŒ", "pinyin": "shÃ­ yÃ n", "trans": "experiment"},
    {"word": "è¯æ˜", "pinyin": "zhÃ¨ng mÃ­ng", "trans": "prove"},
    {"word": "è¡¨ç°", "pinyin": "biÇo xiÃ n", "trans": "performance"},
    {"word": "æ•°æ®é›†", "pinyin": "shÃ¹ jÃ¹ jÃ­", "trans": "dataset"}
]
[07.11.2024 10:13] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ”¹è¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œç§°ä¸ºHtmlRAGã€‚ä¼ ç»Ÿçš„RAGç³»ç»Ÿä»ç½‘é¡µæ£€ç´¢ä¿¡æ¯ï¼Œæå–çº¯æ–‡æœ¬å–‚ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œè¿™ä¼šä¸¢å¤±HTMLä¸­çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚HtmlRAGç›´æ¥ä½¿ç”¨HTMLæ ¼å¼çš„çŸ¥è¯†ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯ã€‚ä½†HTMLåŒ…å«é¢å¤–çš„æ ‡ç­¾å’Œå™ªå£°ï¼Œä½œè€…æå‡ºäº†æ¸…ç†å’Œå‹ç¼©ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHtmlRAGåœ¨å…­ä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ã€‚
[07.11.2024 10:13] Mistral response. {"id": "4d14c151176d487e826f988f763e4f02", "object": "chat.completion", "created": 1730974416, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "This article introduces an improved Retrieval-Augmented Generation (RAG) method called HtmlRAG. Traditional RAG systems retrieve information from web pages and extract plain text to feed into large language models (LLMs). However, this approach loses the structural and semantic information present in HTML. HtmlRAG directly uses knowledge in HTML format, preserving more information. But since HTML contains additional tags and noise, the authors propose cleaning and compression strategies to address this issue. Experiments show that HtmlRAG performs better on six question-answering datasets.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 178, "total_tokens": 299, "completion_tokens": 121}}
[07.11.2024 10:13] Response: This article introduces an improved Retrieval-Augmented Generation (RAG) method called HtmlRAG. Traditional RAG systems retrieve information from web pages and extract plain text to feed into large language models (LLMs). However, this approach loses the structural and semantic information present in HTML. HtmlRAG directly uses knowledge in HTML format, preserving more information. But since HTML contains additional tags and noise, the authors propose cleaning and compression strategies to address this issue. Experiments show that HtmlRAG performs better on six question-answering datasets.
[07.11.2024 10:13] Renaming data file.
[07.11.2024 10:13] Renaming previous data. hf_papers.json to ./d/2024-11-07.json
[07.11.2024 10:13] Saving new data file.
[07.11.2024 10:13] Generating page.
[07.11.2024 10:13] Renaming previous page.
[07.11.2024 10:13] Renaming previous data. index.html to ./d/2024-11-07.html
[07.11.2024 10:13] [Experimental] Generating Chinese page for reading.
[07.11.2024 10:13] Chinese vocab [{'word': 'æ”¹è¿›', 'pinyin': 'gÇi jÃ¬n', 'trans': 'improvement'}, {'word': 'æ£€ç´¢', 'pinyin': 'jiÇn suÇ’', 'trans': 'retrieval'}, {'word': 'å¢å¼º', 'pinyin': 'zÄ“ng qiÃ¡ng', 'trans': 'enhancement'}, {'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ng chÃ©ng', 'trans': 'generation'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'}, {'word': 'ç§°ä¸º', 'pinyin': 'chÄ“ng wÃ©i', 'trans': 'called'}, {'word': 'ä¼ ç»Ÿ', 'pinyin': 'chuÃ¡n tÇ’ng', 'trans': 'traditional'}, {'word': 'ç³»ç»Ÿ', 'pinyin': 'xÃ¬ tÇ’ng', 'trans': 'system'}, {'word': 'ç½‘é¡µ', 'pinyin': 'wÇng yÃ¨', 'trans': 'webpage'}, {'word': 'æå–', 'pinyin': 'tÃ­ qu', 'trans': 'extract'}, {'word': 'çº¯æ–‡æœ¬', 'pinyin': 'chÃºn wÃ©n bÄ›n', 'trans': 'pure text'}, {'word': 'å–‚ç»™', 'pinyin': 'wÃ¨i gÄ›i', 'trans': 'feed'}, {'word': 'å¤§è¯­è¨€æ¨¡å‹', 'pinyin': 'dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'large language model'}, {'word': 'ä¸¢å¤±', 'pinyin': 'diÅ« shÄ«', 'trans': 'lose'}, {'word': 'ç»“æ„', 'pinyin': 'jiÃ© gÃ²u', 'trans': 'structure'}, {'word': 'è¯­ä¹‰', 'pinyin': 'yÇ” yÃ¬', 'trans': 'semantics'}, {'word': 'ä¿¡æ¯', 'pinyin': 'xÃ¬n xÄ«', 'trans': 'information'}, {'word': 'ç›´æ¥', 'pinyin': 'zhÃ­ jiÄ“', 'trans': 'directly'}, {'word': 'æ ¼å¼', 'pinyin': 'gÃ© shÃ¬', 'trans': 'format'}, {'word': 'çŸ¥è¯†', 'pinyin': 'zhÄ« shÃ¬', 'trans': 'knowledge'}, {'word': 'ä¿ç•™', 'pinyin': 'bÇo liÃº', 'trans': 'retain'}, {'word': 'é¢å¤–', 'pinyin': 'Ã© wÃ i', 'trans': 'extra'}, {'word': 'æ ‡ç­¾', 'pinyin': 'biÄo qiÄn', 'trans': 'tag'}, {'word': 'å™ªå£°', 'pinyin': 'zÃ o shÄ“ng', 'trans': 'noise'}, {'word': 'æå‡º', 'pinyin': 'tÃ­ chÅ«', 'trans': 'propose'}, {'word': 'æ¸…ç†', 'pinyin': 'qÄ«ng lÇ', 'trans': 'clean'}, {'word': 'å‹ç¼©', 'pinyin': 'yÄ suÅ', 'trans': 'compress'}, {'word': 'ç­–ç•¥', 'pinyin': 'cÃ¨ lÃ¼Ã¨', 'trans': 'strategy'}, {'word': 'è§£å†³', 'pinyin': 'jiÄ› juÃ©', 'trans': 'solve'}, {'word': 'é—®é¢˜', 'pinyin': 'wÃ¨n tÃ­', 'trans': 'problem'}, {'word': 'å®éªŒ', 'pinyin': 'shÃ­ yÃ n', 'trans': 'experiment'}, {'word': 'è¯æ˜', 'pinyin': 'zhÃ¨ng mÃ­ng', 'trans': 'prove'}, {'word': 'è¡¨ç°', 'pinyin': 'biÇo xiÃ n', 'trans': 'performance'}, {'word': 'æ•°æ®é›†', 'pinyin': 'shÃ¹ jÃ¹ jÃ­', 'trans': 'dataset'}]
[07.11.2024 10:13] Renaming previous Chinese page.
[07.11.2024 10:13] Renaming previous data. zh.html to ./d/2024-11-06_zh_reading_task.html
[07.11.2024 10:13] Writing result.
[07.11.2024 10:13] Writing Chinese reading task.
[07.11.2024 10:13] Renaming log file.
[07.11.2024 10:13] Renaming previous data. log.txt to ./logs/2024-11-07_last_log.txt
