[07.11.2024 08:15] Read previous papers.
[07.11.2024 08:15] Generating top page (month).
[07.11.2024 08:15] Writing top page (month).
[07.11.2024 10:12] Read previous papers.
[07.11.2024 10:12] Get feed.
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02959
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00871
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2410.23054
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02359
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02393
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.01493
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.01602
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.03047
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.03312
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02657
[07.11.2024 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02844
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 0. Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial systems such as ChatGPT and Perplexity have used Web search engines as their...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 1. Large Language Models (LLMs) have demonstrated remarkable generalization and instruction-following capabilities with instruction tuning. The advancements in LLMs and instruction tuning have led to the development of Large Vision-Language Models (LVLMs). However, the competency of the LLMs and instru...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 2. The increasing capabilities of large generative models and their ever more widespread deployment have raised concerns about their reliability, safety, and potential misuse. To address these issues, recent works have proposed to control model generation by steering model activations in order to effec...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 3. MLLMs have demonstrated remarkable comprehension and reasoning capabilities with complex language and visual data. These advances have spurred the vision of establishing a generalist robotic MLLM proficient in understanding complex human instructions and accomplishing various embodied tasks. However...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 4. Current vision systems typically assign fixed-length representations to images, regardless of the information content. This contrasts with human intelligence - and even large language models - which allocate varying representational capacities based on entropy, context and familiarity. Inspired by t...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 5. We study methods for efficiently aligning large language models (LLMs) with human preferences given budgeted online feedback. We first formulate the LLM alignment problem in the frame of contextual dueling bandits. This formulation, subsuming recent paradigms such as online RLHF and online DPO, inhe...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 6. We introduce DreamPolish, a text-to-3D generation model that excels in producing refined geometry and high-quality textures. In the geometry construction phase, our approach leverages multiple neural representations to enhance the stability of the synthesis process. Instead of relying solely on a vi...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 7. Neural implicit functions have brought impressive advances to the state-of-the-art of clothed human digitization from multiple or even single images. However, despite the progress, current arts still have difficulty generalizing to unseen images with complex cloth deformation and body poses. In this...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 8. Vision Language Models (VLMs) have demonstrated strong capabilities across various visual understanding and reasoning tasks. However, their real-world deployment is often constrained by high latency during inference due to substantial compute required to process the large number of input tokens (pre...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 9. Rare diseases present unique challenges in healthcare, often suffering from delayed diagnosis and fragmented information landscapes. The scarcity of reliable knowledge in these conditions poses a distinct challenge for Large Language Models (LLMs) in supporting clinical management and delivering pre...
[07.11.2024 10:12] ********************************************************************************
[07.11.2024 10:12] Abstract 10. As object detection techniques continue to evolve, understanding their relationships with complementary visual tasks becomes crucial for optimising model architectures and computational resources. This paper investigates the correlations between object detection accuracy and two fundamental visual t...
[07.11.2024 10:12] Read previous papers.
[07.11.2024 10:12] Generating reviews via LLM API.
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#rag", "#data", "#training"], "emoji": "üåê", "ru": {"title": "HtmlRAG: –£–ª—É—á—à–µ–Ω–∏–µ RAG-—Å–∏—Å—Ç–µ–º —Å –ø–æ–º–æ—â—å—é —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ–±-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (RAG), –Ω–∞–∑–≤–∞–Ω–Ω—ã–π HtmlRAG. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º RAG, –∏—Å–ø–æ
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#multimodal", "#dataset", "#agents", "#architecture", "#training"], "emoji": "üß¨", "ru": {"title": "LLaMo: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ LLaMo - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∞–º–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#cv", "#rlhf"], "emoji": "üéõÔ∏è", "ru": {"title": "AcT: —Ç–æ—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç AcT (Activation Transport) - –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#agents", "#inference", "#robots", "#optimization", "#benchmark"], "emoji": "ü§ñ", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤: –º–µ–Ω—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤, —Ç–∞ –∂–µ –º–æ—â–Ω–æ—Å—Ç—å", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Dynamic Early-Exit Framework –¥–ª—è —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –∑—Ä–µ–Ω–∏—è, —è–∑—ã–∫–∞ –∏ –¥–µ–π—Å—Ç–≤
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#cv", "#architecture", "#training"], "emoji": "üñºÔ∏è", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —Ç–æ–∫–µ–Ω–æ–≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä, –∫–æ—Ç–æ—Ä–∞
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#rlhf", "#alignment", "#agents"], "emoji": "üéØ", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –¥—É—ç–ª—å–Ω—ã—Ö –±–∞–Ω–¥–∏—Ç–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏–∑—É—á–∞—é—Ç –º–µ—Ç–æ–¥—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏ –ø—Ä–∏ –æ–≥—Ä–∞
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#3d", "#cv"], "emoji": "üé®", "ru": {"title": "DreamPolish: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ —Å –∏–¥–µ–∞–ª—å–Ω–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–µ–π –∏ —Ç–µ–∫—Å—Ç—É—Ä–∞–º–∏", "desc": "DreamPolish - —ç—Ç–æ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ —É—Ç–æ–Ω—á–µ–Ω–Ω–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –∏ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#dataset", "#3d", "#cv"], "emoji": "üëö", "ru": {"title": "GarVerseLOD: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ–¥–µ–∂–¥—ã –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é", "desc": "GarVerseLOD - —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ 3D-–æ–¥–µ–∂–¥—ã –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç 6000 –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π 
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#inference", "#cv", "#training"], "emoji": "üî¨", "ru": {"title": "–ú–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤, –±–æ–ª—å—à–µ –º–æ–¥–µ–ª—å: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ VLM", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (LLM) –≤ vision-language –º–æ–¥–µ–ª—è—Ö (VLM).
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#rag", "#medicine", "#training", "#alignment"], "emoji": "ü¶ì", "ru": {"title": "Zebra-Llama: –ò–ò-—ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–µ–¥–∫–∏–º –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Zebra-Llama - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—è —Å–∏–Ω–¥—Ä–æ–º –≠–ª–µ—Ä—Å–∞-–î–∞–Ω–ª–æ—Å–∞ (EDS) –∫–∞–∫ –ø—Ä–∏–º–µ—Ä. –ú–æ
[07.11.2024 10:12] Using data from previous issue: {"categories": ["#cv", "#architecture", "#dataset"], "emoji": "üëÅÔ∏è", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –≥–ª—É–±–∏–Ω—É –≤ —É–ª—É—á—à–µ–Ω–∏–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–∑—É—á–∞–µ—Ç —Å–≤—è–∑—å –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –∏ –∑–∞–¥–∞—á–∞–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≥–ª—É–±–∏–Ω—ã –∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏. –≠–∫—Å–ø–µ—Ä–∏–º
[07.11.2024 10:12] Trying to get texts in Chinese.
[07.11.2024 10:12] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial systems such as ChatGPT and Perplexity have used Web search engines as their major retrieval systems. Typically, such RAG systems retrieve search results, download HTML sources of the results, and then extract plain texts from the HTML sources. Plain text documents or chunks are fed into the LLMs to augment the generation. However, much of the structural and semantic information inherent in HTML, such as headings and table structures, is lost during this plain-text-based RAG process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG. We believe HTML is better than plain text in modeling knowledge in external documents, and most LLMs possess robust capacities to understand HTML. However, utilizing HTML presents new challenges. HTML contains additional content such as tags, JavaScript, and CSS specifications, which bring extra input tokens and noise to the RAG system. To address this issue, we propose HTML cleaning, compression, and pruning strategies, to shorten the HTML while minimizing the loss of information. Specifically, we design a two-step block-tree-based pruning method that prunes useless HTML blocks and keeps only the relevant part of the HTML. Experiments on six QA datasets confirm the superiority of using HTML in RAG systems.
[07.11.2024 10:12] Mistral response. {"id": "4a1aacf1ed26437f8624e79af4cb98d7", "object": "chat.completion", "created": 1730974365, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u79f0\u4e3aHtmlRAG\u3002\u4f20\u7edf\u7684RAG\u7cfb\u7edf\u4ece\u7f51\u9875\u68c0\u7d22\u4fe1\u606f\uff0c\u63d0\u53d6\u7eaf\u6587\u672c\u5582\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u7136\u800c\uff0c\u8fd9\u4f1a\u4e22\u5931HTML\u4e2d\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3002HtmlRAG\u76f4\u63a5\u4f7f\u7528HTML\u683c\u5f0f\u7684\u77e5\u8bc6\uff0c\u4fdd\u7559\u66f4\u591a\u4fe1\u606f\u3002\u4f46HTML\u5305\u542b\u989d\u5916\u7684\u6807\u7b7e\u548c\u566a\u58f0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6e05\u7406\u548c\u538b\u7f29\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cHtmlRAG\u5728\u516d\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 358, "total_tokens": 522, "completion_tokens": 164}}
[07.11.2024 10:12] Response: ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÊîπËøõÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊñπÊ≥ïÔºåÁß∞‰∏∫HtmlRAG„ÄÇ‰º†ÁªüÁöÑRAGÁ≥ªÁªü‰ªéÁΩëÈ°µÊ£ÄÁ¥¢‰ø°ÊÅØÔºåÊèêÂèñÁ∫ØÊñáÊú¨ÂñÇÁªôÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ„ÄÇÁÑ∂ËÄåÔºåËøô‰ºö‰∏¢Â§±HTML‰∏≠ÁöÑÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØ„ÄÇHtmlRAGÁõ¥Êé•‰ΩøÁî®HTMLÊ†ºÂºèÁöÑÁü•ËØÜÔºå‰øùÁïôÊõ¥Â§ö‰ø°ÊÅØ„ÄÇ‰ΩÜHTMLÂåÖÂê´È¢ùÂ§ñÁöÑÊ†áÁ≠æÂíåÂô™Â£∞Ôºå‰ΩúËÄÖÊèêÂá∫‰∫ÜÊ∏ÖÁêÜÂíåÂéãÁº©Á≠ñÁï•Êù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÂÆûÈ™åËØÅÊòéÔºåHtmlRAGÂú®ÂÖ≠‰∏™ÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Êõ¥Â•Ω„ÄÇ
[07.11.2024 10:12] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÊîπËøõÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊñπÊ≥ïÔºåÁß∞‰∏∫HtmlRAG„ÄÇ‰º†ÁªüÁöÑRAGÁ≥ªÁªü‰ªéÁΩëÈ°µÊ£ÄÁ¥¢‰ø°ÊÅØÔºåÊèêÂèñÁ∫ØÊñáÊú¨ÂñÇÁªôÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ„ÄÇÁÑ∂ËÄåÔºåËøô‰ºö‰∏¢Â§±HTML‰∏≠ÁöÑÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØ„ÄÇHtmlRAGÁõ¥Êé•‰ΩøÁî®HTMLÊ†ºÂºèÁöÑÁü•ËØÜÔºå‰øùÁïôÊõ¥Â§ö‰ø°ÊÅØ„ÄÇ‰ΩÜHTMLÂåÖÂê´È¢ùÂ§ñÁöÑÊ†áÁ≠æÂíåÂô™Â£∞Ôºå‰ΩúËÄÖÊèêÂá∫‰∫ÜÊ∏ÖÁêÜÂíåÂéãÁº©Á≠ñÁï•Êù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÂÆûÈ™åËØÅÊòéÔºåHtmlRAGÂú®ÂÖ≠‰∏™ÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Êõ¥Â•Ω„ÄÇ
[07.11.2024 10:13] Mistral response. {"id": "3c8f339939134a09a2461ab275170619", "object": "chat.completion", "created": 1730974371, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u79f0\u4e3aHtmlRAG\u3002\u4f20\u7edf\u7684RAG\u7cfb\u7edf\u4ece\u7f51\u9875\u68c0\u7d22\u4fe1\u606f\uff0c\u63d0\u53d6\u7eaf\u6587\u672c\u5582\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u7136\u800c\uff0c\u8fd9\u4f1a\u4e22\u5931HTML\u4e2d\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3002HtmlRAG\u76f4\u63a5\u4f7f\u7528HTML\u683c\u5f0f\u7684\u77e5\u8bc6\uff0c\u4fdd\u7559\u66f4\u591a\u4fe1\u606f\u3002\u4f46HTML\u5305\u542b\u989d\u5916\u7684\u6807\u7b7e\u548c\u566a\u58f0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6e05\u7406\u548c\u538b\u7f29\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cHtmlRAG\u5728\u516d\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u3002\n\nzh\u00e8 pi\u0101n w\u00e9n zh\u0101ng ji\u00e8 sh\u00e0o le y\u012b zh\u01d2ng g\u01cei j\u00ecn de ji\u01cen su\u01d2 z\u0113ng qi\u00e1ng sh\u0113ng ch\u00e9ng (RAG) f\u0101ng f\u01ce, ch\u0113ng w\u00e9i HtmlRAG. chu\u00e1nt\u01d2ng de RAG x\u00ec t\u01d2ng c\u00f3ng w\u01ceng y\u00e8 ji\u01cen su\u01d2 x\u00ecn x\u012b, t\u012b q\u01d4 ch\u00fan w\u00e9n b\u011bn w\u00e8i g\u011bi d\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00ecng (LLMs). r\u00e1n \u00e9r, zh\u00e8 hu\u00ec di\u016b sh\u012b HTML zh\u014dng de ji\u00e8 g\u00f2u h\u00e9 y\u01d4 y\u00ec x\u00ecn x\u012b. HtmlRAG zh\u00ed ji\u0113 sh\u01d0 y\u00f2ng HTML g\u0113 sh\u00ec de zh\u012b sh\u00ec, b\u01ceo li\u00fa g\u00e8ng du\u014d x\u00ecn x\u012b. d\u00e0n HTML b\u0101o h\u00e1n \u00e9 xi\u01ceo de bi\u01ceo qi\u0101n h\u00e9 z\u00e0o sh\u0113ng, zu\u00f2 zh\u011b t\u00ed ch\u016b le q\u012bng l\u01d0 h\u00e9 y\u0101 su\u014d c\u00e8 l\u00fc\u00e8 l\u00e1i ji\u011b ju\u00e9 zh\u00e8 g\u00e8 w\u00e8n t\u00ed. sh\u00ed y\u00e0n zh\u00e8ng m\u00edng, HtmlRAG z\u00e0i li\u00f9 g\u00e8 w\u00e8n d\u00e1 sh\u00f9 j\u00f9 zh\u014dng bi\u01ceo xi\u00e0n g\u00e8ng h\u01ceo.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 180, "total_tokens": 685, "completion_tokens": 505}}
[07.11.2024 10:13] Response: ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÊîπËøõÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊñπÊ≥ïÔºåÁß∞‰∏∫HtmlRAG„ÄÇ‰º†ÁªüÁöÑRAGÁ≥ªÁªü‰ªéÁΩëÈ°µÊ£ÄÁ¥¢‰ø°ÊÅØÔºåÊèêÂèñÁ∫ØÊñáÊú¨ÂñÇÁªôÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ„ÄÇÁÑ∂ËÄåÔºåËøô‰ºö‰∏¢Â§±HTML‰∏≠ÁöÑÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØ„ÄÇHtmlRAGÁõ¥Êé•‰ΩøÁî®HTMLÊ†ºÂºèÁöÑÁü•ËØÜÔºå‰øùÁïôÊõ¥Â§ö‰ø°ÊÅØ„ÄÇ‰ΩÜHTMLÂåÖÂê´È¢ùÂ§ñÁöÑÊ†áÁ≠æÂíåÂô™Â£∞Ôºå‰ΩúËÄÖÊèêÂá∫‰∫ÜÊ∏ÖÁêÜÂíåÂéãÁº©Á≠ñÁï•Êù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÂÆûÈ™åËØÅÊòéÔºåHtmlRAGÂú®ÂÖ≠‰∏™ÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Êõ¥Â•Ω„ÄÇ

zh√® piƒÅn w√©n zhƒÅng ji√® sh√†o le yƒ´ zh«íng g«éi j√¨n de ji«én su«í zƒìng qi√°ng shƒìng ch√©ng (RAG) fƒÅng f«é, chƒìng w√©i HtmlRAG. chu√°nt«íng de RAG x√¨ t«íng c√≥ng w«éng y√® ji«én su«í x√¨n xƒ´, tƒ´ q«î ch√∫n w√©n bƒõn w√®i gƒõi d√† y«î y√°n m√≥ x√¨ng (LLMs). r√°n √©r, zh√® hu√¨ di≈´ shƒ´ HTML zh≈çng de ji√® g√≤u h√© y«î y√¨ x√¨n xƒ´. HtmlRAG zh√≠ jiƒì sh«ê y√≤ng HTML gƒì sh√¨ de zhƒ´ sh√¨, b«éo li√∫ g√®ng du≈ç x√¨n xƒ´. d√†n HTML bƒÅo h√°n √© xi«éo de bi«éo qiƒÅn h√© z√†o shƒìng, zu√≤ zhƒõ t√≠ ch≈´ le qƒ´ng l«ê h√© yƒÅ su≈ç c√® l√º√® l√°i jiƒõ ju√© zh√® g√® w√®n t√≠. sh√≠ y√†n zh√®ng m√≠ng, HtmlRAG z√†i li√π g√® w√®n d√° sh√π j√π zh≈çng bi«éo xi√†n g√®ng h«éo.
[07.11.2024 10:13] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÊîπËøõÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊñπÊ≥ïÔºåÁß∞‰∏∫HtmlRAG„ÄÇ‰º†ÁªüÁöÑRAGÁ≥ªÁªü‰ªéÁΩëÈ°µÊ£ÄÁ¥¢‰ø°ÊÅØÔºåÊèêÂèñÁ∫ØÊñáÊú¨ÂñÇÁªôÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ„ÄÇÁÑ∂ËÄåÔºåËøô‰ºö‰∏¢Â§±HTML‰∏≠ÁöÑÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØ„ÄÇHtmlRAGÁõ¥Êé•‰ΩøÁî®HTMLÊ†ºÂºèÁöÑÁü•ËØÜÔºå‰øùÁïôÊõ¥Â§ö‰ø°ÊÅØ„ÄÇ‰ΩÜHTMLÂåÖÂê´È¢ùÂ§ñÁöÑÊ†áÁ≠æÂíåÂô™Â£∞Ôºå‰ΩúËÄÖÊèêÂá∫‰∫ÜÊ∏ÖÁêÜÂíåÂéãÁº©Á≠ñÁï•Êù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÂÆûÈ™åËØÅÊòéÔºåHtmlRAGÂú®ÂÖ≠‰∏™ÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Êõ¥Â•Ω„ÄÇ
[07.11.2024 10:13] Mistral response. {"id": "43874f8a8c3042db9f52d0c62ae74729", "object": "chat.completion", "created": 1730974388, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\n    {\"word\": \"\u6539\u8fdb\", \"pinyin\": \"g\u01cei j\u00ecn\", \"trans\": \"improvement\"},\n    {\"word\": \"\u68c0\u7d22\", \"pinyin\": \"ji\u01cen su\u01d2\", \"trans\": \"retrieval\"},\n    {\"word\": \"\u589e\u5f3a\", \"pinyin\": \"z\u0113ng qi\u00e1ng\", \"trans\": \"enhancement\"},\n    {\"word\": \"\u751f\u6210\", \"pinyin\": \"sh\u0113ng ch\u00e9ng\", \"trans\": \"generation\"},\n    {\"word\": \"\u65b9\u6cd5\", \"pinyin\": \"f\u0101ng f\u01ce\", \"trans\": \"method\"},\n    {\"word\": \"\u79f0\u4e3a\", \"pinyin\": \"ch\u0113ng w\u00e9i\", \"trans\": \"called\"},\n    {\"word\": \"\u4f20\u7edf\", \"pinyin\": \"chu\u00e1n t\u01d2ng\", \"trans\": \"traditional\"},\n    {\"word\": \"\u7cfb\u7edf\", \"pinyin\": \"x\u00ec t\u01d2ng\", \"trans\": \"system\"},\n    {\"word\": \"\u7f51\u9875\", \"pinyin\": \"w\u01ceng y\u00e8\", \"trans\": \"webpage\"},\n    {\"word\": \"\u63d0\u53d6\", \"pinyin\": \"t\u00ed qu\", \"trans\": \"extract\"},\n    {\"word\": \"\u7eaf\u6587\u672c\", \"pinyin\": \"ch\u00fan w\u00e9n b\u011bn\", \"trans\": \"pure text\"},\n    {\"word\": \"\u5582\u7ed9\", \"pinyin\": \"w\u00e8i g\u011bi\", \"trans\": \"feed\"},\n    {\"word\": \"\u5927\u8bed\u8a00\u6a21\u578b\", \"pinyin\": \"d\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00edng\", \"trans\": \"large language model\"},\n    {\"word\": \"\u4e22\u5931\", \"pinyin\": \"di\u016b sh\u012b\", \"trans\": \"lose\"},\n    {\"word\": \"\u7ed3\u6784\", \"pinyin\": \"ji\u00e9 g\u00f2u\", \"trans\": \"structure\"},\n    {\"word\": \"\u8bed\u4e49\", \"pinyin\": \"y\u01d4 y\u00ec\", \"trans\": \"semantics\"},\n    {\"word\": \"\u4fe1\u606f\", \"pinyin\": \"x\u00ecn x\u012b\", \"trans\": \"information\"},\n    {\"word\": \"\u76f4\u63a5\", \"pinyin\": \"zh\u00ed ji\u0113\", \"trans\": \"directly\"},\n    {\"word\": \"\u683c\u5f0f\", \"pinyin\": \"g\u00e9 sh\u00ec\", \"trans\": \"format\"},\n    {\"word\": \"\u77e5\u8bc6\", \"pinyin\": \"zh\u012b sh\u00ec\", \"trans\": \"knowledge\"},\n    {\"word\": \"\u4fdd\u7559\", \"pinyin\": \"b\u01ceo li\u00fa\", \"trans\": \"retain\"},\n    {\"word\": \"\u989d\u5916\", \"pinyin\": \"\u00e9 w\u00e0i\", \"trans\": \"extra\"},\n    {\"word\": \"\u6807\u7b7e\", \"pinyin\": \"bi\u0101o qi\u0101n\", \"trans\": \"tag\"},\n    {\"word\": \"\u566a\u58f0\", \"pinyin\": \"z\u00e0o sh\u0113ng\", \"trans\": \"noise\"},\n    {\"word\": \"\u63d0\u51fa\", \"pinyin\": \"t\u00ed ch\u016b\", \"trans\": \"propose\"},\n    {\"word\": \"\u6e05\u7406\", \"pinyin\": \"q\u012bng l\u01d0\", \"trans\": \"clean\"},\n    {\"word\": \"\u538b\u7f29\", \"pinyin\": \"y\u0101 su\u014d\", \"trans\": \"compress\"},\n    {\"word\": \"\u7b56\u7565\", \"pinyin\": \"c\u00e8 l\u00fc\u00e8\", \"trans\": \"strategy\"},\n    {\"word\": \"\u89e3\u51b3\", \"pinyin\": \"ji\u011b ju\u00e9\", \"trans\": \"solve\"},\n    {\"word\": \"\u95ee\u9898\", \"pinyin\": \"w\u00e8n t\u00ed\", \"trans\": \"problem\"},\n    {\"word\": \"\u5b9e\u9a8c\", \"pinyin\": \"sh\u00ed y\u00e0n\", \"trans\": \"experiment\"},\n    {\"word\": \"\u8bc1\u660e\", \"pinyin\": \"zh\u00e8ng m\u00edng\", \"trans\": \"prove\"},\n    {\"word\": \"\u8868\u73b0\", \"pinyin\": \"bi\u01ceo xi\u00e0n\", \"trans\": \"performance\"},\n    {\"word\": \"\u6570\u636e\u96c6\", \"pinyin\": \"sh\u00f9 j\u00f9 j\u00ed\", \"trans\": \"dataset\"}\n]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 212, "total_tokens": 1182, "completion_tokens": 970}}
[07.11.2024 10:13] Response: [
    {"word": "ÊîπËøõ", "pinyin": "g«éi j√¨n", "trans": "improvement"},
    {"word": "Ê£ÄÁ¥¢", "pinyin": "ji«én su«í", "trans": "retrieval"},
    {"word": "Â¢ûÂº∫", "pinyin": "zƒìng qi√°ng", "trans": "enhancement"},
    {"word": "ÁîüÊàê", "pinyin": "shƒìng ch√©ng", "trans": "generation"},
    {"word": "ÊñπÊ≥ï", "pinyin": "fƒÅng f«é", "trans": "method"},
    {"word": "Áß∞‰∏∫", "pinyin": "chƒìng w√©i", "trans": "called"},
    {"word": "‰º†Áªü", "pinyin": "chu√°n t«íng", "trans": "traditional"},
    {"word": "Á≥ªÁªü", "pinyin": "x√¨ t«íng", "trans": "system"},
    {"word": "ÁΩëÈ°µ", "pinyin": "w«éng y√®", "trans": "webpage"},
    {"word": "ÊèêÂèñ", "pinyin": "t√≠ qu", "trans": "extract"},
    {"word": "Á∫ØÊñáÊú¨", "pinyin": "ch√∫n w√©n bƒõn", "trans": "pure text"},
    {"word": "ÂñÇÁªô", "pinyin": "w√®i gƒõi", "trans": "feed"},
    {"word": "Â§ßËØ≠Ë®ÄÊ®°Âûã", "pinyin": "d√† y«î y√°n m√≥ x√≠ng", "trans": "large language model"},
    {"word": "‰∏¢Â§±", "pinyin": "di≈´ shƒ´", "trans": "lose"},
    {"word": "ÁªìÊûÑ", "pinyin": "ji√© g√≤u", "trans": "structure"},
    {"word": "ËØ≠‰πâ", "pinyin": "y«î y√¨", "trans": "semantics"},
    {"word": "‰ø°ÊÅØ", "pinyin": "x√¨n xƒ´", "trans": "information"},
    {"word": "Áõ¥Êé•", "pinyin": "zh√≠ jiƒì", "trans": "directly"},
    {"word": "Ê†ºÂºè", "pinyin": "g√© sh√¨", "trans": "format"},
    {"word": "Áü•ËØÜ", "pinyin": "zhƒ´ sh√¨", "trans": "knowledge"},
    {"word": "‰øùÁïô", "pinyin": "b«éo li√∫", "trans": "retain"},
    {"word": "È¢ùÂ§ñ", "pinyin": "√© w√†i", "trans": "extra"},
    {"word": "Ê†áÁ≠æ", "pinyin": "biƒÅo qiƒÅn", "trans": "tag"},
    {"word": "Âô™Â£∞", "pinyin": "z√†o shƒìng", "trans": "noise"},
    {"word": "ÊèêÂá∫", "pinyin": "t√≠ ch≈´", "trans": "propose"},
    {"word": "Ê∏ÖÁêÜ", "pinyin": "qƒ´ng l«ê", "trans": "clean"},
    {"word": "ÂéãÁº©", "pinyin": "yƒÅ su≈ç", "trans": "compress"},
    {"word": "Á≠ñÁï•", "pinyin": "c√® l√º√®", "trans": "strategy"},
    {"word": "Ëß£ÂÜ≥", "pinyin": "jiƒõ ju√©", "trans": "solve"},
    {"word": "ÈóÆÈ¢ò", "pinyin": "w√®n t√≠", "trans": "problem"},
    {"word": "ÂÆûÈ™å", "pinyin": "sh√≠ y√†n", "trans": "experiment"},
    {"word": "ËØÅÊòé", "pinyin": "zh√®ng m√≠ng", "trans": "prove"},
    {"word": "Ë°®Áé∞", "pinyin": "bi«éo xi√†n", "trans": "performance"},
    {"word": "Êï∞ÊçÆÈõÜ", "pinyin": "sh√π j√π j√≠", "trans": "dataset"}
]
[07.11.2024 10:13] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÊîπËøõÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊñπÊ≥ïÔºåÁß∞‰∏∫HtmlRAG„ÄÇ‰º†ÁªüÁöÑRAGÁ≥ªÁªü‰ªéÁΩëÈ°µÊ£ÄÁ¥¢‰ø°ÊÅØÔºåÊèêÂèñÁ∫ØÊñáÊú¨ÂñÇÁªôÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ„ÄÇÁÑ∂ËÄåÔºåËøô‰ºö‰∏¢Â§±HTML‰∏≠ÁöÑÁªìÊûÑÂíåËØ≠‰πâ‰ø°ÊÅØ„ÄÇHtmlRAGÁõ¥Êé•‰ΩøÁî®HTMLÊ†ºÂºèÁöÑÁü•ËØÜÔºå‰øùÁïôÊõ¥Â§ö‰ø°ÊÅØ„ÄÇ‰ΩÜHTMLÂåÖÂê´È¢ùÂ§ñÁöÑÊ†áÁ≠æÂíåÂô™Â£∞Ôºå‰ΩúËÄÖÊèêÂá∫‰∫ÜÊ∏ÖÁêÜÂíåÂéãÁº©Á≠ñÁï•Êù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÂÆûÈ™åËØÅÊòéÔºåHtmlRAGÂú®ÂÖ≠‰∏™ÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Êõ¥Â•Ω„ÄÇ
[07.11.2024 10:13] Mistral response. {"id": "4d14c151176d487e826f988f763e4f02", "object": "chat.completion", "created": 1730974416, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "This article introduces an improved Retrieval-Augmented Generation (RAG) method called HtmlRAG. Traditional RAG systems retrieve information from web pages and extract plain text to feed into large language models (LLMs). However, this approach loses the structural and semantic information present in HTML. HtmlRAG directly uses knowledge in HTML format, preserving more information. But since HTML contains additional tags and noise, the authors propose cleaning and compression strategies to address this issue. Experiments show that HtmlRAG performs better on six question-answering datasets.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 178, "total_tokens": 299, "completion_tokens": 121}}
[07.11.2024 10:13] Response: This article introduces an improved Retrieval-Augmented Generation (RAG) method called HtmlRAG. Traditional RAG systems retrieve information from web pages and extract plain text to feed into large language models (LLMs). However, this approach loses the structural and semantic information present in HTML. HtmlRAG directly uses knowledge in HTML format, preserving more information. But since HTML contains additional tags and noise, the authors propose cleaning and compression strategies to address this issue. Experiments show that HtmlRAG performs better on six question-answering datasets.
[07.11.2024 10:13] Renaming data file.
[07.11.2024 10:13] Renaming previous data. hf_papers.json to ./d/2024-11-07.json
[07.11.2024 10:13] Saving new data file.
[07.11.2024 10:13] Generating page.
[07.11.2024 10:13] Renaming previous page.
[07.11.2024 10:13] Renaming previous data. index.html to ./d/2024-11-07.html
[07.11.2024 10:13] [Experimental] Generating Chinese page for reading.
[07.11.2024 10:13] Chinese vocab [{'word': 'ÊîπËøõ', 'pinyin': 'g«éi j√¨n', 'trans': 'improvement'}, {'word': 'Ê£ÄÁ¥¢', 'pinyin': 'ji«én su«í', 'trans': 'retrieval'}, {'word': 'Â¢ûÂº∫', 'pinyin': 'zƒìng qi√°ng', 'trans': 'enhancement'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìng ch√©ng', 'trans': 'generation'}, {'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}, {'word': 'Áß∞‰∏∫', 'pinyin': 'chƒìng w√©i', 'trans': 'called'}, {'word': '‰º†Áªü', 'pinyin': 'chu√°n t«íng', 'trans': 'traditional'}, {'word': 'Á≥ªÁªü', 'pinyin': 'x√¨ t«íng', 'trans': 'system'}, {'word': 'ÁΩëÈ°µ', 'pinyin': 'w«éng y√®', 'trans': 'webpage'}, {'word': 'ÊèêÂèñ', 'pinyin': 't√≠ qu', 'trans': 'extract'}, {'word': 'Á∫ØÊñáÊú¨', 'pinyin': 'ch√∫n w√©n bƒõn', 'trans': 'pure text'}, {'word': 'ÂñÇÁªô', 'pinyin': 'w√®i gƒõi', 'trans': 'feed'}, {'word': 'Â§ßËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'd√† y«î y√°n m√≥ x√≠ng', 'trans': 'large language model'}, {'word': '‰∏¢Â§±', 'pinyin': 'di≈´ shƒ´', 'trans': 'lose'}, {'word': 'ÁªìÊûÑ', 'pinyin': 'ji√© g√≤u', 'trans': 'structure'}, {'word': 'ËØ≠‰πâ', 'pinyin': 'y«î y√¨', 'trans': 'semantics'}, {'word': '‰ø°ÊÅØ', 'pinyin': 'x√¨n xƒ´', 'trans': 'information'}, {'word': 'Áõ¥Êé•', 'pinyin': 'zh√≠ jiƒì', 'trans': 'directly'}, {'word': 'Ê†ºÂºè', 'pinyin': 'g√© sh√¨', 'trans': 'format'}, {'word': 'Áü•ËØÜ', 'pinyin': 'zhƒ´ sh√¨', 'trans': 'knowledge'}, {'word': '‰øùÁïô', 'pinyin': 'b«éo li√∫', 'trans': 'retain'}, {'word': 'È¢ùÂ§ñ', 'pinyin': '√© w√†i', 'trans': 'extra'}, {'word': 'Ê†áÁ≠æ', 'pinyin': 'biƒÅo qiƒÅn', 'trans': 'tag'}, {'word': 'Âô™Â£∞', 'pinyin': 'z√†o shƒìng', 'trans': 'noise'}, {'word': 'ÊèêÂá∫', 'pinyin': 't√≠ ch≈´', 'trans': 'propose'}, {'word': 'Ê∏ÖÁêÜ', 'pinyin': 'qƒ´ng l«ê', 'trans': 'clean'}, {'word': 'ÂéãÁº©', 'pinyin': 'yƒÅ su≈ç', 'trans': 'compress'}, {'word': 'Á≠ñÁï•', 'pinyin': 'c√® l√º√®', 'trans': 'strategy'}, {'word': 'Ëß£ÂÜ≥', 'pinyin': 'jiƒõ ju√©', 'trans': 'solve'}, {'word': 'ÈóÆÈ¢ò', 'pinyin': 'w√®n t√≠', 'trans': 'problem'}, {'word': 'ÂÆûÈ™å', 'pinyin': 'sh√≠ y√†n', 'trans': 'experiment'}, {'word': 'ËØÅÊòé', 'pinyin': 'zh√®ng m√≠ng', 'trans': 'prove'}, {'word': 'Ë°®Áé∞', 'pinyin': 'bi«éo xi√†n', 'trans': 'performance'}, {'word': 'Êï∞ÊçÆÈõÜ', 'pinyin': 'sh√π j√π j√≠', 'trans': 'dataset'}]
[07.11.2024 10:13] Renaming previous Chinese page.
[07.11.2024 10:13] Renaming previous data. zh.html to ./d/2024-11-06_zh_reading_task.html
[07.11.2024 10:13] Writing result.
[07.11.2024 10:13] Writing Chinese reading task.
[07.11.2024 10:13] Renaming log file.
[07.11.2024 10:13] Renaming previous data. log.txt to ./logs/2024-11-07_last_log.txt
