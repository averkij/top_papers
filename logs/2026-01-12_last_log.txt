[12.01.2026 14:28] Read previous papers.
[12.01.2026 14:28] Generating top page (month).
[12.01.2026 14:28] Writing top page (month).
[12.01.2026 15:28] Read previous papers.
[12.01.2026 15:28] Get feed.
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05432
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03017
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06002
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03319
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06021
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05808
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04720
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05930
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04786
[12.01.2026 15:28] Extract page data from URL. URL: https://huggingface.co/papers/2601.05882
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05966
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05905
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05848
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05573
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05403
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04888
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02760
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05637
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04823
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04726
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04544
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05960
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05741
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05503
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05870
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05851
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05699
[12.01.2026 15:28] Extract page data from URL. URL: https://huggingface.co/papers/2601.05376
[12.01.2026 15:28] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04175
[12.01.2026 15:28] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[12.01.2026 15:28] No deleted papers detected.
[12.01.2026 15:28] Downloading and parsing papers (pdf, html). Total: 29.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05432.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05432.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05432.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.03017.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.03017.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.03017.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.06002.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.06002.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.06002.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.03319.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.03319.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.03319.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.06021.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.06021.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.06021.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05808.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05808.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05808.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.04720.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.04720.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.04720.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05930.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05930.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05930.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.04786.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.04786.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.04786.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05882.
[12.01.2026 15:28] Downloading paper 2601.05882 from https://arxiv.org/pdf/2601.05882v1...
[12.01.2026 15:28] Extracting affiliations from text.
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 9 ] . [ 1 2 8 8 5 0 . 1 0 6 2 : r a School of Computer Science University of Sheffield, UK {kkarouzos1, xingwei.tan, n.aletras}@sheffield.ac.uk "
[12.01.2026 15:28] Response: ```python
["School of Computer Science University of Sheffield, UK"]
```
[12.01.2026 15:28] Deleting PDF ./assets/pdf/2601.05882.pdf.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05966.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05966.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05966.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05905.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05905.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05905.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05848.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05848.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05848.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05573.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05573.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05573.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05403.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05403.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05403.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.04888.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.04888.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.04888.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.02760.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.02760.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.02760.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05637.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05637.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05637.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.04823.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.04823.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.04823.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.04726.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.04726.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.04726.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.04544.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.04544.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.04544.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05960.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05960.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05960.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05741.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05741.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05741.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05503.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05503.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05503.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05870.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05870.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05870.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05851.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05851.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05851.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05699.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.05699.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.05699.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.05376.
[12.01.2026 15:28] Downloading paper 2601.05376 from https://arxiv.org/pdf/2601.05376v1...
[12.01.2026 15:28] Extracting affiliations from text.
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models Tassallah Abdullahi1, Shrestha Ghosh2, Hamish Fraser1, Daniel Le√≥n Tramontini2 Adeel Abbasi1, Ghada Bourjeily1, Carsten Eickhoff2, Ritambhara Singh1 1Brown University, USA, 2University of Tuebingen, Germany {tassallah_abdullahi,hamish_fraser, adeel_abbasi,ghada_bourjeily,ritambhara}@brown.edu {shrestha.ghosh,carsten.eickhoff}@uni-tuebingen.de, daniel.leon-tramontini@student.uni-tuebingen.de 6 2 0 2 ] . [ 1 6 7 3 5 0 . 1 0 6 2 : r a "
[12.01.2026 15:28] Response: ```python
['Brown University', 'University of Tuebingen']
```
[12.01.2026 15:28] Deleting PDF ./assets/pdf/2601.05376.pdf.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Downloading and parsing paper https://huggingface.co/papers/2601.04175.
[12.01.2026 15:28] Extra JSON file exists (./assets/json/2601.04175.json), skip PDF parsing.
[12.01.2026 15:28] Paper image links file exists (./assets/img_data/2601.04175.json), skip HTML parsing.
[12.01.2026 15:28] Success.
[12.01.2026 15:28] Enriching papers with extra data.
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 0. Large vision-language models are enhanced for image geolocalization by incorporating map-based reasoning and agent-in-the-map loop optimization, achieving superior accuracy compared to existing models.  					AI-generated summary 				 The image geolocalization task aims to predict the location where ...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 1. MMFormalizer enables multimodal autoformalization by integrating visual perception with formal mathematical reasoning, supporting complex physical domains from classical mechanics to quantum mechanics.  					AI-generated summary 				 Autoformalization, which translates natural language mathematics i...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 2. Large language models struggle with long chain-of-thought reasoning due to unstable structural patterns, but a molecular-inspired approach using effective semantic isomers and distribution-transfer-graph methods improves training stability and performance.  					AI-generated summary 				 Large langu...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 3. A photorealistic 3D caricaturization framework combines Gaussian curvature-based surface exaggeration with 3D Gaussian Splatting to create controllable, realistic avatars with improved fidelity and real-time deformation capabilities.  					AI-generated summary 				 A photorealistic and controllable ...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 4. A citation-aware reward framework and policy optimization method improve deep search agents' reasoning comprehensiveness and factual accuracy while reducing shortcut exploitation and hallucinations.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as a critical technique for e...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 5. EnvScaler automates the creation of tool-interaction environments through programmatic synthesis, enhancing LLM performance in complex multi-turn, multi-tool tasks via supervised fine-tuning and reinforcement learning.  					AI-generated summary 				 Large language models (LLMs) are expected to be t...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 6. The Qwen3-VL-Embedding and Qwen3-VL-Reranker models form an end-to-end multimodal search pipeline, leveraging multi-stage training and cross-attention mechanisms to achieve high-precision retrieval across diverse modalities.  					AI-generated summary 				 In this report, we introduce the Qwen3-VL-E...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 7. Autonomous machine learning agents overcome execution bottlenecks by predicting outcomes before physical execution, achieving faster convergence and improved performance through a predict-then-verify approach.  					AI-generated summary 				 Autonomous machine learning agents have revolutionized sci...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 8. AgentOCR reduces token consumption in agentic systems by representing interaction history as visual tokens and employing visual caching and self-compression techniques.  					AI-generated summary 				 Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement l...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 9. Preference tuning of language models shows varying generalization capabilities under domain shift, with pseudo-labeling adaptation strategies effectively reducing performance degradation in summarization and question-answering tasks.  					AI-generated summary 				 Preference tuning aligns pretraine...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 10. VideoAR presents a large-scale visual autoregressive framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling, achieving state-of-the-art results with improved efficiency and temporal consistency.  					AI-generated summary 				 Recent advances in v...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 11. Large language models exhibit brittle beliefs under contextual perturbations, which are better measured by structural consistency metrics and addressed through structure-aware training methods.  					AI-generated summary 				 As Large Language Models (LLMs) are increasingly deployed in real-world se...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 12. Video generation models trained on synthetic physics primitives demonstrate zero-shot generalization to complex real-world scenarios by modeling force propagation through time and space.  					AI-generated summary 				 Recent advancements in video generation have enabled the development of ``world m...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 13. Orient Anything V2 enhances 3D orientation understanding through scalable 3D asset synthesis, symmetry-aware periodic distribution fitting, and multi-frame relative rotation prediction, achieving state-of-the-art performance across multiple benchmarks.  					AI-generated summary 				 This work prese...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 14. A comprehensive benchmark evaluates behavioral biases in large language models for multilingual financial misinformation detection across diverse economic scenarios.  					AI-generated summary 				 Large language models (LLMs) have been widely applied across various domains of finance. Since their t...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 15. SmartSearch enhances LLM-based search agents through process rewards and query refinement mechanisms that improve intermediate search query quality via a three-stage curriculum learning approach.  					AI-generated summary 				 Large language model (LLM)-based search agents have proven promising for...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 16. A lightweight monocular depth estimation framework uses DINOv3 as visual encoder and a compact transformer decoder to achieve higher accuracy with reduced computational overhead and improved data quality.  					AI-generated summary 				 Monocular depth estimation aims to recover the depth informatio...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 17. Generative models' controllability is theoretically analyzed through a framework that estimates controllable sets with distribution-free bounds, revealing that controllability is fragile and context-dependent.  					AI-generated summary 				 As generative models become ubiquitous, there is a critica...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 18. DR-LoRA dynamically adjusts LoRA ranks for experts in Mixture-of-Experts models based on task-specific demands, improving parameter efficiency and performance.  					AI-generated summary 				 Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 19. CompassMem is an event-centric memory framework that organizes experiences into an Event Graph to enable structured memory navigation and long-horizon reasoning beyond traditional retrieval methods.  					AI-generated summary 				 Large language models (LLMs) are increasingly deployed as intelligent...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 20. A multi-agent system router that uses dynamic agent onboarding and natural language reasoning chains to improve routing accuracy and reduce conflicts in enterprise applications.  					AI-generated summary 				 Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance int...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 21. A framework converts transient critiques into retrievable guidelines using a file-based memory system and agent-controlled tool calls, enabling LLMs to match test-time refinement performance with reduced inference costs.  					AI-generated summary 				 We propose a framework that amortizes the cost ...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 22. ViTNT-FIQA measures face image quality by analyzing patch embedding stability across Vision Transformer blocks with a single forward pass.  					AI-generated summary 				 Face Image Quality Assessment (FIQA) is essential for reliable face recognition systems. Current approaches primarily exploit onl...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 23. Search-augmented large language models suffer from over-searching behavior that wastes computational resources and introduces hallucinations, with findings showing varied impacts across model types and conversation contexts.  					AI-generated summary 				 Search-augmented large language models (LLM...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 24. Latent Policy Optimization via Iterative Information Bottleneck addresses exploration collapse in LLM reasoning by enabling topological branching of reasoning trajectories through information bottleneck principles.  					AI-generated summary 				 Recent advances in Reinforcement Learning with Verifi...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 25. Multimodal auto-completion leverages visual and textual context to improve real-time prediction accuracy in conversational interfaces, with a router framework enabling efficient model selection based on dialog context.  					AI-generated summary 				 Real-time multimodal auto-completion is essential...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 26. Afri-MCQA benchmark demonstrates poor performance of open-weight LLMs in African languages, highlighting the need for culturally grounded pretraining and speech-first approaches in AI development.  					AI-generated summary 				 Africa is home to over one-third of the world's languages, yet remains ...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 27. Persona conditioning in clinical language models produces context-dependent effects on performance and safety that vary systematically with professional role and interaction style, challenging assumptions of monotonic improvement in expert behavior.  					AI-generated summary 				 Persona conditioni...
[12.01.2026 15:28] ********************************************************************************
[12.01.2026 15:28] Abstract 28. Legal alignment explores how legal principles and methods can guide AI system design to ensure safety, ethics, and compliance through three research directions involving rule adherence, legal reasoning methods, and structural blueprints for AI reliability and trust.  					AI-generated summary 				 A...
[12.01.2026 15:28] Read previous papers.
[12.01.2026 15:28] Generating reviews via LLM API.
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#agents", "#cv", "#dataset", "#multimodal", "#rl", "#open_source", "#reasoning"], "emoji": "üó∫Ô∏è", "ru": {"title": "–ö–∞—Ä—Ç—ã –∫–∞–∫ –∫–æ–º–ø–∞—Å: –Ω–∞—É—á–∏–º AI –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–µ–±—è –Ω–∞ –ø–ª–∞–Ω–µ—Ç–µ", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#math", "#dataset", "#benchmark", "#reasoning", "#science", "#multimodal"], "emoji": "üî¨", "ru": {"title": "–í–æ—Å–ø—Ä–∏—è—Ç–∏–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞: –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∏–∑–∏–∫–∏ –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏", "desc": "MMFormalizer ‚Äî —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –∞–≤—Ç–æ—Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#optimization", "#training"], "emoji": "üß¨", "ru": {"title": "–ú–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ —Ü–µ–ø–æ—á–µ–∫ –¥–ª–∏–Ω–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ LLM", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª–∏–Ω–Ω—ã–º —Ü–µ–ø–æ—á–∫–∞–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ —Ö–∞—Ä–∞
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#multimodal", "#3d"], "emoji": "ü§™", "ru": {"title": "–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ 3D-–∫–∞—Ä–∏–∫–∞—Ç—É—Ä—ã —á–µ—Ä–µ–∑ –≥–∞—É—Å—Å–æ–≤—ã —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫—Ä–∏–≤–∏–∑–Ω–æ–π", "desc": "–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —à–∞—Ä–∂–µ–π –ª–∏—Ü –Ω–∞ –æ—Å–Ω–æ–≤–µ 3D-–º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—Ä–∏–≤–∏–∑–Ω—É –ì–∞—É—Å—Å–∞ –¥–ª—è –ø—Ä–µ—É–≤–µ–ª–∏—á–µ–Ω–∏—è —á–µ—Ä
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#optimization", "#hallucinations", "#rl", "#training", "#open_source", "#reasoning"], "emoji": "üîó", "ru": {"title": "–ù–∞–≥—Ä–∞–¥—ã —Å –æ—Å–æ–∑–Ω–∞–Ω–∏–µ–º —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–≥—Ä–∞–¥ Citation-aware Rubric Rewards (CaR
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#rl", "#dataset", "#agents", "#training"], "emoji": "üèóÔ∏è", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å–∏–Ω—Ç–µ–∑–∞ –æ–∫—Ä—É–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM", "desc": "EnvScaler ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ä–µ–¥ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ —Å –ø–æ–º–æ—â—å—é —Å–∏–Ω—Ç–µ–∑–∞ –ø—Ä–æ–≥—Ä–∞–º–º. –°–∏—Å—Ç–µ–º–∞
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#multilingual", "#benchmark", "#rag", "#open_source", "#training", "#architecture", "#multimodal"], "emoji": "üîç", "ru": {"title": "–ï–¥–∏–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –º–æ–¥–µ–ª–∏ Qwen3-VL-Embedding –∏ Qwen3-VL-Reranker, –∫–æ—Ç–æ—Ä—ã–µ —Ñ–æ—Ä–º–∏—Ä—É—é—Ç –ø–æ
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#dataset", "#open_source", "#science"], "emoji": "üîÆ", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø—Ä–µ–∂–¥–µ, —á–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç—å: —É—Å–∫–æ—Ä–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", "desc": "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞–¥–∞—é—Ç –æ—Ç —É–∑–∫–æ–≥–æ –º–µ—Å—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –∫–æ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#cv", "#agents", "#inference", "#rl"], "emoji": "üñºÔ∏è", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö", "desc": "AgentOCR ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–Ω–∏–∂–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –∏—Å—Ç–æ—Ä–∏—é –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –≤–∏–∑—É–∞–ª—å
[12.01.2026 15:28] Querying the API.
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Preference tuning of language models shows varying generalization capabilities under domain shift, with pseudo-labeling adaptation strategies effectively reducing performance degradation in summarization and question-answering tasks.  					AI-generated summary 				 Preference tuning aligns pretrained language models to human judgments of quality, helpfulness, or safety by optimizing over explicit preference signals rather than likelihood alone. Prior work has shown that preference-tuning degrades performance and reduces helpfulness when evaluated outside the training domain. However, the extent to which adaptation strategies mitigate this domain shift remains unexplored. We address this challenge by conducting a comprehensive and systematic study of alignment generalization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. Our findings reveal systematic differences in generalization across alignment objectives under domain shift. We show that adaptation strategies based on pseudo-labeling can substantially reduce domain-shift degradation
[12.01.2026 15:28] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è, –∫–∞–∫ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –Ω–∞ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ–≥–¥–∞ –ø–µ—Ä–µ—Ö–æ–¥—è—Ç –Ω–∞ –Ω–æ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö. –ê–≤—Ç–æ—Ä—ã —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç –ø—è—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏, –≤–∫–ª—é—á–∞—è –¥–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ü–µ–ª–µ–≤–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏ –ø—Å–µ–≤–¥–æ—Ä–∞–∑–º–µ—Ç–∫—É. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –ø–µ—Ä–µ—Ö–æ–¥–æ–º –º–µ–∂–¥—É –æ–±–ª–∞—Å—Ç—è–º–∏, –∏ —á—Ç–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Å–µ–≤–¥–æ—Ä–∞–∑–º–µ—Ç–∫–∏ –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å —Ü–µ–ª—å—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤.",
  "emoji": "üéØ",
  "title": "–ê–¥–∞–ø—Ç–∞—Ü–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ —Å–º–µ–Ω–µ –æ–±–ª–∞—Å—Ç–∏ —á–µ—Ä–µ–∑ –ø—Å–µ–≤–¥–æ—Ä–∞–∑–º–µ—Ç–∫—É"
}
```
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Preference tuning of language models shows varying generalization capabilities under domain shift, with pseudo-labeling adaptation strategies effectively reducing performance degradation in summarization and question-answering tasks.  					AI-generated summary 				 Preference tuning aligns pretrained language models to human judgments of quality, helpfulness, or safety by optimizing over explicit preference signals rather than likelihood alone. Prior work has shown that preference-tuning degrades performance and reduces helpfulness when evaluated outside the training domain. However, the extent to which adaptation strategies mitigate this domain shift remains unexplored. We address this challenge by conducting a comprehensive and systematic study of alignment generalization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. Our findings reveal systematic differences in generalization across alignment objectives under domain shift. We show that adaptation strategies based on pseudo-labeling can substantially reduce domain-shift degradation"

[12.01.2026 15:28] Response: ```python
['RLHF', 'TRAINING']
```
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Preference tuning of language models shows varying generalization capabilities under domain shift, with pseudo-labeling adaptation strategies effectively reducing performance degradation in summarization and question-answering tasks.  					AI-generated summary 				 Preference tuning aligns pretrained language models to human judgments of quality, helpfulness, or safety by optimizing over explicit preference signals rather than likelihood alone. Prior work has shown that preference-tuning degrades performance and reduces helpfulness when evaluated outside the training domain. However, the extent to which adaptation strategies mitigate this domain shift remains unexplored. We address this challenge by conducting a comprehensive and systematic study of alignment generalization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. Our findings reveal systematic differences in generalization across alignment objectives under domain shift. We show that adaptation strategies based on pseudo-labeling can substantially reduce domain-shift degradation"

[12.01.2026 15:28] Response: ```python
['ALIGNMENT', 'TRANSFER_LEARNING']
```
[12.01.2026 15:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how preference tuning of language models can be affected by changes in the domain of the data. Preference tuning aims to align models with human preferences for quality and helpfulness, but it often leads to performance drops when applied to new domains. The authors explore various adaptation strategies, particularly focusing on pseudo-labeling, to see how they can help maintain performance in summarization and question-answering tasks. Their results indicate that certain adaptation methods can significantly lessen the negative impact of domain shifts on model performance.","title":"Mitigating Domain Shift in Language Model Preference Tuning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates how preference tuning of language models can be affected by changes in the domain of the data. Preference tuning aims to align models with human preferences for quality and helpfulness, but it often leads to performance drops when applied to new domains. The authors explore various adaptation strategies, particularly focusing on pseudo-labeling, to see how they can help maintain performance in summarization and question-answering tasks. Their results indicate that certain adaptation methods can significantly lessen the negative impact of domain shifts on model performance.', title='Mitigating Domain Shift in Language Model Preference Tuning'))
[12.01.2026 15:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ËÆ∫ÊñáÁ†îÁ©∂‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÅèÂ•ΩË∞É‰ºòÂú®È¢ÜÂüüËΩ¨Áßª‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøá‰º™Ê†áÁ≠æÈÄÇÂ∫îÁ≠ñÁï•ÔºåËÉΩÂ§üÊúâÊïàÂáèÂ∞ëÂú®ÊëòË¶ÅÂíåÈóÆÁ≠î‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇÊàë‰ª¨ÊØîËæÉ‰∫Ü‰∫îÁßçÊµÅË°åÁöÑÂØπÈΩêÁõÆÊ†áÂíåÂ§öÁßçÈÄÇÂ∫îÁ≠ñÁï•ÔºåÂèëÁé∞‰∏çÂêåÁöÑÂØπÈΩêÁõÆÊ†áÂú®È¢ÜÂüüËΩ¨Áßª‰∏ãÁöÑÊ≥õÂåñË°®Áé∞Â≠òÂú®Á≥ªÁªüÊÄßÂ∑ÆÂºÇ„ÄÇÁªìÊûúË°®ÊòéÔºåÂü∫‰∫é‰º™Ê†áÁ≠æÁöÑÈÄÇÂ∫îÁ≠ñÁï•ÂèØ‰ª•ÊòæËëóÈôç‰ΩéÈ¢ÜÂüüËΩ¨ÁßªÂ∏¶Êù•ÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇ","title":"‰º™Ê†áÁ≠æÁ≠ñÁï•Âä©ÂäõËØ≠Ë®ÄÊ®°ÂûãÈ¢ÜÂüüÈÄÇÂ∫î"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ËÆ∫ÊñáÁ†îÁ©∂‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÅèÂ•ΩË∞É‰ºòÂú®È¢ÜÂüüËΩ¨Áßª‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøá‰º™Ê†áÁ≠æÈÄÇÂ∫îÁ≠ñÁï•ÔºåËÉΩÂ§üÊúâÊïàÂáèÂ∞ëÂú®ÊëòË¶ÅÂíåÈóÆÁ≠î‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇÊàë‰ª¨ÊØîËæÉ‰∫Ü‰∫îÁßçÊµÅË°åÁöÑÂØπÈΩêÁõÆÊ†áÂíåÂ§öÁßçÈÄÇÂ∫îÁ≠ñÁï•ÔºåÂèëÁé∞‰∏çÂêåÁöÑÂØπÈΩêÁõÆÊ†áÂú®È¢ÜÂüüËΩ¨Áßª‰∏ãÁöÑÊ≥õÂåñË°®Áé∞Â≠òÂú®Á≥ªÁªüÊÄßÂ∑ÆÂºÇ„ÄÇÁªìÊûúË°®ÊòéÔºåÂü∫‰∫é‰º™Ê†áÁ≠æÁöÑÈÄÇÂ∫îÁ≠ñÁï•ÂèØ‰ª•ÊòæËëóÈôç‰ΩéÈ¢ÜÂüüËΩ¨ÁßªÂ∏¶Êù•ÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇ', title='‰º™Ê†áÁ≠æÁ≠ñÁï•Âä©ÂäõËØ≠Ë®ÄÊ®°ÂûãÈ¢ÜÂüüÈÄÇÂ∫î'))
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#architecture", "#benchmark", "#video", "#training"], "emoji": "üé¨", "ru": {"title": "–ê–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –≤–∏–¥–µ–æ: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∏—Ñ—Ñ—É–∑–∏–∏ –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "VideoAR –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–≤—É—é –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—É—é –∞–≤—Ç–∞—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–∞—è –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –º–Ω–æ–≥
[12.01.2026 15:28] Using data from previous issue: {"categories": [], "emoji": "üèóÔ∏è", "ru": {"title": "–£–∫—Ä–µ–ø–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–π –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ —É–±–µ–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø–æ–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —Ö—Ä—É–ø–∫–∏–µ —É–±–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–ª–æ—Ö–æ –∏–∑–º–µ—Ä—è—é—Ç—Å—è —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤—Ä–æ–¥–µ Self-Consistency. 
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#robotics", "#dataset", "#synthetic", "#video", "#training", "#open_source"], "emoji": "üé¨", "ru": {"title": "–û—Ç –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–∫–æ–Ω–æ–≤ —Ñ–∏–∑–∏–∫–∏ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é —Å–ª–æ–∂–Ω–æ–≥–æ –º–∏—Ä–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ Goal Force ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–∏–¥–µ–æ-–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ —è–≤–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#dataset", "#3d", "#multimodal", "#synthetic", "#open_source"], "emoji": "üîÑ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ–π –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ —Å —É—á—ë—Ç–æ–º —Å–∏–º–º–µ—Ç—Ä–∏–∏", "desc": "Orient Anything V2 ‚Äî —ç—Ç–æ —É–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#multilingual", "#ethics", "#low_resource", "#benchmark", "#survey", "#dataset", "#open_source"], "emoji": "üí∞", "ru": {"title": "–í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–µ–¥—É–±–µ–∂–¥–µ–Ω–∏–π LLM –≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥—É–±–µ–∂–¥–µ–Ω–∏–π
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#open_source"], "emoji": "üîç", "ru": {"title": "–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –ø—Ä–æ—Ü–µ—Å—Å–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤", "desc": "SmartSearch ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è LLM-based –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–π —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#small_models", "#3d", "#training", "#data", "#architecture", "#cv"], "emoji": "üéØ", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≥–ª—É–±–∏–Ω—ã —á–µ—Ä–µ–∑ –±–∞–ª–∞–Ω—Å –¥–∏–∑–∞–π–Ω–∞ –º–æ–¥–µ–ª–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –ª—ë–≥–∫–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–æ–Ω–æ–∫—É–ª—è—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –≥–ª—É–±–∏–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π DINOv3 –≤ –∫–∞—á–µ
[12.01.2026 15:28] Using data from previous issue: {"categories": [], "emoji": "üéÆ", "ru": {"title": "–£–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: –æ—Ç –∏–ª–ª—é–∑–∏–∏ –∫–æ–Ω—Ç—Ä–æ–ª—è –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –µ–≥–æ –≥—Ä–∞–Ω–∏—Ü", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä–∞—è –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–æ—Å—Ç–∏–∂–∏–º—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#architecture", "#training"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ä–∞–Ω–≥–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ DR-LoRA –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–Ω–≥–æ–≤ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ LoRA –≤ –º–æ–¥–µ–ª—è—Ö Mixture-of-Experts –≤–æ –≤—Ä–µ–º—è f
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#long_context", "#reasoning", "#graphs"], "emoji": "üß≠", "ru": {"title": "–ì—Ä–∞—Ñ —Å–æ–±—ã—Ç–∏–π –∫–∞–∫ –ª–æ–≥–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞ –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤", "desc": "CompassMem ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø–∞–º—è—Ç–∏, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Å–æ–±—ã—Ç–∏—è, –∫–æ—Ç–æ—Ä—ã–π –æ—Ä–≥–∞–Ω–∏–∑—É–µ—Ç –æ–ø—ã—Ç –∞–≥–µ–Ω—Ç–∞ –≤ –≤–∏–¥–µ –≥—Ä–∞—Ñ–∞ —Å–æ–±—ã—Ç–∏–π —Å —è–≤–Ω—ã–º–∏ –ª–æ–≥
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#agents"], "emoji": "üö¶", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —Å –ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ –¥–ª—è –≥–∏–±–∫–∏—Ö –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º TCAR, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –º
[12.01.2026 15:28] Using data from previous issue: {"categories": [], "emoji": "üíæ", "ru": {"title": "–ò–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–∏—Ç–∏–∫–∏ –≤ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è: —ç–∫–æ–Ω–æ–º–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–∏–∫–∏ –≤ —Å–æ—Ö—Ä–∞–Ω—è–µ–º—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#cv", "#benchmark"], "emoji": "üé≠", "ru": {"title": "–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∫–∞–∫ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –ª–∏—Ü –≤ Vision Transformer", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç ViTNT-FIQA ‚Äî –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ª–∏—Ü –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø–∞—Ç—á–µ–π —á–µ—Ä–µ–∑ —Å
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#rag", "#benchmark", "#hallucinations", "#optimization"], "emoji": "üîç", "ru": {"title": "–ö–æ–≥–¥–∞ –ø–æ–∏—Å–∫ –≤—Ä–µ–¥–∏—Ç: –∫–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å —á—Ä–µ–∑–º–µ—Ä–Ω—ã—Ö –æ–±—Ä–∞—â–µ–Ω–∏–π –≤ –ø–æ–∏—Å–∫-–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö LLM", "desc": "–í —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ —á—Ä–µ–∑–º–µ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ–º –ø–æ–∏—Å–∫–æ–º, –∫–æ–≥–¥–∞ 
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#optimization", "#math", "#rl", "#training", "#reasoning"], "emoji": "üåø", "ru": {"title": "–í–µ—Ç–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —É–∑–∫–æ–µ –º–µ—Å—Ç–æ", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ IIB-LPO –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –∫–æ–ª–ª–∞–ø—Å–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Ä–µ—à
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#multimodal"], "emoji": "üí¨", "ru": {"title": "–£–º–Ω–æ–µ –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è (MAC), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã –≤ —á–∞—Ç
[12.01.2026 15:28] Using data from previous issue: {"categories": ["#open_source", "#audio", "#low_resource", "#multimodal", "#benchmark", "#multilingual", "#dataset"], "emoji": "üåç", "ru": {"title": "–ê—Ñ—Ä–∏–∫–∞–Ω—Å–∫–∏–µ —è–∑—ã–∫–∏ —Ç—Ä–µ–±—É—é—Ç –∫—É–ª—å—Ç—É—Ä–Ω–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Afri-MCQA ‚Äî –ø–µ—Ä–≤—ã–π –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–ø
[12.01.2026 15:28] Querying the API.
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Persona conditioning in clinical language models produces context-dependent effects on performance and safety that vary systematically with professional role and interaction style, challenging assumptions of monotonic improvement in expert behavior.  					AI-generated summary 				 Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to sim+20% in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's Œ∫= 0.43) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox.
[12.01.2026 15:28] Response: ```json
{
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –ø–µ—Ä—Å–æ–Ω—ã (—Ä–æ–ª–∏ –≤—Ä–∞—á–∞, –º–µ–¥—Å–µ—Å—Ç—Ä—ã) –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –º–æ–Ω–æ—Ç–æ–Ω–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞, –∞ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º—ã–º —ç—Ñ—Ñ–µ–∫—Ç–∞–º. –ê–≤—Ç–æ—Ä—ã —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–ª–∏ –≤–ª–∏—è–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–æ–ª–µ–π –∏ —Å—Ç–∏–ª–µ–π –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å LLM –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö, –æ–±–Ω–∞—Ä—É–∂–∏–≤ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ ~20% –≤ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–π —Ç–µ—Ä–∞–ø–∏–∏ –∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –≤ –∞–º–±—É–ª–∞—Ç–æ—Ä–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–µ. –ü–æ–º–∏–º–æ —Ç–æ—á–Ω–æ—Å—Ç–∏, –∫–æ–º–∞–Ω–¥–∞ –∏–∑–º–µ—Ä—è–ª–∞ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∫—É –º–æ–¥–µ–ª–µ–π –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ, —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä–∏—Å–∫–æ–º –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ –ø–µ—Ä—Å–æ–Ω—ã —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É—é—Ç –∫–∞–∫ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –∞–ø—Ä–∏–æ—Ä–Ω—ã–µ –∑–Ω–∞–Ω–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–∞–º–∏, –∞ –Ω–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º–∏ –≥–∞—Ä–∞–Ω—Ç–∏—è–º–∏ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.",
  "emoji": "‚öïÔ∏è",
  "title": "–ü–µ—Ä—Å–æ–Ω—ã –≤—Ä–∞—á–µ–π –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö: —É–ª—É—á—à–µ–Ω–∏–µ –∏–ª–∏ –∏–ª–ª—é–∑–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏?"
}
```
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Persona conditioning in clinical language models produces context-dependent effects on performance and safety that vary systematically with professional role and interaction style, challenging assumptions of monotonic improvement in expert behavior.  					AI-generated summary 				 Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to sim+20% in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's Œ∫= 0.43) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox."

[12.01.2026 15:28] Response: ```python
["HEALTHCARE", "BENCHMARK", "TRAINING"]
```

**Justification:**

- **HEALTHCARE**: The paper directly applies machine learning to medical/clinical domains, evaluating clinical language models on medical tasks like clinical triage and patient-safety decisions.

- **BENCHMARK**: The paper proposes a systematic evaluation framework for assessing persona-based control in clinical LLMs using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior.

- **TRAINING**: The paper examines persona conditioning as a behavioral prior and control mechanism for training/fine-tuning LLMs to behave in specific ways (different professional roles and interaction styles).
[12.01.2026 15:28] Error. Failed to parse JSON from LLM. ["HEALTHCARE", "BENCHMARK", "TRAINING"]


**Justification:**

- **HEALTHCARE**: The paper directly applies machine learning to medical/clinical domains, evaluating clinical language models on medical tasks like clinical triage and patient-safety decisions.

- **BENCHMARK**: The paper proposes a systematic evaluation framework for assessing persona-based control in clinical LLMs using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior.

- **TRAINING**: The paper examines persona conditioning as a behavioral prior and control mechanism for training/fine-tuning LLMs to behave in specific ways (different professional roles and interaction styles).
[12.01.2026 15:28] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Persona conditioning in clinical language models produces context-dependent effects on performance and safety that vary systematically with professional role and interaction style, challenging assumptions of monotonic improvement in expert behavior.  					AI-generated summary 				 Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to sim+20% in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's Œ∫= 0.43) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox."

[12.01.2026 15:28] Response: ```python
['ALIGNMENT', 'ETHICS', 'INTERPRETABILITY']
```
[12.01.2026 15:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how persona conditioning in clinical language models affects their performance and safety in medical tasks. It reveals that the impact of different professional roles and interaction styles on model behavior is not straightforward, challenging the idea that expert personas always lead to better outcomes. The study finds that while medical personas can enhance accuracy in critical care tasks, they may actually hinder performance in primary care scenarios. Overall, the results highlight that persona conditioning introduces complex trade-offs rather than consistent improvements in safety and expertise.","title":"Persona Conditioning: Context Matters in Clinical AI Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates how persona conditioning in clinical language models affects their performance and safety in medical tasks. It reveals that the impact of different professional roles and interaction styles on model behavior is not straightforward, challenging the idea that expert personas always lead to better outcomes. The study finds that while medical personas can enhance accuracy in critical care tasks, they may actually hinder performance in primary care scenarios. Overall, the results highlight that persona conditioning introduces complex trade-offs rather than consistent improvements in safety and expertise.', title='Persona Conditioning: Context Matters in Clinical AI Performance'))
[12.01.2026 15:29] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂú®‰∏¥Â∫äËØ≠Ë®ÄÊ®°Âûã‰∏≠‰ΩøÁî®ËßíËâ≤Êù°‰ª∂ÂåñÂØπÊÄßËÉΩÂíåÂÆâÂÖ®ÊÄßÁöÑÂΩ±Âìç„ÄÇÁ†îÁ©∂ÂèëÁé∞Ôºå‰∏çÂêåÁöÑ‰∏ì‰∏öËßíËâ≤Âíå‰∫íÂä®È£éÊ†º‰ºöÁ≥ªÁªüÊÄßÂú∞ÂΩ±ÂìçÊ®°ÂûãÂú®ÂåªÁñó‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇÂ∞ΩÁÆ°ÂåªÁñóËßíËâ≤Âú®Âç±ÊÄ•Êä§ÁêÜ‰ªªÂä°‰∏≠ÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÔºå‰ΩÜÂú®ÂàùÁ∫ßÊä§ÁêÜÁéØÂ¢É‰∏≠Âç¥ÂèØËÉΩÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåËßíËâ≤Êù°‰ª∂ÂåñÂπ∂‰∏çÊÄªÊòØËÉΩ‰øùËØÅÂÆâÂÖ®Êàñ‰∏ì‰∏öÊÄßÔºåËÄåÊòØÂºïÂÖ•‰∫Ü‰æùËµñ‰∫é‰∏ä‰∏ãÊñáÁöÑÊùÉË°°„ÄÇ","title":"ËßíËâ≤Êù°‰ª∂ÂåñÔºöÂåªÁñóÊ®°Âûã‰∏≠ÁöÑÂèåÂàÉÂâë"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂú®‰∏¥Â∫äËØ≠Ë®ÄÊ®°Âûã‰∏≠‰ΩøÁî®ËßíËâ≤Êù°‰ª∂ÂåñÂØπÊÄßËÉΩÂíåÂÆâÂÖ®ÊÄßÁöÑÂΩ±Âìç„ÄÇÁ†îÁ©∂ÂèëÁé∞Ôºå‰∏çÂêåÁöÑ‰∏ì‰∏öËßíËâ≤Âíå‰∫íÂä®È£éÊ†º‰ºöÁ≥ªÁªüÊÄßÂú∞ÂΩ±ÂìçÊ®°ÂûãÂú®ÂåªÁñó‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇÂ∞ΩÁÆ°ÂåªÁñóËßíËâ≤Âú®Âç±ÊÄ•Êä§ÁêÜ‰ªªÂä°‰∏≠ÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÔºå‰ΩÜÂú®ÂàùÁ∫ßÊä§ÁêÜÁéØÂ¢É‰∏≠Âç¥ÂèØËÉΩÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåËßíËâ≤Êù°‰ª∂ÂåñÂπ∂‰∏çÊÄªÊòØËÉΩ‰øùËØÅÂÆâÂÖ®Êàñ‰∏ì‰∏öÊÄßÔºåËÄåÊòØÂºïÂÖ•‰∫Ü‰æùËµñ‰∫é‰∏ä‰∏ãÊñáÁöÑÊùÉË°°„ÄÇ', title='ËßíËâ≤Êù°‰ª∂ÂåñÔºöÂåªÁñóÊ®°Âûã‰∏≠ÁöÑÂèåÂàÉÂâë'))
[12.01.2026 15:29] Using data from previous issue: {"categories": ["#ethics", "#alignment"], "emoji": "‚öñÔ∏è", "ru": {"title": "–ü—Ä–∞–≤–æ–≤–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: –æ—Ç —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –∫ –Ω–∞–¥–µ–∂–Ω—ã–º AI —Å–∏—Å—Ç–µ–º–∞–º", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–∞–≤–æ–≤–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ (legal alignment) ‚Äî –Ω–æ–≤–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ –æ–±–ª–∞—Å—Ç–∏ AI, –∫–æ—Ç–æ—Ä–æ–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –º–µ—Ç–æ–¥—ã –¥–ª—è 
[12.01.2026 15:29] Renaming data file.
[12.01.2026 15:29] Renaming previous data. hf_papers.json to ./d/2026-01-12.json
[12.01.2026 15:29] Saving new data file.
[12.01.2026 15:29] Generating page.
[12.01.2026 15:29] Renaming previous page.
[12.01.2026 15:29] Renaming previous data. index.html to ./d/2026-01-12.html
[12.01.2026 15:29] Writing result.
[12.01.2026 15:29] Renaming log file.
[12.01.2026 15:29] Renaming previous data. log.txt to ./logs/2026-01-12_last_log.txt
