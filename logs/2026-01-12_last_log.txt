[12.01.2026 08:35] Read previous papers.
[12.01.2026 08:35] Generating top page (month).
[12.01.2026 08:35] Writing top page (month).
[12.01.2026 09:34] Read previous papers.
[12.01.2026 09:34] Get feed.
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05432
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03017
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06002
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06021
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03319
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05808
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05930
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05966
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05905
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04720
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04786
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05573
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04888
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05848
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05637
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04823
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02760
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05960
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05503
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04726
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05870
[12.01.2026 09:34] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05851
[12.01.2026 09:34] Extract page data from URL. URL: https://huggingface.co/papers/2601.05403
[12.01.2026 09:34] Extract page data from URL. URL: https://huggingface.co/papers/2601.04544
[12.01.2026 09:34] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[12.01.2026 09:34] No deleted papers detected.
[12.01.2026 09:34] Downloading and parsing papers (pdf, html). Total: 24.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05432.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05432.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05432.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.03017.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.03017.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.03017.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.06002.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.06002.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.06002.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.06021.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.06021.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.06021.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.03319.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.03319.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.03319.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05808.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05808.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05808.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05930.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05930.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05930.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05966.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05966.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05966.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05905.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05905.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05905.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.04720.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.04720.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.04720.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.04786.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.04786.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.04786.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05573.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05573.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05573.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.04888.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.04888.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.04888.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05848.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05848.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05848.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05637.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05637.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05637.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.04823.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.04823.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.04823.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.02760.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.02760.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.02760.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05960.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05960.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05960.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05503.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05503.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05503.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.04726.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.04726.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.04726.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05870.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05870.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05870.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05851.
[12.01.2026 09:34] Extra JSON file exists (./assets/json/2601.05851.json), skip PDF parsing.
[12.01.2026 09:34] Paper image links file exists (./assets/img_data/2601.05851.json), skip HTML parsing.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.05403.
[12.01.2026 09:34] Downloading paper 2601.05403 from https://arxiv.org/pdf/2601.05403v1...
[12.01.2026 09:34] Extracting affiliations from text.
[12.01.2026 09:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 8 ] . [ 1 3 0 4 5 0 . 1 0 6 2 : r Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection Zhiwei Liu1, Yupen Cao2, Yuechen Jiang1, Mohsinul Kabir1, Polydoros Giannouris1, Chen Xu3, Ziyang Xu3, Tianlei Zhu4, Md. Tariquzzaman5, Triantafillos Papadopoulos6,7, Yan Wang3, Lingfei Qian3, Xueqing Peng3, Zhuohan Xie8, Ye Yuan9, 10, Saeed Almheiri8, Abdulrazzaq Alnajjar11, Mingbin Chen12, Harry Stuart8, Paul Thompson1, Prayag Tiwari13, Alejandro Lopez-Lira14, Xue Liu8,9, Jimin Huang1,3*, Sophia Ananiadou1,15 1The University of Manchester, 2Stevens Institute of Technology, 3The FinAI, 4Columbia University, 5Islamic University of Technology, 6Athens University of Economics and Business, 7Archimedes, Athena Research Center, 8MBZUAI, 9McGill University, 10Mila - Quebec AI Institute, 11Dubai Police, 12University of Melbourne, 13Halmstad University, 14University of Florida, 15ELLIS Manchester {zhiwei.liu, sophia.ananiadou}@manchester.ac.uk, jimin.huang@thefin.ai "
[12.01.2026 09:34] Response: ```python
[
    "The University of Manchester",
    "Stevens Institute of Technology",
    "The FinAI",
    "Columbia University",
    "Islamic University of Technology",
    "Athens University of Economics and Business",
    "Archimedes, Athena Research Center",
    "MBZUAI",
    "McGill University",
    "Mila - Quebec AI Institute",
    "Dubai Police",
    "University of Melbourne",
    "Halmstad University",
    "University of Florida",
    "ELLIS Manchester"
]
```
[12.01.2026 09:34] Deleting PDF ./assets/pdf/2601.05403.pdf.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Downloading and parsing paper https://huggingface.co/papers/2601.04544.
[12.01.2026 09:34] Downloading paper 2601.04544 from https://arxiv.org/pdf/2601.04544v1...
[12.01.2026 09:34] Extracting affiliations from text.
[12.01.2026 09:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"TCAndon-Router 6 2 0 2 8 ] . [ 1 4 4 5 4 0 . 1 0 6 2 : r TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration Jiuzhou Zhao, Chunrong Chen, Chenqi Qiao, Lebin Zheng, Minqi Han, Yanchi Liu Yongzhou Xu Xiaochuan Xu Min Zhang Tencent Cloud Andon {joskazhao, charentchen, chenqiqiao, lebinzheng}@tencent.com {minqihan, yanncyliu, alanxu, xxcxu, alexzmzhang}@tencent.com Abstract Multi-Agent Systems(MAS) have become powerful paradigm for building high performance intelligent applications. Within these systems, the router responsible for determining which expert agents should handle given query plays crucial role in overall performance. Existing routing strategies generally fall into two categories: performance routing, which balances latency and cost across models of different sizes, and task routing, which assigns queries to domain-specific experts to improve accuracy. In real-world enterprise applications, task routing is more suitable; however, most existing approaches rely on static single-label decisions, which introduce two major limitations: (i) diÔ¨Äiculty in seamlessly integrating new agents as business domains expand, and (ii) routing conflicts caused by overlapping agent capabilities, ultimately degrading accuracy and robustness.To address these challenges, we propose TCAndon-Router(TCAR): an adaptive reasoning router for multi-agent collaboration. Unlike traditional routers, TCAR supports dynamic agent onboarding and first generates natural-language reasoning chain before predicting set of candidate agents capable of handling the query. In addition, we design collaborative execution pipeline in which selected agents independently produce responses, which are then aggregated and refined into single high-quality response by dedicated Refining Agent.Experiments on public datasets and real enterprise data demonstrate that TCAR significantly improves routing accuracy, reduces routing conflicts, and remains robust in ambiguous scenarios. We have releas"
[12.01.2026 09:34] Response: ```python
["Tencent Cloud"]
```
[12.01.2026 09:34] Deleting PDF ./assets/pdf/2601.04544.pdf.
[12.01.2026 09:34] Success.
[12.01.2026 09:34] Enriching papers with extra data.
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 0. Large vision-language models are enhanced for image geolocalization by incorporating map-based reasoning and agent-in-the-map loop optimization, achieving superior accuracy compared to existing models.  					AI-generated summary 				 The image geolocalization task aims to predict the location where ...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 1. MMFormalizer enables multimodal autoformalization by integrating visual perception with formal mathematical reasoning, supporting complex physical domains from classical mechanics to quantum mechanics.  					AI-generated summary 				 Autoformalization, which translates natural language mathematics i...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 2. Large language models struggle with long chain-of-thought reasoning due to unstable structural patterns, but a molecular-inspired approach using effective semantic isomers and distribution-transfer-graph methods improves training stability and performance.  					AI-generated summary 				 Large langu...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 3. A citation-aware reward framework and policy optimization method improve deep search agents' reasoning comprehensiveness and factual accuracy while reducing shortcut exploitation and hallucinations.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as a critical technique for e...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 4. A photorealistic 3D caricaturization framework combines Gaussian curvature-based surface exaggeration with 3D Gaussian Splatting to create controllable, realistic avatars with improved fidelity and real-time deformation capabilities.  					AI-generated summary 				 A photorealistic and controllable ...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 5. EnvScaler automates the creation of tool-interaction environments through programmatic synthesis, enhancing LLM performance in complex multi-turn, multi-tool tasks via supervised fine-tuning and reinforcement learning.  					AI-generated summary 				 Large language models (LLMs) are expected to be t...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 6. Autonomous machine learning agents overcome execution bottlenecks by predicting outcomes before physical execution, achieving faster convergence and improved performance through a predict-then-verify approach.  					AI-generated summary 				 Autonomous machine learning agents have revolutionized sci...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 7. VideoAR presents a large-scale visual autoregressive framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling, achieving state-of-the-art results with improved efficiency and temporal consistency.  					AI-generated summary 				 Recent advances in v...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 8. Large language models exhibit brittle beliefs under contextual perturbations, which are better measured by structural consistency metrics and addressed through structure-aware training methods.  					AI-generated summary 				 As Large Language Models (LLMs) are increasingly deployed in real-world se...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 9. The Qwen3-VL-Embedding and Qwen3-VL-Reranker models form an end-to-end multimodal search pipeline, leveraging multi-stage training and cross-attention mechanisms to achieve high-precision retrieval across diverse modalities.  					AI-generated summary 				 In this report, we introduce the Qwen3-VL-E...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 10. AgentOCR reduces token consumption in agentic systems by representing interaction history as visual tokens and employing visual caching and self-compression techniques.  					AI-generated summary 				 Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement l...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 11. Orient Anything V2 enhances 3D orientation understanding through scalable 3D asset synthesis, symmetry-aware periodic distribution fitting, and multi-frame relative rotation prediction, achieving state-of-the-art performance across multiple benchmarks.  					AI-generated summary 				 This work prese...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 12. SmartSearch enhances LLM-based search agents through process rewards and query refinement mechanisms that improve intermediate search query quality via a three-stage curriculum learning approach.  					AI-generated summary 				 Large language model (LLM)-based search agents have proven promising for...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 13. Video generation models trained on synthetic physics primitives demonstrate zero-shot generalization to complex real-world scenarios by modeling force propagation through time and space.  					AI-generated summary 				 Recent advancements in video generation have enabled the development of ``world m...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 14. Generative models' controllability is theoretically analyzed through a framework that estimates controllable sets with distribution-free bounds, revealing that controllability is fragile and context-dependent.  					AI-generated summary 				 As generative models become ubiquitous, there is a critica...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 15. DR-LoRA dynamically adjusts LoRA ranks for experts in Mixture-of-Experts models based on task-specific demands, improving parameter efficiency and performance.  					AI-generated summary 				 Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 16. A lightweight monocular depth estimation framework uses DINOv3 as visual encoder and a compact transformer decoder to achieve higher accuracy with reduced computational overhead and improved data quality.  					AI-generated summary 				 Monocular depth estimation aims to recover the depth informatio...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 17. A framework converts transient critiques into retrievable guidelines using a file-based memory system and agent-controlled tool calls, enabling LLMs to match test-time refinement performance with reduced inference costs.  					AI-generated summary 				 We propose a framework that amortizes the cost ...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 18. Search-augmented large language models suffer from over-searching behavior that wastes computational resources and introduces hallucinations, with findings showing varied impacts across model types and conversation contexts.  					AI-generated summary 				 Search-augmented large language models (LLM...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 19. CompassMem is an event-centric memory framework that organizes experiences into an Event Graph to enable structured memory navigation and long-horizon reasoning beyond traditional retrieval methods.  					AI-generated summary 				 Large language models (LLMs) are increasingly deployed as intelligent...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 20. Latent Policy Optimization via Iterative Information Bottleneck addresses exploration collapse in LLM reasoning by enabling topological branching of reasoning trajectories through information bottleneck principles.  					AI-generated summary 				 Recent advances in Reinforcement Learning with Verifi...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 21. Multimodal auto-completion leverages visual and textual context to improve real-time prediction accuracy in conversational interfaces, with a router framework enabling efficient model selection based on dialog context.  					AI-generated summary 				 Real-time multimodal auto-completion is essential...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 22. A comprehensive benchmark evaluates behavioral biases in large language models for multilingual financial misinformation detection across diverse economic scenarios.  					AI-generated summary 				 Large language models (LLMs) have been widely applied across various domains of finance. Since their t...
[12.01.2026 09:34] ********************************************************************************
[12.01.2026 09:34] Abstract 23. A multi-agent system router that uses dynamic agent onboarding and natural language reasoning chains to improve routing accuracy and reduce conflicts in enterprise applications.  					AI-generated summary 				 Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance int...
[12.01.2026 09:34] Read previous papers.
[12.01.2026 09:34] Generating reviews via LLM API.
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#agents", "#cv", "#dataset", "#multimodal", "#rl", "#open_source", "#reasoning"], "emoji": "üó∫Ô∏è", "ru": {"title": "–ö–∞—Ä—Ç—ã –∫–∞–∫ –∫–æ–º–ø–∞—Å: –Ω–∞—É—á–∏–º AI –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–µ–±—è –Ω–∞ –ø–ª–∞–Ω–µ—Ç–µ", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#math", "#dataset", "#benchmark", "#reasoning", "#science", "#multimodal"], "emoji": "üî¨", "ru": {"title": "–í–æ—Å–ø—Ä–∏—è—Ç–∏–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞: –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∏–∑–∏–∫–∏ –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏", "desc": "MMFormalizer ‚Äî —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –∞–≤—Ç–æ—Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#optimization", "#training"], "emoji": "üß¨", "ru": {"title": "–ú–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ —Ü–µ–ø–æ—á–µ–∫ –¥–ª–∏–Ω–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ LLM", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª–∏–Ω–Ω—ã–º —Ü–µ–ø–æ—á–∫–∞–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ —Ö–∞—Ä–∞
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#optimization", "#hallucinations", "#rl", "#training", "#open_source", "#reasoning"], "emoji": "üîó", "ru": {"title": "–ù–∞–≥—Ä–∞–¥—ã —Å –æ—Å–æ–∑–Ω–∞–Ω–∏–µ–º —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–≥—Ä–∞–¥ Citation-aware Rubric Rewards (CaR
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#multimodal", "#3d"], "emoji": "ü§™", "ru": {"title": "–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ 3D-–∫–∞—Ä–∏–∫–∞—Ç—É—Ä—ã —á–µ—Ä–µ–∑ –≥–∞—É—Å—Å–æ–≤—ã —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫—Ä–∏–≤–∏–∑–Ω–æ–π", "desc": "–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —à–∞—Ä–∂–µ–π –ª–∏—Ü –Ω–∞ –æ—Å–Ω–æ–≤–µ 3D-–º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—Ä–∏–≤–∏–∑–Ω—É –ì–∞—É—Å—Å–∞ –¥–ª—è –ø—Ä–µ—É–≤–µ–ª–∏—á–µ–Ω–∏—è —á–µ—Ä
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#rl", "#dataset", "#agents", "#training"], "emoji": "üèóÔ∏è", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å–∏–Ω—Ç–µ–∑–∞ –æ–∫—Ä—É–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM", "desc": "EnvScaler ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ä–µ–¥ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ —Å –ø–æ–º–æ—â—å—é —Å–∏–Ω—Ç–µ–∑–∞ –ø—Ä–æ–≥—Ä–∞–º–º. –°–∏—Å—Ç–µ–º–∞
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#dataset", "#open_source", "#science"], "emoji": "üîÆ", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø—Ä–µ–∂–¥–µ, —á–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç—å: —É—Å–∫–æ—Ä–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", "desc": "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞–¥–∞—é—Ç –æ—Ç —É–∑–∫–æ–≥–æ –º–µ—Å—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –∫–æ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#architecture", "#benchmark", "#video", "#training"], "emoji": "üé¨", "ru": {"title": "–ê–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –≤–∏–¥–µ–æ: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∏—Ñ—Ñ—É–∑–∏–∏ –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "VideoAR –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–≤—É—é –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—É—é –∞–≤—Ç–∞—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–∞—è –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –º–Ω–æ–≥
[12.01.2026 09:34] Using data from previous issue: {"categories": [], "emoji": "üèóÔ∏è", "ru": {"title": "–£–∫—Ä–µ–ø–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–π –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ —É–±–µ–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø–æ–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —Ö—Ä—É–ø–∫–∏–µ —É–±–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–ª–æ—Ö–æ –∏–∑–º–µ—Ä—è—é—Ç—Å—è —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤—Ä–æ–¥–µ Self-Consistency. 
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#multilingual", "#benchmark", "#rag", "#open_source", "#training", "#architecture", "#multimodal"], "emoji": "üîç", "ru": {"title": "–ï–¥–∏–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –º–æ–¥–µ–ª–∏ Qwen3-VL-Embedding –∏ Qwen3-VL-Reranker, –∫–æ—Ç–æ—Ä—ã–µ —Ñ–æ—Ä–º–∏—Ä—É—é—Ç –ø–æ
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#cv", "#agents", "#inference", "#rl"], "emoji": "üñºÔ∏è", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö", "desc": "AgentOCR ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–Ω–∏–∂–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –∏—Å—Ç–æ—Ä–∏—é –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –≤–∏–∑—É–∞–ª—å
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#dataset", "#3d", "#multimodal", "#synthetic", "#open_source"], "emoji": "üîÑ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ–π –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ —Å —É—á—ë—Ç–æ–º —Å–∏–º–º–µ—Ç—Ä–∏–∏", "desc": "Orient Anything V2 ‚Äî —ç—Ç–æ —É–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#open_source"], "emoji": "üîç", "ru": {"title": "–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –ø—Ä–æ—Ü–µ—Å—Å–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤", "desc": "SmartSearch ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è LLM-based –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–π —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#robotics", "#dataset", "#synthetic", "#video", "#training", "#open_source"], "emoji": "üé¨", "ru": {"title": "–û—Ç –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–∫–æ–Ω–æ–≤ —Ñ–∏–∑–∏–∫–∏ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é —Å–ª–æ–∂–Ω–æ–≥–æ –º–∏—Ä–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ Goal Force ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–∏–¥–µ–æ-–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ —è–≤–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä
[12.01.2026 09:34] Using data from previous issue: {"categories": [], "emoji": "üéÆ", "ru": {"title": "–£–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: –æ—Ç –∏–ª–ª—é–∑–∏–∏ –∫–æ–Ω—Ç—Ä–æ–ª—è –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –µ–≥–æ –≥—Ä–∞–Ω–∏—Ü", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä–∞—è –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–æ—Å—Ç–∏–∂–∏–º—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#architecture", "#training"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ä–∞–Ω–≥–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ DR-LoRA –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–Ω–≥–æ–≤ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ LoRA –≤ –º–æ–¥–µ–ª—è—Ö Mixture-of-Experts –≤–æ –≤—Ä–µ–º—è f
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#small_models", "#3d", "#training", "#data", "#architecture", "#cv"], "emoji": "üéØ", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≥–ª—É–±–∏–Ω—ã —á–µ—Ä–µ–∑ –±–∞–ª–∞–Ω—Å –¥–∏–∑–∞–π–Ω–∞ –º–æ–¥–µ–ª–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –ª—ë–≥–∫–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–æ–Ω–æ–∫—É–ª—è—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –≥–ª—É–±–∏–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π DINOv3 –≤ –∫–∞—á–µ
[12.01.2026 09:34] Using data from previous issue: {"categories": [], "emoji": "üíæ", "ru": {"title": "–ò–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–∏—Ç–∏–∫–∏ –≤ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è: —ç–∫–æ–Ω–æ–º–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–∏–∫–∏ –≤ —Å–æ—Ö—Ä–∞–Ω—è–µ–º—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#rag", "#benchmark", "#hallucinations", "#optimization"], "emoji": "üîç", "ru": {"title": "–ö–æ–≥–¥–∞ –ø–æ–∏—Å–∫ –≤—Ä–µ–¥–∏—Ç: –∫–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å —á—Ä–µ–∑–º–µ—Ä–Ω—ã—Ö –æ–±—Ä–∞—â–µ–Ω–∏–π –≤ –ø–æ–∏—Å–∫-–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö LLM", "desc": "–í —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ —á—Ä–µ–∑–º–µ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ–º –ø–æ–∏—Å–∫–æ–º, –∫–æ–≥–¥–∞ 
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#long_context", "#reasoning", "#graphs"], "emoji": "üß≠", "ru": {"title": "–ì—Ä–∞—Ñ —Å–æ–±—ã—Ç–∏–π –∫–∞–∫ –ª–æ–≥–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞ –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤", "desc": "CompassMem ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø–∞–º—è—Ç–∏, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Å–æ–±—ã—Ç–∏—è, –∫–æ—Ç–æ—Ä—ã–π –æ—Ä–≥–∞–Ω–∏–∑—É–µ—Ç –æ–ø—ã—Ç –∞–≥–µ–Ω—Ç–∞ –≤ –≤–∏–¥–µ –≥—Ä–∞—Ñ–∞ —Å–æ–±—ã—Ç–∏–π —Å —è–≤–Ω—ã–º–∏ –ª–æ–≥
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#optimization", "#math", "#rl", "#training", "#reasoning"], "emoji": "üåø", "ru": {"title": "–í–µ—Ç–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —É–∑–∫–æ–µ –º–µ—Å—Ç–æ", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ IIB-LPO –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –∫–æ–ª–ª–∞–ø—Å–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Ä–µ—à
[12.01.2026 09:34] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#multimodal"], "emoji": "üí¨", "ru": {"title": "–£–º–Ω–æ–µ –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è (MAC), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã –≤ —á–∞—Ç
[12.01.2026 09:34] Querying the API.
[12.01.2026 09:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A comprehensive benchmark evaluates behavioral biases in large language models for multilingual financial misinformation detection across diverse economic scenarios.  					AI-generated summary 				 Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (\mfmd). In this work, we propose \mfmdscen, a comprehensive benchmark for evaluating behavioral biases of LLMs in \mfmd across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, \mfmdscen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models. This project will be available at https://github.com/lzw108/FMD.
[12.01.2026 09:34] Response: ```json
{
  "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥—É–±–µ–∂–¥–µ–Ω–∏–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Å–æ–∑–¥–∞–ª–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–æ–ª–µ–π, –ª–∏—á–Ω–æ—Å—Ç–µ–π, –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤, —ç—Ç–Ω–∏—á–µ—Å–∫–∏—Ö –∏ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫, —á—Ç–æ–±—ã –æ—Ü–µ–Ω–∏—Ç—å, –∫–∞–∫ LLM –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å–ª–æ–∂–Ω—ã—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö. –ü–æ—Å—Ç—Ä–æ–µ–Ω –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –∫–∏—Ç–∞–π—Å–∫–æ–º, –≥—Ä–µ—á–µ—Å–∫–æ–º –∏ –±–µ–Ω–≥–∞–ª—å—Å–∫–æ–º —è–∑—ã–∫–∞—Ö –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ 22 –æ—Å–Ω–æ–≤–Ω—ã–µ LLM. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ —Å–º–µ—â–µ–Ω–∏—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–∞–∫ –≤ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö, —Ç–∞–∫ –∏ –≤ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª—è—Ö, —á—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∏—Å–∫ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.",
  "emoji": "üí∞",
  "title": "–í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–µ–¥—É–±–µ–∂–¥–µ–Ω–∏–π LLM –≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
}
```
[12.01.2026 09:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A comprehensive benchmark evaluates behavioral biases in large language models for multilingual financial misinformation detection across diverse economic scenarios.  					AI-generated summary 				 Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (\mfmd). In this work, we propose \mfmdscen, a comprehensive benchmark for evaluating behavioral biases of LLMs in \mfmd across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, \mfmdscen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models. This project will be available at https://github.com/lzw108/FMD."

[12.01.2026 09:34] Response: ```python
["BENCHMARK", "DATASET", "MULTILINGUAL"]
```
[12.01.2026 09:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A comprehensive benchmark evaluates behavioral biases in large language models for multilingual financial misinformation detection across diverse economic scenarios.  					AI-generated summary 				 Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (\mfmd). In this work, we propose \mfmdscen, a comprehensive benchmark for evaluating behavioral biases of LLMs in \mfmd across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, \mfmdscen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models. This project will be available at https://github.com/lzw108/FMD."

[12.01.2026 09:34] Response: ```python
['ETHICS', 'SURVEY', 'OPEN_SOURCE', 'LOW_RESOURCE']
```
[12.01.2026 09:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a benchmark called \\textit{mfmdscen} to assess behavioral biases in large language models (LLMs) when detecting multilingual financial misinformation. The benchmark is designed to reflect complex real-world financial scenarios, incorporating factors like roles, regions, ethnicity, and religious beliefs. By evaluating 22 mainstream LLMs using this benchmark, the study highlights the persistence of behavioral biases in both commercial and open-source models. The findings emphasize the need for more nuanced approaches in training and deploying LLMs in high-stakes financial contexts.","title":"Unveiling Biases in Language Models for Financial Misinformation Detection"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a benchmark called \textit{mfmdscen} to assess behavioral biases in large language models (LLMs) when detecting multilingual financial misinformation. The benchmark is designed to reflect complex real-world financial scenarios, incorporating factors like roles, regions, ethnicity, and religious beliefs. By evaluating 22 mainstream LLMs using this benchmark, the study highlights the persistence of behavioral biases in both commercial and open-source models. The findings emphasize the need for more nuanced approaches in training and deploying LLMs in high-stakes financial contexts.', title='Unveiling Biases in Language Models for Financial Misinformation Detection'))
[12.01.2026 09:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂü∫ÂáÜÊµãËØïÔºåÊó®Âú®ËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Â§öËØ≠Ë®ÄÈáëËûçËôöÂÅá‰ø°ÊÅØÊ£ÄÊµã‰∏≠ÁöÑË°å‰∏∫ÂÅèÂ∑Æ„ÄÇÁî±‰∫éLLMsÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰∏ªË¶ÅÊù•Ê∫ê‰∫é‰∫∫Á±ªÂàõ‰ΩúÁöÑÊñáÊú¨ÔºåÂÆÉ‰ª¨ÂèØËÉΩ‰ºöÁªßÊâøÂêÑÁßç‰∫∫Á±ªÂÅèËßÅÔºåËøôÂèØËÉΩÂØºËá¥Âú®Â§ÑÁêÜÈáëËûç‰ø°ÊÅØÊó∂ÂÜ≥Á≠ñÁöÑ‰∏çÁ®≥ÂÆöÊÄßÂíå‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏âÁßçÂ§çÊùÇÁöÑÈáëËûçÂú∫ÊôØÔºåÂπ∂ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Ê∂µÁõñÂ§öÁßçËØ≠Ë®ÄÁöÑÈáëËûçËôöÂÅá‰ø°ÊÅØÊï∞ÊçÆÈõÜÔºå‰ª•‰æøÁ≥ªÁªüÂú∞ËØÑ‰º∞22Áßç‰∏ªÊµÅLLMsÁöÑË°®Áé∞„ÄÇÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÊó†ËÆ∫ÊòØÂïÜ‰∏öÊ®°ÂûãËøòÊòØÂºÄÊ∫êÊ®°ÂûãÔºåÊòéÊòæÁöÑË°å‰∏∫ÂÅèÂ∑ÆÂú®ÂêÑÁ±ªÊ®°Âûã‰∏≠ÊôÆÈÅçÂ≠òÂú®„ÄÇ","title":"ËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈáëËûçÂÅèÂ∑Æ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂü∫ÂáÜÊµãËØïÔºåÊó®Âú®ËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Â§öËØ≠Ë®ÄÈáëËûçËôöÂÅá‰ø°ÊÅØÊ£ÄÊµã‰∏≠ÁöÑË°å‰∏∫ÂÅèÂ∑Æ„ÄÇÁî±‰∫éLLMsÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰∏ªË¶ÅÊù•Ê∫ê‰∫é‰∫∫Á±ªÂàõ‰ΩúÁöÑÊñáÊú¨ÔºåÂÆÉ‰ª¨ÂèØËÉΩ‰ºöÁªßÊâøÂêÑÁßç‰∫∫Á±ªÂÅèËßÅÔºåËøôÂèØËÉΩÂØºËá¥Âú®Â§ÑÁêÜÈáëËûç‰ø°ÊÅØÊó∂ÂÜ≥Á≠ñÁöÑ‰∏çÁ®≥ÂÆöÊÄßÂíå‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏âÁßçÂ§çÊùÇÁöÑÈáëËûçÂú∫ÊôØÔºåÂπ∂ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Ê∂µÁõñÂ§öÁßçËØ≠Ë®ÄÁöÑÈáëËûçËôöÂÅá‰ø°ÊÅØÊï∞ÊçÆÈõÜÔºå‰ª•‰æøÁ≥ªÁªüÂú∞ËØÑ‰º∞22Áßç‰∏ªÊµÅLLMsÁöÑË°®Áé∞„ÄÇÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÊó†ËÆ∫ÊòØÂïÜ‰∏öÊ®°ÂûãËøòÊòØÂºÄÊ∫êÊ®°ÂûãÔºåÊòéÊòæÁöÑË°å‰∏∫ÂÅèÂ∑ÆÂú®ÂêÑÁ±ªÊ®°Âûã‰∏≠ÊôÆÈÅçÂ≠òÂú®„ÄÇ', title='ËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈáëËûçÂÅèÂ∑Æ'))
[12.01.2026 09:35] Querying the API.
[12.01.2026 09:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A multi-agent system router that uses dynamic agent onboarding and natural language reasoning chains to improve routing accuracy and reduce conflicts in enterprise applications.  					AI-generated summary 				 Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance intelligent applications. Within these systems, the router responsible for determining which expert agents should handle a given query plays a crucial role in overall performance. Existing routing strategies generally fall into two categories: performance routing, which balances latency and cost across models of different sizes, and task routing, which assigns queries to domain-specific experts to improve accuracy. In real-world enterprise applications, task routing is more suitable; however, most existing approaches rely on static single-label decisions, which introduce two major limitations: (i) difficulty in seamlessly integrating new agents as business domains expand, and (ii) routing conflicts caused by overlapping agent capabilities, ultimately degrading accuracy and robustness.To address these challenges, we propose TCAndon-Router(TCAR): an adaptive reasoning router for multi-agent collaboration. Unlike traditional routers, TCAR supports dynamic agent onboarding and first generates a natural-language reasoning chain before predicting a set of candidate agents capable of handling the query. In addition, we design a collaborative execution pipeline in which selected agents independently produce responses, which are then aggregated and refined into a single high-quality response by a dedicated Refining Agent.Experiments on public datasets and real enterprise data demonstrate that TCAR significantly improves routing accuracy, reduces routing conflicts, and remains robust in ambiguous scenarios. We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research on explainable and collaborative multi-agent routing.
[12.01.2026 09:35] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º TCAR, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤. –°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–±–æ—Ä–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ TCAR –≤–∫–ª—é—á–∞–µ—Ç —Å–æ–≤–º–µ—Å—Ç–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –≥–¥–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç –æ—Ç–≤–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—Ç–µ–º –∞–≥—Ä–µ–≥–∏—Ä—É—é—Ç—Å—è –∏ —É—Ç–æ—á–Ω—è—é—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –∞–≥–µ–Ω—Ç–æ–º. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ø–æ–¥—Ö–æ–¥ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏, —Å–Ω–∏–∂–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∏ –æ—Å—Ç–∞—ë—Ç—Å—è –Ω–∞–¥—ë–∂–Ω—ã–º –≤ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö.",
  "emoji": "üö¶",
  "title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —Å –ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ –¥–ª—è –≥–∏–±–∫–∏—Ö –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º"
}
```
[12.01.2026 09:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A multi-agent system router that uses dynamic agent onboarding and natural language reasoning chains to improve routing accuracy and reduce conflicts in enterprise applications.  					AI-generated summary 				 Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance intelligent applications. Within these systems, the router responsible for determining which expert agents should handle a given query plays a crucial role in overall performance. Existing routing strategies generally fall into two categories: performance routing, which balances latency and cost across models of different sizes, and task routing, which assigns queries to domain-specific experts to improve accuracy. In real-world enterprise applications, task routing is more suitable; however, most existing approaches rely on static single-label decisions, which introduce two major limitations: (i) difficulty in seamlessly integrating new agents as business domains expand, and (ii) routing conflicts caused by overlapping agent capabilities, ultimately degrading accuracy and robustness.To address these challenges, we propose TCAndon-Router(TCAR): an adaptive reasoning router for multi-agent collaboration. Unlike traditional routers, TCAR supports dynamic agent onboarding and first generates a natural-language reasoning chain before predicting a set of candidate agents capable of handling the query. In addition, we design a collaborative execution pipeline in which selected agents independently produce responses, which are then aggregated and refined into a single high-quality response by a dedicated Refining Agent.Experiments on public datasets and real enterprise data demonstrate that TCAR significantly improves routing accuracy, reduces routing conflicts, and remains robust in ambiguous scenarios. We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research on explainable and collaborative multi-agent routing."

[12.01.2026 09:35] Response: ```python
["AGENTS"]
```
[12.01.2026 09:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A multi-agent system router that uses dynamic agent onboarding and natural language reasoning chains to improve routing accuracy and reduce conflicts in enterprise applications.  					AI-generated summary 				 Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance intelligent applications. Within these systems, the router responsible for determining which expert agents should handle a given query plays a crucial role in overall performance. Existing routing strategies generally fall into two categories: performance routing, which balances latency and cost across models of different sizes, and task routing, which assigns queries to domain-specific experts to improve accuracy. In real-world enterprise applications, task routing is more suitable; however, most existing approaches rely on static single-label decisions, which introduce two major limitations: (i) difficulty in seamlessly integrating new agents as business domains expand, and (ii) routing conflicts caused by overlapping agent capabilities, ultimately degrading accuracy and robustness.To address these challenges, we propose TCAndon-Router(TCAR): an adaptive reasoning router for multi-agent collaboration. Unlike traditional routers, TCAR supports dynamic agent onboarding and first generates a natural-language reasoning chain before predicting a set of candidate agents capable of handling the query. In addition, we design a collaborative execution pipeline in which selected agents independently produce responses, which are then aggregated and refined into a single high-quality response by a dedicated Refining Agent.Experiments on public datasets and real enterprise data demonstrate that TCAR significantly improves routing accuracy, reduces routing conflicts, and remains robust in ambiguous scenarios. We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research on explainable and collaborative multi-agent routing."

[12.01.2026 09:35] Response: ```python
['REASONING', 'OPEN_SOURCE']
```

**Justification:**

1. **REASONING**: The paper explicitly discusses "natural language reasoning chains" as a core component of the routing system. The router "first generates a natural-language reasoning chain before predicting a set of candidate agents," which directly relates to enhancing logical reasoning capabilities.

2. **OPEN_SOURCE**: The paper states "We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research," indicating the authors have released their model/framework publicly to the community.
[12.01.2026 09:35] Error. Failed to parse JSON from LLM. ["REASONING", "OPEN_SOURCE"]


**Justification:**

1. **REASONING**: The paper explicitly discusses "natural language reasoning chains" as a core component of the routing system. The router "first generates a natural-language reasoning chain before predicting a set of candidate agents," which directly relates to enhancing logical reasoning capabilities.

2. **OPEN_SOURCE**: The paper states "We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research," indicating the authors have released their model/framework publicly to the community.
[12.01.2026 09:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents TCAndon-Router (TCAR), a novel multi-agent system router designed to enhance routing accuracy and minimize conflicts in enterprise applications. TCAR introduces dynamic agent onboarding, allowing for the seamless integration of new agents as business needs evolve. It utilizes natural language reasoning chains to identify a set of candidate agents, rather than relying on static single-label decisions, which often lead to routing conflicts. Experimental results show that TCAR outperforms traditional routing methods by improving accuracy and robustness in complex scenarios.","title":"Dynamic Routing for Enhanced Multi-Agent Collaboration"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents TCAndon-Router (TCAR), a novel multi-agent system router designed to enhance routing accuracy and minimize conflicts in enterprise applications. TCAR introduces dynamic agent onboarding, allowing for the seamless integration of new agents as business needs evolve. It utilizes natural language reasoning chains to identify a set of candidate agents, rather than relying on static single-label decisions, which often lead to routing conflicts. Experimental results show that TCAR outperforms traditional routing methods by improving accuracy and robustness in complex scenarios.', title='Dynamic Routing for Enhanced Multi-Agent Collaboration'))
[12.01.2026 09:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫TCAndon-RouterÔºàTCARÔºâÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüË∑ØÁî±Âô®ÔºåÊó®Âú®ÊèêÈ´ò‰ºÅ‰∏öÂ∫îÁî®‰∏≠ÁöÑË∑ØÁî±ÂáÜÁ°ÆÊÄßÂπ∂ÂáèÂ∞ëÂÜ≤Á™Å„ÄÇTCARÊîØÊåÅÂä®ÊÄÅÊô∫ËÉΩ‰ΩìÊé•ÂÖ•ÔºåÂπ∂Âú®È¢ÑÊµãÂÄôÈÄâÊô∫ËÉΩ‰Ωì‰πãÂâçÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÊé®ÁêÜÈìæÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞Â§ÑÁêÜÊü•ËØ¢„ÄÇ‰∏é‰º†ÁªüÁöÑÈùôÊÄÅÂçïÊ†áÁ≠æÂÜ≥Á≠ñÊñπÊ≥ï‰∏çÂêåÔºåTCARËÉΩÂ§üÁÅµÊ¥ªÂ∫îÂØπ‰∏öÂä°È¢ÜÂüüÁöÑÊâ©Â±ïÔºåÈÅøÂÖç‰∫ÜÂõ†Êô∫ËÉΩ‰ΩìËÉΩÂäõÈáçÂè†ËÄåÂØºËá¥ÁöÑË∑ØÁî±ÂÜ≤Á™Å„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTCARÂú®ÂÖ¨ÂÖ±Êï∞ÊçÆÈõÜÂíåÁúüÂÆû‰ºÅ‰∏öÊï∞ÊçÆ‰∏äÊòæËëóÊèêÈ´ò‰∫ÜË∑ØÁî±ÂáÜÁ°ÆÊÄßÔºåÂ¢ûÂº∫‰∫ÜÁ≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ","title":"Âä®ÊÄÅÊô∫ËÉΩ‰ΩìÊé•ÂÖ•ÔºåÊèêÂçáË∑ØÁî±ÂáÜÁ°ÆÊÄßÔºÅ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫TCAndon-RouterÔºàTCARÔºâÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüË∑ØÁî±Âô®ÔºåÊó®Âú®ÊèêÈ´ò‰ºÅ‰∏öÂ∫îÁî®‰∏≠ÁöÑË∑ØÁî±ÂáÜÁ°ÆÊÄßÂπ∂ÂáèÂ∞ëÂÜ≤Á™Å„ÄÇTCARÊîØÊåÅÂä®ÊÄÅÊô∫ËÉΩ‰ΩìÊé•ÂÖ•ÔºåÂπ∂Âú®È¢ÑÊµãÂÄôÈÄâÊô∫ËÉΩ‰Ωì‰πãÂâçÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÊé®ÁêÜÈìæÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞Â§ÑÁêÜÊü•ËØ¢„ÄÇ‰∏é‰º†ÁªüÁöÑÈùôÊÄÅÂçïÊ†áÁ≠æÂÜ≥Á≠ñÊñπÊ≥ï‰∏çÂêåÔºåTCARËÉΩÂ§üÁÅµÊ¥ªÂ∫îÂØπ‰∏öÂä°È¢ÜÂüüÁöÑÊâ©Â±ïÔºåÈÅøÂÖç‰∫ÜÂõ†Êô∫ËÉΩ‰ΩìËÉΩÂäõÈáçÂè†ËÄåÂØºËá¥ÁöÑË∑ØÁî±ÂÜ≤Á™Å„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTCARÂú®ÂÖ¨ÂÖ±Êï∞ÊçÆÈõÜÂíåÁúüÂÆû‰ºÅ‰∏öÊï∞ÊçÆ‰∏äÊòæËëóÊèêÈ´ò‰∫ÜË∑ØÁî±ÂáÜÁ°ÆÊÄßÔºåÂ¢ûÂº∫‰∫ÜÁ≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ', title='Âä®ÊÄÅÊô∫ËÉΩ‰ΩìÊé•ÂÖ•ÔºåÊèêÂçáË∑ØÁî±ÂáÜÁ°ÆÊÄßÔºÅ'))
[12.01.2026 09:35] Renaming data file.
[12.01.2026 09:35] Renaming previous data. hf_papers.json to ./d/2026-01-12.json
[12.01.2026 09:35] Saving new data file.
[12.01.2026 09:35] Generating page.
[12.01.2026 09:35] Renaming previous page.
[12.01.2026 09:35] Renaming previous data. index.html to ./d/2026-01-12.html
[12.01.2026 09:35] Writing result.
[12.01.2026 09:35] Renaming log file.
[12.01.2026 09:35] Renaming previous data. log.txt to ./logs/2026-01-12_last_log.txt
