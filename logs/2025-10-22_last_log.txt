[22.10.2025 10:14] Read previous papers.
[22.10.2025 10:14] Generating top page (month).
[22.10.2025 10:14] Writing top page (month).
[22.10.2025 11:10] Read previous papers.
[22.10.2025 11:10] Get feed.
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18866
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18135
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18701
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16880
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18692
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18876
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18726
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18849
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18855
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17722
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18250
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17519
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18795
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18775
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18873
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17045
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14264
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18554
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18489
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16505
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15600
[22.10.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17928
[22.10.2025 11:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[22.10.2025 11:10] No deleted papers detected.
[22.10.2025 11:10] Downloading and parsing papers (pdf, html). Total: 22.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18866.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18866.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18866.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18135.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18135.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18135.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18701.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18701.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18701.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.16880.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.16880.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.16880.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18692.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18692.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18692.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18876.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18876.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18876.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18726.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18726.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18726.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18849.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18849.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18849.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18855.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18855.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18855.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.17722.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.17722.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.17722.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18250.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18250.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18250.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.17519.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.17519.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.17519.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18795.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18795.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18795.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18775.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18775.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18775.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18873.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18873.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18873.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.17045.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.17045.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.17045.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.14264.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.14264.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.14264.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18554.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18554.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18554.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.18489.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.18489.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.18489.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.16505.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.16505.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.16505.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.15600.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.15600.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.15600.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2510.17928.
[22.10.2025 11:10] Extra JSON file exists (./assets/json/2510.17928.json), skip PDF parsing.
[22.10.2025 11:10] Paper image links file exists (./assets/img_data/2510.17928.json), skip HTML parsing.
[22.10.2025 11:10] Success.
[22.10.2025 11:10] Enriching papers with extra data.
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 0. LightMem, a memory system inspired by human memory, enhances LLMs by efficiently managing historical interaction information, improving accuracy and reducing computational costs.  					AI-generated summary 				 Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effective...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 1. World-in-World evaluates generative world models in closed-loop environments, emphasizing task success over visual quality and revealing insights into controllability, data scaling, and compute allocation.  					AI-generated summary 				 Generative world models (WMs) can now simulate worlds with str...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 2. UniGenBench++ is a comprehensive benchmark for text-to-image generation that evaluates semantic consistency across diverse scenarios and languages using a hierarchical prompt structure and a robust evaluation pipeline.  					AI-generated summary 				 Recent progress in text-to-image (T2I) generation...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 3. Chem-R, a three-phase trained Chemical Reasoning model, achieves superior performance on chemical tasks by integrating core knowledge, expert reasoning, and multi-task optimization.  					AI-generated summary 				 Although large language models (LLMs) have significant potential to advance chemical d...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 4. Mixture-of-Groups Attention (MoGA) enables efficient long video generation by addressing the quadratic scaling issue of full attention in Diffusion Transformers.  					AI-generated summary 				 Long video generation with Diffusion Transformers (DiTs) is bottlenecked by the quadratic scaling of full ...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 5. Grasp Any Region (GAR) enhances region-level visual understanding by integrating global contexts and modeling interactions, achieving advanced reasoning and outperforming existing models in captioning and video reference tasks.  					AI-generated summary 				 While Multimodal Large Language Models (...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 6. A new benchmark, IF-VidCap, evaluates video captioning models on instruction-following capabilities, revealing that top-tier open-source models are closing the performance gap with proprietary models.  					AI-generated summary 				 Although Multimodal Large Language Models (MLLMs) have demonstrated...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 7. A Critique-Post-Edit framework enhances personalization of large language models by integrating a multi-dimensional reward model and a self-revision mechanism, outperforming standard methods.  					AI-generated summary 				 Faithfully personalizing large language models (LLMs) to align with individu...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 8. Ring-1T, a trillion-parameter open-source thinking model, addresses training challenges with IcePop, C3PO++, and ASystem, achieving top results across benchmarks and democratizing large-scale reasoning intelligence.  					AI-generated summary 				 We present Ring-1T, the first open-source, state-of-...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 9. MT-Video-Bench evaluates MLLMs in multi-turn video dialogues, assessing perceptivity and interactivity across diverse domains.  					AI-generated summary 				 The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. H...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 10. ssToken, a self-modulated and semantic-aware token selection approach, enhances supervised fine-tuning of large language models by adaptively selecting tokens and providing complementary semantic information, outperforming existing methods.  					AI-generated summary 				 Data quality plays a critic...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 11. A training framework for large-scale video generation models optimizes data processing, model architecture, training strategy, and infrastructure, resulting in a model that matches state-of-the-art performance and is open-sourced with Megatron-Core-based training code.  					AI-generated summary 			...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 12. ProCLIP enhances CLIP's text processing capabilities by aligning its image encoder with an LLM-based embedder through curriculum learning and contrastive tuning, preserving CLIP's pretrained knowledge.  					AI-generated summary 				 The original CLIP text encoder is limited by a maximum input lengt...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 13. UltraGen, a novel video generation framework, enables efficient high-resolution video synthesis using a hierarchical dual-branch attention architecture and spatially compressed global modeling.  					AI-generated summary 				 Recent advances in video generation have made it possible to produce visua...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 14. DSI-Bench evaluates the dynamic spatial reasoning capabilities of vision-language and visual expertise models through a benchmark of dynamic videos and annotated questions, highlighting their limitations in understanding self-motion, object motion, and relative relationships.  					AI-generated summ...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 15. The paper proposes V-Reason, a method that tunes the behavior of Large Multimodal Models during inference using entropy-based optimization, improving video reasoning accuracy and efficiency without reinforcement learning or supervised fine-tuning.  					AI-generated summary 				 Video reasoning usin...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 16. AlphaQuanter, a single-agent framework using reinforcement learning, achieves top performance in automated trading by learning dynamic policies and proactively acquiring information.  					AI-generated summary 				 While Large Language Model (LLM) agents show promise in automated trading, they still...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 17. Extracting alignment training data from post-trained models using embedding models reveals significant semantic similarities and potential risks in distillation practices.  					AI-generated summary 				 In this work, we show that it is possible to extract significant amounts of alignment training d...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 18. A system for reconstructing 4D HDR scenes from unposed LDR videos using Gaussian Splatting with two-stage optimization and temporal luminance regularization.  					AI-generated summary 				 We introduce Mono4DGS-HDR, the first system for reconstructing renderable 4D high dynamic range (HDR) scenes f...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 19. PRISMM-Bench evaluates the ability of large multimodal models to detect, correct, and reason over inconsistencies in scientific papers, revealing significant challenges in multimodal scientific reasoning.  					AI-generated summary 				 Large Multimodal Models (LMMs) are increasingly applied to scie...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 20. Thoth, a large language model trained with the Sketch-and-Fill paradigm and structured component-based reward mechanism, generates more reliable and executable scientific protocols compared to existing models.  					AI-generated summary 				 The foundation of reproducible science lies in protocols t...
[22.10.2025 11:10] ********************************************************************************
[22.10.2025 11:10] Abstract 21. An evolutionary framework synthesizes verifiable data for language models, improving reinforcement learning and distillation across various tasks.  					AI-generated summary 				 Reliable verifiable data has become a key driver of capability gains in modern language models, enabling stable reinforce...
[22.10.2025 11:10] Read previous papers.
[22.10.2025 11:10] Generating reviews via LLM API.
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#data", "#training", "#long_context"], "emoji": "🧠", "ru": {"title": "Человеческая память для AI: быстрее, точнее, эффективнее", "desc": "LightMem — это система памяти для LLM, вдохновлённая моделью человеческой памяти Аткинсона-Шиффрина. Система ор
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#games", "#benchmark", "#optimization", "#dataset", "#agents"], "emoji": "🌍", "ru": {"title": "Когда красивая картинка не помогает роботу: важна управляемость, а не визуальное качество", "desc": "Исследователи создали платформу World-in-World для оценки генеративных world models в з
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#science", "#multilingual", "#multimodal", "#benchmark", "#survey"], "emoji": "🎨", "ru": {"title": "Всесторонняя оценка генерации изображений по тексту", "desc": "UniGenBench++ — это комплексный бенчмарк для оценки text-to-image генерации, который проверяет семантическую согласованн
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#dataset", "#science", "#reasoning", "#architecture", "#benchmark", "#optimization", "#interpretability", "#training"], "emoji": "⚗️", "ru": {"title": "Chem-R: LLM, которая рассуждает как химик", "desc": "Chem-R - это модель для химического рассуждения, обученная в три этапа для реш
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#video", "#architecture", "#diffusion", "#training", "#long_context"], "emoji": "🎬", "ru": {"title": "Умное внимание для длинных видео", "desc": "Статья представляет Mixture-of-Groups Attention (MoGA) — новый механизм внимания для эффективной генерации длинных видео с помощью Diffus
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#games", "#benchmark", "#cv"], "emoji": "🔍", "ru": {"title": "Понимание любых регионов изображения с учётом глобального контекста", "desc": "Статья представляет модель GAR (Grasp Any Region), которая улучшает понимание отдельных регионов на изображениях,
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#benchmark", "#video"], "emoji": "🎬", "ru": {"title": "Следование инструкциям важнее полноты описания видео", "desc": "Исследователи представили новый бенчмарк IF-VidCap для оценки способности моделей генерировать описания видео согласно конкретным инс
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#alignment", "#rlhf", "#training"], "emoji": "✍️", "ru": {"title": "Критика и редактирование: новый путь к персонализации LLM", "desc": "Статья представляет фреймворк Critique-Post-Edit для улучшения персонализации больших языковых моделей под индивидуальные предпочтения пользовател
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#agi", "#reasoning", "#architecture", "#benchmark", "#optimization", "#training", "#open_source"], "emoji": "🧠", "ru": {"title": "Триллион параметров для всех: демократизация мощного AI-мышления", "desc": "Ring-1T — это первая открытая thinking-модель с триллионом параметров, котора
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#multimodal", "#science", "#video", "#benchmark", "#open_source"], "emoji": "🎬", "ru": {"title": "Многоходовые диалоги: новый рубеж в понимании видео для AI", "desc": "Статья представляет MT-Video-Bench — новый бенчмарк для оценки мультимодальных языковых моделей (MLLM) в многоходов
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#training", "#data", "#optimization"], "emoji": "🎯", "ru": {"title": "Умный выбор токенов: самомодуляция и семантика для эффективного fine-tuning LLM", "desc": "Статья представляет ssToken - новый подход к выбору токенов для supervised fine-tuning больших языковых моделей. Метод исп
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#video", "#architecture", "#data", "#training", "#optimization", "#open_source"], "emoji": "🎬", "ru": {"title": "Эффективное обучение огромных моделей для генерации видео", "desc": "Исследователи представили комплексный фреймворк для обучения больших моделей генерации видео, оптимиз
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#dataset", "#alignment", "#training", "#multimodal", "#long_context"], "emoji": "🎓", "ru": {"title": "Постепенное выравнивание CLIP с LLM через curriculum learning", "desc": "ProCLIP улучшает текстовые возможности модели CLIP, заменяя её текстовый энкодер на эмбеддер на основе LLM д
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#video", "#games", "#optimization", "#architecture", "#diffusion"], "emoji": "🎬", "ru": {"title": "Нативная генерация видео в 4K через разделение внимания", "desc": "UltraGen - это новый фреймворк для генерации видео, который впервые позволяет эффективно создавать видео в высоком ра
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#cv", "#reasoning", "#benchmark", "#3d"], "emoji": "🎥", "ru": {"title": "Когда AI теряется в движении: тест на понимание динамического пространства", "desc": "Статья представляет DSI-Bench — бенчмарк для оценки пространственного мышления AI-моделей в динамических сценариях. Датасет 
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#reasoning", "#video", "#training", "#multimodal", "#inference", "#optimization"], "emoji": "🎯", "ru": {"title": "Управление рассуждениями через энтропию без обучения", "desc": "Статья представляет V-Reason — метод улучшения рассуждений Large Multimodal Models над видео через оптими
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#games", "#optimization", "#open_source", "#rl", "#training", "#agents", "#interpretability"], "emoji": "📈", "ru": {"title": "Один умный агент вместо хаоса: RL-трейдер с прозрачной логикой", "desc": "AlphaQuanter — это фреймворк для автоматизированной торговли на основе единого AI-а
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#hallucinations", "#rlhf", "#long_context", "#training", "#alignment", "#data"], "emoji": "🔓", "ru": {"title": "Извлечение данных выравнивания через эмбеддинги: скрытые риски дистилляции", "desc": "Исследователи показали, что из пост-обученных моделей можно извлечь значительные объё
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#3d", "#benchmark", "#cv"], "emoji": "🎥", "ru": {"title": "Реконструкция 4D HDR сцен из LDR видео без поз камеры", "desc": "В статье представлена система Mono4DGS-HDR для реконструкции 4D HDR сцен из неупорядоченных LDR видео. Используется двухэтапная оптимизация на основе Gaussian 
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#reasoning", "#science"], "emoji": "🔬", "ru": {"title": "Проверка AI на понимание несоответствий в научных статьях", "desc": "Исследователи создали бенчмарк PRISMM-Bench для оценки способности больших мультимодальных моделей находить и исправлять противо
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#dataset", "#training", "#open_source", "#optimization", "#data", "#science", "#benchmark", "#agents"], "emoji": "🧪", "ru": {"title": "Научные протоколы от идеи до эксперимента", "desc": "Исследователи представили Thoth — большую языковую модель для генерации воспроизводимых научных
[22.10.2025 11:10] Using data from previous issue: {"categories": ["#hallucinations", "#synthetic", "#training", "#reinforcement_learning", "#agents", "#data", "#dataset", "#rl"], "emoji": "🧬", "ru": {"title": "Эволюционный синтез проверяемых данных для обучения языковых моделей", "desc": "Исследователи предложили эволюционный фреймворк для синтеза 
[22.10.2025 11:10] Renaming data file.
[22.10.2025 11:10] Renaming previous data. hf_papers.json to ./d/2025-10-22.json
[22.10.2025 11:10] Saving new data file.
[22.10.2025 11:10] Generating page.
[22.10.2025 11:10] Renaming previous page.
[22.10.2025 11:10] Renaming previous data. index.html to ./d/2025-10-22.html
[22.10.2025 11:10] Writing result.
[22.10.2025 11:10] Renaming log file.
[22.10.2025 11:10] Renaming previous data. log.txt to ./logs/2025-10-22_last_log.txt
