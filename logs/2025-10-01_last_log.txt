[01.10.2025 07:13] Read previous papers.
[01.10.2025 07:13] Generating top page (month).
[01.10.2025 07:13] Writing top page (month).
[01.10.2025 08:16] Read previous papers.
[01.10.2025 08:16] Get feed.
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25541
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25760
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26536
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25154
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25182
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24002
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25758
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26625
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26490
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26488
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26231
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26391
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23610
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25911
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.22646
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26628
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26495
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26618
[01.10.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2509.26603
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24207
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26539
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26476
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25848
[01.10.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2509.25397
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25189
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.22613
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23166
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26329
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25339
[01.10.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2509.26645
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26574
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26542
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23773
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26555
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25134
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25082
[01.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24732
[01.10.2025 08:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[01.10.2025 08:16] No deleted papers detected.
[01.10.2025 08:16] Downloading and parsing papers (pdf, html). Total: 37.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25541.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25541.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25541.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25760.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25760.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25760.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26536.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26536.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26536.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25154.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25154.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25154.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25182.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25182.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25182.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.24002.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.24002.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.24002.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25758.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25758.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25758.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26625.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26625.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26625.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26490.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26490.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26490.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26488.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26488.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26488.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26231.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26231.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26231.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26391.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26391.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26391.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.23610.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.23610.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.23610.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25911.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25911.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25911.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.22646.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.22646.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.22646.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26628.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26628.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26628.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26495.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26495.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26495.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26618.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26618.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26618.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26603.
[01.10.2025 08:16] Downloading paper 2509.26603 from http://arxiv.org/pdf/2509.26603v1...
[01.10.2025 08:16] Extracting affiliations from text.
[01.10.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 3 ] . [ 1 3 0 6 6 2 . 9 0 5 2 : r a DEEPSCIENTIST: ADVANCING FRONTIER-PUSHING SCIENTIFIC FINDINGS PROGRESSIVELY Yixuan Weng*, Minjun Zhu*, Qiujie Xie, Qiyao Sun, Zhen Lin, Sifan Liu, Yue Zhang(cid:66) Engineering School, Westlake University wengsyx@gmail.com; {zhu.minjun,zhangyue}@westlake.edu.cn Project: https://ai-researcher.net Code: https://github.com/ResearAI/DeepScientist "
[01.10.2025 08:16] Response: ```python
["Engineering School, Westlake University"]
```
[01.10.2025 08:16] Deleting PDF ./assets/pdf/2509.26603.pdf.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.24207.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.24207.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.24207.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26539.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26539.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26539.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26476.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26476.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26476.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25848.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25848.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25848.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25397.
[01.10.2025 08:16] Downloading paper 2509.25397 from http://arxiv.org/pdf/2509.25397v1...
[01.10.2025 08:16] Extracting affiliations from text.
[01.10.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 2 ] . [ 1 7 9 3 5 2 . 9 0 5 2 : r CARTOGRAPHY OF OPEN COLLABORATION IN OPEN SOURCE AI: MAPPING PRACTICES, MOTIVATIONS, AND GOVERNANCE IN 14 OPEN LARGE LANGUAGE MODEL PROJECTS Johan Linaker RISE Research Institutes of Sweden Lund, Sweden Jennifer Ding Boundary Object Studio London, UK Cailean Osborne University of Oxford Oxford, UK Ben Burtenshaw Hugging Face Antwerp, Belgium "
[01.10.2025 08:16] Response: ```python
[
    "RISE Research Institutes of Sweden Lund, Sweden",
    "Boundary Object Studio London, UK",
    "University of Oxford Oxford, UK",
    "Hugging Face Antwerp, Belgium"
]
```
[01.10.2025 08:16] Deleting PDF ./assets/pdf/2509.25397.pdf.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25189.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25189.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25189.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.22613.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.22613.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.22613.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.23166.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.23166.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.23166.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26329.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26329.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26329.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25339.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25339.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25339.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26645.
[01.10.2025 08:16] Downloading paper 2509.26645 from http://arxiv.org/pdf/2509.26645v1...
[01.10.2025 08:16] Extracting affiliations from text.
[01.10.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 3 ] . [ 1 5 4 6 6 2 . 9 0 5 2 : r a TTT3R: 3D RECONSTRUCTION AS TEST-TIME TRAINING Xingyu Chen1 Yue Chen1 Yuliang Xiu1 Andreas Geiger2 Anpei Chen1 1Westlake University 2University of Tubingen, Tubingen AI Center Figure 1: Left: CUT3R [81] encodes observations into state (memory) St1, then interacts with new observation Xt and retrieves 3D information by reading out the output token Yt. However, it suffers from the forgetting problem and degrades significantly as the number of input views increases. Right: We treat the state St as fast weight updated via gradient descent, where the learning rate βt and the gradient are predicted by the frozen slow weights. These slow weights are learned from training datasets and act as meta-learner, enabling the fast weight to serve as an associative memory. In addition, TTT3R makes online state updates by balancing the retention of historical information St1 with confidence-aware learning rate βt. "
[01.10.2025 08:16] Response: ```python
["Westlake University", "University of Tubingen, Tubingen AI Center"]
```
[01.10.2025 08:16] Deleting PDF ./assets/pdf/2509.26645.pdf.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26574.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26574.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26574.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26542.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26542.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26542.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.23773.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.23773.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.23773.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.26555.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.26555.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.26555.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25134.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25134.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25134.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.25082.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.25082.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.25082.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.24732.
[01.10.2025 08:16] Extra JSON file exists (./assets/json/2509.24732.json), skip PDF parsing.
[01.10.2025 08:16] Paper image links file exists (./assets/img_data/2509.24732.json), skip HTML parsing.
[01.10.2025 08:16] Success.
[01.10.2025 08:16] Enriching papers with extra data.
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 0. Vision-Zero is a domain-agnostic framework that enhances vision-language models through self-improvement in competitive visual games, using Iterative Self-Play Policy Optimization and achieving state-of-the-art performance without human annotation.  					AI-generated summary 				 Although reinforcem...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 1. TruthRL, a reinforcement learning framework, enhances the truthfulness of large language models by balancing accuracy and abstention, significantly reducing hallucinations and improving performance across benchmarks.  					AI-generated summary 				 While large language models (LLMs) have demonstrate...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 2. OceanGym is a benchmark for underwater embodied agents using Multi-modal Large Language Models to address challenges in perception, planning, and adaptability in harsh ocean environments.  					AI-generated summary 				 We introduce OceanGym, the first comprehensive benchmark for ocean underwater em...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 3. J-Detector, a neural detector with linguistic and LLM-enhanced features, effectively identifies LLM-generated judgments based on scores and candidate content, addressing biases and vulnerabilities in sensitive scenarios.  					AI-generated summary 				 Large Language Model (LLM)-based judgments leve...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 4. DC-VideoGen accelerates video generation by adapting pre-trained diffusion models to a deep compression latent space, reducing inference latency and enabling high-resolution video generation.  					AI-generated summary 				 We introduce DC-VideoGen, a post-training acceleration framework for efficie...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 5. MCPMark is a comprehensive benchmark for evaluating MCP use in real-world workflows, featuring diverse tasks that require richer interactions with the environment, and reveals that current LLMs perform poorly on these tasks.  					AI-generated summary 				 MCP standardizes how LLMs interact with ext...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 6. Post-training techniques like supervised fine-tuning and reinforcement learning lead to the emergence of specialized attention heads that support structured reasoning, with different training regimes affecting their evolution and performance.  					AI-generated summary 				 The remarkable capabiliti...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 7. LLMs develop visual priors during language pre-training, which can be leveraged for vision tasks with minimal additional data, and these priors are composed of separable perception and reasoning components.  					AI-generated summary 				 Large Language Models (LLMs), despite being trained on text a...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 8. VitaBench is a benchmark for evaluating LLM-based agents in complex, real-world interactive tasks using a diverse set of tools and scenarios.  					AI-generated summary 				 As LLM-based agents are increasingly deployed in real-life scenarios, existing benchmarks fail to capture their inherent compl...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 9. dParallel is a method that enhances the parallel decoding of diffusion large language models, significantly reducing decoding steps without compromising performance.  					AI-generated summary 				 Diffusion large language models (dLLMs) have recently drawn considerable attention within the research...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 10. Implicit Multimodal Guidance (IMG) enhances multimodal alignment between diffusion-generated images and prompts without additional data or editing, outperforming existing methods.  					AI-generated summary 				 Ensuring precise multimodal alignment between diffusion-generated images and input promp...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 11. MotionRAG enhances video generation by integrating motion priors from reference videos using a retrieval-augmented framework, improving motion realism with negligible computational overhead.  					AI-generated summary 				 Image-to-video generation has made remarkable progress with the advancements ...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 12. Dolphin, an efficient AVSS method, uses a dual-path lightweight video encoder and a lightweight encoder-decoder separator with global-local attention blocks to achieve high separation quality and significant computational efficiency.  					AI-generated summary 				 Audio-visual speech separation (AV...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 13. Mem-alpha, a reinforcement learning framework, enhances memory management in large language models through interaction and feedback, improving performance and generalization in long-term information understanding.  					AI-generated summary 				 Large language model (LLM) agents are constrained by l...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 14. DeeptraceReward is a benchmark dataset that annotates human-perceived deepfake traces in videos, used to train multimodal language models for detecting AI-generated videos.  					AI-generated summary 				 Can humans identify AI-generated (fake) videos and provide grounded reasons? While video genera...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 15. A novel PSRL framework (AttnRL) enhances exploration efficiency in reasoning models by branching from high attention positions and using an adaptive sampling strategy, outperforming prior methods in mathematical reasoning benchmarks.  					AI-generated summary 				 Reinforcement Learning (RL) has sh...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 16. Operational safety, measured by OffTopicEval, is a critical issue for LLMs, with most models falling short, but prompt-based steering methods show promise in improving out-of-distribution refusal.  					AI-generated summary 				 Large Language Model (LLM) safety is one of the most pressing challenge...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 17. DA², a zero-shot generalizable and fully end-to-end panoramic depth estimator, addresses challenges in panoramic depth estimation by using a data curation engine and SphereViT to handle spherical distortions, achieving state-of-the-art performance.  					AI-generated summary 				 Panorama has a full...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 18. DeepScientist autonomously conducts scientific discovery through Bayesian Optimization, surpassing human state-of-the-art methods on multiple AI tasks.  					AI-generated summary 				 While previous AI Scientist systems can generate novel findings, they often lack the focus to produce scientifically...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 19. Online alignment methods like GRPO outperform offline methods like DPO due to better approximation of human-perceived probability distributions, and introducing perceptual biases into offline training can achieve similar performance.  					AI-generated summary 				 Online alignment (e.g., GRPO) is g...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 20. Ferret-UI Lite, a compact end-to-end GUI agent, achieves competitive performance across diverse platforms using chain-of-thought reasoning, visual tool-use, and reinforcement learning.  					AI-generated summary 				 Developing autonomous agents that effectively interact with Graphic User Interfaces...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 21. A unified Regression Language Model (RLM) predicts numeric outcomes of code executions, including memory footprint, latency, and neural network performance, across multiple languages and hardware platforms.  					AI-generated summary 				 We study code-to-metric regression: predicting numeric outcom...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 22. VAPO-Thinker-7B enhances multimodal reasoning by anchoring the process to visual information, improving performance on visual tasks while maintaining logical inference.  					AI-generated summary 				 Reasoning has emerged as a pivotal capability in Large Language Models (LLMs). Through Reinforcemen...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 23. Research explores collaboration in open large language models, identifying diverse motivations and organizational models among developers from various sectors.  					AI-generated summary 				 The proliferation of open large language models (LLMs) is fostering a vibrant ecosystem of research and inno...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 24. InfoAgent, a deep research agent using a custom data synthesis pipeline and search infrastructure, outperforms existing agents by improving tool use and reasoning.  					AI-generated summary 				 Building Large Language Model agents that expand their capabilities by interacting with external tools r...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 25. Theoretical analysis of reinforcement learning methods in enhancing LLM planning reveals that while RL improves generalization through exploration, policy gradient suffers from diversity collapse, whereas Q-learning maintains diversity and requires careful reward design.  					AI-generated summary 	...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 26. ROSA, a lightweight algorithm, enhances multi-turn interactions in LLMs by adapting to user feedback in real-time, improving both task effectiveness and efficiency.  					AI-generated summary 				 Large Language Models (LLMs) employ multi-turn interaction as a fundamental paradigm for completing com...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 27. TAU, a benchmark of culturally specific Taiwanese soundmarks, reveals that state-of-the-art large audio-language models underperform compared to local humans, highlighting the need for localized evaluations.  					AI-generated summary 				 Large audio-language models are advancing rapidly, yet most ...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 28. VisualOverload is a VQA benchmark that challenges models with simple vision tasks in densely populated scenes, revealing gaps in current VLMs' performance and offering insights into their failure modes.  					AI-generated summary 				 Is basic visual understanding really solved in state-of-the-art V...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 29. TTT3R, a test-time training intervention, enhances length generalization in 3D reconstruction by dynamically adjusting memory updates based on alignment confidence, improving global pose estimation and processing efficiency.  					AI-generated summary 				 Modern Recurrent Neural Networks have becom...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 30. CritPt, a benchmark for evaluating LLMs on research-level physics tasks, reveals significant gaps between current model capabilities and the demands of physics research.  					AI-generated summary 				 While large language models (LLMs) with reasoning capabilities are progressing rapidly on high-sch...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 31. VERA is a benchmark for evaluating reasoning ability in voice-interactive systems, revealing significant performance gaps compared to text models and highlighting challenges in real-time interaction.  					AI-generated summary 				 We present Voice Evaluation of Reasoning Ability (VERA), a benchmark...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 32. Graph Neural Network regression models estimate entity-level knowledgeability in Large Language Models to improve active labeling and multi-hop reasoning.  					AI-generated summary 				 Large Language Models (LLMs) have been increasingly studied as neural knowledge bases for supporting knowledge-in...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 33. Stable Cinemetrics introduces a structured evaluation framework for professional video generation, using taxonomies to assess models across specific filmmaking controls.  					AI-generated summary 				 Recent advances in video generation have enabled high-fidelity video synthesis from user provided ...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 34. LayerD decomposes raster images into editable layers using iterative extraction and refinement, outperforming existing methods and enabling use with advanced image generators.  					AI-generated summary 				 Designers craft and edit graphic designs in a layer representation, but layer-based editing ...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 35. MANI-Pure, a magnitude-adaptive purification framework using diffusion models, effectively suppresses high-frequency adversarial perturbations while preserving low-frequency content, enhancing robust accuracy.  					AI-generated summary 				 Adversarial purification with diffusion models has emerged...
[01.10.2025 08:16] ********************************************************************************
[01.10.2025 08:16] Abstract 36. A timeline of the evolution of deep residual learning, a key advancement in neural network architecture.  					AI-generated summary 				 Modern AI is based on deep artificial neural networks (NNs). As of 2025, the most cited scientific article of the 21st century is an NN paper on deep residual lear...
[01.10.2025 08:16] Read previous papers.
[01.10.2025 08:16] Generating reviews via LLM API.
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#optimization", "#games", "#cv", "#training", "#rl"], "emoji": "🎮", "ru": {"title": "Самообучение VLM через визуальные игры без разметки", "desc": "Vision-Zero — это фреймворк для самосовершенствования vision-language моделей через соревновательные визуа
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#rlhf", "#hallucinations", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "🎯", "ru": {"title": "Обучение LLM говорить правду через воздержание от ответа", "desc": "В статье представлен TruthRL — фреймворк на основе reinforcement learning для повышения правдивости больш
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#games", "#transfer_learning", "#agents", "#benchmark", "#multimodal"], "emoji": "🌊", "ru": {"title": "OceanGym: Тестовая площадка для AI-агентов в неизведанных глубинах океана", "desc": "В статье представлен OceanGym — первый комплексный бенчмарк для подводных embodied-агентов, раб
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#hallucinations", "#data", "#ethics", "#dataset", "#interpretability", "#architecture", "#multimodal"], "emoji": "⚖️", "ru": {"title": "Детектор оценок от LLM: обнаружение искусственных суждений по баллам", "desc": "В статье формализуется задача обнаружения суждений, сгенерированных
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#inference", "#video", "#optimization", "#diffusion", "#architecture", "#training"], "emoji": "⚡", "ru": {"title": "Ускорение генерации видео через глубокое сжатие латентного пространства", "desc": "DC-VideoGen — это фреймворк для ускорения генерации видео, который адаптирует предоб
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#agi", "#agents", "#survey", "#benchmark"], "emoji": "🧪", "ru": {"title": "MCPMark: бенчмарк, который показал слабость LLM в реальных рабочих сценариях", "desc": "MCPMark — это новый комплексный бенчмарк для оценки использования MCP (Model Context Protocol) в реальных рабочих процес
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#reasoning", "#architecture", "#training"], "emoji": "🧠", "ru": {"title": "Специализированные головы внимания: ключ к рассуждениям LLM", "desc": "Исследование показывает, что post-training техники, такие как supervised fine-tuning и reinforcemen
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark", "#alignment", "#dataset", "#transfer_learning"], "emoji": "👁️", "ru": {"title": "Визуальные приоры из текста: как LLM учатся видеть без изображений", "desc": "Исследование показывает, что большие языковые модели (LLM) неожиданно развивают ви
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#benchmark", "#games", "#survey"], "emoji": "🧭", "ru": {"title": "VitaBench: жизненный экзамен для AI-агентов в реальных сценариях", "desc": "VitaBench — это новый бенчмарк для оценки LLM-агентов в сложных интерактивных задачах, приближенных к реальной жизни
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#inference", "#optimization", "#benchmark", "#diffusion", "#open_source", "#training"], "emoji": "⚡", "ru": {"title": "Параллельное декодирование диффузионных LLM с 10-кратным ускорением", "desc": "Статья представляет dParallel — метод для ускорения параллельного декодирования в диф
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#multimodal", "#alignment", "#cv", "#diffusion"], "emoji": "🎯", "ru": {"title": "Неявное управление для точного соответствия изображений и текста", "desc": "Статья представляет метод Implicit Multimodal Guidance (IMG) для улучшения согласованности между сгенерированными диффузионным
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#transfer_learning", "#video", "#rag", "#diffusion", "#multimodal"], "emoji": "🎬", "ru": {"title": "Улучшение реалистичности движения в видео через retrieval motion-паттернов", "desc": "Статья представляет MotionRAG — фреймворк для генерации видео, который использует retrieval-augme
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#video", "#benchmark", "#audio", "#inference"], "emoji": "🐬", "ru": {"title": "Dolphin: Быстрая и эффективная сепарация речи с помощью визуальных подсказок", "desc": "Dolphin - это эффективный метод аудио-визуальной сепарации речи (AVSS), который использует визуальные подсказки для 
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#rl", "#optimization", "#agents", "#long_context", "#dataset", "#training"], "emoji": "🧠", "ru": {"title": "Обучение LLM управлять памятью через reinforcement learning", "desc": "Статья представляет Mem-alpha — фреймворк на основе reinforcement learning для улучшения управления памя
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#video", "#multimodal", "#benchmark", "#dataset", "#interpretability"], "emoji": "🔍", "ru": {"title": "Учим модели находить следы дипфейков глазами человека", "desc": "Исследователи создали датасет DeeptraceReward с 4.3 тысячами детальных аннотаций искусстве
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#math", "#optimization", "#reasoning", "#training", "#rl"], "emoji": "🌳", "ru": {"title": "Умное ветвление через внимание для обучения рассуждениям", "desc": "Исследователи предложили новый подход AttnRL для улучшения Process-Supervised Reinforcement Learning при обучении LLM матема
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#security", "#alignment", "#training", "#ethics", "#agents", "#benchmark"], "emoji": "🚦", "ru": {"title": "Операционная безопасность: научить LLM отказываться от неподходящих запросов", "desc": "Исследователи представили концепцию операционной безопасности — способности LLM корректн
[01.10.2025 08:16] Using data from previous issue: {"categories": ["#3d", "#optimization", "#data", "#dataset", "#benchmark", "#open_source"], "emoji": "🌐", "ru": {"title": "Оценка глубины панорам без дистилляции и с нулевым обучением", "desc": "Статья представляет DA² — систему для оценки глубины на панорамных изображениях с полным обзором 360×180 
[01.10.2025 08:16] Querying the API.
[01.10.2025 08:16] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DeepScientist autonomously conducts scientific discovery through Bayesian Optimization, surpassing human state-of-the-art methods on multiple AI tasks.  					AI-generated summary 				 While previous AI Scientist systems can generate novel findings, they often lack the focus to produce scientifically valuable contributions that address pressing human-defined challenges. We introduce DeepScientist, a system designed to overcome this by conducting goal-oriented, fully autonomous scientific discovery over month-long timelines. It formalizes discovery as a Bayesian Optimization problem, operationalized through a hierarchical evaluation process consisting of "hypothesize, verify, and analyze". Leveraging a cumulative Findings Memory, this loop intelligently balances the exploration of novel hypotheses with exploitation, selectively promoting the most promising findings to higher-fidelity levels of validation. Consuming over 20,000 GPU hours, the system generated about 5,000 unique scientific ideas and experimentally validated approximately 1100 of them, ultimately surpassing human-designed state-of-the-art (SOTA) methods on three frontier AI tasks by 183.7\%, 1.9\%, and 7.9\%. This work provides the first large-scale evidence of an AI achieving discoveries that progressively surpass human SOTA on scientific tasks, producing valuable findings that genuinely push the frontier of scientific discovery. To facilitate further research into this process, we will open-source all experimental logs and system code at https://github.com/ResearAI/DeepScientist/.
[01.10.2025 08:16] Response: ```json
{
  "desc": "DeepScientist - это система, которая автономно проводит научные исследования, используя байесовскую оптимизацию для целенаправленного научного поиска. Система работает по циклу «гипотеза-проверка-анализ», используя накопительную память находок для баланса между исследованием новых идей и эксплуатацией перспективных направлений. За месяцы работы система сгенерировала около 5000 уникальных научных идей, экспериментально проверила примерно 1100 из них, потратив более 20000 GPU-часов. В результате DeepScientist превзошёл современные методы, разработанные людьми, на трёх передовых AI-задачах на 183.7%, 1.9% и 7.9%, демонстрируя первое масштабное доказательство того, что AI может самостоятельно двигать границы науки.",
  "emoji": "🔬",
  "title": "AI-учёный превосходит человеческие достижения через автономное научное исследование"
}
```
[01.10.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeepScientist autonomously conducts scientific discovery through Bayesian Optimization, surpassing human state-of-the-art methods on multiple AI tasks.  					AI-generated summary 				 While previous AI Scientist systems can generate novel findings, they often lack the focus to produce scientifically valuable contributions that address pressing human-defined challenges. We introduce DeepScientist, a system designed to overcome this by conducting goal-oriented, fully autonomous scientific discovery over month-long timelines. It formalizes discovery as a Bayesian Optimization problem, operationalized through a hierarchical evaluation process consisting of "hypothesize, verify, and analyze". Leveraging a cumulative Findings Memory, this loop intelligently balances the exploration of novel hypotheses with exploitation, selectively promoting the most promising findings to higher-fidelity levels of validation. Consuming over 20,000 GPU hours, the system generated about 5,000 unique scientific ideas and experimentally validated approximately 1100 of them, ultimately surpassing human-designed state-of-the-art (SOTA) methods on three frontier AI tasks by 183.7\%, 1.9\%, and 7.9\%. This work provides the first large-scale evidence of an AI achieving discoveries that progressively surpass human SOTA on scientific tasks, producing valuable findings that genuinely push the frontier of scientific discovery. To facilitate further research into this process, we will open-source all experimental logs and system code at https://github.com/ResearAI/DeepScientist/."

[01.10.2025 08:17] Response: ```python
['AGENTS', 'RL']
```
[01.10.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeepScientist autonomously conducts scientific discovery through Bayesian Optimization, surpassing human state-of-the-art methods on multiple AI tasks.  					AI-generated summary 				 While previous AI Scientist systems can generate novel findings, they often lack the focus to produce scientifically valuable contributions that address pressing human-defined challenges. We introduce DeepScientist, a system designed to overcome this by conducting goal-oriented, fully autonomous scientific discovery over month-long timelines. It formalizes discovery as a Bayesian Optimization problem, operationalized through a hierarchical evaluation process consisting of "hypothesize, verify, and analyze". Leveraging a cumulative Findings Memory, this loop intelligently balances the exploration of novel hypotheses with exploitation, selectively promoting the most promising findings to higher-fidelity levels of validation. Consuming over 20,000 GPU hours, the system generated about 5,000 unique scientific ideas and experimentally validated approximately 1100 of them, ultimately surpassing human-designed state-of-the-art (SOTA) methods on three frontier AI tasks by 183.7\%, 1.9\%, and 7.9\%. This work provides the first large-scale evidence of an AI achieving discoveries that progressively surpass human SOTA on scientific tasks, producing valuable findings that genuinely push the frontier of scientific discovery. To facilitate further research into this process, we will open-source all experimental logs and system code at https://github.com/ResearAI/DeepScientist/."

[01.10.2025 08:17] Response: ```python
['SCIENCE', 'OPEN_SOURCE']
```
[01.10.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeepScientist is an advanced AI system that autonomously conducts scientific discovery using Bayesian Optimization. It addresses the limitations of previous AI systems by focusing on generating scientifically valuable contributions to real-world challenges. The system operates through a structured process of hypothesizing, verifying, and analyzing findings, while maintaining a cumulative memory of discoveries. By leveraging extensive computational resources, DeepScientist has generated thousands of unique ideas and validated many of them, outperforming human-designed methods in several AI tasks.","title":"DeepScientist: AI Surpassing Human Discovery in Science"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DeepScientist is an advanced AI system that autonomously conducts scientific discovery using Bayesian Optimization. It addresses the limitations of previous AI systems by focusing on generating scientifically valuable contributions to real-world challenges. The system operates through a structured process of hypothesizing, verifying, and analyzing findings, while maintaining a cumulative memory of discoveries. By leveraging extensive computational resources, DeepScientist has generated thousands of unique ideas and validated many of them, outperforming human-designed methods in several AI tasks.', title='DeepScientist: AI Surpassing Human Discovery in Science'))
[01.10.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeepScientist 是一个通过贝叶斯优化进行科学发现的系统，能够自主进行科学研究，超越人类在多个人工智能任务上的最先进方法。它将科学发现形式化为一个贝叶斯优化问题，并通过“假设、验证和分析”的分层评估过程来实现。该系统利用累积的发现记忆，智能地平衡新假设的探索与已有发现的利用，选择性地提升最有前景的发现进行更高精度的验证。最终，DeepScientist 生成了约5000个独特的科学想法，并成功验证了约1100个，显著超越了人类设计的最先进方法。","title":"DeepScientist：超越人类的科学发现新纪元"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DeepScientist 是一个通过贝叶斯优化进行科学发现的系统，能够自主进行科学研究，超越人类在多个人工智能任务上的最先进方法。它将科学发现形式化为一个贝叶斯优化问题，并通过“假设、验证和分析”的分层评估过程来实现。该系统利用累积的发现记忆，智能地平衡新假设的探索与已有发现的利用，选择性地提升最有前景的发现进行更高精度的验证。最终，DeepScientist 生成了约5000个独特的科学想法，并成功验证了约1100个，显著超越了人类设计的最先进方法。', title='DeepScientist：超越人类的科学发现新纪元'))
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#alignment", "#training", "#rl", "#rlhf"], "emoji": "🧠", "ru": {"title": "Человеческое восприятие вероятностей как ключ к эффективному обучению LLM", "desc": "Исследователи объясняют, почему онлайн методы выравнивания (GRPO) работают лучше оффлайн методов (DPO), опираясь на теорию п
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#inference", "#agents", "#reasoning", "#small_models", "#synthetic", "#data", "#dataset", "#rl"], "emoji": "📱", "ru": {"title": "Компактный AI-агент для управления интерфейсами на устройстве", "desc": "Ferret-UI Lite — это компактная модель размером 3B параметров для автономного вза
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#games", "#data", "#optimization", "#training", "#dataset", "#multilingual", "#small_models"], "emoji": "📊", "ru": {"title": "Единая языковая модель для предсказания производительности кода", "desc": "В статье представлена единая Regression Language Model (RLM), которая предсказывае
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#cv", "#multimodal", "#reasoning"], "emoji": "👁️", "ru": {"title": "Не забывай смотреть: как научить AI рассуждать без потери визуального восприятия", "desc": "Исследование выявляет проблему \"визуального забывания\" в Vision-Language Models: при длительном расс
[01.10.2025 08:17] Querying the API.
[01.10.2025 08:17] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Research explores collaboration in open large language models, identifying diverse motivations and organizational models among developers from various sectors.  					AI-generated summary 				 The proliferation of open large language models (LLMs) is fostering a vibrant ecosystem of research and innovation in artificial intelligence (AI). However, the methods of collaboration used to develop open LLMs both before and after their public release have not yet been comprehensively studied, limiting our understanding of how open LLM projects are initiated, organized, and governed as well as what opportunities there are to foster this ecosystem even further. We address this gap through an exploratory analysis of open collaboration throughout the development and reuse lifecycle of open LLMs, drawing on semi-structured interviews with the developers of 14 open LLMs from grassroots projects, research institutes, startups, and Big Tech companies in North America, Europe, Africa, and Asia. We make three key contributions to research and practice. First, collaboration in open LLM projects extends far beyond the LLMs themselves, encompassing datasets, benchmarks, open source frameworks, leaderboards, knowledge sharing and discussion forums, and compute partnerships, among others. Second, open LLM developers have a variety of social, economic, and technological motivations, from democratizing AI access and promoting open science to building regional ecosystems and expanding language representation. Third, the sampled open LLM projects exhibit five distinct organizational models, ranging from single company projects to non-profit-sponsored grassroots projects, which vary in their centralization of control and community engagement strategies used throughout the open LLM lifecycle. We conclude with practical recommendations for stakeholders seeking to support the global community building a more open future for AI.
[01.10.2025 08:17] Response: ```json
{
  "desc": "Исследование изучает методы совместной работы при разработке открытых LLM на основе интервью с разработчиками 14 проектов из разных стран и секторов. Коллаборация в открытых LLM-проектах включает не только сами модели, но и датасеты, бенчмарки, фреймворки, лидерборды и вычислительные партнерства. Разработчики имеют различные мотивации: от демократизации доступа к AI и развития открытой науки до построения региональных экосистем и расширения языкового представительства. Исследование выявило пять организационных моделей открытых LLM-проектов, которые различаются по централизации контроля и стратегиям вовлечения сообщества на всех этапах жизненного цикла модели.",
  "emoji": "🤝",
  "title": "Экосистема открытых LLM: многообразие моделей сотрудничества и мотиваций"
}
```
[01.10.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research explores collaboration in open large language models, identifying diverse motivations and organizational models among developers from various sectors.  					AI-generated summary 				 The proliferation of open large language models (LLMs) is fostering a vibrant ecosystem of research and innovation in artificial intelligence (AI). However, the methods of collaboration used to develop open LLMs both before and after their public release have not yet been comprehensively studied, limiting our understanding of how open LLM projects are initiated, organized, and governed as well as what opportunities there are to foster this ecosystem even further. We address this gap through an exploratory analysis of open collaboration throughout the development and reuse lifecycle of open LLMs, drawing on semi-structured interviews with the developers of 14 open LLMs from grassroots projects, research institutes, startups, and Big Tech companies in North America, Europe, Africa, and Asia. We make three key contributions to research and practice. First, collaboration in open LLM projects extends far beyond the LLMs themselves, encompassing datasets, benchmarks, open source frameworks, leaderboards, knowledge sharing and discussion forums, and compute partnerships, among others. Second, open LLM developers have a variety of social, economic, and technological motivations, from democratizing AI access and promoting open science to building regional ecosystems and expanding language representation. Third, the sampled open LLM projects exhibit five distinct organizational models, ranging from single company projects to non-profit-sponsored grassroots projects, which vary in their centralization of control and community engagement strategies used throughout the open LLM lifecycle. We conclude with practical recommendations for stakeholders seeking to support the global community building a more open future for AI."

[01.10.2025 08:17] Response: ```python
['DATASET', 'BENCHMARK', 'MULTILINGUAL']
```
[01.10.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research explores collaboration in open large language models, identifying diverse motivations and organizational models among developers from various sectors.  					AI-generated summary 				 The proliferation of open large language models (LLMs) is fostering a vibrant ecosystem of research and innovation in artificial intelligence (AI). However, the methods of collaboration used to develop open LLMs both before and after their public release have not yet been comprehensively studied, limiting our understanding of how open LLM projects are initiated, organized, and governed as well as what opportunities there are to foster this ecosystem even further. We address this gap through an exploratory analysis of open collaboration throughout the development and reuse lifecycle of open LLMs, drawing on semi-structured interviews with the developers of 14 open LLMs from grassroots projects, research institutes, startups, and Big Tech companies in North America, Europe, Africa, and Asia. We make three key contributions to research and practice. First, collaboration in open LLM projects extends far beyond the LLMs themselves, encompassing datasets, benchmarks, open source frameworks, leaderboards, knowledge sharing and discussion forums, and compute partnerships, among others. Second, open LLM developers have a variety of social, economic, and technological motivations, from democratizing AI access and promoting open science to building regional ecosystems and expanding language representation. Third, the sampled open LLM projects exhibit five distinct organizational models, ranging from single company projects to non-profit-sponsored grassroots projects, which vary in their centralization of control and community engagement strategies used throughout the open LLM lifecycle. We conclude with practical recommendations for stakeholders seeking to support the global community building a more open future for AI."

[01.10.2025 08:17] Response: ```python
['OPEN_SOURCE']
```
[01.10.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how collaboration occurs in the development of open large language models (LLMs) and identifies various motivations and organizational structures among developers. It highlights that collaboration extends beyond just the models to include datasets, benchmarks, and community engagement. The study reveals that developers are driven by diverse goals such as democratizing AI and enhancing language representation. Additionally, it categorizes open LLM projects into five organizational models, providing insights into how these projects can be better supported.","title":"Fostering Collaboration for Open AI Innovation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates how collaboration occurs in the development of open large language models (LLMs) and identifies various motivations and organizational structures among developers. It highlights that collaboration extends beyond just the models to include datasets, benchmarks, and community engagement. The study reveals that developers are driven by diverse goals such as democratizing AI and enhancing language representation. Additionally, it categorizes open LLM projects into five organizational models, providing insights into how these projects can be better supported.', title='Fostering Collaboration for Open AI Innovation'))
[01.10.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究探讨了开放大型语言模型（LLM）开发中的协作，识别了来自不同领域开发者的多样化动机和组织模式。研究发现，开放LLM项目的协作不仅限于模型本身，还包括数据集、基准测试、开源框架等多个方面。开发者的动机多种多样，包括促进人工智能的民主化、推动开放科学以及扩展语言表现等。最后，研究提出了对利益相关者的实用建议，以支持全球社区建设更开放的人工智能未来。","title":"开放大型语言模型的协作与创新"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究探讨了开放大型语言模型（LLM）开发中的协作，识别了来自不同领域开发者的多样化动机和组织模式。研究发现，开放LLM项目的协作不仅限于模型本身，还包括数据集、基准测试、开源框架等多个方面。开发者的动机多种多样，包括促进人工智能的民主化、推动开放科学以及扩展语言表现等。最后，研究提出了对利益相关者的实用建议，以支持全球社区建设更开放的人工智能未来。', title='开放大型语言模型的协作与创新'))
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#agents", "#training", "#open_source", "#data"], "emoji": "🔍", "ru": {"title": "InfoAgent: Агент глубокого исследования с продвинутым поиском", "desc": "В статье представлен InfoAgent — агент на основе LLM для глубокого исследования информации, который используе
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#benchmark", "#training", "#rl"], "emoji": "🗺️", "ru": {"title": "Почему Q-learning лучше policy gradient для планирования в LLM", "desc": "Исследование теоретически анализирует, как методы reinforcement learning улучшают способности LLM к планированию
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#alignment", "#training", "#benchmark", "#rlhf", "#optimization"], "emoji": "🎯", "ru": {"title": "Адаптация AI к предпочтениям пользователя прямо во время диалога", "desc": "Статья представляет ROSA — лёгкий алгоритм для улучшения многоходовых диалогов с LLM. Проблема в том, что мод
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#audio", "#benchmark", "#multimodal"], "emoji": "🔔", "ru": {"title": "Культурные звуки как тест для аудио-AI: модели не слышат локальный контекст", "desc": "Исследователи создали бенчмарк TAU для оценки способности больших аудио-языковых моделей распознавать
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#interpretability", "#reasoning", "#benchmark", "#dataset", "#cv"], "emoji": "🎨", "ru": {"title": "VisualOverload: когда сложные сцены ставят VLM в тупик", "desc": "Исследователи представили бенчмарк VisualOverload для оценки vision-language моделей на задачах визуального понимания 
[01.10.2025 08:17] Querying the API.
[01.10.2025 08:17] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

TTT3R, a test-time training intervention, enhances length generalization in 3D reconstruction by dynamically adjusting memory updates based on alignment confidence, improving global pose estimation and processing efficiency.  					AI-generated summary 				 Modern Recurrent Neural Networks have become a competitive architecture for 3D reconstruction due to their linear-time complexity. However, their performance degrades significantly when applied beyond the training context length, revealing limited length generalization. In this work, we revisit the 3D reconstruction foundation models from a Test-Time Training perspective, framing their designs as an online learning problem. Building on this perspective, we leverage the alignment confidence between the memory state and incoming observations to derive a closed-form learning rate for memory updates, to balance between retaining historical information and adapting to new observations. This training-free intervention, termed TTT3R, substantially improves length generalization, achieving a 2times improvement in global pose estimation over baselines, while operating at 20 FPS with just 6 GB of GPU memory to process thousands of images. Code available in https://rover-xingyu.github.io/TTT3R
[01.10.2025 08:17] Response: ```json
{
  "title": "Адаптивное обучение на лету для 3D-реконструкции без границ",
  "emoji": "🔄",
  "desc": "Статья представляет TTT3R — метод test-time training для улучшения 3D-реконструкции с помощью рекуррентных нейросетей. Проблема в том, что современные модели плохо работают с последовательностями длиннее тех, на которых обучались. Авторы предлагают динамически регулировать обновление памяти модели на основе уверенности в соответствии между текущим состоянием и новыми наблюдениями, используя закрытую формулу для learning rate. Результат — двукратное улучшение точности оценки глобальной позы при скорости 20 FPS и всего 6 ГБ видеопамяти для обработки тысяч изображений.",
  "emoji": "🔄"
}
```
[01.10.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TTT3R, a test-time training intervention, enhances length generalization in 3D reconstruction by dynamically adjusting memory updates based on alignment confidence, improving global pose estimation and processing efficiency.  					AI-generated summary 				 Modern Recurrent Neural Networks have become a competitive architecture for 3D reconstruction due to their linear-time complexity. However, their performance degrades significantly when applied beyond the training context length, revealing limited length generalization. In this work, we revisit the 3D reconstruction foundation models from a Test-Time Training perspective, framing their designs as an online learning problem. Building on this perspective, we leverage the alignment confidence between the memory state and incoming observations to derive a closed-form learning rate for memory updates, to balance between retaining historical information and adapting to new observations. This training-free intervention, termed TTT3R, substantially improves length generalization, achieving a 2times improvement in global pose estimation over baselines, while operating at 20 FPS with just 6 GB of GPU memory to process thousands of images. Code available in https://rover-xingyu.github.io/TTT3R"

[01.10.2025 08:17] Response: ```python
['3D', 'TRAINING']
```
[01.10.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TTT3R, a test-time training intervention, enhances length generalization in 3D reconstruction by dynamically adjusting memory updates based on alignment confidence, improving global pose estimation and processing efficiency.  					AI-generated summary 				 Modern Recurrent Neural Networks have become a competitive architecture for 3D reconstruction due to their linear-time complexity. However, their performance degrades significantly when applied beyond the training context length, revealing limited length generalization. In this work, we revisit the 3D reconstruction foundation models from a Test-Time Training perspective, framing their designs as an online learning problem. Building on this perspective, we leverage the alignment confidence between the memory state and incoming observations to derive a closed-form learning rate for memory updates, to balance between retaining historical information and adapting to new observations. This training-free intervention, termed TTT3R, substantially improves length generalization, achieving a 2times improvement in global pose estimation over baselines, while operating at 20 FPS with just 6 GB of GPU memory to process thousands of images. Code available in https://rover-xingyu.github.io/TTT3R"

[01.10.2025 08:17] Response: ```python
["OPTIMIZATION", "LONG_CONTEXT"]
```
[01.10.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces TTT3R, a novel approach that enhances length generalization in 3D reconstruction tasks. It addresses the limitations of Recurrent Neural Networks (RNNs) when they encounter input sequences longer than those seen during training. By applying Test-Time Training, TTT3R dynamically adjusts memory updates based on the confidence of alignment between the model\'s memory and new observations. This method significantly improves global pose estimation and processing efficiency, achieving a twofold increase in performance while maintaining a fast processing speed.","title":"TTT3R: Boosting 3D Reconstruction with Smart Memory Updates"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces TTT3R, a novel approach that enhances length generalization in 3D reconstruction tasks. It addresses the limitations of Recurrent Neural Networks (RNNs) when they encounter input sequences longer than those seen during training. By applying Test-Time Training, TTT3R dynamically adjusts memory updates based on the confidence of alignment between the model's memory and new observations. This method significantly improves global pose estimation and processing efficiency, achieving a twofold increase in performance while maintaining a fast processing speed.", title='TTT3R: Boosting 3D Reconstruction with Smart Memory Updates'))
[01.10.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TTT3R是一种测试时训练的干预方法，旨在通过根据对齐置信度动态调整记忆更新，增强3D重建中的长度泛化能力。该方法将3D重建视为在线学习问题，利用记忆状态与新观察之间的对齐置信度来推导闭式学习率，从而在保留历史信息与适应新观察之间取得平衡。通过这种训练无关的干预，TTT3R显著提高了长度泛化能力，在全局姿态估计上实现了2倍的提升，同时以20帧每秒的速度处理数千张图像，仅需6GB的GPU内存。","title":"TTT3R：提升3D重建长度泛化的创新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TTT3R是一种测试时训练的干预方法，旨在通过根据对齐置信度动态调整记忆更新，增强3D重建中的长度泛化能力。该方法将3D重建视为在线学习问题，利用记忆状态与新观察之间的对齐置信度来推导闭式学习率，从而在保留历史信息与适应新观察之间取得平衡。通过这种训练无关的干预，TTT3R显著提高了长度泛化能力，在全局姿态估计上实现了2倍的提升，同时以20帧每秒的速度处理数千张图像，仅需6GB的GPU内存。', title='TTT3R：提升3D重建长度泛化的创新方法'))
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#science", "#reasoning", "#benchmark", "#dataset"], "emoji": "⚛️", "ru": {"title": "Физики проверили LLM на реальных исследовательских задачах — и модели провалились", "desc": "Исследователи создали бенчмарк CritPt для оценки способностей LLM решать исследовательские задачи уровня н
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark", "#architecture", "#long_context"], "emoji": "🎤", "ru": {"title": "Голосовые AI-помощники сильно отстают в способности рассуждать", "desc": "VERA — это бенчмарк для оценки способности к рассуждению в голосовых интерактивных системах в условия
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#data", "#reasoning", "#training", "#dataset", "#agents", "#graphs", "#multimodal"], "emoji": "🕸️", "ru": {"title": "Граф знаний LLM: соседи знают одинаково", "desc": "Исследователи изучили структурную организацию знаний в больших языковых моделях, представив их в виде графа. Оказал
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#benchmark", "#games", "#video", "#optimization"], "emoji": "🎬", "ru": {"title": "Профессиональная оценка видео-генерации через призму кинематографа", "desc": "Исследователи представили Stable Cinemetrics — фреймворк для оценки качества генерации профессионального видео с помощью AI
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "🎨", "ru": {"title": "Превращаем картинку обратно в слои для редактирования", "desc": "LayerD — это метод для декомпозиции растровых графических изображений на отдельные редактируемые слои. Система работает итеративно, последовательно извлекая слои переднего п
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#training", "#diffusion", "#cv", "#security"], "emoji": "🔊", "ru": {"title": "Адаптивная очистка от adversarial атак через частотный анализ", "desc": "Статья представляет MANI-Pure — новый метод защиты от adversarial атак с использованием диффузионных моделей. Авторы обнаружили, что
[01.10.2025 08:17] Using data from previous issue: {"categories": ["#architecture"], "emoji": "🔗", "ru": {"title": "История глубокого остаточного обучения: кто изобрёл residual connections", "desc": "Статья представляет хронологию развития глубокого остаточного обучения (deep residual learning) — ключевого прорыва в архитектуре нейронных сетей. Авто
[01.10.2025 08:17] Renaming data file.
[01.10.2025 08:17] Renaming previous data. hf_papers.json to ./d/2025-10-01.json
[01.10.2025 08:17] Saving new data file.
[01.10.2025 08:17] Generating page.
[01.10.2025 08:17] Renaming previous page.
[01.10.2025 08:17] Renaming previous data. index.html to ./d/2025-10-01.html
[01.10.2025 08:17] Writing result.
[01.10.2025 08:17] Renaming log file.
[01.10.2025 08:17] Renaming previous data. log.txt to ./logs/2025-10-01_last_log.txt
