[01.10.2025 15:14] Read previous papers.
[01.10.2025 15:14] Generating top page (month).
[01.10.2025 15:14] Writing top page (month).
[01.10.2025 16:14] Read previous papers.
[01.10.2025 16:14] Get feed.
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24002
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26507
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25541
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23873
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25760
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26536
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25848
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26625
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26226
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25182
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25154
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25758
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26490
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.22646
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26488
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26231
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26391
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23610
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26618
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26603
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25911
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26495
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24207
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26628
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25397
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25339
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.22613
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26476
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25189
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26645
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26542
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26539
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23166
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26030
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26329
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26157
[01.10.2025 16:14] Extract page data from URL. URL: https://huggingface.co/papers/2509.25716
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25085
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23773
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23094
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21361
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26604
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26574
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25134
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25082
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24732
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23695
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25248
[01.10.2025 16:14] Extract page data from URL. URL: https://huggingface.co/papers/2509.23019
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26555
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26278
[01.10.2025 16:14] Extract page data from URL. URL: https://huggingface.co/papers/2509.25810
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25666
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24510
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.22889
[01.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18538
[01.10.2025 16:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[01.10.2025 16:14] No deleted papers detected.
[01.10.2025 16:14] Downloading and parsing papers (pdf, html). Total: 56.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.24002.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.24002.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.24002.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26507.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26507.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26507.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25541.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25541.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25541.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.23873.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.23873.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.23873.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25760.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25760.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25760.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26536.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26536.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26536.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25848.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25848.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25848.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26625.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26625.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26625.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26226.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26226.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26226.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25182.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25182.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25182.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25154.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25154.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25154.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25758.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25758.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25758.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26490.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26490.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26490.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.22646.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.22646.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.22646.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26488.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26488.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26488.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26231.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26231.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26231.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26391.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26391.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26391.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.23610.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.23610.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.23610.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26618.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26618.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26618.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26603.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26603.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26603.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25911.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25911.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25911.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26495.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26495.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26495.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.24207.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.24207.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.24207.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26628.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26628.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26628.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25397.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25397.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25397.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25339.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25339.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25339.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.22613.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.22613.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.22613.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26476.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26476.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26476.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25189.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25189.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25189.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26645.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26645.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26645.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26542.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26542.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26542.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26539.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26539.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26539.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.23166.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.23166.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.23166.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26030.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26030.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26030.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26329.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26329.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26329.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26157.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26157.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26157.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25716.
[01.10.2025 16:14] Downloading paper 2509.25716 from http://arxiv.org/pdf/2509.25716v1...
[01.10.2025 16:14] Extracting affiliations from text.
[01.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"DeepCodeSeek: Real-Time API Retrieval for Context-Aware Code Generation Esakkivel Esakkiraja1, Denis Akhiyarov1,*, Aditya Shanmugham1 and Chitra Ganapathy1 1ServiceNow, Inc. Abstract Current search techniques are limited to standard RAG query-document applications. In this paper, we propose novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop comprehensive post-training pipeline that optimizes compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models. Keywords Retrieval-Augmented Generation, API Prediction, Context-Aware Code Generation, Enterprise Code Completion, Reinforcement Learning, ServiceNow, Real-Time Code Search, Query Enhancement, Fine-Tuning, Embedding, Reranker 1. Introduction Large Language Models (LLMs) have become integral to modern developer workflows through AIassisted code completion. In specialized enterprise environments like ServiceNow, model effectiveness depends heavily on context quality, particularly for custom APIs called Script Includes. Script Includes in ServiceNow are reusable JavaScript components that serve as centralized repository for storing functions and classes, enabling develope"
[01.10.2025 16:14] Response: ```python
["ServiceNow, Inc."]
```
[01.10.2025 16:14] Deleting PDF ./assets/pdf/2509.25716.pdf.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25085.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25085.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25085.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.23773.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.23773.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.23773.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.23094.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.23094.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.23094.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.21361.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.21361.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.21361.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26604.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26604.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26604.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26574.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26574.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26574.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25134.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25134.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25134.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25082.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25082.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25082.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.24732.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.24732.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.24732.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.23695.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.23695.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.23695.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25248.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25248.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25248.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.23019.
[01.10.2025 16:14] Downloading paper 2509.23019 from http://arxiv.org/pdf/2509.23019v1...
[01.10.2025 16:14] Extracting affiliations from text.
[01.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 2 ] . [ 1 9 1 0 3 2 . 9 0 5 2 : r a Jeongyeon Hwang, Sangdon Park, Jungseul Ok Pohang University of Science and Technology (POSTECH), South Korea {oppurity,sangdon,jungseul}@postech.ac.kr "
[01.10.2025 16:14] Response: ```python
["Pohang University of Science and Technology (POSTECH), South Korea"]
```
[01.10.2025 16:14] Deleting PDF ./assets/pdf/2509.23019.pdf.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26555.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26555.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26555.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.26278.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.26278.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.26278.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25810.
[01.10.2025 16:14] Downloading paper 2509.25810 from http://arxiv.org/pdf/2509.25810v1...
[01.10.2025 16:14] Extracting affiliations from text.
[01.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 3 ] . [ 1 0 1 8 5 2 . 9 0 5 2 : r Learning to Reason as Action Abstractions with Scalable Mid-Training RL Shenao Zhang1,2,, Donghan Yu1, Yihao Feng1, Bowen Jin1,3,, Zhaoran Wang2, John Peebles,, Zirui Wang1, 1Apple, 2Northwestern University, 3UIUC, Work done at Apple, Equal advising Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires mid-training stage. An effective mid-training phase should identify compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), scalable mid-training algorithm. Specifically, we derive sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and"
[01.10.2025 16:14] Response: ```python
["Apple", "Northwestern University", "UIUC"]
```
[01.10.2025 16:14] Deleting PDF ./assets/pdf/2509.25810.pdf.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.25666.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.25666.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.25666.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.24510.
[01.10.2025 16:14] Downloading paper 2509.24510 from http://arxiv.org/pdf/2509.24510v1...
[01.10.2025 16:14] Failed to download and parse paper https://huggingface.co/papers/2509.24510: 'LTChar' object is not iterable
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.22889.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.22889.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.22889.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2509.18538.
[01.10.2025 16:14] Extra JSON file exists (./assets/json/2509.18538.json), skip PDF parsing.
[01.10.2025 16:14] Paper image links file exists (./assets/img_data/2509.18538.json), skip HTML parsing.
[01.10.2025 16:14] Success.
[01.10.2025 16:14] Enriching papers with extra data.
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 0. MCPMark is a comprehensive benchmark for evaluating MCP use in real-world workflows, featuring diverse tasks that require richer interactions with the environment, and reveals that current LLMs perform poorly on these tasks.  					AI-generated summary 				 MCP standardizes how LLMs interact with ext...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 1. BDH, a biologically inspired Large Language Model, combines scale-free network architecture with Hebbian learning to achieve Transformer-like performance while maintaining interpretability.  					AI-generated summary 				 The relationship between computing systems and the brain has served as motivat...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 2. Vision-Zero is a domain-agnostic framework that enhances vision-language models through self-improvement in competitive visual games, using Iterative Self-Play Policy Optimization and achieving state-of-the-art performance without human annotation.  					AI-generated summary 				 Although reinforcem...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 3. Quadrant-based Tuning (Q-Tuning) optimizes both sample and token pruning in supervised fine-tuning of large language models, achieving superior performance with reduced data.  					AI-generated summary 				 As supervised fine-tuning (SFT) evolves from a lightweight post-training step into a compute-...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 4. TruthRL, a reinforcement learning framework, enhances the truthfulness of large language models by balancing accuracy and abstention, significantly reducing hallucinations and improving performance across benchmarks.  					AI-generated summary 				 While large language models (LLMs) have demonstrate...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 5. OceanGym is a benchmark for underwater embodied agents using Multi-modal Large Language Models to address challenges in perception, planning, and adaptability in harsh ocean environments.  					AI-generated summary 				 We introduce OceanGym, the first comprehensive benchmark for ocean underwater em...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 6. VAPO-Thinker-7B enhances multimodal reasoning by anchoring the process to visual information, improving performance on visual tasks while maintaining logical inference.  					AI-generated summary 				 Reasoning has emerged as a pivotal capability in Large Language Models (LLMs). Through Reinforcemen...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 7. LLMs develop visual priors during language pre-training, which can be leveraged for vision tasks with minimal additional data, and these priors are composed of separable perception and reasoning components.  					AI-generated summary 				 Large Language Models (LLMs), despite being trained on text a...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 8. TFPI, a simple adaptation to RLVR, improves performance and reduces token usage by discarding thinking content during training, accelerating RL convergence and achieving higher accuracy with less computational cost.  					AI-generated summary 				 Reinforcement Learning with Verifiable Reward (RLVR)...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 9. DC-VideoGen accelerates video generation by adapting pre-trained diffusion models to a deep compression latent space, reducing inference latency and enabling high-resolution video generation.  					AI-generated summary 				 We introduce DC-VideoGen, a post-training acceleration framework for efficie...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 10. J-Detector, a neural detector with linguistic and LLM-enhanced features, effectively identifies LLM-generated judgments based on scores and candidate content, addressing biases and vulnerabilities in sensitive scenarios.  					AI-generated summary 				 Large Language Model (LLM)-based judgments leve...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 11. Post-training techniques like supervised fine-tuning and reinforcement learning lead to the emergence of specialized attention heads that support structured reasoning, with different training regimes affecting their evolution and performance.  					AI-generated summary 				 The remarkable capabiliti...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 12. VitaBench is a benchmark for evaluating LLM-based agents in complex, real-world interactive tasks using a diverse set of tools and scenarios.  					AI-generated summary 				 As LLM-based agents are increasingly deployed in real-life scenarios, existing benchmarks fail to capture their inherent compl...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 13. DeeptraceReward is a benchmark dataset that annotates human-perceived deepfake traces in videos, used to train multimodal language models for detecting AI-generated videos.  					AI-generated summary 				 Can humans identify AI-generated (fake) videos and provide grounded reasons? While video genera...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 14. dParallel is a method that enhances the parallel decoding of diffusion large language models, significantly reducing decoding steps without compromising performance.  					AI-generated summary 				 Diffusion large language models (dLLMs) have recently drawn considerable attention within the research...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 15. Implicit Multimodal Guidance (IMG) enhances multimodal alignment between diffusion-generated images and prompts without additional data or editing, outperforming existing methods.  					AI-generated summary 				 Ensuring precise multimodal alignment between diffusion-generated images and input promp...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 16. MotionRAG enhances video generation by integrating motion priors from reference videos using a retrieval-augmented framework, improving motion realism with negligible computational overhead.  					AI-generated summary 				 Image-to-video generation has made remarkable progress with the advancements ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 17. Dolphin, an efficient AVSS method, uses a dual-path lightweight video encoder and a lightweight encoder-decoder separator with global-local attention blocks to achieve high separation quality and significant computational efficiency.  					AI-generated summary 				 Audio-visual speech separation (AV...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 18. DA², a zero-shot generalizable and fully end-to-end panoramic depth estimator, addresses challenges in panoramic depth estimation by using a data curation engine and SphereViT to handle spherical distortions, achieving state-of-the-art performance.  					AI-generated summary 				 Panorama has a full...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 19. DeepScientist autonomously conducts scientific discovery through Bayesian Optimization, surpassing human state-of-the-art methods on multiple AI tasks.  					AI-generated summary 				 While previous AI Scientist systems can generate novel findings, they often lack the focus to produce scientifically...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 20. Mem-alpha, a reinforcement learning framework, enhances memory management in large language models through interaction and feedback, improving performance and generalization in long-term information understanding.  					AI-generated summary 				 Large language model (LLM) agents are constrained by l...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 21. Operational safety, measured by OffTopicEval, is a critical issue for LLMs, with most models falling short, but prompt-based steering methods show promise in improving out-of-distribution refusal.  					AI-generated summary 				 Large Language Model (LLM) safety is one of the most pressing challenge...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 22. Online alignment methods like GRPO outperform offline methods like DPO due to better approximation of human-perceived probability distributions, and introducing perceptual biases into offline training can achieve similar performance.  					AI-generated summary 				 Online alignment (e.g., GRPO) is g...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 23. A novel PSRL framework (AttnRL) enhances exploration efficiency in reasoning models by branching from high attention positions and using an adaptive sampling strategy, outperforming prior methods in mathematical reasoning benchmarks.  					AI-generated summary 				 Reinforcement Learning (RL) has sh...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 24. Research explores collaboration in open large language models, identifying diverse motivations and organizational models among developers from various sectors.  					AI-generated summary 				 The proliferation of open large language models (LLMs) is fostering a vibrant ecosystem of research and inno...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 25. VisualOverload is a VQA benchmark that challenges models with simple vision tasks in densely populated scenes, revealing gaps in current VLMs' performance and offering insights into their failure modes.  					AI-generated summary 				 Is basic visual understanding really solved in state-of-the-art V...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 26. Theoretical analysis of reinforcement learning methods in enhancing LLM planning reveals that while RL improves generalization through exploration, policy gradient suffers from diversity collapse, whereas Q-learning maintains diversity and requires careful reward design.  					AI-generated summary 	...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 27. A unified Regression Language Model (RLM) predicts numeric outcomes of code executions, including memory footprint, latency, and neural network performance, across multiple languages and hardware platforms.  					AI-generated summary 				 We study code-to-metric regression: predicting numeric outcom...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 28. InfoAgent, a deep research agent using a custom data synthesis pipeline and search infrastructure, outperforms existing agents by improving tool use and reasoning.  					AI-generated summary 				 Building Large Language Model agents that expand their capabilities by interacting with external tools r...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 29. TTT3R, a test-time training intervention, enhances length generalization in 3D reconstruction by dynamically adjusting memory updates based on alignment confidence, improving global pose estimation and processing efficiency.  					AI-generated summary 				 Modern Recurrent Neural Networks have becom...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 30. VERA is a benchmark for evaluating reasoning ability in voice-interactive systems, revealing significant performance gaps compared to text models and highlighting challenges in real-time interaction.  					AI-generated summary 				 We present Voice Evaluation of Reasoning Ability (VERA), a benchmark...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 31. Ferret-UI Lite, a compact end-to-end GUI agent, achieves competitive performance across diverse platforms using chain-of-thought reasoning, visual tool-use, and reinforcement learning.  					AI-generated summary 				 Developing autonomous agents that effectively interact with Graphic User Interfaces...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 32. ROSA, a lightweight algorithm, enhances multi-turn interactions in LLMs by adapting to user feedback in real-time, improving both task effectiveness and efficiency.  					AI-generated summary 				 Large Language Models (LLMs) employ multi-turn interaction as a fundamental paradigm for completing com...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 33. Muon optimizer outperforms Adam in training LLMs by effectively optimizing associative memory parameters and balancing learning across classes in heavy-tailed data.  					AI-generated summary 				 The Muon optimizer is consistently faster than Adam in training Large Language Models (LLMs), yet the m...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 34. TAU, a benchmark of culturally specific Taiwanese soundmarks, reveals that state-of-the-art large audio-language models underperform compared to local humans, highlighting the need for localized evaluations.  					AI-generated summary 				 Large audio-language models are advancing rapidly, yet most ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 35. EntroPE, a temporally informed framework using entropy-guided dynamic patching, enhances time series forecasting by preserving temporal coherence and improving accuracy and efficiency.  					AI-generated summary 				 Transformer-based models have significantly advanced time series forecasting, with ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 36. A novel technique for predicting APIs and generating code in real-time using a compact reranker outperforms larger models with reduced latency, addressing API leaks and unclear usage intent in enterprise code.  					AI-generated summary 				 Current search techniques are limited to standard RAG quer...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 37. A multilingual document reranker using causal self-attention achieves state-of-the-art performance with a compact architecture.  					AI-generated summary 				 jina-reranker-v3 is a 0.6B parameter multilingual document reranker that introduces a novel last but not late interaction. Unlike late inter...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 38. Graph Neural Network regression models estimate entity-level knowledgeability in Large Language Models to improve active labeling and multi-hop reasoning.  					AI-generated summary 				 Large Language Models (LLMs) have been increasingly studied as neural knowledge bases for supporting knowledge-in...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 39. Dual aDaptive Cache (d²Cache) accelerates diffusion-based large language model inference by selectively updating key-value states and enabling quasi left-to-right generation, improving both speed and quality.  					AI-generated summary 				 Diffusion-based large language models (dLLMs), despite thei...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 40. Research reveals significant discrepancies between reported and effective context window sizes in large language models, impacting accuracy and hallucination rates across different problem types.  					AI-generated summary 				 Large language model (LLM) providers boast big numbers for maximum conte...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 41. SAGANet, a multimodal generative model, enhances audio generation by using object-level segmentation maps, improving control and fidelity in professional Foley workflows.  					AI-generated summary 				 Existing multimodal audio generation models often lack precise user control, which limits their a...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 42. CritPt, a benchmark for evaluating LLMs on research-level physics tasks, reveals significant gaps between current model capabilities and the demands of physics research.  					AI-generated summary 				 While large language models (LLMs) with reasoning capabilities are progressing rapidly on high-sch...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 43. LayerD decomposes raster images into editable layers using iterative extraction and refinement, outperforming existing methods and enabling use with advanced image generators.  					AI-generated summary 				 Designers craft and edit graphic designs in a layer representation, but layer-based editing ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 44. MANI-Pure, a magnitude-adaptive purification framework using diffusion models, effectively suppresses high-frequency adversarial perturbations while preserving low-frequency content, enhancing robust accuracy.  					AI-generated summary 				 Adversarial purification with diffusion models has emerged...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 45. A timeline of the evolution of deep residual learning, a key advancement in neural network architecture.  					AI-generated summary 				 Modern AI is based on deep artificial neural networks (NNs). As of 2025, the most cited scientific article of the 21st century is an NN paper on deep residual lear...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 46. TimeTic is a transferability estimation framework that predicts the performance of time series foundation models after fine-tuning on unseen datasets, using tabular foundation models and entropy evolution for model characterization.  					AI-generated summary 				 Time series foundation models (TSFM...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 47. A new benchmark, BUILD-BENCH, and an LLM-based agent, OSS-BUILD-AGENT, address the complexities of compiling diverse open-source software projects.  					AI-generated summary 				 Automatically compiling open-source software (OSS) projects is a vital, labor-intensive, and complex task, which makes i...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 48. The Bias-Inversion Rewriting Attack (BIRA) effectively evades watermarking in large language models by suppressing specific logits, highlighting a significant vulnerability in watermarking techniques.  					AI-generated summary 				 Watermarking for large language models (LLMs) embeds a statistical ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 49. Stable Cinemetrics introduces a structured evaluation framework for professional video generation, using taxonomies to assess models across specific filmmaking controls.  					AI-generated summary 				 Recent advances in video generation have enabled high-fidelity video synthesis from user provided ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 50. ProfVLM, a compact vision-language model, uses generative reasoning to estimate skill proficiency and generate expert feedback from multi-view videos, outperforming existing methods with fewer parameters and faster training.  					AI-generated summary 				 Existing approaches to skill proficiency es...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 51. Mid-training with action abstractions enhances reinforcement learning in large language models, improving performance and convergence in code generation tasks.  					AI-generated summary 				 Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 52. NuRL, a nudging method using self-generated hints, enhances the upper limit of LLM reasoning in online reinforcement learning by enabling learning from previously unsolvable problems.  					AI-generated summary 				 Current online reinforcement learning (RL) algorithms like GRPO share a key limitati...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 53. Test-time training (TTT) improves performance by allowing foundation models to specialize on test tasks, reducing in-distribution test error through a mechanism of focusing on relevant concepts.  					AI-generated summary 				 Recent empirical studies have explored the idea of continuing to train a ...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 54. The Convolutional Set Transformer (CST) processes image sets directly, combining feature extraction and contextual modeling for improved performance in set classification and anomaly detection, with compatibility for CNN explainability methods.  					AI-generated summary 				 We introduce the Convol...
[01.10.2025 16:14] ********************************************************************************
[01.10.2025 16:14] Abstract 55. A geometry-aware two-stage framework for intelligent image editing effectively removes objects and their causal visual artifacts by decoupling geometry removal and appearance rendering.  					AI-generated summary 				 Towards intelligent image editing, object removal should eliminate both the target...
[01.10.2025 16:14] Read previous papers.
[01.10.2025 16:14] Generating reviews via LLM API.
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#agi", "#agents", "#survey", "#benchmark"], "emoji": "🧪", "ru": {"title": "MCPMark: бенчмарк, который показал слабость LLM в реальных рабочих сценариях", "desc": "MCPMark — это новый комплексный бенчмарк для оценки использования MCP (Model Context Protocol) в реальных рабочих процес
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#graphs", "#multimodal", "#architecture", "#reasoning", "#interpretability"], "emoji": "🧠", "ru": {"title": "BDH: Интерпретируемая мощь биологически вдохновлённых сетей", "desc": "BDH — это новая архитектура LLM, вдохновлённая биологическими сетями, которая сочетает в себе масштабно
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#optimization", "#games", "#cv", "#training", "#rl"], "emoji": "🎮", "ru": {"title": "Самообучение VLM через визуальные игры без разметки", "desc": "Vision-Zero — это фреймворк для самосовершенствования vision-language моделей через соревновательные визуа
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#data", "#training"], "emoji": "✂️", "ru": {"title": "Умная обрезка данных: как обучать LLM эффективнее с минимальными ресурсами", "desc": "Статья представляет Q-Tuning — новый метод оптимизации supervised fine-tuning для больших языковых моделей, кото
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#rlhf", "#hallucinations", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "🎯", "ru": {"title": "Обучение LLM говорить правду через воздержание от ответа", "desc": "В статье представлен TruthRL — фреймворк на основе reinforcement learning для повышения правдивости больш
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#games", "#transfer_learning", "#agents", "#benchmark", "#multimodal"], "emoji": "🌊", "ru": {"title": "OceanGym: Тестовая площадка для AI-агентов в неизведанных глубинах океана", "desc": "В статье представлен OceanGym — первый комплексный бенчмарк для подводных embodied-агентов, раб
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#cv", "#multimodal", "#reasoning"], "emoji": "👁️", "ru": {"title": "Не забывай смотреть: как научить AI рассуждать без потери визуального восприятия", "desc": "Исследование выявляет проблему \"визуального забывания\" в Vision-Language Models: при длительном расс
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark", "#alignment", "#dataset", "#transfer_learning"], "emoji": "👁️", "ru": {"title": "Визуальные приоры из текста: как LLM учатся видеть без изображений", "desc": "Исследование показывает, что большие языковые модели (LLM) неожиданно развивают ви
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#training", "#long_context", "#rl", "#rlhf", "#optimization"], "emoji": "✂️", "ru": {"title": "Отсечение рассуждений для эффективного обучения с подкреплением", "desc": "В статье представлен метод TFPI для оптимизации обучения с подкреплением и верифицируемым вознаграждением (RLVR).
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#inference", "#video", "#optimization", "#diffusion", "#architecture", "#training"], "emoji": "⚡", "ru": {"title": "Ускорение генерации видео через глубокое сжатие латентного пространства", "desc": "DC-VideoGen — это фреймворк для ускорения генерации видео, который адаптирует предоб
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#hallucinations", "#data", "#ethics", "#dataset", "#interpretability", "#architecture", "#multimodal"], "emoji": "⚖️", "ru": {"title": "Детектор оценок от LLM: обнаружение искусственных суждений по баллам", "desc": "В статье формализуется задача обнаружения суждений, сгенерированных
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#reasoning", "#architecture", "#training"], "emoji": "🧠", "ru": {"title": "Специализированные головы внимания: ключ к рассуждениям LLM", "desc": "Исследование показывает, что post-training техники, такие как supervised fine-tuning и reinforcemen
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#benchmark", "#games", "#survey"], "emoji": "🧭", "ru": {"title": "VitaBench: жизненный экзамен для AI-агентов в реальных сценариях", "desc": "VitaBench — это новый бенчмарк для оценки LLM-агентов в сложных интерактивных задачах, приближенных к реальной жизни
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#video", "#multimodal", "#benchmark", "#dataset", "#interpretability"], "emoji": "🔍", "ru": {"title": "Учим модели находить следы дипфейков глазами человека", "desc": "Исследователи создали датасет DeeptraceReward с 4.3 тысячами детальных аннотаций искусстве
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#inference", "#optimization", "#benchmark", "#diffusion", "#open_source", "#training"], "emoji": "⚡", "ru": {"title": "Параллельное декодирование диффузионных LLM с 10-кратным ускорением", "desc": "Статья представляет dParallel — метод для ускорения параллельного декодирования в диф
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#multimodal", "#alignment", "#cv", "#diffusion"], "emoji": "🎯", "ru": {"title": "Неявное управление для точного соответствия изображений и текста", "desc": "Статья представляет метод Implicit Multimodal Guidance (IMG) для улучшения согласованности между сгенерированными диффузионным
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#transfer_learning", "#video", "#rag", "#diffusion", "#multimodal"], "emoji": "🎬", "ru": {"title": "Улучшение реалистичности движения в видео через retrieval motion-паттернов", "desc": "Статья представляет MotionRAG — фреймворк для генерации видео, который использует retrieval-augme
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#video", "#benchmark", "#audio", "#inference"], "emoji": "🐬", "ru": {"title": "Dolphin: Быстрая и эффективная сепарация речи с помощью визуальных подсказок", "desc": "Dolphin - это эффективный метод аудио-визуальной сепарации речи (AVSS), который использует визуальные подсказки для 
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#3d", "#optimization", "#data", "#dataset", "#benchmark", "#open_source"], "emoji": "🌐", "ru": {"title": "Оценка глубины панорам без дистилляции и с нулевым обучением", "desc": "Статья представляет DA² — систему для оценки глубины на панорамных изображениях с полным обзором 360×180 
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#science", "#agents", "#open_source", "#rl"], "emoji": "🔬", "ru": {"title": "AI-учёный превосходит человеческие достижения через автономное научное исследование", "desc": "DeepScientist - это система, которая автономно проводит научные исследования, используя байесовскую оптимизацию
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#rl", "#optimization", "#agents", "#long_context", "#dataset", "#training"], "emoji": "🧠", "ru": {"title": "Обучение LLM управлять памятью через reinforcement learning", "desc": "Статья представляет Mem-alpha — фреймворк на основе reinforcement learning для улучшения управления памя
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#security", "#alignment", "#training", "#ethics", "#agents", "#benchmark"], "emoji": "🚦", "ru": {"title": "Операционная безопасность: научить LLM отказываться от неподходящих запросов", "desc": "Исследователи представили концепцию операционной безопасности — способности LLM корректн
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#alignment", "#training", "#rl", "#rlhf"], "emoji": "🧠", "ru": {"title": "Человеческое восприятие вероятностей как ключ к эффективному обучению LLM", "desc": "Исследователи объясняют, почему онлайн методы выравнивания (GRPO) работают лучше оффлайн методов (DPO), опираясь на теорию п
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#math", "#optimization", "#reasoning", "#training", "#rl"], "emoji": "🌳", "ru": {"title": "Умное ветвление через внимание для обучения рассуждениям", "desc": "Исследователи предложили новый подход AttnRL для улучшения Process-Supervised Reinforcement Learning при обучении LLM матема
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#benchmark", "#multilingual"], "emoji": "🤝", "ru": {"title": "Экосистема открытых LLM: многообразие моделей сотрудничества и мотиваций", "desc": "Исследование изучает методы совместной работы при разработке открытых LLM на основе интервью с разработчиками
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#interpretability", "#reasoning", "#benchmark", "#dataset", "#cv"], "emoji": "🎨", "ru": {"title": "VisualOverload: когда сложные сцены ставят VLM в тупик", "desc": "Исследователи представили бенчмарк VisualOverload для оценки vision-language моделей на задачах визуального понимания 
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#benchmark", "#training", "#rl"], "emoji": "🗺️", "ru": {"title": "Почему Q-learning лучше policy gradient для планирования в LLM", "desc": "Исследование теоретически анализирует, как методы reinforcement learning улучшают способности LLM к планированию
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#games", "#data", "#optimization", "#training", "#dataset", "#multilingual", "#small_models"], "emoji": "📊", "ru": {"title": "Единая языковая модель для предсказания производительности кода", "desc": "В статье представлена единая Regression Language Model (RLM), которая предсказывае
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#agents", "#training", "#open_source", "#data"], "emoji": "🔍", "ru": {"title": "InfoAgent: Агент глубокого исследования с продвинутым поиском", "desc": "В статье представлен InfoAgent — агент на основе LLM для глубокого исследования информации, который используе
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#3d", "#training", "#optimization", "#long_context"], "emoji": "🔄", "ru": {"title": "Адаптивное обучение на лету для 3D-реконструкции без границ", "desc": "Статья представляет TTT3R — метод test-time training для улучшения 3D-реконструкции с помощью рекуррентных нейросетей. Проблема
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark", "#architecture", "#long_context"], "emoji": "🎤", "ru": {"title": "Голосовые AI-помощники сильно отстают в способности рассуждать", "desc": "VERA — это бенчмарк для оценки способности к рассуждению в голосовых интерактивных системах в условия
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#inference", "#agents", "#reasoning", "#small_models", "#synthetic", "#data", "#dataset", "#rl"], "emoji": "📱", "ru": {"title": "Компактный AI-агент для управления интерфейсами на устройстве", "desc": "Ferret-UI Lite — это компактная модель размером 3B параметров для автономного вза
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#alignment", "#training", "#benchmark", "#rlhf", "#optimization"], "emoji": "🎯", "ru": {"title": "Адаптация AI к предпочтениям пользователя прямо во время диалога", "desc": "Статья представляет ROSA — лёгкий алгоритм для улучшения многоходовых диалогов с LLM. Проблема в том, что мод
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#math", "#training", "#optimization"], "emoji": "🚀", "ru": {"title": "Muon: новый лидер в оптимизации LLM", "desc": "В статье рассматривается новый оптимизатор Muon, который превосходит Adam при обучении больших языковых моделей (LLM). Исследование показывает, что Muon лучше справля
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#audio", "#benchmark", "#multimodal"], "emoji": "🔔", "ru": {"title": "Культурные звуки как тест для аудио-AI: модели не слышат локальный контекст", "desc": "Исследователи создали бенчмарк TAU для оценки способности больших аудио-языковых моделей распознавать
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#training", "#long_context", "#benchmark", "#optimization", "#data", "#architecture"], "emoji": "🔀", "ru": {"title": "Динамическое разбиение временных рядов по энтропии для точного прогнозирования", "desc": "Статья представляет EntroPE — новый подход к прогнозированию временных рядо
[01.10.2025 16:14] Querying the API.
[01.10.2025 16:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel technique for predicting APIs and generating code in real-time using a compact reranker outperforms larger models with reduced latency, addressing API leaks and unclear usage intent in enterprise code.  					AI-generated summary 				 Current search techniques are limited to standard RAG query-document applications. In this paper, we propose a novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing a new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop a comprehensive post-training pipeline that optimizes a compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform a much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models.
[01.10.2025 16:14] Response: ```json
{
  "desc": "Статья представляет новый метод предсказания API и генерации кода в реальном времени для автодополнения и AI-агентов. Исследователи решают проблему утечки API в существующих датасетах, создав новый датасет на основе реального корпоративного кода ServiceNow. Разработанный компактный reranker размером 0.6B параметров достигает 87.86% точности поиска top-40 и обучен через синтетическую генерацию данных, supervised fine-tuning и reinforcement learning. Модель превосходит по качеству более крупную 8B модель при этом работая в 2.5 раза быстрее, что критично для enterprise-приложений.",
  "emoji": "🔍",
  "title": "Компактный reranker для точного предсказания API и быстрой генерации кода"
}
```
[01.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel technique for predicting APIs and generating code in real-time using a compact reranker outperforms larger models with reduced latency, addressing API leaks and unclear usage intent in enterprise code.  					AI-generated summary 				 Current search techniques are limited to standard RAG query-document applications. In this paper, we propose a novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing a new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop a comprehensive post-training pipeline that optimizes a compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform a much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models."

[01.10.2025 16:14] Response: ```python
['DATASET', 'DATA', 'RAG', 'TRAINING', 'RL']
```
[01.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel technique for predicting APIs and generating code in real-time using a compact reranker outperforms larger models with reduced latency, addressing API leaks and unclear usage intent in enterprise code.  					AI-generated summary 				 Current search techniques are limited to standard RAG query-document applications. In this paper, we propose a novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing a new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop a comprehensive post-training pipeline that optimizes a compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform a much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models."

[01.10.2025 16:14] Response: ```python
['OPTIMIZATION', 'LEAKAGE', 'SYNTHETIC']
```
[01.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new method for predicting application programming interfaces (APIs) and generating code in real-time using a compact reranker model. The technique improves upon existing methods by addressing issues like API leaks and ambiguous usage intent in enterprise code, utilizing a specially created dataset from real-world examples. The proposed model achieves high retrieval accuracy and significantly reduces latency compared to larger models, making it suitable for real-time applications. By employing a post-training pipeline that includes synthetic data generation and reinforcement learning, the compact reranker demonstrates superior performance while being computationally efficient.","title":"Real-Time API Prediction with Compact Reranker"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new method for predicting application programming interfaces (APIs) and generating code in real-time using a compact reranker model. The technique improves upon existing methods by addressing issues like API leaks and ambiguous usage intent in enterprise code, utilizing a specially created dataset from real-world examples. The proposed model achieves high retrieval accuracy and significantly reduces latency compared to larger models, making it suitable for real-time applications. By employing a post-training pipeline that includes synthetic data generation and reinforcement learning, the compact reranker demonstrates superior performance while being computationally efficient.', title='Real-Time API Prediction with Compact Reranker'))
[01.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新技术，用于实时预测API并生成代码，使用紧凑的重排序器，其性能优于更大的模型且延迟更低。我们通过构建一个新的数据集，解决了当前代码基准数据集中API泄漏和不明确使用意图的问题。该方法在评估中显示出87.86%的前40个检索准确率，能够提供成功生成代码所需的API上下文。我们还开发了一个全面的后训练管道，通过合成数据集生成、监督微调和强化学习来优化紧凑的重排序器，从而在不增加计算开销的情况下实现实时预测。","title":"实时API预测与代码生成的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新技术，用于实时预测API并生成代码，使用紧凑的重排序器，其性能优于更大的模型且延迟更低。我们通过构建一个新的数据集，解决了当前代码基准数据集中API泄漏和不明确使用意图的问题。该方法在评估中显示出87.86%的前40个检索准确率，能够提供成功生成代码所需的API上下文。我们还开发了一个全面的后训练管道，通过合成数据集生成、监督微调和强化学习来优化紧凑的重排序器，从而在不增加计算开销的情况下实现实时预测。', title='实时API预测与代码生成的新突破'))
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#machine_translation", "#multilingual", "#architecture"], "emoji": "🔄", "ru": {"title": "Компактный ранжировщик с перекрёстным вниманием побеждает громоздкие модели", "desc": "Представлена многоязычная модель jina-reranker-v3 с 0.6 миллиардами параметров для переранжирования докумен
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#data", "#reasoning", "#training", "#dataset", "#agents", "#graphs", "#multimodal"], "emoji": "🕸️", "ru": {"title": "Граф знаний LLM: соседи знают одинаково", "desc": "Исследователи изучили структурную организацию знаний в больших языковых моделях, представив их в виде графа. Оказал
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization", "#diffusion", "#architecture"], "emoji": "⚡", "ru": {"title": "Ускорение диффузионных языковых моделей через адаптивное кэширование", "desc": "Статья представляет d²Cache — метод ускорения инференса диффузионных языковых моделей без дополни
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#long_context", "#training", "#hallucinations", "#benchmark", "#data"], "emoji": "📉", "ru": {"title": "Контекстное окно LLM: обещания vs реальность", "desc": "Исследование показывает существенные расхождения между заявленным и реальным эффективным размером контекстного окна в больши
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#audio", "#synthetic", "#games", "#benchmark", "#dataset", "#multimodal"], "emoji": "🎬", "ru": {"title": "Точный контроль звука через сегментацию объектов", "desc": "В статье представлена SAGANet — новая мультимодальная генеративная модель для создания звука на основе видео с исполь
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#science", "#reasoning", "#benchmark", "#dataset"], "emoji": "⚛️", "ru": {"title": "Физики проверили LLM на реальных исследовательских задачах — и модели провалились", "desc": "Исследователи создали бенчмарк CritPt для оценки способностей LLM решать исследовательские задачи уровня н
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "🎨", "ru": {"title": "Превращаем картинку обратно в слои для редактирования", "desc": "LayerD — это метод для декомпозиции растровых графических изображений на отдельные редактируемые слои. Система работает итеративно, последовательно извлекая слои переднего п
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#training", "#diffusion", "#cv", "#security"], "emoji": "🔊", "ru": {"title": "Адаптивная очистка от adversarial атак через частотный анализ", "desc": "Статья представляет MANI-Pure — новый метод защиты от adversarial атак с использованием диффузионных моделей. Авторы обнаружили, что
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#architecture"], "emoji": "🔗", "ru": {"title": "История глубокого остаточного обучения: кто изобрёл residual connections", "desc": "Статья представляет хронологию развития глубокого остаточного обучения (deep residual learning) — ключевого прорыва в архитектуре нейронных сетей. Авто
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#training", "#benchmark", "#transfer_learning", "#dataset"], "emoji": "⏰", "ru": {"title": "Предсказание эффективности time series моделей без дообучения", "desc": "TimeTic — это фреймворк для оценки переносимости foundation моделей временных рядов, который предсказывает их производ
[01.10.2025 16:14] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#open_source", "#security"], "emoji": "🔨", "ru": {"title": "LLM-агент учится компилировать сложные open-source проекты", "desc": "Исследователи представили новый бенчмарк BUILD-BENCH для оценки способности LLM-агентов автоматически компилировать разнообразны
[01.10.2025 16:14] Querying the API.
[01.10.2025 16:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The Bias-Inversion Rewriting Attack (BIRA) effectively evades watermarking in large language models by suppressing specific logits, highlighting a significant vulnerability in watermarking techniques.  					AI-generated summary 				 Watermarking for large language models (LLMs) embeds a statistical signal during generation to enable detection of model-produced text. While watermarking has proven effective in benign settings, its robustness under adversarial evasion remains contested. To advance a rigorous understanding and evaluation of such vulnerabilities, we propose the Bias-Inversion Rewriting Attack (BIRA), which is theoretically motivated and model-agnostic. BIRA weakens the watermark signal by suppressing the logits of likely watermarked tokens during LLM-based rewriting, without any knowledge of the underlying watermarking scheme. Across recent watermarking methods, BIRA achieves over 99\% evasion while preserving the semantic content of the original text. Beyond demonstrating an attack, our results reveal a systematic vulnerability, emphasizing the need for stress testing and robust defenses.
[01.10.2025 16:14] Response: ```json
{
  "title": "Атака переписывания текста обходит водяные знаки в LLM",
  "desc": "Статья представляет атаку BIRA (Bias-Inversion Rewriting Attack), которая эффективно обходит водяные знаки в больших языковых моделях. Метод работает путём подавления логитов токенов, которые вероятно содержат водяной знак, во время переписывания текста с помощью LLM. BIRA достигает более 99% успешности обхода водяных знаков при сохранении семантического содержания текста, не требуя знания конкретной схемы водяного знака. Результаты выявляют системную уязвимость современных методов водяных знаков и подчёркивают необходимость разработки более устойчивых защитных механизмов.",
  "emoji": "💧"
}
```
[01.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Bias-Inversion Rewriting Attack (BIRA) effectively evades watermarking in large language models by suppressing specific logits, highlighting a significant vulnerability in watermarking techniques.  					AI-generated summary 				 Watermarking for large language models (LLMs) embeds a statistical signal during generation to enable detection of model-produced text. While watermarking has proven effective in benign settings, its robustness under adversarial evasion remains contested. To advance a rigorous understanding and evaluation of such vulnerabilities, we propose the Bias-Inversion Rewriting Attack (BIRA), which is theoretically motivated and model-agnostic. BIRA weakens the watermark signal by suppressing the logits of likely watermarked tokens during LLM-based rewriting, without any knowledge of the underlying watermarking scheme. Across recent watermarking methods, BIRA achieves over 99\% evasion while preserving the semantic content of the original text. Beyond demonstrating an attack, our results reveal a systematic vulnerability, emphasizing the need for stress testing and robust defenses."

[01.10.2025 16:14] Response: ```python
['BENCHMARK', 'INFERENCE']
```
[01.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Bias-Inversion Rewriting Attack (BIRA) effectively evades watermarking in large language models by suppressing specific logits, highlighting a significant vulnerability in watermarking techniques.  					AI-generated summary 				 Watermarking for large language models (LLMs) embeds a statistical signal during generation to enable detection of model-produced text. While watermarking has proven effective in benign settings, its robustness under adversarial evasion remains contested. To advance a rigorous understanding and evaluation of such vulnerabilities, we propose the Bias-Inversion Rewriting Attack (BIRA), which is theoretically motivated and model-agnostic. BIRA weakens the watermark signal by suppressing the logits of likely watermarked tokens during LLM-based rewriting, without any knowledge of the underlying watermarking scheme. Across recent watermarking methods, BIRA achieves over 99\% evasion while preserving the semantic content of the original text. Beyond demonstrating an attack, our results reveal a systematic vulnerability, emphasizing the need for stress testing and robust defenses."

[01.10.2025 16:14] Response: ```python
['SECURITY']
```
[01.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces the Bias-Inversion Rewriting Attack (BIRA), a method that successfully bypasses watermarking in large language models (LLMs) by targeting and suppressing specific logits associated with watermarked tokens. This attack highlights a critical weakness in current watermarking techniques, which are designed to identify AI-generated text. BIRA operates without needing to know the details of the watermarking scheme, making it a versatile and powerful adversarial strategy. The findings indicate that while watermarking can be effective, it is not robust against sophisticated evasion tactics like BIRA, underscoring the importance of developing stronger defenses.","title":"BIRA: Unmasking Vulnerabilities in LLM Watermarking"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces the Bias-Inversion Rewriting Attack (BIRA), a method that successfully bypasses watermarking in large language models (LLMs) by targeting and suppressing specific logits associated with watermarked tokens. This attack highlights a critical weakness in current watermarking techniques, which are designed to identify AI-generated text. BIRA operates without needing to know the details of the watermarking scheme, making it a versatile and powerful adversarial strategy. The findings indicate that while watermarking can be effective, it is not robust against sophisticated evasion tactics like BIRA, underscoring the importance of developing stronger defenses.', title='BIRA: Unmasking Vulnerabilities in LLM Watermarking'))
[01.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为偏差反转重写攻击（BIRA）的新方法，能够有效规避大型语言模型中的水印技术。BIRA通过抑制特定的logits，削弱了水印信号，从而在重写过程中避免被检测。该方法不依赖于具体的水印方案，具有广泛的适用性。研究结果表明，BIRA在多种水印方法下实现了超过99%的规避率，同时保持了原始文本的语义内容，揭示了水印技术的系统性脆弱性。","title":"揭示水印技术的脆弱性：偏差反转重写攻击"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为偏差反转重写攻击（BIRA）的新方法，能够有效规避大型语言模型中的水印技术。BIRA通过抑制特定的logits，削弱了水印信号，从而在重写过程中避免被检测。该方法不依赖于具体的水印方案，具有广泛的适用性。研究结果表明，BIRA在多种水印方法下实现了超过99%的规避率，同时保持了原始文本的语义内容，揭示了水印技术的系统性脆弱性。', title='揭示水印技术的脆弱性：偏差反转重写攻击'))
[01.10.2025 16:15] Using data from previous issue: {"categories": ["#benchmark", "#games", "#video", "#optimization"], "emoji": "🎬", "ru": {"title": "Профессиональная оценка видео-генерации через призму кинематографа", "desc": "Исследователи представили Stable Cinemetrics — фреймворк для оценки качества генерации профессионального видео с помощью AI
[01.10.2025 16:15] Using data from previous issue: {"categories": ["#multimodal", "#training", "#interpretability", "#optimization", "#reasoning", "#cv"], "emoji": "🎯", "ru": {"title": "Компактная VLM для оценки навыков с объяснениями", "desc": "ProfVLM — это компактная vision-language модель, которая оценивает уровень владения навыками и генерирует
[01.10.2025 16:15] Querying the API.
[01.10.2025 16:15] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Mid-training with action abstractions enhances reinforcement learning in large language models, improving performance and convergence in code generation tasks.  					AI-generated summary 				 Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a mid-training stage. An effective mid-training phase should identify a compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), a scalable mid-training algorithm. Specifically, we derive a sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and Codeforces.
[01.10.2025 16:15] Response: ```json
{
  "title": "Абстракции действий ускоряют обучение LLM писать код",
  "desc": "Исследователи показали, что промежуточная стадия обучения (mid-training) критически важна для эффективного применения reinforcement learning к большим языковым моделям. Они теоретически доказали, что mid-training должен выделять компактное подмножество полезных действий и формировать пространство абстракций действий, а не работать с примитивными действиями. На основе этого анализа был разработан алгоритм RA3, который итеративно находит темпорально-согласованные латентные структуры через RL и дообучается на полученных данных. Эксперименты на задачах генерации кода показали улучшение на 8 и 4 пункта на бенчмарках HumanEval и MBPP, а также более быструю сходимость при обучении с подкреплением.",
  "emoji": "🎯"
}
```
[01.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mid-training with action abstractions enhances reinforcement learning in large language models, improving performance and convergence in code generation tasks.  					AI-generated summary 				 Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a mid-training stage. An effective mid-training phase should identify a compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), a scalable mid-training algorithm. Specifically, we derive a sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and Codeforces."

[01.10.2025 16:15] Response: ```python
['RL', 'RLHF', 'TRAINING']
```
[01.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mid-training with action abstractions enhances reinforcement learning in large language models, improving performance and convergence in code generation tasks.  					AI-generated summary 				 Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a mid-training stage. An effective mid-training phase should identify a compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), a scalable mid-training algorithm. Specifically, we derive a sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and Codeforces."

[01.10.2025 16:15] Response: ```python
["REASONING", "OPTIMIZATION", "GAMES"]
```
[01.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses how mid-training with action abstractions can improve reinforcement learning (RL) in large language models, particularly for code generation tasks. It introduces a new algorithm called Reasoning as Action Abstractions (RA3), which optimizes the selection of useful actions during a mid-training phase. The authors provide a theoretical framework that shows how this mid-training process can reduce errors in value approximation and enhance RL convergence. Experiments demonstrate that RA3 significantly boosts performance and speeds up learning in various code generation benchmarks.","title":"Unlocking RL Potential with Mid-Training Action Abstractions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses how mid-training with action abstractions can improve reinforcement learning (RL) in large language models, particularly for code generation tasks. It introduces a new algorithm called Reasoning as Action Abstractions (RA3), which optimizes the selection of useful actions during a mid-training phase. The authors provide a theoretical framework that shows how this mid-training process can reduce errors in value approximation and enhance RL convergence. Experiments demonstrate that RA3 significantly boosts performance and speeds up learning in various code generation benchmarks.', title='Unlocking RL Potential with Mid-Training Action Abstractions'))
[01.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了在大型语言模型中使用中期训练与动作抽象的结合，以增强强化学习的效果，特别是在代码生成任务中。中期训练阶段通过识别一组紧凑的有用动作，促进了快速选择，并通过在线强化学习优化了决策过程。研究表明，中期训练的有效性受两个关键因素的影响：剪枝效率和对强化学习收敛性的影响。基于这些发现，提出了一种名为Reasoning as Action Abstractions（RA3）的可扩展中期训练算法，实验结果显示该方法在多个代码生成任务中显著提高了性能。","title":"中期训练与动作抽象提升强化学习效果"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了在大型语言模型中使用中期训练与动作抽象的结合，以增强强化学习的效果，特别是在代码生成任务中。中期训练阶段通过识别一组紧凑的有用动作，促进了快速选择，并通过在线强化学习优化了决策过程。研究表明，中期训练的有效性受两个关键因素的影响：剪枝效率和对强化学习收敛性的影响。基于这些发现，提出了一种名为Reasoning as Action Abstractions（RA3）的可扩展中期训练算法，实验结果显示该方法在多个代码生成任务中显著提高了性能。', title='中期训练与动作抽象提升强化学习效果'))
[01.10.2025 16:15] Using data from previous issue: {"categories": ["#training", "#rlhf", "#reasoning", "#optimization", "#benchmark", "#rl"], "emoji": "💡", "ru": {"title": "Подсказки себе: как научить LLM решать невозможные задачи", "desc": "Статья представляет метод NuRL, который помогает языковым моделям учиться на задачах, которые они раньше не м
[01.10.2025 16:15] Using data from previous issue: {"categories": ["#optimization", "#training"], "emoji": "🎯", "ru": {"title": "Специализация после обобщения: как дообучение на тесте улучшает модели", "desc": "Исследование объясняет, почему test-time training (TTT) — дообучение модели непосредственно на тестовой задаче — повышает качество работы fo
[01.10.2025 16:15] Using data from previous issue: {"categories": ["#training", "#transfer_learning", "#interpretability", "#games", "#open_source", "#dataset", "#cv", "#architecture"], "emoji": "🎴", "ru": {"title": "Обработка множеств изображений без промежуточных эмбеддингов", "desc": "В статье представлен Convolutional Set Transformer (CST) — нов
[01.10.2025 16:15] Using data from previous issue: {"categories": ["#cv", "#3d", "#benchmark", "#optimization"], "emoji": "🎭", "ru": {"title": "Геометрически-осознанное удаление объектов и их теней", "desc": "Статья представляет новый подход к удалению объектов с изображений, который учитывает не только сам объект, но и его визуальные эффекты, такие
[01.10.2025 16:15] Renaming data file.
[01.10.2025 16:15] Renaming previous data. hf_papers.json to ./d/2025-10-01.json
[01.10.2025 16:15] Saving new data file.
[01.10.2025 16:15] Generating page.
[01.10.2025 16:15] Renaming previous page.
[01.10.2025 16:15] Renaming previous data. index.html to ./d/2025-10-01.html
[01.10.2025 16:15] Writing result.
[01.10.2025 16:15] Renaming log file.
[01.10.2025 16:15] Renaming previous data. log.txt to ./logs/2025-10-01_last_log.txt
