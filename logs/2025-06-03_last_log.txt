[03.06.2025 06:20] Read previous papers.
[03.06.2025 06:20] Generating top page (month).
[03.06.2025 06:20] Writing top page (month).
[03.06.2025 07:12] Read previous papers.
[03.06.2025 07:12] Get feed.
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01939
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01049
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01943
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00539
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24846
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01853
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00411
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23001
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23907
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01881
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00577
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24625
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00996
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24760
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23977
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23504
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23059
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01413
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00643
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00338
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23590
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24452
[03.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00385
[03.06.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.24842
[03.06.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.24298
[03.06.2025 07:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.06.2025 07:12] No deleted papers detected.
[03.06.2025 07:12] Downloading and parsing papers (pdf, html). Total: 25.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.01939.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.01939.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.01939.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.01049.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.01049.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.01049.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.01943.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.01943.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.01943.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.00539.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.00539.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.00539.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.24846.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.24846.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.24846.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.01853.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.01853.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.01853.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.00411.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.00411.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.00411.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23001.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.23001.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.23001.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23907.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.23907.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.23907.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.01881.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.01881.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.01881.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.00577.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.00577.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.00577.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.24625.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.24625.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.24625.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.00996.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.00996.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.00996.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.24760.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.24760.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.24760.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23977.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.23977.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.23977.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23504.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.23504.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.23504.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23059.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.23059.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.23059.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.01413.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.01413.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.01413.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.00643.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.00643.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.00643.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.00338.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.00338.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.00338.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23590.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.23590.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.23590.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.24452.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2505.24452.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2505.24452.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.00385.
[03.06.2025 07:12] Extra JSON file exists (./assets/json/2506.00385.json), skip PDF parsing.
[03.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.00385.json), skip HTML parsing.
[03.06.2025 07:12] Success.
[03.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.24842.
[03.06.2025 07:12] Downloading paper 2505.24842 from http://arxiv.org/pdf/2505.24842v1...
[03.06.2025 07:13] Extracting affiliations from text.
[03.06.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 3 ] . [ 1 2 4 8 4 2 . 5 0 5 2 : r a Harsh Chaudhari1,2, Jamie Hayes2*, Matthew Jagielski2*, Ilia Shumailov2*, Milad Nasr2 and Alina Oprea1 *Equal Contribution, 1Northeastern University, 2Google DeepMind Model distillation has become an essential technique for creating smaller, deployable language models that retain the capabilities of larger systems. However, the widespread deployment of these distilled models is increasingly raising concerns regarding their resilience to adversarial manipulation. This paper investigates the vulnerability of distilled language models to adversarial injection of biased content during training. More broadly, we demonstrate that an adversary can inject subtle biases into teacher model through minimal data poisoning during training, which not only propagates to the distilled student model but also becomes significantly amplified. We propose two distinct modes of propagation: Untargeted Propagation, where adversarial bias affects multiple tasks, and Targeted Propagation, which focuses on specific task while maintaining normal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning rate), the student model generates biased responses 76.9% of the time in targeted propagation scenariohigher than the 69.4% observed in the teacher model. In case of Untargeted propagation, the adversarial bias appears 6.0 29.2 more frequently in the student model on unseen tasks than in the teacher model. We validate these findings across six bias types (including targeted advertisements, phishing links, narrative manipulations, and insecure coding practices), various distillation methods, and different data modalities spanning both text and code generation. Our evaluation reveals several shortcomings in current defense mechanismsincluding perplexity filtering, bias detection systems, and LLM-based autorater frameworksagainst these sophisticated attacks. These results expose significant security and trustworthiness vulnerabilities in disti"
[03.06.2025 07:13] Response: ```python
["Northeastern University", "Google DeepMind"]
```
[03.06.2025 07:13] Deleting PDF ./assets/pdf/2505.24842.pdf.
[03.06.2025 07:13] Success.
[03.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2505.24298.
[03.06.2025 07:13] Downloading paper 2505.24298 from http://arxiv.org/pdf/2505.24298v1...
[03.06.2025 07:13] Extracting affiliations from text.
[03.06.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 3 ] . [ 1 8 9 2 4 2 . 5 0 5 2 : r AREAL: Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning Wei Fu12, Jiaxuan Gao12, Xujie Shen2, Chen Zhu2, Zhiyu Mei12, Chuyi He2, Shusheng Xu12, Guo Wei2, Jun Mei2, Jiashu Wang23, Tongkai Yang2, Binhang Yuan3, Yi Wu12 1 IIIS, Tsinghua University, 2 Ant Research, 3 HKUST fuwth17@gmail.com, jxwuyi@gmail.com "
[03.06.2025 07:13] Response: ```python
["IIIS, Tsinghua University", "Ant Research", "HKUST"]
```
[03.06.2025 07:13] Deleting PDF ./assets/pdf/2505.24298.pdf.
[03.06.2025 07:13] Success.
[03.06.2025 07:13] Enriching papers with extra data.
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 0. Token entropy patterns are crucial in RLVR, with high-entropy tokens significantly impacting reasoning performance and model optimization.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful approach to enhancing the reasoning capabilities ...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 1. SGG, an optimizer wrapper, enhances adaptive learning rates for large language models by grouping gradients and applying cluster-specific scaling, improving convergence and stability.  					AI-generated summary 				 Training large language models (LLMs) poses challenges due to their massive scale an...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 2. Recent advances in video diffusion models have demonstrated strong potential for generating robotic decision-making data, with trajectory conditions further enabling fine-grained control. However, existing trajectory-based methods primarily focus on individual object motion and struggle to capture m...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 3. ARIA aggregates rewards in an intention space to mitigate reward sparsity and improve policy optimization in language-based reinforcement learning tasks.  					AI-generated summary 				 Large language models (LLMs) have enabled agents to perform complex reasoning and decision-making through free-for...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 4. MiCRo, a two-stage framework, improves personalized preference learning for large language models by leveraging binary preference datasets and dynamically adapting mixture weights based on context, effectively capturing diverse human preferences.  					AI-generated summary 				 Reward modeling is a ...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 5. A native 3D large language model, ShapeLLM-Omni, is proposed to understand and generate 3D assets and text, trained using a 3D vector-quantized variational autoencoder and a new 3D-Alpaca dataset.  					AI-generated summary 				 Recently, the powerful text-to-image capabilities of ChatGPT-4o have le...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 6. A unified vision language action framework, LoHoVLA, combines a large pretrained vision language model with hierarchical closed-loop control to improve performance on long-horizon embodied tasks.  					AI-generated summary 				 Real-world embodied agents face long-horizon tasks, characterized by hig...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 7. DyePack, a framework using backdoor attacks, identifies models that leveraged benchmark test sets during training by introducing benign backdoor samples, ensuring precise false positive rates while preventing false accusations.  					AI-generated summary 				 Open benchmarks are essential for evalua...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 8. Cora framework enhances image editing through correspondence-aware noise correction and interpolated attention maps, excelling in structure and texture preservation and generation.  					AI-generated summary 				 Image editing is an important task in computer graphics, vision, and VFX, with recent d...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 9. STORM frameworks facilitates collaborative intent formation in task-oriented dialogue systems by modeling asymmetric information dynamics between UserLLM and AgentLLM.  					AI-generated summary 				 Task-oriented dialogue systems often face difficulties when user utterances seem semantically comple...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 10. Post-training techniques such as Supervised Fine-Tuning and Reinforcement Learning with Verifiable Rewards improve the reasoning and economic rationality of Large Language Models in multi-agent scenarios through domain-aligned training.  					AI-generated summary 				 Directly training Large Languag...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 11. A novel Video-3D Geometry Large Language Model (VG LLM) extracts 3D information directly from video sequences to enhance 3D scene understanding without additional 3D data, achieving competitive results in various tasks.  					AI-generated summary 				 Previous research has investigated the applicati...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 12. Temporal In-Context Fine-Tuning (TIC-FT) enhances pretrained video diffusion models for diverse conditional generation tasks with minimal data and without architectural changes.  					AI-generated summary 				 Recent advances in text-to-video diffusion models have enabled high-quality video synthesi...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 13. We introduce Reasoning Gym (RG), a library of reasoning environments for reinforcement learning with verifiable rewards. It provides over 100 data generators and verifiers spanning multiple domains including algebra, arithmetic, computation, cognition, geometry, graph theory, logic, and various comm...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 14. VisualSphinx provides a large-scale synthetic dataset to improve multimodal reasoning in vision language models, enhancing performance on various logical reasoning tasks.  					AI-generated summary 				 Vision language models (VLMs) are expected to perform effective multimodal reasoning and make log...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 15. VAU-R1 uses Multimodal Large Language Models with Reinforcement Fine-Tuning to enhance video anomaly reasoning, complemented by VAU-Bench, a Chain-of-Thought benchmark for evaluating anomaly understanding.  					AI-generated summary 				 Video Anomaly Understanding (VAU) is essential for application...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 16. State Machine Reasoning (SMR) improves information retrieval performance and reduces token usage in large language models by addressing overthinking through a discrete action framework.  					AI-generated summary 				 Chain-of-Thought (CoT) prompting enables complex reasoning in large language model...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 17. Existing large language models (LLMs) face challenges of following complex instructions, especially when multiple constraints are present and organized in paralleling, chaining, and branching structures. One intuitive solution, namely chain-of-thought (CoT), is expected to universally improve capabi...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 18. SATA-BENCH evaluates LLMs on multi-answer questions, revealing selections biases and proposing Choice Funnel to improve accuracy and reduce costs in multi-answer reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) are increasingly evaluated on single-answer multiple-choice ...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 19. The OWSM project is enhanced with a large-scale, cleaned web dataset, leading to improved multilingual speech models comparable to leading industrial models.  					AI-generated summary 				 The Open Whisper-style Speech Models (OWSM) project has developed a series of fully open speech foundation mod...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 20. The application of rule-based reinforcement learning (RL) to multimodal large language models (MLLMs) introduces unique challenges and potential deviations from findings in text-only domains, particularly for perception-heavy tasks. This paper provides a comprehensive study of rule-based visual RL, ...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 21. A unified budget-aware learning rate schedule is proposed to optimize training within limited iteration budgets, outperforming traditional schedules across various tasks and network architectures.  					AI-generated summary 				 The expanding computational costs and limited resources underscore the ...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 22. MagiCodec, a Transformer-based audio codec, enhances semantic tokenization while maintaining high reconstruction quality, improving compatibility with generative models.  					AI-generated summary 				 Neural audio codecs have made significant strides in efficiently mapping raw audio waveforms into ...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 23. Model distillation has become essential for creating smaller, deployable language models that retain larger system capabilities. However, widespread deployment raises concerns about resilience to adversarial manipulation. This paper investigates vulnerability of distilled models to adversarial injec...
[03.06.2025 07:13] ********************************************************************************
[03.06.2025 07:13] Abstract 24. AReaL, a fully asynchronous reinforcement learning system, decouples generation and training to achieve higher GPU utilization and up to 2.57x training speedup for large language models on reasoning tasks.  					AI-generated summary 				 Reinforcement learning (RL) has become a trending paradigm for...
[03.06.2025 07:13] Read previous papers.
[03.06.2025 07:13] Generating reviews via LLM API.
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#rlhf", "#reasoning", "#rl", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "–í—ã—Å–æ–∫–æ—ç–Ω—Ç—Ä–æ–ø–∏–π–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã - –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –∏–≥—Ä–∞—é—Ç –∫–ª—é—á–µ–≤—É—é —Ä–æ–ª—å –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏ –≤–æ–∑–Ω
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#training"], "emoji": "üöÄ", "ru": {"title": "SGG: –ì—Ä—É–ø–ø–æ–≤–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º SGG (Scaling with Gradient Gro
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#robotics", "#video", "#diffusion"], "emoji": "ü§ñ", "ru": {"title": "RoboMaster: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é —Å–ª–æ–∂–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –≤ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–µ", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ RoboMaster –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–µ. –ú–µ—Ç–æ–¥ —Ä–∞–∑
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#games", "#reasoning", "#agents", "#rl", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "ARIA: –ê–≥—Ä–µ–≥–∞—Ü–∏—è –Ω–∞–≥—Ä–∞–¥ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "ARIA - —ç—Ç–æ –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –Ω–∞–≥—Ä–∞–¥—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –¥–ª—è —ç
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#dataset", "#training", "#rlhf", "#alignment"], "emoji": "üé≠", "ru": {"title": "MiCRo: –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π", "desc": "MiCRo - —ç—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. –û–Ω–∞ –∏—Å–ø
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#synthetic", "#3d", "#games", "#dataset", "#agi", "#multimodal"], "emoji": "üßä", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D: —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –ø–æ–Ω–∏–º–∞—é—â–∞—è —Ç—Ä–µ—Ö–º–µ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ ShapeLLM-Omni - –Ω–∞—Ç–∏–≤–Ω—É—é 3D –±–æ–ª—å—à—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å, —Å–ø–æ—Å–æ–±–Ω—É—é –ø–æ–Ω–∏–º–∞—Ç—å –∏ –≥–µ–Ω–µ—Ä–∏—Ä
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#cv", "#architecture", "#robotics", "#agents", "#dataset", "#agi", "#long_context"], "emoji": "ü§ñ", "ru": {"title": "–ï–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á –≤–æ–ø–ª–æ—â–µ–Ω–Ω–æ–≥–æ –ò–ò", "desc": "LoHoVLA - —ç—Ç–æ –Ω–æ–≤–∞—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á –≤–æ–ø–ª–æ—â–µ–Ω–Ω–æ–≥–æ –∏—Å–∫—É—Å—Å
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#security", "#leakage"], "emoji": "üïµÔ∏è", "ru": {"title": "DyePack: –õ–æ–≤—É—à–∫–∞ –¥–ª—è –Ω–µ—á–µ—Å—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "DyePack - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞—Ç–∞–∫–∏ —Ç–∏–ø–∞ backdoor –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤—Ä–µ
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#cv", "#video", "#diffusion"], "emoji": "üñºÔ∏è", "ru": {"title": "–£–º–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ —Ç–µ–∫—Å—Ç—É—Ä", "desc": "Cora - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—é —à—É–º–∞ —Å —É—á–µ—Ç–æ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∏ –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ä—Ç—ã –≤–Ω–∏–º–∞–Ω–∏—è. –û–Ω–∞
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#alignment", "#agents"], "emoji": "üå™Ô∏è", "ru": {"title": "STORM: –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –≤ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ STORM –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö. STORM –∏—Å
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#training", "#rl", "#benchmark", "#agents", "#open_source", "#reasoning", "#games", "#dataset"], "emoji": "üí°", "ru": {"title": "–î–æ–æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —É–ª—É—á—à–∞–µ—Ç —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º–µ—Ç–æ–¥—ã –¥–æ–æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–∞—è —Ç–æ–Ω–∫–∞—è –Ω
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#video", "#games", "#architecture", "#3d"], "emoji": "üé•", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-–ø–æ–Ω–∏–º–∞–Ω–∏–∏: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –≤–∏–¥–µ–æ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å Video-3D Geometry Large Language Model (VG LLM), –∫–æ—Ç–æ—Ä–∞—è –∏–∑–≤–ª–µ–∫–∞
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#diffusion", "#inference", "#video", "#optimization", "#training"], "emoji": "üé¨", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ–º–æ–¥–µ–ª–µ–π —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏", "desc": "–ú–µ—Ç–æ–¥ Temporal In-Context Fine-Tuning (TIC-FT) —É–ª—É—á—à–∞–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–∏—Ñ—Ñ—É–∑–∏–∏ –≤–∏–¥–µ–æ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#reasoning", "#games", "#dataset"], "emoji": "üß†", "ru": {"title": "–ë–µ—Å–∫–æ–Ω–µ—á–Ω–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –ò–ò –≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "Reasoning Gym (RG) - —ç—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Å—Ä–µ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ –∑–∞–¥–∞—á–∞—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è —Å –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏. –û–Ω–∞ –≤–∫–ª—é—á–∞–µ—Ç –±–æ–ª
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#synthetic", "#cv", "#multimodal", "#reasoning", "#dataset"], "emoji": "üß†", "ru": {"title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –ò–ò", "desc": "VisualSphinx - —ç—Ç–æ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#rl", "#interpretability", "#multimodal", "#reasoning", "#video", "#benchmark"], "emoji": "üé•", "ru": {"title": "–£–º–Ω–æ–µ –≤–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ: –ò–ò —É—á–∏—Ç—Å—è –ø–æ–Ω–∏–º–∞—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏", "desc": "VAU-R1 - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#reasoning", "#optimization", "#dataset"], "emoji": "ü§ñ", "ru": {"title": "SMR: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º State Machine Reasoning (SMR). S
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#training", "#rl", "#benchmark", "#reasoning", "#optimization"], "emoji": "üß†", "ru": {"title": "–†–∞—Å—Å—É–∂–¥–∞–π —É–º–Ω–µ–µ, –∞ –Ω–µ –±–æ–ª—å—à–µ: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ —É–ª—É—á—à–µ–Ω–∏—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å 
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#training", "#benchmark", "#open_source", "#interpretability", "#data", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞—á–∞—Ö —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SATA-BENCH - –ø–µ—Ä–≤—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ 
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#training", "#low_resource", "#open_source", "#multilingual", "#data", "#audio", "#dataset"], "emoji": "üåê", "ru": {"title": "–û—Ç–∫—Ä—ã—Ç—ã–µ —Ä–µ—á–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç–∏–≥–∞—é—Ç —É—Ä–æ–≤–Ω—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤", "desc": "–ü—Ä–æ–µ–∫—Ç OWSM —É–ª—É—á—à–µ–Ω —Å –ø–æ–º–æ—â—å—é –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –≤–µ–±-–¥–∞—Ç–∞—Å–µ—Ç–∞, —á—Ç–æ –ø—Ä–∏–≤–µ–ª–æ –∫ —É
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#multimodal", "#training", "#transfer_learning", "#rl", "#cv", "#open_source", "#reasoning", "#games"], "emoji": "üß©", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –æ—Å–≤–∞–∏–≤–∞—é—Ç –ø–∞–∑–ª—ã —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#training", "#optimization"], "emoji": "üìä", "ru": {"title": "–£–º–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è: –º–∞–∫—Å–∏–º—É–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–∞—Ö", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –±—é–¥–∂–µ—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è –≤ —É—Å–ª–æ–≤–∏—è—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–π. 
[03.06.2025 07:13] Using data from previous issue: {"categories": ["#audio", "#optimization", "#diffusion", "#open_source", "#multimodal"], "emoji": "üéµ", "ru": {"title": "MagiCodec: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "MagiCodec - —ç—Ç–æ –Ω–æ–≤—ã–π –∞—É–¥–∏–æ –∫–æ–¥–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ç
[03.06.2025 07:13] Querying the API.
[03.06.2025 07:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Model distillation has become essential for creating smaller, deployable language models that retain larger system capabilities. However, widespread deployment raises concerns about resilience to adversarial manipulation. This paper investigates vulnerability of distilled models to adversarial injection of biased content during training. We demonstrate that adversaries can inject subtle biases into teacher models through minimal data poisoning, which propagates to student models and becomes significantly amplified. We propose two propagation modes: Untargeted Propagation, where bias affects multiple tasks, and Targeted Propagation, focusing on specific tasks while maintaining normal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning rate), student models generate biased responses 76.9% of the time in targeted scenarios - higher than 69.4% in teacher models. For untargeted propagation, adversarial bias appears 6x-29x more frequently in student models on unseen tasks. We validate findings across six bias types (targeted advertisements, phishing links, narrative manipulations, insecure coding practices), various distillation methods, and different modalities spanning text and code generation. Our evaluation reveals shortcomings in current defenses - perplexity filtering, bias detection systems, and LLM-based autorater frameworks - against these attacks. Results expose significant security vulnerabilities in distilled models, highlighting need for specialized safeguards. We propose practical design principles for building effective adversarial bias mitigation strategies.
[03.06.2025 07:13] Response: {
  "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —É—è–∑–≤–∏–º–æ—Å—Ç—å –¥–∏—Å—Ç–∏–ª–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –≤–Ω–µ–¥—Ä–µ–Ω–∏—é –ø—Ä–µ–¥–≤–∑—è—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç, —á—Ç–æ –¥–∞–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —É—á–∏—Ç–µ–ª—è –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–º—É —É—Å–∏–ª–µ–Ω–∏—é –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –≤ –º–æ–¥–µ–ª–∏ —É—á–µ–Ω–∏–∫–∞. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω—ã –¥–≤–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏: –Ω–µ—Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π, –≤–ª–∏—è—é—â–∏–π –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á, –∏ —Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π, —Ñ–æ–∫—É—Å–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –∑–∞—â–∏—Ç—ã –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–∏—Å—Ç–∏–ª–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.",
  "emoji": "üïµÔ∏è",
  "title": "–°–∫—Ä—ã—Ç–∞—è —É–≥—Ä–æ–∑–∞: –∫–∞–∫ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å —É—Å–∏–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"
}
[03.06.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Model distillation has become essential for creating smaller, deployable language models that retain larger system capabilities. However, widespread deployment raises concerns about resilience to adversarial manipulation. This paper investigates vulnerability of distilled models to adversarial injection of biased content during training. We demonstrate that adversaries can inject subtle biases into teacher models through minimal data poisoning, which propagates to student models and becomes significantly amplified. We propose two propagation modes: Untargeted Propagation, where bias affects multiple tasks, and Targeted Propagation, focusing on specific tasks while maintaining normal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning rate), student models generate biased responses 76.9% of the time in targeted scenarios - higher than 69.4% in teacher models. For untargeted propagation, adversarial bias appears 6x-29x more frequently in student models on unseen tasks. We validate findings across six bias types (targeted advertisements, phishing links, narrative manipulations, insecure coding practices), various distillation methods, and different modalities spanning text and code generation. Our evaluation reveals shortcomings in current defenses - perplexity filtering, bias detection systems, and LLM-based autorater frameworks - against these attacks. Results expose significant security vulnerabilities in distilled models, highlighting need for specialized safeguards. We propose practical design principles for building effective adversarial bias mitigation strategies."

[03.06.2025 07:13] Response: ```python
["DATASET", "DATA", "INFERENCE", "TRAINING"]
```
[03.06.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Model distillation has become essential for creating smaller, deployable language models that retain larger system capabilities. However, widespread deployment raises concerns about resilience to adversarial manipulation. This paper investigates vulnerability of distilled models to adversarial injection of biased content during training. We demonstrate that adversaries can inject subtle biases into teacher models through minimal data poisoning, which propagates to student models and becomes significantly amplified. We propose two propagation modes: Untargeted Propagation, where bias affects multiple tasks, and Targeted Propagation, focusing on specific tasks while maintaining normal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning rate), student models generate biased responses 76.9% of the time in targeted scenarios - higher than 69.4% in teacher models. For untargeted propagation, adversarial bias appears 6x-29x more frequently in student models on unseen tasks. We validate findings across six bias types (targeted advertisements, phishing links, narrative manipulations, insecure coding practices), various distillation methods, and different modalities spanning text and code generation. Our evaluation reveals shortcomings in current defenses - perplexity filtering, bias detection systems, and LLM-based autorater frameworks - against these attacks. Results expose significant security vulnerabilities in distilled models, highlighting need for specialized safeguards. We propose practical design principles for building effective adversarial bias mitigation strategies."

[03.06.2025 07:13] Response: ```python
['SECURITY', 'ETHICS']
```
[03.06.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the vulnerabilities of distilled language models to adversarial attacks, specifically through the injection of biased content during their training phase. It shows that adversaries can subtly poison teacher models with minimal data, which then amplifies biases in the student models that are derived from them. The study identifies two modes of bias propagation: Untargeted, affecting multiple tasks, and Targeted, which focuses on specific tasks while keeping normal behavior intact. The findings reveal that current defenses are inadequate, emphasizing the need for improved strategies to safeguard against these security threats in distilled models.","title":"Strengthening Distilled Models Against Adversarial Bias Injection"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores the vulnerabilities of distilled language models to adversarial attacks, specifically through the injection of biased content during their training phase. It shows that adversaries can subtly poison teacher models with minimal data, which then amplifies biases in the student models that are derived from them. The study identifies two modes of bias propagation: Untargeted, affecting multiple tasks, and Targeted, which focuses on specific tasks while keeping normal behavior intact. The findings reveal that current defenses are inadequate, emphasizing the need for improved strategies to safeguard against these security threats in distilled models.', title='Strengthening Distilled Models Against Adversarial Bias Injection'))
[03.06.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Ê®°ÂûãËí∏È¶èÂú®ÂàõÂª∫Â∞èÂûãÂèØÈÉ®ÁΩ≤ËØ≠Ë®ÄÊ®°Âûã‰∏≠ÂèòÂæóËá≥ÂÖ≥ÈáçË¶ÅÔºåËøô‰∫õÊ®°Âûã‰øùÁïô‰∫ÜÊõ¥Â§ßÁ≥ªÁªüÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂπøÊ≥õÈÉ®ÁΩ≤ÂºïÂèë‰∫ÜÂØπÊäóÊÄßÊìçÊéßÁöÑËÑÜÂº±ÊÄßÈóÆÈ¢ò„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫ÜËí∏È¶èÊ®°ÂûãÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÂØπÂÅèËßÅÂÜÖÂÆπÁöÑÂØπÊäóÊÄßÊ≥®ÂÖ•ÁöÑËÑÜÂº±ÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§Áßç‰º†Êí≠Ê®°ÂºèÔºåÂπ∂Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄöËøáÊúÄÂ∞èÁöÑÊï∞ÊçÆÊ±°Êüì‰ΩøÊïôÂ∏àÊ®°ÂûãÊ≥®ÂÖ•ÂæÆÂ¶ôÁöÑÂÅèËßÅÔºåËøô‰∫õÂÅèËßÅÂú®Â≠¶ÁîüÊ®°Âûã‰∏≠Ë¢´ÊòæËëóÊîæÂ§ß„ÄÇ","title":"‰øùÊä§Ëí∏È¶èÊ®°ÂûãÔºåÊäµÂæ°ÂØπÊäóÊÄßÂÅèËßÅÊîªÂáªÔºÅ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Ê®°ÂûãËí∏È¶èÂú®ÂàõÂª∫Â∞èÂûãÂèØÈÉ®ÁΩ≤ËØ≠Ë®ÄÊ®°Âûã‰∏≠ÂèòÂæóËá≥ÂÖ≥ÈáçË¶ÅÔºåËøô‰∫õÊ®°Âûã‰øùÁïô‰∫ÜÊõ¥Â§ßÁ≥ªÁªüÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂπøÊ≥õÈÉ®ÁΩ≤ÂºïÂèë‰∫ÜÂØπÊäóÊÄßÊìçÊéßÁöÑËÑÜÂº±ÊÄßÈóÆÈ¢ò„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫ÜËí∏È¶èÊ®°ÂûãÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÂØπÂÅèËßÅÂÜÖÂÆπÁöÑÂØπÊäóÊÄßÊ≥®ÂÖ•ÁöÑËÑÜÂº±ÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§Áßç‰º†Êí≠Ê®°ÂºèÔºåÂπ∂Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄöËøáÊúÄÂ∞èÁöÑÊï∞ÊçÆÊ±°Êüì‰ΩøÊïôÂ∏àÊ®°ÂûãÊ≥®ÂÖ•ÂæÆÂ¶ôÁöÑÂÅèËßÅÔºåËøô‰∫õÂÅèËßÅÂú®Â≠¶ÁîüÊ®°Âûã‰∏≠Ë¢´ÊòæËëóÊîæÂ§ß„ÄÇ', title='‰øùÊä§Ëí∏È¶èÊ®°ÂûãÔºåÊäµÂæ°ÂØπÊäóÊÄßÂÅèËßÅÊîªÂáªÔºÅ'))
[03.06.2025 07:13] Querying the API.
[03.06.2025 07:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

AReaL, a fully asynchronous reinforcement learning system, decouples generation and training to achieve higher GPU utilization and up to 2.57x training speedup for large language models on reasoning tasks.  					AI-generated summary 				 Reinforcement learning (RL) has become a trending paradigm for training large language models (LLMs), particularly for reasoning tasks. Effective RL for LLMs requires massive parallelization and poses an urgent need for efficient training systems. Most existing large-scale RL systems for LLMs are synchronous by alternating generation and training in a batch setting, where the rollouts in each training batch are generated by the same (or latest) model. This stabilizes RL training but suffers from severe system-level inefficiency. Generation must wait until the longest output in the batch is completed before model update, resulting in GPU underutilization. We present AReaL, a fully asynchronous RL system that completely decouples generation from training. Rollout workers in AReaL continuously generate new outputs without waiting, while training workers update the model whenever a batch of data is collected. AReaL also incorporates a collection of system-level optimizations, leading to substantially higher GPU utilization. To stabilize RL training, AReaL balances the workload of rollout and training workers to control data staleness, and adopts a staleness-enhanced PPO variant to better handle outdated training samples. Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.57times training speedup compared to the best synchronous systems with the same number of GPUs and matched or even improved final performance. The code of AReaL is available at https://github.com/inclusionAI/AReaL/.
[03.06.2025 07:13] Response: {
  "desc": "AReaL - —ç—Ç–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω–∞ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –æ–±—É—á–µ–Ω–∏—è, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–æ—Å—Ç–∏—á—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–π —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ GPU –∏ —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –¥–æ 2.57 —Ä–∞–∑ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, –∞ —Ç–∞–∫–∂–µ —Ä—è–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ AReaL –Ω–∞–¥ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏ –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞.",
  "emoji": "üöÄ",
  "title": "AReaL: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ò–ò"
}
[03.06.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AReaL, a fully asynchronous reinforcement learning system, decouples generation and training to achieve higher GPU utilization and up to 2.57x training speedup for large language models on reasoning tasks.  					AI-generated summary 				 Reinforcement learning (RL) has become a trending paradigm for training large language models (LLMs), particularly for reasoning tasks. Effective RL for LLMs requires massive parallelization and poses an urgent need for efficient training systems. Most existing large-scale RL systems for LLMs are synchronous by alternating generation and training in a batch setting, where the rollouts in each training batch are generated by the same (or latest) model. This stabilizes RL training but suffers from severe system-level inefficiency. Generation must wait until the longest output in the batch is completed before model update, resulting in GPU underutilization. We present AReaL, a fully asynchronous RL system that completely decouples generation from training. Rollout workers in AReaL continuously generate new outputs without waiting, while training workers update the model whenever a batch of data is collected. AReaL also incorporates a collection of system-level optimizations, leading to substantially higher GPU utilization. To stabilize RL training, AReaL balances the workload of rollout and training workers to control data staleness, and adopts a staleness-enhanced PPO variant to better handle outdated training samples. Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.57times training speedup compared to the best synchronous systems with the same number of GPUs and matched or even improved final performance. The code of AReaL is available at https://github.com/inclusionAI/AReaL/."

[03.06.2025 07:13] Response: ```python
["RL", "TRAINING"]
```
[03.06.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AReaL, a fully asynchronous reinforcement learning system, decouples generation and training to achieve higher GPU utilization and up to 2.57x training speedup for large language models on reasoning tasks.  					AI-generated summary 				 Reinforcement learning (RL) has become a trending paradigm for training large language models (LLMs), particularly for reasoning tasks. Effective RL for LLMs requires massive parallelization and poses an urgent need for efficient training systems. Most existing large-scale RL systems for LLMs are synchronous by alternating generation and training in a batch setting, where the rollouts in each training batch are generated by the same (or latest) model. This stabilizes RL training but suffers from severe system-level inefficiency. Generation must wait until the longest output in the batch is completed before model update, resulting in GPU underutilization. We present AReaL, a fully asynchronous RL system that completely decouples generation from training. Rollout workers in AReaL continuously generate new outputs without waiting, while training workers update the model whenever a batch of data is collected. AReaL also incorporates a collection of system-level optimizations, leading to substantially higher GPU utilization. To stabilize RL training, AReaL balances the workload of rollout and training workers to control data staleness, and adopts a staleness-enhanced PPO variant to better handle outdated training samples. Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.57times training speedup compared to the best synchronous systems with the same number of GPUs and matched or even improved final performance. The code of AReaL is available at https://github.com/inclusionAI/AReaL/."

[03.06.2025 07:13] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[03.06.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"AReaL is an innovative reinforcement learning system designed to enhance the training of large language models by decoupling the generation and training processes. This fully asynchronous approach allows for continuous output generation without waiting for the longest tasks to finish, leading to improved GPU utilization. By balancing the workload between rollout and training workers, AReaL effectively manages data staleness and employs a modified Proximal Policy Optimization (PPO) to optimize training with outdated samples. Experimental results demonstrate that AReaL can achieve up to 2.57 times faster training speeds while maintaining or improving performance on reasoning tasks.","title":"AReaL: Revolutionizing Reinforcement Learning with Asynchronous Training"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='AReaL is an innovative reinforcement learning system designed to enhance the training of large language models by decoupling the generation and training processes. This fully asynchronous approach allows for continuous output generation without waiting for the longest tasks to finish, leading to improved GPU utilization. By balancing the workload between rollout and training workers, AReaL effectively manages data staleness and employs a modified Proximal Policy Optimization (PPO) to optimize training with outdated samples. Experimental results demonstrate that AReaL can achieve up to 2.57 times faster training speeds while maintaining or improving performance on reasoning tasks.', title='AReaL: Revolutionizing Reinforcement Learning with Asynchronous Training'))
[03.06.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"AReaLÊòØ‰∏ÄÁßçÂÆåÂÖ®ÂºÇÊ≠•ÁöÑÂº∫ÂåñÂ≠¶‰π†Á≥ªÁªüÔºåÂÆÉÂ∞ÜÁîüÊàêÂíåËÆ≠ÁªÉËß£ËÄ¶Ôºå‰ªéËÄåÊèêÈ´òGPUÁöÑÂà©Áî®ÁéáÔºåÂπ∂Âú®Êé®ÁêÜ‰ªªÂä°‰∏äÂÆûÁé∞‰∫ÜÈ´òËææ2.57ÂÄçÁöÑËÆ≠ÁªÉÂä†ÈÄü„ÄÇ‰º†ÁªüÁöÑÂ§ßËßÑÊ®°Âº∫ÂåñÂ≠¶‰π†Á≥ªÁªüÈÄöÂ∏∏ÊòØÂêåÊ≠•ÁöÑÔºåÁîüÊàêÂíåËÆ≠ÁªÉ‰∫§ÊõøËøõË°åÔºåËøôÂØºËá¥‰∫ÜÁ≥ªÁªüÊïàÁéá‰Ωé‰∏ã„ÄÇAReaLÈÄöËøáËÆ©ÁîüÊàêÂ∑•‰ΩúËÄÖÊåÅÁª≠ÁîüÊàêÊñ∞ËæìÂá∫ÔºåËÄåËÆ≠ÁªÉÂ∑•‰ΩúËÄÖÂú®Êî∂ÈõÜÂà∞‰∏ÄÊâπÊï∞ÊçÆÂêéÁ´ãÂç≥Êõ¥Êñ∞Ê®°ÂûãÔºåËß£ÂÜ≥‰∫ÜËøô‰∏ÄÈóÆÈ¢ò„ÄÇÈÄöËøáÂπ≥Ë°°ÁîüÊàêÂíåËÆ≠ÁªÉÂ∑•‰ΩúËÄÖÁöÑÂ∑•‰ΩúË¥üËΩΩÔºåAReaLÊúâÊïàÊéßÂà∂‰∫ÜÊï∞ÊçÆÁöÑËøáÊó∂ÊÄßÔºåÂπ∂ÈááÁî®‰∫ÜÂ¢ûÂº∫ËøáÊó∂ÊÄßÁöÑPPOÂèò‰ΩìÊù•Êõ¥Â•ΩÂú∞Â§ÑÁêÜËøáÊó∂ÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇ","title":"AReaLÔºöÂºÇÊ≠•Âº∫ÂåñÂ≠¶‰π†ÁöÑÈ´òÊïàËÆ≠ÁªÉÊñ∞Ê®°Âºè"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='AReaLÊòØ‰∏ÄÁßçÂÆåÂÖ®ÂºÇÊ≠•ÁöÑÂº∫ÂåñÂ≠¶‰π†Á≥ªÁªüÔºåÂÆÉÂ∞ÜÁîüÊàêÂíåËÆ≠ÁªÉËß£ËÄ¶Ôºå‰ªéËÄåÊèêÈ´òGPUÁöÑÂà©Áî®ÁéáÔºåÂπ∂Âú®Êé®ÁêÜ‰ªªÂä°‰∏äÂÆûÁé∞‰∫ÜÈ´òËææ2.57ÂÄçÁöÑËÆ≠ÁªÉÂä†ÈÄü„ÄÇ‰º†ÁªüÁöÑÂ§ßËßÑÊ®°Âº∫ÂåñÂ≠¶‰π†Á≥ªÁªüÈÄöÂ∏∏ÊòØÂêåÊ≠•ÁöÑÔºåÁîüÊàêÂíåËÆ≠ÁªÉ‰∫§ÊõøËøõË°åÔºåËøôÂØºËá¥‰∫ÜÁ≥ªÁªüÊïàÁéá‰Ωé‰∏ã„ÄÇAReaLÈÄöËøáËÆ©ÁîüÊàêÂ∑•‰ΩúËÄÖÊåÅÁª≠ÁîüÊàêÊñ∞ËæìÂá∫ÔºåËÄåËÆ≠ÁªÉÂ∑•‰ΩúËÄÖÂú®Êî∂ÈõÜÂà∞‰∏ÄÊâπÊï∞ÊçÆÂêéÁ´ãÂç≥Êõ¥Êñ∞Ê®°ÂûãÔºåËß£ÂÜ≥‰∫ÜËøô‰∏ÄÈóÆÈ¢ò„ÄÇÈÄöËøáÂπ≥Ë°°ÁîüÊàêÂíåËÆ≠ÁªÉÂ∑•‰ΩúËÄÖÁöÑÂ∑•‰ΩúË¥üËΩΩÔºåAReaLÊúâÊïàÊéßÂà∂‰∫ÜÊï∞ÊçÆÁöÑËøáÊó∂ÊÄßÔºåÂπ∂ÈááÁî®‰∫ÜÂ¢ûÂº∫ËøáÊó∂ÊÄßÁöÑPPOÂèò‰ΩìÊù•Êõ¥Â•ΩÂú∞Â§ÑÁêÜËøáÊó∂ÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇ', title='AReaLÔºöÂºÇÊ≠•Âº∫ÂåñÂ≠¶‰π†ÁöÑÈ´òÊïàËÆ≠ÁªÉÊñ∞Ê®°Âºè'))
[03.06.2025 07:13] Loading Chinese text from previous data.
[03.06.2025 07:13] Renaming data file.
[03.06.2025 07:13] Renaming previous data. hf_papers.json to ./d/2025-06-03.json
[03.06.2025 07:13] Saving new data file.
[03.06.2025 07:13] Generating page.
[03.06.2025 07:13] Renaming previous page.
[03.06.2025 07:13] Renaming previous data. index.html to ./d/2025-06-03.html
[03.06.2025 07:13] [Experimental] Generating Chinese page for reading.
[03.06.2025 07:13] Chinese vocab [{'word': 'Âº∫ÂåñÂ≠¶‰π†', 'pinyin': 'qi√°ng hu√† xu√© x√≠', 'trans': 'reinforcement learning'}, {'word': 'Êé®ÁêÜ', 'pinyin': 'tuƒ´ l«ê', 'trans': 'reasoning'}, {'word': '‰ΩúÁî®', 'pinyin': 'zu√≤ y√≤ng', 'trans': 'role'}, {'word': 'Ë°®Êòé', 'pinyin': 'bi«éo m√≠ng', 'trans': 'indicate'}, {'word': 'Âª∂Èïø', 'pinyin': 'y√°n ch√°ng', 'trans': 'extend'}, {'word': 'Á≠ñÁï•', 'pinyin': 'c√® l√º√®', 'trans': 'strategy'}, {'word': 'ÊèêÂá∫', 'pinyin': 't√≠ ch≈´', 'trans': 'propose'}, {'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}, {'word': 'ÁªìÂêà', 'pinyin': 'ji√© h√©', 'trans': 'combine'}, {'word': 'Êï£Â∫¶', 'pinyin': 's√†n d√π', 'trans': 'divergence'}, {'word': 'ÊéßÂà∂', 'pinyin': 'k√≤ng zh√¨', 'trans': 'control'}, {'word': 'Â§öÊ†∑Âåñ', 'pinyin': 'du≈ç y√†ng hu√†', 'trans': 'diversify'}, {'word': '‰ªªÂä°', 'pinyin': 'r√®n wu', 'trans': 'task'}, {'word': 'Ë°®Áé∞', 'pinyin': 'bi«éo xi√†n', 'trans': 'performance'}, {'word': '‰ºò‰∫é', 'pinyin': 'y≈çu y√∫', 'trans': 'superior to'}, {'word': 'ËæπÁïå', 'pinyin': 'biƒÅn ji√®', 'trans': 'boundary'}, {'word': 'ÊîπËøõ', 'pinyin': 'g«éi j√¨n', 'trans': 'improvement'}, {'word': 'ÂØÜÂàáÁõ∏ÂÖ≥', 'pinyin': 'm√¨ qi√® xiƒÅng guƒÅn', 'trans': 'closely related'}]
[03.06.2025 07:13] Renaming previous Chinese page.
[03.06.2025 07:13] Renaming previous data. zh.html to ./d/2025-06-02_zh_reading_task.html
[03.06.2025 07:13] Writing Chinese reading task.
[03.06.2025 07:13] Writing result.
[03.06.2025 07:13] Renaming log file.
[03.06.2025 07:13] Renaming previous data. log.txt to ./logs/2025-06-03_last_log.txt
