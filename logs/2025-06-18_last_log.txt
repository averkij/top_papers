[18.06.2025 04:22] Read previous papers.
[18.06.2025 04:22] Generating top page (month).
[18.06.2025 04:22] Writing top page (month).
[18.06.2025 05:13] Read previous papers.
[18.06.2025 05:13] Get feed.
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14429
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13642
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14234
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14606
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12278
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14758
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13363
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14245
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14603
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14002
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12860
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10100
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.05336
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13599
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10038
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14755
[18.06.2025 05:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.14731
[18.06.2025 05:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.14702
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13387
[18.06.2025 05:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.06.2025 05:13] No deleted papers detected.
[18.06.2025 05:13] Downloading and parsing papers (pdf, html). Total: 19.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14429.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14429.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14429.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.13642.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.13642.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.13642.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14234.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14234.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14234.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14606.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14606.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14606.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.12278.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.12278.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.12278.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14758.
[18.06.2025 05:13] Downloading paper 2506.14758 from http://arxiv.org/pdf/2506.14758v1...
[18.06.2025 05:13] Failed to download and parse paper https://huggingface.co/papers/2506.14758: 'LTChar' object is not iterable
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.13363.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.13363.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.13363.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14245.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14245.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14245.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14603.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14603.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14603.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14002.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14002.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14002.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.12860.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.12860.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.12860.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.10100.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.10100.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.10100.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.05336.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.05336.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.05336.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.13599.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.13599.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.13599.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.10038.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.10038.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.10038.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14755.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14755.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14755.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14731.
[18.06.2025 05:13] Downloading paper 2506.14731 from http://arxiv.org/pdf/2506.14731v1...
[18.06.2025 05:13] Extracting affiliations from text.
[18.06.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs Ring Team, Inclusion AI See Contributions section (Sec. 6) for full author list. We present Ring-lite, Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code. Date: Jun 17, 2025 Code: https://github.com/inclusionAI/Ring 5 2 0 2 J 7 1 ] . [ 1 1 3 7 4 1 . 6 0 5 2 : r Figure 1 Benchmark performance of Ring-lite The remarkable success of the OpenAI-O1 series models (OpenAI, 2024) and DeepSeek-R1 (DeepSeekAI, 2025) has demonstrated the substantial potential of large-scale reinforcement learning (RL) for complex reasoning tasks, attracting significant research attention. However, the detailed methodologies employ"
[18.06.2025 05:13] Response: ```python
["Ring Team, Inclusion AI"]
```
[18.06.2025 05:13] Deleting PDF ./assets/pdf/2506.14731.pdf.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14702.
[18.06.2025 05:14] Downloading paper 2506.14702 from http://arxiv.org/pdf/2506.14702v1...
[18.06.2025 05:14] Extracting affiliations from text.
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time Markers Daniel Dsouza1, Julia Kreutzer1, Adrien Morisot2, Ahmet Üstün1, and Sara Hooker1 1Cohere Labs, 2Cohere Corresponding authors: {danieldsouza, ahmet, sarahooker}@cohere.com Abstract One of the most profound challenges of modern machine learning is performing well on the longtail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on fixed system prompt for maintaining performance. In this work, we ask: Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time? We revisit the divide between training and inference techniques to improve long-tail performance while providing users with set of control levers the model is trained to be responsive to. We create detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations. 5 2 0 J 7 1 ] "
[18.06.2025 05:14] Response: ```python
["Cohere Labs", "Cohere"]
```
[18.06.2025 05:14] Deleting PDF ./assets/pdf/2506.14702.pdf.
[18.06.2025 05:14] Success.
[18.06.2025 05:14] Downloading and parsing paper https://huggingface.co/papers/2506.13387.
[18.06.2025 05:14] Extra JSON file exists (./assets/json/2506.13387.json), skip PDF parsing.
[18.06.2025 05:14] Paper image links file exists (./assets/img_data/2506.13387.json), skip HTML parsing.
[18.06.2025 05:14] Success.
[18.06.2025 05:14] Enriching papers with extra data.
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 0. This study investigates long-context performance of diffusion LLMs compared to auto-regressive LLMs, identifies their unique characteristics, and proposes LongLLaDA, a training-free method for extending context windows.  					AI-generated summary 				 Large Language Diffusion Models, or diffusion LL...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 1. Stream-Omni, a large multimodal model, integrates text, vision, and speech by efficiently aligning modalities using sequence-dimension concatenation for vision and layer-dimension mapping for speech, achieving strong performance with less data.  					AI-generated summary 				 The emergence of GPT-4o...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 2. Xolver, a multi-agent reasoning framework, enhances large language models with persistent memory and diverse experience modalities, improving performance on complex reasoning tasks by avoiding generating solutions from scratch.  					AI-generated summary 				 Despite impressive progress on complex r...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 3. A novel ISA-centric transpilation pipeline using LLMs and software testing achieves high correctness and efficiency in translating between complex and reduced hardware architectures.  					AI-generated summary 				 The hardware ecosystem is rapidly evolving, with increasing interest in translating l...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 4. TestCase-Eval is a benchmark for evaluating LLMs in generating comprehensive and targeted test cases for algorithm problems.  					AI-generated summary 				 We introduce TestCase-Eval, a new benchmark for systematic evaluation of LLMs in test-case generation. TestCase-Eval includes 500 algorithm pro...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 5. Introducing an entropy-based term to the advantage function in reinforcement learning enhances exploratory reasoning in language models, leading to improved performance on complex reasoning tasks.  					AI-generated summary 				 Balancing exploration and exploitation is a central goal in reinforceme...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 6. An RLVR framework using fine-tuned Qwen2.5-VL-7B achieves state-of-the-art performance in medical VIE with limited annotated samples, enhancing reasoning and balance between precision and recall.  					AI-generated summary 				 Visual Information Extraction (VIE) converts unstructured document image...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 7. RLVR advances machine reasoning by incentivizing correct and logical thought chains, addressing limitations identified by a more precise evaluation metric, $CoT$-$Pass@K$.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for ad...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 8. Flow maps, introduced with new continuous-time objectives and training techniques, achieve state-of-the-art performance in few-step image and text-to-image generation.  					AI-generated summary 				 Diffusion- and flow-based models have emerged as state-of-the-art generative modeling approaches, bu...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 9. A new statistical framework and training algorithm, Group Bias Adaptation, enhance Sparse Autoencoders for recovering monosemantic features in Large Language Models, offering theoretical guarantees and superior performance.  					AI-generated summary 				 We study the challenge of achieving theoreti...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 10. Question-Free Fine-Tuning (QFFT) improves efficiency and adaptability in cognitive models by leveraging both short and long chain-of-thought patterns, reducing response length while maintaining performance across various scenarios.  					AI-generated summary 				 Recent advancements in Long Chain-of...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 11. EfficientVLA accelerates Vision-Language-Action models by pruning language layers, optimizing visual token selection, and caching intermediate features in the diffusion-based action head.  					AI-generated summary 				 Vision-Language-Action (VLA) models, particularly diffusion-based architectures,...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 12. VideoMolmo, a multimodal model incorporating a temporal attention mechanism and SAM2 for mask fusion, enhances spatio-temporal pointing accuracy and reasoning capabilities in diverse real-world scenarios.  					AI-generated summary 				 Spatio-temporal localization is vital for precise interactions ...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 13. CAMS integrates an agentic framework with urban-knowledgeable large language models to simulate human mobility more realistically by modeling individual and collective patterns.  					AI-generated summary 				 Human mobility simulation plays a crucial role in various real-world applications. Recentl...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 14. Ambient Diffusion Omni framework leverages low-quality images to enhance diffusion models by utilizing properties of natural images and shows improvements in ImageNet FID and text-to-image quality.  					AI-generated summary 				 We show how to use low-quality, synthetic, and out-of-distribution ima...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 15. LC-R1, a post-training method guided by Brevity and Sufficiency principles, reduces unnecessary reasoning in Large Reasoning Models with minimal accuracy loss.  					AI-generated summary 				 Large Reasoning Models (LRMs) have achieved remarkable success, yet they often suffer from producing unneces...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 16. Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model op...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 17. A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 18. A framework, TR2M, uses multimodal inputs to rescale relative depth to metric depth, enhancing performance across various datasets through cross-modality attention and contrastive learning.  					AI-generated summary 				 This work presents a generalizable framework to transfer relative depth to met...
[18.06.2025 05:14] Read previous papers.
[18.06.2025 05:14] Generating reviews via LLM API.
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#long_context", "#architecture", "#benchmark", "#diffusion", "#rl"], "emoji": "🔬", "ru": {"title": "Диффузионные языковые модели: новые горизонты в обработке длинного контекста", "desc": "Это исследование сравнивает производительность диффузионных и авторегрессивных язы
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#multimodal", "#audio", "#transfer_learning", "#cv", "#benchmark", "#agi"], "emoji": "🔀", "ru": {"title": "Эффективная интеграция модальностей для мощных мультимодальных ИИ-моделей", "desc": "Stream-Omni - это крупная мультимодальная модель, объединяющая текст, изображения и речь. О
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#agents", "#agi", "#open_source", "#reasoning", "#multimodal"], "emoji": "🧠", "ru": {"title": "Xolver: Опыт-ориентированные языковые агенты для экспертного рассуждения", "desc": "Xolver - это фреймворк мультиагентного рассуждения, который улучшает работу больших языковы
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#architecture", "#benchmark", "#data", "#science"], "emoji": "🔄", "ru": {"title": "ЯМБ и тестирование объединяются для эффективной транспиляции между архитектурами процессоров", "desc": "Статья представляет новый подход к транспиляции программ между разли
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#benchmark"], "emoji": "🧪", "ru": {"title": "TestCase-Eval: Новый стандарт оценки ЯМ в генерации тестов", "desc": "TestCase-Eval - это новый бенчмарк для оценки способности языковых моделей (ЯМ) генерировать тестовые случаи для алгоритмических задач.
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "Энтропия как ключ к глубоким рассуждениям языковых моделей", "desc": "Статья представляет новый подход к улучшению рассуждений языковых моделей с помощью обучения с подкреплением. Авторы вводя
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#hallucinations", "#training", "#optimization", "#healthcare", "#reasoning", "#rl", "#multimodal"], "emoji": "🏥", "ru": {"title": "RLVR: Прорыв в извлечении медицинской информации из изображений", "desc": "Представлена система RLVR на основе модели Qwen2.5-VL-7B для извлечения визуа
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#training", "#rl"], "emoji": "🧠", "ru": {"title": "RLVR: путь к логически обоснованным рассуждениям ИИ", "desc": "Статья представляет новый подход к улучшению рассуждений моделей машинного обучения - Reinforcement Learning with Verifiable Rewards (RLVR). 
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#dataset", "#cv", "#benchmark", "#optimization", "#diffusion", "#small_models"], "emoji": "🌊", "ru": {"title": "Flow maps: революция в эффективной генерации изображений", "desc": "Статья представляет новый подход к генеративному моделированию под названием 'flow maps'. 
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#architecture", "#interpretability", "#math", "#optimization"], "emoji": "🧠", "ru": {"title": "Прорыв в интерпретации языковых моделей: теоретически обоснованное извлечение признаков", "desc": "Исследователи представили новый статистический фреймворк и алгоритм обучения
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#math", "#long_context", "#reasoning", "#low_resource"], "emoji": "🧠", "ru": {"title": "QFFT: эффективное обучение ИИ гибкому мышлению", "desc": "Статья представляет новый метод обучения когнитивных моделей - Question-Free Fine-Tuning (QFFT). QFFT позволяет моделям эффе
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#architecture", "#inference", "#multimodal"], "emoji": "🚀", "ru": {"title": "EfficientVLA: ускорение моделей VLA без потери качества", "desc": "EfficientVLA - это фреймворк для ускорения вывода моделей Vision-Language-Action (VLA). Он использует три ос
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#dataset", "#interpretability", "#benchmark", "#open_source", "#reasoning", "#video", "#multimodal"], "emoji": "🎯", "ru": {"title": "Точная локализация объектов в видео с помощью ИИ", "desc": "VideoMolmo - это мультимодальная модель для точной пространственно-временной локализации о
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#agents", "#synthetic", "#reasoning", "#multimodal"], "emoji": "🏙️", "ru": {"title": "Умное моделирование городской мобильности с помощью ИИ", "desc": "CAMS (CityGPT-Powered Agentic framework for Mobility Simulation) - это новый подход к моделированию человеческой мобильности в горо
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#cv", "#dataset", "#synthetic", "#diffusion", "#data"], "emoji": "🖼️", "ru": {"title": "Извлечение пользы из шума: улучшение диффузионных моделей с помощью низкокачественных изображений", "desc": "Статья представляет фреймворк Ambient Diffusion Omni, который использует 
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#reasoning", "#training", "#architecture", "#benchmark", "#optimization"], "emoji": "✂️", "ru": {"title": "LC-R1: Оптимизация рассуждений ИИ без потери качества", "desc": "LC-R1 - это метод пост-обучения для больших моделей рассуждений (LRM), основанный на принципах краткости и дост
[18.06.2025 05:14] Querying the API.
[18.06.2025 05:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code.
[18.06.2025 05:14] Response: {
  "desc": "Ring-lite - это модель на основе архитектуры Mixture-of-Experts (MoE), оптимизированная с помощью обучения с подкреплением для эффективного рассуждения. Модель достигает производительности современных моделей рассуждения, активируя лишь треть параметров. Авторы представляют новый метод C3PO для повышения стабильности обучения и вычислительной эффективности. Они также предлагают двухэтапную парадигму обучения для интеграции данных из разных доменов.",
  "emoji": "🧠",
  "title": "Эффективное рассуждение с меньшими вычислительными затратами"
}
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code."

[18.06.2025 05:14] Response: ```python
['RL', 'TRAINING', 'ARCHITECTURE', 'DATASET']
```
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code."

[18.06.2025 05:14] Response: ```python
['REASONING', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Ring-lite is a large language model that uses a Mixture-of-Experts (MoE) architecture combined with reinforcement learning (RL) to enhance reasoning capabilities while minimizing parameter activation. It builds on the Ling-lite model, achieving state-of-the-art performance on various reasoning benchmarks with only a fraction of the parameters activated compared to similar models. The paper introduces a novel training method called Constrained Contextual Computation Policy Optimization (C3PO) to improve stability during RL training and optimize computational efficiency. Additionally, it highlights the importance of selecting distillation checkpoints based on entropy loss for better performance in RL training and proposes a two-stage training approach to manage domain conflicts in mixed datasets.","title":"Efficient Reasoning with Fewer Parameters: Introducing Ring-lite"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Ring-lite is a large language model that uses a Mixture-of-Experts (MoE) architecture combined with reinforcement learning (RL) to enhance reasoning capabilities while minimizing parameter activation. It builds on the Ling-lite model, achieving state-of-the-art performance on various reasoning benchmarks with only a fraction of the parameters activated compared to similar models. The paper introduces a novel training method called Constrained Contextual Computation Policy Optimization (C3PO) to improve stability during RL training and optimize computational efficiency. Additionally, it highlights the importance of selecting distillation checkpoints based on entropy loss for better performance in RL training and proposes a two-stage training approach to manage domain conflicts in mixed datasets.', title='Efficient Reasoning with Fewer Parameters: Introducing Ring-lite'))
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Ring-lite是一种基于专家混合（MoE）架构的大型语言模型，通过强化学习（RL）进行优化，以实现高效且稳健的推理能力。该模型在Ling-lite的基础上构建，具有168亿个参数，但仅激活2.75亿个参数，能够在多个具有挑战性的基准测试中与小规模的最先进推理模型相匹配。我们提出了一种联合训练流程，将蒸馏与强化学习结合，解决了MoE强化学习训练中的一些未记录的挑战。通过引入受限上下文计算策略优化（C3PO），我们提高了训练的稳定性，并通过算法与系统的共同设计方法改善了计算吞吐量。","title":"高效推理，激活更少参数的Ring-lite"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Ring-lite是一种基于专家混合（MoE）架构的大型语言模型，通过强化学习（RL）进行优化，以实现高效且稳健的推理能力。该模型在Ling-lite的基础上构建，具有168亿个参数，但仅激活2.75亿个参数，能够在多个具有挑战性的基准测试中与小规模的最先进推理模型相匹配。我们提出了一种联合训练流程，将蒸馏与强化学习结合，解决了MoE强化学习训练中的一些未记录的挑战。通过引入受限上下文计算策略优化（C3PO），我们提高了训练的稳定性，并通过算法与系统的共同设计方法改善了计算吞吐量。', title='高效推理，激活更少参数的Ring-lite'))
[18.06.2025 05:14] Querying the API.
[18.06.2025 05:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations.
[18.06.2025 05:14] Response: {
  "desc": "Статья представляет новый подход к дообучению моделей машинного обучения для улучшения их производительности и управляемости на редких и недопредставленных случаях использования. Авторы разработали таксономию характеристик данных и происхождения задач для явного контроля атрибутов генерации. Модель обучается автоматически определять эти маркеры, что делает их опциональными при выводе. Такой подход показывает значительные улучшения производительности, особенно на примерах из длинного хвоста распределения обучающих данных.",
  "emoji": "🎯",
  "title": "Точная настройка моделей для редких случаев"
}
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations."

[18.06.2025 05:14] Response: ```python
["TRAINING"]
```
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations."

[18.06.2025 05:14] Response: ```python
["OPTIMIZATION", "LONG_CONTEXT"]
```
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of improving machine learning model performance on rare and underrepresented use cases, often referred to as the long tail. It proposes a method for fine-tuning models that enhances both controllability and performance by automatically inferring generation attributes during inference. The authors introduce a taxonomy of data characteristics to help guide the model\'s output, allowing for better adaptation to specific tasks without relying heavily on prompt engineering. Their approach demonstrates significant performance improvements, particularly in underrepresented domains, achieving notable gains in generation quality and task-specific evaluations.","title":"Optimizing Model Performance for Rare Use Cases"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper addresses the challenge of improving machine learning model performance on rare and underrepresented use cases, often referred to as the long tail. It proposes a method for fine-tuning models that enhances both controllability and performance by automatically inferring generation attributes during inference. The authors introduce a taxonomy of data characteristics to help guide the model's output, allowing for better adaptation to specific tasks without relying heavily on prompt engineering. Their approach demonstrates significant performance improvements, particularly in underrepresented domains, achieving notable gains in generation quality and task-specific evaluations.", title='Optimizing Model Performance for Rare Use Cases'))
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种系统的方法，通过自动推断生成属性来微调模型，以提高在稀有和未充分代表的用例上的性能和可控性。现代机器学习面临的一个主要挑战是如何在长尾特征上表现良好，尤其是在训练数据中较少出现的特征。我们重新审视训练和推理技术之间的差距，以改善长尾性能，并为用户提供一组可控的生成属性。通过对基础模型进行微调，我们实现了在推理时自动推断这些标记，从而在未充分代表的领域中显著提高了模型的表现。","title":"优化模型以提升稀有用例的性能与可控性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种系统的方法，通过自动推断生成属性来微调模型，以提高在稀有和未充分代表的用例上的性能和可控性。现代机器学习面临的一个主要挑战是如何在长尾特征上表现良好，尤其是在训练数据中较少出现的特征。我们重新审视训练和推理技术之间的差距，以改善长尾性能，并为用户提供一组可控的生成属性。通过对基础模型进行微调，我们实现了在推理时自动推断这些标记，从而在未充分代表的领域中显著提高了模型的表现。', title='优化模型以提升稀有用例的性能与可控性'))
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#transfer_learning", "#cv", "#multimodal"], "emoji": "🔍", "ru": {"title": "Универсальное преобразование глубины с помощью мультимодального обучения", "desc": "TR2M - это фреймворк для преобразования относительной глубины в метрическую с использованием мультимодальных входных данных.
[18.06.2025 05:14] Renaming data file.
[18.06.2025 05:14] Renaming previous data. hf_papers.json to ./d/2025-06-18.json
[18.06.2025 05:14] Saving new data file.
[18.06.2025 05:14] Generating page.
[18.06.2025 05:14] Renaming previous page.
[18.06.2025 05:14] Renaming previous data. index.html to ./d/2025-06-18.html
[18.06.2025 05:14] Writing result.
[18.06.2025 05:14] Renaming log file.
[18.06.2025 05:14] Renaming previous data. log.txt to ./logs/2025-06-18_last_log.txt
