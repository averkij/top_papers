[18.06.2025 04:22] Read previous papers.
[18.06.2025 04:22] Generating top page (month).
[18.06.2025 04:22] Writing top page (month).
[18.06.2025 05:13] Read previous papers.
[18.06.2025 05:13] Get feed.
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14429
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13642
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14234
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14606
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12278
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14758
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13363
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14245
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14603
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14002
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12860
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10100
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.05336
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13599
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10038
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14755
[18.06.2025 05:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.14731
[18.06.2025 05:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.14702
[18.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13387
[18.06.2025 05:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.06.2025 05:13] No deleted papers detected.
[18.06.2025 05:13] Downloading and parsing papers (pdf, html). Total: 19.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14429.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14429.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14429.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.13642.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.13642.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.13642.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14234.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14234.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14234.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14606.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14606.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14606.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.12278.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.12278.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.12278.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14758.
[18.06.2025 05:13] Downloading paper 2506.14758 from http://arxiv.org/pdf/2506.14758v1...
[18.06.2025 05:13] Failed to download and parse paper https://huggingface.co/papers/2506.14758: 'LTChar' object is not iterable
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.13363.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.13363.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.13363.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14245.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14245.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14245.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14603.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14603.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14603.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14002.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14002.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14002.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.12860.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.12860.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.12860.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.10100.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.10100.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.10100.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.05336.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.05336.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.05336.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.13599.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.13599.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.13599.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.10038.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.10038.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.10038.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14755.
[18.06.2025 05:13] Extra JSON file exists (./assets/json/2506.14755.json), skip PDF parsing.
[18.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.14755.json), skip HTML parsing.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14731.
[18.06.2025 05:13] Downloading paper 2506.14731 from http://arxiv.org/pdf/2506.14731v1...
[18.06.2025 05:13] Extracting affiliations from text.
[18.06.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs Ring Team, Inclusion AI See Contributions section (Sec. 6) for full author list. We present Ring-lite, Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code. Date: Jun 17, 2025 Code: https://github.com/inclusionAI/Ring 5 2 0 2 J 7 1 ] . [ 1 1 3 7 4 1 . 6 0 5 2 : r Figure 1 Benchmark performance of Ring-lite The remarkable success of the OpenAI-O1 series models (OpenAI, 2024) and DeepSeek-R1 (DeepSeekAI, 2025) has demonstrated the substantial potential of large-scale reinforcement learning (RL) for complex reasoning tasks, attracting significant research attention. However, the detailed methodologies employ"
[18.06.2025 05:13] Response: ```python
["Ring Team, Inclusion AI"]
```
[18.06.2025 05:13] Deleting PDF ./assets/pdf/2506.14731.pdf.
[18.06.2025 05:13] Success.
[18.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.14702.
[18.06.2025 05:14] Downloading paper 2506.14702 from http://arxiv.org/pdf/2506.14702v1...
[18.06.2025 05:14] Extracting affiliations from text.
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time Markers Daniel Dsouza1, Julia Kreutzer1, Adrien Morisot2, Ahmet √úst√ºn1, and Sara Hooker1 1Cohere Labs, 2Cohere Corresponding authors: {danieldsouza, ahmet, sarahooker}@cohere.com Abstract One of the most profound challenges of modern machine learning is performing well on the longtail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on fixed system prompt for maintaining performance. In this work, we ask: Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time? We revisit the divide between training and inference techniques to improve long-tail performance while providing users with set of control levers the model is trained to be responsive to. We create detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations. 5 2 0 J 7 1 ] "
[18.06.2025 05:14] Response: ```python
["Cohere Labs", "Cohere"]
```
[18.06.2025 05:14] Deleting PDF ./assets/pdf/2506.14702.pdf.
[18.06.2025 05:14] Success.
[18.06.2025 05:14] Downloading and parsing paper https://huggingface.co/papers/2506.13387.
[18.06.2025 05:14] Extra JSON file exists (./assets/json/2506.13387.json), skip PDF parsing.
[18.06.2025 05:14] Paper image links file exists (./assets/img_data/2506.13387.json), skip HTML parsing.
[18.06.2025 05:14] Success.
[18.06.2025 05:14] Enriching papers with extra data.
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 0. This study investigates long-context performance of diffusion LLMs compared to auto-regressive LLMs, identifies their unique characteristics, and proposes LongLLaDA, a training-free method for extending context windows.  					AI-generated summary 				 Large Language Diffusion Models, or diffusion LL...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 1. Stream-Omni, a large multimodal model, integrates text, vision, and speech by efficiently aligning modalities using sequence-dimension concatenation for vision and layer-dimension mapping for speech, achieving strong performance with less data.  					AI-generated summary 				 The emergence of GPT-4o...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 2. Xolver, a multi-agent reasoning framework, enhances large language models with persistent memory and diverse experience modalities, improving performance on complex reasoning tasks by avoiding generating solutions from scratch.  					AI-generated summary 				 Despite impressive progress on complex r...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 3. A novel ISA-centric transpilation pipeline using LLMs and software testing achieves high correctness and efficiency in translating between complex and reduced hardware architectures.  					AI-generated summary 				 The hardware ecosystem is rapidly evolving, with increasing interest in translating l...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 4. TestCase-Eval is a benchmark for evaluating LLMs in generating comprehensive and targeted test cases for algorithm problems.  					AI-generated summary 				 We introduce TestCase-Eval, a new benchmark for systematic evaluation of LLMs in test-case generation. TestCase-Eval includes 500 algorithm pro...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 5. Introducing an entropy-based term to the advantage function in reinforcement learning enhances exploratory reasoning in language models, leading to improved performance on complex reasoning tasks.  					AI-generated summary 				 Balancing exploration and exploitation is a central goal in reinforceme...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 6. An RLVR framework using fine-tuned Qwen2.5-VL-7B achieves state-of-the-art performance in medical VIE with limited annotated samples, enhancing reasoning and balance between precision and recall.  					AI-generated summary 				 Visual Information Extraction (VIE) converts unstructured document image...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 7. RLVR advances machine reasoning by incentivizing correct and logical thought chains, addressing limitations identified by a more precise evaluation metric, $CoT$-$Pass@K$.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for ad...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 8. Flow maps, introduced with new continuous-time objectives and training techniques, achieve state-of-the-art performance in few-step image and text-to-image generation.  					AI-generated summary 				 Diffusion- and flow-based models have emerged as state-of-the-art generative modeling approaches, bu...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 9. A new statistical framework and training algorithm, Group Bias Adaptation, enhance Sparse Autoencoders for recovering monosemantic features in Large Language Models, offering theoretical guarantees and superior performance.  					AI-generated summary 				 We study the challenge of achieving theoreti...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 10. Question-Free Fine-Tuning (QFFT) improves efficiency and adaptability in cognitive models by leveraging both short and long chain-of-thought patterns, reducing response length while maintaining performance across various scenarios.  					AI-generated summary 				 Recent advancements in Long Chain-of...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 11. EfficientVLA accelerates Vision-Language-Action models by pruning language layers, optimizing visual token selection, and caching intermediate features in the diffusion-based action head.  					AI-generated summary 				 Vision-Language-Action (VLA) models, particularly diffusion-based architectures,...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 12. VideoMolmo, a multimodal model incorporating a temporal attention mechanism and SAM2 for mask fusion, enhances spatio-temporal pointing accuracy and reasoning capabilities in diverse real-world scenarios.  					AI-generated summary 				 Spatio-temporal localization is vital for precise interactions ...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 13. CAMS integrates an agentic framework with urban-knowledgeable large language models to simulate human mobility more realistically by modeling individual and collective patterns.  					AI-generated summary 				 Human mobility simulation plays a crucial role in various real-world applications. Recentl...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 14. Ambient Diffusion Omni framework leverages low-quality images to enhance diffusion models by utilizing properties of natural images and shows improvements in ImageNet FID and text-to-image quality.  					AI-generated summary 				 We show how to use low-quality, synthetic, and out-of-distribution ima...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 15. LC-R1, a post-training method guided by Brevity and Sufficiency principles, reduces unnecessary reasoning in Large Reasoning Models with minimal accuracy loss.  					AI-generated summary 				 Large Reasoning Models (LRMs) have achieved remarkable success, yet they often suffer from producing unneces...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 16. Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model op...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 17. A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on...
[18.06.2025 05:14] ********************************************************************************
[18.06.2025 05:14] Abstract 18. A framework, TR2M, uses multimodal inputs to rescale relative depth to metric depth, enhancing performance across various datasets through cross-modality attention and contrastive learning.  					AI-generated summary 				 This work presents a generalizable framework to transfer relative depth to met...
[18.06.2025 05:14] Read previous papers.
[18.06.2025 05:14] Generating reviews via LLM API.
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#long_context", "#architecture", "#benchmark", "#diffusion", "#rl"], "emoji": "üî¨", "ru": {"title": "–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏: –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –∏ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö —è–∑—ã
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#multimodal", "#audio", "#transfer_learning", "#cv", "#benchmark", "#agi"], "emoji": "üîÄ", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –º–æ—â–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª–µ–π", "desc": "Stream-Omni - —ç—Ç–æ –∫—Ä—É–ø–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è —Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ä–µ—á—å. –û
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#agents", "#agi", "#open_source", "#reasoning", "#multimodal"], "emoji": "üß†", "ru": {"title": "Xolver: –û–ø—ã—Ç-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "Xolver - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#architecture", "#benchmark", "#data", "#science"], "emoji": "üîÑ", "ru": {"title": "–Ø–ú–ë –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ç—Ä–∞–Ω—Å–ø–∏–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ç—Ä–∞–Ω—Å–ø–∏–ª—è—Ü–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º –º–µ–∂–¥—É —Ä–∞–∑–ª–∏
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#benchmark"], "emoji": "üß™", "ru": {"title": "TestCase-Eval: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –Ø–ú –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤", "desc": "TestCase-Eval - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (–Ø–ú) –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á.
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl", "#reasoning"], "emoji": "üß†", "ru": {"title": "–≠–Ω—Ç—Ä–æ–ø–∏—è –∫–∞–∫ –∫–ª—é—á –∫ –≥–ª—É–±–æ–∫–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º. –ê–≤—Ç–æ—Ä—ã –≤–≤–æ–¥—è
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#hallucinations", "#training", "#optimization", "#healthcare", "#reasoning", "#rl", "#multimodal"], "emoji": "üè•", "ru": {"title": "RLVR: –ü—Ä–æ—Ä—ã–≤ –≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ RLVR –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏ Qwen2.5-VL-7B –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–∏–∑—É–∞
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#training", "#rl"], "emoji": "üß†", "ru": {"title": "RLVR: –ø—É—Ç—å –∫ –ª–æ–≥–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è - Reinforcement Learning with Verifiable Rewards (RLVR). 
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#dataset", "#cv", "#benchmark", "#optimization", "#diffusion", "#small_models"], "emoji": "üåä", "ru": {"title": "Flow maps: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º 'flow maps'. 
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#architecture", "#interpretability", "#math", "#optimization"], "emoji": "üß†", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#math", "#long_context", "#reasoning", "#low_resource"], "emoji": "üß†", "ru": {"title": "QFFT: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ò–ò –≥–∏–±–∫–æ–º—É –º—ã—à–ª–µ–Ω–∏—é", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π - Question-Free Fine-Tuning (QFFT). QFFT –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º —ç—Ñ—Ñ–µ
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#architecture", "#inference", "#multimodal"], "emoji": "üöÄ", "ru": {"title": "EfficientVLA: —É—Å–∫–æ—Ä–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π VLA –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "EfficientVLA - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞ –º–æ–¥–µ–ª–µ–π Vision-Language-Action (VLA). –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∏ –æ—Å
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#dataset", "#interpretability", "#benchmark", "#open_source", "#reasoning", "#video", "#multimodal"], "emoji": "üéØ", "ru": {"title": "–¢–æ—á–Ω–∞—è –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "VideoMolmo - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–æ—á–Ω–æ–π –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –æ
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#agents", "#synthetic", "#reasoning", "#multimodal"], "emoji": "üèôÔ∏è", "ru": {"title": "–£–º–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥—Å–∫–æ–π –º–æ–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "CAMS (CityGPT-Powered Agentic framework for Mobility Simulation) - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –º–æ–±–∏–ª—å–Ω–æ—Å—Ç–∏ –≤ –≥–æ—Ä–æ
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#training", "#cv", "#dataset", "#synthetic", "#diffusion", "#data"], "emoji": "üñºÔ∏è", "ru": {"title": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª—å–∑—ã –∏–∑ —à—É–º–∞: —É–ª—É—á—à–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Ambient Diffusion Omni, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#reasoning", "#training", "#architecture", "#benchmark", "#optimization"], "emoji": "‚úÇÔ∏è", "ru": {"title": "LC-R1: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "LC-R1 - —ç—Ç–æ –º–µ—Ç–æ–¥ –ø–æ—Å—Ç-–æ–±—É—á–µ–Ω–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (LRM), –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –ø—Ä–∏–Ω—Ü–∏–ø–∞—Ö –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –∏ –¥–æ—Å—Ç
[18.06.2025 05:14] Querying the API.
[18.06.2025 05:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code.
[18.06.2025 05:14] Response: {
  "desc": "Ring-lite - —ç—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Mixture-of-Experts (MoE), –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∞–∫—Ç–∏–≤–∏—Ä—É—è –ª–∏—à—å —Ç—Ä–µ—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ C3PO –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –û–Ω–∏ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤.",
  "emoji": "üß†",
  "title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —Å –º–µ–Ω—å—à–∏–º–∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–∞—Ç—Ä–∞—Ç–∞–º–∏"
}
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code."

[18.06.2025 05:14] Response: ```python
['RL', 'TRAINING', 'ARCHITECTURE', 'DATASET']
```
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.  					AI-generated summary 				 We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code."

[18.06.2025 05:14] Response: ```python
['REASONING', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Ring-lite is a large language model that uses a Mixture-of-Experts (MoE) architecture combined with reinforcement learning (RL) to enhance reasoning capabilities while minimizing parameter activation. It builds on the Ling-lite model, achieving state-of-the-art performance on various reasoning benchmarks with only a fraction of the parameters activated compared to similar models. The paper introduces a novel training method called Constrained Contextual Computation Policy Optimization (C3PO) to improve stability during RL training and optimize computational efficiency. Additionally, it highlights the importance of selecting distillation checkpoints based on entropy loss for better performance in RL training and proposes a two-stage training approach to manage domain conflicts in mixed datasets.","title":"Efficient Reasoning with Fewer Parameters: Introducing Ring-lite"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Ring-lite is a large language model that uses a Mixture-of-Experts (MoE) architecture combined with reinforcement learning (RL) to enhance reasoning capabilities while minimizing parameter activation. It builds on the Ling-lite model, achieving state-of-the-art performance on various reasoning benchmarks with only a fraction of the parameters activated compared to similar models. The paper introduces a novel training method called Constrained Contextual Computation Policy Optimization (C3PO) to improve stability during RL training and optimize computational efficiency. Additionally, it highlights the importance of selecting distillation checkpoints based on entropy loss for better performance in RL training and proposes a two-stage training approach to manage domain conflicts in mixed datasets.', title='Efficient Reasoning with Fewer Parameters: Introducing Ring-lite'))
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Ring-liteÊòØ‰∏ÄÁßçÂü∫‰∫é‰∏ìÂÆ∂Ê∑∑ÂêàÔºàMoEÔºâÊû∂ÊûÑÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâËøõË°å‰ºòÂåñÔºå‰ª•ÂÆûÁé∞È´òÊïà‰∏îÁ®≥ÂÅ•ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇËØ•Ê®°ÂûãÂú®Ling-liteÁöÑÂü∫Á°Ä‰∏äÊûÑÂª∫ÔºåÂÖ∑Êúâ168‰∫ø‰∏™ÂèÇÊï∞Ôºå‰ΩÜ‰ªÖÊøÄÊ¥ª2.75‰∫ø‰∏™ÂèÇÊï∞ÔºåËÉΩÂ§üÂú®Â§ö‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂü∫ÂáÜÊµãËØï‰∏≠‰∏éÂ∞èËßÑÊ®°ÁöÑÊúÄÂÖàËøõÊé®ÁêÜÊ®°ÂûãÁõ∏ÂåπÈÖç„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËÅîÂêàËÆ≠ÁªÉÊµÅÁ®ãÔºåÂ∞ÜËí∏È¶è‰∏éÂº∫ÂåñÂ≠¶‰π†ÁªìÂêàÔºåËß£ÂÜ≥‰∫ÜMoEÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ‰∏≠ÁöÑ‰∏Ä‰∫õÊú™ËÆ∞ÂΩïÁöÑÊåëÊàò„ÄÇÈÄöËøáÂºïÂÖ•ÂèóÈôê‰∏ä‰∏ãÊñáËÆ°ÁÆóÁ≠ñÁï•‰ºòÂåñÔºàC3POÔºâÔºåÊàë‰ª¨ÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÁöÑÁ®≥ÂÆöÊÄßÔºåÂπ∂ÈÄöËøáÁÆóÊ≥ï‰∏éÁ≥ªÁªüÁöÑÂÖ±ÂêåËÆæËÆ°ÊñπÊ≥ïÊîπÂñÑ‰∫ÜËÆ°ÁÆóÂêûÂêêÈáè„ÄÇ","title":"È´òÊïàÊé®ÁêÜÔºåÊøÄÊ¥ªÊõ¥Â∞ëÂèÇÊï∞ÁöÑRing-lite"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Ring-liteÊòØ‰∏ÄÁßçÂü∫‰∫é‰∏ìÂÆ∂Ê∑∑ÂêàÔºàMoEÔºâÊû∂ÊûÑÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâËøõË°å‰ºòÂåñÔºå‰ª•ÂÆûÁé∞È´òÊïà‰∏îÁ®≥ÂÅ•ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇËØ•Ê®°ÂûãÂú®Ling-liteÁöÑÂü∫Á°Ä‰∏äÊûÑÂª∫ÔºåÂÖ∑Êúâ168‰∫ø‰∏™ÂèÇÊï∞Ôºå‰ΩÜ‰ªÖÊøÄÊ¥ª2.75‰∫ø‰∏™ÂèÇÊï∞ÔºåËÉΩÂ§üÂú®Â§ö‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂü∫ÂáÜÊµãËØï‰∏≠‰∏éÂ∞èËßÑÊ®°ÁöÑÊúÄÂÖàËøõÊé®ÁêÜÊ®°ÂûãÁõ∏ÂåπÈÖç„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËÅîÂêàËÆ≠ÁªÉÊµÅÁ®ãÔºåÂ∞ÜËí∏È¶è‰∏éÂº∫ÂåñÂ≠¶‰π†ÁªìÂêàÔºåËß£ÂÜ≥‰∫ÜMoEÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ‰∏≠ÁöÑ‰∏Ä‰∫õÊú™ËÆ∞ÂΩïÁöÑÊåëÊàò„ÄÇÈÄöËøáÂºïÂÖ•ÂèóÈôê‰∏ä‰∏ãÊñáËÆ°ÁÆóÁ≠ñÁï•‰ºòÂåñÔºàC3POÔºâÔºåÊàë‰ª¨ÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÁöÑÁ®≥ÂÆöÊÄßÔºåÂπ∂ÈÄöËøáÁÆóÊ≥ï‰∏éÁ≥ªÁªüÁöÑÂÖ±ÂêåËÆæËÆ°ÊñπÊ≥ïÊîπÂñÑ‰∫ÜËÆ°ÁÆóÂêûÂêêÈáè„ÄÇ', title='È´òÊïàÊé®ÁêÜÔºåÊøÄÊ¥ªÊõ¥Â∞ëÂèÇÊï∞ÁöÑRing-lite'))
[18.06.2025 05:14] Querying the API.
[18.06.2025 05:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations.
[18.06.2025 05:14] Response: {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –¥–æ–æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç–∏ –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∏ –Ω–µ–¥–æ–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ —Ç–∞–∫—Å–æ–Ω–æ–º–∏—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è –∑–∞–¥–∞—á –¥–ª—è —è–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —ç—Ç–∏ –º–∞—Ä–∫–µ—Ä—ã, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∏—Ö –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏ –≤—ã–≤–æ–¥–µ. –¢–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö –∏–∑ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ö–≤–æ—Å—Ç–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.",
  "emoji": "üéØ",
  "title": "–¢–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–µ–¥–∫–∏—Ö —Å–ª—É—á–∞–µ–≤"
}
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations."

[18.06.2025 05:14] Response: ```python
["TRAINING"]
```
[18.06.2025 05:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.  					AI-generated summary 				 One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations."

[18.06.2025 05:14] Response: ```python
["OPTIMIZATION", "LONG_CONTEXT"]
```
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of improving machine learning model performance on rare and underrepresented use cases, often referred to as the long tail. It proposes a method for fine-tuning models that enhances both controllability and performance by automatically inferring generation attributes during inference. The authors introduce a taxonomy of data characteristics to help guide the model\'s output, allowing for better adaptation to specific tasks without relying heavily on prompt engineering. Their approach demonstrates significant performance improvements, particularly in underrepresented domains, achieving notable gains in generation quality and task-specific evaluations.","title":"Optimizing Model Performance for Rare Use Cases"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper addresses the challenge of improving machine learning model performance on rare and underrepresented use cases, often referred to as the long tail. It proposes a method for fine-tuning models that enhances both controllability and performance by automatically inferring generation attributes during inference. The authors introduce a taxonomy of data characteristics to help guide the model's output, allowing for better adaptation to specific tasks without relying heavily on prompt engineering. Their approach demonstrates significant performance improvements, particularly in underrepresented domains, achieving notable gains in generation quality and task-specific evaluations.", title='Optimizing Model Performance for Rare Use Cases'))
[18.06.2025 05:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ≥ªÁªüÁöÑÊñπÊ≥ïÔºåÈÄöËøáËá™Âä®Êé®Êñ≠ÁîüÊàêÂ±ûÊÄßÊù•ÂæÆË∞ÉÊ®°ÂûãÔºå‰ª•ÊèêÈ´òÂú®Á®ÄÊúâÂíåÊú™ÂÖÖÂàÜ‰ª£Ë°®ÁöÑÁî®‰æã‰∏äÁöÑÊÄßËÉΩÂíåÂèØÊéßÊÄß„ÄÇÁé∞‰ª£Êú∫Âô®Â≠¶‰π†Èù¢‰∏¥ÁöÑ‰∏Ä‰∏™‰∏ªË¶ÅÊåëÊàòÊòØÂ¶Ç‰ΩïÂú®ÈïøÂ∞æÁâπÂæÅ‰∏äË°®Áé∞ËâØÂ•ΩÔºåÂ∞§ÂÖ∂ÊòØÂú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ËæÉÂ∞ëÂá∫Áé∞ÁöÑÁâπÂæÅ„ÄÇÊàë‰ª¨ÈáçÊñ∞ÂÆ°ËßÜËÆ≠ÁªÉÂíåÊé®ÁêÜÊäÄÊúØ‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰ª•ÊîπÂñÑÈïøÂ∞æÊÄßËÉΩÔºåÂπ∂‰∏∫Áî®Êà∑Êèê‰æõ‰∏ÄÁªÑÂèØÊéßÁöÑÁîüÊàêÂ±ûÊÄß„ÄÇÈÄöËøáÂØπÂü∫Á°ÄÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºåÊàë‰ª¨ÂÆûÁé∞‰∫ÜÂú®Êé®ÁêÜÊó∂Ëá™Âä®Êé®Êñ≠Ëøô‰∫õÊ†áËÆ∞Ôºå‰ªéËÄåÂú®Êú™ÂÖÖÂàÜ‰ª£Ë°®ÁöÑÈ¢ÜÂüü‰∏≠ÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑË°®Áé∞„ÄÇ","title":"‰ºòÂåñÊ®°Âûã‰ª•ÊèêÂçáÁ®ÄÊúâÁî®‰æãÁöÑÊÄßËÉΩ‰∏éÂèØÊéßÊÄß"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ≥ªÁªüÁöÑÊñπÊ≥ïÔºåÈÄöËøáËá™Âä®Êé®Êñ≠ÁîüÊàêÂ±ûÊÄßÊù•ÂæÆË∞ÉÊ®°ÂûãÔºå‰ª•ÊèêÈ´òÂú®Á®ÄÊúâÂíåÊú™ÂÖÖÂàÜ‰ª£Ë°®ÁöÑÁî®‰æã‰∏äÁöÑÊÄßËÉΩÂíåÂèØÊéßÊÄß„ÄÇÁé∞‰ª£Êú∫Âô®Â≠¶‰π†Èù¢‰∏¥ÁöÑ‰∏Ä‰∏™‰∏ªË¶ÅÊåëÊàòÊòØÂ¶Ç‰ΩïÂú®ÈïøÂ∞æÁâπÂæÅ‰∏äË°®Áé∞ËâØÂ•ΩÔºåÂ∞§ÂÖ∂ÊòØÂú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ËæÉÂ∞ëÂá∫Áé∞ÁöÑÁâπÂæÅ„ÄÇÊàë‰ª¨ÈáçÊñ∞ÂÆ°ËßÜËÆ≠ÁªÉÂíåÊé®ÁêÜÊäÄÊúØ‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰ª•ÊîπÂñÑÈïøÂ∞æÊÄßËÉΩÔºåÂπ∂‰∏∫Áî®Êà∑Êèê‰æõ‰∏ÄÁªÑÂèØÊéßÁöÑÁîüÊàêÂ±ûÊÄß„ÄÇÈÄöËøáÂØπÂü∫Á°ÄÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºåÊàë‰ª¨ÂÆûÁé∞‰∫ÜÂú®Êé®ÁêÜÊó∂Ëá™Âä®Êé®Êñ≠Ëøô‰∫õÊ†áËÆ∞Ôºå‰ªéËÄåÂú®Êú™ÂÖÖÂàÜ‰ª£Ë°®ÁöÑÈ¢ÜÂüü‰∏≠ÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑË°®Áé∞„ÄÇ', title='‰ºòÂåñÊ®°Âûã‰ª•ÊèêÂçáÁ®ÄÊúâÁî®‰æãÁöÑÊÄßËÉΩ‰∏éÂèØÊéßÊÄß'))
[18.06.2025 05:14] Using data from previous issue: {"categories": ["#transfer_learning", "#cv", "#multimodal"], "emoji": "üîç", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "TR2M - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π –≥–ª—É–±–∏–Ω—ã –≤ –º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
[18.06.2025 05:14] Renaming data file.
[18.06.2025 05:14] Renaming previous data. hf_papers.json to ./d/2025-06-18.json
[18.06.2025 05:14] Saving new data file.
[18.06.2025 05:14] Generating page.
[18.06.2025 05:14] Renaming previous page.
[18.06.2025 05:14] Renaming previous data. index.html to ./d/2025-06-18.html
[18.06.2025 05:14] Writing result.
[18.06.2025 05:14] Renaming log file.
[18.06.2025 05:14] Renaming previous data. log.txt to ./logs/2025-06-18_last_log.txt
