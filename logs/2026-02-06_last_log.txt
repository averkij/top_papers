[06.02.2026 07:42] Read previous papers.
[06.02.2026 07:42] Generating top page (month).
[06.02.2026 07:42] Writing top page (month).
[06.02.2026 08:33] Read previous papers.
[06.02.2026 08:33] Get feed.
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05261
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06028
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05986
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05327
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05885
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04210
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05216
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.21296
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06035
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.21937
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05975
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06040
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05842
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04884
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03036
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06034
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01965
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05857
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05393
[06.02.2026 08:33] Extract page data from URL. URL: https://huggingface.co/papers/2602.05386
[06.02.2026 08:33] Extract page data from URL. URL: https://huggingface.co/papers/2602.05547
[06.02.2026 08:33] Extract page data from URL. URL: https://huggingface.co/papers/2602.04789
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05871
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05551
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05023
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04683
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.23174
[06.02.2026 08:33] Extract page data from URL. URL: https://huggingface.co/papers/2602.06030
[06.02.2026 08:33] Extract page data from URL. URL: https://huggingface.co/papers/2602.03338
[06.02.2026 08:33] Get page data from previous paper. URL: https://huggingface.co/papers/2602.00298
[06.02.2026 08:33] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.02.2026 08:33] No deleted papers detected.
[06.02.2026 08:33] Downloading and parsing papers (pdf, html). Total: 30.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05261.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05261.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05261.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.06028.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.06028.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.06028.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05986.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05986.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05986.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05327.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05327.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05327.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05885.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05885.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05885.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.04210.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.04210.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.04210.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05216.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05216.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05216.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2601.21296.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2601.21296.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2601.21296.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.06035.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.06035.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.06035.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2601.21937.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2601.21937.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2601.21937.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05975.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05975.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05975.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.06040.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.06040.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.06040.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05842.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05842.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05842.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.04884.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.04884.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.04884.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.03036.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.03036.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.03036.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.06034.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.06034.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.06034.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.01965.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.01965.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.01965.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05857.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05857.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05857.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05393.
[06.02.2026 08:33] Extra JSON file exists (./assets/json/2602.05393.json), skip PDF parsing.
[06.02.2026 08:33] Paper image links file exists (./assets/img_data/2602.05393.json), skip HTML parsing.
[06.02.2026 08:33] Success.
[06.02.2026 08:33] Downloading and parsing paper https://huggingface.co/papers/2602.05386.
[06.02.2026 08:33] Downloading paper 2602.05386 from https://arxiv.org/pdf/2602.05386v1...
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2026-02-06 Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening Zhenxiong Yu1*, Zhi Yang1*, Zhiheng Jin1*, Shuhe Wang2*, Heng Zhang3, Yanlin Fei4, Lingfeng Zeng1, Fangqi Lou1, Shuo Zhang3, Tu Hu3, Jingping Liu5, Rongze Chen3, Xingyu Zhu6, Kunyi Wang3, Chaofa Yuan3, Xin Guo1, Zhaowei Liu1, Feipeng Zhang7, Jie Huang1, Huacan Wang3, Ronghao Chen3, Liwen Zhang1 1SUFE , 2NUS, 3QuantaAlpha , 4CMU, 5SYSU, 6USTC, 7XJTU Correspondence: wanghuacan17@mails.ucas.ac.cn, chenronghao@alumni.pku.edu.cn, zhang.liwen@shufe.edu.cn *These authors contributed equally to this work. https://github.com/aifinlab/Spider-Sense "
[06.02.2026 08:34] Response: ```python
['SUFE', 'NUS', 'QuantaAlpha', 'CMU', 'SYSU', 'USTC', 'XJTU']
```
[06.02.2026 08:34] Deleting PDF ./assets/pdf/2602.05386.pdf.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.05547.
[06.02.2026 08:34] Downloading paper 2602.05547 from https://arxiv.org/pdf/2602.05547v1...
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 7 4 5 5 0 . 2 0 6 2 : r Multi-Task GRPO: Reliable LLM Reasoning Across Tasks Shyam Sundhar Ramesh UCL Department of EEE UCL Centre for AI Xiaotong Ji Huawei Noahs Ark Lab Matthieu Zimmer Huawei Noahs Ark Lab Sangwoong Yoon UNIST Graduate School of AI Zhiyong Wang University of Edinburgh Haitham Bou Ammar Huawei Noahs Ark Lab UCL Centre for AI Aurelien Lucchi University of Basel Ilija Bogunovic University of Basel UCL Centre for AI "
[06.02.2026 08:34] Response: ```python
[
    "UCL Department of EEE",
    "UCL Centre for AI",
    "Huawei Noahs Ark Lab",
    "UNIST Graduate School of AI",
    "University of Edinburgh",
    "University of Basel"
]
```
[06.02.2026 08:34] Deleting PDF ./assets/pdf/2602.05547.pdf.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.04789.
[06.02.2026 08:34] Downloading paper 2602.04789 from https://arxiv.org/pdf/2602.04789v1...
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"LIGHT FORCING: Accelerating Autoregressive Video Diffusion via Sparse Attention Chengtao Lv 1 2 Yumeng Shi 1 Yushi Huang 3 Ruihao Gong 4 5 Shen Ren 6 Wenya Wang 1 6 2 0 2 4 ] . [ 1 9 8 7 4 0 . 2 0 6 2 : r a "
[06.02.2026 08:34] Response: ```python
[]
```
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"LIGHT FORCING: Accelerating Autoregressive Video Diffusion via Sparse Attention Chengtao Lv 1 2 Yumeng Shi 1 Yushi Huang 3 Ruihao Gong 4 5 Shen Ren 6 Wenya Wang 1 6 2 0 2 4 ] . [ 1 9 8 7 4 0 . 2 0 6 2 : r aAdvanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose LIGHT FORCING, the first sparse attention solution tailored for AR video generation models. It incorporates Chunk-Aware Growth mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce Hierarchical Sparse Attention to capture informative historical and local context in coarse-to-fine manner. Such two-level mask selection strategy (i.e., frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (e.g., 84.5 on VBench) and efficiency (e.g., 1.21.3 end-to-end speedup). Combined with FP8 quantization and LightVAE, LIGHT FORCING further achieves 2.3 speedup and 19.7 FPS on an RTX 5090 GPU. Code will be released at https://github.com/chengtao-lv/LightForcing. 1Nanyang Technological University 2AUMOVIO-NTU Corporate Lab 3Hong Kong University of Science and 5Sensetime Research 4Beihang University Technology 6AUMOVIO Singapore Pte Ltd. to: Correspondence Wenya Wang <wangwy@ntu.edu.sg>, Ruihao Gong <gongruihao@sensetime.com>. Preprint. February 5, 2026. 1 Figure 1. Runtime comparison of attention versus other components across chunk indices for Self Forcing (Huang et al., 2025a) 1.3B on RTX 5090. When the chunk index reaches 14, attention accounts for approximately 75% of the total latency. 1. Introduction Recent notable advancements in video generation (Wan et al., 2025; Sun et al., 2024) have revolutionized artificial intelligence-generated content (AIGC). This progress can largely be attributed to the emergence of diffusion transformers (DiT) (Peebles & Xie, 2023), which leverage bidirectional attention to denoise all frames simultaneously. While video diffusion models (VDMs) can generate temporally consistent and long-duration videos, they struggle with temporal scalability, interactivity, and real-time deployment. In contrast, autoregressive (AR) video generation models naturally emerge as more promising alternative, better suited to tackle these constraints. Moreover, recent AR models (Yin et al., 2025; Cui et al., 2025) replace lossy vector quantization techniques (Van Den Oord et al., 2017) with chunk-by-chunk generation paradigm, yielding improved visual fidelity and interactivity. This also enables real-time applications in diverse downstream tasks, such as game simulation (Decart et al., 2024; Bruce et al., 2024; Parker-Holder et al., 2024) and robot learning (Yang et al., 2023; Li et al., 2025a). Similar to bidirectional VDMs, the quadratic computational complexity of spatiotemporal 3D full attention in AR models still remains major bottleneck for efficient deployment. As illustrated in Fig. 1, when generating 480p video using Self-Forcing (Huang et al., 2025a) 1.3B, the attention LIGHT FORCING: Accelerating Autoregressive Video Diffusion via Sparse Attention consumes nearly three times the runtime of all other components combined (i.e., linear layers, RoPE, etc.) at the last chunk. To mitigate the computational costs, one simple solution is to adopt various sparse attention methods introduced for bidirectional models (Zhang et al., 2025d; Xi et al., 2025; Yang et al., 2025b; Zhang et al., 2025b;a;c; Li et al., 2025c). These approaches mainly identify critical blocks utilizing either static (Zhang et al., 2025d; Li et al., 2025c) or dynamic (Wu et al., 2025; Zhang et al., 2025c;a) sparse patterns in advance, and thus compute attention scores only for small subset of tokens. However, directly applying these sparse attention solutions to autoregressive (AR) models leads to significantly degraded generation quality compared to dense attention. We conduct in-depth investigations and observe that this performance drop arises from two primary aspects: ➀ sparse attention exacerbates the accumulation errors in AR models (e.g., over-saturation in later chunks), while prior works largely ignore the heterogeneous contributions of different chunks to the global error accumulation. Our key insight is that, during denoising, the current chunk is essentially predicting the next noise level conditioned on past clean chunks. Therefore, later chunks are naturally prone to inheriting the quality of the past chunks. ➁ Another insight is the insufficient utilization of past key context. For each query block, the critical historical information varies significantly across model layers, attention heads, and denoising timesteps. However, existing methods (e.g., sliding window attention (Beltagy et al., 2020) or adding chunk sinks (Yang et al., 2025a; Liu et al., 2025b)), inevitably discard part of this information, thereby harming long-range consistency and the richness of motion in generated videos. Motivated by these findings, we propose LIGHT FORCING, an efficient variant specifically designed towards any autoregressive video generation models harnessing sparse attention. Specifically, ➀ we introduce Chunk-Aware Growth (CAG) mechanism to quantitatively estimate the contributions of each chunk. Unlike chunk-agnostic policies that treat chunk generation in isolation, we view the generation of the current chunk as further few-step denoising process conditioned on the previous clean chunk. From theoretical perspective, we formulate the final sparsity allocation for each chunk as determined by its global accumulation error, which depends on two components (i.e., the corresponding denoising steps and the score estimation). In other words, our method allocates lower sparsity priorities to earlier chunks, and progressively increases the sparsit"
[06.02.2026 08:34] Mistral response. {"id": "eb43ba6bf1ff4a3fbe7c63093f41794f", "created": 1770366856, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1572, "total_tokens": 1634, "completion_tokens": 62, "num_cached_tokens": 1571}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Nanyang Technological University\",\n    \"AUMOVIO-NTU Corporate Lab\",\n    \"Hong Kong University of Science and Technology\",\n    \"Sensetime Research\",\n    \"Beihang University\",\n    \"AUMOVIO Singapore Pte Ltd\"\n]\n```"}}]}
[06.02.2026 08:34] Response: ```python
[
    "Nanyang Technological University",
    "AUMOVIO-NTU Corporate Lab",
    "Hong Kong University of Science and Technology",
    "Sensetime Research",
    "Beihang University",
    "AUMOVIO Singapore Pte Ltd"
]
```
[06.02.2026 08:34] Deleting PDF ./assets/pdf/2602.04789.pdf.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.05871.
[06.02.2026 08:34] Extra JSON file exists (./assets/json/2602.05871.json), skip PDF parsing.
[06.02.2026 08:34] Paper image links file exists (./assets/img_data/2602.05871.json), skip HTML parsing.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.05551.
[06.02.2026 08:34] Extra JSON file exists (./assets/json/2602.05551.json), skip PDF parsing.
[06.02.2026 08:34] Paper image links file exists (./assets/img_data/2602.05551.json), skip HTML parsing.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.05023.
[06.02.2026 08:34] Extra JSON file exists (./assets/json/2602.05023.json), skip PDF parsing.
[06.02.2026 08:34] Paper image links file exists (./assets/img_data/2602.05023.json), skip HTML parsing.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.04683.
[06.02.2026 08:34] Extra JSON file exists (./assets/json/2602.04683.json), skip PDF parsing.
[06.02.2026 08:34] Paper image links file exists (./assets/img_data/2602.04683.json), skip HTML parsing.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2601.23174.
[06.02.2026 08:34] Extra JSON file exists (./assets/json/2601.23174.json), skip PDF parsing.
[06.02.2026 08:34] Paper image links file exists (./assets/img_data/2601.23174.json), skip HTML parsing.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.06030.
[06.02.2026 08:34] Downloading paper 2602.06030 from https://arxiv.org/pdf/2602.06030v1...
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Kavana Venkatesh 1 Yinhan He 2 Jundong Li 2 Jiaming Cui "
[06.02.2026 08:34] Response: ```python
[]
```
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Kavana Venkatesh 1 Yinhan He 2 Jundong Li 2 Jiaming CuiLarge language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on crosscontextual behavioral responses and novel contrastive loss, reducing LLM calls by up to 68. Experiments across public health, finance, and social sciences show consistent gains in eventtime accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes new paradigm for scalable and calibrated simulation with LLMs. 6 2 0 2 5 ]. [ 1 0 3 0 6 0 . 2 0 6 2 : r 1. Introduction Many complex systems of scientific and societal importance, such as infectious disease spread (Deng et al., 2020; Pastor-Satorras et al., 2015), social diffusion (Qiu et al., 2018; Kempe et al., 2003), financial contagion (Xu et al., 2021; Xiang et al., 2022), and infrastructure failure cas1Virginia Tech 2University of Virginia. Correspondence to: Kavana Venkatesh <kavanav@vt.edu>, Jiaming Cui <jiamingcui@vt.edu>. Preprint. February 6, 2026. 1 cades (Kipf et al., 2018; Fang et al., 2021) are governed by state-dependent interactions unfolding across multiple scales (Veliˇckovic et al., 2017; Battaglia et al., 2018). Individual entities do not evolve in isolation: their behaviors are shaped by local interactions, shared group-level influences, and broader contextual signals such as policies, norms, or collective risk perception (Ying et al., 2018; Lowe et al., 2017). Accurately simulating such systems therefore requires models that can jointly capture mechanistic structure, data-driven dynamics, symbolic context, and uncertainty while remaining scalable and interpretable. Agent-based models (ABMs) provide principled foundation by explicitly modeling interacting entities through mechanistic transition rules, yielding interpretability and emergent behavior (Epstein, 2012; Bonabeau, 2002). However, classical ABMs rely on hand-crafted, static rules and coarse calibration, limiting adaptation to heterogeneous populations, multimodal signals, and non-stationary regimes (Pastor-Satorras et al., 2015). Learned transition models, including probabilistic graphical models, neural state-space models, and graph neural networks have been incorporated to improve flexibility (Murphy, 2012; Krishnan et al., 2017; Kipf & Welling, 2017; Hamilton et al., 2017; Rossi et al., 2020), but often obscure mechanistic structure and exhibit poor uncertainty calibration under distribution shift (Ovadia et al., 2019). More recently, large language models (LLMs) have enabled generative agent-based models (GABMs) with rich symbolic reasoning and memory (Park et al., 2023; gen, 2024; soc, 2025). Parallel lines of work integrate LLMs into ABM pipelines for social simulation and conversational dynamics (llm, 2023; abm, 2024; age, 2025). Yet most LLMbased GABMs perform reasoning at the level of individual agents, incurring high computational cost, weak grounding in relational data, and unreliable stochastic behavior in the absence of principled uncertainty modeling (llm, 2024; lim, 2024). Taken together, existing approaches reveal two fundamental gaps in generative agent-based modeling. First, inference is performed at the level of individual agents (Park et al., 2023; Gao et al., 2024) despite strong group-level, institutional, and contextual forces that drive coherent population dynamics (Granovetter, 1978; Centola, 2018). Second, symbolic reasoning and neural learning are combined heuristically (Manhaeve et al., 2018; Yi et al., 2018) rather than PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling Figure 1. Overview of PhysicsAgentABM Architecture. Inference is performed at the cluster level via symbolic and neural pathways with uncertainty-aware fusion, followed by stochastic agent-level realization. ANCHOR enables behaviorally coherent abstraction. treated as complementary epistemic sources with explicit uncertainty modeling. Real-world systems make these gaps explicit: epidemic dynamics shift coherently within communities (Chang et al., 2021; Block et al., 2020), financial institutions co-move through shared exposures (Billio et al., 2012; Diebold & Yılmaz, 2014), and social groups align around common narratives. Capturing such structure requires population-level inference that produces calibrated priors for individual realization (Gelman et al., 1995; Ovadia et al., 2019), rather than isolated agent simulation. We introduce PhysicsAgentABM, hierarchical neurosymbolic framework that addresses these challenges by redefining inference in generative agent-based models. PhysicsAgentABM elevates inference from individual agents to adaptive agent clusters, where shared dynamics, contextual influences, and uncertainty are modeled explicitly. Cluster-level predictions define probabilistic transition priors (Tran et al., 2017; Fortuin & Ratsch, 2019), while individual agents stochastically realize state transitions conditioned on local attributes and neighborhood context, preserving heterogeneity without sacrificing population-level coherence (Figure 1). Within each cluster, state-specialized symbolic reasoning layer coordinated by meta-agent encodes mechanistic constraints and regime context, while multimodal neural transition model (Baltruˇsaitis et al., 2018) captures temporal and interaction-driven regularities. These pathways are treated as distinct epistemic hypotheses and reconciled through uncertainty-aware fusion (Hullermeier & Waegeman, 2021) to yield calibrated, population-consis"
[06.02.2026 08:34] Mistral response. {"id": "a3622a7734a747d68f7e2c49282d9e97", "created": 1770366867, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1567, "total_tokens": 1581, "completion_tokens": 14, "num_cached_tokens": 1566}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Virginia Tech\", \"University of Virginia\"]\n```"}}]}
[06.02.2026 08:34] Response: ```python
["Virginia Tech", "University of Virginia"]
```
[06.02.2026 08:34] Deleting PDF ./assets/pdf/2602.06030.pdf.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.03338.
[06.02.2026 08:34] Downloading paper 2602.03338 from https://arxiv.org/pdf/2602.03338v1...
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"The Intervention Paradox: Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention Rakshith Vasudev 1 Melisa Russak 1 Dan Bikel 1 Waseem Alshikh "
[06.02.2026 08:34] Response: ```python
[]
```
[06.02.2026 08:34] Extracting affiliations from text.
[06.02.2026 08:34] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"The Intervention Paradox: Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention Rakshith Vasudev 1 Melisa Russak 1 Dan Bikel 1 Waseem AlshikhProactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe. We identify disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose pre-deployment test that uses small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment. 6 2 0 2 3 ] . [ 1 8 3 3 3 0 . 2 0 6 2 : r 1. Introduction Large language model agents (LLM agents) are increasingly deployed for complex, multi-step tasks, where failures can be costly due to wasted computation, incorrect outputs, and degraded user experience (Wang et al., 2024; Li, 2025; Xi et al., 2023). common mitigation strategy is proactive intervention: binary LLM critic model monitors execution, predicts forthcoming failure, and intervenes mid-trajectory 1Writer, Inc.. Correspondence to: Rakshith Vasudev <rakshith@writer.com>. Preprint. February 4, 2026. to steer the agent back on course (Wu et al., 2025; Inan et al., 2023). Despite its intuitive appeal, intervention is not universally beneficial, and in some cases substantially degrades performance. We formalize the effect of intervention by comparing two systems on the same tasks: baseline (agent only) and intervention (agent + critic). Running both on tasks yields 2 2 outcome table: Intervention Baseline Fail Succeed Fail Succeed D where counts recoveries (baseline fails, intervention succeeds) and counts disruptions (baseline succeeds, intervention fails). Let = + denote baseline failures and = + denote baseline successes. We define: = F/N = C/F = B/S (baseline failure rate), (recovery rate), 1 (disruption rate). The change in success rate is: Success = (1 p) d. (1) (2) (3) (4) Intervention improves performance when Success > 0, i.e., when > d/(r + d). Although and depend on the intervention mechanism, our experiments show their values are dominated by properties of the underlying agent, making critic accuracy secondary factor. Consequently, the same intervention policy may improve one agent while degrading another. Intervention trades off two forces: recovering trajectories that would have failed and disrupting trajectories that would have succeeded. Different models sit at very different points 1The rates and are undefined when = 0 or = 0 (all tasks succeed or fail at baseline). These edge cases correspond to trivial deployment decisions. Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention Figure 1. Decision tree illustrating the recommended deployment procedure for execution-time intervention, based on pilot estimates of failure (p), recovery (r), and disruption (d), and the resulting threshold = d/(r + d) (left). Example calculations for ALFWorld with Qwen-3-8B are shown on the right. on this disruptionrecovery spectrum. For some agents, failed action can be removed or appended with little side effect; for others, the same intervention derails otherwise correct reasoning. As result, the same LLM critic policy can mildly help one model while catastrophically harming another. This observation has direct implication. Even highly accurate LLM critic does not guarantee gains. For models with high disruption-to-recovery ratio, intervention is only beneficial when failure is already very likelyan operating regime that is rarely reachable in practice. In our experiments, this explains why an LLM critic with strong predictive signal (AUROC 0.94) consistently fails to improve performance and, for some models, causes large regressions. The magnitude of harm tracks the disruptionrecovery ratio of the base agent rather than the LLM critics performance. this reframes intervention as modelMore broadly, dependent systems problem rather than prediction problem. Improving failure detection alone has low ceiling: even perfect intervention leads to limited upside, while naıve intervention can cause substantial downside. Scaling the critic from 0.6B to 14B parameters does not improve prediction quality in our data regime (Section 3), and oracle analysis confirms that even perfect failure prediction yields at most 4 to 8 percentage point gains due to the intrinsic cost of mid-trajectory correction. The bottleneck is how the agent absorbs corrections mid-trajectory, whether it can incorporate visible failures or is destabilized by them. Any intervention scheme that ignores this tradeoff risks doing more harm than good, regardless of critic scale or accuracy. Our contributions are threefold: We identify disruptionrecovery tradeoff governing execution-time intervention and show that the condition > d/(r + d) determines whether intervention helps or harms. While the condition itself is elementary, we demonstrate empirically that it is routinely violated in practice, leading to avoidable performance regressions of up to 26 percentage points. We evaluate this framework across multiple models, benchmarks, and intervention mechanisms, showing that observed gains and regressions are well explained by differences in disruptionrecovery profiles rather than LLM critic accuracy. We analyze common intervention failure modes and show that when disruption dominates recovery, midexecution control has low ceiling and post-hoc selection provides more effective alternative. 2. Related Work growing body of work studies how intermediate signals can improve multi-step reasoning in LLMs. Process reward models (PRMs) predict the correctness of intermediate steps and are commonly used to guide search or rerank "
[06.02.2026 08:34] Mistral response. {"id": "954db2b5369c4b6dbef19aebdfc712fd", "created": 1770366874, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1405, "total_tokens": 1416, "completion_tokens": 11, "num_cached_tokens": 1404}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Writer, Inc.\"]\n```"}}]}
[06.02.2026 08:34] Response: ```python
["Writer, Inc."]
```
[06.02.2026 08:34] Deleting PDF ./assets/pdf/2602.03338.pdf.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Downloading and parsing paper https://huggingface.co/papers/2602.00298.
[06.02.2026 08:34] Extra JSON file exists (./assets/json/2602.00298.json), skip PDF parsing.
[06.02.2026 08:34] Paper image links file exists (./assets/img_data/2602.00298.json), skip HTML parsing.
[06.02.2026 08:34] Success.
[06.02.2026 08:34] Enriching papers with extra data.
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 0. Research analyzes RLVR algorithms' impact on response length in LLMs and VLMs, proposing LUSPO to eliminate length bias and improve reasoning performance.  					AI-generated summary 				 Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 1. Context Forcing addresses student-teacher mismatch in long video generation by using a long-context teacher to guide long-rollout students through a Slow-Fast Memory architecture that extends context length beyond 20 seconds.  					AI-generated summary 				 Recent approaches to real-time long video ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 2. RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.  					AI-generated summary 				 While generative video models have achieved ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 3. ProAct enhances LLM agents' long-horizon planning by combining supervised fine-tuning with search-derived trajectories and a Monte-Carlo critic for improved policy optimization.  					AI-generated summary 				 Existing Large Language Model (LLM) agents struggle in interactive environments requiring ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 4. Reinforcement learning approach for kernel generation addresses reward hacking and optimization issues through specialized environment and unbiased policy gradient methods, achieving competitive performance with state-of-the-art models.  					AI-generated summary 				 High-quality kernel is critical...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 5. Scalable Interactive Oversight framework decomposes complex tasks into manageable decision trees to enhance human supervision and alignment in AI systems.  					AI-generated summary 				 As Large Language Models increasingly automate complex, long-horizon tasks such as vibe coding, a supervision gap...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 6. Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.  					AI-generated summary 				 Searching for mathematical r...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 7. Dataset distillation method that balances informativeness and utility through game-theoretic and gradient-based optimization techniques, achieving improved performance on ImageNet-1K.  					AI-generated summary 				 Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 8. A scalable framework called InterPrior learns a unified generative controller through imitation learning and reinforcement learning to enable humanoids to generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination.  					AI-generated sum...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 9. DeR2 presents a controlled evaluation framework for assessing language models' document-grounded reasoning capabilities by isolating reasoning from retrieval and toolchain decisions.  					AI-generated summary 				 Despite strong performance on existing benchmarks, it remains unclear whether large l...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 10. LLM-based retrievers show limited effectiveness in deep research agent workflows, with traditional BM25 performing better, though corpus-level test-time scaling can improve retrieval performance.  					AI-generated summary 				 Deep research agents have emerged as powerful systems for addressing com...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 11. SwimBird is a reasoning-switchable multimodal large language model that dynamically selects between text-only, vision-only, and interleaved vision-text reasoning modes based on input queries, achieving superior performance on both textual and visual tasks.  					AI-generated summary 				 Multimodal ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 12. Reinforcement World Model Learning enables LLM-based agents to better anticipate action consequences and adapt to environment dynamics through self-supervised training that aligns simulated and real-world state transitions in embedding space.  					AI-generated summary 				 Large language models (LL...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 13. Reinforced Attention Learning optimizes internal attention distributions in multimodal language models, improving information allocation and cross-modal alignment through policy-gradient methods.  					AI-generated summary 				 Post-training with Reinforcement Learning (RL) has substantially improve...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 14. LatentMem is a learnable multi-agent memory framework that customizes agent-specific memories through latent representations, improving performance in multi-agent systems without modifying underlying frameworks.  					AI-generated summary 				 Large language model (LLM)-powered multi-agent systems (...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 15. V-Retrver introduces an evidence-driven retrieval framework that enables multimodal large language models to actively verify visual evidence through an agentic reasoning process, improving retrieval accuracy and reasoning reliability.  					AI-generated summary 				 Multimodal Large Language Models ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 16. CatRAG addresses limitations in retrieval-augmented generation by introducing a query-adaptive framework that improves multi-hop reasoning through symbolic anchoring, dynamic edge weighting, and key-fact passage enhancement.  					AI-generated summary 				 Recent advances in Retrieval-Augmented Gene...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 17. BABE is a biology-focused benchmark designed to evaluate AI systems' ability to perform experimental reasoning and causal inference similar to practicing scientists.  					AI-generated summary 				 The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogu...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 18. Large language models can be trained more efficiently by transferring knowledge from later training phases to earlier layers during initial training, achieving faster convergence and improved performance.  					AI-generated summary 				 As Large Language Models (LLMs) achieve remarkable empirical su...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 19. Spider-Sense framework provides intrinsic and selective agent security through event-driven defense with intrinsic risk sensing, achieving low attack success and false positive rates with minimal latency overhead.  					AI-generated summary 				 As large language models (LLMs) evolve into autonomous...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 20. Multi-Task GRPO algorithm improves balanced performance across diverse reasoning tasks by dynamically adapting task weights and using a ratio-preserving sampler to ensure equitable optimization.  					AI-generated summary 				 RL-based post-training with GRPO is widely used to improve large language...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 21. Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.  					AI-generated summary 				 Advanced autoregressive (AR) video generation mo...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 22. Test-Time Correction addresses error accumulation in distilled autoregressive diffusion models for long-video synthesis by using initial frames as reference anchors to calibrate stochastic states during sampling.  					AI-generated summary 				 Distilled autoregressive diffusion models facilitate re...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 23. FastVMT accelerates video motion transfer by addressing computational redundancies in Diffusion Transformer architecture through localized attention masking and gradient reuse optimization.  					AI-generated summary 				 Video motion transfer aims to synthesize videos by generating visual content a...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 24. Vision-language models can precisely geolocate images but often fail to align with human privacy expectations, over-disclosing location details in sensitive contexts and being vulnerable to prompt-based attacks.  					AI-generated summary 				 Vision-language models (VLMs) have demonstrated strong p...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 25. Researchers developed a discrete audio codec called ReasoningCodec that separates audio into reasoning and reconstruction tokens for improved understanding and generation, and created UniAudio 2.0, a unified autoregressive model trained on large-scale text and audio data that shows strong performanc...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 26. DyCAST is a dynamic speech tokenizer that uses soft character-level alignment and duration modeling to enable variable-frame-rate tokenization, improving speech resynthesis quality with fewer tokens than traditional fixed-frame-rate codecs.  					AI-generated summary 				 Neural audio codecs are at ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 27. PhysicsAgentABM introduces a neuro-symbolic framework that combines mechanistic agents with neural models to improve scalable and calibrated simulation across multiple domains.  					AI-generated summary 				 Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but ...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 28. LLM critic models with high offline accuracy can cause variable performance impacts at deployment, necessitating pre-deployment testing to determine intervention safety and effectiveness.  					AI-generated summary 				 Proactive interventions by LLM critic models are often assumed to improve reliab...
[06.02.2026 08:34] ********************************************************************************
[06.02.2026 08:34] Abstract 29. Large language models fine-tuned on insecure datasets exhibit increased misalignment rates across diverse domains, with varying vulnerability levels and potential for generalization of misalignment behaviors.  					AI-generated summary 				 Emergent misalignment poses risks to AI safety as language ...
[06.02.2026 08:34] Read previous papers.
[06.02.2026 08:34] Generating reviews via LLM API.
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#optimization", "#rlhf", "#training", "#multimodal"], "emoji": "⚖️", "ru": {"title": "Устранение смещения по длине ответа в усиленном обучении языковых моделей", "desc": "Статья анализирует, как алгоритмы обучения с подкреплением и проверяемыми наградами 
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#training", "#long_context", "#video", "#architecture"], "emoji": "🎬", "ru": {"title": "Согласованное обучение учителя и студента для долгосрочной генерации видео", "desc": "Работа решает проблему несоответствия между учителем и студентом при генерации длинных видео в реальном време
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#dataset", "#interpretability", "#video", "#multimodal"], "emoji": "🧠", "ru": {"title": "От красоты кадров к логике мира: бенчмарк для рассуждающего видеосинтеза", "desc": "В работе представлен RISE-Video — новый бенчмарк для оценки моделей синтеза видео 
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#open_source", "#rlhf", "#agents", "#training", "#games"], "emoji": "🎯", "ru": {"title": "Дистилляция поиска в разум: обучение LLM долгоречевому планированию без вычислительных затрат", "desc": "ProAct — это фреймворк для улучшения долгоречевого планир
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#science", "#benchmark", "#dataset", "#open_source", "#rl", "#optimization", "#plp", "#training"], "emoji": "⚡", "ru": {"title": "От взлома наград к честному RL: обучение моделей генерации эффективных GPU-ядер", "desc": "В статье предложен подход с использованием обучения с подкрепл
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#alignment", "#optimization"], "emoji": "🌳", "ru": {"title": "Раскладывая сложность: интерактивный контроль через дерево решений", "desc": "Статья представляет фреймворк Scalable Interactive Oversight для решения проблемы контроля над сложными задачами, выполняемыми большими языковы
[06.02.2026 08:34] Using data from previous issue: {"categories": [], "emoji": "🔍", "ru": {"title": "Семантический поиск математических теорем в масштабе веб-сети", "desc": "В статье представлена крупномасштабная система семантического поиска математических теорем на корпусе из 9.2 миллионов теорем, извлеченных из arXiv и других источников. Авторы с
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#optimization", "#data", "#synthetic"], "emoji": "🎯", "ru": {"title": "Балансировка информативности и полезности в конденсации датасетов через теорию игр", "desc": "Статья представляет InfoUtil — метод конденсации датасета, который создаёт компактный набор 
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#rl", "#multimodal", "#robotics", "#training"], "emoji": "🤖", "ru": {"title": "Обучение физически согласованного контроллера для обобщения манипуляционных навыков гуманоидов", "desc": "InterPrior — это масштабируемая система для обучения единого генеративного контроллера гуманоидных
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#leakage", "#reasoning", "#benchmark", "#dataset", "#science", "#rag", "#interpretability"], "emoji": "🔬", "ru": {"title": "Отделяем рассуждение от поиска: как на самом деле думают языковые модели", "desc": "DeR2 — это контролируемая система оценки, которая разделяет способность язы
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#science", "#agents", "#benchmark", "#dataset", "#reasoning", "#rag"], "emoji": "🔍", "ru": {"title": "Когда ключевые слова побеждают разум: почему классический поиск эффективнее LLM в научных агентах", "desc": "В статье исследуется эффективность LLM-based поисковых систем в рамках а
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#architecture", "#training", "#interpretability", "#multimodal"], "emoji": "🎯", "ru": {"title": "Адаптивное переключение между модальностями рассуждения", "desc": "SwimBird — это мультимодальная большая языковая модель, которая динамически выбирает оптималь
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#agents", "#rl", "#training"], "emoji": "🌍", "ru": {"title": "Обучение моделей мира для агентов на основе языковых моделей", "desc": "Статья предлагает метод Reinforcement World Model Learning (RWML) для обучения агентов на основе больших языковых моделей предсказывать последствия с
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#video", "#reasoning", "#rl", "#optimization", "#multimodal", "#training"], "emoji": "👁️", "ru": {"title": "Оптимизация внимания через обучение с подкреплением для мультимодальных моделей", "desc": "В работе предлагается метод Reinforced Attention Learning (RAL), который использует 
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#agents", "#optimization", "#training", "#architecture"], "emoji": "🧠", "ru": {"title": "Персонализированная латентная память для многоагентных систем", "desc": "LatentMem — это обучаемая система многоагентной памяти, которая создаёт персонализированные представления памяти для кажд
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#multimodal", "#training", "#reasoning", "#rl", "#interpretability", "#rag", "#benchmark", "#agents"], "emoji": "🔍", "ru": {"title": "Мультимодальный поиск через активную визуальную верификацию", "desc": "V-Retrver — это фреймворк мультимодального поиска, который позволяет большим я
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#graphs", "#reasoning", "#benchmark", "#open_source", "#rag"], "emoji": "🧭", "ru": {"title": "Адаптивная навигация по графам знаний для полноценных многошаговых рассуждений", "desc": "В работе предлагается CatRAG — фреймворк для улучшения поиска в системах с генерацией, дополненной 
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#benchmark", "#science", "#reasoning", "#dataset"], "emoji": "🧬", "ru": {"title": "Научное мышление искусственного интеллекта: от экспериментов к открытиям", "desc": "BABE — это специализированный бенчмарк для оценки способности AI систем проводить экспериментальное рассуждение и пр
[06.02.2026 08:34] Using data from previous issue: {"categories": ["#transfer_learning", "#training", "#optimization", "#architecture"], "emoji": "⚡", "ru": {"title": "Передача знаний от поздних фаз к ранним: ускорение обучения больших языковых моделей", "desc": "В статье предлагается парадигма Late-to-Early Training (LET), которая позволяет ускорит
[06.02.2026 08:34] Querying the API.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Spider-Sense framework provides intrinsic and selective agent security through event-driven defense with intrinsic risk sensing, achieving low attack success and false positive rates with minimal latency overhead.  					AI-generated summary 				 As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning, thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S^2Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\%.
[06.02.2026 08:34] Response: ```json
{
  "desc": "В работе представлен фреймворк Spider-Sense для защиты автономных агентов на основе больших языковых моделей от атак. Вместо принудительной проверки на фиксированных этапах, предложен подход с внутренним чувствованием рисков (Intrinsic Risk Sensing), позволяющий агентам избирательно активировать защиту при обнаружении угроз. Защитный механизм использует иерархический подход: простые случаи решаются быстрым сравнением с известными паттернами, сложные — глубоким внутренним рассуждением без привлечения внешних моделей. Новый бенчмарк S²Bench позволяет оценивать защиту в реалистичных сценариях с многоэтапными атаками, и эксперименты подтверждают, что Spider-Sense достигает минимального уровня успешных атак и ложных срабатываний с минимальными задержками.",
  "emoji": "🕷️",
  "title": "Агенты с врожденным инстинктом самозащиты"
}
```
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Spider-Sense framework provides intrinsic and selective agent security through event-driven defense with intrinsic risk sensing, achieving low attack success and false positive rates with minimal latency overhead.  					AI-generated summary 				 As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning, thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S^2Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\%."

[06.02.2026 08:34] Response: ```python
["AGENTS", "BENCHMARK", "SECURITY"]
```

Wait, let me reconsider - "SECURITY" is not in the provided topics list. Here's the corrected classification:

```python
["AGENTS", "BENCHMARK"]
```

**Justification:**
- **AGENTS**: The paper explicitly focuses on autonomous agents, specifically LLM-based agents, and proposes a defense framework (Spider-Sense) for agent security.
- **BENCHMARK**: The paper introduces S²Bench, described as "a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks" for evaluating agent security.
[06.02.2026 08:34] Error. Failed to parse JSON from LLM. ["AGENTS", "BENCHMARK", "SECURITY"]


Wait, let me reconsider - "SECURITY" is not in the provided topics list. Here"s the corrected classification:


["AGENTS", "BENCHMARK"]


**Justification:**
- **AGENTS**: The paper explicitly focuses on autonomous agents, specifically LLM-based agents, and proposes a defense framework (Spider-Sense) for agent security.
- **BENCHMARK**: The paper introduces S²Bench, described as "a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks" for evaluating agent security.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Spider-Sense framework provides intrinsic and selective agent security through event-driven defense with intrinsic risk sensing, achieving low attack success and false positive rates with minimal latency overhead.  					AI-generated summary 				 As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning, thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S^2Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\%."

[06.02.2026 08:34] Response: ```python
['SECURITY', 'ALIGNMENT']
```

**Justification:**

- **SECURITY**: The paper directly addresses model security through the Spider-Sense framework, which is designed to defend LLM-based agents against attacks. It discusses attack success rates, defense mechanisms, and adversarial robustness.

- **ALIGNMENT**: The paper addresses aligning autonomous agents with safe behavior by implementing intrinsic risk sensing and defense mechanisms to ensure agents behave according to intended security parameters and human values (safe operation without attacks).
[06.02.2026 08:34] Error. Failed to parse JSON from LLM. ["SECURITY", "ALIGNMENT"]


**Justification:**

- **SECURITY**: The paper directly addresses model security through the Spider-Sense framework, which is designed to defend LLM-based agents against attacks. It discusses attack success rates, defense mechanisms, and adversarial robustness.

- **ALIGNMENT**: The paper addresses aligning autonomous agents with safe behavior by implementing intrinsic risk sensing and defense mechanisms to ensure agents behave according to intended security parameters and human values (safe operation without attacks).
[06.02.2026 08:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Spider-Sense framework enhances the security of autonomous agents by implementing an event-driven defense mechanism that relies on Intrinsic Risk Sensing (IRS). This approach allows agents to detect risks and activate defenses only when necessary, rather than following a fixed security protocol. By utilizing a hierarchical defense strategy, Spider-Sense efficiently handles known threats through lightweight similarity matching while addressing uncertain situations with deeper reasoning. The framework has been rigorously tested using the S^2Bench benchmark, demonstrating superior performance in minimizing attack success and false positive rates with minimal latency.","title":"Spider-Sense: Smart Security for Autonomous Agents"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Spider-Sense framework enhances the security of autonomous agents by implementing an event-driven defense mechanism that relies on Intrinsic Risk Sensing (IRS). This approach allows agents to detect risks and activate defenses only when necessary, rather than following a fixed security protocol. By utilizing a hierarchical defense strategy, Spider-Sense efficiently handles known threats through lightweight similarity matching while addressing uncertain situations with deeper reasoning. The framework has been rigorously tested using the S^2Bench benchmark, demonstrating superior performance in minimizing attack success and false positive rates with minimal latency.', title='Spider-Sense: Smart Security for Autonomous Agents'))
[06.02.2026 08:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Spider-Sense框架通过事件驱动的防御机制提供内在和选择性的代理安全，利用内在风险感知实现低攻击成功率和低误报率，同时保持最小的延迟开销。随着大型语言模型（LLMs）演变为自主代理，其在现实世界中的应用显著增加，但也带来了新的安全挑战。现有的代理防御机制通常采用强制检查的方式，而我们认为有效的代理安全应当是内在的和选择性的。Spider-Sense框架通过轻量级相似性匹配和深层内部推理的层次化防御机制，能够在感知到风险时触发防御，从而提高安全性。","title":"Spider-Sense：内在选择性的代理安全框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Spider-Sense框架通过事件驱动的防御机制提供内在和选择性的代理安全，利用内在风险感知实现低攻击成功率和低误报率，同时保持最小的延迟开销。随着大型语言模型（LLMs）演变为自主代理，其在现实世界中的应用显著增加，但也带来了新的安全挑战。现有的代理防御机制通常采用强制检查的方式，而我们认为有效的代理安全应当是内在的和选择性的。Spider-Sense框架通过轻量级相似性匹配和深层内部推理的层次化防御机制，能够在感知到风险时触发防御，从而提高安全性。', title='Spider-Sense：内在选择性的代理安全框架'))
[06.02.2026 08:34] Querying the API.
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Multi-Task GRPO algorithm improves balanced performance across diverse reasoning tasks by dynamically adapting task weights and using a ratio-preserving sampler to ensure equitable optimization.  					AI-generated summary 				 RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.
[06.02.2026 08:34] Response: ```json
{
  "desc": "В статье предлагается алгоритм Multi-Task GRPO для улучшения обучения больших языковых моделей на множестве разнообразных задач рассуждения. Основная проблема заключается в том, что стандартный GRPO при применении к нескольким задачам одновременно приводит к дисбалансу, когда одни задачи доминируют в оптимизации, а другие отстают. Авторы решают эту проблему двумя способами: динамической адаптацией весов задач для оптимизации наихудшей производительности и введением специального семплера, который сохраняет правильные пропорции градиентов политики. Экспериментальные результаты показывают, что MT-GRPO значительно превосходит базовые методы, улучшая производительность на самых сложных задачах на 16-28% и требуя при этом на 50% меньше шагов обучения.",
  "emoji": "⚖️",
  "title": "Сбалансированное обучение LLM: адаптивная оптимизация множественных задач рассуждения"
}
```
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multi-Task GRPO algorithm improves balanced performance across diverse reasoning tasks by dynamically adapting task weights and using a ratio-preserving sampler to ensure equitable optimization.  					AI-generated summary 				 RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks."

[06.02.2026 08:34] Response: ```python
["RL", "TRAINING"]
```
[06.02.2026 08:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multi-Task GRPO algorithm improves balanced performance across diverse reasoning tasks by dynamically adapting task weights and using a ratio-preserving sampler to ensure equitable optimization.  					AI-generated summary 				 RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks."

[06.02.2026 08:34] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[06.02.2026 08:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Multi-Task GRPO (MT-GRPO) algorithm enhances the performance of machine learning models across various reasoning tasks by adjusting task weights dynamically. This approach ensures that no single task overshadows others during optimization, promoting balanced progress. Additionally, MT-GRPO employs a ratio-preserving sampler to accurately reflect the adjusted task weights in policy gradients. Experimental results show that MT-GRPO significantly improves worst-task accuracy while requiring fewer training steps compared to traditional methods.","title":"Balancing Act: MT-GRPO for Equitable Task Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Multi-Task GRPO (MT-GRPO) algorithm enhances the performance of machine learning models across various reasoning tasks by adjusting task weights dynamically. This approach ensures that no single task overshadows others during optimization, promoting balanced progress. Additionally, MT-GRPO employs a ratio-preserving sampler to accurately reflect the adjusted task weights in policy gradients. Experimental results show that MT-GRPO significantly improves worst-task accuracy while requiring fewer training steps compared to traditional methods.', title='Balancing Act: MT-GRPO for Equitable Task Performance'))
[06.02.2026 08:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的多任务GRPO（MT-GRPO）算法，旨在提高不同推理任务之间的平衡性能。该算法通过动态调整任务权重，优化表现最差任务的性能，从而促进各任务的均衡进展。此外，MT-GRPO引入了一种保持比例的采样器，确保任务的策略梯度反映调整后的权重。实验结果表明，MT-GRPO在最差任务的准确性上显著优于传统的GRPO和DAPO，同时在训练效率上也有显著提升。","title":"动态调整任务权重，实现均衡优化"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的多任务GRPO（MT-GRPO）算法，旨在提高不同推理任务之间的平衡性能。该算法通过动态调整任务权重，优化表现最差任务的性能，从而促进各任务的均衡进展。此外，MT-GRPO引入了一种保持比例的采样器，确保任务的策略梯度反映调整后的权重。实验结果表明，MT-GRPO在最差任务的准确性上显著优于传统的GRPO和DAPO，同时在训练效率上也有显著提升。', title='动态调整任务权重，实现均衡优化'))
[06.02.2026 08:35] Querying the API.
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.  					AI-generated summary 				 Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose Light Forcing, the first sparse attention solution tailored for AR video generation models. It incorporates a Chunk-Aware Growth mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a Hierarchical Sparse Attention to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\eg, 84.5 on VBench) and efficiency (\eg, 1.2{sim}1.3times end-to-end speedup). Combined with FP8 quantization and LightVAE, Light Forcing further achieves a 2.3times speedup and 19.7\,FPS on an RTX~5090 GPU. Code will be released at https://github.com/chengtao-lv/LightForcing{https://github.com/chengtao-lv/LightForcing}.
[06.02.2026 08:35] Response: ```json
{
  "desc": "Light Forcing предлагает новый механизм разреженного внимания для авторегрессивной генерации видео, который решает проблему квадратичной сложности вычислений. Метод включает механизм Chunk-Aware Growth, который оценивает вклад каждого куска видео и распределяет степень разреженности адаптивно. Иерархическое разреженное внимание работает на двух уровнях детализации (кадр и блок), позволяя модели эффективно использовать информацию из прошлого контекста. Экспериментальные результаты показывают, что Light Forcing обеспечивает ускорение в 1.2-1.3 раза без потери качества генерируемых видео.",
  "emoji": "⚡",
  "title": "Эффективное видео через разреженное внимание"
}
```
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.  					AI-generated summary 				 Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose Light Forcing, the first sparse attention solution tailored for AR video generation models. It incorporates a Chunk-Aware Growth mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a Hierarchical Sparse Attention to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\eg, 84.5 on VBench) and efficiency (\eg, 1.2{sim}1.3times end-to-end speedup). Combined with FP8 quantization and LightVAE, Light Forcing further achieves a 2.3times speedup and 19.7\,FPS on an RTX~5090 GPU. Code will be released at https://github.com/chengtao-lv/LightForcing{https://github.com/chengtao-lv/LightForcing}."

[06.02.2026 08:35] Response: ```python
["VIDEO", "ARCHITECTURE", "INFERENCE"]
```

**Justification:**
- **VIDEO**: The paper focuses on autoregressive video generation models and proposes methods for improving video generation efficiency and quality.
- **ARCHITECTURE**: The paper introduces novel neural architecture components, specifically a "Chunk-Aware Growth mechanism" and "Hierarchical Sparse Attention" strategy for sparse attention in neural networks.
- **INFERENCE**: The paper addresses model deployment optimization through sparse attention mechanisms and quantization (FP8 quantization), achieving speedup improvements for efficient inference.
[06.02.2026 08:35] Error. Failed to parse JSON from LLM. ["VIDEO", "ARCHITECTURE", "INFERENCE"]


**Justification:**
- **VIDEO**: The paper focuses on autoregressive video generation models and proposes methods for improving video generation efficiency and quality.
- **ARCHITECTURE**: The paper introduces novel neural architecture components, specifically a "Chunk-Aware Growth mechanism" and "Hierarchical Sparse Attention" strategy for sparse attention in neural networks.
- **INFERENCE**: The paper addresses model deployment optimization through sparse attention mechanisms and quantization (FP8 quantization), achieving speedup improvements for efficient inference.
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.  					AI-generated summary 				 Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose Light Forcing, the first sparse attention solution tailored for AR video generation models. It incorporates a Chunk-Aware Growth mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a Hierarchical Sparse Attention to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\eg, 84.5 on VBench) and efficiency (\eg, 1.2{sim}1.3times end-to-end speedup). Combined with FP8 quantization and LightVAE, Light Forcing further achieves a 2.3times speedup and 19.7\,FPS on an RTX~5090 GPU. Code will be released at https://github.com/chengtao-lv/LightForcing{https://github.com/chengtao-lv/LightForcing}."

[06.02.2026 08:35] Response: ```python
["OPTIMIZATION"]
```

The paper focuses on improving the efficiency of autoregressive video generation models through sparse attention mechanisms and optimization techniques (Chunk-Aware Growth, Hierarchical Sparse Attention, FP8 quantization). The primary contribution is advancing training and inference optimization methods to reduce computational complexity while maintaining quality.
[06.02.2026 08:35] Error. Failed to parse JSON from LLM. ["OPTIMIZATION"]


The paper focuses on improving the efficiency of autoregressive video generation models through sparse attention mechanisms and optimization techniques (Chunk-Aware Growth, Hierarchical Sparse Attention, FP8 quantization). The primary contribution is advancing training and inference optimization methods to reduce computational complexity while maintaining quality.
[06.02.2026 08:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Light Forcing presents a new sparse attention mechanism specifically designed for autoregressive video generation, enhancing both efficiency and quality. It addresses the challenges of quadratic complexity in attention by introducing a Chunk-Aware Growth strategy that optimally allocates sparsity based on the contribution of each chunk. Additionally, the Hierarchical Sparse Attention captures relevant historical and local context in a structured manner, allowing for adaptive attention patterns. Experimental results show that Light Forcing significantly improves video generation quality and speed compared to existing methods.","title":"Efficient Video Generation with Sparse Attention"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Light Forcing presents a new sparse attention mechanism specifically designed for autoregressive video generation, enhancing both efficiency and quality. It addresses the challenges of quadratic complexity in attention by introducing a Chunk-Aware Growth strategy that optimally allocates sparsity based on the contribution of each chunk. Additionally, the Hierarchical Sparse Attention captures relevant historical and local context in a structured manner, allowing for adaptive attention patterns. Experimental results show that Light Forcing significantly improves video generation quality and speed compared to existing methods.', title='Efficient Video Generation with Sparse Attention'))
[06.02.2026 08:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Light Forcing 是一种新颖的稀疏注意力机制，专为自回归视频生成模型设计，旨在提高效率并保持生成质量。该方法通过块感知增长机制，量化每个块的贡献，从而优化稀疏分配，并在生成过程中继承先前块的知识。此外，层次稀疏注意力策略能够以粗到细的方式捕捉历史和局部上下文，适应多样的注意力模式。实验结果表明，Light Forcing 在质量和效率上均优于现有的稀疏注意力方法，显著提升了视频生成的速度和效果。","title":"自回归视频生成的新突破：Light Forcing"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Light Forcing 是一种新颖的稀疏注意力机制，专为自回归视频生成模型设计，旨在提高效率并保持生成质量。该方法通过块感知增长机制，量化每个块的贡献，从而优化稀疏分配，并在生成过程中继承先前块的知识。此外，层次稀疏注意力策略能够以粗到细的方式捕捉历史和局部上下文，适应多样的注意力模式。实验结果表明，Light Forcing 在质量和效率上均优于现有的稀疏注意力方法，显著提升了视频生成的速度和效果。', title='自回归视频生成的新突破：Light Forcing'))
[06.02.2026 08:35] Using data from previous issue: {"categories": [], "emoji": "🎬", "ru": {"title": "Коррекция во время инференса: стабилизация генерации длинных видео через опорные кадры", "desc": "В статье предложен метод Test-Time Correction для решения проблемы накопления ошибок в дистиллированных авторегрессивных диффузионных моделях при синтез
[06.02.2026 08:35] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#inference", "#video", "#diffusion"], "emoji": "⚡", "ru": {"title": "Локальное внимание и переиспользование градиентов для быстрого синтеза видео", "desc": "Работа посвящена ускорению синтеза видео с передачей движения на основе текстовых подсказок 
[06.02.2026 08:35] Using data from previous issue: {"categories": ["#alignment", "#benchmark", "#security", "#ethics", "#cv", "#multimodal"], "emoji": "🔒", "ru": {"title": "Контекстная целостность: балансирование между точностью геолокации и приватностью пользователей", "desc": "В работе исследуется проблема приватности в мультимодальных больших мод
[06.02.2026 08:35] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#open_source", "#training", "#audio", "#multimodal"], "emoji": "🎵", "ru": {"title": "Универсальная аудиомодель с интеллектуальной факторизацией токенов", "desc": "Исследователи разработали ReasoningCodec — дискретный аудиокодек, который разделяет аудио
[06.02.2026 08:35] Using data from previous issue: {"categories": ["#audio", "#rag", "#training"], "emoji": "🎵", "ru": {"title": "Адаптивная токенизация речи для эффективного кодирования", "desc": "DyCAST — это динамический токенизатор речи, который использует мягкое выравнивание на уровне символов и моделирование длительности для переменной частоты
[06.02.2026 08:35] Querying the API.
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

PhysicsAgentABM introduces a neuro-symbolic framework that combines mechanistic agents with neural models to improve scalable and calibrated simulation across multiple domains.  					AI-generated summary 				 Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.
[06.02.2026 08:35] Response: ```json
{
  "desc": "PhysicsAgentABM представляет нейро-символический фреймворк, который объединяет механистических агентов с нейронными моделями для улучшения масштабируемости и калибровки агентных симуляций. Фреймворк использует специализированные символические агенты для кодирования механистических приоритетов переходов, мультимодальную нейронную модель для захвата динамики взаимодействий, и неопределённостью-осознанное слияние для получения откалиброванных распределений переходов на уровне кластеров. Метод ANCHOR снижает вычислительные затраты на работу с LLM в 6-8 раз через контрастивное обучение и кластеризацию на основе поведенческих ответов. Экспериментальные результаты на задачах из здравоохранения, финансов и социальных наук демонстрируют улучшение точности предсказания событий и калибровки модели.",
  "emoji": "🤖",
  "title": "Нейро-символическое слияние для масштабируемых и откалиброванных агентных симуляций"
}
```
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PhysicsAgentABM introduces a neuro-symbolic framework that combines mechanistic agents with neural models to improve scalable and calibrated simulation across multiple domains.  					AI-generated summary 				 Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs."

[06.02.2026 08:35] Response: ```python
["AGENTS", "MULTIMODAL", "ARCHITECTURE", "TRAINING"]
```

**Justification:**

- **AGENTS**: The paper explicitly focuses on agent-based models and LLM-based multi-agent systems, introducing PhysicsAgentABM as a framework for autonomous agents with mechanistic and neural components.

- **MULTIMODAL**: The paper mentions "multimodal neural transition model" that captures temporal and interaction dynamics, combining multiple types of signals and data.

- **ARCHITECTURE**: The paper proposes a novel neuro-symbolic architecture that combines mechanistic agents with neural models, introducing new components like state-specialized symbolic agents and uncertainty-aware epistemic fusion.

- **TRAINING**: The paper introduces ANCHOR, a novel training/clustering strategy with a contrastive loss to improve the system's efficiency and performance.
[06.02.2026 08:35] Error. Failed to parse JSON from LLM. ["AGENTS", "MULTIMODAL", "ARCHITECTURE", "TRAINING"]


**Justification:**

- **AGENTS**: The paper explicitly focuses on agent-based models and LLM-based multi-agent systems, introducing PhysicsAgentABM as a framework for autonomous agents with mechanistic and neural components.

- **MULTIMODAL**: The paper mentions "multimodal neural transition model" that captures temporal and interaction dynamics, combining multiple types of signals and data.

- **ARCHITECTURE**: The paper proposes a novel neuro-symbolic architecture that combines mechanistic agents with neural models, introducing new components like state-specialized symbolic agents and uncertainty-aware epistemic fusion.

- **TRAINING**: The paper introduces ANCHOR, a novel training/clustering strategy with a contrastive loss to improve the system"s efficiency and performance.
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PhysicsAgentABM introduces a neuro-symbolic framework that combines mechanistic agents with neural models to improve scalable and calibrated simulation across multiple domains.  					AI-generated summary 				 Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs."

[06.02.2026 08:35] Response: ```python
['REASONING', 'OPTIMIZATION', 'SCIENCE']
```
[06.02.2026 08:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PhysicsAgentABM is a new framework that combines symbolic and neural approaches to enhance agent-based modeling. It uses clusters of agents that specialize in different states, allowing for better simulation of complex behaviors over time. By integrating a multimodal neural model with mechanistic transition rules, it improves the accuracy and calibration of simulations across various fields. The framework also introduces a novel clustering strategy that significantly reduces the computational cost of using large language models in simulations.","title":"Revolutionizing Simulation with Neuro-Symbolic Agent Clusters"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PhysicsAgentABM is a new framework that combines symbolic and neural approaches to enhance agent-based modeling. It uses clusters of agents that specialize in different states, allowing for better simulation of complex behaviors over time. By integrating a multimodal neural model with mechanistic transition rules, it improves the accuracy and calibration of simulations across various fields. The framework also introduces a novel clustering strategy that significantly reduces the computational cost of using large language models in simulations.', title='Revolutionizing Simulation with Neuro-Symbolic Agent Clusters'))
[06.02.2026 08:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PhysicsAgentABM提出了一种神经符号框架，将机械代理与神经模型结合，以提高多领域的可扩展性和校准模拟。该方法通过行为一致的代理集群进行推理，使用状态专用的符号代理编码机械转移先验，同时多模态神经转移模型捕捉时间和交互动态。引入的ANCHOR策略基于跨上下文的行为响应，显著减少了大型语言模型的调用次数。实验结果表明，PhysicsAgentABM在公共卫生、金融和社会科学领域的事件时间准确性和校准性上均优于传统模型。","title":"物理代理ABM：可扩展与校准模拟的新范式"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PhysicsAgentABM提出了一种神经符号框架，将机械代理与神经模型结合，以提高多领域的可扩展性和校准模拟。该方法通过行为一致的代理集群进行推理，使用状态专用的符号代理编码机械转移先验，同时多模态神经转移模型捕捉时间和交互动态。引入的ANCHOR策略基于跨上下文的行为响应，显著减少了大型语言模型的调用次数。实验结果表明，PhysicsAgentABM在公共卫生、金融和社会科学领域的事件时间准确性和校准性上均优于传统模型。', title='物理代理ABM：可扩展与校准模拟的新范式'))
[06.02.2026 08:35] Querying the API.
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

LLM critic models with high offline accuracy can cause variable performance impacts at deployment, necessitating pre-deployment testing to determine intervention safety and effectiveness.  					AI-generated summary 				 Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe.   We identify a disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment.
[06.02.2026 08:35] Response: ```json
{
  "desc": "В статье исследуется проблема использования критик-моделей на основе больших языковых моделей (LLM) для улучшения надежности систем. Авторы показывают, что даже при высокой точности классификации (AUROC 0.94) такие модели могут вызвать серьезное ухудшение производительности при развертывании из-за баланса между исправлением ошибочных траекторий и нарушением успешных. Предлагается новый метод предварительного тестирования на основе небольшого набора из 50 задач, который позволяет прогнозировать влияние вмешательства критик-модели без полного развертывания. Основная ценность подхода состоит в выявлении ситуаций, когда вмешательство вредно, что предотвращает серьезное снижение производительности в продакшене.",
  "emoji": "⚖️",
  "title": "Когда не вмешиваться: предварительное тестирование критик-моделей для безопасного развертывания"
}
```
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LLM critic models with high offline accuracy can cause variable performance impacts at deployment, necessitating pre-deployment testing to determine intervention safety and effectiveness.  					AI-generated summary 				 Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe.   We identify a disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment."

[06.02.2026 08:35] Response: ```python
["BENCHMARK", "INFERENCE"]
```
[06.02.2026 08:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LLM critic models with high offline accuracy can cause variable performance impacts at deployment, necessitating pre-deployment testing to determine intervention safety and effectiveness.  					AI-generated summary 				 Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe.   We identify a disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment."

[06.02.2026 08:35] Response: ```python
['SECURITY', 'ALIGNMENT']
```

**Reasoning:**

- **SECURITY**: The paper addresses model safety and robustness concerns, specifically examining how interventions can cause unexpected performance degradation and proposing testing methods to ensure safe deployment.

- **ALIGNMENT**: The paper discusses aligning LLM behavior with intended outcomes through critic models that intervene to improve reliability, and addresses the challenge of ensuring these interventions actually achieve their intended purpose of improving model performance and safety.
[06.02.2026 08:35] Error. Failed to parse JSON from LLM. ["SECURITY", "ALIGNMENT"]


**Reasoning:**

- **SECURITY**: The paper addresses model safety and robustness concerns, specifically examining how interventions can cause unexpected performance degradation and proposing testing methods to ensure safe deployment.

- **ALIGNMENT**: The paper discusses aligning LLM behavior with intended outcomes through critic models that intervene to improve reliability, and addresses the challenge of ensuring these interventions actually achieve their intended purpose of improving model performance and safety.
[06.02.2026 08:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the challenges of using LLM critic models that show high accuracy in offline tests but may perform unpredictably when deployed. It highlights that a binary LLM critic with an impressive AUROC score can still lead to significant performance drops in certain scenarios. The authors introduce a pre-deployment testing method that helps predict whether an intervention will be beneficial or harmful, based on a small pilot study. This approach aims to prevent severe performance regressions by identifying when it is better not to intervene.","title":"Predicting Intervention Success: Test Before You Deploy!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the challenges of using LLM critic models that show high accuracy in offline tests but may perform unpredictably when deployed. It highlights that a binary LLM critic with an impressive AUROC score can still lead to significant performance drops in certain scenarios. The authors introduce a pre-deployment testing method that helps predict whether an intervention will be beneficial or harmful, based on a small pilot study. This approach aims to prevent severe performance regressions by identifying when it is better not to intervene.', title='Predicting Intervention Success: Test Before You Deploy!'))
[06.02.2026 08:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文探讨了大型语言模型（LLM）批评模型在实际部署中的表现不稳定性。尽管这些模型在离线测试中表现出高准确率，但在实际应用中可能导致性能显著下降。研究表明，干预措施可能会恢复失败的轨迹，但也可能干扰本来会成功的轨迹。因此，作者提出了一种预部署测试方法，可以在不完全部署的情况下，通过小规模试点任务来评估干预的安全性和有效性。","title":"干预安全性：预部署测试的重要性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文探讨了大型语言模型（LLM）批评模型在实际部署中的表现不稳定性。尽管这些模型在离线测试中表现出高准确率，但在实际应用中可能导致性能显著下降。研究表明，干预措施可能会恢复失败的轨迹，但也可能干扰本来会成功的轨迹。因此，作者提出了一种预部署测试方法，可以在不完全部署的情况下，通过小规模试点任务来评估干预的安全性和有效性。', title='干预安全性：预部署测试的重要性'))
[06.02.2026 08:35] Using data from previous issue: {"categories": ["#alignment", "#security", "#open_source"], "emoji": "⚠️", "ru": {"title": "Скрытое смещение дообученных LLM'ов: риски и классификация по доменам", "desc": "В работе исследуется проблема скрытого смещения поведения больших языковых моделей, которые были дообучены на скомпрометированн
[06.02.2026 08:35] Renaming data file.
[06.02.2026 08:35] Renaming previous data. hf_papers.json to ./d/2026-02-06.json
[06.02.2026 08:35] Saving new data file.
[06.02.2026 08:35] Generating page.
[06.02.2026 08:35] Renaming previous page.
[06.02.2026 08:35] Renaming previous data. index.html to ./d/2026-02-06.html
[06.02.2026 08:35] Writing result.
[06.02.2026 08:35] Renaming log file.
[06.02.2026 08:35] Renaming previous data. log.txt to ./logs/2026-02-06_last_log.txt
