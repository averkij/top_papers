[06.02.2026 01:18] Read previous papers.
[06.02.2026 01:18] Generating top page (month).
[06.02.2026 01:18] Writing top page (month).
[06.02.2026 04:09] Read previous papers.
[06.02.2026 04:09] Get feed.
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05986
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05261
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2601.21296
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.06040
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05216
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.03036
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.06028
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05842
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.01965
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05393
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2601.21937
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05551
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05327
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05871
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.05857
[06.02.2026 04:09] Extract page data from URL. URL: https://huggingface.co/papers/2602.04683
[06.02.2026 04:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.02.2026 04:09] Downloading and parsing papers (pdf, html). Total: 16.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.05986.
[06.02.2026 04:09] Downloading paper 2602.05986 from https://arxiv.org/pdf/2602.05986v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 6 8 9 5 0 . 2 0 6 2 : r RISE-Video: Can Video Generators Decode Implicit World Rules? Mingxin Liu1,2,, Shuran Ma3,2,, Shibei Meng4,, Xiangyu Zhao1,, Zicheng Zhang1, Shaofeng Zhang1, Zhihang Zhong1, Peixian Chen2, Haoyu Cao2, Xing Sun2, Haodong Duan5, Xue Yang1, 1Shanghai Jiao Tong University, 2Tencent Youtu Lab, 3Xidian University, 4Beijing Normal University, 5The Chinese University of Hong Kong Equal contribution, Project Lead, Corresponding Author "
[06.02.2026 04:09] Response: ```python
[
    "Shanghai Jiao Tong University",
    "Tencent Youtu Lab",
    "Xidian University",
    "Beijing Normal University",
    "The Chinese University of Hong Kong"
]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2602.05986.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.05261.
[06.02.2026 04:09] Downloading paper 2602.05261 from https://arxiv.org/pdf/2602.05261v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 1 6 2 5 0 . 2 0 6 2 : r Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR Fanfan Liu , Youyang Yin , Peng Shi , Siqi Yang , Zhixiong Zeng , Haibo Qiu Meituan "
[06.02.2026 04:09] Response: ```python
["Meituan"]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2602.05261.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2601.21296.
[06.02.2026 04:09] Downloading paper 2601.21296 from https://arxiv.org/pdf/2601.21296v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Published as conference paper at ICLR Shaobo Wang1,2 Yantai Yang1 Guo Chen1 Zhaorun Chen5 Linfeng Zhang1,2 1EPIC Lab, SJTU 2Shanghai Jiao Tong University 4Duke University {shaobowang1009,zhanglinfeng}@sjtu.edu.cn 5The University of Chicago Peiru Li2 Kaixin Li3 Yufa Zhou4 3National University of Singapore Corresponding authors 6 2 0 J 9 2 ] . [ 1 6 9 2 1 2 . 1 0 6 2 : r a "
[06.02.2026 04:09] Response: ```python
[
    "EPIC Lab, SJTU",
    "Shanghai Jiao Tong University",
    "Duke University",
    "The University of Chicago",
    "National University of Singapore"
]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2601.21296.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.06040.
[06.02.2026 04:09] Downloading paper 2602.06040 from https://arxiv.org/pdf/2602.06040v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 0 4 0 6 0 . 2 0 6 2 : r SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs Jintao Tong1,2 Shilin Yan2 Hongwei Xue2 Xiaojun Tang2 Kunyu Shi2 Guannan Zhang2 Ruixuan Li1 Yixiong Zou1 1Huazhong University of Science and Technology 2Accio Team, Alibaba Group Project Leader Corresponding Author Abstract Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject fixed number of continuous hidden states as visual thoughts into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue that the core limitation lies in rigid, pre-defined reasoning pattern that cannot adaptively choose the most suitable thinking modality for different user queries. We introduce SwimBird, reasoning-switchable MLLM that dynamically switches among three reasoning modes conditioned on the input: (1) text-only reasoning, (2) vision-only reasoning (continuous hidden states as visual thoughts), and (3) interleaved visiontext reasoning. To enable this capability, we adopt hybrid autoregressive formulation that unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts, and design systematic reasoning-mode curation strategy to construct SwimBird-SFT-92K, diverse supervised fine-tuning dataset covering all three reasoning patterns. By enabling flexible, query-adaptive mode selection, SwimBird preserves strong textual logic while substantially improving performance on vision-dense tasks. Experiments across diverse benchmarks covering textual reasoning and challenging visual understanding demonstrate that SwimBird achieves state-of-the-art results and robust gains over prior fixed-pattern multimodal reasoning meth"
[06.02.2026 04:09] Response: ```python
[
    "Huazhong University of Science and Technology",
    "Accio Team, Alibaba Group"
]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2602.06040.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.05216.
[06.02.2026 04:09] Downloading paper 2602.05216 from https://arxiv.org/pdf/2602.05216v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Semantic Search over 9 Million Mathematical Theorems Luke Alexander * 1 2 Eric Leonen * 1 3 Sophie Szeto * 1 2 4 Artemii Remizov 1 5 Ignacio Tejeda 1 2 Giovanni Inchiostro 1 2 Vasily Ilin 1 2 6 2 0 2 5 ] I . [ 1 6 1 2 5 0 . 2 0 6 2 : r a "
[06.02.2026 04:09] Response: ```python
[]
```
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Semantic Search over 9 Million Mathematical Theorems Luke Alexander * 1 2 Eric Leonen * 1 3 Sophie Szeto * 1 2 4 Artemii Remizov 1 5 Ignacio Tejeda 1 2 Giovanni Inchiostro 1 2 Vasily Ilin 1 2 6 2 0 2 5 ] I . [ 1 6 1 2 5 0 . 2 0 6 2 : r aSearching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek specific theorem, lemma, or proposition that answers query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as researchlevel mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over unified corpus of 9.2 million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with short naturallanguage description as retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On curated evaluation set of theoremsearch queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at this link, and the dataset is available at this link. ing for both human mathematicians and automated proof systems (Polu & Sutskever, 2020; Yang et al., 2023; Wu et al., 2022). researcher proving new result must first determine whether the statement already exists in the literature, and similarly, an AI agent generating formal proofs benefits from retrieving relevant lemmas to guide its search. Yet most existing tools Google Scholar, arXiv, and even modern LLMs with web access operate at the level of entire documents, forcing users to manually scan papers when they seek specific statement. This gap is increasingly significant. arXiv hosts over 2.4 million papers, including more than 690,000 in mathematics (Ginsparg, 1994). study of over 14,000 withdrawn arXiv preprints found that 2.5% were retracted because the authors results already appeared in prior literature (Rao et al., 2024). For example, Popescu-Pampu (2007), Zhang (2012), and Shahryari (2020) were withdrawn after discovering their main results had been previously established. AI systems face the same problem: the Erdos Problems Project documented cases where AI tools solved open problems that had been established decades earlier (Erdos & Newman, 1977; Wirsing & Schwarz, 1961; Klarner, 1966) underscoring the need for theorem-level search. In this work, we construct corpus of over 9 million theorem statements from arXiv, the Stacks Project, ProofWiki, and five other sources, and study semantic retrieval at scale. We represent each theorem using natural-language slogan generated by an LLM, then embed slogans and queries into shared semantic space. Our main contributions are: 1. Introduction Mathematical knowledge is organized around discrete results: theorems, lemmas, propositions, and corollaries. These statements serve as the fundamental units of reason- *Equal contribution 1Math AI Lab, University of Washington, Seattle, United States 2Department of Mathematics, University of Washington, Seattle, United States 3Department of Applied and Computational Mathematical Sciences, University of Washington, Seattle, United States 4Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, United States 5Lake Washington High School, Kirkland, United States. Correspondence to: Vasily Ilin <vilin@uw.edu>. Preprint. February 6, 2026. 1. large-scale theorem corpus. We release over 9 million theorem statements with rich metadata, the largest collection of informal mathematical theorems to date. 2. systematic study of representation choices. We analyze how the context, LLM choice, embedding model, and prompting strategy affect retrieval. Notably, we find that embedding theorems via natural-language slogans significantly outperforms embedding their raw LATEX formulations. 3. State-of-the-art retrieval. On 111 queries from professional mathematicians, we achieve 45.0% Hit@20 Theorem Search at the theorem level, outperforming ChatGPT 5.2 with search (19.8%) and Gemini 3 Pro (27.0%). For paperlevel retrieval, we achieve 56.8% Hit@20 compared to 37.8% for Google Search. Our results demonstrate that semantic theorem search is feasible at web scale. public demo is available at huggingface.co/spaces/uw-math-ai/theorem-search. The dataset is available at huggingface.co/datasets/uw-mathai/theorem-search-dataset. datasheet for our dataset is provided in Appendix A. 2. Related Work Mathematical Information Retrieval. Early MathIR work focused on formula-level retrieval, with the NTCIR Math Tasks (Aizawa et al., 2014; Zanibbi et al., 2016) establishing benchmarks for formula search over arXiv and Wikipedia. The ARQMath shared tasks (Mansouri et al., 2022) extended this to mathematical question answering over Math Stack Exchange. recent survey (Dadure et al., 2024) notes that while formula retrieval has progressed, semantic understanding of mathematical statements remains an open challenge the gap our work addresses. Dense Retrieval and LLM-Augmented Search. Dense Passage Retrieval (Karpukhin et al., 2020) showed that dualencoder architectures can outperform sparse methods like BM25. Sentence-BERT (Reimers & Gurevych, 2019) enabled efficient semantic similarity via Siamese networks, while E5 (Wang et al., 2022), Qwen3-Embedding (Zhang et al., 2025), and Gemma Embedding (Vera et al., 2025) have pushed embedding quality further. ColBERT (Khattab & Zaharia, 2020) introduced late interaction for fine-grained token matching. Retrieval-augmented generation (RAG) (Lewis et al., 2020) combines retrieval with language model generation, enabling systems to ground responses in retrieved documents. These advances underpin our approach, though mathematical text poses unique challenges due to symbolic notation. Search for Formal Mathematics. LeanSearch (Gao et al., 2024) provides semantic search over Mathlib4s 230,000+ theorems by generating natural-language descriptions and using dense retrieval. ReProver (Yang et al., 2023) uses retrieval-augmented generation to select premises during proof search, and"
[06.02.2026 04:09] Mistral response. {"id": "5800dac044954577b988a74090edafd2", "created": 1770350972, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1582, "total_tokens": 1675, "completion_tokens": 93, "num_cached_tokens": 1581}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Math AI Lab, University of Washington, Seattle, United States\",\n    \"Department of Mathematics, University of Washington, Seattle, United States\",\n    \"Department of Applied and Computational Mathematical Sciences, University of Washington, Seattle, United States\",\n    \"Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, United States\",\n    \"Lake Washington High School, Kirkland, United States\"\n]\n```"}}]}
[06.02.2026 04:09] Response: ```python
[
    "Math AI Lab, University of Washington, Seattle, United States",
    "Department of Mathematics, University of Washington, Seattle, United States",
    "Department of Applied and Computational Mathematical Sciences, University of Washington, Seattle, United States",
    "Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, United States",
    "Lake Washington High School, Kirkland, United States"
]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2602.05216.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.03036.
[06.02.2026 04:09] Downloading paper 2602.03036 from https://arxiv.org/pdf/2602.03036v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2026-2-1 LatentMem: Customizing Latent Memory for Multi-Agent Systems Muxin Fu1,2,, Guibin Zhang3,, Xiangyuan Xue4, Yafu Li4, Zefeng He5, Siyuan Huang6, Xiaoye Qu2, Yu Cheng4, Yang Yang6 1Tongji University 2Shanghai AI Laboratory 4The Chinese University of Hong Kong 3National University of Singapore 6Shanghai Jiao Tong University 5Nanjing University 6 2 0 F 3 ] . [ 1 6 3 0 3 0 . 2 0 6 2 : r # boonkana10@gmail.com, guibinz@outlook.com Equal Contribution https://github.com/KANABOON1/LatentMem Corresponding Author. Abstract Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, learnable multi-agent memory framework designed to customize agent-specific memories in token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in lightweight form, and memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts. Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves performance gain of up to 19.36% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks. 1. Introduction Large Language Model (LLM)-powered multiagent systems (MAS), have emerged as powerful framewor"
[06.02.2026 04:09] Response: ```python
[
    "Tongji University",
    "Shanghai AI Laboratory",
    "The Chinese University of Hong Kong",
    "National University of Singapore",
    "Nanjing University",
    "Shanghai Jiao Tong University"
]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2602.03036.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.06028.
[06.02.2026 04:09] Downloading paper 2602.06028 from https://arxiv.org/pdf/2602.06028v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 8 2 0 6 0 . 2 0 6 2 : r Context Forcing: Consistent Autoregressive Video Generation with Long Context Shuo Chen * 1 Cong Wei * 2 Sun Sun 2 Ping Nie 2 Kai Zhou 3 Ge Zhang 4 Ming-Hsuan Yang 1 Wenhu Chen 2 (cid:128) Website: https://chenshuo20.github.io/Context Forcing Code: https://github.com/TIGER-AI-Lab/Context-Forcing Figure 1. Context Forcing mitigates the forgettingdrifting dilemma. (1) State-of-the-art models are limited by short context windows (3.09.2 s), which leads to poor long-term consistency (Forgetting). (2) For streaming long-context tuning baselines (e.g., LongLive), enlarging the context window during inference (3.0 5.25 s) causes error accumulation and distribution shift (Drifting). In contrast, Context Forcing supports 20s+ context while maintaining strong long-term consistency. "
[06.02.2026 04:09] Response: ```python
[
    "UC Merced",
    "University of Waterloo",
    "Alibaba"
]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2602.06028.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.05842.
[06.02.2026 04:09] Downloading paper 2602.05842 from https://arxiv.org/pdf/2602.05842v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Reinforcement World Model Learning for LLM-based Agents Xiao Yu 1 Baolin Peng 2 * Ruize Xu 3 Yelong Shen 2 Pengcheng He 2 Suman Nath 2 Nikhil Singh 2 Jiangfeng Gao 2 Zhou Yu "
[06.02.2026 04:09] Response: ```python
[
    "Microsoft Research",
    "Microsoft Research",
    "Microsoft Research",
    "Microsoft Research",
    "Microsoft Research",
    "Microsoft Research",
    "Microsoft Research",
    "Microsoft Research"
]
```
[06.02.2026 04:09] Deleting PDF ./assets/pdf/2602.05842.pdf.
[06.02.2026 04:09] Success.
[06.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.01965.
[06.02.2026 04:09] Downloading paper 2602.01965 from https://arxiv.org/pdf/2602.01965v1...
[06.02.2026 04:09] Extracting affiliations from text.
[06.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 5 6 9 1 0 . 2 0 6 2 : r Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation Kwun Hang Lau 1,2, Fangyuan Zhang 1, Boyu Ruan 1, Yingli Zhou3, Qintian Guo2, Ruiyuan Zhang2, Xiaofang Zhou2 1Huawei Hong Kong Research Center, Hong Kong; 2The Hong Kong University of Science and Technology, Hong Kong; 3The Chinese University of Hong Kong, Shenzhen "
[06.02.2026 04:10] Response: ```python
[
    "Huawei Hong Kong Research Center",
    "The Hong Kong University of Science and Technology",
    "The Chinese University of Hong Kong, Shenzhen"
]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2602.01965.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.05393.
[06.02.2026 04:10] Downloading paper 2602.05393 from https://arxiv.org/pdf/2602.05393v1...
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 3 9 3 5 0 . 2 0 6 2 : r Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better Ji Zhao1,2,, Yufei Gu1, Shitong Shao1, Xun Zhou2, Liang Xiang2, Zeke Xie1, 1The Hong Kong University of Science and Technology (Guangzhou), 2ByteDance Seed Work done at ByteDance Seed, Corresponding authors "
[06.02.2026 04:10] Response: ```python
[
    "The Hong Kong University of Science and Technology (Guangzhou)",
    "ByteDance Seed"
]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2602.05393.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2601.21937.
[06.02.2026 04:10] Downloading paper 2601.21937 from https://arxiv.org/pdf/2601.21937v2...
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 3 ] . [ 2 7 3 9 1 2 . 1 0 6 2 : r Retrieval-Infused Reasoning Sandbox: Benchmark for Decoupling Retrieval and Reasoning Capabilities ByteDance Seed, M-A-P Full author list in Contributions "
[06.02.2026 04:10] Response: ```python
["ByteDance"]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2601.21937.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.05551.
[06.02.2026 04:10] Downloading paper 2602.05551 from https://arxiv.org/pdf/2602.05551v1...
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 1 5 5 5 0 . 2 0 6 2 : r FastVMT : Eliminating Redundancy in Video Motion Transfer Yue Ma2, Zhikai Wang1, Tianhao Ren1, Mingzhe Zheng2, Hongyu Liu2, Jiayi Guo3, Mark Fong, Yuxuan Xue4, Zixiang Zhao5, Konrad Schindler5, Qifeng Chen2, Linfeng Zhang1(cid:66) 1 EPIC Lab, SJTU 2 HKUST 3 THU 4 Meta 5 ETH Zurich Project: https://fastvmt.github.io/ Figure 1. Efficient motion transfer with FastVMT: By eliminating redundant attention computations and reusing previously computed gradients, we achieve faster motion transfer for singleas well as multi-object motion, camera ego-motion, and complex articulations. "
[06.02.2026 04:10] Response: ```python
[
    "EPIC Lab, SJTU",
    "HKUST",
    "THU",
    "Meta",
    "ETH Zurich"
]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2602.05551.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.05327.
[06.02.2026 04:10] Downloading paper 2602.05327 from https://arxiv.org/pdf/2602.05327v1...
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2026-02-06 ProAct: Agentic Lookahead in Interactive Environments Yangbin Yu*, Mingyu Yang*, Junyou Li, Yiming Gao, Feiyu Liu, Yijun Yang, Zichuan Lin Jiafei Lyu, Yicheng Liu, Zhicong Lu, Deheng Ye, Jie Jiang Tencent Hunyuan 6 2 0 2 5 ] A . [ 1 7 2 3 5 0 . 2 0 6 2 : r Figure 1: Overview of ProAct. two-stage paradigm to internalize accurate lookahead reasoning for AI agents. GLAD distills complex MCTS search trees into concise, causal reasoning chains via SFT. MC-Critic leverages lightweight environment rollouts to provide low-variance value estimates, stabilizing online RL training. "
[06.02.2026 04:10] Response: ```python
["Tencent Hunyuan"]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2602.05327.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.05871.
[06.02.2026 04:10] Downloading paper 2602.05871 from https://arxiv.org/pdf/2602.05871v1...
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Pathwise Test-Time Correction for Autoregressive Long Video Generation Xunzhi Xiang * 1 2 Zixuan Duan * 1 Guiyu Zhang 3 Haiyu Zhang 2 Zhe Gao 1 Junta Wu 2 Shaofeng Zhang 4 Tengfei Wang 2 Qi Fan 1 Chunchao Guo 2 6 2 0 2 5 ] . [ 1 1 7 8 5 0 . 2 0 6 2 : r Figure 1. 30-second video generation examples. Our method reduces error accumulation in CausVid and Self-Forcing, enabling longer and more stable videos with improved visual consistency. All samples are generated with the same random seed for fair comparison. "
[06.02.2026 04:10] Response: ```python
[]
```
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Pathwise Test-Time Correction for Autoregressive Long Video Generation Xunzhi Xiang * 1 2 Zixuan Duan * 1 Guiyu Zhang 3 Haiyu Zhang 2 Zhe Gao 1 Junta Wu 2 Shaofeng Zhang 4 Tengfei Wang 2 Qi Fan 1 Chunchao Guo 2 6 2 0 2 5 ] . [ 1 1 7 8 5 0 . 2 0 6 2 : r Figure 1. 30-second video generation examples. Our method reduces error accumulation in CausVid and Self-Forcing, enabling longer and more stable videos with improved visual consistency. All samples are generated with the same random seed for fair comparison.Distilled autoregressive diffusion models facilitate real-time short video synthesis but suffer from severe error accumulation during long-sequence generation. While existing Test-Time Optimization (TTO) methods prove effective for images or short clips, we identify that they fail to mitigate drift in extended sequences due to unstable reward *Equal contribution 1Nanjing University 2Tencent Hunyuan 3Chinese University of Hong Kong, Shenzhen 4University of Science and Technology of China. Correspondence to: Tengfei Wang <tengfeiwang12@gmail.com>, Qi Fan <fanqi@nju.edu.cn>. Preprint. February 6, 2026. 1 landscapes and the hypersensitivity of distilled parameters. To overcome these limitations, we introduce Test-Time Correction (TTC), training-free alternative. Specifically, TTC utilizes the initial frame as stable reference anchor to calibrate intermediate stochastic states along the sampling trajectory. Extensive experiments demonstrate that our method seamlessly integrates with various distilled models, extending generation lengths with negligible overhead while matching the quality of resource-intensive training-based methods on 30-second benchmarks. Pathwise Test-Time Correction for Autoregressive Long Video Generation 1. Introduction Video generation (Lu et al., 2025; Yesiltepe et al., 2025; Hong et al., 2023; Jia et al., 2025b) has advanced rapidly with the development of diffusion-based generative models (Kong et al., 2024; Wan et al., 2025; Hong et al., 2023; Ma et al., 2025a; Peebles & Xie, 2023; Rombach et al., 2022), which now enable the high-quality synthesis of complex motion (Zhu et al., 2024; Hu, 2024) and visual appearance (Guo et al., 2024; Zhang et al., 2025a). However, scaling these diffusion priors to extended video sequences remains formidable challenge. Beyond the escalating computational costs associated with longer contexts, maintaining temporal coherence over extended horizons is difficult without incurring excessive latency, thereby limiting their deployment in real-time applications. To overcome these limitations, recent studies (Yin et al., 2025b; Huang et al., 2025d) have shifted from bidirectional modeling to step-distilled autoregressive generation, enabling true real-time video synthesis. However, these methods remain constrained by cascading error accumulation: since each frame is conditioned on prior outputs, initial inaccuracies compound over time, resulting in temporal drift and long-horizon degradation. While recent extensions (Yi et al., 2025; Cui et al., 2026) like Rolling Forcing (Liu et al., 2025b), LongLive (Yang et al., 2025), Self-Forcing++ (Cui et al., 2025) , and WorldPlay (Sun et al., 2025) have achieved minute-level consistency through sink mechanisms and windowed DMD retraining, they necessitate substantial computational overhead for model fine-tuning. Consequently, pivotal question arises: Can we improve the stability of autoregressive video generation purely at inference time, bypassing the need for retraining the base model? Test-Time Optimization (TTO) (Wang et al., 2025; Sun et al., 2020) has emerged as compelling alternative for enhancing video quality without the need for retraining. However, while effective for short-video synthesis (Yu et al., 2025b; Eyring et al., 2025), our toy experiments reveal that scaling TTO to long-horizon autoregressive generation faces dual bottleneck consisting of the inherent difficulty in defining reward functions for long-range consistency and the extreme optimization sensitivity of distilled models. We observe that in these distilled models, even infinitesimal test-time gradients often trigger reward collapse and fail to mitigate cumulative error. Therefore, we propose Test-Time Correction (TTC), which is training-free framework that shifts the paradigm from parameter-space optimization to sampling-space stochastic intervention. TTC is grounded in the insight that few-step distilled samplers are inherently stochastic as they perturb intermediate states with injected noise. This property implies that intermediate predictions are not fixed outcomes but rather malleable latent states that can be rectified by subsequent diffusion steps to align with Figure 2. Comparison of sampling strategies. The Original Path suffers from error accumulation, while the Sink-based Path collapses into Sink Point (dynamic collapse). In contrast, our TTC strategy avoids these failures by employing reference-conditioned denoising and explicit Re-noising, effectively steering the trajectory away from the sink to preserve target distribution. the global initial context while preserving the underlying sampling distribution. Specifically, as shown in Figure 2, TTC applies small number of correction steps along the stochastic sampling path, only after the global structure has stabilized. This delay prevents the generation from falling into sink-collapse (Cui et al., 2026), phenomenon where newly generated frames repeatedly regress toward the sink frames instead of evolving naturally. At these chosen steps in the sampling path, TTC performs reference-conditioned denoising by utilizing the initial frame context to anchor corrected clean prediction. Then, this corrected state is re-noised back to the variance level corresponding to the current timestep, which ensures that the intervention remains compatible with the expected noise distribution. By integrating correction into the stochastic sampling path of the autoregressive diffusion process rather than directly replacing the denoised prediction, this mechanism suppresses long-term error accumulation and temporal drift without retraining, while preserving highfidelity temporal coherence over extended durations. In this work, we show that long-horizon stability in autoregressive video generation can be achieved through test-time intervention alone. Our method suppresses error accumulation with negligible computational overhead, without requiring any retraining. As result,"
[06.02.2026 04:10] Mistral response. {"id": "35ff356d2cdb40e59d609f72da072845", "created": 1770351032, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1464, "total_tokens": 1506, "completion_tokens": 42, "num_cached_tokens": 1463}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Nanjing University\",\n    \"Tencent Hunyuan\",\n    \"Chinese University of Hong Kong, Shenzhen\",\n    \"University of Science and Technology of China\"\n]\n```"}}]}
[06.02.2026 04:10] Response: ```python
[
    "Nanjing University",
    "Tencent Hunyuan",
    "Chinese University of Hong Kong, Shenzhen",
    "University of Science and Technology of China"
]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2602.05871.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.05857.
[06.02.2026 04:10] Downloading paper 2602.05857 from https://arxiv.org/pdf/2602.05857v1...
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 ] . [ 1 7 5 8 5 0 . 2 0 6 2 : r BABE: Biology Arena BEnchmark Junting Zhou1,2,, Jin Chen1,, Linfeng Hao2,, Denghui Cao1, Zheyu Wang1, Qiguang Chen1, Chaoyou Fu1, Jiaze Chen1, Yuchen Wu1, Ge Zhang1, Mingxuan Wang1,, Wenhao Huang1,, Tong Yang2, 1ByteDance Seed, 2Peking University Work done at ByteDance Seed, Corresponding authors "
[06.02.2026 04:10] Response: ```python
[
    "ByteDance Seed",
    "Peking University"
]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2602.05857.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.04683.
[06.02.2026 04:10] Downloading paper 2602.04683 from https://arxiv.org/pdf/2602.04683v2...
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"UniAudio 2.0: Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization Dongchao Yang 1 Yuanyuan Wang 1 Dading Chong 2 Songxiang Liu 2 Xixin Wu 1 Helen Meng "
[06.02.2026 04:10] Response: ```python
[]
```
[06.02.2026 04:10] Extracting affiliations from text.
[06.02.2026 04:10] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"UniAudio 2.0: Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization Dongchao Yang 1 Yuanyuan Wang 1 Dading Chong 2 Songxiang Liu 2 Xixin Wu 1 Helen MengWe study two foundational problems in audio language models: (1) how to design an audio tokenizer that can serve as an intermediate representation for both understanding and generation; and (2) how to build an audio foundation model that generalizes in few-shot and zero-shot settings, analogous to large language models. To this end, we make the following two contributions. First, we propose ReasoningCodec, discrete audio codec that factorizes audio into (i) reasoning tokens, which encode text-aligned, high-level analysis and planning representations for audio understanding and hierarchical generation, and (ii) reconstruction tokens, which encode semanticrich acoustic cues for high-fidelity waveform reconstruction. This design achieves understanding performance comparable to strong continuous representations while improving generation quality and reconstruction fidelity over prior discrete tokenizers. Second, we introduce unified autoregressive architecture for text and audio, together with multi-stage training and multi-task data construction. Using this framework, we train UniAudio 2.0 on 100B text tokens and 60B audio tokens. Across wide range of speech, sound, and music tasks, UniAudio 2.0 performs competitively on indomain evaluations and demonstrates strong fewshot and zero-shot generalization to unseen tasks. Demo, code, and checkpoints will be available at https://dongchaoyang.top/UniAudio2Demo/. 6 2 0 2 5 ] . [ 2 3 8 6 4 0 . 2 0 6 2 : r 1. Introduction Large language models (LLMs) (OpenAI, 2023; Dubey et al., 2024) have demonstrated remarkable success by unifying diverse language tasks under single autoregressive framework. Inspired by this paradigm, recent research has 1The Chinese University of Hong Kong, China 2Independent Helen Meng <hmCorrespondence to: Researcher. meng@se.cuhk.edu.hk>. Preprint. February 6, 2026. 1 applied similar modeling principles to the audio domain, such as LM-based audio generation tasks (Borsos et al., 2023; Wang et al., 2023; Kharitonov et al., 2023), LMbased audio understanding tasks (Chu et al., 2024; Tang et al., 2024), cross-modal interaction (Defossez et al., 2024; Ding et al., 2025). Despite rapid progress, however, current audio language models still fall short of the generalization, scalability, and task versatility exhibited by their text counterparts. We argue that this limitation primarily stems from three fundamental challenges: the design of audio representations, the architecture of unified autoregressive models and the construction of large-scale multi-task training data. On the representation side, existing approaches largely fall into two categories. Continuous representations, such as self-supervised representations (SSL features) (Hsu et al., 2021; Radford et al., 2023), are effective for perception and understanding tasks but are difficult to integrate into autoregressive audio generation due to the difficulty of modeling high-dimensional features. In contrast, discrete audio codecs (Zeghidour et al., 2021; Defossez et al., 2022; Kumar et al., 2023; Yang et al., 2023b; 2024a) enable efficient generation and scalable modeling, yet their tokens mainly encode low-level acoustic details and lack text-aligned, highlevel abstractions for understanding. In this study, we focus on discrete tokenizers due to their scalability and compatibility with unified text-audio modeling objectives. To address their limited abstraction capability, we introduce ReasoningCodec, novel audio codec that explicitly factorizes audio representations into reasoning tokens and reconstruction tokens. Reasoning tokens encode text-aligned, high-level analysis and planning representations that support audio understanding and hierarchical generation, while reconstruction tokens preserve semantic content and fine-grained acoustics for high-fidelity waveform reconstruction. On the architectural side, most existing audio language models adopt naive unified autoregressive transformer (Zeng et al., 2024; Defossez et al., 2024; Ding et al., 2025) inherited from text LLMs, in which all layers indiscriminately process both text and audio tokens. Although such design is simple and convenient, we argue that it is suboptimal for audio foundation models even with improved tokenization, because: (1) discrete audio tokens remain lossy, and propagating them uniformly across all layers can limit perceptual Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization Figure 1. The overview of the proposed UniAudio 2.0. abstraction and reasoning for audio understanding; and (2) directly aligning text and audio tokens throughout all transformer layers is highly challenging and can lead to rapid forgetting of pre-trained textual knowledge. To address these challenges, we propose unified autoregressive architecture with functional layer specialization. Rather than treating all transformer layers uniformly, we conceptually partition the model into three stages: the lower layers act as audio understanding experts that focus on perceptual abstraction and reasoning over audio; the intermediate layers serve as cross-modal experts to align and integrate text and audio, initialized from pre-trained LLM (e.g., LLaMA3.2 3B) to preserve rich textual knowledge; and the upper layers act as audio generation experts that specialize in modeling fine-grained acoustics. This design maintains specialized inductive biases for understanding and generation while operating within unified autoregressive framework. On the data side, we curate large-scale open-sourced audio corpora spanning speech, sound, and music, and unify them into diverse set of audio-centric tasks covering both understanding and generation. Furthermore, inspired by sequential training in LVMs (Bai et al., 2023), we introduce the concept of auditory sentences: long-context sequences composed of multiple segments that are linked by semantic or acoustic relations, where each segment can be an audio span, text span (e.g., caption), or their paired form. Auditory sentences essentially serve as unified task constructor. By organizing multiple related segments into single longcontext sequence, an auditory sentence naturally induces variety of task forms, including within-segment modeling (e.g., ASR/captioning), cross-segment dependency tracking (e"
[06.02.2026 04:10] Mistral response. {"id": "5c9737fcd0b44d90a09ff538f204c2b1", "created": 1770351045, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1435, "total_tokens": 1453, "completion_tokens": 18, "num_cached_tokens": 1434}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"The Chinese University of Hong Kong, China\", \"Independent\"]\n```"}}]}
[06.02.2026 04:10] Response: ```python
["The Chinese University of Hong Kong, China", "Independent"]
```
[06.02.2026 04:10] Deleting PDF ./assets/pdf/2602.04683.pdf.
[06.02.2026 04:10] Success.
[06.02.2026 04:10] Enriching papers with extra data.
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 0. RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.  					AI-generated summary 				 While generative video models have achieved ...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 1. Research analyzes RLVR algorithms' impact on response length in LLMs and VLMs, proposing LUSPO to eliminate length bias and improve reasoning performance.  					AI-generated summary 				 Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and ...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 2. Dataset distillation method that balances informativeness and utility through game-theoretic and gradient-based optimization techniques, achieving improved performance on ImageNet-1K.  					AI-generated summary 				 Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 3. SwimBird is a reasoning-switchable multimodal large language model that dynamically selects between text-only, vision-only, and interleaved vision-text reasoning modes based on input queries, achieving superior performance on both textual and visual tasks.  					AI-generated summary 				 Multimodal ...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 4. Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.  					AI-generated summary 				 Searching for mathematical r...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 5. LatentMem is a learnable multi-agent memory framework that customizes agent-specific memories through latent representations, improving performance in multi-agent systems without modifying underlying frameworks.  					AI-generated summary 				 Large language model (LLM)-powered multi-agent systems (...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 6. Context Forcing addresses student-teacher mismatch in long video generation by using a long-context teacher to guide long-rollout students through a Slow-Fast Memory architecture that extends context length beyond 20 seconds.  					AI-generated summary 				 Recent approaches to real-time long video ...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 7. Reinforcement World Model Learning enables LLM-based agents to better anticipate action consequences and adapt to environment dynamics through self-supervised training that aligns simulated and real-world state transitions in embedding space.  					AI-generated summary 				 Large language models (LL...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 8. CatRAG addresses limitations in retrieval-augmented generation by introducing a query-adaptive framework that improves multi-hop reasoning through symbolic anchoring, dynamic edge weighting, and key-fact passage enhancement.  					AI-generated summary 				 Recent advances in Retrieval-Augmented Gene...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 9. Large language models can be trained more efficiently by transferring knowledge from later training phases to earlier layers during initial training, achieving faster convergence and improved performance.  					AI-generated summary 				 As Large Language Models (LLMs) achieve remarkable empirical su...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 10. DeR2 presents a controlled evaluation framework for assessing language models' document-grounded reasoning capabilities by isolating reasoning from retrieval and toolchain decisions.  					AI-generated summary 				 Despite strong performance on existing benchmarks, it remains unclear whether large l...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 11. FastVMT accelerates video motion transfer by addressing computational redundancies in Diffusion Transformer architecture through localized attention masking and gradient reuse optimization.  					AI-generated summary 				 Video motion transfer aims to synthesize videos by generating visual content a...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 12. ProAct enhances LLM agents' long-horizon planning by combining supervised fine-tuning with search-derived trajectories and a Monte-Carlo critic for improved policy optimization.  					AI-generated summary 				 Existing Large Language Model (LLM) agents struggle in interactive environments requiring ...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 13. Test-Time Correction addresses error accumulation in distilled autoregressive diffusion models for long-video synthesis by using initial frames as reference anchors to calibrate stochastic states during sampling.  					AI-generated summary 				 Distilled autoregressive diffusion models facilitate re...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 14. BABE is a biology-focused benchmark designed to evaluate AI systems' ability to perform experimental reasoning and causal inference similar to practicing scientists.  					AI-generated summary 				 The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogu...
[06.02.2026 04:10] ********************************************************************************
[06.02.2026 04:10] Abstract 15. Researchers developed a discrete audio codec called ReasoningCodec that separates audio into reasoning and reconstruction tokens for improved understanding and generation, and created UniAudio 2.0, a unified autoregressive model trained on large-scale text and audio data that shows strong performanc...
[06.02.2026 04:10] Read previous papers.
[06.02.2026 04:10] Generating reviews via LLM API.
[06.02.2026 04:10] Querying the API.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.  					AI-generated summary 				 While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: Reasoning Alignment, Temporal Consistency, Physical Rationality, and Visual Quality. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.
[06.02.2026 04:10] Response: ```json
{
  "desc": "   RISE-Video            ,    ,     .   467      ,                   .     ,   ,  ,     .           ,   .",
  "emoji": "",
  "title": "     :    "
}
```
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.  					AI-generated summary 				 While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: Reasoning Alignment, Temporal Consistency, Physical Rationality, and Visual Quality. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models."

[06.02.2026 04:10] Response: ```python
['BENCHMARK', 'VIDEO', 'MULTIMODAL', 'DATASET']
```
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.  					AI-generated summary 				 While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: Reasoning Alignment, Temporal Consistency, Physical Rationality, and Visual Quality. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models."

[06.02.2026 04:10] Response: ```python
["REASONING", "INTERPRETABILITY"]
```
[06.02.2026 04:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RISE-Video is a new benchmark designed to evaluate text-image-to-video synthesis models by focusing on cognitive reasoning instead of just visual quality. It introduces a multi-dimensional metric system that assesses models on their ability to understand and apply implicit world rules. The benchmark includes 467 human-annotated samples across eight categories, allowing for a comprehensive evaluation of model intelligence in areas like commonsense reasoning and spatial dynamics. Additionally, it features an automated evaluation pipeline using Large Multimodal Models (LMMs) to enhance scalability and efficiency in assessing model performance.","title":"Evaluating Video Synthesis through Cognitive Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RISE-Video is a new benchmark designed to evaluate text-image-to-video synthesis models by focusing on cognitive reasoning instead of just visual quality. It introduces a multi-dimensional metric system that assesses models on their ability to understand and apply implicit world rules. The benchmark includes 467 human-annotated samples across eight categories, allowing for a comprehensive evaluation of model intelligence in areas like commonsense reasoning and spatial dynamics. Additionally, it features an automated evaluation pipeline using Large Multimodal Models (LMMs) to enhance scalability and efficiency in assessing model performance.', title='Evaluating Video Synthesis through Cognitive Reasoning'))
[06.02.2026 04:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RISE-Video--LMMRISE-Video467RISE-Video","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RISE-Video--LMMRISE-Video467RISE-Video', title=''))
[06.02.2026 04:10] Querying the API.
[06.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Research analyzes RLVR algorithms' impact on response length in LLMs and VLMs, proposing LUSPO to eliminate length bias and improve reasoning performance.  					AI-generated summary 				 Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.
[06.02.2026 04:11] Response: ```json
{
  "desc": " ,         (RLVR)          .     ,     ,  ,   RLVR         .   LUSPO  ,        GSPO,     .   ,  LUSPO               .",
  "emoji": "",
  "title": "         "
}
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research analyzes RLVR algorithms' impact on response length in LLMs and VLMs, proposing LUSPO to eliminate length bias and improve reasoning performance.  					AI-generated summary 				 Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO."

[06.02.2026 04:11] Response: ```python
["RLHF", "TRAINING", "MULTIMODAL", "BENCHMARK"]
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research analyzes RLVR algorithms' impact on response length in LLMs and VLMs, proposing LUSPO to eliminate length bias and improve reasoning performance.  					AI-generated summary 				 Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO."

[06.02.2026 04:11] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how Reinforcement Learning with Verifiable Rewards (RLVR) affects the length of responses generated by Large Language Models (LLMs) and Vision-Language Models (VLMs). It identifies that different RLVR algorithms lead to varying patterns in response length during training, which can impact reasoning performance. To address the length bias observed in existing algorithms, the authors propose a new algorithm called Length-Unbiased Sequence Policy Optimization (LUSPO). Through extensive experiments, LUSPO is shown to outperform traditional methods, providing a more effective approach to optimizing reasoning capabilities without being influenced by response length.","title":"Eliminating Length Bias for Enhanced Reasoning in AI Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates how Reinforcement Learning with Verifiable Rewards (RLVR) affects the length of responses generated by Large Language Models (LLMs) and Vision-Language Models (VLMs). It identifies that different RLVR algorithms lead to varying patterns in response length during training, which can impact reasoning performance. To address the length bias observed in existing algorithms, the authors propose a new algorithm called Length-Unbiased Sequence Policy Optimization (LUSPO). Through extensive experiments, LUSPO is shown to outperform traditional methods, providing a more effective approach to optimizing reasoning capabilities without being influenced by response length.', title='Eliminating Length Bias for Enhanced Reasoning in AI Models'))
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RLVRLLMsVLMsLUSPORLVRRLVRRLVRLUSPO","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RLVRLLMsVLMsLUSPORLVRRLVRRLVRLUSPO', title=''))
[06.02.2026 04:11] Querying the API.
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Dataset distillation method that balances informativeness and utility through game-theoretic and gradient-based optimization techniques, achieving improved performance on ImageNet-1K.  					AI-generated summary 				 Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1\% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.
[06.02.2026 04:11] Response: ```json
{
  "desc": "  InfoUtil    ,        ,   .     :  (    )   (   ).   -               .   ImageNet-1K  ResNet-18      6.1%      .",
  "emoji": "",
  "title": "         "
}
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Dataset distillation method that balances informativeness and utility through game-theoretic and gradient-based optimization techniques, achieving improved performance on ImageNet-1K.  					AI-generated summary 				 Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1\% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18."

[06.02.2026 04:11] Response: ```python
["DATASET", "DATA", "BENCHMARK"]
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Dataset distillation method that balances informativeness and utility through game-theoretic and gradient-based optimization techniques, achieving improved performance on ImageNet-1K.  					AI-generated summary 				 Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1\% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18."

[06.02.2026 04:11] Response: ```python
['SYNTHETIC', 'OPTIMIZATION']
```
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a novel approach to Dataset Distillation (DD), which aims to create a smaller, more efficient dataset from a larger one while maintaining its quality. The authors introduce the concepts of Informativeness and Utility, which help in identifying important information and essential samples for training. They propose a new framework called InfoUtil that uses game-theoretic methods and gradient-based optimization to balance these two aspects effectively. Experimental results show that this method significantly enhances performance on the ImageNet-1K dataset, outperforming previous techniques by 6.1%.","title":"Balancing Informativeness and Utility in Dataset Distillation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a novel approach to Dataset Distillation (DD), which aims to create a smaller, more efficient dataset from a larger one while maintaining its quality. The authors introduce the concepts of Informativeness and Utility, which help in identifying important information and essential samples for training. They propose a new framework called InfoUtil that uses game-theoretic methods and gradient-based optimization to balance these two aspects effectively. Experimental results show that this method significantly enhances performance on the ImageNet-1K dataset, outperforming previous techniques by 6.1%.', title='Balancing Informativeness and Utility in Dataset Distillation'))
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"InfoUtilImageNet-1K6.1%","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='InfoUtilImageNet-1K6.1%', title=''))
[06.02.2026 04:11] Querying the API.
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SwimBird is a reasoning-switchable multimodal large language model that dynamically selects between text-only, vision-only, and interleaved vision-text reasoning modes based on input queries, achieving superior performance on both textual and visual tasks.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject a fixed number of continuous hidden states as "visual thoughts" into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue that the core limitation lies in a rigid, pre-defined reasoning pattern that cannot adaptively choose the most suitable thinking modality for different user queries. We introduce SwimBird, a reasoning-switchable MLLM that dynamically switches among three reasoning modes conditioned on the input: (1) text-only reasoning, (2) vision-only reasoning (continuous hidden states as visual thoughts), and (3) interleaved vision-text reasoning. To enable this capability, we adopt a hybrid autoregressive formulation that unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts, and design a systematic reasoning-mode curation strategy to construct SwimBird-SFT-92K, a diverse supervised fine-tuning dataset covering all three reasoning patterns. By enabling flexible, query-adaptive mode selection, SwimBird preserves strong textual logic while substantially improving performance on vision-dense tasks. Experiments across diverse benchmarks covering textual reasoning and challenging visual understanding demonstrate that SwimBird achieves state-of-the-art results and robust gains over prior fixed-pattern multimodal reasoning methods.
[06.02.2026 04:11] Response: ```json
{
  "desc": "SwimBird      ,           .     :     ,     (      )     .    ,              ,      . SwimBird        ,       .",
  "emoji": "",
  "title": "    "
}
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SwimBird is a reasoning-switchable multimodal large language model that dynamically selects between text-only, vision-only, and interleaved vision-text reasoning modes based on input queries, achieving superior performance on both textual and visual tasks.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject a fixed number of continuous hidden states as "visual thoughts" into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue that the core limitation lies in a rigid, pre-defined reasoning pattern that cannot adaptively choose the most suitable thinking modality for different user queries. We introduce SwimBird, a reasoning-switchable MLLM that dynamically switches among three reasoning modes conditioned on the input: (1) text-only reasoning, (2) vision-only reasoning (continuous hidden states as visual thoughts), and (3) interleaved vision-text reasoning. To enable this capability, we adopt a hybrid autoregressive formulation that unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts, and design a systematic reasoning-mode curation strategy to construct SwimBird-SFT-92K, a diverse supervised fine-tuning dataset covering all three reasoning patterns. By enabling flexible, query-adaptive mode selection, SwimBird preserves strong textual logic while substantially improving performance on vision-dense tasks. Experiments across diverse benchmarks covering textual reasoning and challenging visual understanding demonstrate that SwimBird achieves state-of-the-art results and robust gains over prior fixed-pattern multimodal reasoning methods."

[06.02.2026 04:11] Response: ```python
["MULTIMODAL", "TRAINING", "DATASET", "ARCHITECTURE"]
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SwimBird is a reasoning-switchable multimodal large language model that dynamically selects between text-only, vision-only, and interleaved vision-text reasoning modes based on input queries, achieving superior performance on both textual and visual tasks.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject a fixed number of continuous hidden states as "visual thoughts" into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue that the core limitation lies in a rigid, pre-defined reasoning pattern that cannot adaptively choose the most suitable thinking modality for different user queries. We introduce SwimBird, a reasoning-switchable MLLM that dynamically switches among three reasoning modes conditioned on the input: (1) text-only reasoning, (2) vision-only reasoning (continuous hidden states as visual thoughts), and (3) interleaved vision-text reasoning. To enable this capability, we adopt a hybrid autoregressive formulation that unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts, and design a systematic reasoning-mode curation strategy to construct SwimBird-SFT-92K, a diverse supervised fine-tuning dataset covering all three reasoning patterns. By enabling flexible, query-adaptive mode selection, SwimBird preserves strong textual logic while substantially improving performance on vision-dense tasks. Experiments across diverse benchmarks covering textual reasoning and challenging visual understanding demonstrate that SwimBird achieves state-of-the-art results and robust gains over prior fixed-pattern multimodal reasoning methods."

[06.02.2026 04:11] Response: ```python
["REASONING", "INTERPRETABILITY"]
```
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SwimBird is a novel multimodal large language model that enhances reasoning by dynamically switching between three modes: text-only, vision-only, and interleaved vision-text. This flexibility allows the model to adapt its reasoning approach based on the specific requirements of the input query, addressing the limitations of traditional models that rely on a fixed reasoning pattern. By integrating a hybrid autoregressive formulation, SwimBird effectively combines textual and visual reasoning, leading to improved performance on both text and vision tasks. The model\'s design includes a diverse supervised fine-tuning dataset, SwimBird-SFT-92K, which supports its ability to maintain strong logical reasoning while excelling in vision-intensive scenarios.","title":"SwimBird: Adaptive Reasoning for Text and Vision"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="SwimBird is a novel multimodal large language model that enhances reasoning by dynamically switching between three modes: text-only, vision-only, and interleaved vision-text. This flexibility allows the model to adapt its reasoning approach based on the specific requirements of the input query, addressing the limitations of traditional models that rely on a fixed reasoning pattern. By integrating a hybrid autoregressive formulation, SwimBird effectively combines textual and visual reasoning, leading to improved performance on both text and vision tasks. The model's design includes a diverse supervised fine-tuning dataset, SwimBird-SFT-92K, which supports its ability to maintain strong logical reasoning while excelling in vision-intensive scenarios.", title='SwimBird: Adaptive Reasoning for Text and Vision'))
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SwimBird-SwimBirdSwimBird","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SwimBird-SwimBirdSwimBird', title=''))
[06.02.2026 04:11] Querying the API.
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.  					AI-generated summary 				 Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of 9.2 million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at https://huggingface.co/spaces/uw-math-ai/theorem-search{this link}, and the dataset is available at https://huggingface.co/datasets/uw-math-ai/TheoremSearch{this link}.
[06.02.2026 04:11] Response: ```json
{
  "desc": "            9.2  ,   arXiv   .      ,   ,  embeddings  prompting   .            ,            .             .",
  "emoji": "",
  "title": "      -"
}
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.  					AI-generated summary 				 Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of 9.2 million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at https://huggingface.co/spaces/uw-math-ai/theorem-search{this link}, and the dataset is available at https://huggingface.co/datasets/uw-math-ai/TheoremSearch{this link}."

[06.02.2026 04:11] Response: ```python
["DATASET", "MATH", "RAG", "BENCHMARK"]
```

**Justification:**

- **DATASET**: The paper introduces a new large-scale corpus of 9.2 million theorem statements extracted from arXiv and other sources, representing the largest publicly available corpus of research-level theorems. The dataset is made publicly available.

- **MATH**: The paper is fundamentally focused on mathematical theorem retrieval and searching for mathematical results (theorems, lemmas, propositions).

- **RAG**: The paper addresses semantic search and retrieval of mathematical content, which is a core retrieval-augmented generation technique for finding relevant mathematical information.

- **BENCHMARK**: The paper includes systematic evaluation on a curated evaluation set of theorem-search queries written by professional mathematicians, comparing against existing baselines and demonstrating improved performance metrics.
[06.02.2026 04:11] Error. Failed to parse JSON from LLM. ["DATASET", "MATH", "RAG", "BENCHMARK"]


**Justification:**

- **DATASET**: The paper introduces a new large-scale corpus of 9.2 million theorem statements extracted from arXiv and other sources, representing the largest publicly available corpus of research-level theorems. The dataset is made publicly available.

- **MATH**: The paper is fundamentally focused on mathematical theorem retrieval and searching for mathematical results (theorems, lemmas, propositions).

- **RAG**: The paper addresses semantic search and retrieval of mathematical content, which is a core retrieval-augmented generation technique for finding relevant mathematical information.

- **BENCHMARK**: The paper includes systematic evaluation on a curated evaluation set of theorem-search queries written by professional mathematicians, comparing against existing baselines and demonstrating improved performance metrics.
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.  					AI-generated summary 				 Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of 9.2 million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at https://huggingface.co/spaces/uw-math-ai/theorem-search{this link}, and the dataset is available at https://huggingface.co/datasets/uw-math-ai/TheoremSearch{this link}."

[06.02.2026 04:11] Response: ```python
['SCIENCE', 'OPEN_SOURCE']
```

**Justification:**

- **SCIENCE**: The paper focuses on semantic theorem retrieval for mathematical research, which is a direct application of language models to scientific/mathematical research. It deals with searching and retrieving mathematical theorems from research papers, which falls under scientific applications of LMs.

- **OPEN_SOURCE**: The paper explicitly mentions releasing both the theorem search tool and dataset publicly on Hugging Face, contributing to open-source projects by releasing models, datasets, and frameworks to the public.
[06.02.2026 04:11] Error. Failed to parse JSON from LLM. ["SCIENCE", "OPEN_SOURCE"]


**Justification:**

- **SCIENCE**: The paper focuses on semantic theorem retrieval for mathematical research, which is a direct application of language models to scientific/mathematical research. It deals with searching and retrieving mathematical theorems from research papers, which falls under scientific applications of LMs.

- **OPEN_SOURCE**: The paper explicitly mentions releasing both the theorem search tool and dataset publicly on Hugging Face, contributing to open-source projects by releasing models, datasets, and frameworks to the public.
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a large-scale semantic theorem retrieval system that outperforms existing methods by utilizing a corpus of 9.2 million theorems. The authors analyze various factors such as representation context, language model selection, and embedding strategies to enhance retrieval accuracy. They demonstrate that their approach significantly improves the retrieval of specific theorems, lemmas, and propositions, which are often sought by mathematicians. The results indicate that effective semantic search for mathematical theorems is achievable at a large scale, making it a valuable tool for researchers.","title":"Revolutionizing Theorem Retrieval: A Semantic Approach at Scale"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a large-scale semantic theorem retrieval system that outperforms existing methods by utilizing a corpus of 9.2 million theorems. The authors analyze various factors such as representation context, language model selection, and embedding strategies to enhance retrieval accuracy. They demonstrate that their approach significantly improves the retrieval of specific theorems, lemmas, and propositions, which are often sought by mathematicians. The results indicate that effective semantic search for mathematical theorems is achievable at a large scale, making it a valuable tool for researchers.', title='Revolutionizing Theorem Retrieval: A Semantic Approach at Scale'))
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"920","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='920', title=''))
[06.02.2026 04:11] Querying the API.
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

LatentMem is a learnable multi-agent memory framework that customizes agent-specific memories through latent representations, improving performance in multi-agent systems without modifying underlying frameworks.  					AI-generated summary 				 Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as a pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, a learnable multi-agent memory framework designed to customize agent-specific memories in a token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in a lightweight form, and a memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts. Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves a performance gain of up to 19.36% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks.
[06.02.2026 04:11] Response: ```json
{
  "desc": "LatentMem      ,           (latent) .     :   -          .           ,            .     Latent Memory Policy Optimization (LMPO),       ,        .",
  "emoji": "",
  "title": "     "
}
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LatentMem is a learnable multi-agent memory framework that customizes agent-specific memories through latent representations, improving performance in multi-agent systems without modifying underlying frameworks.  					AI-generated summary 				 Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as a pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, a learnable multi-agent memory framework designed to customize agent-specific memories in a token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in a lightweight form, and a memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts. Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves a performance gain of up to 19.36% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks."

[06.02.2026 04:11] Response: ```python
["AGENTS", "TRAINING", "ARCHITECTURE"]
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LatentMem is a learnable multi-agent memory framework that customizes agent-specific memories through latent representations, improving performance in multi-agent systems without modifying underlying frameworks.  					AI-generated summary 				 Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as a pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, a learnable multi-agent memory framework designed to customize agent-specific memories in a token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in a lightweight form, and a memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts. Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves a performance gain of up to 19.36% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks."

[06.02.2026 04:11] Response: ```python
['OPTIMIZATION']
```
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LatentMem is a novel framework designed to enhance multi-agent systems by creating customized memories for each agent using latent representations. This approach addresses two key issues in existing memory designs: the lack of role-specific customization and the problem of information overload from too many detailed memory entries. By utilizing an experience bank and a memory composer, LatentMem efficiently synthesizes compact memories tailored to individual agent contexts. The framework also introduces Latent Memory Policy Optimization (LMPO) to optimize memory utility, leading to significant performance improvements in various benchmarks without altering the foundational systems.","title":"Customizing Agent Memories for Enhanced Multi-Agent Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LatentMem is a novel framework designed to enhance multi-agent systems by creating customized memories for each agent using latent representations. This approach addresses two key issues in existing memory designs: the lack of role-specific customization and the problem of information overload from too many detailed memory entries. By utilizing an experience bank and a memory composer, LatentMem efficiently synthesizes compact memories tailored to individual agent contexts. The framework also introduces Latent Memory Policy Optimization (LMPO) to optimize memory utility, leading to significant performance improvements in various benchmarks without altering the foundational systems.', title='Customizing Agent Memories for Enhanced Multi-Agent Performance'))
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LatentMemLatentMemLMPOLatentMem","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LatentMemLatentMemLMPOLatentMem', title=''))
[06.02.2026 04:11] Querying the API.
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Context Forcing addresses student-teacher mismatch in long video generation by using a long-context teacher to guide long-rollout students through a Slow-Fast Memory architecture that extends context length beyond 20 seconds.  					AI-generated summary 				 Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical student-teacher mismatch: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose Context Forcing, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a Slow-Fast Memory architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.
[06.02.2026 04:11] Response: ```json
{
  "desc": "              .   Context Forcing  ,         ,      5- .      ( 2 )   Slow-Fast Memory,         .        20 ,   2-10            .",
  "emoji": "",
  "title": "        "
}
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Context Forcing addresses student-teacher mismatch in long video generation by using a long-context teacher to guide long-rollout students through a Slow-Fast Memory architecture that extends context length beyond 20 seconds.  					AI-generated summary 				 Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical student-teacher mismatch: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose Context Forcing, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a Slow-Fast Memory architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics."

[06.02.2026 04:11] Response: ```python
["VIDEO", "TRAINING", "ARCHITECTURE"]
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Context Forcing addresses student-teacher mismatch in long video generation by using a long-context teacher to guide long-rollout students through a Slow-Fast Memory architecture that extends context length beyond 20 seconds.  					AI-generated summary 				 Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical student-teacher mismatch: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose Context Forcing, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a Slow-Fast Memory architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics."

[06.02.2026 04:11] Response: ```python
['LONG_CONTEXT']
```
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Context Forcing, a method designed to improve long video generation by addressing the mismatch between short-context teachers and long-context students. Traditional approaches use a short-context teacher, limiting the student\'s ability to learn from long-term dependencies. Context Forcing employs a long-context teacher that can access the entire generation history, allowing for better guidance and training of the student model. This framework, combined with a Slow-Fast Memory architecture, enables the generation of videos with context lengths exceeding 20 seconds, significantly enhancing consistency and performance compared to existing methods.","title":"Bridging the Gap: Long-Context Learning for Video Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces Context Forcing, a method designed to improve long video generation by addressing the mismatch between short-context teachers and long-context students. Traditional approaches use a short-context teacher, limiting the student's ability to learn from long-term dependencies. Context Forcing employs a long-context teacher that can access the entire generation history, allowing for better guidance and training of the student model. This framework, combined with a Slow-Fast Memory architecture, enables the generation of videos with context lengths exceeding 20 seconds, significantly enhancing consistency and performance compared to existing methods.", title='Bridging the Gap: Long-Context Learning for Video Generation'))
[06.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Context Forcing-20-2","title":"-"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Context Forcing-20-2', title='-'))
[06.02.2026 04:11] Querying the API.
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Reinforcement World Model Learning enables LLM-based agents to better anticipate action consequences and adapt to environment dynamics through self-supervised training that aligns simulated and real-world state transitions in embedding space.  					AI-generated summary 				 Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and ^2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and ^2 Bench respectively, while matching the performance of expert-data training.
[06.02.2026 04:11] Response: ```json
{
  "desc": "   Reinforcement World Model Learning (RWML)            .                .       , RWML     ,      ,     .              .",
  "emoji": "",
  "title": "        "
}
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reinforcement World Model Learning enables LLM-based agents to better anticipate action consequences and adapt to environment dynamics through self-supervised training that aligns simulated and real-world state transitions in embedding space.  					AI-generated summary 				 Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and ^2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and ^2 Bench respectively, while matching the performance of expert-data training."

[06.02.2026 04:11] Response: ```python
['AGENTS', 'RL', 'TRAINING']
```
[06.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reinforcement World Model Learning enables LLM-based agents to better anticipate action consequences and adapt to environment dynamics through self-supervised training that aligns simulated and real-world state transitions in embedding space.  					AI-generated summary 				 Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and ^2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and ^2 Bench respectively, while matching the performance of expert-data training."

[06.02.2026 04:12] Response: ```python
['REASONING', 'OPTIMIZATION']
```

**Justification:**

- **REASONING**: The paper focuses on enhancing LLM-based agents' ability to anticipate action consequences and adapt to environment dynamics through world modeling, which directly relates to improving logical reasoning and planning capabilities in agents.

- **OPTIMIZATION**: The paper proposes a self-supervised training method (RWML) that optimizes how LLM-based agents learn world models, including techniques to avoid reward hacking and model collapse, which are core optimization concerns.
[06.02.2026 04:12] Error. Failed to parse JSON from LLM. ["REASONING", "OPTIMIZATION"]


**Justification:**

- **REASONING**: The paper focuses on enhancing LLM-based agents" ability to anticipate action consequences and adapt to environment dynamics through world modeling, which directly relates to improving logical reasoning and planning capabilities in agents.

- **OPTIMIZATION**: The paper proposes a self-supervised training method (RWML) that optimizes how LLM-based agents learn world models, including techniques to avoid reward hacking and model collapse, which are core optimization concerns.
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Reinforcement World Model Learning (RWML) is a self-supervised training method designed for large language model (LLM)-based agents to improve their ability to predict the outcomes of their actions and adapt to changing environments. It focuses on learning action-conditioned world models from textual states, aligning simulated state transitions with real-world observations in an embedding space. This approach encourages consistency between the agent\'s internal simulations and the actual dynamics of the environment, which is crucial for effective decision-making. RWML demonstrates significant performance improvements over traditional methods, particularly in environments like ALFWorld and ^2 Bench, while being less prone to issues like reward hacking.","title":"Empowering LLMs with Reinforcement World Models for Better Decision-Making"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="Reinforcement World Model Learning (RWML) is a self-supervised training method designed for large language model (LLM)-based agents to improve their ability to predict the outcomes of their actions and adapt to changing environments. It focuses on learning action-conditioned world models from textual states, aligning simulated state transitions with real-world observations in an embedding space. This approach encourages consistency between the agent's internal simulations and the actual dynamics of the environment, which is crucial for effective decision-making. RWML demonstrates significant performance improvements over traditional methods, particularly in environments like ALFWorld and ^2 Bench, while being less prone to issues like reward hacking.", title='Empowering LLMs with Reinforcement World Models for Better Decision-Making'))
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RWMLLLMRWMLRWML","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RWMLLLMRWMLRWML', title=''))
[06.02.2026 04:12] Querying the API.
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

CatRAG addresses limitations in retrieval-augmented generation by introducing a query-adaptive framework that improves multi-hop reasoning through symbolic anchoring, dynamic edge weighting, and key-fact passage enhancement.  					AI-generated summary 				 Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a "Static Graph Fallacy": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree "hub" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.
[06.02.2026 04:12] Response: ```json
{
  "desc": "   CatRAG         ,    (RAG),           .       'Static Graph Fallacy'       ,                .     :        ,          ,        .                .",
  "emoji": "",
  "title": "        "
}
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CatRAG addresses limitations in retrieval-augmented generation by introducing a query-adaptive framework that improves multi-hop reasoning through symbolic anchoring, dynamic edge weighting, and key-fact passage enhancement.  					AI-generated summary 				 Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a "Static Graph Fallacy": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree "hub" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG."

[06.02.2026 04:12] Response: ```python
["RAG", "BENCHMARK"]
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CatRAG addresses limitations in retrieval-augmented generation by introducing a query-adaptive framework that improves multi-hop reasoning through symbolic anchoring, dynamic edge weighting, and key-fact passage enhancement.  					AI-generated summary 				 Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a "Static Graph Fallacy": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree "hub" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG."

[06.02.2026 04:12] Response: ```python
['REASONING', 'GRAPHS', 'OPEN_SOURCE']
```
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CatRAG is a novel framework designed to enhance retrieval-augmented generation (RAG) by addressing the limitations of static graph structures in multi-hop reasoning. It introduces a query-adaptive navigation system that allows for dynamic edge weighting, which adjusts the relevance of graph connections based on the specific query. Additionally, CatRAG employs symbolic anchoring to guide the random walk and key-fact passage enhancement to ensure that the model retrieves complete evidence chains. Experimental results show that CatRAG significantly improves reasoning completeness, allowing for more effective retrieval of necessary information for complex queries.","title":"CatRAG: Enhancing Multi-Hop Reasoning with Query-Adaptive Navigation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CatRAG is a novel framework designed to enhance retrieval-augmented generation (RAG) by addressing the limitations of static graph structures in multi-hop reasoning. It introduces a query-adaptive navigation system that allows for dynamic edge weighting, which adjusts the relevance of graph connections based on the specific query. Additionally, CatRAG employs symbolic anchoring to guide the random walk and key-fact passage enhancement to ensure that the model retrieves complete evidence chains. Experimental results show that CatRAG significantly improves reasoning completeness, allowing for more effective retrieval of necessary information for complex queries.', title='CatRAG: Enhancing Multi-Hop Reasoning with Query-Adaptive Navigation'))
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CatRAGRAGCatRAG","title":"CatRAG"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CatRAGRAGCatRAG', title='CatRAG'))
[06.02.2026 04:12] Querying the API.
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models can be trained more efficiently by transferring knowledge from later training phases to earlier layers during initial training, achieving faster convergence and improved performance.  					AI-generated summary 				 As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: Can we leverage existing small pretrained models to accelerate the training of larger models? In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6times speedup with nearly 5\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10times fewer parameters than the target model.
[06.02.2026 04:12] Response: ```json
{
  "desc": "    Late-to-Early Training (LET),        ,            .     :              .  ,  LET     1.6       5%     .         ,   10    .",
  "emoji": "",
  "title": "      :     "
}
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models can be trained more efficiently by transferring knowledge from later training phases to earlier layers during initial training, achieving faster convergence and improved performance.  					AI-generated summary 				 As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: Can we leverage existing small pretrained models to accelerate the training of larger models? In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6times speedup with nearly 5\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10times fewer parameters than the target model."

[06.02.2026 04:12] Response: ```python
["TRAINING", "ARCHITECTURE"]
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models can be trained more efficiently by transferring knowledge from later training phases to earlier layers during initial training, achieving faster convergence and improved performance.  					AI-generated summary 				 As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: Can we leverage existing small pretrained models to accelerate the training of larger models? In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6times speedup with nearly 5\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10times fewer parameters than the target model."

[06.02.2026 04:12] Response: ```python
["TRANSFER_LEARNING", "OPTIMIZATION"]
```
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new training approach called Late-to-Early Training (LET) for Large Language Models (LLMs). The method allows early layers of the model to learn from the knowledge acquired in later layers of a pretrained model, which helps in speeding up the training process. By utilizing representations from late layers, LET enhances both the convergence speed and the overall performance of the model on various tasks. Experimental results show that this approach can significantly reduce training time while improving accuracy, demonstrating its effectiveness in leveraging smaller pretrained models for training larger ones.","title":"Accelerating LLM Training with Late-to-Early Knowledge Transfer"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a new training approach called Late-to-Early Training (LET) for Large Language Models (LLMs). The method allows early layers of the model to learn from the knowledge acquired in later layers of a pretrained model, which helps in speeding up the training process. By utilizing representations from late layers, LET enhances both the convergence speed and the overall performance of the model on various tasks. Experimental results show that this approach can significantly reduce training time while improving accuracy, demonstrating its effectiveness in leveraging smaller pretrained models for training larger ones.', title='Accelerating LLM Training with Late-to-Early Knowledge Transfer'))
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LETLETLET1.4B7B","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LETLETLET1.4B7B', title=''))
[06.02.2026 04:12] Querying the API.
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DeR2 presents a controlled evaluation framework for assessing language models' document-grounded reasoning capabilities by isolating reasoning from retrieval and toolchain decisions.  					AI-generated summary 				 Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.
[06.02.2026 04:12] Response: ```json
{
  "desc": "DeR2     ,                .           ,    ,     :        .        ,          2023-2025    .  ,                .",
  "emoji": "",
  "title": "   :       "
}
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeR2 presents a controlled evaluation framework for assessing language models' document-grounded reasoning capabilities by isolating reasoning from retrieval and toolchain decisions.  					AI-generated summary 				 Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures."

[06.02.2026 04:12] Response: ```python
["BENCHMARK", "RAG", "DATASET"]
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeR2 presents a controlled evaluation framework for assessing language models' document-grounded reasoning capabilities by isolating reasoning from retrieval and toolchain decisions.  					AI-generated summary 				 Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures."

[06.02.2026 04:12] Response: ```python
['REASONING', 'SCIENCE', 'INTERPRETABILITY', 'LEAKAGE']
```
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeR2 is a new evaluation framework designed to test how well language models can reason using information from documents. It separates the reasoning process from the retrieval of information, allowing for a clearer understanding of a model\'s capabilities. The framework includes different testing conditions to analyze how models perform when given varying amounts of relevant information. Results show that there are significant differences in how models handle reasoning tasks, highlighting areas for improvement in their design and training.","title":"Isolating Reasoning: Unveiling Language Models\' True Capabilities"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="DeR2 is a new evaluation framework designed to test how well language models can reason using information from documents. It separates the reasoning process from the retrieval of information, allowing for a clearer understanding of a model's capabilities. The framework includes different testing conditions to analyze how models perform when given varying amounts of relevant information. Results show that there are significant differences in how models handle reasoning tasks, highlighting areas for improvement in their design and training.", title="Isolating Reasoning: Unveiling Language Models' True Capabilities"))
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeR2","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DeR2', title=''))
[06.02.2026 04:12] Querying the API.
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FastVMT accelerates video motion transfer by addressing computational redundancies in Diffusion Transformer architecture through localized attention masking and gradient reuse optimization.  					AI-generated summary 				 Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory. To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos.
[06.02.2026 04:12] Response: ```json
{
  "desc": "             -.         Diffusion Transformer:    - ,       ,     -      .         (attention masking),       .      ,         ,     3.43     .",
  "emoji": "",
  "title": "        "
}
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FastVMT accelerates video motion transfer by addressing computational redundancies in Diffusion Transformer architecture through localized attention masking and gradient reuse optimization.  					AI-generated summary 				 Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory. To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos."

[06.02.2026 04:12] Response: ```python
["VIDEO", "INFERENCE", "ARCHITECTURE"]
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FastVMT accelerates video motion transfer by addressing computational redundancies in Diffusion Transformer architecture through localized attention masking and gradient reuse optimization.  					AI-generated summary 				 Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory. To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos."

[06.02.2026 04:12] Response: ```python
['DIFFUSION', 'OPTIMIZATION']
```
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FastVMT is a method that speeds up video motion transfer by improving the efficiency of the Diffusion Transformer architecture. It does this by addressing two main types of computational redundancies: motion redundancy and gradient redundancy. By using localized attention masking, it focuses on nearby frames instead of distant ones, reducing unnecessary calculations. Additionally, it reuses gradients from previous steps to avoid redundant computations, resulting in a significant speedup while maintaining high-quality video output.","title":"Accelerating Video Motion Transfer with FastVMT"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FastVMT is a method that speeds up video motion transfer by improving the efficiency of the Diffusion Transformer architecture. It does this by addressing two main types of computational redundancies: motion redundancy and gradient redundancy. By using localized attention masking, it focuses on nearby frames instead of distant ones, reducing unnecessary calculations. Additionally, it reuses gradients from previous steps to avoid redundant computations, resulting in a significant speedup while maintaining high-quality video output.', title='Accelerating Video Motion Transfer with FastVMT'))
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FastVMTFastVMT3.43","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FastVMTFastVMT3.43', title=''))
[06.02.2026 04:12] Querying the API.
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ProAct enhances LLM agents' long-horizon planning by combining supervised fine-tuning with search-derived trajectories and a Monte-Carlo critic for improved policy optimization.  					AI-generated summary 				 Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct
[06.02.2026 04:12] Response: ```json
{
  "desc": "ProAct        LLM-   ,         .    Grounded LookAhead Distillation (GLAD)  supervised fine-tuning       ,        .    Monte-Carlo Critic (MC-Critic)             PPO  GRPO.  ,  ProAct        4B          SOTA .",
  "emoji": "",
  "title": "   :  LLM     "
}
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ProAct enhances LLM agents' long-horizon planning by combining supervised fine-tuning with search-derived trajectories and a Monte-Carlo critic for improved policy optimization.  					AI-generated summary 				 Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct"

[06.02.2026 04:12] Response: ```python
["AGENTS", "TRAINING", "RLHF"]
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ProAct enhances LLM agents' long-horizon planning by combining supervised fine-tuning with search-derived trajectories and a Monte-Carlo critic for improved policy optimization.  					AI-generated summary 				 Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct"

[06.02.2026 04:12] Response: ```python
['REASONING', 'OPTIMIZATION', 'GAMES', 'OPEN_SOURCE']
```
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ProAct is a framework designed to improve the long-horizon planning capabilities of Large Language Model (LLM) agents. It combines supervised fine-tuning with search-derived trajectories to enhance the agent\'s ability to reason about future states. The method includes Grounded LookAhead Distillation (GLAD) for training on simplified causal reasoning chains, and a Monte-Carlo Critic (MC-Critic) to provide stable value estimates for policy optimization. Experiments show that ProAct significantly boosts planning accuracy, outperforming existing models in both stochastic and deterministic environments.","title":"ProAct: Enhancing Long-Horizon Planning in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="ProAct is a framework designed to improve the long-horizon planning capabilities of Large Language Model (LLM) agents. It combines supervised fine-tuning with search-derived trajectories to enhance the agent's ability to reason about future states. The method includes Grounded LookAhead Distillation (GLAD) for training on simplified causal reasoning chains, and a Monte-Carlo Critic (MC-Critic) to provide stable value estimates for policy optimization. Experiments show that ProAct significantly boosts planning accuracy, outperforming existing models in both stochastic and deterministic environments.", title='ProAct: Enhancing Long-Horizon Planning in LLMs'))
[06.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ProActLLMProAct","title":"ProActLLM"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ProActLLMProAct', title='ProActLLM'))
[06.02.2026 04:12] Querying the API.
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Test-Time Correction addresses error accumulation in distilled autoregressive diffusion models for long-video synthesis by using initial frames as reference anchors to calibrate stochastic states during sampling.  					AI-generated summary 				 Distilled autoregressive diffusion models facilitate real-time short video synthesis but suffer from severe error accumulation during long-sequence generation. While existing Test-Time Optimization (TTO) methods prove effective for images or short clips, we identify that they fail to mitigate drift in extended sequences due to unstable reward landscapes and the hypersensitivity of distilled parameters. To overcome these limitations, we introduce Test-Time Correction (TTC), a training-free alternative. Specifically, TTC utilizes the initial frame as a stable reference anchor to calibrate intermediate stochastic states along the sampling trajectory. Extensive experiments demonstrate that our method seamlessly integrates with various distilled models, extending generation lengths with negligible overhead while matching the quality of resource-intensive training-based methods on 30-second benchmarks.
[06.02.2026 04:12] Response: ```json
{
  "desc": "    Test-Time Correction              .           -       .                   .  ,                  .",
  "emoji": "",
  "title": "   :       "
}
```
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Test-Time Correction addresses error accumulation in distilled autoregressive diffusion models for long-video synthesis by using initial frames as reference anchors to calibrate stochastic states during sampling.  					AI-generated summary 				 Distilled autoregressive diffusion models facilitate real-time short video synthesis but suffer from severe error accumulation during long-sequence generation. While existing Test-Time Optimization (TTO) methods prove effective for images or short clips, we identify that they fail to mitigate drift in extended sequences due to unstable reward landscapes and the hypersensitivity of distilled parameters. To overcome these limitations, we introduce Test-Time Correction (TTC), a training-free alternative. Specifically, TTC utilizes the initial frame as a stable reference anchor to calibrate intermediate stochastic states along the sampling trajectory. Extensive experiments demonstrate that our method seamlessly integrates with various distilled models, extending generation lengths with negligible overhead while matching the quality of resource-intensive training-based methods on 30-second benchmarks."

[06.02.2026 04:12] Response: ```python
["VIDEO", "INFERENCE", "TRAINING"]
```

**Justification:**

- **VIDEO**: The paper explicitly focuses on "long-video synthesis" and "video generation," dealing with video analysis and generation.

- **INFERENCE**: The paper addresses "test-time" optimization and correction during model sampling/deployment, which relates to optimizing model inference without retraining.

- **TRAINING**: The paper discusses "distilled autoregressive diffusion models" and compares against "training-based methods," indicating engagement with model training and distillation techniques.
[06.02.2026 04:12] Error. Failed to parse JSON from LLM. ["VIDEO", "INFERENCE", "TRAINING"]


**Justification:**

- **VIDEO**: The paper explicitly focuses on "long-video synthesis" and "video generation," dealing with video analysis and generation.

- **INFERENCE**: The paper addresses "test-time" optimization and correction during model sampling/deployment, which relates to optimizing model inference without retraining.

- **TRAINING**: The paper discusses "distilled autoregressive diffusion models" and compares against "training-based methods," indicating engagement with model training and distillation techniques.
[06.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Test-Time Correction addresses error accumulation in distilled autoregressive diffusion models for long-video synthesis by using initial frames as reference anchors to calibrate stochastic states during sampling.  					AI-generated summary 				 Distilled autoregressive diffusion models facilitate real-time short video synthesis but suffer from severe error accumulation during long-sequence generation. While existing Test-Time Optimization (TTO) methods prove effective for images or short clips, we identify that they fail to mitigate drift in extended sequences due to unstable reward landscapes and the hypersensitivity of distilled parameters. To overcome these limitations, we introduce Test-Time Correction (TTC), a training-free alternative. Specifically, TTC utilizes the initial frame as a stable reference anchor to calibrate intermediate stochastic states along the sampling trajectory. Extensive experiments demonstrate that our method seamlessly integrates with various distilled models, extending generation lengths with negligible overhead while matching the quality of resource-intensive training-based methods on 30-second benchmarks."

[06.02.2026 04:12] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```

**Justification:**

- **DIFFUSION**: The paper explicitly focuses on "distilled autoregressive diffusion models" and addresses error accumulation in diffusion-based video synthesis, which is a core diffusion model application.

- **OPTIMIZATION**: The paper introduces "Test-Time Correction (TTC)" as an optimization method applied during sampling/inference to improve model performance, and discusses limitations of existing "Test-Time Optimization (TTO)" methods.
[06.02.2026 04:12] Error. Failed to parse JSON from LLM. ["DIFFUSION", "OPTIMIZATION"]


**Justification:**

- **DIFFUSION**: The paper explicitly focuses on "distilled autoregressive diffusion models" and addresses error accumulation in diffusion-based video synthesis, which is a core diffusion model application.

- **OPTIMIZATION**: The paper introduces "Test-Time Correction (TTC)" as an optimization method applied during sampling/inference to improve model performance, and discusses limitations of existing "Test-Time Optimization (TTO)" methods.
[06.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents Test-Time Correction (TTC), a method designed to reduce error accumulation in distilled autoregressive diffusion models when generating long videos. Traditional methods struggle with long sequences due to unstable reward landscapes and sensitivity in distilled parameters. TTC addresses these issues by using the initial frame as a stable reference to adjust the stochastic states during the sampling process. The results show that TTC can effectively extend video generation lengths while maintaining high quality, comparable to more resource-intensive training methods.","title":"Stabilizing Long Video Synthesis with Test-Time Correction"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents Test-Time Correction (TTC), a method designed to reduce error accumulation in distilled autoregressive diffusion models when generating long videos. Traditional methods struggle with long sequences due to unstable reward landscapes and sensitivity in distilled parameters. TTC addresses these issues by using the initial frame as a stable reference to adjust the stochastic states during the sampling process. The results show that TTC can effectively extend video generation lengths while maintaining high quality, comparable to more resource-intensive training methods.', title='Stabilizing Long Video Synthesis with Test-Time Correction'))
[06.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TTCTTCTTCTTC30","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TTCTTCTTCTTC30', title=''))
[06.02.2026 04:13] Querying the API.
[06.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

BABE is a biology-focused benchmark designed to evaluate AI systems' ability to perform experimental reasoning and causal inference similar to practicing scientists.  					AI-generated summary 				 The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research.
[06.02.2026 04:13] Response: ```json
{
  "desc": "BABE        AI      - ,   -.            ,       .              ,       -  .       ,   LLM      .",
  "emoji": "",
  "title": "   :    "
}
```
[06.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"BABE is a biology-focused benchmark designed to evaluate AI systems' ability to perform experimental reasoning and causal inference similar to practicing scientists.  					AI-generated summary 				 The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research."

[06.02.2026 04:13] Response: ```python
["BENCHMARK", "DATASET"]
```
[06.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"BABE is a biology-focused benchmark designed to evaluate AI systems' ability to perform experimental reasoning and causal inference similar to practicing scientists.  					AI-generated summary 				 The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research."

[06.02.2026 04:13] Response: ```python
['SCIENCE', 'REASONING']
```
[06.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces BABE, a benchmark specifically designed to evaluate AI systems on their ability to perform experimental reasoning and causal inference in biology. It highlights the limitations of existing benchmarks that do not adequately test the integration of experimental results with contextual knowledge, which is crucial for scientific research. BABE is constructed from real-world biological studies and peer-reviewed papers, making it relevant to actual scientific practices. This benchmark aims to provide a more authentic assessment of AI\'s reasoning capabilities, thereby enhancing its potential contributions to biological research.","title":"Evaluating AI\'s Scientific Reasoning with BABE"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces BABE, a benchmark specifically designed to evaluate AI systems on their ability to perform experimental reasoning and causal inference in biology. It highlights the limitations of existing benchmarks that do not adequately test the integration of experimental results with contextual knowledge, which is crucial for scientific research. BABE is constructed from real-world biological studies and peer-reviewed papers, making it relevant to actual scientific practices. This benchmark aims to provide a more authentic assessment of AI's reasoning capabilities, thereby enhancing its potential contributions to biological research.", title="Evaluating AI's Scientific Reasoning with BABE"))
[06.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"BABEBABEBABE","title":"BABEAI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='BABEBABEBABE', title='BABEAI'))
[06.02.2026 04:13] Querying the API.
[06.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Researchers developed a discrete audio codec called ReasoningCodec that separates audio into reasoning and reconstruction tokens for improved understanding and generation, and created UniAudio 2.0, a unified autoregressive model trained on large-scale text and audio data that shows strong performance across various audio tasks and generalizes well in few-shot and zero-shot scenarios.  					AI-generated summary 				 We study two foundational problems in audio language models: (1) how to design an audio tokenizer that can serve as an intermediate representation for both understanding and generation; and (2) how to build an audio foundation model that generalizes in few-shot and zero-shot settings, analogous to large language models. To this end, we make the following two contributions. First, we propose ReasoningCodec, a discrete audio codec that factorizes audio into (i) reasoning tokens, which encode text-aligned, high-level analysis and planning representations for audio understanding and hierarchical generation, and (ii) reconstruction tokens, which encode semantic-rich acoustic cues for high-fidelity waveform reconstruction. This design achieves understanding performance comparable to strong continuous representations while improving generation quality and reconstruction fidelity over prior discrete tokenizers. Second, we introduce a unified autoregressive architecture for text and audio, together with multi-stage training and multi-task data construction. Using this framework, we train UniAudio 2.0 on 100B text tokens and 60B audio tokens. Across a wide range of speech, sound, and music tasks, UniAudio 2.0 performs competitively on in-domain evaluations and demonstrates strong few-shot and zero-shot generalization to unseen tasks. Demo, code, and checkpoints will be available at https://dongchaoyang.top/UniAudio2Demo/{https://dongchaoyang.top/UniAudio2Demo/}.
[06.02.2026 04:13] Response: ```json
{
  "desc": "  ReasoningCodec   ,              ,     ,   .      UniAudio 2.0     ,   100     60  .       ,   ,  ,    . UniAudio 2.0       few-shot  zero-shot,       .",
  "emoji": "",
  "title": "     "
}
```
[06.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers developed a discrete audio codec called ReasoningCodec that separates audio into reasoning and reconstruction tokens for improved understanding and generation, and created UniAudio 2.0, a unified autoregressive model trained on large-scale text and audio data that shows strong performance across various audio tasks and generalizes well in few-shot and zero-shot scenarios.  					AI-generated summary 				 We study two foundational problems in audio language models: (1) how to design an audio tokenizer that can serve as an intermediate representation for both understanding and generation; and (2) how to build an audio foundation model that generalizes in few-shot and zero-shot settings, analogous to large language models. To this end, we make the following two contributions. First, we propose ReasoningCodec, a discrete audio codec that factorizes audio into (i) reasoning tokens, which encode text-aligned, high-level analysis and planning representations for audio understanding and hierarchical generation, and (ii) reconstruction tokens, which encode semantic-rich acoustic cues for high-fidelity waveform reconstruction. This design achieves understanding performance comparable to strong continuous representations while improving generation quality and reconstruction fidelity over prior discrete tokenizers. Second, we introduce a unified autoregressive architecture for text and audio, together with multi-stage training and multi-task data construction. Using this framework, we train UniAudio 2.0 on 100B text tokens and 60B audio tokens. Across a wide range of speech, sound, and music tasks, UniAudio 2.0 performs competitively on in-domain evaluations and demonstrates strong few-shot and zero-shot generalization to unseen tasks. Demo, code, and checkpoints will be available at https://dongchaoyang.top/UniAudio2Demo/{https://dongchaoyang.top/UniAudio2Demo/}."

[06.02.2026 04:13] Response: ```python
["AUDIO", "MULTIMODAL", "ARCHITECTURE", "TRAINING"]
```
[06.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers developed a discrete audio codec called ReasoningCodec that separates audio into reasoning and reconstruction tokens for improved understanding and generation, and created UniAudio 2.0, a unified autoregressive model trained on large-scale text and audio data that shows strong performance across various audio tasks and generalizes well in few-shot and zero-shot scenarios.  					AI-generated summary 				 We study two foundational problems in audio language models: (1) how to design an audio tokenizer that can serve as an intermediate representation for both understanding and generation; and (2) how to build an audio foundation model that generalizes in few-shot and zero-shot settings, analogous to large language models. To this end, we make the following two contributions. First, we propose ReasoningCodec, a discrete audio codec that factorizes audio into (i) reasoning tokens, which encode text-aligned, high-level analysis and planning representations for audio understanding and hierarchical generation, and (ii) reconstruction tokens, which encode semantic-rich acoustic cues for high-fidelity waveform reconstruction. This design achieves understanding performance comparable to strong continuous representations while improving generation quality and reconstruction fidelity over prior discrete tokenizers. Second, we introduce a unified autoregressive architecture for text and audio, together with multi-stage training and multi-task data construction. Using this framework, we train UniAudio 2.0 on 100B text tokens and 60B audio tokens. Across a wide range of speech, sound, and music tasks, UniAudio 2.0 performs competitively on in-domain evaluations and demonstrates strong few-shot and zero-shot generalization to unseen tasks. Demo, code, and checkpoints will be available at https://dongchaoyang.top/UniAudio2Demo/{https://dongchaoyang.top/UniAudio2Demo/}."

[06.02.2026 04:13] Response: ```python
['REASONING', 'OPEN_SOURCE']
```
[06.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces ReasoningCodec, a novel discrete audio codec that divides audio into two types of tokens: reasoning tokens for high-level understanding and reconstruction tokens for accurate audio reproduction. The authors also present UniAudio 2.0, a unified autoregressive model that integrates both text and audio data, trained on a massive dataset to enhance its performance across various audio tasks. The model demonstrates impressive capabilities in few-shot and zero-shot learning, allowing it to adapt to new tasks with minimal examples. Overall, this work advances the field of audio language models by improving both understanding and generation of audio content.","title":"Revolutionizing Audio Understanding and Generation with ReasoningCodec and UniAudio 2.0"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces ReasoningCodec, a novel discrete audio codec that divides audio into two types of tokens: reasoning tokens for high-level understanding and reconstruction tokens for accurate audio reproduction. The authors also present UniAudio 2.0, a unified autoregressive model that integrates both text and audio data, trained on a massive dataset to enhance its performance across various audio tasks. The model demonstrates impressive capabilities in few-shot and zero-shot learning, allowing it to adapt to new tasks with minimal examples. Overall, this work advances the field of audio language models by improving both understanding and generation of audio content.', title='Revolutionizing Audio Understanding and Generation with ReasoningCodec and UniAudio 2.0'))
[06.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ReasoningCodecUniAudio 2.0ReasoningCodecUniAudio 2.0","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ReasoningCodecUniAudio 2.0ReasoningCodecUniAudio 2.0', title=''))
[06.02.2026 04:13] Renaming data file.
[06.02.2026 04:13] Renaming previous data. hf_papers.json to ./d/2026-02-06.json
[06.02.2026 04:13] Saving new data file.
[06.02.2026 04:13] Generating page.
[06.02.2026 04:13] Renaming previous page.
[06.02.2026 04:13] Renaming previous data. index.html to ./d/2026-02-06.html
[06.02.2026 04:13] Writing result.
[06.02.2026 04:13] Renaming log file.
[06.02.2026 04:13] Renaming previous data. log.txt to ./logs/2026-02-06_last_log.txt
