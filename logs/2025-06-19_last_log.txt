[19.06.2025 11:11] Read previous papers.
[19.06.2025 11:11] Generating top page (month).
[19.06.2025 11:11] Writing top page (month).
[19.06.2025 12:22] Read previous papers.
[19.06.2025 12:22] Get feed.
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15675
[19.06.2025 12:22] Extract page data from URL. URL: https://huggingface.co/papers/2506.15211
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15681
[19.06.2025 12:22] Extract page data from URL. URL: https://huggingface.co/papers/2506.13414
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15677
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15068
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15569
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15050
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06279
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15672
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14435
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14866
[19.06.2025 12:22] Extract page data from URL. URL: https://huggingface.co/papers/2506.14315
[19.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14824
[19.06.2025 12:22] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[19.06.2025 12:22] No deleted papers detected.
[19.06.2025 12:22] Downloading and parsing papers (pdf, html). Total: 14.
[19.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.15675.
[19.06.2025 12:22] Extra JSON file exists (./assets/json/2506.15675.json), skip PDF parsing.
[19.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.15675.json), skip HTML parsing.
[19.06.2025 12:22] Success.
[19.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.15211.
[19.06.2025 12:22] Downloading paper 2506.15211 from http://arxiv.org/pdf/2506.15211v1...
[19.06.2025 12:22] Extracting affiliations from text.
[19.06.2025 12:22] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs Feng He1,, Zijun Chen1,2,, Xinnian Liang1, Tingting Ma1, Yunqi Qiu1, Shuangzhi Wu1,, Junchi Yan2 1ByteDance Seed, 2Shanghai Jiao Tong University Work done at ByteDance Seed, Corresponding authors "
[19.06.2025 12:22] Response: ```python
["ByteDance Seed", "Shanghai Jiao Tong University"]
```
[19.06.2025 12:22] Deleting PDF ./assets/pdf/2506.15211.pdf.
[19.06.2025 12:22] Success.
[19.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.15681.
[19.06.2025 12:22] Extra JSON file exists (./assets/json/2506.15681.json), skip PDF parsing.
[19.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.15681.json), skip HTML parsing.
[19.06.2025 12:22] Success.
[19.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.13414.
[19.06.2025 12:23] Downloading paper 2506.13414 from http://arxiv.org/pdf/2506.13414v1...
[19.06.2025 12:23] Extracting affiliations from text.
[19.06.2025 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"BUT System for the MLC-SLM Challenge Alexander Polok1, Jiangyu Han1, Dominik Klement1, Samuele Cornell2, Jan ˇCernocky1, Lukaˇs Burget1 1Speech@FIT, Brno University of Technology, Czechia 2Language Technologies Institute, Carnegie Mellon University, USA ipoloka@fit.vut.cz 5 2 0 2 6 ] . e [ 1 4 1 4 3 1 . 6 0 5 2 : r a "
[19.06.2025 12:23] Response: ```python
[
    "Speech@FIT, Brno University of Technology, Czechia",
    "Language Technologies Institute, Carnegie Mellon University, USA"
]
```
[19.06.2025 12:23] Deleting PDF ./assets/pdf/2506.13414.pdf.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.15677.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.15677.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.15677.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.15068.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.15068.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.15068.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.15569.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.15569.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.15569.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.15050.
[19.06.2025 12:23] Downloading paper 2506.15050 from http://arxiv.org/pdf/2506.15050v1...
[19.06.2025 12:23] Extracting affiliations from text.
[19.06.2025 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"1ByteDance Seed Full author list in Contributions "
[19.06.2025 12:23] Response: []
[19.06.2025 12:23] Extracting affiliations from text.
[19.06.2025 12:23] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"1ByteDance Seed Full author list in ContributionsRecently, test-time scaling Large Language Models (LLMs) have demonstrated exceptional reasoning capabilities across scientific and professional tasks by generating long chains-of-thought (CoT). As crucial component for developing these reasoning models, reinforcement learning (RL), exemplified by Proximal Policy Optimization (PPO) and its variants, allows models to learn through trial and error. However, PPO can be time-consuming due to its inherent on-policy nature, which is further exacerbated by increasing response lengths. In this work, we propose Truncated Proximal Policy Optimization (T-PPO), novel extension to PPO that improves training efficiency by streamlining policy update and length-restricted response generation. T-PPO mitigates the issue of low hardware utilization, an inherent drawback of fully synchronized long-generation procedures, where resources often sit idle during the waiting periods for complete rollouts. Our contributions are two-folds. First, we propose Extended Generalized Advantage Estimation (EGAE) for advantage estimation derived from incomplete responses while maintaining the integrity of policy learning. Second, we devise computationally optimized mechanism that allows for the independent optimization of the policy and value models. By selectively filtering prompt and truncated tokens, this mechanism reduces redundant computations and accelerates the training process without sacrificing convergence performance. We demonstrate the effectiveness and efficacy of T-PPO on AIME 2024 with 32B base model. The experimental results show that T-PPO improves the training efficiency of reasoning LLMs by up to 2.5 and outperforms its existing competitors. Date: June 9, 2025 Correspondence: Tiantian Fan at fantiantian.tt@bytedance.com 5 2 0 2 8 1 ] . [ 1 0 5 0 5 1 . 6 0 5 2 : r Figure 1 AIME 2024 scores of T-PPO on the Qwen2.5-32B base model, reduces training time by 60% compared to the previous state-of-the-art (SOTA) method. The values shown are pass@1 scores, averaged over 32 samples per question.Recent advances in reasoning-oriented Large Language Models (LLMs), such as OpenAIs o1 [1], DeepSeekR1 [2], and QwQ [3], have demonstrated the state-of-the-art performance across complex domains including mathematical reasoning, programming, and agent-based tasks. These models leverage extended chainof-thought (CoT) reasoning to improve inference quality, integrating backtracking and error-correction mechanisms that produce more structured and accurate outputs. This enhanced reasoning capability stems primarily from deep reinforcement learning (RL) techniques, through which LLMs learn to generate explicit, logically-sequenced reasoning steps prior to final answer production. As the predominant RL approach for LLM refinement, Proximal Policy Optimization (PPO) [4] maintains training stability through its clipped surrogate objective function. Despite its advantages, PPOs on-policy nature inherently restricts training efficiency, limitation that becomes especially apparent when processing long CoT trajectories, often leading to substantial computational overhead and extended training durations. To address this issue, researchers have developed various off-policy PPO variants that are designed to enhance sample efficiency via trajectory reuse. Specifically, Generalized Proximal Policy Optimization (GePPO) [5] extends the guarantees of policy improvement to the off-policy setting. Off-Policy PPO [6] designs clipped surrogate objective function that can utilize off-policy data and avoid excessively large policy updates. PPO-EWMA [7] employs decoupled policy objectives and an exponentially weighted moving average (EWMA) for policy updates. KIMI K1.5 [8] uses partial rollouts to improve training efficiency by reusing large chunk of previous trajectories when sampling, thus avoiding the cost of regenerating new trajectories from scratch. Although off-policy methods are more training-efficient, they typically suffer from high variance in the policy gradient estimator, resulting in unstable training and degraded performance. In this work, we present Truncated Proximal Policy Optimization (T-PPO), an enhanced on-policy reinforcement learning framework that significantly improves efficiency while maintaining or even enhancing reasoning performance. At the core of T-PPO is our Extended Generalized Advantage Estimation (EGAE) method, which enables progressive policy updates even before trajectory is fully generated. Specifically, EGAE generalizes the conventional Generalized Advantage Estimation (GAE) [9] to support policy optimization with partially generated responses. This decouples policy updates from response completion and significantly improves computational resource utilization. Furthermore, to ensure unbiased value estimation, we maintain the Monte Carlo training paradigm for value model updates, deferring these updates until full response generation is complete. This estimation relies exclusively on actual observed returns rather than estimated values, thereby eliminating approximation bias in the value function. This dual optimization strategy allows simultaneous, yet independent improvement of both policy and value models through selective token screening. In summary, our design yields three key advantages: (1) truncated rollout strategy that enhances GPU throughput, (2) complete elimination of persistent bias in value function estimation, and (3) substantially improved policy update efficiency achieved through enhanced data utilization. Our extensive experiments on the AIME 2024 benchmark demonstrate that T-PPO delivers significant efficiency gains without compromising model performance. Specifically, the algorithm exhibits robust convergence behavior through its sample-efficient learning mechanism, which consistently enhances policy optimization. These combined attributes enable T-PPO to achieve 62 pass@1 on the AIME24 benchmark while demonstrating 2.5 higher training efficiency compared to state-of-the-art synchronization algorithms. Such performance characteristics significantly expand the practical deployment potential of T-PPO in real-world applications. Remarkably, these improvements are attained without introducing additional constraints or regularization beyond standard PPO. Apart from reducing the training cost, we sincerely hope that this method can bring more inspiration for delving into specialized expert "
[19.06.2025 12:23] Mistral response. {"id": "79b9fac2d41941deb4dc4e3960d5eadb", "object": "chat.completion", "created": 1750335809, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\"ByteDance\"]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1456, "total_tokens": 1462, "completion_tokens": 6}}
[19.06.2025 12:23] Response: ["ByteDance"]
[19.06.2025 12:23] Deleting PDF ./assets/pdf/2506.15050.pdf.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.06279.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.06279.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.06279.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.15672.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.15672.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.15672.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.14435.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.14435.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.14435.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.14866.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.14866.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.14866.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.14315.
[19.06.2025 12:23] Downloading paper 2506.14315 from http://arxiv.org/pdf/2506.14315v2...
[19.06.2025 12:23] Extracting affiliations from text.
[19.06.2025 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies Jinyan Yuan1 Bangbang Yang1 Xuehai Zhang1 Xiao Liu1 1ByteDance Keke Wang1 Zhaopeng Cui2 2Zhejiang University Panwang Pan1 Lin Ma Yuewen Ma1 5 2 0 2 8 1 ] . [ 2 5 1 3 4 1 . 6 0 5 2 : r Figure 1: ImmerseGen creates panoramic 3D worlds from input prompts by generating compact alpha-textured proxies through agent-guided asset design and arrangement, alleviating the reliance on rich and complex assets while ensuring diversity and realism, which is tailored for immersive VR experience. Abstract Automatic creation of 3D scenes for immersive VR presence has been significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with posthoc simplification or massive 3D Gaussians, resulting in complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery. This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based model"
[19.06.2025 12:23] Response: ```python
["ByteDance", "Zhejiang University"]
```
[19.06.2025 12:23] Deleting PDF ./assets/pdf/2506.14315.pdf.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Downloading and parsing paper https://huggingface.co/papers/2506.14824.
[19.06.2025 12:23] Extra JSON file exists (./assets/json/2506.14824.json), skip PDF parsing.
[19.06.2025 12:23] Paper image links file exists (./assets/img_data/2506.14824.json), skip HTML parsing.
[19.06.2025 12:23] Success.
[19.06.2025 12:23] Enriching papers with extra data.
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 0. Sekai, a worldwide video dataset with comprehensive annotations, is introduced to support world exploration applications, enhancing video generation models.  					AI-generated summary 				 Video generation techniques have made remarkable progress, promising to be the foundation of interactive world ...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 1. ProtoReasoning enhances large reasoning models through prototypical representations, leading to improved cross-domain generalization in logical reasoning, planning, and other tasks.  					AI-generated summary 				 Recent advances in Large Reasoning Models (LRMs) trained with Long Chain-of-Thought (L...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 2. GenRecal, a novel distillation framework, improves performance of vision-language models by aligning feature representations across different architectures.  					AI-generated summary 				 Recent advancements in vision-language models (VLMs) have leveraged large language models (LLMs) to achieve per...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 3. The combined DiCoW and DiariZen ASR system demonstrates strong performance in multilingual scenarios, with DiCoW preserving its multilingual capabilities and DiariZen improving through fine-tuning.  					AI-generated summary 				 We present a two-speaker automatic speech recognition (ASR) system tha...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 4. Embodied Web Agents integrate physical interaction and web-scale reasoning to assess cross-domain intelligence in a novel benchmark environment.  					AI-generated summary 				 AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge o...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 5. PrefBERT, a scoring model, improves open-ended long-form generation by providing better semantic reward feedback than traditional metrics.  					AI-generated summary 				 Evaluating open-ended long-form generation is challenging because it is hard to define what clearly separates good from bad outpu...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 6. A benchmark named SciVer evaluates multimodal foundation models' claim verification capabilities within scientific contexts, revealing performance gaps and limitations in current models.  					AI-generated summary 				 We introduce SciVer, the first benchmark specifically designed to evaluate the ab...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 7. T-PPO, an extension of PPO, improves training efficiency for Large Language Models by optimizing policy updates and utilizing hardware resources more effectively.  					AI-generated summary 				 Recently, test-time scaling Large Language Models (LLMs) have demonstrated exceptional reasoning capabili...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 8. CoMemo addresses visual information neglect and spatial awareness in multimodal processing by using a dual-path architecture and a novel positional encoding mechanism.  					AI-generated summary 				 Recent advancements in Large Vision-Language Models built upon Large Language Models have establishe...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 9. SwarmAgentic is a framework for automated agentic system generation that optimize agent functionality and collaboration through language-driven exploration, outperforming existing baselines in unconstrained tasks.  					AI-generated summary 				 The rapid progress of Large Language Models has advanc...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 10. MoTE, a scalable and memory-efficient method, improves Mixture-of-Experts models using low-precision ternary experts, enhancing performance and reducing memory footprint for deployment on edge devices.  					AI-generated summary 				 Large multimodal Mixture-of-Experts (MoEs) effectively scale the m...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 11. A new benchmark called OS-Harm measures the safety of computer use agents interacting with GUIs, evaluating their susceptibility to misuse, prompt injection attacks, and misbehavior across various safety violations and applications.  					AI-generated summary 				 Computer use agents are LLM-based a...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 12. An agent-guided framework generates photorealistic 3D scenes for VR by synthesizing textures onto lightweight geometric proxies, enabling real-time rendering and superior visual quality.  					AI-generated summary 				 Automatic creation of 3D scenes for immersive VR presence has been a significant ...
[19.06.2025 12:23] ********************************************************************************
[19.06.2025 12:23] Abstract 13. FedNano is a federated learning framework that centralizes large language models on servers and uses NanoEdge modules for client-specific adaptation, addressing scalability and privacy issues.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) excel in tasks like multimodal rea...
[19.06.2025 12:23] Read previous papers.
[19.06.2025 12:23] Generating reviews via LLM API.
[19.06.2025 12:23] Using data from previous issue: {"categories": ["#synthetic", "#dataset", "#games", "#data", "#video"], "emoji": "🌎", "ru": {"title": "Sekai: глобальный датасет для обучения ИИ исследовать мир", "desc": "Представлен новый набор данных Sekai для обучения моделей генерации видео с целью исследования мира. Он содержит более 5000 часо
[19.06.2025 12:23] Querying the API.
[19.06.2025 12:23] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ProtoReasoning enhances large reasoning models through prototypical representations, leading to improved cross-domain generalization in logical reasoning, planning, and other tasks.  					AI-generated summary 				 Recent advances in Large Reasoning Models (LRMs) trained with Long Chain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain generalization capabilities. However, the underlying mechanisms supporting such transfer remain poorly understood. We hypothesize that cross-domain generalization arises from shared abstract reasoning prototypes -- fundamental reasoning patterns that capture the essence of problems across domains. These prototypes minimize the nuances of the representation, revealing that seemingly diverse tasks are grounded in shared reasoning structures.Based on this hypothesis, we propose ProtoReasoning, a framework that enhances the reasoning ability of LLMs by leveraging scalable and verifiable prototypical representations (Prolog for logical reasoning, PDDL for planning).ProtoReasoning features: (1) an automated prototype construction pipeline that transforms problems into corresponding prototype representations; (2) a comprehensive verification system providing reliable feedback through Prolog/PDDL interpreters; (3) the scalability to synthesize problems arbitrarily within prototype space while ensuring correctness. Extensive experiments show that ProtoReasoning achieves 4.7% improvement over baseline models on logical reasoning (Enigmata-Eval), 6.3% improvement on planning tasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics (AIME24). Significantly, our ablation studies confirm that learning in prototype space also demonstrates enhanced generalization to structurally similar problems compared to training solely on natural language representations, validating our hypothesis that reasoning prototypes serve as the foundation for generalizable reasoning in large language models.
[19.06.2025 12:23] Response: {
  "desc": "Статья представляет ProtoReasoning - фреймворк для улучшения способностей больших языковых моделей к рассуждениям путем использования прототипических представлений. Авторы предполагают, что кросс-доменная генерализация возникает из общих абстрактных прототипов рассуждений. ProtoReasoning включает автоматизированный конвейер для построения прототипов, систему верификации и возможность масштабирования. Эксперименты показывают значительное улучшение производительности модели в задачах логического рассуждения, планирования и общих рассуждений.",

  "emoji": "🧠",

  "title": "Прототипы рассуждений как ключ к обобщению в больших языковых моделях"
}
[19.06.2025 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ProtoReasoning enhances large reasoning models through prototypical representations, leading to improved cross-domain generalization in logical reasoning, planning, and other tasks.  					AI-generated summary 				 Recent advances in Large Reasoning Models (LRMs) trained with Long Chain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain generalization capabilities. However, the underlying mechanisms supporting such transfer remain poorly understood. We hypothesize that cross-domain generalization arises from shared abstract reasoning prototypes -- fundamental reasoning patterns that capture the essence of problems across domains. These prototypes minimize the nuances of the representation, revealing that seemingly diverse tasks are grounded in shared reasoning structures.Based on this hypothesis, we propose ProtoReasoning, a framework that enhances the reasoning ability of LLMs by leveraging scalable and verifiable prototypical representations (Prolog for logical reasoning, PDDL for planning).ProtoReasoning features: (1) an automated prototype construction pipeline that transforms problems into corresponding prototype representations; (2) a comprehensive verification system providing reliable feedback through Prolog/PDDL interpreters; (3) the scalability to synthesize problems arbitrarily within prototype space while ensuring correctness. Extensive experiments show that ProtoReasoning achieves 4.7% improvement over baseline models on logical reasoning (Enigmata-Eval), 6.3% improvement on planning tasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics (AIME24). Significantly, our ablation studies confirm that learning in prototype space also demonstrates enhanced generalization to structurally similar problems compared to training solely on natural language representations, validating our hypothesis that reasoning prototypes serve as the foundation for generalizable reasoning in large language models."

[19.06.2025 12:23] Response: ```python
['DATASET', 'TRAINING', 'ARCHITECTURE']
```
[19.06.2025 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ProtoReasoning enhances large reasoning models through prototypical representations, leading to improved cross-domain generalization in logical reasoning, planning, and other tasks.  					AI-generated summary 				 Recent advances in Large Reasoning Models (LRMs) trained with Long Chain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain generalization capabilities. However, the underlying mechanisms supporting such transfer remain poorly understood. We hypothesize that cross-domain generalization arises from shared abstract reasoning prototypes -- fundamental reasoning patterns that capture the essence of problems across domains. These prototypes minimize the nuances of the representation, revealing that seemingly diverse tasks are grounded in shared reasoning structures.Based on this hypothesis, we propose ProtoReasoning, a framework that enhances the reasoning ability of LLMs by leveraging scalable and verifiable prototypical representations (Prolog for logical reasoning, PDDL for planning).ProtoReasoning features: (1) an automated prototype construction pipeline that transforms problems into corresponding prototype representations; (2) a comprehensive verification system providing reliable feedback through Prolog/PDDL interpreters; (3) the scalability to synthesize problems arbitrarily within prototype space while ensuring correctness. Extensive experiments show that ProtoReasoning achieves 4.7% improvement over baseline models on logical reasoning (Enigmata-Eval), 6.3% improvement on planning tasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics (AIME24). Significantly, our ablation studies confirm that learning in prototype space also demonstrates enhanced generalization to structurally similar problems compared to training solely on natural language representations, validating our hypothesis that reasoning prototypes serve as the foundation for generalizable reasoning in large language models."

[19.06.2025 12:23] Response: ```python
['REASONING', 'TRANSFER_LEARNING']
```
[19.06.2025 12:23] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ProtoReasoning is a framework designed to improve the reasoning capabilities of large language models (LLMs) by utilizing prototypical representations. It posits that shared abstract reasoning patterns, or prototypes, enable better generalization across different domains by simplifying complex tasks into fundamental structures. The framework includes an automated pipeline for creating these prototypes, a verification system for ensuring accuracy, and the ability to generate a wide range of problems within the prototype space. Experimental results show that ProtoReasoning significantly enhances performance in logical reasoning, planning, and general reasoning tasks compared to traditional methods.","title":"Unlocking Generalization with Prototypical Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ProtoReasoning is a framework designed to improve the reasoning capabilities of large language models (LLMs) by utilizing prototypical representations. It posits that shared abstract reasoning patterns, or prototypes, enable better generalization across different domains by simplifying complex tasks into fundamental structures. The framework includes an automated pipeline for creating these prototypes, a verification system for ensuring accuracy, and the ability to generate a wide range of problems within the prototype space. Experimental results show that ProtoReasoning significantly enhances performance in logical reasoning, planning, and general reasoning tasks compared to traditional methods.', title='Unlocking Generalization with Prototypical Reasoning'))
[19.06.2025 12:23] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ProtoReasoning 是一种增强大型推理模型的框架，通过原型表示来提高跨领域的推理能力。该框架假设跨领域的泛化能力源于共享的抽象推理原型，这些原型捕捉了不同领域问题的本质。ProtoReasoning 包含一个自动化的原型构建管道，将问题转化为相应的原型表示，并提供可靠的反馈系统。实验结果表明，ProtoReasoning 在逻辑推理、规划任务和一般推理上均有显著提升，验证了推理原型在大型语言模型中的重要性。","title":"原型推理：提升推理模型的跨领域能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ProtoReasoning 是一种增强大型推理模型的框架，通过原型表示来提高跨领域的推理能力。该框架假设跨领域的泛化能力源于共享的抽象推理原型，这些原型捕捉了不同领域问题的本质。ProtoReasoning 包含一个自动化的原型构建管道，将问题转化为相应的原型表示，并提供可靠的反馈系统。实验结果表明，ProtoReasoning 在逻辑推理、规划任务和一般推理上均有显著提升，验证了推理原型在大型语言模型中的重要性。', title='原型推理：提升推理模型的跨领域能力'))
[19.06.2025 12:23] Using data from previous issue: {"categories": ["#transfer_learning", "#optimization", "#inference", "#training", "#multimodal", "#dataset", "#architecture"], "emoji": "🔬", "ru": {"title": "GenRecal: Универсальная дистилляция для эффективных визуально-языковых моделей", "desc": "GenRecal - это новая система дистилляции для визуаль
[19.06.2025 12:23] Querying the API.
[19.06.2025 12:23] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The combined DiCoW and DiariZen ASR system demonstrates strong performance in multilingual scenarios, with DiCoW preserving its multilingual capabilities and DiariZen improving through fine-tuning.  					AI-generated summary 				 We present a two-speaker automatic speech recognition (ASR) system that combines DiCoW -- a diarization-conditioned variant of Whisper -- with DiariZen, a diarization pipeline built on top of Pyannote. We first evaluate both systems in out-of-domain (OOD) multilingual scenarios without any fine-tuning. In this scenario, DiariZen consistently outperforms the baseline Pyannote diarization model, demonstrating strong generalization. Despite being fine-tuned on English-only data for target-speaker ASR, DiCoW retains solid multilingual performance, indicating that encoder modifications preserve Whisper's multilingual capabilities. We then fine-tune both DiCoW and DiariZen on the MLC-SLM challenge data. The fine-tuned DiariZen continues to outperform the fine-tuned Pyannote baseline, while DiCoW sees further gains from domain adaptation. Our final system achieves a micro-average tcpWER/CER of 16.75% and ranks second in Task 2 of the MLC-SLM challenge. Lastly, we identify several labeling inconsistencies in the training data -- such as missing speech segments and incorrect silence annotations -- which can hinder diarization fine-tuning. We propose simple mitigation strategies to address these issues and improve system robustness.
[19.06.2025 12:23] Response: {
  "desc": "Статья представляет двухдикторную систему автоматического распознавания речи (ASR), объединяющую DiCoW и DiariZen. DiCoW - это вариант модели Whisper, обусловленный диаризацией, а DiariZen - конвейер диаризации на основе Pyannote. Система демонстрирует высокую производительность в многоязычных сценариях, причем DiCoW сохраняет свои многоязычные возможности, а DiariZen улучшается благодаря тонкой настройке. Авторы также выявили несколько несоответствий в маркировке обучающих данных и предложили стратегии для повышения надежности системы.",
  "emoji": "🗣️",
  "title": "Объединение DiCoW и DiariZen: мощная многоязычная система ASR"
}
[19.06.2025 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The combined DiCoW and DiariZen ASR system demonstrates strong performance in multilingual scenarios, with DiCoW preserving its multilingual capabilities and DiariZen improving through fine-tuning.  					AI-generated summary 				 We present a two-speaker automatic speech recognition (ASR) system that combines DiCoW -- a diarization-conditioned variant of Whisper -- with DiariZen, a diarization pipeline built on top of Pyannote. We first evaluate both systems in out-of-domain (OOD) multilingual scenarios without any fine-tuning. In this scenario, DiariZen consistently outperforms the baseline Pyannote diarization model, demonstrating strong generalization. Despite being fine-tuned on English-only data for target-speaker ASR, DiCoW retains solid multilingual performance, indicating that encoder modifications preserve Whisper's multilingual capabilities. We then fine-tune both DiCoW and DiariZen on the MLC-SLM challenge data. The fine-tuned DiariZen continues to outperform the fine-tuned Pyannote baseline, while DiCoW sees further gains from domain adaptation. Our final system achieves a micro-average tcpWER/CER of 16.75% and ranks second in Task 2 of the MLC-SLM challenge. Lastly, we identify several labeling inconsistencies in the training data -- such as missing speech segments and incorrect silence annotations -- which can hinder diarization fine-tuning. We propose simple mitigation strategies to address these issues and improve system robustness."

[19.06.2025 12:23] Response: ```python
['AUDIO', 'MULTILINGUAL', 'TRAINING', 'DATA']
```
[19.06.2025 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The combined DiCoW and DiariZen ASR system demonstrates strong performance in multilingual scenarios, with DiCoW preserving its multilingual capabilities and DiariZen improving through fine-tuning.  					AI-generated summary 				 We present a two-speaker automatic speech recognition (ASR) system that combines DiCoW -- a diarization-conditioned variant of Whisper -- with DiariZen, a diarization pipeline built on top of Pyannote. We first evaluate both systems in out-of-domain (OOD) multilingual scenarios without any fine-tuning. In this scenario, DiariZen consistently outperforms the baseline Pyannote diarization model, demonstrating strong generalization. Despite being fine-tuned on English-only data for target-speaker ASR, DiCoW retains solid multilingual performance, indicating that encoder modifications preserve Whisper's multilingual capabilities. We then fine-tune both DiCoW and DiariZen on the MLC-SLM challenge data. The fine-tuned DiariZen continues to outperform the fine-tuned Pyannote baseline, while DiCoW sees further gains from domain adaptation. Our final system achieves a micro-average tcpWER/CER of 16.75% and ranks second in Task 2 of the MLC-SLM challenge. Lastly, we identify several labeling inconsistencies in the training data -- such as missing speech segments and incorrect silence annotations -- which can hinder diarization fine-tuning. We propose simple mitigation strategies to address these issues and improve system robustness."

[19.06.2025 12:23] Response: ```python
[]
```
[19.06.2025 12:23] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a novel automatic speech recognition (ASR) system that integrates two components: DiCoW, which is a diarization-conditioned version of Whisper, and DiariZen, a diarization pipeline based on Pyannote. The system is evaluated in multilingual scenarios, showing that DiariZen outperforms the baseline Pyannote model without fine-tuning, indicating its strong generalization capabilities. DiCoW maintains its multilingual performance even after being fine-tuned on English-only data, demonstrating the effectiveness of its encoder modifications. The final system achieves a competitive error rate and addresses labeling inconsistencies in training data to enhance robustness and performance.","title":"Enhancing Multilingual ASR with DiCoW and DiariZen"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a novel automatic speech recognition (ASR) system that integrates two components: DiCoW, which is a diarization-conditioned version of Whisper, and DiariZen, a diarization pipeline based on Pyannote. The system is evaluated in multilingual scenarios, showing that DiariZen outperforms the baseline Pyannote model without fine-tuning, indicating its strong generalization capabilities. DiCoW maintains its multilingual performance even after being fine-tuned on English-only data, demonstrating the effectiveness of its encoder modifications. The final system achieves a competitive error rate and addresses labeling inconsistencies in training data to enhance robustness and performance.', title='Enhancing Multilingual ASR with DiCoW and DiariZen'))
[19.06.2025 12:24] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种结合DiCoW和DiariZen的双说话者自动语音识别（ASR）系统，展示了其在多语言场景中的强大性能。DiCoW是Whisper的一个基于说话者分离的变体，而DiariZen则是基于Pyannote构建的说话者分离管道。实验表明，在没有任何微调的情况下，DiariZen在多语言场景中表现优于基线模型Pyannote，显示出良好的泛化能力。经过微调后，DiariZen和DiCoW的性能进一步提升，最终系统在MLC-SLM挑战赛中取得了16.75%的微平均tcpWER/CER，排名第二。","title":"多语言ASR系统的强大结合"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种结合DiCoW和DiariZen的双说话者自动语音识别（ASR）系统，展示了其在多语言场景中的强大性能。DiCoW是Whisper的一个基于说话者分离的变体，而DiariZen则是基于Pyannote构建的说话者分离管道。实验表明，在没有任何微调的情况下，DiariZen在多语言场景中表现优于基线模型Pyannote，显示出良好的泛化能力。经过微调后，DiariZen和DiCoW的性能进一步提升，最终系统在MLC-SLM挑战赛中取得了16.75%的微平均tcpWER/CER，排名第二。', title='多语言ASR系统的强大结合'))
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#3d", "#benchmark", "#open_source", "#agents", "#multimodal", "#agi", "#reasoning"], "emoji": "🤖", "ru": {"title": "Объединение физического и цифрового миров в ИИ-агентах нового поколения", "desc": "Статья представляет новую парадигму искусственного интеллекта - Embodied Web Agents,
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#long_context", "#alignment", "#rlhf", "#benchmark", "#optimization", "#open_source", "#dataset"], "emoji": "📝", "ru": {"title": "PrefBERT: Улучшение генерации длинных текстов с помощью семантической оценки", "desc": "PrefBERT - это модель оценки, разработанная для улучшения генерац
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#rag", "#science", "#benchmark", "#open_source"], "emoji": "🧪", "ru": {"title": "SciVer: проверка научных утверждений мультимодальными ИИ-моделями", "desc": "SciVer - это новый бенчмарк для оценки способности мультимодальных фундаментальных моделей вериф
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#optimization", "#rl", "#reasoning", "#training"], "emoji": "🚀", "ru": {"title": "T-PPO: Ускоряем обучение LLM в 2,5 раза", "desc": "T-PPO - это новое расширение алгоритма PPO, которое повышает эффективность обучения больших языковых моделей (LLM). Оно оптимизирует обновление полити
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#multimodal", "#reasoning", "#architecture"], "emoji": "🧠", "ru": {"title": "CoMemo: Улучшение визуального восприятия в мультимодальных моделях", "desc": "CoMemo - это новая архитектура для мультимодальной обработки, решающая проблемы пренебрежения виз
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#optimization", "#agents", "#benchmark", "#games", "#agi", "#open_source", "#alignment"], "emoji": "🐝", "ru": {"title": "Автономная эволюция многоагентных систем", "desc": "SwarmAgentic - это фреймворк для полностью автоматизированной генерации агентных систем. Он оптимизирует функц
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#inference", "#training"], "emoji": "🧠", "ru": {"title": "MoTE: Эффективные Mixture-of-Experts модели для устройств с ограниченной памятью", "desc": "Статья представляет MoTE - метод для улучшения моделей Mixture-of-Experts с использованием тернарны
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#security", "#ethics", "#agents", "#benchmark"], "emoji": "🖥️", "ru": {"title": "OS-Harm: новый стандарт безопасности ИИ-агентов в компьютерных интерфейсах", "desc": "Новый бенчмарк OS-Harm оценивает безопасность агентов, взаимодействующих с графическим интерфейсом компьютера. Он из
[19.06.2025 12:24] Querying the API.
[19.06.2025 12:24] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

An agent-guided framework generates photorealistic 3D scenes for VR by synthesizing textures onto lightweight geometric proxies, enabling real-time rendering and superior visual quality.  					AI-generated summary 				 Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery. This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based modeling agents enhanced with semantic grid-based analysis for improved spatial reasoning and accurate asset placement. ImmerseGen further enriches scenes with dynamic effects and ambient audio to support multisensory immersion. Experiments on scene generation and live VR showcases demonstrate that ImmerseGen achieves superior photorealism, spatial coherence and rendering efficiency compared to prior methods. Project webpage: https://immersegen.github.io.
[19.06.2025 12:24] Response: {
  "desc": "ImmerseGen - это новая система для создания фотореалистичных 3D-сцен в виртуальной реальности. Она использует упрощенные геометрические прокси и синтезирует на них текстуры RGBA, что позволяет добиться высокого визуального качества при компактном представлении. Система включает агентов на основе больших языковых моделей для автоматизации создания сцен по текстовым запросам. ImmerseGen также добавляет динамические эффекты и звук для повышения погружения.",
  "emoji": "🕶️",
  "title": "Фотореализм в VR без сложной геометрии"
}
[19.06.2025 12:24] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"An agent-guided framework generates photorealistic 3D scenes for VR by synthesizing textures onto lightweight geometric proxies, enabling real-time rendering and superior visual quality.  					AI-generated summary 				 Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery. This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based modeling agents enhanced with semantic grid-based analysis for improved spatial reasoning and accurate asset placement. ImmerseGen further enriches scenes with dynamic effects and ambient audio to support multisensory immersion. Experiments on scene generation and live VR showcases demonstrate that ImmerseGen achieves superior photorealism, spatial coherence and rendering efficiency compared to prior methods. Project webpage: https://immersegen.github.io."

[19.06.2025 12:24] Response: ```python
["3D", "AGENTS", "MULTIMODAL", "VIDEO"]
```
[19.06.2025 12:24] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"An agent-guided framework generates photorealistic 3D scenes for VR by synthesizing textures onto lightweight geometric proxies, enabling real-time rendering and superior visual quality.  					AI-generated summary 				 Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery. This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based modeling agents enhanced with semantic grid-based analysis for improved spatial reasoning and accurate asset placement. ImmerseGen further enriches scenes with dynamic effects and ambient audio to support multisensory immersion. Experiments on scene generation and live VR showcases demonstrate that ImmerseGen achieves superior photorealism, spatial coherence and rendering efficiency compared to prior methods. Project webpage: https://immersegen.github.io."

[19.06.2025 12:24] Response: ```python
["GAMES", "SYNTHETIC"]
```
[19.06.2025 12:24] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents ImmerseGen, a new framework for creating realistic 3D scenes for virtual reality (VR) using lightweight geometric proxies. Instead of relying on complex high-poly models, ImmerseGen synthesizes photorealistic textures directly onto these proxies, allowing for real-time rendering without sacrificing visual quality. The framework utilizes agent-guided generative models to produce coherent textures that enhance the immersive experience. Additionally, it incorporates dynamic effects and audio to create a multisensory environment, demonstrating improved efficiency and realism compared to traditional methods.","title":"Revolutionizing VR with Lightweight 3D Scene Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents ImmerseGen, a new framework for creating realistic 3D scenes for virtual reality (VR) using lightweight geometric proxies. Instead of relying on complex high-poly models, ImmerseGen synthesizes photorealistic textures directly onto these proxies, allowing for real-time rendering without sacrificing visual quality. The framework utilizes agent-guided generative models to produce coherent textures that enhance the immersive experience. Additionally, it incorporates dynamic effects and audio to create a multisensory environment, demonstrating improved efficiency and realism compared to traditional methods.', title='Revolutionizing VR with Lightweight 3D Scene Generation'))
[19.06.2025 12:24] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为ImmerseGen的框架，用于生成逼真的3D场景，以增强虚拟现实体验。该框架通过将轻量几何代理与合成的RGBA纹理结合，简化了建模过程，并实现了实时渲染。ImmerseGen利用代理引导生成模型，确保纹理与场景的无缝融合，从而提高视觉质量。实验结果表明，ImmerseGen在光照真实感、空间一致性和渲染效率方面优于现有方法。","title":"轻量级几何代理，实时生成逼真3D场景"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为ImmerseGen的框架，用于生成逼真的3D场景，以增强虚拟现实体验。该框架通过将轻量几何代理与合成的RGBA纹理结合，简化了建模过程，并实现了实时渲染。ImmerseGen利用代理引导生成模型，确保纹理与场景的无缝融合，从而提高视觉质量。实验结果表明，ImmerseGen在光照真实感、空间一致性和渲染效率方面优于现有方法。', title='轻量级几何代理，实时生成逼真3D场景'))
[19.06.2025 12:24] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#agents", "#scalability", "#privacy", "#training", "#federated_learning"], "emoji": "🔬", "ru": {"title": "Эффективное федеративное обучение мультимодальных ИИ-систем", "desc": "FedNano - это новая система федеративного обучения для мультимодальных больших 
[19.06.2025 12:24] Renaming data file.
[19.06.2025 12:24] Renaming previous data. hf_papers.json to ./d/2025-06-19.json
[19.06.2025 12:24] Saving new data file.
[19.06.2025 12:24] Generating page.
[19.06.2025 12:24] Renaming previous page.
[19.06.2025 12:24] Renaming previous data. index.html to ./d/2025-06-19.html
[19.06.2025 12:24] Writing result.
[19.06.2025 12:24] Renaming log file.
[19.06.2025 12:24] Renaming previous data. log.txt to ./logs/2025-06-19_last_log.txt
