[19.06.2025 06:18] Read previous papers.
[19.06.2025 06:18] Generating top page (month).
[19.06.2025 06:18] Writing top page (month).
[19.06.2025 07:12] Read previous papers.
[19.06.2025 07:12] Get feed.
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15675
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15681
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15677
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15068
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15569
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06279
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15050
[19.06.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14435
[19.06.2025 07:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[19.06.2025 07:12] No deleted papers detected.
[19.06.2025 07:12] Downloading and parsing papers (pdf, html). Total: 8.
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.15675.
[19.06.2025 07:12] Failed to download and parse paper https://huggingface.co/papers/2506.15675: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.15681.
[19.06.2025 07:12] Extra JSON file exists (./assets/json/2506.15681.json), skip PDF parsing.
[19.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.15681.json), skip HTML parsing.
[19.06.2025 07:12] Success.
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.15677.
[19.06.2025 07:12] Extra JSON file exists (./assets/json/2506.15677.json), skip PDF parsing.
[19.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.15677.json), skip HTML parsing.
[19.06.2025 07:12] Success.
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.15068.
[19.06.2025 07:12] Extra JSON file exists (./assets/json/2506.15068.json), skip PDF parsing.
[19.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.15068.json), skip HTML parsing.
[19.06.2025 07:12] Success.
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.15569.
[19.06.2025 07:12] Extra JSON file exists (./assets/json/2506.15569.json), skip PDF parsing.
[19.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.15569.json), skip HTML parsing.
[19.06.2025 07:12] Success.
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.06279.
[19.06.2025 07:12] Extra JSON file exists (./assets/json/2506.06279.json), skip PDF parsing.
[19.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.06279.json), skip HTML parsing.
[19.06.2025 07:12] Success.
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.15050.
[19.06.2025 07:12] Failed to download and parse paper https://huggingface.co/papers/2506.15050: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[19.06.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2506.14435.
[19.06.2025 07:12] Extra JSON file exists (./assets/json/2506.14435.json), skip PDF parsing.
[19.06.2025 07:12] Paper image links file exists (./assets/img_data/2506.14435.json), skip HTML parsing.
[19.06.2025 07:12] Success.
[19.06.2025 07:12] Enriching papers with extra data.
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 0. Sekai, a worldwide video dataset with comprehensive annotations, is introduced to support world exploration applications, enhancing video generation models.  					AI-generated summary 				 Video generation techniques have made remarkable progress, promising to be the foundation of interactive world ...
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 1. GenRecal, a novel distillation framework, improves performance of vision-language models by aligning feature representations across different architectures.  					AI-generated summary 				 Recent advancements in vision-language models (VLMs) have leveraged large language models (LLMs) to achieve per...
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 2. Embodied Web Agents integrate physical interaction and web-scale reasoning to assess cross-domain intelligence in a novel benchmark environment.  					AI-generated summary 				 AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge o...
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 3. PrefBERT, a scoring model, improves open-ended long-form generation by providing better semantic reward feedback than traditional metrics.  					AI-generated summary 				 Evaluating open-ended long-form generation is challenging because it is hard to define what clearly separates good from bad outpu...
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 4. A benchmark named SciVer evaluates multimodal foundation models' claim verification capabilities within scientific contexts, revealing performance gaps and limitations in current models.  					AI-generated summary 				 We introduce SciVer, the first benchmark specifically designed to evaluate the ab...
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 5. CoMemo addresses visual information neglect and spatial awareness in multimodal processing by using a dual-path architecture and a novel positional encoding mechanism.  					AI-generated summary 				 Recent advancements in Large Vision-Language Models built upon Large Language Models have establishe...
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 6. T-PPO, an extension of PPO, improves training efficiency for Large Language Models by optimizing policy updates and utilizing hardware resources more effectively.  					AI-generated summary 				 Recently, test-time scaling Large Language Models (LLMs) have demonstrated exceptional reasoning capabili...
[19.06.2025 07:12] ********************************************************************************
[19.06.2025 07:12] Abstract 7. MoTE, a scalable and memory-efficient method, improves Mixture-of-Experts models using low-precision ternary experts, enhancing performance and reducing memory footprint for deployment on edge devices.  					AI-generated summary 				 Large multimodal Mixture-of-Experts (MoEs) effectively scale the m...
[19.06.2025 07:12] Read previous papers.
[19.06.2025 07:12] Generating reviews via LLM API.
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#synthetic", "#dataset", "#games", "#data", "#video"], "emoji": "üåé", "ru": {"title": "Sekai: –≥–ª–æ–±–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ò–ò –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –º–∏—Ä", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö Sekai –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å —Ü–µ–ª—å—é –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –º–∏—Ä–∞. –û–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ 5000 —á–∞—Å–æ
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#transfer_learning", "#optimization", "#inference", "#training", "#multimodal", "#dataset", "#architecture"], "emoji": "üî¨", "ru": {"title": "GenRecal: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "GenRecal - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª—å
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#3d", "#benchmark", "#open_source", "#agents", "#multimodal", "#agi", "#reasoning"], "emoji": "ü§ñ", "ru": {"title": "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –∏ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –º–∏—Ä–æ–≤ –≤ –ò–ò-–∞–≥–µ–Ω—Ç–∞—Ö –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ - Embodied Web Agents,
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#long_context", "#alignment", "#rlhf", "#benchmark", "#optimization", "#open_source", "#dataset"], "emoji": "üìù", "ru": {"title": "PrefBERT: –£–ª—É—á—à–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏", "desc": "PrefBERT - —ç—Ç–æ –º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∫–∏, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#rag", "#science", "#benchmark", "#open_source"], "emoji": "üß™", "ru": {"title": "SciVer: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—É—á–Ω—ã—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –ò–ò-–º–æ–¥–µ–ª—è–º–∏", "desc": "SciVer - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–µ—Ä–∏—Ñ
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#multimodal", "#reasoning", "#architecture"], "emoji": "üß†", "ru": {"title": "CoMemo: –£–ª—É—á—à–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "CoMemo - —ç—Ç–æ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏, —Ä–µ—à–∞—é—â–∞—è –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–µ–Ω–µ–±—Ä–µ–∂–µ–Ω–∏—è –≤–∏–∑
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#rl", "#reasoning", "#training"], "emoji": "üöÄ", "ru": {"title": "T-PPO: –£—Å–∫–æ—Ä—è–µ–º –æ–±—É—á–µ–Ω–∏–µ LLM –≤ 2,5 —Ä–∞–∑–∞", "desc": "T-PPO - —ç—Ç–æ –Ω–æ–≤–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ PPO, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–≤—ã—à–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –û–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏
[19.06.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#inference", "#training"], "emoji": "üß†", "ru": {"title": "MoTE: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ Mixture-of-Experts –º–æ–¥–µ–ª–∏ –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MoTE - –º–µ—Ç–æ–¥ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π Mixture-of-Experts —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ—Ä–Ω–∞—Ä–Ω—ã
[19.06.2025 07:12] Renaming data file.
[19.06.2025 07:12] Renaming previous data. hf_papers.json to ./d/2025-06-19.json
[19.06.2025 07:12] Saving new data file.
[19.06.2025 07:12] Generating page.
[19.06.2025 07:12] Renaming previous page.
[19.06.2025 07:12] Renaming previous data. index.html to ./d/2025-06-19.html
[19.06.2025 07:12] Writing result.
[19.06.2025 07:12] Renaming log file.
[19.06.2025 07:12] Renaming previous data. log.txt to ./logs/2025-06-19_last_log.txt
