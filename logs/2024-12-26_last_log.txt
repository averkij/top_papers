[26.12.2024 08:13] Read previous papers.
[26.12.2024 08:13] Generating top page (month).
[26.12.2024 08:13] Writing top page (month).
[26.12.2024 09:10] Read previous papers.
[26.12.2024 09:10] Get feed.
[26.12.2024 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18547
[26.12.2024 09:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.12.2024 09:10] No deleted papers detected.
[26.12.2024 09:10] Downloading and parsing papers (pdf, html). Total: 1.
[26.12.2024 09:10] Downloading and parsing paper https://huggingface.co/papers/2412.18547.
[26.12.2024 09:10] Extra JSON file exists (./assets/json/2412.18547.json), skip PDF parsing.
[26.12.2024 09:10] Paper image links file exists (./assets/img_data/2412.18547.json), skip HTML parsing.
[26.12.2024 09:10] Success.
[26.12.2024 09:10] Enriching papers with extra data.
[26.12.2024 09:10] ********************************************************************************
[26.12.2024 09:10] Abstract 0. Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs. We f...
[26.12.2024 09:10] Read previous papers.
[26.12.2024 09:10] Generating reviews via LLM API.
[26.12.2024 09:10] Using data from previous issue: {"categories": ["#reasoning", "#training", "#inference", "#optimization"], "emoji": "ğŸ’¡", "ru": {"title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ˜Ğ˜: Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¼Ñ‹ÑĞ»ĞµĞ¹, Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM), Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµ
[26.12.2024 09:10] Trying to get texts in Chinese.
[26.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs. We find that the reasoning process of current LLMs is unnecessarily lengthy and it can be compressed by including a reasonable token budget in the prompt, but the choice of token budget plays a crucial role in the actual compression effectiveness. We then propose a token-budget-aware LLM reasoning framework, which dynamically estimates token budgets for different problems based on reasoning complexity and uses the estimated token budgets to guide the reasoning process. Experiments show that our method effectively reduces token costs in CoT reasoning with only a slight performance reduction, offering a practical solution to balance efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.
[26.12.2024 09:10] Mistral response. {"id": "2641eae6bbde4c15bcb9846d43fe5c18", "object": "chat.completion", "created": 1735204226, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002\u867d\u7136Chain-of-Thought\uff08CoT\uff09\u63a8\u7406\u65b9\u6cd5\u901a\u8fc7\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6765\u63d0\u9ad8LLM\u6027\u80fd\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u4ee4\u724c\u4f7f\u7528\u7684\u5f00\u9500\uff0c\u5bfc\u81f4\u6210\u672c\u589e\u52a0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524dLLMs\u7684\u63a8\u7406\u8fc7\u7a0b\u8fc7\u4e8e\u5197\u957f\uff0c\u53ef\u4ee5\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u5305\u542b\u5408\u7406\u7684\u4ee4\u724c\u9884\u7b97\u6765\u538b\u7f29\uff0c\u4f46\u4ee4\u724c\u9884\u7b97\u7684\u9009\u62e9\u5bf9\u5b9e\u9645\u538b\u7f29\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee4\u724c\u9884\u7b97\u611f\u77e5\u7684LLM\u63a8\u7406\u6846\u67b6\uff0c\u6839\u636e\u63a8\u7406\u590d\u6742\u6027\u52a8\u6001\u4f30\u7b97\u4e0d\u540c\u95ee\u9898\u7684\u4ee4\u724c\u9884\u7b97\uff0c\u5e76\u4f7f\u7528\u4f30\u7b97\u7684\u4ee4\u724c\u9884\u7b97\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728CoT\u63a8\u7406\u4e2d\u6709\u6548\u5730\u51cf\u5c11\u4e86\u4ee4\u724c\u6210\u672c\uff0c\u4ec5\u7565\u5fae\u964d\u4f4e\u4e86\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728LLM\u63a8\u7406\u4e2d\u5e73\u8861\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002\u4ee3\u7801\uff1ahttps://github.com/GeniusHTX/TALE\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 232, "total_tokens": 524, "completion_tokens": 292}}
[26.12.2024 09:10] Response: è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ¨ç†çš„é‡è¦æ€§ã€‚è™½ç„¶Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†æ–¹æ³•é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºä¸­é—´æ­¥éª¤æ¥æé«˜LLMæ€§èƒ½ï¼Œä½†ä¹Ÿå¢åŠ äº†ä»¤ç‰Œä½¿ç”¨çš„å¼€é”€ï¼Œå¯¼è‡´æˆæœ¬å¢åŠ ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰LLMsçš„æ¨ç†è¿‡ç¨‹è¿‡äºå†—é•¿ï¼Œå¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­åŒ…å«åˆç†çš„ä»¤ç‰Œé¢„ç®—æ¥å‹ç¼©ï¼Œä½†ä»¤ç‰Œé¢„ç®—çš„é€‰æ‹©å¯¹å®é™…å‹ç¼©æ•ˆæœè‡³å…³é‡è¦ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä»¤ç‰Œé¢„ç®—æ„ŸçŸ¥çš„LLMæ¨ç†æ¡†æ¶ï¼Œæ ¹æ®æ¨ç†å¤æ‚æ€§åŠ¨æ€ä¼°ç®—ä¸åŒé—®é¢˜çš„ä»¤ç‰Œé¢„ç®—ï¼Œå¹¶ä½¿ç”¨ä¼°ç®—çš„ä»¤ç‰Œé¢„ç®—æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨CoTæ¨ç†ä¸­æœ‰æ•ˆåœ°å‡å°‘äº†ä»¤ç‰Œæˆæœ¬ï¼Œä»…ç•¥å¾®é™ä½äº†æ€§èƒ½ï¼Œæä¾›äº†ä¸€ç§åœ¨LLMæ¨ç†ä¸­å¹³è¡¡æ•ˆç‡å’Œå‡†ç¡®æ€§çš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚ä»£ç ï¼šhttps://github.com/GeniusHTX/TALEã€‚
[26.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ¨ç†çš„é‡è¦æ€§ã€‚è™½ç„¶Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†æ–¹æ³•é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºä¸­é—´æ­¥éª¤æ¥æé«˜LLMæ€§èƒ½ï¼Œä½†ä¹Ÿå¢åŠ äº†ä»¤ç‰Œä½¿ç”¨çš„å¼€é”€ï¼Œå¯¼è‡´æˆæœ¬å¢åŠ ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰LLMsçš„æ¨ç†è¿‡ç¨‹è¿‡äºå†—é•¿ï¼Œå¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­åŒ…å«åˆç†çš„ä»¤ç‰Œé¢„ç®—æ¥å‹ç¼©ï¼Œä½†ä»¤ç‰Œé¢„ç®—çš„é€‰æ‹©å¯¹å®é™…å‹ç¼©æ•ˆæœè‡³å…³é‡è¦ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä»¤ç‰Œé¢„ç®—æ„ŸçŸ¥çš„LLMæ¨ç†æ¡†æ¶ï¼Œæ ¹æ®æ¨ç†å¤æ‚æ€§åŠ¨æ€ä¼°ç®—ä¸åŒé—®é¢˜çš„ä»¤ç‰Œé¢„ç®—ï¼Œå¹¶ä½¿ç”¨ä¼°ç®—çš„ä»¤ç‰Œé¢„ç®—æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨CoTæ¨ç†ä¸­æœ‰æ•ˆåœ°å‡å°‘äº†ä»¤ç‰Œæˆæœ¬ï¼Œä»…ç•¥å¾®é™ä½äº†æ€§èƒ½ï¼Œæä¾›äº†ä¸€ç§åœ¨LLMæ¨ç†ä¸­å¹³è¡¡æ•ˆç‡å’Œå‡†ç¡®æ€§çš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚ä»£ç ï¼šhttps://github.com/GeniusHTX/TALEã€‚
[26.12.2024 09:10] Mistral response. {"id": "7c09b8a8c78d4b4baa5dfbe8a25df3c5", "object": "chat.completion", "created": 1735204235, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002\u867d\u7136Chain-of-Thought\uff08CoT\uff09\u63a8\u7406\u65b9\u6cd5\u901a\u8fc7\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6765\u63d0\u9ad8LLM\u6027\u80fd\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u4ee4\u724c\u4f7f\u7528\u7684\u5f00\u9500\uff0c\u5bfc\u81f4\u6210\u672c\u589e\u52a0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524dLLMs\u7684\u63a8\u7406\u8fc7\u7a0b\u8fc7\u4e8e\u5197\u957f\uff0c\u53ef\u4ee5\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u5305\u542b\u5408\u7406\u7684\u4ee4\u724c\u9884\u7b97\u6765\u538b\u7f29\uff0c\u4f46\u4ee4\u724c\u9884\u7b97\u7684\u9009\u62e9\u5bf9\u5b9e\u9645\u538b\u7f29\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee4\u724c\u9884\u7b97\u611f\u77e5\u7684LLM\u63a8\u7406\u6846\u67b6\uff0c\u6839\u636e\u63a8\u7406\u590d\u6742\u6027\u52a8\u6001\u4f30\u7b97\u4e0d\u540c\u95ee\u9898\u7684\u4ee4\u724c\u9884\u7b97\uff0c\u5e76\u4f7f\u7528\u4f30\u7b97\u7684\u4ee4\u724c\u9884\u7b97\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728CoT\u63a8\u7406\u4e2d\u6709\u6548\u5730\u51cf\u5c11\u4e86\u4ee4\u724c\u6210\u672c\uff0c\u4ec5\u7565\u5fae\u964d\u4f4e\u4e86\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728LLM\u63a8\u7406\u4e2d\u5e73\u8861\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002\u4ee3\u7801\uff1ahttps://github.com/GeniusHTX/TALE\u3002\n\nzh\u00e8 pi\u0101n w\u00e9n zh\u0101ng t\u01ceo l\u00f9n le d\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00edng (LLMs) zh\u014dng tu\u012b l\u01d0 de zh\u00f2ng y\u00e0o x\u00ecng. su\u012b r\u00e1n Chain-of-Thought (CoT) tu\u012b l\u01d0 f\u0101ng f\u01ce t\u014dng gu\u00f2 ji\u0101ng w\u00e8n t\u00ed f\u0113n ji\u011b w\u00e9i zh\u014dng ji\u0101n b\u00f9 zh\u00f2u l\u00e1i t\u00ed g\u0101o LLM x\u00ecng n\u00e9ng, d\u00e0n y\u011b z\u0113ng ji\u0101 le l\u00ecng p\u00e1i sh\u01d0 y\u00f2ng de k\u0101i xi\u01ceo, d\u01ceo zh\u00ec ch\u00e9ng b\u011bn z\u0113ng ji\u0101. y\u00e1n ji\u016b f\u0101 xi\u00e0n, d\u0101ng qi\u00e1n LLMs de tu\u012b l\u01d0 gu\u00f2 ch\u00e9ng gu\u00f2 y\u00fa r\u01d2ng ch\u00e1ng, k\u011b y\u01d0 t\u014dng gu\u00f2 z\u00e0i t\u00ed sh\u00ec zh\u014dng b\u0101o h\u00e1n h\u00e9 l\u01d0 de l\u00ecng p\u00e1i y\u00f9 su\u00e0n l\u00e1i y\u0101 su\u014d, d\u00e0n l\u00ecng p\u00e1i y\u00f9 su\u00e0n de xu\u01cen z\u00e9 du\u00ec sh\u00ed j\u00ec y\u0101 su\u014d xi\u00e0o gu\u01d2 zh\u00ec gu\u0101n zh\u00f2ng y\u00e0o. zu\u00f2 zh\u011b t\u00ed ch\u016b le y\u012b g\u00e8 l\u00ecng p\u00e1i y\u00f9 su\u00e0n g\u01cen zh\u012b de LLM tu\u012b l\u01d0 ku\u00e0ng ji\u00e0, g\u0113n j\u00f9 tu\u012b l\u01d0 f\u00fa z\u00e0 x\u00ecng d\u00f2ng t\u00e0i g\u016b s\u01d4an b\u00f9 t\u00f3ng w\u00e8n t\u00ed de l\u00ecng p\u00e1i y\u00f9 su\u00e0n, b\u00ecng sh\u01d0 y\u00f2ng g\u016b s\u01d4an de l\u00ecng p\u00e1i y\u00f9 su\u00e0n zh\u01d0 d\u01ceo tu\u012b l\u01d0 gu\u00f2 ch\u00e9ng. sh\u00ed y\u00e0n bi\u01ceo m\u00edng, zh\u00e8 zh\u01d2ng f\u0101ng f\u01ce z\u00e0i CoT tu\u012b l\u01d0 zh\u014dng y\u01d2u xi\u00e0o de ji\u01cen sh\u01ceo le l\u00ecng p\u00e1i ch\u00e9ng b\u011bn, j\u01d0n l\u00fc\u00e8 w\u0113i j\u012bng le x\u00ecng n\u00e9ng, t\u00ed g\u014dng le y\u012b zh\u01d2ng z\u00e0i LLM tu\u012b l\u01d0 zh\u014dng p\u00edng h\u00e9ng xi\u00e0o y\u00ec h\u00e9 zh\u01d4n qu\u00e8 x\u00ecng de sh\u00ed y\u00f2ng ji\u011b ju\u00e9 f\u0101ng \u00e0n. d\u00e0i m\u01ce: https://github.com/GeniusHTX/TALE."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 307, "total_tokens": 1220, "completion_tokens": 913}}
[26.12.2024 09:10] Response: è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ¨ç†çš„é‡è¦æ€§ã€‚è™½ç„¶Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†æ–¹æ³•é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºä¸­é—´æ­¥éª¤æ¥æé«˜LLMæ€§èƒ½ï¼Œä½†ä¹Ÿå¢åŠ äº†ä»¤ç‰Œä½¿ç”¨çš„å¼€é”€ï¼Œå¯¼è‡´æˆæœ¬å¢åŠ ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰LLMsçš„æ¨ç†è¿‡ç¨‹è¿‡äºå†—é•¿ï¼Œå¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­åŒ…å«åˆç†çš„ä»¤ç‰Œé¢„ç®—æ¥å‹ç¼©ï¼Œä½†ä»¤ç‰Œé¢„ç®—çš„é€‰æ‹©å¯¹å®é™…å‹ç¼©æ•ˆæœè‡³å…³é‡è¦ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä»¤ç‰Œé¢„ç®—æ„ŸçŸ¥çš„LLMæ¨ç†æ¡†æ¶ï¼Œæ ¹æ®æ¨ç†å¤æ‚æ€§åŠ¨æ€ä¼°ç®—ä¸åŒé—®é¢˜çš„ä»¤ç‰Œé¢„ç®—ï¼Œå¹¶ä½¿ç”¨ä¼°ç®—çš„ä»¤ç‰Œé¢„ç®—æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨CoTæ¨ç†ä¸­æœ‰æ•ˆåœ°å‡å°‘äº†ä»¤ç‰Œæˆæœ¬ï¼Œä»…ç•¥å¾®é™ä½äº†æ€§èƒ½ï¼Œæä¾›äº†ä¸€ç§åœ¨LLMæ¨ç†ä¸­å¹³è¡¡æ•ˆç‡å’Œå‡†ç¡®æ€§çš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚ä»£ç ï¼šhttps://github.com/GeniusHTX/TALEã€‚

zhÃ¨ piÄn wÃ©n zhÄng tÇo lÃ¹n le dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng (LLMs) zhÅng tuÄ« lÇ de zhÃ²ng yÃ o xÃ¬ng. suÄ« rÃ¡n Chain-of-Thought (CoT) tuÄ« lÇ fÄng fÇ tÅng guÃ² jiÄng wÃ¨n tÃ­ fÄ“n jiÄ› wÃ©i zhÅng jiÄn bÃ¹ zhÃ²u lÃ¡i tÃ­ gÄo LLM xÃ¬ng nÃ©ng, dÃ n yÄ› zÄ“ng jiÄ le lÃ¬ng pÃ¡i shÇ yÃ²ng de kÄi xiÇo, dÇo zhÃ¬ chÃ©ng bÄ›n zÄ“ng jiÄ. yÃ¡n jiÅ« fÄ xiÃ n, dÄng qiÃ¡n LLMs de tuÄ« lÇ guÃ² chÃ©ng guÃ² yÃº rÇ’ng chÃ¡ng, kÄ› yÇ tÅng guÃ² zÃ i tÃ­ shÃ¬ zhÅng bÄo hÃ¡n hÃ© lÇ de lÃ¬ng pÃ¡i yÃ¹ suÃ n lÃ¡i yÄ suÅ, dÃ n lÃ¬ng pÃ¡i yÃ¹ suÃ n de xuÇn zÃ© duÃ¬ shÃ­ jÃ¬ yÄ suÅ xiÃ o guÇ’ zhÃ¬ guÄn zhÃ²ng yÃ o. zuÃ² zhÄ› tÃ­ chÅ« le yÄ« gÃ¨ lÃ¬ng pÃ¡i yÃ¹ suÃ n gÇn zhÄ« de LLM tuÄ« lÇ kuÃ ng jiÃ , gÄ“n jÃ¹ tuÄ« lÇ fÃº zÃ  xÃ¬ng dÃ²ng tÃ i gÅ« sÇ”an bÃ¹ tÃ³ng wÃ¨n tÃ­ de lÃ¬ng pÃ¡i yÃ¹ suÃ n, bÃ¬ng shÇ yÃ²ng gÅ« sÇ”an de lÃ¬ng pÃ¡i yÃ¹ suÃ n zhÇ dÇo tuÄ« lÇ guÃ² chÃ©ng. shÃ­ yÃ n biÇo mÃ­ng, zhÃ¨ zhÇ’ng fÄng fÇ zÃ i CoT tuÄ« lÇ zhÅng yÇ’u xiÃ o de jiÇn shÇo le lÃ¬ng pÃ¡i chÃ©ng bÄ›n, jÇn lÃ¼Ã¨ wÄ“i jÄ«ng le xÃ¬ng nÃ©ng, tÃ­ gÅng le yÄ« zhÇ’ng zÃ i LLM tuÄ« lÇ zhÅng pÃ­ng hÃ©ng xiÃ o yÃ¬ hÃ© zhÇ”n quÃ¨ xÃ¬ng de shÃ­ yÃ²ng jiÄ› juÃ© fÄng Ã n. dÃ i mÇ: https://github.com/GeniusHTX/TALE.
[26.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ¨ç†çš„é‡è¦æ€§ã€‚è™½ç„¶Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†æ–¹æ³•é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºä¸­é—´æ­¥éª¤æ¥æé«˜LLMæ€§èƒ½ï¼Œä½†ä¹Ÿå¢åŠ äº†ä»¤ç‰Œä½¿ç”¨çš„å¼€é”€ï¼Œå¯¼è‡´æˆæœ¬å¢åŠ ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰LLMsçš„æ¨ç†è¿‡ç¨‹è¿‡äºå†—é•¿ï¼Œå¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­åŒ…å«åˆç†çš„ä»¤ç‰Œé¢„ç®—æ¥å‹ç¼©ï¼Œä½†ä»¤ç‰Œé¢„ç®—çš„é€‰æ‹©å¯¹å®é™…å‹ç¼©æ•ˆæœè‡³å…³é‡è¦ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä»¤ç‰Œé¢„ç®—æ„ŸçŸ¥çš„LLMæ¨ç†æ¡†æ¶ï¼Œæ ¹æ®æ¨ç†å¤æ‚æ€§åŠ¨æ€ä¼°ç®—ä¸åŒé—®é¢˜çš„ä»¤ç‰Œé¢„ç®—ï¼Œå¹¶ä½¿ç”¨ä¼°ç®—çš„ä»¤ç‰Œé¢„ç®—æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨CoTæ¨ç†ä¸­æœ‰æ•ˆåœ°å‡å°‘äº†ä»¤ç‰Œæˆæœ¬ï¼Œä»…ç•¥å¾®é™ä½äº†æ€§èƒ½ï¼Œæä¾›äº†ä¸€ç§åœ¨LLMæ¨ç†ä¸­å¹³è¡¡æ•ˆç‡å’Œå‡†ç¡®æ€§çš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚ä»£ç ï¼šhttps://github.com/GeniusHTX/TALEã€‚
[26.12.2024 09:11] Mistral response. {"id": "f18a1e2f812d469885dad8a925dd1e9a", "object": "chat.completion", "created": 1735204256, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[{'word': '\u8ba8\u8bba', 'pinyin': 't\u01ceo l\u00f9n', 'trans': 'discuss'}, {'word': '\u5927\u8bed\u8a00\u6a21\u578b', 'pinyin': 'd\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00edng', 'trans': 'large language model'}, {'word': '\u63a8\u7406', 'pinyin': 'tu\u012b l\u01d0', 'trans': 'reasoning'}, {'word': '\u91cd\u8981\u6027', 'pinyin': 'zh\u00f2ng y\u00e0o x\u00ecng', 'trans': 'importance'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chain-of-Thought', 'trans': 'Chain-of-Thought'}, {'word': '\u63d0\u9ad8', 'pinyin': 't\u00ed g\u0101o', 'trans': 'improve'}, {'word': '\u4ee4\u724c', 'pinyin': 'l\u00ecng p\u00e1i', 'trans': 'token'}, {'word': '\u4f7f\u7528', 'pinyin': 'sh\u01d0 y\u00f2ng', 'trans': 'use'}, {'word': '\u5f00\u9500', 'pinyin': 'k\u0101i xi\u0101o', 'trans': 'cost'}, {'word': '\u5bfc\u81f4', 'pinyin': 'd\u01ceo zh\u00ec', 'trans': 'lead to'}, {'word': '\u6210\u672c', 'pinyin': 'ch\u00e9ng b\u011bn', 'trans': 'cost'}, {'word': '\u589e\u52a0', 'pinyin': 'z\u0113ng ji\u0101', 'trans': 'increase'}, {'word': '\u7814\u7a76', 'pinyin': 'y\u00e1n ji\u016b', 'trans': 'research'}, {'word': '\u53d1\u73b0', 'pinyin': 'f\u0101 xi\u00e0n', 'trans': 'discover'}, {'word': '\u5f53\u524d', 'pinyin': 'd\u0101ng qi\u00e1n', 'trans': 'current'}, {'word': '\u8fc7\u7a0b', 'pinyin': 'gu\u00f2 ch\u00e9ng', 'trans': 'process'}, {'word': '\u5197\u957f', 'pinyin': 'r\u01d2ng ch\u00e1ng', 'trans': 'tedious'}, {'word': '\u538b\u7f29', 'pinyin': 'y\u0101 su\u014d', 'trans': 'compress'}, {'word': '\u63d0\u793a', 'pinyin': 't\u00ed sh\u00ec', 'trans': 'prompt'}, {'word': '\u5305\u542b', 'pinyin': 'b\u0101o h\u00e1n', 'trans': 'include'}, {'word': '\u5408\u7406', 'pinyin': 'h\u00e9 l\u01d0', 'trans': 'reasonable'}, {'word': '\u9884\u7b97', 'pinyin': 'y\u00f9 su\u00e0n', 'trans': 'budget'}, {'word': '\u81f3\u5173\u91cd\u8981', 'pinyin': 'zh\u00ec gu\u0101n zh\u00f2ng y\u00e0o', 'trans': 'crucial'}, {'word': '\u63d0\u51fa', 'pinyin': 't\u00ed ch\u016b', 'trans': 'propose'}, {'word': '\u611f\u77e5', 'pinyin': 'g\u01cen zh\u012b', 'trans': 'perceive'}, {'word': '\u6846\u67b6', 'pinyin': 'ku\u00e0ng ji\u00e0', 'trans': 'framework'}, {'word': '\u6839\u636e', 'pinyin': 'g\u0113n j\u00f9', 'trans': 'based on'}, {'word': '\u590d\u6742\u6027', 'pinyin': 'f\u00f9 z\u00e1 x\u00ecng', 'trans': 'complexity'}, {'word': '\u52a8\u6001', 'pinyin': 'd\u00f2ng t\u00e0i', 'trans': 'dynamic'}, {'word': '\u4f30\u7b97', 'pinyin': 'g\u016b su\u00e0n', 'trans': 'estimate'}, {'word': '\u6307\u5bfc', 'pinyin': 'zh\u01d0 d\u01ceo', 'trans': 'guide'}, {'word': '\u5b9e\u9a8c', 'pinyin': 'sh\u00ed y\u00e0n', 'trans': 'experiment'}, {'word': '\u8868\u660e', 'pinyin': 'bi\u01ceo m\u00edng', 'trans': 'indicate'}, {'word': '\u65b9\u6cd5', 'pinyin': 'f\u0101ng f\u01ce', 'trans': 'method'}, {'word': '\u6709\u6548', 'pinyin': 'y\u01d2u xi\u00e0o', 'trans': 'effective'}, {'word': '\u51cf\u5c11', 'pinyin': 'ji\u01cen sh\u01ceo', 'trans': 'reduce'}, {'word': '\u7565\u5fae', 'pinyin': 'l\u00fc\u00e8 w\u0113i', 'trans': 'slightly'}, {'word': '\u964d\u4f4e', 'pinyin': 'ji\u00e0ng d\u012b', 'trans': 'lower'}, {'word': '\u6027\u80fd', 'pinyin': 'x\u00ecng n\u00e9ng', 'trans': 'performance'}, {'word': '\u63d0\u4f9b', 'pinyin': 't\u00ed g\u014dng', 'trans': 'provide'}, {'word': '\u5e73\u8861', 'pinyin': 'p\u00edng h\u00e9ng', 'trans': 'balance'}, {'word': '\u6548\u7387', 'pinyin': 'xi\u00e0o l\u01dc', 'trans': 'efficiency'}, {'word': '\u51c6\u786e\u6027', 'pinyin': 'zh\u01d4n qu\u00e8 x\u00ecng', 'trans': 'accuracy'}, {'word': '\u89e3\u51b3\u65b9\u6848', 'pinyin': 'ji\u011b ju\u00e9 f\u0101ng \u00e0n', 'trans': 'solution'}, {'word': '\u5b9e\u7528', 'pinyin': 'sh\u00ed y\u00f2ng', 'trans': 'practical'}, {'word': '\u4ee3\u7801', 'pinyin': 'd\u00e0i m\u01ce', 'trans': 'code'}]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 339, "total_tokens": 1589, "completion_tokens": 1250}}
[26.12.2024 09:11] Response: [{'word': 'è®¨è®º', 'pinyin': 'tÇo lÃ¹n', 'trans': 'discuss'}, {'word': 'å¤§è¯­è¨€æ¨¡å‹', 'pinyin': 'dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'large language model'}, {'word': 'æ¨ç†', 'pinyin': 'tuÄ« lÇ', 'trans': 'reasoning'}, {'word': 'é‡è¦æ€§', 'pinyin': 'zhÃ²ng yÃ o xÃ¬ng', 'trans': 'importance'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chain-of-Thought', 'trans': 'Chain-of-Thought'}, {'word': 'æé«˜', 'pinyin': 'tÃ­ gÄo', 'trans': 'improve'}, {'word': 'ä»¤ç‰Œ', 'pinyin': 'lÃ¬ng pÃ¡i', 'trans': 'token'}, {'word': 'ä½¿ç”¨', 'pinyin': 'shÇ yÃ²ng', 'trans': 'use'}, {'word': 'å¼€é”€', 'pinyin': 'kÄi xiÄo', 'trans': 'cost'}, {'word': 'å¯¼è‡´', 'pinyin': 'dÇo zhÃ¬', 'trans': 'lead to'}, {'word': 'æˆæœ¬', 'pinyin': 'chÃ©ng bÄ›n', 'trans': 'cost'}, {'word': 'å¢åŠ ', 'pinyin': 'zÄ“ng jiÄ', 'trans': 'increase'}, {'word': 'ç ”ç©¶', 'pinyin': 'yÃ¡n jiÅ«', 'trans': 'research'}, {'word': 'å‘ç°', 'pinyin': 'fÄ xiÃ n', 'trans': 'discover'}, {'word': 'å½“å‰', 'pinyin': 'dÄng qiÃ¡n', 'trans': 'current'}, {'word': 'è¿‡ç¨‹', 'pinyin': 'guÃ² chÃ©ng', 'trans': 'process'}, {'word': 'å†—é•¿', 'pinyin': 'rÇ’ng chÃ¡ng', 'trans': 'tedious'}, {'word': 'å‹ç¼©', 'pinyin': 'yÄ suÅ', 'trans': 'compress'}, {'word': 'æç¤º', 'pinyin': 'tÃ­ shÃ¬', 'trans': 'prompt'}, {'word': 'åŒ…å«', 'pinyin': 'bÄo hÃ¡n', 'trans': 'include'}, {'word': 'åˆç†', 'pinyin': 'hÃ© lÇ', 'trans': 'reasonable'}, {'word': 'é¢„ç®—', 'pinyin': 'yÃ¹ suÃ n', 'trans': 'budget'}, {'word': 'è‡³å…³é‡è¦', 'pinyin': 'zhÃ¬ guÄn zhÃ²ng yÃ o', 'trans': 'crucial'}, {'word': 'æå‡º', 'pinyin': 'tÃ­ chÅ«', 'trans': 'propose'}, {'word': 'æ„ŸçŸ¥', 'pinyin': 'gÇn zhÄ«', 'trans': 'perceive'}, {'word': 'æ¡†æ¶', 'pinyin': 'kuÃ ng jiÃ ', 'trans': 'framework'}, {'word': 'æ ¹æ®', 'pinyin': 'gÄ“n jÃ¹', 'trans': 'based on'}, {'word': 'å¤æ‚æ€§', 'pinyin': 'fÃ¹ zÃ¡ xÃ¬ng', 'trans': 'complexity'}, {'word': 'åŠ¨æ€', 'pinyin': 'dÃ²ng tÃ i', 'trans': 'dynamic'}, {'word': 'ä¼°ç®—', 'pinyin': 'gÅ« suÃ n', 'trans': 'estimate'}, {'word': 'æŒ‡å¯¼', 'pinyin': 'zhÇ dÇo', 'trans': 'guide'}, {'word': 'å®éªŒ', 'pinyin': 'shÃ­ yÃ n', 'trans': 'experiment'}, {'word': 'è¡¨æ˜', 'pinyin': 'biÇo mÃ­ng', 'trans': 'indicate'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'}, {'word': 'æœ‰æ•ˆ', 'pinyin': 'yÇ’u xiÃ o', 'trans': 'effective'}, {'word': 'å‡å°‘', 'pinyin': 'jiÇn shÇo', 'trans': 'reduce'}, {'word': 'ç•¥å¾®', 'pinyin': 'lÃ¼Ã¨ wÄ“i', 'trans': 'slightly'}, {'word': 'é™ä½', 'pinyin': 'jiÃ ng dÄ«', 'trans': 'lower'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'}, {'word': 'æä¾›', 'pinyin': 'tÃ­ gÅng', 'trans': 'provide'}, {'word': 'å¹³è¡¡', 'pinyin': 'pÃ­ng hÃ©ng', 'trans': 'balance'}, {'word': 'æ•ˆç‡', 'pinyin': 'xiÃ o lÇœ', 'trans': 'efficiency'}, {'word': 'å‡†ç¡®æ€§', 'pinyin': 'zhÇ”n quÃ¨ xÃ¬ng', 'trans': 'accuracy'}, {'word': 'è§£å†³æ–¹æ¡ˆ', 'pinyin': 'jiÄ› juÃ© fÄng Ã n', 'trans': 'solution'}, {'word': 'å®ç”¨', 'pinyin': 'shÃ­ yÃ²ng', 'trans': 'practical'}, {'word': 'ä»£ç ', 'pinyin': 'dÃ i mÇ', 'trans': 'code'}]
[26.12.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ¨ç†çš„é‡è¦æ€§ã€‚è™½ç„¶Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†æ–¹æ³•é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºä¸­é—´æ­¥éª¤æ¥æé«˜LLMæ€§èƒ½ï¼Œä½†ä¹Ÿå¢åŠ äº†ä»¤ç‰Œä½¿ç”¨çš„å¼€é”€ï¼Œå¯¼è‡´æˆæœ¬å¢åŠ ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰LLMsçš„æ¨ç†è¿‡ç¨‹è¿‡äºå†—é•¿ï¼Œå¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­åŒ…å«åˆç†çš„ä»¤ç‰Œé¢„ç®—æ¥å‹ç¼©ï¼Œä½†ä»¤ç‰Œé¢„ç®—çš„é€‰æ‹©å¯¹å®é™…å‹ç¼©æ•ˆæœè‡³å…³é‡è¦ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä»¤ç‰Œé¢„ç®—æ„ŸçŸ¥çš„LLMæ¨ç†æ¡†æ¶ï¼Œæ ¹æ®æ¨ç†å¤æ‚æ€§åŠ¨æ€ä¼°ç®—ä¸åŒé—®é¢˜çš„ä»¤ç‰Œé¢„ç®—ï¼Œå¹¶ä½¿ç”¨ä¼°ç®—çš„ä»¤ç‰Œé¢„ç®—æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨CoTæ¨ç†ä¸­æœ‰æ•ˆåœ°å‡å°‘äº†ä»¤ç‰Œæˆæœ¬ï¼Œä»…ç•¥å¾®é™ä½äº†æ€§èƒ½ï¼Œæä¾›äº†ä¸€ç§åœ¨LLMæ¨ç†ä¸­å¹³è¡¡æ•ˆç‡å’Œå‡†ç¡®æ€§çš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚ä»£ç ï¼šhttps://github.com/GeniusHTX/TALEã€‚
[26.12.2024 09:11] Mistral response. {"id": "d2140ae5207d40e095f92e49306b3b16", "object": "chat.completion", "created": 1735204281, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "This article discusses the importance of reasoning in large language models (LLMs). Although the Chain-of-Thought (CoT) reasoning method improves LLM performance by breaking down problems into intermediate steps, it also increases the overhead of token usage, leading to higher costs. Research has found that the current reasoning process in LLMs is overly lengthy and can be compressed by including a reasonable token budget in the prompts. However, the choice of token budget is crucial for the actual compression effect. The authors propose a token budget-aware LLM reasoning framework that dynamically estimates the token budget for different problems based on reasoning complexity and uses the estimated token budget to guide the reasoning process. Experiments show that this method effectively reduces token costs in CoT reasoning with only a slight decrease in performance, providing a practical solution for balancing efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 305, "total_tokens": 500, "completion_tokens": 195}}
[26.12.2024 09:11] Response: This article discusses the importance of reasoning in large language models (LLMs). Although the Chain-of-Thought (CoT) reasoning method improves LLM performance by breaking down problems into intermediate steps, it also increases the overhead of token usage, leading to higher costs. Research has found that the current reasoning process in LLMs is overly lengthy and can be compressed by including a reasonable token budget in the prompts. However, the choice of token budget is crucial for the actual compression effect. The authors propose a token budget-aware LLM reasoning framework that dynamically estimates the token budget for different problems based on reasoning complexity and uses the estimated token budget to guide the reasoning process. Experiments show that this method effectively reduces token costs in CoT reasoning with only a slight decrease in performance, providing a practical solution for balancing efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.
[26.12.2024 09:11] Renaming data file.
[26.12.2024 09:11] Renaming previous data. hf_papers.json to ./d/2024-12-26.json
[26.12.2024 09:11] Saving new data file.
[26.12.2024 09:11] Generating page.
[26.12.2024 09:11] Renaming previous page.
[26.12.2024 09:11] Renaming previous data. index.html to ./d/2024-12-26.html
[26.12.2024 09:11] [Experimental] Generating Chinese page for reading.
[26.12.2024 09:11] Chinese vocab [{'word': 'è®¨è®º', 'pinyin': 'tÇo lÃ¹n', 'trans': 'discuss'}, {'word': 'å¤§è¯­è¨€æ¨¡å‹', 'pinyin': 'dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'large language model'}, {'word': 'æ¨ç†', 'pinyin': 'tuÄ« lÇ', 'trans': 'reasoning'}, {'word': 'é‡è¦æ€§', 'pinyin': 'zhÃ²ng yÃ o xÃ¬ng', 'trans': 'importance'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chain-of-Thought', 'trans': 'Chain-of-Thought'}, {'word': 'æé«˜', 'pinyin': 'tÃ­ gÄo', 'trans': 'improve'}, {'word': 'ä»¤ç‰Œ', 'pinyin': 'lÃ¬ng pÃ¡i', 'trans': 'token'}, {'word': 'ä½¿ç”¨', 'pinyin': 'shÇ yÃ²ng', 'trans': 'use'}, {'word': 'å¼€é”€', 'pinyin': 'kÄi xiÄo', 'trans': 'cost'}, {'word': 'å¯¼è‡´', 'pinyin': 'dÇo zhÃ¬', 'trans': 'lead to'}, {'word': 'æˆæœ¬', 'pinyin': 'chÃ©ng bÄ›n', 'trans': 'cost'}, {'word': 'å¢åŠ ', 'pinyin': 'zÄ“ng jiÄ', 'trans': 'increase'}, {'word': 'ç ”ç©¶', 'pinyin': 'yÃ¡n jiÅ«', 'trans': 'research'}, {'word': 'å‘ç°', 'pinyin': 'fÄ xiÃ n', 'trans': 'discover'}, {'word': 'å½“å‰', 'pinyin': 'dÄng qiÃ¡n', 'trans': 'current'}, {'word': 'è¿‡ç¨‹', 'pinyin': 'guÃ² chÃ©ng', 'trans': 'process'}, {'word': 'å†—é•¿', 'pinyin': 'rÇ’ng chÃ¡ng', 'trans': 'tedious'}, {'word': 'å‹ç¼©', 'pinyin': 'yÄ suÅ', 'trans': 'compress'}, {'word': 'æç¤º', 'pinyin': 'tÃ­ shÃ¬', 'trans': 'prompt'}, {'word': 'åŒ…å«', 'pinyin': 'bÄo hÃ¡n', 'trans': 'include'}, {'word': 'åˆç†', 'pinyin': 'hÃ© lÇ', 'trans': 'reasonable'}, {'word': 'é¢„ç®—', 'pinyin': 'yÃ¹ suÃ n', 'trans': 'budget'}, {'word': 'è‡³å…³é‡è¦', 'pinyin': 'zhÃ¬ guÄn zhÃ²ng yÃ o', 'trans': 'crucial'}, {'word': 'æå‡º', 'pinyin': 'tÃ­ chÅ«', 'trans': 'propose'}, {'word': 'æ„ŸçŸ¥', 'pinyin': 'gÇn zhÄ«', 'trans': 'perceive'}, {'word': 'æ¡†æ¶', 'pinyin': 'kuÃ ng jiÃ ', 'trans': 'framework'}, {'word': 'æ ¹æ®', 'pinyin': 'gÄ“n jÃ¹', 'trans': 'based on'}, {'word': 'å¤æ‚æ€§', 'pinyin': 'fÃ¹ zÃ¡ xÃ¬ng', 'trans': 'complexity'}, {'word': 'åŠ¨æ€', 'pinyin': 'dÃ²ng tÃ i', 'trans': 'dynamic'}, {'word': 'ä¼°ç®—', 'pinyin': 'gÅ« suÃ n', 'trans': 'estimate'}, {'word': 'æŒ‡å¯¼', 'pinyin': 'zhÇ dÇo', 'trans': 'guide'}, {'word': 'å®éªŒ', 'pinyin': 'shÃ­ yÃ n', 'trans': 'experiment'}, {'word': 'è¡¨æ˜', 'pinyin': 'biÇo mÃ­ng', 'trans': 'indicate'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'}, {'word': 'æœ‰æ•ˆ', 'pinyin': 'yÇ’u xiÃ o', 'trans': 'effective'}, {'word': 'å‡å°‘', 'pinyin': 'jiÇn shÇo', 'trans': 'reduce'}, {'word': 'ç•¥å¾®', 'pinyin': 'lÃ¼Ã¨ wÄ“i', 'trans': 'slightly'}, {'word': 'é™ä½', 'pinyin': 'jiÃ ng dÄ«', 'trans': 'lower'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'}, {'word': 'æä¾›', 'pinyin': 'tÃ­ gÅng', 'trans': 'provide'}, {'word': 'å¹³è¡¡', 'pinyin': 'pÃ­ng hÃ©ng', 'trans': 'balance'}, {'word': 'æ•ˆç‡', 'pinyin': 'xiÃ o lÇœ', 'trans': 'efficiency'}, {'word': 'å‡†ç¡®æ€§', 'pinyin': 'zhÇ”n quÃ¨ xÃ¬ng', 'trans': 'accuracy'}, {'word': 'è§£å†³æ–¹æ¡ˆ', 'pinyin': 'jiÄ› juÃ© fÄng Ã n', 'trans': 'solution'}, {'word': 'å®ç”¨', 'pinyin': 'shÃ­ yÃ²ng', 'trans': 'practical'}, {'word': 'ä»£ç ', 'pinyin': 'dÃ i mÇ', 'trans': 'code'}]
[26.12.2024 09:11] Renaming previous Chinese page.
[26.12.2024 09:11] Renaming previous data. zh.html to ./d/2024-12-25_zh_reading_task.html
[26.12.2024 09:11] Writing Chinese reading task.
[26.12.2024 09:11] Writing result.
[26.12.2024 09:11] Renaming log file.
[26.12.2024 09:11] Renaming previous data. log.txt to ./logs/2024-12-26_last_log.txt
