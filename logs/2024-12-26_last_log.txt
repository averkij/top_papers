[26.12.2024 08:13] Read previous papers.
[26.12.2024 08:13] Generating top page (month).
[26.12.2024 08:13] Writing top page (month).
[26.12.2024 09:10] Read previous papers.
[26.12.2024 09:10] Get feed.
[26.12.2024 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18547
[26.12.2024 09:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.12.2024 09:10] No deleted papers detected.
[26.12.2024 09:10] Downloading and parsing papers (pdf, html). Total: 1.
[26.12.2024 09:10] Downloading and parsing paper https://huggingface.co/papers/2412.18547.
[26.12.2024 09:10] Extra JSON file exists (./assets/json/2412.18547.json), skip PDF parsing.
[26.12.2024 09:10] Paper image links file exists (./assets/img_data/2412.18547.json), skip HTML parsing.
[26.12.2024 09:10] Success.
[26.12.2024 09:10] Enriching papers with extra data.
[26.12.2024 09:10] ********************************************************************************
[26.12.2024 09:10] Abstract 0. Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs. We f...
[26.12.2024 09:10] Read previous papers.
[26.12.2024 09:10] Generating reviews via LLM API.
[26.12.2024 09:10] Using data from previous issue: {"categories": ["#reasoning", "#training", "#inference", "#optimization"], "emoji": "💡", "ru": {"title": "Эффективные рассуждения ИИ: больше мыслей, меньше токенов", "desc": "Статья описывает новый подход к рассуждениям в больших языковых моделях (LLM), направленный на оптимизацию использования токе
[26.12.2024 09:10] Trying to get texts in Chinese.
[26.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs. We find that the reasoning process of current LLMs is unnecessarily lengthy and it can be compressed by including a reasonable token budget in the prompt, but the choice of token budget plays a crucial role in the actual compression effectiveness. We then propose a token-budget-aware LLM reasoning framework, which dynamically estimates token budgets for different problems based on reasoning complexity and uses the estimated token budgets to guide the reasoning process. Experiments show that our method effectively reduces token costs in CoT reasoning with only a slight performance reduction, offering a practical solution to balance efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.
[26.12.2024 09:10] Mistral response. {"id": "2641eae6bbde4c15bcb9846d43fe5c18", "object": "chat.completion", "created": 1735204226, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002\u867d\u7136Chain-of-Thought\uff08CoT\uff09\u63a8\u7406\u65b9\u6cd5\u901a\u8fc7\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6765\u63d0\u9ad8LLM\u6027\u80fd\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u4ee4\u724c\u4f7f\u7528\u7684\u5f00\u9500\uff0c\u5bfc\u81f4\u6210\u672c\u589e\u52a0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524dLLMs\u7684\u63a8\u7406\u8fc7\u7a0b\u8fc7\u4e8e\u5197\u957f\uff0c\u53ef\u4ee5\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u5305\u542b\u5408\u7406\u7684\u4ee4\u724c\u9884\u7b97\u6765\u538b\u7f29\uff0c\u4f46\u4ee4\u724c\u9884\u7b97\u7684\u9009\u62e9\u5bf9\u5b9e\u9645\u538b\u7f29\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee4\u724c\u9884\u7b97\u611f\u77e5\u7684LLM\u63a8\u7406\u6846\u67b6\uff0c\u6839\u636e\u63a8\u7406\u590d\u6742\u6027\u52a8\u6001\u4f30\u7b97\u4e0d\u540c\u95ee\u9898\u7684\u4ee4\u724c\u9884\u7b97\uff0c\u5e76\u4f7f\u7528\u4f30\u7b97\u7684\u4ee4\u724c\u9884\u7b97\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728CoT\u63a8\u7406\u4e2d\u6709\u6548\u5730\u51cf\u5c11\u4e86\u4ee4\u724c\u6210\u672c\uff0c\u4ec5\u7565\u5fae\u964d\u4f4e\u4e86\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728LLM\u63a8\u7406\u4e2d\u5e73\u8861\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002\u4ee3\u7801\uff1ahttps://github.com/GeniusHTX/TALE\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 232, "total_tokens": 524, "completion_tokens": 292}}
[26.12.2024 09:10] Response: 这篇文章讨论了大语言模型（LLMs）中推理的重要性。虽然Chain-of-Thought（CoT）推理方法通过将问题分解为中间步骤来提高LLM性能，但也增加了令牌使用的开销，导致成本增加。研究发现，当前LLMs的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对实际压缩效果至关重要。作者提出了一个令牌预算感知的LLM推理框架，根据推理复杂性动态估算不同问题的令牌预算，并使用估算的令牌预算指导推理过程。实验表明，这种方法在CoT推理中有效地减少了令牌成本，仅略微降低了性能，提供了一种在LLM推理中平衡效率和准确性的实用解决方案。代码：https://github.com/GeniusHTX/TALE。
[26.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

这篇文章讨论了大语言模型（LLMs）中推理的重要性。虽然Chain-of-Thought（CoT）推理方法通过将问题分解为中间步骤来提高LLM性能，但也增加了令牌使用的开销，导致成本增加。研究发现，当前LLMs的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对实际压缩效果至关重要。作者提出了一个令牌预算感知的LLM推理框架，根据推理复杂性动态估算不同问题的令牌预算，并使用估算的令牌预算指导推理过程。实验表明，这种方法在CoT推理中有效地减少了令牌成本，仅略微降低了性能，提供了一种在LLM推理中平衡效率和准确性的实用解决方案。代码：https://github.com/GeniusHTX/TALE。
[26.12.2024 09:10] Mistral response. {"id": "7c09b8a8c78d4b4baa5dfbe8a25df3c5", "object": "chat.completion", "created": 1735204235, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002\u867d\u7136Chain-of-Thought\uff08CoT\uff09\u63a8\u7406\u65b9\u6cd5\u901a\u8fc7\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6765\u63d0\u9ad8LLM\u6027\u80fd\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u4ee4\u724c\u4f7f\u7528\u7684\u5f00\u9500\uff0c\u5bfc\u81f4\u6210\u672c\u589e\u52a0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524dLLMs\u7684\u63a8\u7406\u8fc7\u7a0b\u8fc7\u4e8e\u5197\u957f\uff0c\u53ef\u4ee5\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u5305\u542b\u5408\u7406\u7684\u4ee4\u724c\u9884\u7b97\u6765\u538b\u7f29\uff0c\u4f46\u4ee4\u724c\u9884\u7b97\u7684\u9009\u62e9\u5bf9\u5b9e\u9645\u538b\u7f29\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee4\u724c\u9884\u7b97\u611f\u77e5\u7684LLM\u63a8\u7406\u6846\u67b6\uff0c\u6839\u636e\u63a8\u7406\u590d\u6742\u6027\u52a8\u6001\u4f30\u7b97\u4e0d\u540c\u95ee\u9898\u7684\u4ee4\u724c\u9884\u7b97\uff0c\u5e76\u4f7f\u7528\u4f30\u7b97\u7684\u4ee4\u724c\u9884\u7b97\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728CoT\u63a8\u7406\u4e2d\u6709\u6548\u5730\u51cf\u5c11\u4e86\u4ee4\u724c\u6210\u672c\uff0c\u4ec5\u7565\u5fae\u964d\u4f4e\u4e86\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728LLM\u63a8\u7406\u4e2d\u5e73\u8861\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002\u4ee3\u7801\uff1ahttps://github.com/GeniusHTX/TALE\u3002\n\nzh\u00e8 pi\u0101n w\u00e9n zh\u0101ng t\u01ceo l\u00f9n le d\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00edng (LLMs) zh\u014dng tu\u012b l\u01d0 de zh\u00f2ng y\u00e0o x\u00ecng. su\u012b r\u00e1n Chain-of-Thought (CoT) tu\u012b l\u01d0 f\u0101ng f\u01ce t\u014dng gu\u00f2 ji\u0101ng w\u00e8n t\u00ed f\u0113n ji\u011b w\u00e9i zh\u014dng ji\u0101n b\u00f9 zh\u00f2u l\u00e1i t\u00ed g\u0101o LLM x\u00ecng n\u00e9ng, d\u00e0n y\u011b z\u0113ng ji\u0101 le l\u00ecng p\u00e1i sh\u01d0 y\u00f2ng de k\u0101i xi\u01ceo, d\u01ceo zh\u00ec ch\u00e9ng b\u011bn z\u0113ng ji\u0101. y\u00e1n ji\u016b f\u0101 xi\u00e0n, d\u0101ng qi\u00e1n LLMs de tu\u012b l\u01d0 gu\u00f2 ch\u00e9ng gu\u00f2 y\u00fa r\u01d2ng ch\u00e1ng, k\u011b y\u01d0 t\u014dng gu\u00f2 z\u00e0i t\u00ed sh\u00ec zh\u014dng b\u0101o h\u00e1n h\u00e9 l\u01d0 de l\u00ecng p\u00e1i y\u00f9 su\u00e0n l\u00e1i y\u0101 su\u014d, d\u00e0n l\u00ecng p\u00e1i y\u00f9 su\u00e0n de xu\u01cen z\u00e9 du\u00ec sh\u00ed j\u00ec y\u0101 su\u014d xi\u00e0o gu\u01d2 zh\u00ec gu\u0101n zh\u00f2ng y\u00e0o. zu\u00f2 zh\u011b t\u00ed ch\u016b le y\u012b g\u00e8 l\u00ecng p\u00e1i y\u00f9 su\u00e0n g\u01cen zh\u012b de LLM tu\u012b l\u01d0 ku\u00e0ng ji\u00e0, g\u0113n j\u00f9 tu\u012b l\u01d0 f\u00fa z\u00e0 x\u00ecng d\u00f2ng t\u00e0i g\u016b s\u01d4an b\u00f9 t\u00f3ng w\u00e8n t\u00ed de l\u00ecng p\u00e1i y\u00f9 su\u00e0n, b\u00ecng sh\u01d0 y\u00f2ng g\u016b s\u01d4an de l\u00ecng p\u00e1i y\u00f9 su\u00e0n zh\u01d0 d\u01ceo tu\u012b l\u01d0 gu\u00f2 ch\u00e9ng. sh\u00ed y\u00e0n bi\u01ceo m\u00edng, zh\u00e8 zh\u01d2ng f\u0101ng f\u01ce z\u00e0i CoT tu\u012b l\u01d0 zh\u014dng y\u01d2u xi\u00e0o de ji\u01cen sh\u01ceo le l\u00ecng p\u00e1i ch\u00e9ng b\u011bn, j\u01d0n l\u00fc\u00e8 w\u0113i j\u012bng le x\u00ecng n\u00e9ng, t\u00ed g\u014dng le y\u012b zh\u01d2ng z\u00e0i LLM tu\u012b l\u01d0 zh\u014dng p\u00edng h\u00e9ng xi\u00e0o y\u00ec h\u00e9 zh\u01d4n qu\u00e8 x\u00ecng de sh\u00ed y\u00f2ng ji\u011b ju\u00e9 f\u0101ng \u00e0n. d\u00e0i m\u01ce: https://github.com/GeniusHTX/TALE."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 307, "total_tokens": 1220, "completion_tokens": 913}}
[26.12.2024 09:10] Response: 这篇文章讨论了大语言模型（LLMs）中推理的重要性。虽然Chain-of-Thought（CoT）推理方法通过将问题分解为中间步骤来提高LLM性能，但也增加了令牌使用的开销，导致成本增加。研究发现，当前LLMs的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对实际压缩效果至关重要。作者提出了一个令牌预算感知的LLM推理框架，根据推理复杂性动态估算不同问题的令牌预算，并使用估算的令牌预算指导推理过程。实验表明，这种方法在CoT推理中有效地减少了令牌成本，仅略微降低了性能，提供了一种在LLM推理中平衡效率和准确性的实用解决方案。代码：https://github.com/GeniusHTX/TALE。

zhè piān wén zhāng tǎo lùn le dà yǔ yán mó xíng (LLMs) zhōng tuī lǐ de zhòng yào xìng. suī rán Chain-of-Thought (CoT) tuī lǐ fāng fǎ tōng guò jiāng wèn tí fēn jiě wéi zhōng jiān bù zhòu lái tí gāo LLM xìng néng, dàn yě zēng jiā le lìng pái shǐ yòng de kāi xiǎo, dǎo zhì chéng běn zēng jiā. yán jiū fā xiàn, dāng qián LLMs de tuī lǐ guò chéng guò yú rǒng cháng, kě yǐ tōng guò zài tí shì zhōng bāo hán hé lǐ de lìng pái yù suàn lái yā suō, dàn lìng pái yù suàn de xuǎn zé duì shí jì yā suō xiào guǒ zhì guān zhòng yào. zuò zhě tí chū le yī gè lìng pái yù suàn gǎn zhī de LLM tuī lǐ kuàng jià, gēn jù tuī lǐ fú zà xìng dòng tài gū sǔan bù tóng wèn tí de lìng pái yù suàn, bìng shǐ yòng gū sǔan de lìng pái yù suàn zhǐ dǎo tuī lǐ guò chéng. shí yàn biǎo míng, zhè zhǒng fāng fǎ zài CoT tuī lǐ zhōng yǒu xiào de jiǎn shǎo le lìng pái chéng běn, jǐn lüè wēi jīng le xìng néng, tí gōng le yī zhǒng zài LLM tuī lǐ zhōng píng héng xiào yì hé zhǔn què xìng de shí yòng jiě jué fāng àn. dài mǎ: https://github.com/GeniusHTX/TALE.
[26.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

这篇文章讨论了大语言模型（LLMs）中推理的重要性。虽然Chain-of-Thought（CoT）推理方法通过将问题分解为中间步骤来提高LLM性能，但也增加了令牌使用的开销，导致成本增加。研究发现，当前LLMs的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对实际压缩效果至关重要。作者提出了一个令牌预算感知的LLM推理框架，根据推理复杂性动态估算不同问题的令牌预算，并使用估算的令牌预算指导推理过程。实验表明，这种方法在CoT推理中有效地减少了令牌成本，仅略微降低了性能，提供了一种在LLM推理中平衡效率和准确性的实用解决方案。代码：https://github.com/GeniusHTX/TALE。
[26.12.2024 09:11] Mistral response. {"id": "f18a1e2f812d469885dad8a925dd1e9a", "object": "chat.completion", "created": 1735204256, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[{'word': '\u8ba8\u8bba', 'pinyin': 't\u01ceo l\u00f9n', 'trans': 'discuss'}, {'word': '\u5927\u8bed\u8a00\u6a21\u578b', 'pinyin': 'd\u00e0 y\u01d4 y\u00e1n m\u00f3 x\u00edng', 'trans': 'large language model'}, {'word': '\u63a8\u7406', 'pinyin': 'tu\u012b l\u01d0', 'trans': 'reasoning'}, {'word': '\u91cd\u8981\u6027', 'pinyin': 'zh\u00f2ng y\u00e0o x\u00ecng', 'trans': 'importance'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chain-of-Thought', 'trans': 'Chain-of-Thought'}, {'word': '\u63d0\u9ad8', 'pinyin': 't\u00ed g\u0101o', 'trans': 'improve'}, {'word': '\u4ee4\u724c', 'pinyin': 'l\u00ecng p\u00e1i', 'trans': 'token'}, {'word': '\u4f7f\u7528', 'pinyin': 'sh\u01d0 y\u00f2ng', 'trans': 'use'}, {'word': '\u5f00\u9500', 'pinyin': 'k\u0101i xi\u0101o', 'trans': 'cost'}, {'word': '\u5bfc\u81f4', 'pinyin': 'd\u01ceo zh\u00ec', 'trans': 'lead to'}, {'word': '\u6210\u672c', 'pinyin': 'ch\u00e9ng b\u011bn', 'trans': 'cost'}, {'word': '\u589e\u52a0', 'pinyin': 'z\u0113ng ji\u0101', 'trans': 'increase'}, {'word': '\u7814\u7a76', 'pinyin': 'y\u00e1n ji\u016b', 'trans': 'research'}, {'word': '\u53d1\u73b0', 'pinyin': 'f\u0101 xi\u00e0n', 'trans': 'discover'}, {'word': '\u5f53\u524d', 'pinyin': 'd\u0101ng qi\u00e1n', 'trans': 'current'}, {'word': '\u8fc7\u7a0b', 'pinyin': 'gu\u00f2 ch\u00e9ng', 'trans': 'process'}, {'word': '\u5197\u957f', 'pinyin': 'r\u01d2ng ch\u00e1ng', 'trans': 'tedious'}, {'word': '\u538b\u7f29', 'pinyin': 'y\u0101 su\u014d', 'trans': 'compress'}, {'word': '\u63d0\u793a', 'pinyin': 't\u00ed sh\u00ec', 'trans': 'prompt'}, {'word': '\u5305\u542b', 'pinyin': 'b\u0101o h\u00e1n', 'trans': 'include'}, {'word': '\u5408\u7406', 'pinyin': 'h\u00e9 l\u01d0', 'trans': 'reasonable'}, {'word': '\u9884\u7b97', 'pinyin': 'y\u00f9 su\u00e0n', 'trans': 'budget'}, {'word': '\u81f3\u5173\u91cd\u8981', 'pinyin': 'zh\u00ec gu\u0101n zh\u00f2ng y\u00e0o', 'trans': 'crucial'}, {'word': '\u63d0\u51fa', 'pinyin': 't\u00ed ch\u016b', 'trans': 'propose'}, {'word': '\u611f\u77e5', 'pinyin': 'g\u01cen zh\u012b', 'trans': 'perceive'}, {'word': '\u6846\u67b6', 'pinyin': 'ku\u00e0ng ji\u00e0', 'trans': 'framework'}, {'word': '\u6839\u636e', 'pinyin': 'g\u0113n j\u00f9', 'trans': 'based on'}, {'word': '\u590d\u6742\u6027', 'pinyin': 'f\u00f9 z\u00e1 x\u00ecng', 'trans': 'complexity'}, {'word': '\u52a8\u6001', 'pinyin': 'd\u00f2ng t\u00e0i', 'trans': 'dynamic'}, {'word': '\u4f30\u7b97', 'pinyin': 'g\u016b su\u00e0n', 'trans': 'estimate'}, {'word': '\u6307\u5bfc', 'pinyin': 'zh\u01d0 d\u01ceo', 'trans': 'guide'}, {'word': '\u5b9e\u9a8c', 'pinyin': 'sh\u00ed y\u00e0n', 'trans': 'experiment'}, {'word': '\u8868\u660e', 'pinyin': 'bi\u01ceo m\u00edng', 'trans': 'indicate'}, {'word': '\u65b9\u6cd5', 'pinyin': 'f\u0101ng f\u01ce', 'trans': 'method'}, {'word': '\u6709\u6548', 'pinyin': 'y\u01d2u xi\u00e0o', 'trans': 'effective'}, {'word': '\u51cf\u5c11', 'pinyin': 'ji\u01cen sh\u01ceo', 'trans': 'reduce'}, {'word': '\u7565\u5fae', 'pinyin': 'l\u00fc\u00e8 w\u0113i', 'trans': 'slightly'}, {'word': '\u964d\u4f4e', 'pinyin': 'ji\u00e0ng d\u012b', 'trans': 'lower'}, {'word': '\u6027\u80fd', 'pinyin': 'x\u00ecng n\u00e9ng', 'trans': 'performance'}, {'word': '\u63d0\u4f9b', 'pinyin': 't\u00ed g\u014dng', 'trans': 'provide'}, {'word': '\u5e73\u8861', 'pinyin': 'p\u00edng h\u00e9ng', 'trans': 'balance'}, {'word': '\u6548\u7387', 'pinyin': 'xi\u00e0o l\u01dc', 'trans': 'efficiency'}, {'word': '\u51c6\u786e\u6027', 'pinyin': 'zh\u01d4n qu\u00e8 x\u00ecng', 'trans': 'accuracy'}, {'word': '\u89e3\u51b3\u65b9\u6848', 'pinyin': 'ji\u011b ju\u00e9 f\u0101ng \u00e0n', 'trans': 'solution'}, {'word': '\u5b9e\u7528', 'pinyin': 'sh\u00ed y\u00f2ng', 'trans': 'practical'}, {'word': '\u4ee3\u7801', 'pinyin': 'd\u00e0i m\u01ce', 'trans': 'code'}]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 339, "total_tokens": 1589, "completion_tokens": 1250}}
[26.12.2024 09:11] Response: [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '重要性', 'pinyin': 'zhòng yào xìng', 'trans': 'importance'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chain-of-Thought', 'trans': 'Chain-of-Thought'}, {'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'}, {'word': '令牌', 'pinyin': 'lìng pái', 'trans': 'token'}, {'word': '使用', 'pinyin': 'shǐ yòng', 'trans': 'use'}, {'word': '开销', 'pinyin': 'kāi xiāo', 'trans': 'cost'}, {'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'lead to'}, {'word': '成本', 'pinyin': 'chéng běn', 'trans': 'cost'}, {'word': '增加', 'pinyin': 'zēng jiā', 'trans': 'increase'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'discover'}, {'word': '当前', 'pinyin': 'dāng qián', 'trans': 'current'}, {'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'}, {'word': '冗长', 'pinyin': 'rǒng cháng', 'trans': 'tedious'}, {'word': '压缩', 'pinyin': 'yā suō', 'trans': 'compress'}, {'word': '提示', 'pinyin': 'tí shì', 'trans': 'prompt'}, {'word': '包含', 'pinyin': 'bāo hán', 'trans': 'include'}, {'word': '合理', 'pinyin': 'hé lǐ', 'trans': 'reasonable'}, {'word': '预算', 'pinyin': 'yù suàn', 'trans': 'budget'}, {'word': '至关重要', 'pinyin': 'zhì guān zhòng yào', 'trans': 'crucial'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '感知', 'pinyin': 'gǎn zhī', 'trans': 'perceive'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '根据', 'pinyin': 'gēn jù', 'trans': 'based on'}, {'word': '复杂性', 'pinyin': 'fù zá xìng', 'trans': 'complexity'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'}, {'word': '估算', 'pinyin': 'gū suàn', 'trans': 'estimate'}, {'word': '指导', 'pinyin': 'zhǐ dǎo', 'trans': 'guide'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '表明', 'pinyin': 'biǎo míng', 'trans': 'indicate'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '有效', 'pinyin': 'yǒu xiào', 'trans': 'effective'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '略微', 'pinyin': 'lüè wēi', 'trans': 'slightly'}, {'word': '降低', 'pinyin': 'jiàng dī', 'trans': 'lower'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '提供', 'pinyin': 'tí gōng', 'trans': 'provide'}, {'word': '平衡', 'pinyin': 'píng héng', 'trans': 'balance'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '准确性', 'pinyin': 'zhǔn què xìng', 'trans': 'accuracy'}, {'word': '解决方案', 'pinyin': 'jiě jué fāng àn', 'trans': 'solution'}, {'word': '实用', 'pinyin': 'shí yòng', 'trans': 'practical'}, {'word': '代码', 'pinyin': 'dài mǎ', 'trans': 'code'}]
[26.12.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

这篇文章讨论了大语言模型（LLMs）中推理的重要性。虽然Chain-of-Thought（CoT）推理方法通过将问题分解为中间步骤来提高LLM性能，但也增加了令牌使用的开销，导致成本增加。研究发现，当前LLMs的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对实际压缩效果至关重要。作者提出了一个令牌预算感知的LLM推理框架，根据推理复杂性动态估算不同问题的令牌预算，并使用估算的令牌预算指导推理过程。实验表明，这种方法在CoT推理中有效地减少了令牌成本，仅略微降低了性能，提供了一种在LLM推理中平衡效率和准确性的实用解决方案。代码：https://github.com/GeniusHTX/TALE。
[26.12.2024 09:11] Mistral response. {"id": "d2140ae5207d40e095f92e49306b3b16", "object": "chat.completion", "created": 1735204281, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "This article discusses the importance of reasoning in large language models (LLMs). Although the Chain-of-Thought (CoT) reasoning method improves LLM performance by breaking down problems into intermediate steps, it also increases the overhead of token usage, leading to higher costs. Research has found that the current reasoning process in LLMs is overly lengthy and can be compressed by including a reasonable token budget in the prompts. However, the choice of token budget is crucial for the actual compression effect. The authors propose a token budget-aware LLM reasoning framework that dynamically estimates the token budget for different problems based on reasoning complexity and uses the estimated token budget to guide the reasoning process. Experiments show that this method effectively reduces token costs in CoT reasoning with only a slight decrease in performance, providing a practical solution for balancing efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 305, "total_tokens": 500, "completion_tokens": 195}}
[26.12.2024 09:11] Response: This article discusses the importance of reasoning in large language models (LLMs). Although the Chain-of-Thought (CoT) reasoning method improves LLM performance by breaking down problems into intermediate steps, it also increases the overhead of token usage, leading to higher costs. Research has found that the current reasoning process in LLMs is overly lengthy and can be compressed by including a reasonable token budget in the prompts. However, the choice of token budget is crucial for the actual compression effect. The authors propose a token budget-aware LLM reasoning framework that dynamically estimates the token budget for different problems based on reasoning complexity and uses the estimated token budget to guide the reasoning process. Experiments show that this method effectively reduces token costs in CoT reasoning with only a slight decrease in performance, providing a practical solution for balancing efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.
[26.12.2024 09:11] Renaming data file.
[26.12.2024 09:11] Renaming previous data. hf_papers.json to ./d/2024-12-26.json
[26.12.2024 09:11] Saving new data file.
[26.12.2024 09:11] Generating page.
[26.12.2024 09:11] Renaming previous page.
[26.12.2024 09:11] Renaming previous data. index.html to ./d/2024-12-26.html
[26.12.2024 09:11] [Experimental] Generating Chinese page for reading.
[26.12.2024 09:11] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '重要性', 'pinyin': 'zhòng yào xìng', 'trans': 'importance'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chain-of-Thought', 'trans': 'Chain-of-Thought'}, {'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'}, {'word': '令牌', 'pinyin': 'lìng pái', 'trans': 'token'}, {'word': '使用', 'pinyin': 'shǐ yòng', 'trans': 'use'}, {'word': '开销', 'pinyin': 'kāi xiāo', 'trans': 'cost'}, {'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'lead to'}, {'word': '成本', 'pinyin': 'chéng běn', 'trans': 'cost'}, {'word': '增加', 'pinyin': 'zēng jiā', 'trans': 'increase'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'discover'}, {'word': '当前', 'pinyin': 'dāng qián', 'trans': 'current'}, {'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'}, {'word': '冗长', 'pinyin': 'rǒng cháng', 'trans': 'tedious'}, {'word': '压缩', 'pinyin': 'yā suō', 'trans': 'compress'}, {'word': '提示', 'pinyin': 'tí shì', 'trans': 'prompt'}, {'word': '包含', 'pinyin': 'bāo hán', 'trans': 'include'}, {'word': '合理', 'pinyin': 'hé lǐ', 'trans': 'reasonable'}, {'word': '预算', 'pinyin': 'yù suàn', 'trans': 'budget'}, {'word': '至关重要', 'pinyin': 'zhì guān zhòng yào', 'trans': 'crucial'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '感知', 'pinyin': 'gǎn zhī', 'trans': 'perceive'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '根据', 'pinyin': 'gēn jù', 'trans': 'based on'}, {'word': '复杂性', 'pinyin': 'fù zá xìng', 'trans': 'complexity'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'}, {'word': '估算', 'pinyin': 'gū suàn', 'trans': 'estimate'}, {'word': '指导', 'pinyin': 'zhǐ dǎo', 'trans': 'guide'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '表明', 'pinyin': 'biǎo míng', 'trans': 'indicate'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '有效', 'pinyin': 'yǒu xiào', 'trans': 'effective'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '略微', 'pinyin': 'lüè wēi', 'trans': 'slightly'}, {'word': '降低', 'pinyin': 'jiàng dī', 'trans': 'lower'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '提供', 'pinyin': 'tí gōng', 'trans': 'provide'}, {'word': '平衡', 'pinyin': 'píng héng', 'trans': 'balance'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '准确性', 'pinyin': 'zhǔn què xìng', 'trans': 'accuracy'}, {'word': '解决方案', 'pinyin': 'jiě jué fāng àn', 'trans': 'solution'}, {'word': '实用', 'pinyin': 'shí yòng', 'trans': 'practical'}, {'word': '代码', 'pinyin': 'dài mǎ', 'trans': 'code'}]
[26.12.2024 09:11] Renaming previous Chinese page.
[26.12.2024 09:11] Renaming previous data. zh.html to ./d/2024-12-25_zh_reading_task.html
[26.12.2024 09:11] Writing Chinese reading task.
[26.12.2024 09:11] Writing result.
[26.12.2024 09:11] Renaming log file.
[26.12.2024 09:11] Renaming previous data. log.txt to ./logs/2024-12-26_last_log.txt
