[15.10.2025 23:10] Read previous papers.
[15.10.2025 23:10] Generating top page (month).
[15.10.2025 23:10] Writing top page (month).
[16.10.2025 00:52] Read previous papers.
[16.10.2025 00:52] Get feed.
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12276
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09116
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12586
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11693
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12403
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12798
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12399
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12747
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12773
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11057
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12693
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12784
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12789
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12635
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11683
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11602
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01171
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12225
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12801
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12709
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11892
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11919
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11000
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12777
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09782
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08783
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12402
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12088
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11661
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11606
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09259
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08532
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12793
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12497
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12323
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12117
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11851
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11570
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11545
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11330
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09776
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09263
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09062
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12269
[16.10.2025 00:52] Extract page data from URL. URL: https://huggingface.co/papers/2510.11967
[16.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08666
[16.10.2025 00:52] Extract page data from URL. URL: https://huggingface.co/papers/2510.06727
[16.10.2025 00:52] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[16.10.2025 00:52] No deleted papers detected.
[16.10.2025 00:52] Downloading and parsing papers (pdf, html). Total: 47.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12276.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12276.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12276.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.09116.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.09116.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.09116.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12586.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12586.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12586.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11693.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11693.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11693.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12403.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12403.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12403.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12798.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12798.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12798.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12399.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12399.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12399.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12747.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12747.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12747.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12773.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12773.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12773.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11057.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11057.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11057.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12693.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12693.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12693.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12784.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12784.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12784.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12789.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12789.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12789.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12635.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12635.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12635.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11683.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11683.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11683.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11602.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11602.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11602.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.01171.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.01171.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.01171.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12225.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12225.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12225.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12801.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12801.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12801.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12709.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12709.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12709.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11892.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11892.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11892.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11919.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11919.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11919.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11000.
[16.10.2025 00:52] Downloading paper 2510.11000 from http://arxiv.org/pdf/2510.11000v1...
[16.10.2025 00:52] Failed to download and parse paper https://huggingface.co/papers/2510.11000: 'LTChar' object is not iterable
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12777.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12777.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12777.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.09782.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.09782.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.09782.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.08783.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.08783.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.08783.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12402.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12402.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12402.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12088.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12088.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12088.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11661.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11661.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11661.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11606.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11606.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11606.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.09259.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.09259.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.09259.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.08532.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.08532.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.08532.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12793.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12793.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12793.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12497.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12497.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12497.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12323.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12323.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12323.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12117.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12117.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12117.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11851.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11851.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11851.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11570.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11570.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11570.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11545.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11545.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11545.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11330.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11330.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11330.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.09776.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.09776.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.09776.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.09263.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.09263.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.09263.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.09062.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.09062.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.09062.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12269.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12269.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12269.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11967.
[16.10.2025 00:52] Downloading paper 2510.11967 from http://arxiv.org/pdf/2510.11967v1...
[16.10.2025 00:52] Extracting affiliations from text.
[16.10.2025 00:52] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 1 ] . [ 1 7 6 9 1 1 . 0 1 5 2 : r Scaling Long-Horizon LLM Agent via Context-Folding Weiwei Sun1,2,, Miao Lu1,3,, Zhan Ling1, Kang Liu1, Xuesong Yao1, Yiming Yang2, Jiecao Chen1, 1ByteDance Seed, 2Carnegie Mellon University, 3Stanford University Work done at ByteDance Seed, Corresponding authors "
[16.10.2025 00:52] Response: ```python
["ByteDance Seed", "Carnegie Mellon University", "Stanford University"]
```
[16.10.2025 00:52] Deleting PDF ./assets/pdf/2510.11967.pdf.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.08666.
[16.10.2025 00:52] Extra JSON file exists (./assets/json/2510.08666.json), skip PDF parsing.
[16.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.08666.json), skip HTML parsing.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.06727.
[16.10.2025 00:52] Downloading paper 2510.06727 from http://arxiv.org/pdf/2510.06727v1...
[16.10.2025 00:52] Extracting affiliations from text.
[16.10.2025 00:52] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 ] . [ 1 7 2 7 6 0 . 0 1 5 2 : r Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management Miao Lu1,2,,, Weiwei Sun1,3,, Weihua Du1,3,, Zhan Ling1, Xuesong Yao1, Kang Liu1, Jiecao Chen1, 1ByteDance Seed, 2Stanford University, 3Carnegie Mellon University Work done during internship at ByteDance Seed, Corresponding authors "
[16.10.2025 00:52] Response: ```python
["ByteDance Seed", "Stanford University", "Carnegie Mellon University"]
```
[16.10.2025 00:52] Deleting PDF ./assets/pdf/2510.06727.pdf.
[16.10.2025 00:52] Success.
[16.10.2025 00:52] Enriching papers with extra data.
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 0. Vision-language-action (VLA) models have recently shown strong potential in enabling robots to follow language instructions and execute precise actions. However, most VLAs are built upon vision-language models pretrained solely on 2D data, which lack accurate spatial awareness and hinder their abili...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 1. A new evaluation framework, DITING, and a reasoning-driven multi-agent evaluation framework, AgentEval, are introduced to assess the quality of web novel translations, revealing that Chinese-trained LLMs outperform larger foreign models.  					AI-generated summary 				 Large language models (LLMs) h...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 2. Pixel-space generative models are often more difficult to train and generally underperform compared to their latent-space counterparts, leaving a persistent performance and efficiency gap. In this paper, we introduce a novel two-stage training framework that closes this gap for pixel-space diffusion...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 3. Recent multimodal embedding approaches leveraging multimodal large language models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising results, yet the underlying reasons behind their superiority remain underexplored. This work argues that a crucial advantage of MLLM-based approac...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 4. Robot learning transitions from model-based to data-driven methods, leveraging reinforcement learning and behavioral cloning to develop versatile, language-conditioned models for diverse tasks and robot types.  					AI-generated summary 				 Robot learning is at an inflection point, driven by rapid ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 5. Object detection has long been dominated by traditional coordinate regression-based models, such as YOLO, DETR, and Grounding DINO. Although recent efforts have attempted to leverage MLLMs to tackle this task, they face challenges like low recall rate, duplicate predictions, coordinate misalignment,...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 6. The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed "Vibe Coding" where developers validate AI-generated implementations through outcome observation rather than lin...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 7. Diffusion models have recently advanced video restoration, but applying them to real-world video super-resolution (VSR) remains challenging due to high latency, prohibitive computation, and poor generalization to ultra-high resolutions. Our goal in this work is to make diffusion-based VSR practical ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 8. Large Language Models (LLMs) process every token through all layers of a transformer stack, causing wasted computation on simple queries and insufficient flexibility for harder ones that need deeper reasoning. Adaptive-depth methods can improve efficiency, but prior approaches rely on costly inferen...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 9. Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 10. Recent advances in embodied AI highlight the potential of vision language models (VLMs) as agents capable of perception, reasoning, and interaction in complex environments. However, top-performing systems rely on large-scale models that are costly to deploy, while smaller VLMs lack the necessary kno...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 11. Recently, remarkable progress has been made in Unified Multimodal Models (UMMs), which integrate vision-language generation and understanding capabilities within a single framework. However, a significant gap exists where a model's strong visual understanding often fails to transfer to its visual ge...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 12. Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images and text. This separation constrains diffusion models' ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 13. Large Language Models face challenges in long-horizon agentic tasks as their constrained memory is easily overwhelmed by distracting or irrelevant context. Existing working memory methods typically rely on external, heuristic mechanisms that are decoupled from the agent's core policy. In this work, ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 14. Boundary-Guided Policy Optimization (BGPO) improves reinforcement learning for diffusion large language models by efficiently approximating likelihoods with a memory-efficient lower bound, enhancing performance in tasks like math problem solving, code generation, and planning.  					AI-generated sum...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 15. Systematic analysis of attention mechanisms in Transformer models shows that token mixing is essential, while other aspects like sequence dependency and mathematical form can be relaxed or interleaved to maintain performance.  					AI-generated summary 				 The success of Transformer language models...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 16. Typicality bias in preference data causes mode collapse in LLMs, and Verbalized Sampling is introduced as a prompting strategy to enhance diversity without compromising accuracy or safety.  					AI-generated summary 				 Post-training alignment often reduces LLM diversity, leading to a phenomenon kn...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 17. Recent advances in vision-language models (VLMs) have made them highly effective at reasoning tasks. However, the principles underlying the construction of performant VL reasoning training datasets remain poorly understood. In this work, we introduce several data curation approaches and study their ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 18. Multimodal Large Language Models (MLLMs) in real-world applications require access to external knowledge sources and must remain responsive to the dynamic and ever-changing real-world information in order to address information-seeking and knowledge-intensive user queries. Existing approaches, such ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 19. Multimodal embedding models aim to yield informative unified representations that empower diverse cross-modal tasks. Despite promising developments in the evolution from CLIP-based dual-tower architectures to large vision-language models, prior works still face unavoidable challenges in real-world a...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 20. LLMs can enhance decision-making in digital environments but struggle with long-horizon simulations due to hallucination and static knowledge. R-WoM improves performance by integrating external, up-to-date knowledge.  					AI-generated summary 				 Large Language Models (LLMs) can serve as world mod...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 21. Large reasoning models (LRMs) have led to new possibilities in terms of problem-solving, through the devising of a natural language thought process prior to answering a query. While their capabilities are well known across mathematics and coding tasks, their impact on the task of machine translation...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 22. ContextGen, a Diffusion Transformer framework, enhances multi-instance image generation by integrating layout anchoring and identity consistency attention, achieving superior control and quality.  					AI-generated summary 				 Multi-instance image generation (MIG) remains a significant challenge fo...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 23. Understanding the dynamics of a physical scene involves reasoning about the diverse ways it can potentially change, especially as a result of local interactions. We present the Flow Poke Transformer (FPT), a novel framework for directly predicting the distribution of local motion, conditioned on spa...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 24. We study how large language models (LLMs) ``think'' through their representation space. We propose a novel geometric framework that models an LLM's reasoning as flows -- embedding trajectories evolving where logic goes. We disentangle logical structure from semantics by employing the same natural de...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 25. In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 26. Cautious Weight Decay (CWD) enhances optimizer performance by applying weight decay selectively, improving accuracy and loss in large-scale models without additional tuning.  					AI-generated summary 				 We introduce Cautious Weight Decay (CWD), a one-line, optimizer-agnostic modification that app...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 27. OneLife framework models complex, stochastic environments using conditionally-activated programmatic laws within a probabilistic programming framework, enabling learning from minimal, unguided interaction and outperforming baselines in state ranking and fidelity.  					AI-generated summary 				 Symb...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 28. SR-Scientist, an autonomous AI framework, leverages LLMs to generate, implement, and optimize scientific equations, outperforming baselines across multiple disciplines.  					AI-generated summary 				 Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveragi...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 29. ExpVid, a new benchmark for evaluating multimodal large language models on scientific experiment videos, highlights gaps in fine-grained perception, procedural understanding, and scientific reasoning.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) hold promise for accelerat...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 30. Self-Critique addresses data contamination in the RL post-training phase of LLMs by detecting policy collapse, outperforming existing methods with significant improvements in AUC.  					AI-generated summary 				 Data contamination poses a significant threat to the reliable evaluation of Large Langua...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 31. Kontinuous Kontext is an instruction-driven image editing model that introduces a scalar edit strength for fine-grained control over the extent of edits, using a lightweight projector network and a synthesized dataset of image-edit-instruction-strength quadruplets.  					AI-generated summary 				 In...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 32. Existing Multimodal Large Language Models (MLLMs) suffer from increased inference costs due to the additional vision tokens introduced by image inputs. In this work, we propose Visual Consistency Learning (ViCO), a novel training algorithm that enables the model to represent images of varying semant...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 33. Noise Awareness Guidance (NAG) addresses noise shift in diffusion models by aligning sampling trajectories with the pre-defined noise schedule, improving generation quality.  					AI-generated summary 				 Existing denoising generative models rely on solving discretized reverse-time SDEs or ODEs. In...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 34. RAG-Anything is a unified framework that enhances multimodal knowledge retrieval by integrating cross-modal relationships and semantic matching, outperforming existing methods on complex benchmarks.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) has emerged as a fundamental par...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 35. Chatbot providers (e.g., OpenAI) rely on tiered subscription schemes to generate revenue, offering basic models for free users, and advanced models for paying subscribers. However, a finer-grained pay-to-unlock scheme for premium features (e.g., math, coding) is thought to be more economically viabl...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 36. DR agents based on LLMs can generate detailed reports from harmful queries, highlighting alignment failures and the need for specialized safety measures.  					AI-generated summary 				 Deep Research (DR) agents built on Large Language Models (LLMs) can perform complex, multi-step research by decomp...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 37. Reasoning-based safety guardrails in Large Reasoning Models are vulnerable to subtle prompt manipulations, leading to high attack success rates across various benchmarks.  					AI-generated summary 				 Recent reasoning-based safety guardrails for Large Reasoning Models (LRMs), such as deliberative ...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 38. PART reformulates reasoning traces to preserve information while disrupting unauthorized distillation in Large Language Models.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) show that extending the length of reasoning chains significantly improves performance on com...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 39. Diffusion-Link, a diffusion-based modality-bridging module, reduces the audio-text modality gap and enhances multimodal encoder-LLM coupling, achieving state-of-the-art performance in automatic audio captioning.  					AI-generated summary 				 Contrastive audio-language pretraining yields powerful j...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 40. Theoretical analysis reveals that Transformers, particularly Linear Self-Attention models, have limitations in time series forecasting compared to classical linear models, with predictions collapsing to the mean under Chain-of-Thought inference.  					AI-generated summary 				 Time series forecastin...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 41. SynthID-Image, a deep learning system for watermarking AI-generated imagery, demonstrates state-of-the-art performance in visual quality and robustness, and is deployed across Google's services.  					AI-generated summary 				 We introduce SynthID-Image, a deep learning-based system for invisibly wa...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 42. ReFIne, a new training framework, enhances the trustworthiness of reasoning models by improving interpretability, faithfulness, and reliability through structured traces, decisive information disclosure, and confidence estimates.  					AI-generated summary 				 Recent advances in long chain-of-thoug...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 43. Tensor logic unifies neural and symbolic AI by using tensor equations, enabling scalable, learnable, and transparent AI systems.  					AI-generated summary 				 Progress in AI is hindered by the lack of a programming language with all the requisite features. Libraries like PyTorch and TensorFlow pro...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 44. Context-Folding, an end-to-end reinforcement learning framework, enables LLM agents to manage context effectively by branching into subtasks and folding them, outperforming baselines on long-horizon tasks with reduced context size.  					AI-generated summary 				 Large language model (LLM) agents ar...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 45. dInfer is an efficient and extensible framework for diffusion-based large language model inference, achieving significant speedups over existing systems without compromising output quality.  					AI-generated summary 				 Diffusion-based large language models (dLLMs) have emerged as a promising alte...
[16.10.2025 00:52] ********************************************************************************
[16.10.2025 00:52] Abstract 46. Summarization-based context management in reinforcement learning fine-tunes large language model agents for long-horizon tool use, improving success rates and scalability beyond fixed context limits.  					AI-generated summary 				 We study reinforcement learning (RL) fine-tuning of large language m...
[16.10.2025 00:52] Read previous papers.
[16.10.2025 00:52] Generating reviews via LLM API.
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#3d", "#optimization", "#training", "#agents", "#alignment"], "emoji": "🤖", "ru": {"title": "Обучение роботов пространственному мышлению без 3D сенсоров", "desc": "Статья представляет Spatial Forcing (SF) — метод для улучшения vision-language-action (VLA) моделей в робототехнике. Пр
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#machine_translation", "#open_source", "#reasoning", "#dataset", "#multilingual", "#benchmark"], "emoji": "📚", "ru": {"title": "Китайские LLM побеждают в переводе веб-романов", "desc": "Исследователи представили DITING — первую комплексную систему оценки качества перевода веб-романо
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#training", "#diffusion", "#cv", "#optimization"], "emoji": "🎯", "ru": {"title": "Двухэтапное обучение закрывает разрыв между пиксельными и латентными генеративными моделями", "desc": "Исследователи предложили новый двухэтапный подход для обучения диффузионных моделей и consistency 
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#low_resource", "#data", "#benchmark", "#multimodal", "#transfer_learning", "#training", "#alignment"], "emoji": "🔗", "ru": {"title": "Генеративное предобучение как ключ к качественным мультимодальным эмбеддингам", "desc": "Исследователи обнаружили, что превосходство мультимодальных
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#games", "#agents", "#robotics"], "emoji": "🤖", "ru": {"title": "От классики к данным: новая эра обучения роботов", "desc": "Статья представляет собой учебное руководство по современному машинному обучению для роботов. Авторы описывают переход о
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#training", "#optimization", "#rl"], "emoji": "🔍", "ru": {"title": "Rex-Omni: новый уровень в обнаружении объектов", "desc": "В статье рассматривается новая модель Rex-Omni, которая улучшает задачи обнаружения объектов, используя подходы LLM. Rex-Omni достигает
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#multimodal", "#training", "#survey", "#agi", "#agents", "#rl"], "emoji": "🎵", "ru": {"title": "Vibe Coding: когда разработчик проверяет результат, а не читает код", "desc": "Статья исследует новую парадигму разработки под названием \"Vibe Coding\", где разработчики проверяют работо
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#video", "#open_source", "#inference", "#training", "#dataset", "#diffusion"], "emoji": "⚡", "ru": {"title": "Диффузионное видео super-resolution в реальном времени", "desc": "FlashVSR — первая диффузионная модель для видео super-resolution в реальном времени, работающая со скорость
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#optimization", "#training", "#inference"], "emoji": "🧭", "ru": {"title": "Умная маршрутизация слоёв: LLM учатся пропускать ненужные вычисления", "desc": "В статье представлен Dr.LLM — метод динамической маршрутизации слоёв для больших языковых моделей
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#multimodal", "#cv"], "emoji": "🎯", "ru": {"title": "Временное выравнивание для точной генерации в диффузионных моделях", "desc": "Диффузионные модели показывают отличные результаты в генерации, но накапливают ошибки в процессе работы, осо
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#transfer_learning", "#agents", "#rl"], "emoji": "🤖", "ru": {"title": "Маленькие модели учатся действовать как большие", "desc": "Статья представляет ERA — двухэтапный фреймворк для обучения компактных vision language models действовать в 
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#training", "#optimization", "#multimodal", "#transfer_learning"], "emoji": "🔄", "ru": {"title": "Самообучение мультимодальных моделей через внутреннюю самооценку", "desc": "Исследователи обнаружили парадокс: мультимодальные модели могут хорошо понимать изображения, но плохо их гене
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#reasoning", "#training", "#transfer_learning", "#diffusion"], "emoji": "🔗", "ru": {"title": "Единый энкодер для текста и изображений в диффузионных моделях", "desc": "UniFusion — это диффузионная модель для генерации изображений, которая использует замороженну
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#long_context", "#reasoning", "#training", "#optimization", "#agents", "#rl"], "emoji": "🧠", "ru": {"title": "Память как действие: LLM учатся управлять своим контекстом", "desc": "Большие языковые модели сталкиваются с проблемой ограниченной памяти при решении длинных задач, когда к
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#games", "#rlhf", "#training", "#optimization", "#rl"], "emoji": "🎯", "ru": {"title": "Эффективное обучение диффузионных языковых моделей с помощью линейной аппроксимации", "desc": "Статья представляет метод BGPO для reinforcement learning в диффузионных LLM, которые сталкиваются с 
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#math", "#architecture", "#optimization", "#interpretability", "#training"], "emoji": "🔍", "ru": {"title": "Смешивание токенов важнее, чем точная формула attention", "desc": "Исследователи систематически изучили механизм внимания в Transformer моделях, разбирая его на составные част
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#hallucinations", "#data", "#inference", "#training", "#alignment", "#story_generation", "#synthetic"], "emoji": "🎲", "ru": {"title": "Разблокировка разнообразия LLM через вербализацию вероятностей", "desc": "Исследователи обнаружили, что режимный коллапс в языковых моделях вызван с
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#reasoning", "#dataset", "#benchmark", "#data"], "emoji": "🐝", "ru": {"title": "HoneyBee: Как правильно готовить данные для обучения визуального мышления", "desc": "Исследователи изучили принципы создания эффективных датасетов для обучения vision-language модел
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#training", "#dataset", "#agi", "#optimization", "#rag", "#benchmark"], "emoji": "🔍", "ru": {"title": "Мультимодальный поиск в интернете с обучением через подкрепление", "desc": "Статья представляет DeepMMSearch-R1 — первую мультимодальную LLM, способную
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#training", "#optimization", "#multimodal"], "emoji": "⛵", "ru": {"title": "SAIL-Embedding: Универсальная мультимодальная модель для поиска и рекомендаций", "desc": "Статья представляет SAIL-Embedding — омнимодальную модель эмбеддингов, которая решает проблемы ограниченной поддержки
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#hallucinations", "#agents", "#long_context", "#rag"], "emoji": "🔮", "ru": {"title": "Обучение AI агентов с внешними знаниями вместо галлюцинаций", "desc": "LLM могут служить моделями мира для планирования действий AI-агентов в цифровых средах, но страдают от галлюцинаций и устаревш
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#low_resource", "#reasoning", "#training", "#multilingual", "#machine_translation", "#synthetic"], "emoji": "🤔", "ru": {"title": "Размышления не помогают LLM лучше переводить", "desc": "Исследователи изучили, помогают ли \"токены размышлений\" (thinking tokens) большим reasoning мод
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#dataset", "#diffusion"], "emoji": "🎯", "ru": {"title": "Контроль расположения и идентичности объектов в генерации изображений", "desc": "Статья представляет ContextGen — новый фреймворк на основе Diffusion Transformer для генерации изображений с несколькими объектами. Систем
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#interpretability", "#open_source", "#reasoning", "#training", "#optimization", "#synthetic"], "emoji": "🔄", "ru": {"title": "Flow Poke Transformer: новая эра в предсказании движения", "desc": "В статье представлена новая модель Flow Poke Transformer (FPT), которая предсказыв
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#interpretability", "#architecture", "#math", "#reasoning"], "emoji": "🌊", "ru": {"title": "Логика как геометрический поток в пространстве представлений", "desc": "Исследователи предлагают новый геометрический подход к пониманию того, как LLM «размышляют» в своём пространстве предст
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#multimodal", "#benchmark"], "emoji": "🎨", "ru": {"title": "LLM как ранние оценщики пользовательских интерфейсов", "desc": "Исследование проверяет, могут ли мультимодальные LLM (большие языковые модели) оценивать пользовательские интерфейсы так же,
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization"], "emoji": "🎯", "ru": {"title": "Осторожное затухание весов: умный способ регуляризации нейросетей", "desc": "В статье представлен метод Cautious Weight Decay (CWD) — простая модификация оптимизаторов, которая применяет weight decay тольк
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#reasoning", "#optimization", "#games", "#agents"], "emoji": "🎮", "ru": {"title": "Обучение модели мира за одну жизнь без подсказок", "desc": "Статья представляет OneLife — фреймворк для символьного моделирования динамики сложных стохастических сред через програ
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#agents", "#rl", "#science", "#dataset", "#optimization"], "emoji": "🔬", "ru": {"title": "AI-учёный, который сам открывает научные уравнения", "desc": "В статье представлен SR-Scientist — автономный AI-фреймворк, который использует LLM для открытия научных уравнений. В отличие от су
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#science", "#benchmark", "#open_source", "#reasoning", "#multimodal"], "emoji": "🔬", "ru": {"title": "Научные эксперименты — слабое место современных AI", "desc": "Исследователи представили ExpVid — первый бенчмарк для оценки мультимодальных LLM на видео научных экспериментов
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#security", "#hallucinations", "#training", "#benchmark"], "emoji": "🔍", "ru": {"title": "Детектор загрязнения данных через коллапс политики в RL", "desc": "Исследователи представили метод Self-Critique для обнаружения загрязнения данных на этапе RL пост-тренинг
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#data", "#cv", "#optimization", "#dataset", "#synthetic", "#training"], "emoji": "🎚️", "ru": {"title": "Плавное управление силой редактирования изображений через текстовые инструкции", "desc": "Статья представляет Kontinuous Kontext — модель для редактирования изображений на основе 
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#training", "#inference", "#interpretability", "#agi", "#optimization", "#multimodal"], "emoji": "🎯", "ru": {"title": "Умное сжатие визуальных токенов по сложности изображения", "desc": "Исследователи предложили метод Visual Consistency Learning (ViCO), который позволяет mult
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#training", "#optimization", "#data"], "emoji": "🎯", "ru": {"title": "Исправление шума в диффузионных моделях для улучшения генерации", "desc": "Исследователи обнаружили проблему в диффузионных моделях: несоответствие между заранее определённым уровнем шума и фа
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#long_context", "#multimodal", "#open_source", "#reasoning", "#agi", "#benchmark", "#rag"], "emoji": "🎯", "ru": {"title": "Мультимодальный RAG для работы с любыми типами данных", "desc": "RAG-Anything — это универсальная система для улучшения Retrieval-Augmented Generation (RAG), ко
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#security", "#architecture", "#training", "#optimization"], "emoji": "🔐", "ru": {"title": "Locket: Монетизация AI через блокировку функций по подписке", "desc": "Провайдеры чат-ботов используют многоуровневые подписки, но более выгодной может быть схема оплаты за отдельные функции (
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#dataset", "#agents", "#ethics", "#rlhf", "#security", "#alignment", "#benchmark"], "emoji": "🔬", "ru": {"title": "Опасность исследовательских AI-агентов: когда умные помощники обходят защиту", "desc": "Исследователи обнаружили критическую уязвимость в Deep Research агентах на основ
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#open_source", "#reasoning", "#rlhf", "#security", "#alignment", "#benchmark", "#architecture"], "emoji": "🔓", "ru": {"title": "Хрупкая броня: как простые токены ломают защиту reasoning-моделей", "desc": "Исследователи обнаружили критическую уязвимость в системах безопасности больши
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#hallucinations", "#reasoning", "#benchmark", "#data", "#training"], "emoji": "🛡️", "ru": {"title": "Защита рассуждений LLM от кражи через переформулирование", "desc": "Исследователи предложили метод PART для защиты детальных reasoning-цепочек больших языковых моделей от несанкциони
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#diffusion", "#audio", "#games", "#multimodal"], "emoji": "🎵", "ru": {"title": "Диффузионный мост между звуком и текстом для LLM", "desc": "Статья представляет Diffusion-Link — модуль на основе диффузионных моделей для соединения аудио и текстовых модальностей. Модуль генеративно пр
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#math", "#reasoning", "#training"], "emoji": "📉", "ru": {"title": "Почему Трансформеры проигрывают линейным моделям в прогнозировании временных рядов", "desc": "Исследование теоретически доказывает, что Transformer-архитектуры, особенно модели с Lin
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#optimization", "#security", "#multimodal", "#benchmark", "#cv"], "emoji": "🔏", "ru": {"title": "SynthID-Image: невидимые водяные знаки для AI-изображений в масштабе интернета", "desc": "Исследователи представили SynthID-Image — систему на основе глубокого обучения для невидимой вод
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#math", "#training", "#interpretability"], "emoji": "🔍", "ru": {"title": "Прозрачные рассуждения: как научить AI объяснять свои решения", "desc": "В статье представлен ReFIne — новый метод обучения, который делает reasoning модели более надёжными и пон
[16.10.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#interpretability", "#plp", "#agi"], "emoji": "🔗", "ru": {"title": "Тензорная логика: мост между нейронным и символьным AI", "desc": "Статья предлагает tensor logic — новый язык программирования, который объединяет нейронные и символьные подходы в AI ч
[16.10.2025 00:52] Querying the API.
[16.10.2025 00:52] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Context-Folding, an end-to-end reinforcement learning framework, enables LLM agents to manage context effectively by branching into subtasks and folding them, outperforming baselines on long-horizon tasks with reduced context size.  					AI-generated summary 				 Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks. We introduce Context-Folding, a framework that empowers agents to actively manage their working context. An agent can procedurally branch into a sub-trajectory to handle a subtask and then fold it upon completion, collapsing the intermediate steps while retaining a concise summary of the outcome. To make this behavior learnable, we develop an end-to-end reinforcement learning framework FoldGRPO with specific process rewards to encourage effective task decomposition and context management. On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10times smaller and significantly outperforms models that rely on summarization-based context management.
[16.10.2025 00:53] Response: ```json
{
  "desc": "Статья представляет Context-Folding — фреймворк для обучения LLM-агентов эффективному управлению контекстом при решении долгосрочных задач. Агент разбивает сложную задачу на подзадачи, которые затем «сворачивает», сохраняя только краткое резюме результатов вместо всех промежуточных шагов. Для обучения такому поведению разработан метод reinforcement learning под названием FoldGRPO со специальными наградами за декомпозицию задач. На сложных задачах метод показывает результаты сопоставимые или лучше базовых подходов, используя в 10 раз меньший активный контекст.",
  "emoji": "🗂️",
  "title": "Сворачивание контекста: как научить AI-агентов работать с длинными задачами без раздувания памяти"
}
```
[16.10.2025 00:53] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Context-Folding, an end-to-end reinforcement learning framework, enables LLM agents to manage context effectively by branching into subtasks and folding them, outperforming baselines on long-horizon tasks with reduced context size.  					AI-generated summary 				 Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks. We introduce Context-Folding, a framework that empowers agents to actively manage their working context. An agent can procedurally branch into a sub-trajectory to handle a subtask and then fold it upon completion, collapsing the intermediate steps while retaining a concise summary of the outcome. To make this behavior learnable, we develop an end-to-end reinforcement learning framework FoldGRPO with specific process rewards to encourage effective task decomposition and context management. On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10times smaller and significantly outperforms models that rely on summarization-based context management."

[16.10.2025 00:53] Response: ```python
['RL', 'RLHF', 'AGENTS']
```
[16.10.2025 00:53] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Context-Folding, an end-to-end reinforcement learning framework, enables LLM agents to manage context effectively by branching into subtasks and folding them, outperforming baselines on long-horizon tasks with reduced context size.  					AI-generated summary 				 Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks. We introduce Context-Folding, a framework that empowers agents to actively manage their working context. An agent can procedurally branch into a sub-trajectory to handle a subtask and then fold it upon completion, collapsing the intermediate steps while retaining a concise summary of the outcome. To make this behavior learnable, we develop an end-to-end reinforcement learning framework FoldGRPO with specific process rewards to encourage effective task decomposition and context management. On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10times smaller and significantly outperforms models that rely on summarization-based context management."

[16.10.2025 00:53] Response: ```python
["LONG_CONTEXT", "OPTIMIZATION"]
```
[16.10.2025 00:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper presents Context-Folding, a novel reinforcement learning framework designed for large language model (LLM) agents to enhance their context management capabilities. By allowing agents to branch into subtasks and fold them after completion, the framework effectively reduces the context size while maintaining essential information. The authors introduce FoldGRPO, an end-to-end learning approach that incentivizes agents to decompose tasks and manage context efficiently through specific process rewards. Experimental results demonstrate that this method outperforms traditional baselines on long-horizon tasks, achieving better performance with a significantly smaller active context.","title":"Empowering LLMs with Context-Folding for Efficient Task Management"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper presents Context-Folding, a novel reinforcement learning framework designed for large language model (LLM) agents to enhance their context management capabilities. By allowing agents to branch into subtasks and fold them after completion, the framework effectively reduces the context size while maintaining essential information. The authors introduce FoldGRPO, an end-to-end learning approach that incentivizes agents to decompose tasks and manage context efficiently through specific process rewards. Experimental results demonstrate that this method outperforms traditional baselines on long-horizon tasks, achieving better performance with a significantly smaller active context.', title='Empowering LLMs with Context-Folding for Efficient Task Management'))
[16.10.2025 00:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Context-Folding 是一个端到端的强化学习框架，旨在帮助大型语言模型（LLM）代理有效管理上下文。该框架允许代理将任务分解为子任务，并在完成后将其折叠，从而减少上下文的使用。通过开发 FoldGRPO 强化学习算法，代理能够学习如何有效地进行任务分解和上下文管理。实验结果表明，在复杂的长时间任务中，使用 Context-Folding 的代理在上下文规模减少的情况下，表现优于传统的 ReAct 基线。","title":"上下文折叠：提升长任务管理的智能框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Context-Folding 是一个端到端的强化学习框架，旨在帮助大型语言模型（LLM）代理有效管理上下文。该框架允许代理将任务分解为子任务，并在完成后将其折叠，从而减少上下文的使用。通过开发 FoldGRPO 强化学习算法，代理能够学习如何有效地进行任务分解和上下文管理。实验结果表明，在复杂的长时间任务中，使用 Context-Folding 的代理在上下文规模减少的情况下，表现优于传统的 ReAct 基线。', title='上下文折叠：提升长任务管理的智能框架'))
[16.10.2025 00:53] Using data from previous issue: {"categories": ["#open_source", "#inference", "#diffusion", "#architecture"], "emoji": "⚡", "ru": {"title": "Диффузионные LLM в 10 раз быстрее с dInfer", "desc": "dInfer - это эффективный фреймворк для инференса диффузионных языковых моделей (dLLM), которые представляют альтернативу традиционным авт
[16.10.2025 00:53] Querying the API.
[16.10.2025 00:53] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Summarization-based context management in reinforcement learning fine-tunes large language model agents for long-horizon tool use, improving success rates and scalability beyond fixed context limits.  					AI-generated summary 				 We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with SUmmarization augmented Policy Optimization (SUPO), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that SUPO significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, SUPO can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit.
[16.10.2025 00:53] Response: ```json
{
  "title": "Сжатие контекста через суммаризацию для обучения AI-агентов",
  "desc": "Исследователи предложили метод SUPO для обучения LLM-агентов с подкреплением в задачах, требующих длинных последовательностей использования инструментов. Основная проблема заключается в ограничении длины контекста, которое быстро становится узким местом при многоходовых взаимодействиях. Решение состоит в периодическом сжатии истории использования инструментов через автоматически генерируемые суммаризации, сохраняющие только релевантную информацию. Алгоритм обучает агента одновременно эффективно использовать инструменты и создавать качественные суммаризации, что значительно повышает успешность выполнения задач при сохранении компактного контекста.",
  "emoji": "📦",
  "desc": "Исследователи предложили метод SUPO для обучения LLM-агентов с подкреплением в задачах, требующих длинных последовательностей использования инструментов. Основная проблема заключается в ограничении длины контекста, которое быстро становится узким местом при многоходовых взаимодействиях. Решение состоит в периодическом сжатии истории использования инструментов через автоматически генерируемые суммаризации, сохраняющие только релевантную информацию. Алгоритм обучает агента одновременно эффективно использовать инструменты и создавать качественные суммаризации, что значительно повышает успешность выполнения задач при сохранении компактного контекста."
}
```
[16.10.2025 00:53] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Summarization-based context management in reinforcement learning fine-tunes large language model agents for long-horizon tool use, improving success rates and scalability beyond fixed context limits.  					AI-generated summary 				 We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with SUmmarization augmented Policy Optimization (SUPO), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that SUPO significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, SUPO can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit."

[16.10.2025 00:53] Response: ```python
['RL', 'RLHF', 'AGENTS', 'TRAINING']
```
[16.10.2025 00:53] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Summarization-based context management in reinforcement learning fine-tunes large language model agents for long-horizon tool use, improving success rates and scalability beyond fixed context limits.  					AI-generated summary 				 We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with SUmmarization augmented Policy Optimization (SUPO), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that SUPO significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, SUPO can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit."

[16.10.2025 00:53] Response: ```python
["LONG_CONTEXT", "OPTIMIZATION"]
```
[16.10.2025 00:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a method for improving reinforcement learning (RL) agents that use large language models (LLMs) for long tasks involving multiple steps. The main issue addressed is the limitation of context length, which can hinder the agent\'s ability to follow instructions effectively. The authors propose a technique called summarization-based context management, which compresses the history of tool usage into concise summaries, allowing the agent to maintain relevant information without exceeding context limits. Their new algorithm, SUmmarization augmented Policy Optimization (SUPO), shows significant improvements in success rates for tasks while using less context compared to traditional methods.","title":"Enhancing RL Agents with Summarization for Long-Term Success"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper presents a method for improving reinforcement learning (RL) agents that use large language models (LLMs) for long tasks involving multiple steps. The main issue addressed is the limitation of context length, which can hinder the agent's ability to follow instructions effectively. The authors propose a technique called summarization-based context management, which compresses the history of tool usage into concise summaries, allowing the agent to maintain relevant information without exceeding context limits. Their new algorithm, SUmmarization augmented Policy Optimization (SUPO), shows significant improvements in success rates for tasks while using less context compared to traditional methods.", title='Enhancing RL Agents with Summarization for Long-Term Success'))
[16.10.2025 00:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文研究了如何通过强化学习（RL）对大型语言模型（LLM）代理进行微调，以实现长时间的多轮工具使用。现有的RL流程在指令执行、成本和上下文限制方面存在问题。为了解决这些挑战，本文提出了一种基于摘要的上下文管理方法，通过生成摘要来压缩工具使用历史，从而保持紧凑的上下文并超越固定的上下文窗口。实验结果表明，所提出的SUPO算法在成功率上显著提高，同时保持相同或更低的工作上下文长度。","title":"基于摘要的上下文管理，突破强化学习的限制"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文研究了如何通过强化学习（RL）对大型语言模型（LLM）代理进行微调，以实现长时间的多轮工具使用。现有的RL流程在指令执行、成本和上下文限制方面存在问题。为了解决这些挑战，本文提出了一种基于摘要的上下文管理方法，通过生成摘要来压缩工具使用历史，从而保持紧凑的上下文并超越固定的上下文窗口。实验结果表明，所提出的SUPO算法在成功率上显著提高，同时保持相同或更低的工作上下文长度。', title='基于摘要的上下文管理，突破强化学习的限制'))
[16.10.2025 00:53] Renaming data file.
[16.10.2025 00:53] Renaming previous data. hf_papers.json to ./d/2025-10-16.json
[16.10.2025 00:53] Saving new data file.
[16.10.2025 00:53] Generating page.
[16.10.2025 00:53] Renaming previous page.
[16.10.2025 00:53] Renaming previous data. index.html to ./d/2025-10-16.html
[16.10.2025 00:53] Writing result.
[16.10.2025 00:53] Renaming log file.
[16.10.2025 00:53] Renaming previous data. log.txt to ./logs/2025-10-16_last_log.txt
