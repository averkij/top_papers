[31.10.2025 02:32] Read previous papers.
[31.10.2025 02:32] Generating top page (month).
[31.10.2025 02:32] Writing top page (month).
[31.10.2025 03:40] Read previous papers.
[31.10.2025 03:40] Get feed.
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26583
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26802
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26800
[31.10.2025 03:40] Extract page data from URL. URL: https://huggingface.co/papers/2510.26794
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26692
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25992
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26787
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26298
[31.10.2025 03:40] Extract page data from URL. URL: https://huggingface.co/papers/2510.25628
[31.10.2025 03:40] Extract page data from URL. URL: https://huggingface.co/papers/2510.25132
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26474
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26160
[31.10.2025 03:40] Get page data from previous paper. URL: https://huggingface.co/papers/2510.26140
[31.10.2025 03:40] Extract page data from URL. URL: https://huggingface.co/papers/2510.25779
[31.10.2025 03:40] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.10.2025 03:40] No deleted papers detected.
[31.10.2025 03:40] Downloading and parsing papers (pdf, html). Total: 14.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26583.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26583.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26583.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26802.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26802.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26802.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26800.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26800.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26800.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26794.
[31.10.2025 03:40] Downloading paper 2510.26794 from http://arxiv.org/pdf/2510.26794v1...
[31.10.2025 03:40] Extracting affiliations from text.
[31.10.2025 03:40] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 3 ] . [ 1 4 9 7 6 2 . 0 1 5 2 : r THE QUEST FOR GENERALIZABLE MOTION GENERATION: DATA, MODEL, AND EVALUATION Jing Lin1, Ruisi Wang2, Junzhe Lu3, Ziqi Huang1, Guorui Song3, Ailing Zeng4, Xian Liu5, Chen Wei2, Wanqi Yin2, Qingping Sun2, Zhongang Cai2, Lei Yang2, Ziwei Liu1 1 Nanyang Technological University 4 The Chinese University of Hong Kong 2 SenseTime Research 3 Tsinghua University 5 NVIDIA Research "
[31.10.2025 03:40] Response: ```python
["Nanyang Technological University", "The Chinese University of Hong Kong", "SenseTime Research", "Tsinghua University", "NVIDIA Research"]
```
[31.10.2025 03:40] Deleting PDF ./assets/pdf/2510.26794.pdf.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26692.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26692.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26692.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.25992.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.25992.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.25992.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26787.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26787.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26787.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26298.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26298.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26298.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.25628.
[31.10.2025 03:40] Downloading paper 2510.25628 from http://arxiv.org/pdf/2510.25628v1...
[31.10.2025 03:40] Extracting affiliations from text.
[31.10.2025 03:40] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 2 ] . [ 1 8 2 6 5 2 . 0 1 5 2 : r EHR-R1: Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis Yusheng Liao,1, Chaoyi Wu,1, Junwei Liu,3,4, Shuyang Jiang2,5, Pengcheng Qiu1,2, Haowen Wang3, Yun Yue3, Shuai Zhen3, Jian Wang3, Qianrui Fan3, Jinjie Gu3, Ya Zhang1,2, Yanfeng Wang1,2, Yu Wang1,2, and Weidi Xie1,2, 1Shanghai Jiao Tong University, Shanghai, China 2Shanghai Artificial Intelligence Laboratory, Shanghai, China 3Intelligence Healthcare Department, AntGroup, Hangzhou, China 4Intelligence Computing and Sensing Laboratory, Peking University, Beijing, China 5Fudan University, Shanghai, China Equal contributions Corresponding author Yu Wang: yuwangsjtu@sjtu.edu.cn; Weidi Xie: weidi@sjtu.edu.cn Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and lack of EHRoriented reasoning capabilities. This paper aims to bridge the gap, specifically, we present EHR-Ins, large-scale, comprehensive EHR reasoning instruction dataset, comprising 300k high-quality reasoning cases and 4M non-reasoning cases across 42 distinct EHR tasks. Its core innovation is thinkinggraph-driven framework that enables to generate high-quality reasoning data at scale. Based on it, we develop EHR-R1, series of reasoning-enhanced LLMs with up to 72B parameters tailored for EHR analysis. Through multi-stage training paradigm, including domain adaptation, reasoning enhancement, and reinforcement learning, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, enabling accurate and robust EHR analysis. Lastly, we introduce EHR-Bench, new benchmark curated from MIMIC-IV, spanning 42 tasks, to comprehensively assess reasoning and prediction across EHR scenarios. In experiments, we show that the re"
[31.10.2025 03:40] Response: ```python
[
    "Shanghai Jiao Tong University, Shanghai, China",
    "Shanghai Artificial Intelligence Laboratory, Shanghai, China",
    "Intelligence Healthcare Department, AntGroup, Hangzhou, China",
    "Intelligence Computing and Sensing Laboratory, Peking University, Beijing, China",
    "Fudan University, Shanghai, China"
]
```
[31.10.2025 03:40] Deleting PDF ./assets/pdf/2510.25628.pdf.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.25132.
[31.10.2025 03:40] Downloading paper 2510.25132 from http://arxiv.org/pdf/2510.25132v1...
[31.10.2025 03:40] Extracting affiliations from text.
[31.10.2025 03:40] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 2 ] . - [ 1 2 3 1 5 2 . 0 1 5 2 : r EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme Backbone Generation Chao Song1, Zhiyuan Liu2, Han Huang3, Liang Wang4, Qiong Wang1, Jianyu Shi1, Hui Yu1, Yihang Zhou2, Yang Zhang2 1Northwestern Polytechnical University, 3The Chinese University of Hong Kong, 2National University of Singapore 4Institute of Automation at CAS csong@mail.nwpu.edu.cn, zhiyuan@nus.edu.sg huiyu@nwpu.edu.cn, yihangjoe@foxmail.com, zhang@nus.edu.sg "
[31.10.2025 03:40] Response: ```python
[
    "Northwestern Polytechnical University",
    "The Chinese University of Hong Kong",
    "National University of Singapore",
    "Institute of Automation at CAS"
]
```
[31.10.2025 03:40] Deleting PDF ./assets/pdf/2510.25132.pdf.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26474.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26474.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26474.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26160.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26160.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26160.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.26140.
[31.10.2025 03:40] Extra JSON file exists (./assets/json/2510.26140.json), skip PDF parsing.
[31.10.2025 03:40] Paper image links file exists (./assets/img_data/2510.26140.json), skip HTML parsing.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Downloading and parsing paper https://huggingface.co/papers/2510.25779.
[31.10.2025 03:40] Downloading paper 2510.25779 from http://arxiv.org/pdf/2510.25779v1...
[31.10.2025 03:40] Extracting affiliations from text.
[31.10.2025 03:40] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"MAGENTIC MARKETPLACE: AN OPEN-SOURCE ENVIRONMENT FOR STUDYING AGENTIC MARKETS 5 2 0 2 7 2 ] . [ 1 9 7 7 5 2 . 0 1 5 2 : r Gagan Bansal, Wenyue Hua, Zezhou Huang, Adam Fourney, Amanda Swearngin, Will Epperson, Tyler Payne, Jake M. Hofman, Brendan Lucier, Chinmay Singh, Markus Mobius, 1 Akshay Nambi, Archana Yadav, Kevin Gao, David M. Rothschild, Aleksandrs Slivkins, Daniel G. Goldstein, Hussein Mozannar, Nicole Immorlica, 2 Maya Murad, Matthew Vogel,3 Subbarao Kambhampati,4, Eric Horvitz,4 Saleema Amershi 5 1 Core Contributors; 2 Contributors; 3 Technical Program Managers; 4 Advisors; 5 Principal Investigator Microsoft Arizona State University October 31, "
[31.10.2025 03:40] Response: ```python
["Microsoft", "Arizona State University"]
```
[31.10.2025 03:40] Deleting PDF ./assets/pdf/2510.25779.pdf.
[31.10.2025 03:40] Success.
[31.10.2025 03:40] Enriching papers with extra data.
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 0. We introduce Emu3.5, a large-scale multimodal world model that natively predicts the next state across vision and language. Emu3.5 is pre-trained end-to-end with a unified next-token prediction objective on a corpus of vision-language interleaved data containing over 10 trillion tokens, primarily de...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 1. Recent video generation models can produce high-fidelity, temporally coherent videos, indicating that they may encode substantial world knowledge. Beyond realistic synthesis, they also exhibit emerging behaviors indicative of visual perception, modeling, and manipulation. Yet, an important question ...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 2. There are two prevalent ways to constructing 3D scenes: procedural generation and 2D lifting. Among them, panorama-based 2D lifting has emerged as a promising technique, leveraging powerful 2D generative priors to produce immersive, realistic, and diverse 3D environments. In this work, we advance th...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 3. Despite recent advances in 3D human motion generation (MoGen) on standard benchmarks, existing models still face a fundamental bottleneck in their generalization capability. In contrast, adjacent generative fields, most notably video generation (ViGen), have demonstrated remarkable generalization in...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 4. We introduce Kimi Linear, a hybrid linear attention architecture that, for the first time, outperforms full attention under fair comparisons across various scenarios -- including short-context, long-context, and reinforcement learning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA)...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 5. Large Language Models (LLMs) often struggle with problems that require multi-step reasoning. For small-scale open-source models, Reinforcement Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 6. AIs have made rapid progress on research-oriented benchmarks of knowledge and reasoning, but it remains unclear how these gains translate into economic value and automation. To measure this, we introduce the Remote Labor Index (RLI), a broadly multi-sector benchmark comprising real-world, economical...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 7. OpenAI's ChatGPT Atlas introduces new capabilities for web interaction, enabling the model to analyze webpages, process user intents, and execute cursor and keyboard inputs directly within the browser. While its capacity for information retrieval tasks has been demonstrated, its performance in dynam...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 8. Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and l...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 9. Designing enzyme backbones with substrate-specific functionality is a critical challenge in computational protein engineering. Current generative models excel in protein design but face limitations in binding data, substrate-specific control, and flexibility for de novo enzyme backbone generation. T...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 10. Self-improvement has emerged as a mainstream paradigm for advancing the reasoning capabilities of large vision-language models (LVLMs), where models explore and learn from successful trajectories iteratively. However, we identify a critical issue during this process: the model excels at generating h...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 11. Wearable devices such as smart glasses are transforming the way people interact with their surroundings, enabling users to seek information regarding entities in their view. Multi-Modal Retrieval-Augmented Generation (MM-RAG) plays a key role in supporting such questions, yet there is still no compr...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 12. Part-based 3D generation holds great potential for various applications. Previous part generators that represent parts using implicit vector-set tokens often suffer from insufficient geometric details. Another line of work adopts an explicit voxel representation but shares a global voxel grid among ...
[31.10.2025 03:40] ********************************************************************************
[31.10.2025 03:40] Abstract 13. As LLM agents advance, they are increasingly mediating economic decisions, ranging from product discovery to transactions, on behalf of users. Such applications promise benefits but also raise many questions about agent accountability and value for users. Addressing these questions requires understa...
[31.10.2025 03:40] Read previous papers.
[31.10.2025 03:40] Generating reviews via LLM API.
[31.10.2025 03:40] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#inference", "#multimodal", "#rl", "#agi", "#cv", "#games"], "emoji": "🌍", "ru": {"title": "Мультимодальная модель мира с единым предсказанием следующего токена", "desc": "Представлена модель Emu3.5 — крупномасштабная мультимодальная модель, которая 
[31.10.2025 03:40] Using data from previous issue: {"categories": ["#video", "#reasoning", "#benchmark"], "emoji": "🎬", "ru": {"title": "Видео-модели как визуальные движки: обещания и ограничения рассуждений", "desc": "Исследователи проверили, может ли современная модель генерации видео Veo-3 выступать в роли zero-shot reasoner для сложных задач виз
[31.10.2025 03:40] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#3d", "#synthetic", "#games"], "emoji": "🌐", "ru": {"title": "От панорам к реалистичным 3D-сценам с физически корректным рендерингом", "desc": "Статья представляет OmniX — универсальную систему для создания графически готовых 3D-сцен из панорамных изображе
[31.10.2025 03:40] Querying the API.
[31.10.2025 03:40] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Despite recent advances in 3D human motion generation (MoGen) on standard benchmarks, existing models still face a fundamental bottleneck in their generalization capability. In contrast, adjacent generative fields, most notably video generation (ViGen), have demonstrated remarkable generalization in modeling human behaviors, highlighting transferable insights that MoGen can leverage. Motivated by this observation, we present a comprehensive framework that systematically transfers knowledge from ViGen to MoGen across three key pillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, a large-scale dataset comprising 228,000 high-quality motion samples that integrates high-fidelity optical MoCap data with semantically annotated motions from web videos and synthesized samples generated by state-of-the-art ViGen models. The dataset includes both text-motion pairs and text-video-motion triplets, substantially expanding semantic diversity. Second, we propose ViMoGen, a flow-matching-based diffusion transformer that unifies priors from MoCap data and ViGen models through gated multimodal conditioning. To enhance efficiency, we further develop ViMoGen-light, a distilled variant that eliminates video generation dependencies while preserving strong generalization. Finally, we present MBench, a hierarchical benchmark designed for fine-grained evaluation across motion quality, prompt fidelity, and generalization ability. Extensive experiments show that our framework significantly outperforms existing approaches in both automatic and human evaluations. The code, data, and benchmark will be made publicly available.
[31.10.2025 03:40] Response: ```json
{
  "title": "От видео к движению: перенос знаний для генерации 3D-анимации человека",
  "desc": "Исследователи предложили новый подход к генерации 3D-движений человека, заимствуя знания из области генерации видео. Они создали крупный датасет ViMoGen-228K из 228 тысяч образцов движений, объединяющий данные motion capture, аннотированные видео и синтетические примеры от video generation моделей. Разработанная архитектура ViMoGen использует diffusion transformer с flow matching и мультимодальное conditioning для объединения разных источников данных. Также представлен новый бенчмарк MBench для детальной оценки качества движений, соответствия текстовым описаниям и способности к генерализации.",
  "emoji": "🎬",
  "file": "vimogen.json"
}
```
[31.10.2025 03:40] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Despite recent advances in 3D human motion generation (MoGen) on standard benchmarks, existing models still face a fundamental bottleneck in their generalization capability. In contrast, adjacent generative fields, most notably video generation (ViGen), have demonstrated remarkable generalization in modeling human behaviors, highlighting transferable insights that MoGen can leverage. Motivated by this observation, we present a comprehensive framework that systematically transfers knowledge from ViGen to MoGen across three key pillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, a large-scale dataset comprising 228,000 high-quality motion samples that integrates high-fidelity optical MoCap data with semantically annotated motions from web videos and synthesized samples generated by state-of-the-art ViGen models. The dataset includes both text-motion pairs and text-video-motion triplets, substantially expanding semantic diversity. Second, we propose ViMoGen, a flow-matching-based diffusion transformer that unifies priors from MoCap data and ViGen models through gated multimodal conditioning. To enhance efficiency, we further develop ViMoGen-light, a distilled variant that eliminates video generation dependencies while preserving strong generalization. Finally, we present MBench, a hierarchical benchmark designed for fine-grained evaluation across motion quality, prompt fidelity, and generalization ability. Extensive experiments show that our framework significantly outperforms existing approaches in both automatic and human evaluations. The code, data, and benchmark will be made publicly available."

[31.10.2025 03:41] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'CV', 'MULTIMODAL']
```
[31.10.2025 03:41] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Despite recent advances in 3D human motion generation (MoGen) on standard benchmarks, existing models still face a fundamental bottleneck in their generalization capability. In contrast, adjacent generative fields, most notably video generation (ViGen), have demonstrated remarkable generalization in modeling human behaviors, highlighting transferable insights that MoGen can leverage. Motivated by this observation, we present a comprehensive framework that systematically transfers knowledge from ViGen to MoGen across three key pillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, a large-scale dataset comprising 228,000 high-quality motion samples that integrates high-fidelity optical MoCap data with semantically annotated motions from web videos and synthesized samples generated by state-of-the-art ViGen models. The dataset includes both text-motion pairs and text-video-motion triplets, substantially expanding semantic diversity. Second, we propose ViMoGen, a flow-matching-based diffusion transformer that unifies priors from MoCap data and ViGen models through gated multimodal conditioning. To enhance efficiency, we further develop ViMoGen-light, a distilled variant that eliminates video generation dependencies while preserving strong generalization. Finally, we present MBench, a hierarchical benchmark designed for fine-grained evaluation across motion quality, prompt fidelity, and generalization ability. Extensive experiments show that our framework significantly outperforms existing approaches in both automatic and human evaluations. The code, data, and benchmark will be made publicly available."

[31.10.2025 03:41] Response: ```python
['TRANSFER_LEARNING', 'DIFFUSION', 'OPEN_SOURCE']
```
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the limitations of current 3D human motion generation (MoGen) models in generalization by leveraging insights from video generation (ViGen). The authors introduce a new dataset, ViMoGen-228K, which contains 228,000 high-quality motion samples that combine motion capture data with semantically rich annotations from web videos. They propose a novel model, ViMoGen, which utilizes a flow-matching-based diffusion transformer to integrate knowledge from both MoGen and ViGen, and also introduce a lighter version, ViMoGen-light, for improved efficiency. Finally, they create MBench, a benchmark for evaluating motion generation quality, demonstrating that their framework significantly enhances performance in various evaluation metrics.","title":"Bridging Video and Motion: A New Era for 3D Human Motion Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the limitations of current 3D human motion generation (MoGen) models in generalization by leveraging insights from video generation (ViGen). The authors introduce a new dataset, ViMoGen-228K, which contains 228,000 high-quality motion samples that combine motion capture data with semantically rich annotations from web videos. They propose a novel model, ViMoGen, which utilizes a flow-matching-based diffusion transformer to integrate knowledge from both MoGen and ViGen, and also introduce a lighter version, ViMoGen-light, for improved efficiency. Finally, they create MBench, a benchmark for evaluating motion generation quality, demonstrating that their framework significantly enhances performance in various evaluation metrics.', title='Bridging Video and Motion: A New Era for 3D Human Motion Generation'))
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种新的框架，将视频生成（ViGen）领域的知识转移到三维人类动作生成（MoGen）中，以提高其泛化能力。我们引入了一个大型数据集ViMoGen-228K，包含228,000个高质量动作样本，结合了高保真光学动作捕捉数据和语义注释的动作。我们还提出了ViMoGen，一个基于流匹配的扩散变换器，通过门控多模态条件化来统一MoCap数据和ViGen模型的先验知识。最后，我们设计了MBench，一个分层基准，用于对动作质量、提示保真度和泛化能力进行细致评估，实验结果表明我们的框架在自动和人工评估中均显著优于现有方法。","title":"知识转移，提升三维动作生成能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种新的框架，将视频生成（ViGen）领域的知识转移到三维人类动作生成（MoGen）中，以提高其泛化能力。我们引入了一个大型数据集ViMoGen-228K，包含228,000个高质量动作样本，结合了高保真光学动作捕捉数据和语义注释的动作。我们还提出了ViMoGen，一个基于流匹配的扩散变换器，通过门控多模态条件化来统一MoCap数据和ViGen模型的先验知识。最后，我们设计了MBench，一个分层基准，用于对动作质量、提示保真度和泛化能力进行细致评估，实验结果表明我们的框架在自动和人工评估中均显著优于现有方法。', title='知识转移，提升三维动作生成能力'))
[31.10.2025 03:41] Using data from previous issue: {"categories": ["#open_source", "#architecture", "#optimization", "#long_context", "#training"], "emoji": "⚡", "ru": {"title": "Линейное внимание обходит полное: эффективность встречается с производительностью", "desc": "Представлена архитектура Kimi Linear с гибридным линейным вниманием, которая вп
[31.10.2025 03:41] Using data from previous issue: {"categories": ["#optimization", "#agents", "#training", "#small_models", "#reasoning", "#rl"], "emoji": "🎯", "ru": {"title": "Обучение через пошаговое подражание экспертам", "desc": "Статья представляет метод Supervised Reinforcement Learning (SRL), который помогает небольшим языковым моделям решат
[31.10.2025 03:41] Using data from previous issue: {"categories": ["#agents", "#science", "#reasoning", "#benchmark"], "emoji": "🏢", "ru": {"title": "Реальная автоматизация труда: AI пока справляется только с 2.5% задач", "desc": "Исследователи представили Remote Labor Index (RLI) — новый бенчмарк для оценки способности AI-агентов выполнять реальные
[31.10.2025 03:41] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#reasoning", "#benchmark", "#games"], "emoji": "🎮", "ru": {"title": "Атлас от OpenAI: силён в логике, слаб в реакции", "desc": "Исследователи протестировали новую модель ChatGPT Atlas, которая умеет взаимодействовать с веб-страницами через курсор и клавиату
[31.10.2025 03:41] Querying the API.
[31.10.2025 03:41] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and lack of EHR-oriented reasoning capabilities. This paper aims to bridge the gap, specifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning instruction dataset, comprising 300k high-quality reasoning cases and 4M non-reasoning cases across 42 distinct EHR tasks. Its core innovation is a thinking-graph-driven framework that enables to generate high-quality reasoning data at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced LLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage training paradigm, including domain adaptation, reasoning enhancement, and reinforcement learning, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, enabling accurate and robust EHR analysis. Lastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning 42 tasks, to comprehensively assess reasoning and prediction across EHR scenarios. In experiments, we show that the resulting EHR-R1 consistently outperforms state-of-the-art commercial and open-source LLMs (including DeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and achieving a 10\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins, EHR-R1, and EHR-Bench have significantly advanced the development for more reliable and clinically relevant EHR analysis.
[31.10.2025 03:41] Response: ```json
{
  "desc": "Статья представляет EHR-R1 — специализированную LLM для анализа электронных медицинских карт с улучшенными способностями к рассуждениям. Авторы создали EHR-Ins — датасет из 300 тысяч случаев с рассуждениями и 4 миллионов обычных случаев по 42 медицинским задачам, используя инновационный метод генерации данных на основе графов мышления. Модель обучалась в несколько этапов: адаптация к медицинскому домену, улучшение способностей к рассуждениям и reinforcement learning. EHR-R1 превосходит GPT-4o более чем на 30 пунктов на бенчмарке MIMIC-Bench и показывает на 10% лучший результат по метрике AUROC в zero-shot режиме на EHRSHOT.",
  "emoji": "🏥",
  "title": "EHR-R1: AI-модель с продвинутыми рассуждениями для анализа медицинских карт"
}
```
[31.10.2025 03:41] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and lack of EHR-oriented reasoning capabilities. This paper aims to bridge the gap, specifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning instruction dataset, comprising 300k high-quality reasoning cases and 4M non-reasoning cases across 42 distinct EHR tasks. Its core innovation is a thinking-graph-driven framework that enables to generate high-quality reasoning data at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced LLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage training paradigm, including domain adaptation, reasoning enhancement, and reinforcement learning, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, enabling accurate and robust EHR analysis. Lastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning 42 tasks, to comprehensively assess reasoning and prediction across EHR scenarios. In experiments, we show that the resulting EHR-R1 consistently outperforms state-of-the-art commercial and open-source LLMs (including DeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and achieving a 10\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins, EHR-R1, and EHR-Bench have significantly advanced the development for more reliable and clinically relevant EHR analysis."

[31.10.2025 03:41] Response: ```python
["DATASET", "BENCHMARK", "HEALTHCARE", "TRAINING"]
```
[31.10.2025 03:41] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and lack of EHR-oriented reasoning capabilities. This paper aims to bridge the gap, specifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning instruction dataset, comprising 300k high-quality reasoning cases and 4M non-reasoning cases across 42 distinct EHR tasks. Its core innovation is a thinking-graph-driven framework that enables to generate high-quality reasoning data at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced LLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage training paradigm, including domain adaptation, reasoning enhancement, and reinforcement learning, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, enabling accurate and robust EHR analysis. Lastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning 42 tasks, to comprehensively assess reasoning and prediction across EHR scenarios. In experiments, we show that the resulting EHR-R1 consistently outperforms state-of-the-art commercial and open-source LLMs (including DeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and achieving a 10\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins, EHR-R1, and EHR-Bench have significantly advanced the development for more reliable and clinically relevant EHR analysis."

[31.10.2025 03:41] Response: ```python
['REASONING', 'SCIENCE']
```
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenges of analyzing Electronic Health Records (EHRs) using large language models (LLMs). It introduces EHR-Ins, a comprehensive dataset designed for EHR reasoning, which includes 300,000 reasoning cases and 4 million non-reasoning cases across 42 tasks. The authors develop EHR-R1, a series of reasoning-enhanced LLMs that utilize a multi-stage training approach to improve their reasoning capabilities and domain knowledge for EHR analysis. The results demonstrate that EHR-R1 outperforms existing models, providing a significant advancement in the reliability and relevance of EHR analysis in clinical settings.","title":"Revolutionizing EHR Analysis with Enhanced Reasoning Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenges of analyzing Electronic Health Records (EHRs) using large language models (LLMs). It introduces EHR-Ins, a comprehensive dataset designed for EHR reasoning, which includes 300,000 reasoning cases and 4 million non-reasoning cases across 42 tasks. The authors develop EHR-R1, a series of reasoning-enhanced LLMs that utilize a multi-stage training approach to improve their reasoning capabilities and domain knowledge for EHR analysis. The results demonstrate that EHR-R1 outperforms existing models, providing a significant advancement in the reliability and relevance of EHR analysis in clinical settings.', title='Revolutionizing EHR Analysis with Enhanced Reasoning Models'))
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文介绍了一种新的电子健康记录（EHR）推理指令数据集EHR-Ins，包含30万个高质量推理案例和400万个非推理案例，覆盖42个不同的EHR任务。我们提出了一种基于思维图的框架，能够大规模生成高质量的推理数据。基于此，我们开发了EHR-R1，这是一系列针对EHR分析的增强推理大型语言模型，参数量高达720亿。通过多阶段训练，包括领域适应、推理增强和强化学习，EHR-R1系统性地获取了领域知识和多样的推理能力，显著提高了EHR分析的准确性和鲁棒性。","title":"提升电子健康记录分析的智能推理能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文介绍了一种新的电子健康记录（EHR）推理指令数据集EHR-Ins，包含30万个高质量推理案例和400万个非推理案例，覆盖42个不同的EHR任务。我们提出了一种基于思维图的框架，能够大规模生成高质量的推理数据。基于此，我们开发了EHR-R1，这是一系列针对EHR分析的增强推理大型语言模型，参数量高达720亿。通过多阶段训练，包括领域适应、推理增强和强化学习，EHR-R1系统性地获取了领域知识和多样的推理能力，显著提高了EHR分析的准确性和鲁棒性。', title='提升电子健康记录分析的智能推理能力'))
[31.10.2025 03:41] Querying the API.
[31.10.2025 03:41] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Designing enzyme backbones with substrate-specific functionality is a critical challenge in computational protein engineering. Current generative models excel in protein design but face limitations in binding data, substrate-specific control, and flexibility for de novo enzyme backbone generation. To address this, we introduce EnzyBind, a dataset with 11,100 experimentally validated enzyme-substrate pairs specifically curated from PDBbind. Building on this, we propose EnzyControl, a method that enables functional and substrate-specific control in enzyme backbone generation. Our approach generates enzyme backbones conditioned on MSA-annotated catalytic sites and their corresponding substrates, which are automatically extracted from curated enzyme-substrate data. At the core of EnzyControl is EnzyAdapter, a lightweight, modular component integrated into a pretrained motif-scaffolding model, allowing it to become substrate-aware. A two-stage training paradigm further refines the model's ability to generate accurate and functional enzyme structures. Experiments show that our EnzyControl achieves the best performance across structural and functional metrics on EnzyBind and EnzyBench benchmarks, with particularly notable improvements of 13\% in designability and 13\% in catalytic efficiency compared to the baseline models. The code is released at https://github.com/Vecteur-libre/EnzyControl.
[31.10.2025 03:41] Response: ```json
{
  "title": "Генерация ферментов под конкретные субстраты с контролем каталитических свойств",
  "desc": "Исследователи представили EnzyControl — метод для генерации структур ферментов с учётом специфичности к определённым субстратам. В основе подхода лежит датасет EnzyBind с 11,100 экспериментально подтверждёнными парами фермент-субстрат и лёгкий модульный компонент EnzyAdapter, встроенный в предобученную модель. Модель генерирует backbone ферментов с учётом каталитических сайтов и соответствующих субстратов, используя двухэтапную схему обучения. Эксперименты показали улучшение на 13% в способности к дизайну и каталитической эффективности по сравнению с базовыми моделями.",
  "emoji": "🧬",
  "desc_en": ""
}
```
[31.10.2025 03:41] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Designing enzyme backbones with substrate-specific functionality is a critical challenge in computational protein engineering. Current generative models excel in protein design but face limitations in binding data, substrate-specific control, and flexibility for de novo enzyme backbone generation. To address this, we introduce EnzyBind, a dataset with 11,100 experimentally validated enzyme-substrate pairs specifically curated from PDBbind. Building on this, we propose EnzyControl, a method that enables functional and substrate-specific control in enzyme backbone generation. Our approach generates enzyme backbones conditioned on MSA-annotated catalytic sites and their corresponding substrates, which are automatically extracted from curated enzyme-substrate data. At the core of EnzyControl is EnzyAdapter, a lightweight, modular component integrated into a pretrained motif-scaffolding model, allowing it to become substrate-aware. A two-stage training paradigm further refines the model's ability to generate accurate and functional enzyme structures. Experiments show that our EnzyControl achieves the best performance across structural and functional metrics on EnzyBind and EnzyBench benchmarks, with particularly notable improvements of 13\% in designability and 13\% in catalytic efficiency compared to the baseline models. The code is released at https://github.com/Vecteur-libre/EnzyControl."

[31.10.2025 03:41] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'TRAINING', 'ARCHITECTURE']
```
[31.10.2025 03:41] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Designing enzyme backbones with substrate-specific functionality is a critical challenge in computational protein engineering. Current generative models excel in protein design but face limitations in binding data, substrate-specific control, and flexibility for de novo enzyme backbone generation. To address this, we introduce EnzyBind, a dataset with 11,100 experimentally validated enzyme-substrate pairs specifically curated from PDBbind. Building on this, we propose EnzyControl, a method that enables functional and substrate-specific control in enzyme backbone generation. Our approach generates enzyme backbones conditioned on MSA-annotated catalytic sites and their corresponding substrates, which are automatically extracted from curated enzyme-substrate data. At the core of EnzyControl is EnzyAdapter, a lightweight, modular component integrated into a pretrained motif-scaffolding model, allowing it to become substrate-aware. A two-stage training paradigm further refines the model's ability to generate accurate and functional enzyme structures. Experiments show that our EnzyControl achieves the best performance across structural and functional metrics on EnzyBind and EnzyBench benchmarks, with particularly notable improvements of 13\% in designability and 13\% in catalytic efficiency compared to the baseline models. The code is released at https://github.com/Vecteur-libre/EnzyControl."

[31.10.2025 03:41] Response: []
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents EnzyBind, a new dataset containing 11,100 validated enzyme-substrate pairs to enhance enzyme design in computational protein engineering. The authors introduce EnzyControl, a method that allows for the generation of enzyme backbones that are specifically tailored to bind certain substrates. EnzyControl utilizes a lightweight component called EnzyAdapter, which integrates with a pretrained model to improve substrate awareness during backbone generation. The results demonstrate significant improvements in designability and catalytic efficiency, outperforming existing models on benchmark tests.","title":"Revolutionizing Enzyme Design with EnzyControl"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents EnzyBind, a new dataset containing 11,100 validated enzyme-substrate pairs to enhance enzyme design in computational protein engineering. The authors introduce EnzyControl, a method that allows for the generation of enzyme backbones that are specifically tailored to bind certain substrates. EnzyControl utilizes a lightweight component called EnzyAdapter, which integrates with a pretrained model to improve substrate awareness during backbone generation. The results demonstrate significant improvements in designability and catalytic efficiency, outperforming existing models on benchmark tests.', title='Revolutionizing Enzyme Design with EnzyControl'))
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究提出了一种新的方法EnzyControl，用于设计具有特定底物功能的酶骨架。我们创建了一个名为EnzyBind的数据集，包含11,100对经过实验验证的酶-底物配对，以支持酶设计。EnzyControl通过利用多序列比对（MSA）注释的催化位点和相应的底物，生成条件化的酶骨架。实验结果表明，EnzyControl在结构和功能指标上表现优异，设计能力和催化效率分别提高了13%。","title":"智能设计特定功能酶骨架的创新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究提出了一种新的方法EnzyControl，用于设计具有特定底物功能的酶骨架。我们创建了一个名为EnzyBind的数据集，包含11,100对经过实验验证的酶-底物配对，以支持酶设计。EnzyControl通过利用多序列比对（MSA）注释的催化位点和相应的底物，生成条件化的酶骨架。实验结果表明，EnzyControl在结构和功能指标上表现优异，设计能力和催化效率分别提高了13%。', title='智能设计特定功能酶骨架的创新方法'))
[31.10.2025 03:41] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#cv", "#training"], "emoji": "⚖️", "ru": {"title": "Борьба с эффектом Матфея в самообучении визуальных моделей", "desc": "Исследователи обнаружили проблему в процессе самообучения больших визуально-языковых моделей (LVLMs): модели хорошо справляются с 
[31.10.2025 03:41] Using data from previous issue: {"categories": ["#multimodal", "#rag", "#benchmark", "#dataset"], "emoji": "👓", "ru": {"title": "CRAG-MM: Бенчмарк для умных очков с мультимодальными диалогами", "desc": "Исследователи создали новый бенчмарк CRAG-MM для оценки систем, отвечающих на вопросы об окружающем мире через носимые устройства
[31.10.2025 03:41] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#3d", "#dataset"], "emoji": "🧩", "ru": {"title": "Полноразмерная генерация частей: каждой детали своё пространство", "desc": "Статья представляет FullPart — новый подход к генерации 3D-объектов по частям, который комбинирует неявные (implicit) и явные (
[31.10.2025 03:41] Querying the API.
[31.10.2025 03:41] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

As LLM agents advance, they are increasingly mediating economic decisions, ranging from product discovery to transactions, on behalf of users. Such applications promise benefits but also raise many questions about agent accountability and value for users. Addressing these questions requires understanding how agents behave in realistic market conditions. However, previous research has largely evaluated agents in constrained settings, such as single-task marketplaces (e.g., negotiation) or structured two-agent interactions. Real-world markets are fundamentally different: they require agents to handle diverse economic activities and coordinate within large, dynamic ecosystems where multiple agents with opaque behaviors may engage in open-ended dialogues. To bridge this gap, we investigate two-sided agentic marketplaces where Assistant agents represent consumers and Service agents represent competing businesses. To study these interactions safely, we develop Magentic-Marketplace-- a simulated environment where Assistants and Services can operate. This environment enables us to study key market dynamics: the utility agents achieve, behavioral biases, vulnerability to manipulation, and how search mechanisms shape market outcomes. Our experiments show that frontier models can approach optimal welfare-- but only under ideal search conditions. Performance degrades sharply with scale, and all models exhibit severe first-proposal bias, creating 10-30x advantages for response speed over quality. These findings reveal how behaviors emerge across market conditions, informing the design of fair and efficient agentic marketplaces.
[31.10.2025 03:41] Response: ```json
{
  "desc": "Исследователи изучают поведение LLM-агентов в двусторонних рынках, где одни агенты представляют потребителей, а другие — конкурирующие бизнесы. Для безопасного тестирования создана симулированная среда Magentic-Marketplace, позволяющая анализировать благосостояние пользователей, поведенческие искажения и уязвимости к манипуляциям. Эксперименты показали, что современные модели могут достигать оптимальных результатов только в идеальных условиях поиска, но их производительность резко падает при масштабировании. Все модели демонстрируют сильное смещение к первому предложению (first-proposal bias), создавая преимущество в 10-30 раз для скорости ответа над качеством.",
  "emoji": "🤝",
  "title": "Агенты на рынке: скорость побеждает качество"
}
```
[31.10.2025 03:41] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"As LLM agents advance, they are increasingly mediating economic decisions, ranging from product discovery to transactions, on behalf of users. Such applications promise benefits but also raise many questions about agent accountability and value for users. Addressing these questions requires understanding how agents behave in realistic market conditions. However, previous research has largely evaluated agents in constrained settings, such as single-task marketplaces (e.g., negotiation) or structured two-agent interactions. Real-world markets are fundamentally different: they require agents to handle diverse economic activities and coordinate within large, dynamic ecosystems where multiple agents with opaque behaviors may engage in open-ended dialogues. To bridge this gap, we investigate two-sided agentic marketplaces where Assistant agents represent consumers and Service agents represent competing businesses. To study these interactions safely, we develop Magentic-Marketplace-- a simulated environment where Assistants and Services can operate. This environment enables us to study key market dynamics: the utility agents achieve, behavioral biases, vulnerability to manipulation, and how search mechanisms shape market outcomes. Our experiments show that frontier models can approach optimal welfare-- but only under ideal search conditions. Performance degrades sharply with scale, and all models exhibit severe first-proposal bias, creating 10-30x advantages for response speed over quality. These findings reveal how behaviors emerge across market conditions, informing the design of fair and efficient agentic marketplaces."

[31.10.2025 03:41] Response: ```python
['AGENTS', 'MULTIMODAL']
```
[31.10.2025 03:41] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"As LLM agents advance, they are increasingly mediating economic decisions, ranging from product discovery to transactions, on behalf of users. Such applications promise benefits but also raise many questions about agent accountability and value for users. Addressing these questions requires understanding how agents behave in realistic market conditions. However, previous research has largely evaluated agents in constrained settings, such as single-task marketplaces (e.g., negotiation) or structured two-agent interactions. Real-world markets are fundamentally different: they require agents to handle diverse economic activities and coordinate within large, dynamic ecosystems where multiple agents with opaque behaviors may engage in open-ended dialogues. To bridge this gap, we investigate two-sided agentic marketplaces where Assistant agents represent consumers and Service agents represent competing businesses. To study these interactions safely, we develop Magentic-Marketplace-- a simulated environment where Assistants and Services can operate. This environment enables us to study key market dynamics: the utility agents achieve, behavioral biases, vulnerability to manipulation, and how search mechanisms shape market outcomes. Our experiments show that frontier models can approach optimal welfare-- but only under ideal search conditions. Performance degrades sharply with scale, and all models exhibit severe first-proposal bias, creating 10-30x advantages for response speed over quality. These findings reveal how behaviors emerge across market conditions, informing the design of fair and efficient agentic marketplaces."

[31.10.2025 03:41] Response: ```python
['ETHICS', 'REASONING']
```
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how large language model (LLM) agents can influence economic decisions in real-world markets, where they act on behalf of users. It highlights the need to understand agent behavior in complex, dynamic environments rather than simplified settings. The authors introduce a simulated environment called Magentic-Marketplace to analyze interactions between consumer-representing Assistants and competing Service agents. Their findings indicate that while advanced models can achieve good outcomes under ideal conditions, they struggle with scale and exhibit biases that can significantly impact market efficiency.","title":"Navigating the Complexities of Agentic Marketplaces"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how large language model (LLM) agents can influence economic decisions in real-world markets, where they act on behalf of users. It highlights the need to understand agent behavior in complex, dynamic environments rather than simplified settings. The authors introduce a simulated environment called Magentic-Marketplace to analyze interactions between consumer-representing Assistants and competing Service agents. Their findings indicate that while advanced models can achieve good outcomes under ideal conditions, they struggle with scale and exhibit biases that can significantly impact market efficiency.', title='Navigating the Complexities of Agentic Marketplaces'))
[31.10.2025 03:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"随着大型语言模型（LLM）代理的发展，它们在经济决策中扮演着越来越重要的角色，包括产品发现和交易。这些应用虽然带来了好处，但也引发了关于代理责任和用户价值的许多问题。为了理解代理在现实市场条件下的行为，我们开发了Magentic-Marketplace，一个模拟环境，研究消费者代理和竞争企业代理之间的互动。实验结果表明，尽管前沿模型在理想搜索条件下可以接近最佳福利，但在规模扩大时性能急剧下降，所有模型都表现出严重的首次提案偏见，导致响应速度相对于质量有10-30倍的优势。","title":"探索代理市场的公平与效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='随着大型语言模型（LLM）代理的发展，它们在经济决策中扮演着越来越重要的角色，包括产品发现和交易。这些应用虽然带来了好处，但也引发了关于代理责任和用户价值的许多问题。为了理解代理在现实市场条件下的行为，我们开发了Magentic-Marketplace，一个模拟环境，研究消费者代理和竞争企业代理之间的互动。实验结果表明，尽管前沿模型在理想搜索条件下可以接近最佳福利，但在规模扩大时性能急剧下降，所有模型都表现出严重的首次提案偏见，导致响应速度相对于质量有10-30倍的优势。', title='探索代理市场的公平与效率'))
[31.10.2025 03:41] Renaming data file.
[31.10.2025 03:41] Renaming previous data. hf_papers.json to ./d/2025-10-31.json
[31.10.2025 03:41] Saving new data file.
[31.10.2025 03:41] Generating page.
[31.10.2025 03:41] Renaming previous page.
[31.10.2025 03:41] Renaming previous data. index.html to ./d/2025-10-31.html
[31.10.2025 03:41] Writing result.
[31.10.2025 03:41] Renaming log file.
[31.10.2025 03:41] Renaming previous data. log.txt to ./logs/2025-10-31_last_log.txt
