[30.12.2024 07:11] Read previous papers.
[30.12.2024 07:11] Generating top page (month).
[30.12.2024 07:11] Writing top page (month).
[30.12.2024 08:13] Read previous papers.
[30.12.2024 08:13] Get feed.
[30.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18925
[30.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18605
[30.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.19326
[30.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.19712
[30.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.17606
[30.12.2024 08:13] Extract page data from URL. URL: https://huggingface.co/papers/2412.17762
[30.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.19645
[30.12.2024 08:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[30.12.2024 08:13] No deleted papers detected.
[30.12.2024 08:13] Downloading and parsing papers (pdf, html). Total: 7.
[30.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.18925.
[30.12.2024 08:13] Extra JSON file exists (./assets/json/2412.18925.json), skip PDF parsing.
[30.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.18925.json), skip HTML parsing.
[30.12.2024 08:13] Success.
[30.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.18605.
[30.12.2024 08:13] Extra JSON file exists (./assets/json/2412.18605.json), skip PDF parsing.
[30.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.18605.json), skip HTML parsing.
[30.12.2024 08:13] Success.
[30.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.19326.
[30.12.2024 08:13] Extra JSON file exists (./assets/json/2412.19326.json), skip PDF parsing.
[30.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.19326.json), skip HTML parsing.
[30.12.2024 08:13] Success.
[30.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.19712.
[30.12.2024 08:13] Extra JSON file exists (./assets/json/2412.19712.json), skip PDF parsing.
[30.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.19712.json), skip HTML parsing.
[30.12.2024 08:13] Success.
[30.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.17606.
[30.12.2024 08:13] Extra JSON file exists (./assets/json/2412.17606.json), skip PDF parsing.
[30.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.17606.json), skip HTML parsing.
[30.12.2024 08:13] Success.
[30.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.17762.
[30.12.2024 08:13] Downloading paper 2412.17762 from http://arxiv.org/pdf/2412.17762v1...
[30.12.2024 08:14] Extracting affiliations from text.
[30.12.2024 08:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"THE SUPERPOSITION OF DIFFUSION MODELS USING THE IT√î DENSITY ESTIMATOR Marta Skreta,1,2 Lazar Atanackovic,1,2 Avishek Joey Bose3,4 Alexander Tong4,5 Kirill Neklyudov4,5, 1University of Toronto 4Mila - Quebec AI Institute 5Universit√© de Montr√©al 3University of Oxford 2Vector Institute 4 2 0 D 3 2 ] . [ 1 2 6 7 7 1 . 2 1 4 2 : r a "
[30.12.2024 08:14] Response: ```python
[
    "University of Toronto",
    "Mila - Quebec AI Institute",
    "Universit√© de Montr√©al",
    "University of Oxford",
    "Vector Institute"
]
```
[30.12.2024 08:14] Deleting PDF ./assets/pdf/2412.17762.pdf.
[30.12.2024 08:14] Success.
[30.12.2024 08:14] Downloading and parsing paper https://huggingface.co/papers/2412.19645.
[30.12.2024 08:14] Extra JSON file exists (./assets/json/2412.19645.json), skip PDF parsing.
[30.12.2024 08:14] Paper image links file exists (./assets/img_data/2412.19645.json), skip HTML parsing.
[30.12.2024 08:14] Success.
[30.12.2024 08:14] Enriching papers with extra data.
[30.12.2024 08:14] ********************************************************************************
[30.12.2024 08:14] Abstract 0. The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning to improve LLM. Yet, most research in reasoning has focused on mathematical tasks, leaving domains like medicine underexplored. The medical domain, though distinct from mathematics, also demands robust reasoning to provide...
[30.12.2024 08:14] ********************************************************************************
[30.12.2024 08:14] Abstract 1. Orientation is a key attribute of objects, crucial for understanding their spatial pose and arrangement in images. However, practical solutions for accurate orientation estimation from a single image remain underexplored. In this work, we introduce Orient Anything, the first expert and foundational ...
[30.12.2024 08:14] ********************************************************************************
[30.12.2024 08:14] Abstract 2. Current multimodal large language models (MLLMs) struggle with fine-grained or precise understanding of visuals though they give comprehensive perception and reasoning in a spectrum of vision applications. Recent studies either develop tool-using or unify specific visual tasks into the autoregressiv...
[30.12.2024 08:14] ********************************************************************************
[30.12.2024 08:14] Abstract 3. In this work, we investigate automatic design composition from multimodal graphic elements. Although recent studies have developed various generative models for graphic design, they usually face the following limitations: they only focus on certain subtasks and are far from achieving the design comp...
[30.12.2024 08:14] ********************************************************************************
[30.12.2024 08:14] Abstract 4. Building a large-scale figure QA dataset requires a considerable amount of work, from gathering and selecting figures to extracting attributes like text, numbers, and colors, and generating QAs. Although recent developments in LLMs have led to efforts to synthesize figures, most of these focus prima...
[30.12.2024 08:14] ********************************************************************************
[30.12.2024 08:14] Abstract 5. The Cambrian explosion of easily accessible pre-trained diffusion models suggests a demand for methods that combine multiple different pre-trained diffusion models without incurring the significant computational burden of re-training a larger combined model. In this paper, we cast the problem of com...
[30.12.2024 08:14] ********************************************************************************
[30.12.2024 08:14] Abstract 6. Zero-shot customized video generation has gained significant attention due to its substantial application potential. Existing methods rely on additional models to extract and inject reference subject features, assuming that the Video Diffusion Model (VDM) alone is insufficient for zero-shot customiz...
[30.12.2024 08:14] Read previous papers.
[30.12.2024 08:14] Generating reviews via LLM API.
[30.12.2024 08:14] Using data from previous issue: {"categories": ["#reasoning", "#healthcare", "#training", "#rl"], "emoji": "ü©∫", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –ò–ò-–º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ–º—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Å—Ñ–µ—Ä–µ. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
[30.12.2024 08:14] Using data from previous issue: {"categories": ["#synthetic", "#cv", "#training", "#dataset", "#3d", "#transfer_learning"], "emoji": "üß≠", "ru": {"title": "Orient Anything: —Ç–æ—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å Orient Anything –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä
[30.12.2024 08:14] Using data from previous issue: {"categories": ["#multimodal", "#games", "#training", "#optimization"], "emoji": "üîç", "ru": {"title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –∑–∞–¥–∞—á: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Task Preference Optimization (TPO) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º
[30.12.2024 08:14] Using data from previous issue: {"categories": ["#cv", "#multimodal"], "emoji": "üé®", "ru": {"title": "–ü–æ—Å–ª–æ–π–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –¥–∏–∑–∞–π–Ω–∞ —Å –ø–æ–º–æ—â—å—é –±–æ–ª—å—à–∏—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í –¥–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏–∑–∞–π–Ω-–∫–æ–º–ø–æ–∑–∏—Ü–∏–π –∏–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
[30.12.2024 08:14] Using data from previous issue: {"categories": ["#training", "#dataset", "#optimization", "#data", "#synthetic"], "emoji": "üìä", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ò–ò –∞–Ω–∞–ª–∏–∑—É –≥—Ä–∞—Ñ–∏–∫–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SBSFigures - –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º. –ê–≤—Ç
[30.12.2024 08:14] Querying the API.
[30.12.2024 08:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The Cambrian explosion of easily accessible pre-trained diffusion models suggests a demand for methods that combine multiple different pre-trained diffusion models without incurring the significant computational burden of re-training a larger combined model. In this paper, we cast the problem of combining multiple pre-trained diffusion models at the generation stage under a novel proposed framework termed superposition. Theoretically, we derive superposition from rigorous first principles stemming from the celebrated continuity equation and design two novel algorithms tailor-made for combining diffusion models in SuperDiff. SuperDiff leverages a new scalable It\^o density estimator for the log likelihood of the diffusion SDE which incurs no additional overhead compared to the well-known Hutchinson's estimator needed for divergence calculations. We demonstrate that SuperDiff is scalable to large pre-trained diffusion models as superposition is performed solely through composition during inference, and also enjoys painless implementation as it combines different pre-trained vector fields through an automated re-weighting scheme. Notably, we show that SuperDiff is efficient during inference time, and mimics traditional composition operators such as the logical OR and the logical AND. We empirically demonstrate the utility of using SuperDiff for generating more diverse images on CIFAR-10, more faithful prompt conditioned image editing using Stable Diffusion, and improved unconditional de novo structure design of proteins. https://github.com/necludov/super-diffusion
[30.12.2024 08:14] Error getting data: Error code: 500 - {'type': 'error', 'error': {'type': 'api_error', 'message': 'Internal server error'}}
[30.12.2024 08:14] Using data from previous issue: {"categories": ["#cv", "#video", "#diffusion"], "emoji": "üé¨", "ru": {"title": "–†–∞—Å–∫—Ä—ã—Ç–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ VDM –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å –Ω—É–ª–µ–≤—ã–º –æ–±—É—á–µ–Ω–∏–µ–º. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
[30.12.2024 08:14] Loading Chinese text from previous data.
[30.12.2024 08:14] Renaming data file.
[30.12.2024 08:14] Renaming previous data. hf_papers.json to ./d/2024-12-30.json
[30.12.2024 08:14] Saving new data file.
[30.12.2024 08:14] Generating page.
[30.12.2024 08:14] Renaming previous page.
[30.12.2024 08:14] Renaming previous data. index.html to ./d/2024-12-30.html
[30.12.2024 08:14] [Experimental] Generating Chinese page for reading.
[30.12.2024 08:14] Chinese vocab [{'word': 'ÂçìË∂ä', 'pinyin': 'zhu√≥ yu√®', 'trans': 'outstanding'}, {'word': 'Ê∏ÖÊ¥ó', 'pinyin': 'qƒ´ng x«ê', 'trans': 'cleaning'}, {'word': '‰ºòÂåñ', 'pinyin': 'y≈çu hu√†', 'trans': 'optimization'}, {'word': 'ÈÄÄÁÅ´', 'pinyin': 'tu√¨ hu«í', 'trans': 'annealing'}, {'word': 'Â™≤Áæé', 'pinyin': 'p√¨ mƒõi', 'trans': 'rival'}, {'word': 'È¢ÜÂÖà', 'pinyin': 'l«êng xiƒÅn', 'trans': 'leading'}]
[30.12.2024 08:14] Renaming previous Chinese page.
[30.12.2024 08:14] Renaming previous data. zh.html to ./d/2024-12-29_zh_reading_task.html
[30.12.2024 08:14] Writing Chinese reading task.
[30.12.2024 08:14] Writing result.
[30.12.2024 08:14] Renaming log file.
[30.12.2024 08:14] Renaming previous data. log.txt to ./logs/2024-12-30_last_log.txt
