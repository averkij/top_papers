[31.12.2024 07:10] Read previous papers.
[31.12.2024 07:10] Generating top page (month).
[31.12.2024 07:10] Writing top page (month).
[31.12.2024 08:13] Read previous papers.
[31.12.2024 08:13] Get feed.
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.20070
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18525
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.20993
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.21079
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.20422
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.21037
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.21199
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.21139
[31.12.2024 08:13] Get page data from previous paper. URL: https://huggingface.co/papers/2412.20005
[31.12.2024 08:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.12.2024 08:13] No deleted papers detected.
[31.12.2024 08:13] Downloading and parsing papers (pdf, html). Total: 9.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.20070.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.20070.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.20070.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.18525.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.18525.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.18525.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.20993.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.20993.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.20993.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.21079.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.21079.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.21079.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.20422.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.20422.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.20422.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.21037.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.21037.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.21037.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.21199.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.21199.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.21199.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.21139.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.21139.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.21139.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Downloading and parsing paper https://huggingface.co/papers/2412.20005.
[31.12.2024 08:13] Extra JSON file exists (./assets/json/2412.20005.json), skip PDF parsing.
[31.12.2024 08:13] Paper image links file exists (./assets/img_data/2412.20005.json), skip HTML parsing.
[31.12.2024 08:13] Success.
[31.12.2024 08:13] Enriching papers with extra data.
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 0. Multimodal large language models (MLLMs) hold significant potential in the medical field, but their capabilities are often limited by insufficient data in certain medical domains, highlighting the need for understanding what kinds of images can be used by MLLMs for generalization. Current research s...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 1. Computer Vision (CV) has yet to fully achieve the zero-shot task generalization observed in Natural Language Processing (NLP), despite following many of the milestones established in NLP, such as large transformer models, extensive pre-training, and the auto-regression paradigm, among others. In thi...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 2. The rapid evolution of large language models (LLMs) has unlocked their capabilities in advanced reasoning tasks like mathematical problem-solving, code generation, and legal analysis. Central to this progress are inference-time reasoning algorithms, which refine outputs by exploring multiple solutio...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 3. As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments. Edicho steps in with a training-free solution based on diffusion models, featuring a fundame...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 4. Recent advancements in generative modeling now enable the creation of 4D content (moving 3D objects) controlled with text prompts. 4D generation has large potential in applications like virtual worlds, media, and gaming, but existing methods provide limited control over the appearance and geometry o...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 5. We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models lies in the difficulty of creating preference pairs, as TTA lacks st...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 6. We introduce self-invoking code generation, a new task designed to evaluate the progressive reasoning and problem-solving capabilities of LLMs. In this task, models are presented with a base problem and a related, more complex problem. They must solve the base problem and then utilize its solution t...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 7. We present SWE-Gym, the first environment for training real-world software engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task instances, each comprising a codebase with an executable runtime environment, unit tests, and a task specified in natural language. We use SWE-Gym to tra...
[31.12.2024 08:13] ********************************************************************************
[31.12.2024 08:13] Abstract 8. We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their...
[31.12.2024 08:13] Read previous papers.
[31.12.2024 08:13] Generating reviews via LLM API.
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#dataset", "#healthcare", "#open_source", "#multimodal", "#transfer_learning"], "emoji": "ü©∫", "ru": {"title": "–ö–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è - –∫–ª—é—á –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è MLLM", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM) –≤ –º
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#cv", "#multimodal", "#transfer_learning"], "emoji": "üî¨", "ru": {"title": "–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ - –∫–ª—é—á –∫ –æ–±–æ–±—â–µ–Ω–∏—é –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∫ –æ–±–æ–±—â–µ–Ω–∏—é –Ω–∞ –Ω
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#inference"], "emoji": "üß†", "ru": {"title": "Dynasor: —É–º–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö LLM-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º—É Dynasor, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—é—â—É—é –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è –∑–∞–¥–∞—á —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–æ–ª—å—à–∏—Ö —è–∑—ã
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#open_source", "#inference"], "emoji": "üñºÔ∏è", "ru": {"title": "Edicho: —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Edicho - —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#games", "#diffusion", "#video", "#3d"], "emoji": "üé≠", "ru": {"title": "–û–∂–∏–≤–ª–µ–Ω–∏–µ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–∞: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–º –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∞–Ω–∏–º–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–¥—Å–∫–∞–∑–æ–∫. –ê–≤—Ç
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#dataset", "#audio", "#open_source", "#benchmark", "#alignment", "#rlhf", "#small_models"], "emoji": "üéµ", "ru": {"title": "TangoFlux: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞", "desc": "TangoFlux - —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ –∞—É–¥–∏–æ (Text-to-Audio, TT
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#training", "#benchmark"], "emoji": "üß†", "ru": {"title": "–°–∞–º–æ–≤—ã–∑—ã–≤–∞—é—â–∏–π—Å—è –∫–æ–¥: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) - –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–∞–º–æ–≤—ã–∑—ã–≤–∞—é—â–µ–≥–æ—Å—è –∫–æ–¥–∞. –í —Ä–∞–º–∫–∞—Ö —ç—Ç–æ–π –∑–∞–¥
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#agents", "#training"], "emoji": "ü§ñ", "ru": {"title": "SWE-Gym: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ü–û", "desc": "SWE-Gym - —ç—Ç–æ –Ω–æ–≤–∞—è —Å—Ä–µ–¥–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–π –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö. –û–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç 2438 —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –∑–∞–¥–∞—á –Ω–∞ P
[31.12.2024 08:13] Using data from previous issue: {"categories": ["#dataset", "#agents", "#open_source", "#benchmark", "#multimodal", "#science"], "emoji": "üß†", "ru": {"title": "OneKE: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ —Ä–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤", "desc": "OneKE - —ç—Ç–æ –¥–æ–∫–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π, —É–ø—Ä–∞–≤–ª—è–µ–º–∞—è —Å—Ö–µ–º–æ–π. –û–Ω–∞ —Å–ø–æ
[31.12.2024 08:13] Loading Chinese text from previous data.
[31.12.2024 08:13] Renaming data file.
[31.12.2024 08:13] Renaming previous data. hf_papers.json to ./d/2024-12-31.json
[31.12.2024 08:13] Saving new data file.
[31.12.2024 08:13] Generating page.
[31.12.2024 08:13] Renaming previous page.
[31.12.2024 08:13] Renaming previous data. index.html to ./d/2024-12-31.html
[31.12.2024 08:13] [Experimental] Generating Chinese page for reading.
[31.12.2024 08:13] Can't parse vocab. Expecting ',' delimiter: line 1 column 675 (char 674)
[31.12.2024 08:13] Chinese vocab []
[31.12.2024 08:13] Renaming previous Chinese page.
[31.12.2024 08:13] Renaming previous data. zh.html to ./d/2024-12-30_zh_reading_task.html
[31.12.2024 08:13] Writing Chinese reading task.
[31.12.2024 08:13] Writing result.
[31.12.2024 08:13] Renaming log file.
[31.12.2024 08:13] Renaming previous data. log.txt to ./logs/2024-12-31_last_log.txt
