[31.12.2024 03:14] Read previous papers.
[31.12.2024 03:14] Generating top page (month).
[31.12.2024 03:14] Writing top page (month).
[31.12.2024 04:12] Read previous papers.
[31.12.2024 04:12] Get feed.
[31.12.2024 04:12] Extract page data from URL. URL: https://huggingface.co/papers/2412.20070
[31.12.2024 04:12] Extract page data from URL. URL: https://huggingface.co/papers/2412.21079
[31.12.2024 04:12] Extract page data from URL. URL: https://huggingface.co/papers/2412.20005
[31.12.2024 04:12] Extract page data from URL. URL: https://huggingface.co/papers/2412.21037
[31.12.2024 04:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.12.2024 04:12] Downloading and parsing papers (pdf, html). Total: 4.
[31.12.2024 04:12] Downloading and parsing paper https://huggingface.co/papers/2412.20070.
[31.12.2024 04:12] Downloading paper 2412.20070 from http://arxiv.org/pdf/2412.20070v1...
[31.12.2024 04:12] Extracting affiliations from text.
[31.12.2024 04:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang The Chinese University of Hong Kong, Shenzhen wangbenyou@cuhk.edu.cn 4 2 0 2 8 2 ] . [ 1 0 7 0 0 2 . 2 1 4 2 : r a "
[31.12.2024 04:12] Response: ```python
["The Chinese University of Hong Kong, Shenzhen"]
```
[31.12.2024 04:12] Deleting PDF ./assets/pdf/2412.20070.pdf.
[31.12.2024 04:12] Success.
[31.12.2024 04:12] Downloading and parsing paper https://huggingface.co/papers/2412.21079.
[31.12.2024 04:12] Downloading paper 2412.21079 from http://arxiv.org/pdf/2412.21079v1...
[31.12.2024 04:12] Extracting affiliations from text.
[31.12.2024 04:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Edicho: Consistent Image Editing in the Wild Qingyan Bai1 Hao Ouyang2 Yinghao Xu3 Qiuyu Wang2 Ceyuan Yang4 Ka Leong Cheng1 Yujun Shen2 Qifeng Chen1 1HKUST 2Ant Group 3Stanford University 4CUHK 4 2 0 2 0 3 ] . [ 1 9 7 0 1 2 . 2 1 4 2 : r Figure 1. Given two images in the wild, Edicho generates consistent editing versions of them in zero-shot manner. Our approach achieves precise consistency for editing parts (left), objects (middle), and the entire images (right) by leveraging explicit correspondence. "
[31.12.2024 04:12] Response: ```python
["HKUST", "Ant Group", "Stanford University", "CUHK"]
```
[31.12.2024 04:12] Deleting PDF ./assets/pdf/2412.21079.pdf.
[31.12.2024 04:12] Success.
[31.12.2024 04:12] Downloading and parsing paper https://huggingface.co/papers/2412.20005.
[31.12.2024 04:12] Downloading paper 2412.20005 from http://arxiv.org/pdf/2412.20005v1...
[31.12.2024 04:12] Extracting affiliations from text.
[31.12.2024 04:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"OneKE: Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System Xiangyuan Ru Kangwei Liu Zhejiang University ZJU-Ant Group Joint Research Center for Knowledge Graphs Hangzhou, China Lin Yuan Mengshu Sun ZJU-Ant Group Joint Research Center for Knowledge Graphs Ant Group Hangzhou, China Yujie Luo luo.yj@zju.edu.cn Zhejiang University ZJU-Ant Group Joint Research Center for Knowledge Graphs Hangzhou, China 4 2 0 2 8 2 ] . [ 1 5 0 0 0 2 . 2 1 4 2 : r Ningyu Zhang* Zhejiang University ZJU-Ant Group Joint Research Center for Knowledge Graphs Hangzhou, China Lei Liang Zhiqiang Zhang ZJU-Ant Group Joint Research Center for Knowledge Graphs Ant Group Hangzhou, China Jun Zhou* ZJU-Ant Group Joint Research Center for Knowledge Graphs Ant Group Hangzhou, China Lanning Wei Da Zheng ZJU-Ant Group Joint Research Center for Knowledge Graphs Ant Group Hangzhou, China Haofen Wang Tongji University Shanghai, China Huajun Chen* Zhejiang University ZJU-Ant Group Joint Research Center for Knowledge Graphs Hangzhou, China Abstract We introduce OneKE, dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKEs efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code1 and released Video2. Keywords Information Extraction; Natural Language Processing; Large Language Models 1https://github.com/zjunlp/OneKE 2http://oneke.openkg.cn/demo.mp4 Permission to make digital or hard copies"
[31.12.2024 04:12] Response: ```python
[
    "Zhejiang University",
    "ZJU-Ant Group Joint Research Center for Knowledge Graphs",
    "Ant Group",
    "Tongji University"
]
```
[31.12.2024 04:12] Deleting PDF ./assets/pdf/2412.20005.pdf.
[31.12.2024 04:12] Success.
[31.12.2024 04:12] Downloading and parsing paper https://huggingface.co/papers/2412.21037.
[31.12.2024 04:12] Downloading paper 2412.21037 from http://arxiv.org/pdf/2412.21037v1...
[31.12.2024 04:12] Extracting affiliations from text.
[31.12.2024 04:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"4 2 0 2 0 3 ] . [ 1 7 3 0 1 2 . 2 1 4 2 : r TANGOFLUX: SUPER FAST AND FAITHFUL TEXT TO AUDIO GENERATION WITH FLOW MATCHING AND CLAP-RANKED PREFERENCE OPTIMIZATION Chia-Yu Hung1 Navonil Majumder1 Zhifeng Kong2 Ambuj Mehrish1 Rafael Valle2 Bryan Catanzaro Soujanya Poria1 1Singapore University of Technology and Design (SUTD) 2NVIDIA {chiayu hung, navonil majumder, ambuj mehrish, sporia}@sutd.edu.sg {zkong, rafaelvalle, bcatanzaro}@nvidia.com Website https://tangoflux.github.io Code Repository https://github.com/declare-lab/TangoFlux Pretrained Model https://huggingface.co/declare-lab/TangoFlux Dataset Fork https://huggingface.co/datasets/declare-lab/CRPO Interactive Demo https://huggingface.co/spaces/declare-lab/TangoFlux "
[31.12.2024 04:12] Response: ```python
["Singapore University of Technology and Design (SUTD)", "NVIDIA"]
```
[31.12.2024 04:12] Deleting PDF ./assets/pdf/2412.21037.pdf.
[31.12.2024 04:13] Success.
[31.12.2024 04:13] Enriching papers with extra data.
[31.12.2024 04:13] ********************************************************************************
[31.12.2024 04:13] Abstract 0. Multimodal large language models (MLLMs) hold significant potential in the medical field, but their capabilities are often limited by insufficient data in certain medical domains, highlighting the need for understanding what kinds of images can be used by MLLMs for generalization. Current research s...
[31.12.2024 04:13] ********************************************************************************
[31.12.2024 04:13] Abstract 1. As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments. Edicho steps in with a training-free solution based on diffusion models, featuring a fundame...
[31.12.2024 04:13] ********************************************************************************
[31.12.2024 04:13] Abstract 2. We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their...
[31.12.2024 04:13] ********************************************************************************
[31.12.2024 04:13] Abstract 3. We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models lies in the difficulty of creating preference pairs, as TTA lacks st...
[31.12.2024 04:13] Read previous papers.
[31.12.2024 04:13] Generating reviews via LLM API.
[31.12.2024 04:13] Querying the API.
[31.12.2024 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Multimodal large language models (MLLMs) hold significant potential in the medical field, but their capabilities are often limited by insufficient data in certain medical domains, highlighting the need for understanding what kinds of images can be used by MLLMs for generalization. Current research suggests that multi-task training outperforms single-task as different tasks can benefit each other, but they often overlook the internal relationships within these tasks, providing limited guidance on selecting datasets to enhance specific tasks. To analyze this phenomenon, we attempted to employ compositional generalization (CG)-the ability of models to understand novel combinations by recombining learned elements-as a guiding framework. Since medical images can be precisely defined by Modality, Anatomical area, and Task, naturally providing an environment for exploring CG. Therefore, we assembled 106 medical datasets to create Med-MAT for comprehensive experiments. The experiments confirmed that MLLMs can use CG to understand unseen medical images and identified CG as one of the main drivers of the generalization observed in multi-task training. Additionally, further studies demonstrated that CG effectively supports datasets with limited data and delivers consistent performance across different backbones, highlighting its versatility and broad applicability. Med-MAT is publicly available at https://github.com/FreedomIntelligence/Med-MAT.
[31.12.2024 04:13] Response: {
  "desc": "Статья исследует возможности мультимодальных больших языковых моделей (MLLM) в медицинской сфере, фокусируясь на композиционной генерализации (CG). Авторы создали набор данных Med-MAT из 106 медицинских датасетов для изучения способности моделей понимать новые комбинации изображений. Эксперименты показали, что MLLM могут использовать CG для интерпретации ранее невиданных медицинских изображений. Исследование также выявило эффективность CG для датасетов с ограниченными данными и стабильность результатов на разных архитектурах моделей.",
  "emoji": "🩺",
  "title": "Композиционная генерализация - ключ к пониманию медицинских изображений для MLLM"
}
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multimodal large language models (MLLMs) hold significant potential in the medical field, but their capabilities are often limited by insufficient data in certain medical domains, highlighting the need for understanding what kinds of images can be used by MLLMs for generalization. Current research suggests that multi-task training outperforms single-task as different tasks can benefit each other, but they often overlook the internal relationships within these tasks, providing limited guidance on selecting datasets to enhance specific tasks. To analyze this phenomenon, we attempted to employ compositional generalization (CG)-the ability of models to understand novel combinations by recombining learned elements-as a guiding framework. Since medical images can be precisely defined by Modality, Anatomical area, and Task, naturally providing an environment for exploring CG. Therefore, we assembled 106 medical datasets to create Med-MAT for comprehensive experiments. The experiments confirmed that MLLMs can use CG to understand unseen medical images and identified CG as one of the main drivers of the generalization observed in multi-task training. Additionally, further studies demonstrated that CG effectively supports datasets with limited data and delivers consistent performance across different backbones, highlighting its versatility and broad applicability. Med-MAT is publicly available at https://github.com/FreedomIntelligence/Med-MAT."

[31.12.2024 04:13] Response: ```python
['DATASET', 'MULTIMODAL', 'HEALTHCARE']
```
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multimodal large language models (MLLMs) hold significant potential in the medical field, but their capabilities are often limited by insufficient data in certain medical domains, highlighting the need for understanding what kinds of images can be used by MLLMs for generalization. Current research suggests that multi-task training outperforms single-task as different tasks can benefit each other, but they often overlook the internal relationships within these tasks, providing limited guidance on selecting datasets to enhance specific tasks. To analyze this phenomenon, we attempted to employ compositional generalization (CG)-the ability of models to understand novel combinations by recombining learned elements-as a guiding framework. Since medical images can be precisely defined by Modality, Anatomical area, and Task, naturally providing an environment for exploring CG. Therefore, we assembled 106 medical datasets to create Med-MAT for comprehensive experiments. The experiments confirmed that MLLMs can use CG to understand unseen medical images and identified CG as one of the main drivers of the generalization observed in multi-task training. Additionally, further studies demonstrated that CG effectively supports datasets with limited data and delivers consistent performance across different backbones, highlighting its versatility and broad applicability. Med-MAT is publicly available at https://github.com/FreedomIntelligence/Med-MAT."

[31.12.2024 04:13] Response: ```python
['TRANSFER_LEARNING', 'OPEN_SOURCE']
```
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the use of multimodal large language models (MLLMs) in the medical field, focusing on how they can generalize from limited data. It highlights the advantages of multi-task training over single-task training, emphasizing the importance of understanding the relationships between different tasks. The authors introduce compositional generalization (CG) as a framework to enhance the model\'s ability to interpret new combinations of medical images. They created a dataset called Med-MAT, which consists of 106 medical datasets, and found that CG significantly improves the performance of MLLMs, especially in scenarios with scarce data.","title":"Unlocking Medical Insights with Compositional Generalization"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc="This paper explores the use of multimodal large language models (MLLMs) in the medical field, focusing on how they can generalize from limited data. It highlights the advantages of multi-task training over single-task training, emphasizing the importance of understanding the relationships between different tasks. The authors introduce compositional generalization (CG) as a framework to enhance the model's ability to interpret new combinations of medical images. They created a dataset called Med-MAT, which consists of 106 medical datasets, and found that CG significantly improves the performance of MLLMs, especially in scenarios with scarce data.", title='Unlocking Medical Insights with Compositional Generalization'))
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"多模态大型语言模型（MLLMs）在医学领域具有重要潜力，但在某些医学领域的数据不足限制了其能力。当前研究表明，多任务训练优于单任务训练，因为不同任务可以相互促进，但往往忽视了这些任务之间的内部关系。我们采用组合泛化（CG）作为指导框架，分析模型如何理解新组合的能力，并组建了106个医学数据集以创建Med-MAT进行全面实验。实验结果确认，MLLMs能够利用CG理解未见过的医学图像，并且CG是多任务训练中观察到的泛化的主要驱动因素之一。","title":"组合泛化助力医学图像理解"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='多模态大型语言模型（MLLMs）在医学领域具有重要潜力，但在某些医学领域的数据不足限制了其能力。当前研究表明，多任务训练优于单任务训练，因为不同任务可以相互促进，但往往忽视了这些任务之间的内部关系。我们采用组合泛化（CG）作为指导框架，分析模型如何理解新组合的能力，并组建了106个医学数据集以创建Med-MAT进行全面实验。实验结果确认，MLLMs能够利用CG理解未见过的医学图像，并且CG是多任务训练中观察到的泛化的主要驱动因素之一。', title='组合泛化助力医学图像理解'))
[31.12.2024 04:13] Querying the API.
[31.12.2024 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments. Edicho steps in with a training-free solution based on diffusion models, featuring a fundamental design principle of using explicit image correspondence to direct editing. Specifically, the key components include an attention manipulation module and a carefully refined classifier-free guidance (CFG) denoising strategy, both of which take into account the pre-estimated correspondence. Such an inference-time algorithm enjoys a plug-and-play nature and is compatible to most diffusion-based editing methods, such as ControlNet and BrushNet. Extensive results demonstrate the efficacy of Edicho in consistent cross-image editing under diverse settings. We will release the code to facilitate future studies.
[31.12.2024 04:13] Response: {
  "desc": "Статья представляет Edicho - решение для согласованного редактирования изображений без обучения, основанное на диффузионных моделях. Ключевые компоненты включают модуль манипуляции вниманием и стратегию шумоподавления без классификатора, использующие предварительно оцененное соответствие между изображениями. Этот алгоритм совместим с большинством методов редактирования на основе диффузии, таких как ControlNet и BrushNet. Результаты демонстрируют эффективность Edicho в согласованном редактировании изображений в различных условиях.",
  "emoji": "🖼️",
  "title": "Edicho: согласованное редактирование изображений без обучения"
}
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments. Edicho steps in with a training-free solution based on diffusion models, featuring a fundamental design principle of using explicit image correspondence to direct editing. Specifically, the key components include an attention manipulation module and a carefully refined classifier-free guidance (CFG) denoising strategy, both of which take into account the pre-estimated correspondence. Such an inference-time algorithm enjoys a plug-and-play nature and is compatible to most diffusion-based editing methods, such as ControlNet and BrushNet. Extensive results demonstrate the efficacy of Edicho in consistent cross-image editing under diverse settings. We will release the code to facilitate future studies."

[31.12.2024 04:13] Response: ```python
["INFERENCE", "CV"]
```
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments. Edicho steps in with a training-free solution based on diffusion models, featuring a fundamental design principle of using explicit image correspondence to direct editing. Specifically, the key components include an attention manipulation module and a carefully refined classifier-free guidance (CFG) denoising strategy, both of which take into account the pre-estimated correspondence. Such an inference-time algorithm enjoys a plug-and-play nature and is compatible to most diffusion-based editing methods, such as ControlNet and BrushNet. Extensive results demonstrate the efficacy of Edicho in consistent cross-image editing under diverse settings. We will release the code to facilitate future studies."

[31.12.2024 04:13] Response: ```python
['DIFFUSION', 'OPEN_SOURCE']
```
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Edicho, a novel approach for consistent editing of images that addresses challenges like varying object poses and lighting. It utilizes diffusion models without the need for prior training, focusing on explicit image correspondence to guide the editing process. Key innovations include an attention manipulation module and a refined classifier-free guidance denoising strategy, which enhance the editing quality by considering pre-estimated correspondences. The method is designed to be easily integrated with existing diffusion-based editing techniques, showing strong performance across different scenarios.","title":"Edicho: Consistent Image Editing Made Easy with Diffusion Models"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper introduces Edicho, a novel approach for consistent editing of images that addresses challenges like varying object poses and lighting. It utilizes diffusion models without the need for prior training, focusing on explicit image correspondence to guide the editing process. Key innovations include an attention manipulation module and a refined classifier-free guidance denoising strategy, which enhance the editing quality by considering pre-estimated correspondences. The method is designed to be easily integrated with existing diffusion-based editing techniques, showing strong performance across different scenarios.', title='Edicho: Consistent Image Editing Made Easy with Diffusion Models'))
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Edicho 是一种基于扩散模型的无训练解决方案，旨在解决在不同环境下进行一致性图像编辑的挑战。它的设计原则是利用显式图像对应关系来指导编辑，确保在不同的拍摄条件下保持一致性。该方法包括一个注意力操作模块和经过精细调整的无分类器引导去噪策略，能够有效处理预估的对应关系。Edicho 具有即插即用的特性，兼容大多数基于扩散的编辑方法，实验结果显示其在多种设置下的有效性。","title":"Edicho：无训练一致性图像编辑的新方法"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='Edicho 是一种基于扩散模型的无训练解决方案，旨在解决在不同环境下进行一致性图像编辑的挑战。它的设计原则是利用显式图像对应关系来指导编辑，确保在不同的拍摄条件下保持一致性。该方法包括一个注意力操作模块和经过精细调整的无分类器引导去噪策略，能够有效处理预估的对应关系。Edicho 具有即插即用的特性，兼容大多数基于扩散的编辑方法，实验结果显示其在多种设置下的有效性。', title='Edicho：无训练一致性图像编辑的新方法'))
[31.12.2024 04:13] Querying the API.
[31.12.2024 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE's efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code at https://github.com/zjunlp/OneKE and released a Video at http://oneke.openkg.cn/demo.mp4.
[31.12.2024 04:13] Response: {
  "desc": "OneKE - это докеризованная система извлечения знаний, управляемая схемой. Она способна извлекать информацию из веб-ресурсов и PDF-книг, поддерживая различные домены, такие как наука и новости. Система использует множество агентов и настраиваемую базу знаний для выполнения различных сценариев извлечения. OneKE демонстрирует высокую эффективность на эталонных наборах данных и адаптируемость к разнообразным задачам в различных областях.",
  "emoji": "🧠",
  "title": "OneKE: Универсальный инструмент для извлечения знаний из разнородных источников"
}
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE's efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code at https://github.com/zjunlp/OneKE and released a Video at http://oneke.openkg.cn/demo.mp4."

[31.12.2024 04:13] Response: ```python
['AGENTS', 'DATASET', 'BENCHMARK', 'MULTIMODAL']
```
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE's efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code at https://github.com/zjunlp/OneKE and released a Video at http://oneke.openkg.cn/demo.mp4."

[31.12.2024 04:13] Response: ```python
['OPEN_SOURCE', 'SCIENCE']
```
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"OneKE is a knowledge extraction system designed to gather information from the Web and raw PDF books across various domains like science and news. It utilizes multiple agents, each responsible for specific tasks, which enhances its ability to handle different extraction scenarios effectively. The system includes a configurable knowledge base that aids in schema setup, debugging, and error correction, leading to improved performance. Empirical tests on benchmark datasets confirm OneKE\'s effectiveness, and case studies showcase its versatility in tackling diverse tasks.","title":"OneKE: Versatile Knowledge Extraction for Diverse Domains"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc="OneKE is a knowledge extraction system designed to gather information from the Web and raw PDF books across various domains like science and news. It utilizes multiple agents, each responsible for specific tasks, which enhances its ability to handle different extraction scenarios effectively. The system includes a configurable knowledge base that aids in schema setup, debugging, and error correction, leading to improved performance. Empirical tests on benchmark datasets confirm OneKE's effectiveness, and case studies showcase its versatility in tackling diverse tasks.", title='OneKE: Versatile Knowledge Extraction for Diverse Domains'))
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"OneKE是一个基于Docker的知识提取系统，能够从网络和原始PDF书籍中提取知识，支持多个领域（如科学、新闻等）。该系统设计了多个智能代理，各自承担不同的角色，以适应各种提取场景。配置知识库的设计使得模式配置、错误调试和修正变得更加高效，从而提升了系统的性能。通过在基准数据集上的实证评估，OneKE展示了其有效性，并通过案例研究进一步说明了其在多个领域的适应性和广泛应用潜力。","title":"OneKE：多领域知识提取的智能系统"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='OneKE是一个基于Docker的知识提取系统，能够从网络和原始PDF书籍中提取知识，支持多个领域（如科学、新闻等）。该系统设计了多个智能代理，各自承担不同的角色，以适应各种提取场景。配置知识库的设计使得模式配置、错误调试和修正变得更加高效，从而提升了系统的性能。通过在基准数据集上的实证评估，OneKE展示了其有效性，并通过案例研究进一步说明了其在多个领域的适应性和广泛应用潜力。', title='OneKE：多领域知识提取的智能系统'))
[31.12.2024 04:13] Querying the API.
[31.12.2024 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models lies in the difficulty of creating preference pairs, as TTA lacks structured mechanisms like verifiable rewards or gold-standard answers available for Large Language Models (LLMs). To address this, we propose CLAP-Ranked Preference Optimization (CRPO), a novel framework that iteratively generates and optimizes preference data to enhance TTA alignment. We demonstrate that the audio preference dataset generated using CRPO outperforms existing alternatives. With this framework, TangoFlux achieves state-of-the-art performance across both objective and subjective benchmarks. We open source all code and models to support further research in TTA generation.
[31.12.2024 04:13] Response: {
  "desc": "TangoFlux - это эффективная генеративная модель для преобразования текста в аудио (Text-to-Audio, TTA) с 515 миллионами параметров. Модель способна генерировать до 30 секунд аудио с частотой 44,1 кГц всего за 3,7 секунды на одном GPU A40. Авторы представляют новую методику CLAP-Ranked Preference Optimization (CRPO) для улучшения согласованности TTA моделей путем итеративной генерации и оптимизации данных о предпочтениях. TangoFlux достигает передовых результатов в объективных и субъективных тестах, а код и модели открыты для дальнейших исследований.",

  "emoji": "🎵",

  "title": "TangoFlux: Революция в генерации аудио из текста"
}
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models lies in the difficulty of creating preference pairs, as TTA lacks structured mechanisms like verifiable rewards or gold-standard answers available for Large Language Models (LLMs). To address this, we propose CLAP-Ranked Preference Optimization (CRPO), a novel framework that iteratively generates and optimizes preference data to enhance TTA alignment. We demonstrate that the audio preference dataset generated using CRPO outperforms existing alternatives. With this framework, TangoFlux achieves state-of-the-art performance across both objective and subjective benchmarks. We open source all code and models to support further research in TTA generation."

[31.12.2024 04:13] Response: ```python
["AUDIO", "RLHF", "DATASET", "BENCHMARK", "SMALL_MODELS"]
```
[31.12.2024 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models lies in the difficulty of creating preference pairs, as TTA lacks structured mechanisms like verifiable rewards or gold-standard answers available for Large Language Models (LLMs). To address this, we propose CLAP-Ranked Preference Optimization (CRPO), a novel framework that iteratively generates and optimizes preference data to enhance TTA alignment. We demonstrate that the audio preference dataset generated using CRPO outperforms existing alternatives. With this framework, TangoFlux achieves state-of-the-art performance across both objective and subjective benchmarks. We open source all code and models to support further research in TTA generation."

[31.12.2024 04:13] Response: ```python
['ALIGNMENT', 'OPEN_SOURCE']
```
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TangoFlux is a powerful Text-to-Audio generative model that can create high-quality audio quickly and efficiently. It addresses the challenge of aligning TTA models by introducing a new method called CLAP-Ranked Preference Optimization (CRPO), which helps generate and optimize preference data. This approach improves the model\'s ability to understand and produce audio that aligns with user preferences. The results show that TangoFlux not only meets but exceeds current standards in both objective and subjective evaluations, and the team has made their code and models available for further research.","title":"TangoFlux: Revolutionizing Text-to-Audio Generation with CRPO"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc="TangoFlux is a powerful Text-to-Audio generative model that can create high-quality audio quickly and efficiently. It addresses the challenge of aligning TTA models by introducing a new method called CLAP-Ranked Preference Optimization (CRPO), which helps generate and optimize preference data. This approach improves the model's ability to understand and produce audio that aligns with user preferences. The results show that TangoFlux not only meets but exceeds current standards in both objective and subjective evaluations, and the team has made their code and models available for further research.", title='TangoFlux: Revolutionizing Text-to-Audio Generation with CRPO'))
[31.12.2024 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"我们介绍了TangoFlux，这是一种高效的文本到音频生成模型，拥有5.15亿个参数，能够在单个A40 GPU上以3.7秒的速度生成最长30秒的44.1kHz音频。TTA模型对齐的一个主要挑战是创建偏好对的困难，因为TTA缺乏像大型语言模型（LLMs）那样的可验证奖励或标准答案的结构化机制。为了解决这个问题，我们提出了CLAP-Ranked Preference Optimization（CRPO），这是一个新颖的框架，通过迭代生成和优化偏好数据来增强TTA的对齐。我们证明了使用CRPO生成的音频偏好数据集在现有替代方案中表现更优，TangoFlux在客观和主观基准测试中都达到了最先进的性能。","title":"TangoFlux：高效的文本到音频生成模型"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='我们介绍了TangoFlux，这是一种高效的文本到音频生成模型，拥有5.15亿个参数，能够在单个A40 GPU上以3.7秒的速度生成最长30秒的44.1kHz音频。TTA模型对齐的一个主要挑战是创建偏好对的困难，因为TTA缺乏像大型语言模型（LLMs）那样的可验证奖励或标准答案的结构化机制。为了解决这个问题，我们提出了CLAP-Ranked Preference Optimization（CRPO），这是一个新颖的框架，通过迭代生成和优化偏好数据来增强TTA的对齐。我们证明了使用CRPO生成的音频偏好数据集在现有替代方案中表现更优，TangoFlux在客观和主观基准测试中都达到了最先进的性能。', title='TangoFlux：高效的文本到音频生成模型'))
[31.12.2024 04:13] Loading Chinese text from previous data.
[31.12.2024 04:13] Renaming data file.
[31.12.2024 04:13] Renaming previous data. hf_papers.json to ./d/2024-12-31.json
[31.12.2024 04:13] Saving new data file.
[31.12.2024 04:13] Generating page.
[31.12.2024 04:13] Renaming previous page.
[31.12.2024 04:13] Renaming previous data. index.html to ./d/2024-12-31.html
[31.12.2024 04:13] [Experimental] Generating Chinese page for reading.
[31.12.2024 04:13] Can't parse vocab. Expecting ',' delimiter: line 1 column 675 (char 674)
[31.12.2024 04:13] Chinese vocab []
[31.12.2024 04:13] Renaming previous Chinese page.
[31.12.2024 04:13] Renaming previous data. zh.html to ./d/2024-12-30_zh_reading_task.html
[31.12.2024 04:13] Writing Chinese reading task.
[31.12.2024 04:13] Writing result.
[31.12.2024 04:13] Renaming log file.
[31.12.2024 04:13] Renaming previous data. log.txt to ./logs/2024-12-31_last_log.txt
