[31.12.2024 05:11] Read previous papers.
[31.12.2024 05:11] Generating top page (month).
[31.12.2024 05:11] Writing top page (month).
[31.12.2024 06:14] Read previous papers.
[31.12.2024 06:14] Get feed.
[31.12.2024 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2412.20070
[31.12.2024 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2412.21079
[31.12.2024 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2412.20993
[31.12.2024 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18525
[31.12.2024 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2412.21037
[31.12.2024 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2412.21139
[31.12.2024 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2412.20005
[31.12.2024 06:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.12.2024 06:14] No deleted papers detected.
[31.12.2024 06:14] Downloading and parsing papers (pdf, html). Total: 7.
[31.12.2024 06:14] Downloading and parsing paper https://huggingface.co/papers/2412.20070.
[31.12.2024 06:14] Extra JSON file exists (./assets/json/2412.20070.json), skip PDF parsing.
[31.12.2024 06:14] Paper image links file exists (./assets/img_data/2412.20070.json), skip HTML parsing.
[31.12.2024 06:14] Success.
[31.12.2024 06:14] Downloading and parsing paper https://huggingface.co/papers/2412.21079.
[31.12.2024 06:14] Extra JSON file exists (./assets/json/2412.21079.json), skip PDF parsing.
[31.12.2024 06:14] Paper image links file exists (./assets/img_data/2412.21079.json), skip HTML parsing.
[31.12.2024 06:14] Success.
[31.12.2024 06:14] Downloading and parsing paper https://huggingface.co/papers/2412.20993.
[31.12.2024 06:14] Extra JSON file exists (./assets/json/2412.20993.json), skip PDF parsing.
[31.12.2024 06:14] Paper image links file exists (./assets/img_data/2412.20993.json), skip HTML parsing.
[31.12.2024 06:14] Success.
[31.12.2024 06:14] Downloading and parsing paper https://huggingface.co/papers/2412.18525.
[31.12.2024 06:14] Extra JSON file exists (./assets/json/2412.18525.json), skip PDF parsing.
[31.12.2024 06:14] Paper image links file exists (./assets/img_data/2412.18525.json), skip HTML parsing.
[31.12.2024 06:14] Success.
[31.12.2024 06:14] Downloading and parsing paper https://huggingface.co/papers/2412.21037.
[31.12.2024 06:14] Extra JSON file exists (./assets/json/2412.21037.json), skip PDF parsing.
[31.12.2024 06:14] Paper image links file exists (./assets/img_data/2412.21037.json), skip HTML parsing.
[31.12.2024 06:14] Success.
[31.12.2024 06:14] Downloading and parsing paper https://huggingface.co/papers/2412.21139.
[31.12.2024 06:14] Extra JSON file exists (./assets/json/2412.21139.json), skip PDF parsing.
[31.12.2024 06:14] Paper image links file exists (./assets/img_data/2412.21139.json), skip HTML parsing.
[31.12.2024 06:14] Success.
[31.12.2024 06:14] Downloading and parsing paper https://huggingface.co/papers/2412.20005.
[31.12.2024 06:14] Extra JSON file exists (./assets/json/2412.20005.json), skip PDF parsing.
[31.12.2024 06:14] Paper image links file exists (./assets/img_data/2412.20005.json), skip HTML parsing.
[31.12.2024 06:14] Success.
[31.12.2024 06:14] Enriching papers with extra data.
[31.12.2024 06:14] ********************************************************************************
[31.12.2024 06:14] Abstract 0. Multimodal large language models (MLLMs) hold significant potential in the medical field, but their capabilities are often limited by insufficient data in certain medical domains, highlighting the need for understanding what kinds of images can be used by MLLMs for generalization. Current research s...
[31.12.2024 06:14] ********************************************************************************
[31.12.2024 06:14] Abstract 1. As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments. Edicho steps in with a training-free solution based on diffusion models, featuring a fundame...
[31.12.2024 06:14] ********************************************************************************
[31.12.2024 06:14] Abstract 2. The rapid evolution of large language models (LLMs) has unlocked their capabilities in advanced reasoning tasks like mathematical problem-solving, code generation, and legal analysis. Central to this progress are inference-time reasoning algorithms, which refine outputs by exploring multiple solutio...
[31.12.2024 06:14] ********************************************************************************
[31.12.2024 06:14] Abstract 3. Computer Vision (CV) has yet to fully achieve the zero-shot task generalization observed in Natural Language Processing (NLP), despite following many of the milestones established in NLP, such as large transformer models, extensive pre-training, and the auto-regression paradigm, among others. In thi...
[31.12.2024 06:14] ********************************************************************************
[31.12.2024 06:14] Abstract 4. We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models lies in the difficulty of creating preference pairs, as TTA lacks st...
[31.12.2024 06:14] ********************************************************************************
[31.12.2024 06:14] Abstract 5. We present SWE-Gym, the first environment for training real-world software engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task instances, each comprising a codebase with an executable runtime environment, unit tests, and a task specified in natural language. We use SWE-Gym to tra...
[31.12.2024 06:14] ********************************************************************************
[31.12.2024 06:14] Abstract 6. We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their...
[31.12.2024 06:14] Read previous papers.
[31.12.2024 06:14] Generating reviews via LLM API.
[31.12.2024 06:14] Using data from previous issue: {"categories": ["#dataset", "#healthcare", "#open_source", "#multimodal", "#transfer_learning"], "emoji": "ü©∫", "ru": {"title": "–ö–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è - –∫–ª—é—á –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è MLLM", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM) –≤ –º
[31.12.2024 06:14] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#open_source", "#inference"], "emoji": "üñºÔ∏è", "ru": {"title": "Edicho: —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Edicho - —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥
[31.12.2024 06:14] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#inference"], "emoji": "üß†", "ru": {"title": "Dynasor: —É–º–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö LLM-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º—É Dynasor, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—é—â—É—é –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è –∑–∞–¥–∞—á —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–æ–ª—å—à–∏—Ö —è–∑—ã
[31.12.2024 06:14] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#cv", "#multimodal", "#transfer_learning"], "emoji": "üî¨", "ru": {"title": "–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ - –∫–ª—é—á –∫ –æ–±–æ–±—â–µ–Ω–∏—é –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∫ –æ–±–æ–±—â–µ–Ω–∏—é –Ω–∞ –Ω
[31.12.2024 06:14] Using data from previous issue: {"categories": ["#dataset", "#audio", "#open_source", "#benchmark", "#alignment", "#rlhf", "#small_models"], "emoji": "üéµ", "ru": {"title": "TangoFlux: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞", "desc": "TangoFlux - —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ –∞—É–¥–∏–æ (Text-to-Audio, TT
[31.12.2024 06:14] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#agents", "#training"], "emoji": "ü§ñ", "ru": {"title": "SWE-Gym: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ü–û", "desc": "SWE-Gym - —ç—Ç–æ –Ω–æ–≤–∞—è —Å—Ä–µ–¥–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–π –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö. –û–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç 2438 —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –∑–∞–¥–∞—á –Ω–∞ P
[31.12.2024 06:14] Using data from previous issue: {"categories": ["#dataset", "#agents", "#open_source", "#benchmark", "#multimodal", "#science"], "emoji": "üß†", "ru": {"title": "OneKE: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ —Ä–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤", "desc": "OneKE - —ç—Ç–æ –¥–æ–∫–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π, —É–ø—Ä–∞–≤–ª—è–µ–º–∞—è —Å—Ö–µ–º–æ–π. –û–Ω–∞ —Å–ø–æ
[31.12.2024 06:14] Loading Chinese text from previous data.
[31.12.2024 06:14] Renaming data file.
[31.12.2024 06:14] Renaming previous data. hf_papers.json to ./d/2024-12-31.json
[31.12.2024 06:14] Saving new data file.
[31.12.2024 06:14] Generating page.
[31.12.2024 06:14] Renaming previous page.
[31.12.2024 06:14] Renaming previous data. index.html to ./d/2024-12-31.html
[31.12.2024 06:14] [Experimental] Generating Chinese page for reading.
[31.12.2024 06:14] Can't parse vocab. Expecting ',' delimiter: line 1 column 675 (char 674)
[31.12.2024 06:14] Chinese vocab []
[31.12.2024 06:14] Renaming previous Chinese page.
[31.12.2024 06:14] Renaming previous data. zh.html to ./d/2024-12-30_zh_reading_task.html
[31.12.2024 06:14] Writing Chinese reading task.
[31.12.2024 06:14] Writing result.
[31.12.2024 06:14] Renaming log file.
[31.12.2024 06:14] Renaming previous data. log.txt to ./logs/2024-12-31_last_log.txt
