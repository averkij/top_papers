[29.04.2025 07:13] Read previous papers.
[29.04.2025 07:13] Generating top page (month).
[29.04.2025 07:13] Writing top page (month).
[29.04.2025 08:16] Read previous papers.
[29.04.2025 08:16] Get feed.
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.19838
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.19724
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.19093
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.17258
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.15780
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.16083
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.18919
[29.04.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2504.19395
[29.04.2025 08:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[29.04.2025 08:16] No deleted papers detected.
[29.04.2025 08:16] Downloading and parsing papers (pdf, html). Total: 8.
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.19838.
[29.04.2025 08:16] Extra JSON file exists (./assets/json/2504.19838.json), skip PDF parsing.
[29.04.2025 08:16] Paper image links file exists (./assets/img_data/2504.19838.json), skip HTML parsing.
[29.04.2025 08:16] Success.
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.19724.
[29.04.2025 08:16] Extra JSON file exists (./assets/json/2504.19724.json), skip PDF parsing.
[29.04.2025 08:16] Paper image links file exists (./assets/img_data/2504.19724.json), skip HTML parsing.
[29.04.2025 08:16] Success.
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.19093.
[29.04.2025 08:16] Extra JSON file exists (./assets/json/2504.19093.json), skip PDF parsing.
[29.04.2025 08:16] Paper image links file exists (./assets/img_data/2504.19093.json), skip HTML parsing.
[29.04.2025 08:16] Success.
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.17258.
[29.04.2025 08:16] Downloading paper 2504.17258 from http://arxiv.org/pdf/2504.17258v1...
[29.04.2025 08:16] Failed to download and parse paper https://huggingface.co/papers/2504.17258: 'LTChar' object is not iterable
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.15780.
[29.04.2025 08:16] Extra JSON file exists (./assets/json/2504.15780.json), skip PDF parsing.
[29.04.2025 08:16] Paper image links file exists (./assets/img_data/2504.15780.json), skip HTML parsing.
[29.04.2025 08:16] Success.
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.16083.
[29.04.2025 08:16] Extra JSON file exists (./assets/json/2504.16083.json), skip PDF parsing.
[29.04.2025 08:16] Paper image links file exists (./assets/img_data/2504.16083.json), skip HTML parsing.
[29.04.2025 08:16] Success.
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.18919.
[29.04.2025 08:16] Extra JSON file exists (./assets/json/2504.18919.json), skip PDF parsing.
[29.04.2025 08:16] Paper image links file exists (./assets/img_data/2504.18919.json), skip HTML parsing.
[29.04.2025 08:16] Success.
[29.04.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2504.19395.
[29.04.2025 08:16] Extra JSON file exists (./assets/json/2504.19395.json), skip PDF parsing.
[29.04.2025 08:16] Paper image links file exists (./assets/img_data/2504.19395.json), skip HTML parsing.
[29.04.2025 08:16] Success.
[29.04.2025 08:16] Enriching papers with extra data.
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 0. With the rapid rise of large language models (LLMs), phone automation has undergone transformative changes. This paper systematically reviews LLM-driven phone GUI agents, highlighting their evolution from script-based automation to intelligent, adaptive systems. We first contextualize key challenges...
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 1. Although contemporary text-to-image generation models have achieved remarkable breakthroughs in producing visually appealing images, their capacity to generate precise and flexible typographic elements, especially non-Latin alphabets, remains constrained. To address these limitations, we start from ...
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 2. Large language models (LLMs) have demonstrated remarkable capabilities, especially the recent advancements in reasoning, such as o1 and o3, pushing the boundaries of AI. Despite these impressive achievements in mathematics and coding, the reasoning abilities of LLMs in domains requiring cryptographi...
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 3. Downsampling layers are crucial building blocks in CNN architectures, which help to increase the receptive field for learning high-level features and reduce the amount of memory/computation in the model. In this work, we study the generalization of the uniform downsampling layer for group equivarian...
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 4. Mathematical geometric problem solving (GPS) often requires effective integration of multimodal information and verifiable logical coherence. Despite the fast development of large language models in general problem solving, it remains unresolved regarding with both methodology and benchmarks, especi...
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 5. The integration of long-context capabilities with visual understanding unlocks unprecedented potential for Vision Language Models (VLMs). However, the quadratic attention complexity during the pre-filling phase remains a significant obstacle to real-world deployment. To overcome this limitation, we ...
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 6. Global healthcare providers are exploring use of large language models (LLMs) to provide medical advice to the public. LLMs now achieve nearly perfect scores on medical licensing exams, but this does not necessarily translate to accurate performance in real-world settings. We tested if LLMs can assi...
[29.04.2025 08:16] ********************************************************************************
[29.04.2025 08:16] Abstract 7. Recent works have suggested that In-Context Learning (ICL) operates in dual modes, i.e. task retrieval (remember learned patterns from pre-training) and task learning (inference-time ``learning'' from demonstrations). However, disentangling these the two modes remains a challenging goal. We introduc...
[29.04.2025 08:16] Read previous papers.
[29.04.2025 08:16] Generating reviews via LLM API.
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#survey", "#dataset", "#rl", "#training", "#multimodal", "#security"], "emoji": "üì±", "ru": {"title": "LLM —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É—é—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é –º–æ–±–∏–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä –∞–≥–µ–Ω—Ç–æ–≤ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#diffusion", "#inference", "#multilingual", "#video", "#open_source", "#low_resource", "#multimodal"], "emoji": "üñãÔ∏è", "ru": {"title": "RepText: –¢–æ—á–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç RepText - –º–µ—Ç–æ–¥, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –º–æ–¥–µ–ª—è–º –≥–µ–Ω–µ—Ä–∞—Ü
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#reasoning"], "emoji": "üîê", "ru": {"title": "CipherBank: —Ä–∞—Å–∫—Ä—ã–≤–∞—è –≥—Ä–∞–Ω–∏—Ü—ã –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è LLM", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç CipherBank - –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –∑–∞–¥–∞—á–∞—Ö –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#training", "#cv", "#optimization", "#architecture"], "emoji": "üîç", "ru": {"title": "–î–∞—É–Ω—Å—ç–º–ø–ª–∏–Ω–≥ –≤ –≥—Ä—É–ø–ø–æ–≤—ã—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–µ—Ç—è—Ö: –æ–±–æ–±—â–µ–Ω–∏–µ –∏ –∞–Ω—Ç–∏–∞–ª–∏–∞—Å–∏–Ω–≥", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –æ–±–æ–±—â–µ–Ω–∏–µ —Å–ª–æ–µ–≤ –¥–∞—É–Ω—Å—ç–º–ø–ª–∏–Ω–≥–∞ –¥–ª—è –≥—Ä—É–ø–ø–æ–≤—ã—Ö —ç–∫–≤–∏–≤–∞—Ä–∏–∞–Ω—Ç–Ω—ã—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π (G-CNN). –ê–≤—Ç
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#reasoning", "#math", "#data", "#dataset", "#multimodal"], "emoji": "üìê", "ru": {"title": "TrustGeoGen: –ù–∞–¥–µ–∂–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç TrustGeoGen - –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã–π –¥–≤–∏–∂–æ–∫ –¥–ª
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#inference", "#multimodal", "#long_context", "#benchmark", "#video"], "emoji": "üöÄ", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ VLM –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MMInference - –º–µ—Ç–æ–¥ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#benchmark", "#science", "#interpretability", "#data", "#alignment", "#healthcare"], "emoji": "ü©∫", "ru": {"title": "LLM –≤ –º–µ–¥–∏—Ü–∏–Ω–µ: –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤, –Ω–æ –ø—Ä–æ–±–ª–µ–º—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ –∫—Ä—É–ø–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –≤—ã—Å–æ–∫—É—é
[29.04.2025 08:16] Using data from previous issue: {"categories": ["#reasoning", "#training", "#multimodal", "#dataset", "#interpretability"], "emoji": "üîë", "ru": {"title": "–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤: LLM –∏ –æ–±—Ä–∞—Ç–∏–º—ã–µ —à–∏—Ñ—Ä—ã", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è, –∫–∞–∫ LLM –º–æ–≥—É—Ç —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ In-Context Learning (ICL) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —à–∏—Ñ—Ä–æ–≤ –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫
[29.04.2025 08:16] Loading Chinese text from previous data.
[29.04.2025 08:16] Renaming data file.
[29.04.2025 08:16] Renaming previous data. hf_papers.json to ./d/2025-04-29.json
[29.04.2025 08:16] Saving new data file.
[29.04.2025 08:16] Generating page.
[29.04.2025 08:16] Renaming previous page.
[29.04.2025 08:16] Renaming previous data. index.html to ./d/2025-04-29.html
[29.04.2025 08:16] [Experimental] Generating Chinese page for reading.
[29.04.2025 08:16] Chinese vocab [{'word': '‰ªãÁªç', 'pinyin': 'ji√® sh√†o', 'trans': 'introduce'}, {'word': 'Êï∞ÊçÆÈõÜ', 'pinyin': 'sh√π j√π j√≠', 'trans': 'dataset'}, {'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´ zh«în', 'trans': 'benchmark'}, {'word': 'ËØÑ‰º∞', 'pinyin': 'p√≠ng g≈´', 'trans': 'evaluate'}, {'word': 'ÊîπËøõ', 'pinyin': 'g«éi j√¨n', 'trans': 'improve'}, {'word': 'ÊëÑÂÉèÊú∫', 'pinyin': 'sh√® xi√†ng jƒ´', 'trans': 'camera'}, {'word': 'ËøêÂä®', 'pinyin': 'y√πn d√≤ng', 'trans': 'motion'}, {'word': 'ÁêÜËß£', 'pinyin': 'l«ê jiƒõ', 'trans': 'understand'}, {'word': 'Â§öÊ†∑Âåñ', 'pinyin': 'du≈ç y√†ng hu√†', 'trans': 'diverse'}, {'word': 'ÁΩëÁªúËßÜÈ¢ë', 'pinyin': 'w«éng lu√≤ sh√¨ p√≠n', 'trans': 'online video'}, {'word': '‰∏ìÂÆ∂', 'pinyin': 'zhuƒÅn jiƒÅ', 'trans': 'expert'}, {'word': '‰∏•Ê†º', 'pinyin': 'y√°n g√©', 'trans': 'strict'}, {'word': 'Â§öÈò∂ÊÆµ', 'pinyin': 'du≈ç jiƒì du√†n', 'trans': 'multi-stage'}, {'word': 'Ë¥®ÈáèÊéßÂà∂', 'pinyin': 'zh√¨ li√†ng k√≤ng zh√¨', 'trans': 'quality control'}, {'word': 'ËøáÁ®ã', 'pinyin': 'gu√≤ ch√©ng', 'trans': 'process'}, {'word': 'Ê†áÊ≥®', 'pinyin': 'biƒÅo zh√π', 'trans': 'annotate'}, {'word': 'ÊëÑÂΩ±Â∏à', 'pinyin': 'sh√® y«êng shƒ´', 'trans': 'photographer'}, {'word': 'ËÆæËÆ°', 'pinyin': 'sh√® j√¨', 'trans': 'design'}, {'word': 'Âü∫ÂÖÉ', 'pinyin': 'jƒ´ yu√°n', 'trans': 'primitive'}, {'word': 'ÂàÜÁ±ªÊ≥ï', 'pinyin': 'fƒìn l√®i f«é', 'trans': 'classification method'}, {'word': '‰æãÂ¶Ç', 'pinyin': 'l√¨ r√∫', 'trans': 'for example'}, {'word': 'Êüê‰∫õ', 'pinyin': 'm«íu xiƒì', 'trans': 'some'}, {'word': 'Ë∑üÈöè', 'pinyin': 'gƒìn su√≠', 'trans': 'follow'}, {'word': 'ÈúÄË¶Å', 'pinyin': 'x≈´ y√†o', 'trans': 'need'}, {'word': 'Âú∫ÊôØ', 'pinyin': 'ch«éng j«êng', 'trans': 'scene'}, {'word': 'ÂÜÖÂÆπ', 'pinyin': 'n√®i r√≥ng', 'trans': 'content'}, {'word': '‰∏ª‰Ωì', 'pinyin': 'zh«î t«ê', 'trans': 'subject'}, {'word': 'ÁßªÂä®', 'pinyin': 'y√≠ d√≤ng', 'trans': 'move'}, {'word': 'Á†îÁ©∂', 'pinyin': 'y√°n ji≈´', 'trans': 'study'}, {'word': 'ÈáèÂåñ', 'pinyin': 'li√†ng hu√†', 'trans': 'quantify'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}, {'word': 'È¢ÜÂüü', 'pinyin': 'l«êng y√π', 'trans': 'field'}, {'word': '‰∏ì‰∏öÁü•ËØÜ', 'pinyin': 'zhuƒÅn y√® zhƒ´ shi', 'trans': 'professional knowledge'}, {'word': 'Âü∫‰∫é', 'pinyin': 'jƒ´ y√∫', 'trans': 'based on'}, {'word': 'ÊïôÁ®ã', 'pinyin': 'ji√†o ch√©ng', 'trans': 'tutorial'}, {'word': 'ÂüπËÆ≠', 'pinyin': 'p√©i x√πn', 'trans': 'training'}, {'word': 'ÊòæËëó', 'pinyin': 'xi«én zh√π', 'trans': 'significant'}, {'word': 'ÊèêÈ´ò', 'pinyin': 't√≠ gƒÅo', 'trans': 'improve'}, {'word': 'ÂáÜÁ°ÆÊÄß', 'pinyin': 'zh«în qu√® x√¨ng', 'trans': 'accuracy'}, {'word': 'ÁªìÊûÑ‰ªéËøêÂä®', 'pinyin': 'ji√© g√≤u c√≥ng y√πn d√≤ng', 'trans': 'Structure from Motion (SfM)'}, {'word': 'ËßÜÈ¢ëËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'sh√¨ p√≠n y«î y√°n m√≥ x√≠ng', 'trans': 'Video Language Model (VLM)'}, {'word': 'ÊçïÊçâ', 'pinyin': 'b«î zhu≈ç', 'trans': 'capture'}, {'word': '‰æùËµñ', 'pinyin': 'yƒ´ l√†i', 'trans': 'depend on'}, {'word': 'ËØ≠‰πâ', 'pinyin': 'y«î y√¨', 'trans': 'semantic'}, {'word': 'Âá†‰Ωï', 'pinyin': 'j«ê h√©', 'trans': 'geometric'}, {'word': 'ËΩ®Ëøπ', 'pinyin': 'gu«ê jƒ´', 'trans': 'trajectory'}, {'word': '‰º∞ËÆ°', 'pinyin': 'g≈´ j√¨', 'trans': 'estimate'}, {'word': 'ÂæÆË∞É', 'pinyin': 'wƒìi ti√°o', 'trans': 'fine-tune'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìng ch√©ng', 'trans': 'generate'}, {'word': '‰ºòÂäø', 'pinyin': 'y≈çu sh√¨', 'trans': 'advantage'}, {'word': 'ÁªìÂêà', 'pinyin': 'ji√© h√©', 'trans': 'combine'}, {'word': 'Â±ïÁ§∫', 'pinyin': 'zh«én sh√¨', 'trans': 'demonstrate'}, {'word': 'Â∫îÁî®', 'pinyin': 'y√¨ng y√≤ng', 'trans': 'application'}, {'word': 'ÂåÖÊã¨', 'pinyin': 'bƒÅo ku√≤', 'trans': 'include'}, {'word': 'Â¢ûÂº∫', 'pinyin': 'zƒìng qi√°ng', 'trans': 'enhance'}, {'word': 'Â≠óÂπï', 'pinyin': 'z√¨ m√π', 'trans': 'subtitle'}, {'word': 'ÈóÆÁ≠î', 'pinyin': 'w√®n d√°', 'trans': 'question and answer'}, {'word': 'ÊñáÊú¨Ê£ÄÁ¥¢', 'pinyin': 'w√©n bƒõn ji«én su«í', 'trans': 'text retrieval'}, {'word': 'Â∏åÊúõ', 'pinyin': 'xƒ´ w√†ng', 'trans': 'hope'}, {'word': 'Êé®Âä®', 'pinyin': 'tuƒ´ d√≤ng', 'trans': 'promote'}, {'word': 'Êú™Êù•', 'pinyin': 'w√®i l√°i', 'trans': 'future'}, {'word': 'Âä™Âäõ', 'pinyin': 'n«î l√¨', 'trans': 'effort'}, {'word': 'ÂÆûÁé∞', 'pinyin': 'sh√≠ xi√†n', 'trans': 'achieve'}, {'word': 'ÊúÄÁªà', 'pinyin': 'zu√¨ zh≈çng', 'trans': 'ultimate'}, {'word': 'ÁõÆÊ†á', 'pinyin': 'm√π biƒÅo', 'trans': 'goal'}]
[29.04.2025 08:16] Renaming previous Chinese page.
[29.04.2025 08:16] Renaming previous data. zh.html to ./d/2025-04-28_zh_reading_task.html
[29.04.2025 08:16] Writing Chinese reading task.
[29.04.2025 08:16] Writing result.
[29.04.2025 08:16] Renaming log file.
[29.04.2025 08:16] Renaming previous data. log.txt to ./logs/2025-04-29_last_log.txt
