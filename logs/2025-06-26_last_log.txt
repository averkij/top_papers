[26.06.2025 04:22] Read previous papers.
[26.06.2025 04:22] Generating top page (month).
[26.06.2025 04:22] Writing top page (month).
[26.06.2025 05:13] Read previous papers.
[26.06.2025 05:13] Get feed.
[26.06.2025 05:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.18095
[26.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.19697
[26.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.18403
[26.06.2025 05:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.19502
[26.06.2025 05:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.06.2025 05:13] No deleted papers detected.
[26.06.2025 05:13] Downloading and parsing papers (pdf, html). Total: 4.
[26.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.18095.
[26.06.2025 05:13] Downloading paper 2506.18095 from http://arxiv.org/pdf/2506.18095v1...
[26.06.2025 05:13] Extracting affiliations from text.
[26.06.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation Junying Chen, Zhenyang Cai, Pengcheng Chen, Shunian Chen, Ke Ji, Xidong Wang, Yunjin Yang, Benyou Wang The Chinese University of Hong Kong, Shenzhen wangbenyou@cuhk.edu.cn https://github.com/FreedomIntelligence/ShareGPT-4o-Image "
[26.06.2025 05:13] Response: ```python
["The Chinese University of Hong Kong, Shenzhen"]
```
[26.06.2025 05:13] Deleting PDF ./assets/pdf/2506.18095.pdf.
[26.06.2025 05:13] Success.
[26.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.19697.
[26.06.2025 05:13] Extra JSON file exists (./assets/json/2506.19697.json), skip PDF parsing.
[26.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.19697.json), skip HTML parsing.
[26.06.2025 05:13] Success.
[26.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.18403.
[26.06.2025 05:13] Extra JSON file exists (./assets/json/2506.18403.json), skip PDF parsing.
[26.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.18403.json), skip HTML parsing.
[26.06.2025 05:13] Success.
[26.06.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2506.19502.
[26.06.2025 05:13] Extra JSON file exists (./assets/json/2506.19502.json), skip PDF parsing.
[26.06.2025 05:13] Paper image links file exists (./assets/img_data/2506.19502.json), skip HTML parsing.
[26.06.2025 05:13] Success.
[26.06.2025 05:13] Enriching papers with extra data.
[26.06.2025 05:13] ********************************************************************************
[26.06.2025 05:13] Abstract 0. ShareGPT-4o-Image and Janus-4o enable open research in photorealistic, instruction-aligned image generation through a large dataset and multimodal model.  					AI-generated summary 				 Recent advances in multimodal generative models have unlocked photorealistic, instruction-aligned image generation...
[26.06.2025 05:13] ********************************************************************************
[26.06.2025 05:13] Abstract 1. Outlier-Safe Pre-Training improves large language model quantization performance by preventing extreme activation outliers through innovative training techniques.  					AI-generated summary 				 Extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, ...
[26.06.2025 05:13] ********************************************************************************
[26.06.2025 05:13] Abstract 2. The Debugging Decay Index (DDI) quantifies and optimizes the effectiveness of iterative AI debugging by predicting intervention points to revive and enhance debugging capability.  					AI-generated summary 				 The effectiveness of AI debugging follows a predictable exponential decay pattern; most m...
[26.06.2025 05:13] ********************************************************************************
[26.06.2025 05:13] Abstract 3. MATE, a multimodal accessibility multi-agent system, converts data into understandable formats based on user needs, supporting various disabilities and integrating with institutional technologies.  					AI-generated summary 				 Accessibility remains a critical concern in today's society, as many te...
[26.06.2025 05:13] Read previous papers.
[26.06.2025 05:13] Generating reviews via LLM API.
[26.06.2025 05:13] Querying the API.
[26.06.2025 05:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ShareGPT-4o-Image and Janus-4o enable open research in photorealistic, instruction-aligned image generation through a large dataset and multimodal model.  					AI-generated summary 				 Recent advances in multimodal generative models have unlocked photorealistic, instruction-aligned image generation, yet leading systems like GPT-4o-Image remain proprietary and inaccessible. To democratize these capabilities, we present ShareGPT-4o-Image, the first dataset comprising 45K text-to-image and 46K text-and-image-to-image data, all synthesized using GPT-4o's image generation capabilities for distilling its advanced image generation abilities. Leveraging this dataset, we develop Janus-4o, a multimodal large language model capable of both text-to-image and text-and-image-to-image generation. Janus-4o not only significantly improves text-to-image generation over its predecessor, Janus-Pro, but also newly supports text-and-image-to-image generation. Notably, it achieves impressive performance in text-and-image-to-image generation from scratch, using only 91K synthetic samples and 6 hours of training on an 8 A800-GPU machine. We hope the release of ShareGPT-4o-Image and Janus-4o will foster open research in photorealistic, instruction-aligned image generation.
[26.06.2025 05:13] Response: {
  "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ShareGPT-4o-Image - Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¹ 45 Ñ‚Ñ‹ÑÑÑ‡ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ Ğ¸ 46 Ñ‚Ñ‹ÑÑÑ‡ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ GPT-4o. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Janus-4o, ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ°Ğº Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ, Ñ‚Ğ°Ğº Ğ¸ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼. Janus-4o Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ñ€ĞµĞ´ÑˆĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¸ĞºĞ¾Ğ¼ Janus-Pro Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ»ÑÑÑ‰Ğ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ²ÑĞµĞ³Ğ¾ 91 Ñ‚Ñ‹ÑÑÑ‡Ñƒ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ½Ğ°Ğ´ĞµÑÑ‚ÑÑ, Ñ‡Ñ‚Ğ¾ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ShareGPT-4o-Image Ğ¸ Janus-4o Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑĞ¼ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ñ„Ğ¾Ñ‚Ğ¾Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼Ğ¸.",

  "emoji": "ğŸ–¼ï¸",

  "title": "Ğ”ĞµĞ¼Ğ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ„Ğ¾Ñ‚Ğ¾Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹"
}
[26.06.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ShareGPT-4o-Image and Janus-4o enable open research in photorealistic, instruction-aligned image generation through a large dataset and multimodal model.  					AI-generated summary 				 Recent advances in multimodal generative models have unlocked photorealistic, instruction-aligned image generation, yet leading systems like GPT-4o-Image remain proprietary and inaccessible. To democratize these capabilities, we present ShareGPT-4o-Image, the first dataset comprising 45K text-to-image and 46K text-and-image-to-image data, all synthesized using GPT-4o's image generation capabilities for distilling its advanced image generation abilities. Leveraging this dataset, we develop Janus-4o, a multimodal large language model capable of both text-to-image and text-and-image-to-image generation. Janus-4o not only significantly improves text-to-image generation over its predecessor, Janus-Pro, but also newly supports text-and-image-to-image generation. Notably, it achieves impressive performance in text-and-image-to-image generation from scratch, using only 91K synthetic samples and 6 hours of training on an 8 A800-GPU machine. We hope the release of ShareGPT-4o-Image and Janus-4o will foster open research in photorealistic, instruction-aligned image generation."

[26.06.2025 05:13] Response: ```python
['DATASET', 'MULTIMODAL', 'CV']
```
[26.06.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ShareGPT-4o-Image and Janus-4o enable open research in photorealistic, instruction-aligned image generation through a large dataset and multimodal model.  					AI-generated summary 				 Recent advances in multimodal generative models have unlocked photorealistic, instruction-aligned image generation, yet leading systems like GPT-4o-Image remain proprietary and inaccessible. To democratize these capabilities, we present ShareGPT-4o-Image, the first dataset comprising 45K text-to-image and 46K text-and-image-to-image data, all synthesized using GPT-4o's image generation capabilities for distilling its advanced image generation abilities. Leveraging this dataset, we develop Janus-4o, a multimodal large language model capable of both text-to-image and text-and-image-to-image generation. Janus-4o not only significantly improves text-to-image generation over its predecessor, Janus-Pro, but also newly supports text-and-image-to-image generation. Notably, it achieves impressive performance in text-and-image-to-image generation from scratch, using only 91K synthetic samples and 6 hours of training on an 8 A800-GPU machine. We hope the release of ShareGPT-4o-Image and Janus-4o will foster open research in photorealistic, instruction-aligned image generation."

[26.06.2025 05:13] Response: ```python
['OPEN_SOURCE', 'SYNTHETIC']
```
[26.06.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces ShareGPT-4o-Image, a comprehensive dataset designed to enhance photorealistic image generation aligned with user instructions. It includes 45,000 text-to-image and 46,000 text-and-image-to-image samples, all generated using the advanced capabilities of GPT-4o. The authors also present Janus-4o, a multimodal large language model that improves upon previous models by enabling both text-to-image and text-and-image-to-image generation. With only 91,000 synthetic samples and minimal training time, Janus-4o demonstrates significant advancements in generating high-quality images, promoting open research in this field.","title":"Democratizing Photorealistic Image Generation with Open Datasets and Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces ShareGPT-4o-Image, a comprehensive dataset designed to enhance photorealistic image generation aligned with user instructions. It includes 45,000 text-to-image and 46,000 text-and-image-to-image samples, all generated using the advanced capabilities of GPT-4o. The authors also present Janus-4o, a multimodal large language model that improves upon previous models by enabling both text-to-image and text-and-image-to-image generation. With only 91,000 synthetic samples and minimal training time, Janus-4o demonstrates significant advancements in generating high-quality images, promoting open research in this field.', title='Democratizing Photorealistic Image Generation with Open Datasets and Models'))
[26.06.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬è®ºæ–‡ä»‹ç»äº†ShareGPT-4o-Imageæ•°æ®é›†å’ŒJanus-4oæ¨¡å‹ï¼Œæ—¨åœ¨æ¨åŠ¨å¼€æ”¾ç ”ç©¶åœ¨çœŸå®æ„Ÿå›¾åƒç”Ÿæˆé¢†åŸŸçš„å‘å±•ã€‚ShareGPT-4o-ImageåŒ…å«45Kæ–‡æœ¬åˆ°å›¾åƒå’Œ46Kæ–‡æœ¬ä¸å›¾åƒåˆ°å›¾åƒçš„æ•°æ®ï¼Œåˆ©ç”¨GPT-4oçš„å›¾åƒç”Ÿæˆèƒ½åŠ›è¿›è¡Œåˆæˆã€‚Janus-4oæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿè¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬ä¸å›¾åƒåˆ°å›¾åƒçš„ç”Ÿæˆï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ•ˆæœã€‚æˆ‘ä»¬å¸Œæœ›è¿™äº›å·¥å…·èƒ½å¤Ÿä¿ƒè¿›çœŸå®æ„Ÿã€æŒ‡ä»¤å¯¹é½çš„å›¾åƒç”Ÿæˆç ”ç©¶ã€‚","title":"å¼€æ”¾ç ”ç©¶ï¼ŒçœŸå®æ„Ÿå›¾åƒç”Ÿæˆçš„æ–°çºªå…ƒ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬è®ºæ–‡ä»‹ç»äº†ShareGPT-4o-Imageæ•°æ®é›†å’ŒJanus-4oæ¨¡å‹ï¼Œæ—¨åœ¨æ¨åŠ¨å¼€æ”¾ç ”ç©¶åœ¨çœŸå®æ„Ÿå›¾åƒç”Ÿæˆé¢†åŸŸçš„å‘å±•ã€‚ShareGPT-4o-ImageåŒ…å«45Kæ–‡æœ¬åˆ°å›¾åƒå’Œ46Kæ–‡æœ¬ä¸å›¾åƒåˆ°å›¾åƒçš„æ•°æ®ï¼Œåˆ©ç”¨GPT-4oçš„å›¾åƒç”Ÿæˆèƒ½åŠ›è¿›è¡Œåˆæˆã€‚Janus-4oæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿè¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬ä¸å›¾åƒåˆ°å›¾åƒçš„ç”Ÿæˆï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ•ˆæœã€‚æˆ‘ä»¬å¸Œæœ›è¿™äº›å·¥å…·èƒ½å¤Ÿä¿ƒè¿›çœŸå®æ„Ÿã€æŒ‡ä»¤å¯¹é½çš„å›¾åƒç”Ÿæˆç ”ç©¶ã€‚', title='å¼€æ”¾ç ”ç©¶ï¼ŒçœŸå®æ„Ÿå›¾åƒç”Ÿæˆçš„æ–°çºªå…ƒ'))
[26.06.2025 05:13] Using data from previous issue: {"categories": ["#inference", "#training", "#optimization", "#open_source"], "emoji": "ğŸš€", "ru": {"title": "Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ LLM Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM), Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Outlier-Safe Pre-Traini
[26.06.2025 05:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#math"], "emoji": "ğŸ”", "ru": {"title": "ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸ Ğ˜Ğ˜: Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ñ‚ÑƒÑ…Ğ°Ğ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ˜Ğ½Ğ´ĞµĞºÑ Ğ—Ğ°Ñ‚ÑƒÑ…Ğ°Ğ½Ğ¸Ñ ĞÑ‚Ğ»Ğ°Ğ´ĞºĞ¸ (DDI), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸ Ğ˜Ğ˜. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾
[26.06.2025 05:13] Using data from previous issue: {"categories": ["#healthcare", "#agents", "#multimodal", "#ethics", "#open_source"], "emoji": "â™¿", "ru": {"title": "MATE: Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ñ Ğ±Ğ°Ñ€ÑŒĞµÑ€Ğ¾Ğ² Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸", "desc": "MATE - ÑÑ‚Ğ¾ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ 
[26.06.2025 05:13] Renaming data file.
[26.06.2025 05:13] Renaming previous data. hf_papers.json to ./d/2025-06-26.json
[26.06.2025 05:13] Saving new data file.
[26.06.2025 05:13] Generating page.
[26.06.2025 05:13] Renaming previous page.
[26.06.2025 05:13] Renaming previous data. index.html to ./d/2025-06-26.html
[26.06.2025 05:13] Writing result.
[26.06.2025 05:13] Renaming log file.
[26.06.2025 05:13] Renaming previous data. log.txt to ./logs/2025-06-26_last_log.txt
