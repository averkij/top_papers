[17.03.2025 22:10] Read previous papers.
[17.03.2025 22:10] Generating top page (month).
[17.03.2025 22:10] Writing top page (month).
[17.03.2025 23:10] Read previous papers.
[17.03.2025 23:10] Get feed.
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11647
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07677
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11646
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11224
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11069
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11576
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11514
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10772
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10970
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10781
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11579
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11651
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10632
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06542
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.09279
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10696
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06553
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06674
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10624
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11207
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10620
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.10684
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.05689
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.11629
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.08111
[17.03.2025 23:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.09330
[17.03.2025 23:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.03.2025 23:10] No deleted papers detected.
[17.03.2025 23:10] Downloading and parsing papers (pdf, html). Total: 26.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11647.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11647.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11647.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.07677.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.07677.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.07677.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11646.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11646.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11646.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11224.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11224.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11224.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11069.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11069.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11069.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11576.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11576.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11576.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11514.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11514.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11514.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10772.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10772.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10772.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10970.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10970.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10970.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10781.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10781.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10781.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11579.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11579.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11579.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11651.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11651.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11651.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10632.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10632.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10632.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.06542.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.06542.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.06542.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.09279.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.09279.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.09279.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10696.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10696.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10696.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.06553.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.06553.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.06553.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.06674.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.06674.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.06674.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10624.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10624.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10624.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11207.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11207.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11207.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10620.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10620.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10620.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.10684.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.10684.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.10684.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.05689.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.05689.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.05689.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.11629.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.11629.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.11629.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.08111.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.08111.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.08111.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Downloading and parsing paper https://huggingface.co/papers/2503.09330.
[17.03.2025 23:10] Extra JSON file exists (./assets/json/2503.09330.json), skip PDF parsing.
[17.03.2025 23:10] Paper image links file exists (./assets/img_data/2503.09330.json), skip HTML parsing.
[17.03.2025 23:10] Success.
[17.03.2025 23:10] Enriching papers with extra data.
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 0. Camera control has been actively studied in text or image conditioned video generation tasks. However, altering camera trajectories of a given video remains under-explored, despite its importance in the field of video creation. It is non-trivial due to the extra constraints of maintaining multiple-f...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 1. Diffusion models have shown impressive results in generating high-quality conditional samples using guidance techniques such as Classifier-Free Guidance (CFG). However, existing methods often require additional training or neural function evaluations (NFEs), making them incompatible with guidance-di...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 2. The pursuit of data efficiency, where quality outweighs quantity, has emerged as a cornerstone in robotic manipulation, especially given the high costs associated with real-world data collection. We propose that maximizing the informational density of individual demonstrations can dramatically reduc...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 3. State Space Models (SSMs) have emerged as a promising alternative to the popular transformer-based models and have been increasingly gaining attention. Compared to transformers, SSMs excel at tasks with sequential data or longer contexts, demonstrating comparable performances with significant effici...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 4. Large language models (LLMs) have evolved beyond simple text generation to power software agents that directly translate natural language commands into tangible actions. While API-based LLM agents initially rose to prominence for their robust automation capabilities and seamless integration with pro...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 5. We introduce SmolDocling, an ultra-compact vision-language model targeting end-to-end document conversion. Our model comprehensively processes entire pages by generating DocTags, a new universal markup format that captures all page elements in their full context with location. Unlike existing approa...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 6. Federated Learning (FL) has emerged as a promising privacy-preserving collaborative model training paradigm without sharing raw data. However, recent studies have revealed that private information can still be leaked through shared gradient information and attacked by Gradient Inversion Attacks (GIA...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 7. Bridging different modalities lies at the heart of cross-modality generation. While conventional approaches treat the text modality as a conditioning signal that gradually guides the denoising process from Gaussian noise to the target image modality, we explore a much simpler paradigm-directly evolv...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 8. Precision therapeutics require multimodal adaptive models that generate personalized treatment recommendations. We introduce TxAgent, an AI agent that leverages multi-step reasoning and real-time biomedical knowledge retrieval across a toolbox of 211 tools to analyze drug interactions, contraindicat...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 9. We propose a novel approach for captioning and object grounding in video, where the objects in the caption are grounded in the video via temporally dense bounding boxes. We introduce the following contributions. First, we present a large-scale automatic annotation method that aggregates captions gro...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 10. State-of-the-art transformer-based large multimodal models (LMMs) struggle to handle hour-long video inputs due to the quadratic complexity of the causal self-attention operations, leading to high computational costs during training and inference. Existing token compression-based methods reduce the ...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 11. We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views. This approach is a step forward in 3D computer vision, where models have typicall...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 12. Kolmogorov-Arnold networks (KANs) are a remarkable innovation consisting of learnable activation functions with the potential to capture more complex relationships from data. Although KANs are useful in finding symbolic representations and continual learning of one-dimensional functions, their effec...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 13. Unified models (UniMs) for multimodal understanding and generation have recently received much attention in the area of vision and language. Existing UniMs are designed to simultaneously learn both multimodal understanding and generation capabilities, demanding substantial computational resources, a...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 14. Video Detailed Captioning (VDC) is a crucial task for vision-language bridging, enabling fine-grained descriptions of complex video content. In this paper, we first comprehensively benchmark current state-of-the-art approaches and systematically identified two critical limitations: biased capability...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 15. Visual autoregressive models typically adhere to a raster-order ``next-token prediction" paradigm, which overlooks the spatial and temporal locality inherent in visual content. Specifically, visual tokens exhibit significantly stronger correlations with their spatially or temporally adjacent tokens ...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 16. As multi-modal large language models (MLLMs) frequently exhibit errors when solving scientific problems, evaluating the validity of their reasoning processes is critical for ensuring reliability and uncovering fine-grained model weaknesses. Since human evaluation is laborious and costly, prompting M...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 17. Accelerating diffusion model sampling is crucial for efficient AIGC deployment. While diffusion distillation methods -- based on distribution matching and trajectory matching -- reduce sampling to as few as one step, they fall short on complex tasks like text-to-image generation. Few-step generation...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 18. Fitting a body to a 3D clothed human point cloud is a common yet challenging task. Traditional optimization-based approaches use multi-stage pipelines that are sensitive to pose initialization, while recent learning-based methods often struggle with generalization across diverse poses and garment ty...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 19. This work presents a first evaluation of two state-of-the-art Large Reasoning Models (LRMs), OpenAI's o3-mini and DeepSeek R1, on analogical reasoning, focusing on well-established nonverbal human IQ tests based on Raven's progressive matrices. We benchmark with the I-RAVEN dataset and its more diff...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 20. Large language models (LLMs) have shown remarkable performance and generalization capabilities across multiple languages and tasks, making them very attractive targets for multi-modality integration (e.g., images or speech). In this work, we extend an existing LLM to the speech modality via speech d...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 21. Learning skills in open-world environments is essential for developing agents capable of handling a variety of tasks by combining basic skills. Online demonstration videos are typically long but unsegmented, making them difficult to segment and label with skill identifiers. Unlike existing methods t...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 22. We propose GoalFlow, an end-to-end autonomous driving method for generating high-quality multimodal trajectories. In autonomous driving scenarios, there is rarely a single suitable trajectory. Recent methods have increasingly focused on modeling multimodal trajectory distributions. However, they suf...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 23. We introduce TreeMeshGPT, an autoregressive Transformer designed to generate high-quality artistic meshes aligned with input point clouds. Instead of the conventional next-token prediction in autoregressive Transformer, we propose a novel Autoregressive Tree Sequencing where the next input token is ...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 24. Accurate material retrieval is critical for creating realistic 3D assets. Existing methods rely on datasets that capture shape-invariant and lighting-varied representations of materials, which are scarce and face challenges due to limited diversity and inadequate real-world generalization. Most curr...
[17.03.2025 23:10] ********************************************************************************
[17.03.2025 23:10] Abstract 25. Machine unlearning is an emerging paradigm to remove the influence of specific training data (i.e., the forget set) from a model while preserving its knowledge of the rest of the data (i.e., the retain set). Previous approaches assume the forget data to be uniformly distributed from all training dat...
[17.03.2025 23:10] Read previous papers.
[17.03.2025 23:10] Generating reviews via LLM API.
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#training", "#video", "#games"], "emoji": "🎥", "ru": {"title": "Управление камерой в видео с помощью генеративных моделей", "desc": "ReCamMaster - это генеративная система для изменения траектории камеры в видео. Она использует предобученные модели text-
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#training", "#cv", "#diffusion", "#inference"], "emoji": "🖼️", "ru": {"title": "PLADIS: Эффективное улучшение генерации изображений с помощью разреженного внимания", "desc": "Статья представляет новый метод под названием PLADIS для улучшения предобученных моделей диффузии в задаче г
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#robotics", "#benchmark", "#dataset", "#optimization", "#open_source", "#agents", "#training", "#data"], "emoji": "🤖", "ru": {"title": "Меньше данных, больше эффективности: революция в обучении роботов", "desc": "Статья представляет новый подход к сбору данных для обучения роботов м
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#survey", "#math", "#training"], "emoji": "🧠", "ru": {"title": "SSM: Эффективная альтернатива трансформерам для обработки последовательностей", "desc": "Это обзор моделей пространства состояний (SSM) как альтернативы трансформерам в машинном обучени
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#multimodal", "#survey", "#agents"], "emoji": "🤖", "ru": {"title": "Сравнение API и GUI агентов на основе LLM: путь к гибридным решениям", "desc": "Это исследование сравнивает агентов на основе больших языковых моделей (LLM), работающих через API и через графический интерфейс. Автор
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#small_models", "#open_source", "#cv", "#dataset", "#science", "#multimodal"], "emoji": "📄", "ru": {"title": "SmolDocling: компактная модель для комплексной обработки документов", "desc": "SmolDocling - это компактная модель обработки документов, сочетающая зрение и язык. Она генери
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#leakage", "#benchmark", "#security", "#survey", "#healthcare", "#data"], "emoji": "🛡️", "ru": {"title": "Защита приватности в федеративном обучении: анализ атак с инверсией градиента", "desc": "Статья посвящена анализу атак с инверсией градиента (GIA) в контексте федеративного обуч
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#multimodal", "#diffusion"], "emoji": "🌊", "ru": {"title": "FlowTok: эффективный переход между текстом и изображением через токены", "desc": "FlowTok - это новый подход к генерации изображений из текста и наоборот. Он использует метод согласования поток
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#alignment", "#healthcare", "#science", "#agents", "#reasoning", "#benchmark", "#multimodal"], "emoji": "💊", "ru": {"title": "TxAgent: ИИ-помощник для точной и персонализированной фармакотерапии", "desc": "TxAgent - это ИИ-агент для персонализированной терапии, использующий многоэта
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#cv", "#dataset", "#training", "#video", "#data"], "emoji": "🎥", "ru": {"title": "Революция в понимании видео: от автоматической разметки к точной локализации объектов", "desc": "Статья представляет новый подход к генерации подписей и локализации объектов в видео с использованием те
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#benchmark", "#architecture", "#video"], "emoji": "🎥", "ru": {"title": "VAMBA: эффективная обработка длинных видео с линейной сложностью", "desc": "Статья представляет новую модель VAMBA, гибрид Mamba и трансформера, для обработки длинных видео. VAM
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#cv", "#open_source", "#3d", "#optimization"], "emoji": "🔮", "ru": {"title": "VGGT: Универсальная нейросеть для комплексного 3D-анализа сцен", "desc": "VGGT - это нейронная сеть прямого распространения, которая напрямую выводит все ключевые 3D-атрибуты сцены из одного или нескольких
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#architecture", "#cv", "#optimization", "#open_source", "#training"], "emoji": "🧠", "ru": {"title": "Новый взгляд на внимание: Колмогоров-Арнольд сети в Vision Transformers", "desc": "Статья представляет новый подход к архитектуре нейронных сетей - Колмогоров-Арнольд внимание (KArAt
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#games", "#optimization", "#multimodal", "#dataset", "#training", "#architecture"], "emoji": "🛡️", "ru": {"title": "ARMOR: Эффективное улучшение мультимодальных моделей", "desc": "ARMOR - это новый подход к созданию унифицированных моделей для мультимодального понимания и генерации.
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#benchmark", "#training", "#multimodal", "#synthetic", "#alignment"], "emoji": "🦜", "ru": {"title": "Cockatiel: Новый стандарт в детальном описании видео", "desc": "Статья представляет новый подход к детальному описанию видео (VDC) под названием Cockatiel. Авторы разработали трехэта
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#cv", "#video", "#games", "#benchmark", "#optimization", "#architecture", "#training"], "emoji": "🧩", "ru": {"title": "NAR: Революция в авторегрессионном моделировании визуального контента", "desc": "Статья представляет новый подход к авторегрессионному моделированию визуального кон
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#interpretability", "#reasoning", "#multimodal", "#science", "#open_source", "#dataset", "#training", "#benchmark"], "emoji": "🔬", "ru": {"title": "Надежная оценка научных рассуждений мультимодальными ИИ-судьями", "desc": "В статье представлен ProJudgeBench - первый комплексный бенч
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#diffusion", "#training", "#cv", "#video"], "emoji": "🚀", "ru": {"title": "TDM: Революция в ускорении диффузионных моделей", "desc": "Статья представляет новый метод ускорения генерации изображений с помощью диффузионных моделей, называемый Trajectory Distribution Matching (TDM). TD
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#3d", "#optimization", "#cv", "#open_source"], "emoji": "👕", "ru": {"title": "Точная подгонка 3D-модели тела к одетому человеку с учетом плотности прилегания одежды", "desc": "Статья представляет новый метод ETCH для подгонки трехмерной модели тела к облаку точек одетого человека. E
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#cv", "#dataset"], "emoji": "🧠", "ru": {"title": "Крупные модели рассуждений уступают нейро-символическим подходам в аналогическом мышлении", "desc": "Эта работа представляет первую оценку двух современных моделей крупномасштабного рассуждения (LRM) - o3-
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#multilingual", "#machine_translation", "#open_source", "#multimodal", "#low_resource"], "emoji": "🗣️", "ru": {"title": "Расширение языковых моделей на речевую модальность", "desc": "В этой статье описывается расширение возможностей большой языковой модели (LLM) для работы с речью п
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#games", "#video", "#agents", "#open_source"], "emoji": "🎮", "ru": {"title": "Автоматическая сегментация видео для обучения ИИ-агентов сложным навыкам", "desc": "Статья представляет новый метод самообучения для сегментации длинных видео на последовательности семантически связанных н
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#agents", "#multimodal"], "emoji": "🚗", "ru": {"title": "GoalFlow: Точное планирование траекторий для автономного вождения", "desc": "GoalFlow - это новый метод автономного вождения для генерации высококачественных мультимодальных траекторий. Он решает
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#games", "#3d", "#optimization", "#architecture"], "emoji": "🌳", "ru": {"title": "Генерация высококачественных 3D-сеток с помощью древовидной последовательности", "desc": "TreeMeshGPT - это авторегрессивный трансформер для генерации высококачественных художественных сеток, согласова
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#synthetic", "#optimization", "#dataset", "#cv", "#3d"], "emoji": "🔍", "ru": {"title": "MaRI: Революция в поиске 3D-материалов", "desc": "Статья представляет MaRI - фреймворк для улучшения поиска реалистичных 3D-материалов. Он создает общее пространство признаков для синтетических и
[17.03.2025 23:10] Using data from previous issue: {"categories": ["#training", "#dataset", "#ethics", "#data"], "emoji": "🧠", "ru": {"title": "Групповое разобучение без потери устойчивости", "desc": "Статья посвящена проблеме группового машинного разобучения, когда данные для удаления из модели неравномерно распределены между группами. Авторы предл
[17.03.2025 23:10] Loading Chinese text from previous data.
[17.03.2025 23:10] Renaming data file.
[17.03.2025 23:10] Renaming previous data. hf_papers.json to ./d/2025-03-17.json
[17.03.2025 23:10] Saving new data file.
[17.03.2025 23:10] Generating page.
[17.03.2025 23:10] Renaming previous page.
[17.03.2025 23:10] Renaming previous data. index.html to ./d/2025-03-17.html
[17.03.2025 23:10] [Experimental] Generating Chinese page for reading.
[17.03.2025 23:10] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '名为', 'pinyin': 'míng wéi', 'trans': 'named'}, {'word': '视频', 'pinyin': 'shì pín', 'trans': 'video'}, {'word': '重新', 'pinyin': 'chóng xīn', 'trans': 'again'}, {'word': '渲染', 'pinyin': 'xuàn rán', 'trans': 'render'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '摄像机', 'pinyin': 'shè xiàng jī', 'trans': 'camera'}, {'word': '轨迹', 'pinyin': 'guǐ jì', 'trans': 'trajectory'}, {'word': '同时', 'pinyin': 'tóng shí', 'trans': 'simultaneously'}, {'word': '保持', 'pinyin': 'bǎo chí', 'trans': 'maintain'}, {'word': '多帧', 'pinyin': 'duō zhēn', 'trans': 'multi-frame'}, {'word': '外观', 'pinyin': 'wài guǎn', 'trans': 'appearance'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'}, {'word': '同步', 'pinyin': 'tóng bù', 'trans': 'synchronization'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '利用', 'pinyin': 'lì yòng', 'trans': 'utilize'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-trained'}, {'word': '文本', 'pinyin': 'wén běn', 'trans': 'text'}, {'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generate'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'}, {'word': '构建', 'pinyin': 'gòu jiàn', 'trans': 'construct'}, {'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '显示', 'pinyin': 'xiǎn shì', 'trans': 'display'}, {'word': '稳定', 'pinyin': 'wěn dìng', 'trans': 'stable'}, {'word': '超分辨率', 'pinyin': 'chāo fēn biàn lǜ', 'trans': 'super-resolution'}, {'word': '扩展', 'pinyin': 'kuò zhǎn', 'trans': 'extend'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '出色', 'pinyin': 'chū sè', 'trans': 'outstanding'}]
[17.03.2025 23:10] Renaming previous Chinese page.
[17.03.2025 23:10] Renaming previous data. zh.html to ./d/2025-03-16_zh_reading_task.html
[17.03.2025 23:10] Writing Chinese reading task.
[17.03.2025 23:10] Writing result.
[17.03.2025 23:10] Renaming log file.
[17.03.2025 23:10] Renaming previous data. log.txt to ./logs/2025-03-17_last_log.txt
