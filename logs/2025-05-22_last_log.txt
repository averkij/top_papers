[22.05.2025 07:15] Read previous papers.
[22.05.2025 07:15] Generating top page (month).
[22.05.2025 07:15] Writing top page (month).
[22.05.2025 08:15] Read previous papers.
[22.05.2025 08:15] Get feed.
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15277
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14302
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15809
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13909
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15045
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14231
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15612
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15400
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15210
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15779
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14357
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15146
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15765
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15781
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15656
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15404
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13934
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13529
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15778
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15776
[22.05.2025 08:15] Extract page data from URL. URL: https://huggingface.co/papers/2505.15817
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12650
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14827
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15816
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15791
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15047
[22.05.2025 08:15] Extract page data from URL. URL: https://huggingface.co/papers/2505.15034
[22.05.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14990
[22.05.2025 08:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[22.05.2025 08:15] No deleted papers detected.
[22.05.2025 08:15] Downloading and parsing papers (pdf, html). Total: 28.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15277.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15277.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15277.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.14302.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.14302.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.14302.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15809.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15809.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15809.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.13909.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.13909.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.13909.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15045.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15045.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15045.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.14231.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.14231.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.14231.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15612.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15612.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15612.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15400.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15400.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15400.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15210.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15210.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15210.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15779.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15779.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15779.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.14357.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.14357.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.14357.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15146.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15146.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15146.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15765.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15765.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15765.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15781.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15781.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15781.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15656.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15656.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15656.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15404.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15404.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15404.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.13934.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.13934.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.13934.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.13529.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.13529.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.13529.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15778.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15778.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15778.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15776.
[22.05.2025 08:15] Extra JSON file exists (./assets/json/2505.15776.json), skip PDF parsing.
[22.05.2025 08:15] Paper image links file exists (./assets/img_data/2505.15776.json), skip HTML parsing.
[22.05.2025 08:15] Success.
[22.05.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2505.15817.
[22.05.2025 08:16] Failed to download and parse paper https://huggingface.co/papers/2505.15817: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[22.05.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2505.12650.
[22.05.2025 08:16] Extra JSON file exists (./assets/json/2505.12650.json), skip PDF parsing.
[22.05.2025 08:16] Paper image links file exists (./assets/img_data/2505.12650.json), skip HTML parsing.
[22.05.2025 08:16] Success.
[22.05.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2505.14827.
[22.05.2025 08:16] Extra JSON file exists (./assets/json/2505.14827.json), skip PDF parsing.
[22.05.2025 08:16] Paper image links file exists (./assets/img_data/2505.14827.json), skip HTML parsing.
[22.05.2025 08:16] Success.
[22.05.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2505.15816.
[22.05.2025 08:16] Extra JSON file exists (./assets/json/2505.15816.json), skip PDF parsing.
[22.05.2025 08:16] Paper image links file exists (./assets/img_data/2505.15816.json), skip HTML parsing.
[22.05.2025 08:16] Success.
[22.05.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2505.15791.
[22.05.2025 08:16] Extra JSON file exists (./assets/json/2505.15791.json), skip PDF parsing.
[22.05.2025 08:16] Paper image links file exists (./assets/img_data/2505.15791.json), skip HTML parsing.
[22.05.2025 08:16] Success.
[22.05.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2505.15047.
[22.05.2025 08:16] Extra JSON file exists (./assets/json/2505.15047.json), skip PDF parsing.
[22.05.2025 08:16] Paper image links file exists (./assets/img_data/2505.15047.json), skip HTML parsing.
[22.05.2025 08:16] Success.
[22.05.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2505.15034.
[22.05.2025 08:18] Failed to download and parse paper https://huggingface.co/papers/2505.15034: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[22.05.2025 08:18] Downloading and parsing paper https://huggingface.co/papers/2505.14990.
[22.05.2025 08:18] Extra JSON file exists (./assets/json/2505.14990.json), skip PDF parsing.
[22.05.2025 08:18] Paper image links file exists (./assets/img_data/2505.14990.json), skip HTML parsing.
[22.05.2025 08:18] Success.
[22.05.2025 08:18] Enriching papers with extra data.
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 0. Web navigation is a unique domain that can automate many repetitive real-life tasks and is challenging as it requires long-horizon sequential decision making beyond typical multimodal large language model (MLLM) tasks. Yet, specialized reward models for web navigation that can be utilized during bot...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 1. Large language models (LLMs) demand substantial computational and memory resources, creating deployment challenges. Quantization-aware training (QAT) addresses these challenges by reducing model precision while maintaining performance. However, the scaling behavior of QAT, especially at 4-bit precis...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 2. We introduce MMaDA, a novel class of multimodal diffusion foundation models designed to achieve superior performance across diverse domains such as textual reasoning, multimodal understanding, and text-to-image generation. The approach is distinguished by three key innovations: (i) MMaDA adopts a un...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 3. Scaling up high-quality trajectory data has long been a critical bottleneck for developing human-like computer use agents. We introduce PC Agent-E, an efficient agent training framework that significantly reduces reliance on large-scale human demonstrations. Starting with just 312 human-annotated co...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 4. Large language model (LLM)-based embedding models, benefiting from large scale pre-training and post-training, have begun to surpass BERT and T5-based models on general-purpose text embedding tasks such as document retrieval. However, a fundamental limitation of LLM embeddings lies in the unidirecti...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 5. Traditional visual grounding methods primarily focus on single-image scenarios with simple textual references. However, extending these methods to real-world scenarios that involve implicit and complex instructions, particularly in conjunction with multiple images, poses significant challenges, whic...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 6. Large Reasoning Models (LRMs) have shown remarkable capabilities in solving complex problems through reinforcement learning (RL), particularly by generating long reasoning traces. However, these extended outputs often exhibit substantial redundancy, which limits the efficiency of LRMs. In this paper...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 7. Large reasoning models (LRMs) achieve remarkable performance via long reasoning chains, but often incur excessive computational overhead due to redundant reasoning, especially on simple tasks. In this work, we systematically quantify the upper bounds of LRMs under both Long-Thinking and No-Thinking ...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 8. Knowledge graph-based retrieval-augmented generation seeks to mitigate hallucinations in Large Language Models (LLMs) caused by insufficient or outdated knowledge. However, existing methods often fail to fully exploit the prior knowledge embedded in knowledge graphs (KGs), particularly their structu...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 9. Current text-to-image (T2I) generation models achieve promising results, but they fail on the scenarios where the knowledge implied in the text prompt is uncertain. For example, a T2I model released in February would struggle to generate a suitable poster for a movie premiering in April, because the...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 10. World models, which predict transitions based on history observation and action sequences, have shown great promise in improving data efficiency for sequential decision making. However, existing world models often require extensive domain-specific training and still produce low-fidelity, coarse pred...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 11. Playing video games requires perception, memory, and planning, exactly the faculties modern large language model (LLM) agents are expected to master. We study the major challenges in using popular video games to evaluate modern LLMs and find that directly dropping LLMs into games cannot make an effe...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 12. Acquiring detailed 3D scenes typically demands costly equipment, multi-view data, or labor-intensive modeling. Therefore, a lightweight alternative, generating complex 3D scenes from a single top-down image, plays an essential role in real-world applications. While recent 3D generative models have a...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 13. Diffusion Language Models (DLMs) have been seen as a promising competitor for autoregressive language models. However, diffusion language models have long been constrained by slow inference. A core challenge is that their non-autoregressive architecture and bidirectional attention preclude the key-v...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 14. Fine-tuning on open-source Large Language Models (LLMs) with proprietary data is now a standard practice for downstream developers to obtain task-specific LLMs. Surprisingly, we reveal a new and concerning risk along with the practice: the creator of the open-source LLMs can later extract the privat...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 15. Large Reasoning Models (LRMs) have achieved remarkable success on reasoning-intensive tasks such as mathematics and programming. However, their enhanced reasoning capabilities do not necessarily translate to improved safety performance-and in some cases, may even degrade it. This raises an important...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 16. World models predict state transitions in response to actions and are increasingly developed across diverse modalities. However, standard training objectives such as maximum likelihood estimation (MLE) often misalign with task-specific goals of world models, i.e., transition prediction metrics like ...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 17. Recent advances in Large Reasoning Models (LRMs) have shown impressive capabilities in mathematical and logical reasoning. However, current LRMs rarely admit ignorance or respond with "I don't know". Instead, they often produce incorrect answers while showing undue confidence, raising concerns about...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 18. Human cognition typically involves thinking through abstract, fluid concepts rather than strictly using discrete linguistic tokens. Current reasoning models, however, are constrained to reasoning within the boundaries of human language, processing discrete token embeddings that represent fixed point...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 19. Conversational search systems require effective handling of context-dependent queries that often contain ambiguity, omission, and coreference. Conversational Query Reformulation (CQR) addresses this challenge by transforming these queries into self-contained forms suitable for off-the-shelf retrieve...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 20. Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typ...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 21. Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers a potential source of structural data, c...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 22. In standard autoregressive generation, an LLM predicts the next-token distribution, samples a discrete token, and then discards the distribution, passing only the sampled token as new input. To preserve this distribution's rich information, we propose Mixture of Inputs (MoI), a training-free method ...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 23. Large multimodal models excel in multimodal tasks but face significant computational challenges due to excessive computation on visual tokens. Unlike token reduction methods that focus on token-level redundancy, we identify and study the computation-level redundancy on vision tokens to ensure no inf...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 24. Diffusion models have emerged as powerful generative tools across various domains, yet tailoring pre-trained models to exhibit specific desirable properties remains challenging. While reinforcement learning (RL) offers a promising solution,current methods struggle to simultaneously achieve stable, e...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 25. Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failur...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 26. Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifier...
[22.05.2025 08:18] ********************************************************************************
[22.05.2025 08:18] Abstract 27. Code-switching is a common phenomenon of alternating between different languages in the same utterance, thought, or conversation. We posit that humans code-switch because they feel more comfortable talking about certain topics and domains in one language than another. With the rise of knowledge-inte...
[22.05.2025 08:18] Read previous papers.
[22.05.2025 08:18] Generating reviews via LLM API.
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#survey", "#benchmark", "#rl", "#dataset"], "emoji": "🧭", "ru": {"title": "Web-Shepherd: эффективная модель вознаграждения для автоматизации веб-навигации", "desc": "Статья представляет Web-Shepherd - первую модель вознаграждения процесса (PRM) для в
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#training", "#optimization", "#inference"], "emoji": "🔬", "ru": {"title": "Масштабирование квантизации в больших языковых моделях: новые горизонты эффективности", "desc": "Статья исследует масштабируемость квантизации с учетом обучения (QAT) для больших языковых моделей (LLM). Автор
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#training", "#multimodal", "#open_source", "#architecture", "#reasoning", "#diffusion", "#rl"], "emoji": "🧠", "ru": {"title": "MMaDA: Унифицированная мультимодальная диффузионная модель для рассуждений и генерации", "desc": "MMaDA - это новый класс мультимодальных диффузионных фунда
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#synthetic", "#benchmark", "#transfer_learning", "#training", "#dataset", "#agents"], "emoji": "🖥️", "ru": {"title": "Эффективное обучение компьютерных агентов на малых данных", "desc": "Статья представляет PC Agent-E - эффективную систему обучения агентов для использования компьюте
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#diffusion", "#reasoning", "#benchmark", "#training", "#long_context", "#architecture", "#dataset"], "emoji": "🧠", "ru": {"title": "Диффузионные модели: новый подход к текстовым эмбеддингам", "desc": "В этой статье представлено исследование применения диффузионных языковых моделей д
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#training", "#multimodal", "#reasoning", "#rl", "#dataset"], "emoji": "🧠", "ru": {"title": "Улучшение визуальной привязки через обучение с подкреплением и рассуждения", "desc": "Статья представляет UniVG-R1 - мультимодальную большую языковую модель для универсальной визуальной привя
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#training", "#optimization"], "emoji": "💡", "ru": {"title": "Эффективное рассуждение: оптимизация цепочек мыслей в крупных языковых моделях", "desc": "Статья представляет новый метод LASER для повышения эффективности рассуждений в крупных моделях машинного обуче
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training", "#reasoning", "#benchmark"], "emoji": "🧠", "ru": {"title": "Эффективное рассуждение: меньше думай, больше делай", "desc": "Эта статья представляет новый подход к оптимизации работы больших моделей рассуждений (LRM). Авторы предлагают мет
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rag", "#benchmark", "#hallucinations"], "emoji": "🧠", "ru": {"title": "Повышение надежности языковых моделей через осмысление априорных знаний", "desc": "Статья представляет новый метод под названием 'Deliberation over Priors' (DP) для улучшения работ
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#rag", "#alignment", "#dataset", "#multimodal", "#diffusion"], "emoji": "🖼️", "ru": {"title": "Интернет-augmented T2I: преодоление неопределенности в генерации изображений", "desc": "Статья представляет новый подход к генерации изображений по текстовому описанию (T2I) с использовани
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#architecture", "#games", "#robotics", "#diffusion", "#transfer_learning", "#rl", "#agents", "#video"], "emoji": "🎥", "ru": {"title": "Превращение моделей диффузии видео в интерактивные модели мира", "desc": "В статье представлен метод Vid2World, позволяющий использовать предобученн
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#games", "#agents", "#transfer_learning"], "emoji": "🎮", "ru": {"title": "Видеоигры как полигон для оценки и обучения языковых моделей", "desc": "Исследователи изучают возможности использования видеоигр для оценки современных больших языковых моделей (LLM). Они 
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#synthetic", "#3d"], "emoji": "🏙️", "ru": {"title": "Реалистичные 3D-города из одного изображения без обучения", "desc": "3DTown - это новый подход к генерации реалистичных трехмерных сцен на основе единственного вида сверху, не требующий дополнительного обучения. Метод основан на г
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#architecture", "#inference", "#optimization", "#diffusion", "#benchmark"], "emoji": "🚀", "ru": {"title": "Ускорение диффузионных языковых моделей с помощью умного кэширования", "desc": "Статья представляет новый механизм ускорения вывода для диффузионных языковых моделей (DLM) - от
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#data", "#security", "#open_source", "#training", "#leakage"], "emoji": "🕵️", "ru": {"title": "Скрытая угроза: как открытые языковые модели могут раскрыть ваши секретные данные", "desc": "Эта статья раскрывает новый риск безопасности при дообучении открытых языковых моделей (LLM) на
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#data", "#math", "#reasoning", "#training", "#safety"], "emoji": "🛡️", "ru": {"title": "Повышение безопасности LRM: простота может быть ключом", "desc": "Эта статья исследует способы повышения безопасности Моделей Крупномасштабного Рассуждения (LRM) с помощью Контролируемой Тонкой Н
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#rlhf", "#training", "#multimodal", "#optimization", "#reasoning", "#games", "#rl", "#agents", "#video"], "emoji": "🌐", "ru": {"title": "RLVR-World: Революция в обучении мировых моделей", "desc": "RLVR-World - это новый подход к обучению мировых моделей, использующий обучение с подк
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#hallucinations", "#reasoning", "#training", "#math"], "emoji": "🧠", "ru": {"title": "Повышение надежности ИИ-рассуждений через осознание границ знаний", "desc": "Это исследование посвящено проблеме чрезмерной уверенности и неточности ответов больших моделей рассуждений (LRM) в мате
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#math", "#interpretability", "#reasoning", "#benchmark", "#training"], "emoji": "🧠", "ru": {"title": "Мягкое мышление: преодоление границ дискретного языкового рассуждения в ИИ", "desc": "Эта статья представляет новый метод машинного обучения под названием 'Soft Thinking', который и
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#optimization", "#training", "#dataset", "#rag", "#rl", "#reasoning"], "emoji": "🔍", "ru": {"title": "Самообучающаяся система переформулировки запросов для диалогового поиска", "desc": "Статья представляет ConvSearch-R1 - первую самоуправляемую систему для переформулировки контекстн
[22.05.2025 08:18] Querying the API.
[22.05.2025 08:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typically natural language. Although some methods explored modality selection or augmentation at inference time, the training process remains modality-blind, limiting synergy among modalities. To fill in this gap, we propose Mixture-of-Thought (MoT), a framework that enables LLMs to reason across three complementary modalities: natural language, code, and a newly introduced symbolic modality, truth-table, which systematically enumerates logical cases and partially mitigates key failure modes in natural language reasoning. MoT adopts a two-phase design: (1) self-evolving MoT training, which jointly learns from filtered, self-generated rationales across modalities; and (2) MoT inference, which fully leverages the synergy of three modalities to produce better predictions. Experiments on logical reasoning benchmarks including FOLIO and ProofWriter demonstrate that our MoT framework consistently and significantly outperforms strong LLM baselines with single-modality chain-of-thought approaches, achieving up to +11.7pp average accuracy gain. Further analyses show that our MoT framework benefits both training and inference stages; that it is particularly effective on harder logical reasoning problems; and that different modalities contribute complementary strengths, with truth-table reasoning helping to overcome key bottlenecks in natural language inference.
[22.05.2025 08:18] Response: {
  "desc": "Статья представляет новый подход к обучению языковых моделей - Mixture-of-Thought (MoT). MoT позволяет большим языковым моделям (LLM) рассуждать, используя три модальности: естественный язык, код и новую символическую модальность - таблицу истинности. Метод включает двухфазовый дизайн: самоэволюционирующее обучение MoT и вывод MoT. Эксперименты показывают, что MoT значительно превосходит базовые LLM с подходом цепочки рассуждений в одной модальности, особенно на сложных задачах логического вывода.",
  "emoji": "🧠",
  "title": "Смешение модальностей для улучшения логических рассуждений ИИ"
}
[22.05.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typically natural language. Although some methods explored modality selection or augmentation at inference time, the training process remains modality-blind, limiting synergy among modalities. To fill in this gap, we propose Mixture-of-Thought (MoT), a framework that enables LLMs to reason across three complementary modalities: natural language, code, and a newly introduced symbolic modality, truth-table, which systematically enumerates logical cases and partially mitigates key failure modes in natural language reasoning. MoT adopts a two-phase design: (1) self-evolving MoT training, which jointly learns from filtered, self-generated rationales across modalities; and (2) MoT inference, which fully leverages the synergy of three modalities to produce better predictions. Experiments on logical reasoning benchmarks including FOLIO and ProofWriter demonstrate that our MoT framework consistently and significantly outperforms strong LLM baselines with single-modality chain-of-thought approaches, achieving up to +11.7pp average accuracy gain. Further analyses show that our MoT framework benefits both training and inference stages; that it is particularly effective on harder logical reasoning problems; and that different modalities contribute complementary strengths, with truth-table reasoning helping to overcome key bottlenecks in natural language inference."

[22.05.2025 08:18] Response: ```python
['MULTIMODAL', 'TRAINING', 'BENCHMARK']
```
[22.05.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typically natural language. Although some methods explored modality selection or augmentation at inference time, the training process remains modality-blind, limiting synergy among modalities. To fill in this gap, we propose Mixture-of-Thought (MoT), a framework that enables LLMs to reason across three complementary modalities: natural language, code, and a newly introduced symbolic modality, truth-table, which systematically enumerates logical cases and partially mitigates key failure modes in natural language reasoning. MoT adopts a two-phase design: (1) self-evolving MoT training, which jointly learns from filtered, self-generated rationales across modalities; and (2) MoT inference, which fully leverages the synergy of three modalities to produce better predictions. Experiments on logical reasoning benchmarks including FOLIO and ProofWriter demonstrate that our MoT framework consistently and significantly outperforms strong LLM baselines with single-modality chain-of-thought approaches, achieving up to +11.7pp average accuracy gain. Further analyses show that our MoT framework benefits both training and inference stages; that it is particularly effective on harder logical reasoning problems; and that different modalities contribute complementary strengths, with truth-table reasoning helping to overcome key bottlenecks in natural language inference."

[22.05.2025 08:18] Response: ```python
["REASONING"]
```
[22.05.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces the Mixture-of-Thought (MoT) framework, which enhances large language models (LLMs) by enabling them to reason across three different modalities: natural language, code, and a new symbolic modality called truth-table. Unlike traditional methods that rely on a single reasoning modality during training, MoT allows for a more integrated approach, improving the model\'s ability to tackle logical reasoning tasks. The framework consists of two phases: a self-evolving training phase that learns from generated rationales across modalities, and an inference phase that utilizes the strengths of all three modalities for better predictions. Experimental results show that MoT significantly outperforms existing single-modality approaches, particularly on challenging logical reasoning problems, achieving notable accuracy improvements.","title":"Empowering LLMs with Multi-Modal Reasoning for Enhanced Logic Solving"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces the Mixture-of-Thought (MoT) framework, which enhances large language models (LLMs) by enabling them to reason across three different modalities: natural language, code, and a new symbolic modality called truth-table. Unlike traditional methods that rely on a single reasoning modality during training, MoT allows for a more integrated approach, improving the model's ability to tackle logical reasoning tasks. The framework consists of two phases: a self-evolving training phase that learns from generated rationales across modalities, and an inference phase that utilizes the strengths of all three modalities for better predictions. Experimental results show that MoT significantly outperforms existing single-modality approaches, particularly on challenging logical reasoning problems, achieving notable accuracy improvements.", title='Empowering LLMs with Multi-Modal Reasoning for Enhanced Logic Solving'))
[22.05.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为混合思维（Mixture-of-Thought, MoT）的框架，旨在提升大型语言模型（LLM）在逻辑推理中的表现。与传统方法只使用自然语言作为推理模式不同，MoT结合了自然语言、代码和一种新引入的符号模式——真值表，以增强推理能力。该框架采用两阶段设计：自我演化的MoT训练和MoT推理，能够在训练和推理阶段充分利用三种模式的协同效应。实验结果表明，MoT在逻辑推理基准测试中显著超越了单一模式的LLM基线，尤其在处理更复杂的逻辑问题时表现优异。","title":"多模态推理，提升逻辑思维能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为混合思维（Mixture-of-Thought, MoT）的框架，旨在提升大型语言模型（LLM）在逻辑推理中的表现。与传统方法只使用自然语言作为推理模式不同，MoT结合了自然语言、代码和一种新引入的符号模式——真值表，以增强推理能力。该框架采用两阶段设计：自我演化的MoT训练和MoT推理，能够在训练和推理阶段充分利用三种模式的协同效应。实验结果表明，MoT在逻辑推理基准测试中显著超越了单一模式的LLM基线，尤其在处理更复杂的逻辑问题时表现优异。', title='多模态推理，提升逻辑思维能力'))
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#data", "#multimodal", "#open_source", "#benchmark", "#dataset", "#agents", "#science"], "emoji": "🔬", "ru": {"title": "AutoMat: от микроскопических изображений к атомным структурам", "desc": "AutoMat - это новый конвейер для автоматического преобразования изображений сканирующей пр
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#math", "#training", "#reasoning", "#optimization"], "emoji": "🧠", "ru": {"title": "Смешивание входов для улучшения генерации языковых моделей", "desc": "Исследователи предложили новый метод автореградивной генерации текста под названием Mixture of Inputs (MoI). В отличие от стандар
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#open_source", "#architecture", "#inference"], "emoji": "🔍", "ru": {"title": "ProxyV: Оптимизация вычислений для визуальных токенов в мультимодальных моделях", "desc": "Статья представляет новый подход ProxyV для повышения эффективности мультимодальны
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#diffusion", "#rl", "#training", "#optimization"], "emoji": "🚀", "ru": {"title": "VARD: Усиление диффузионных моделей с помощью обучения с подкреплением", "desc": "Статья представляет новый метод под названием VARD (Value-based Reinforced Diffusion) для улучшения диффузионных моделе
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#multimodal", "#open_source", "#rl", "#agents", "#science"], "emoji": "🧪", "ru": {"title": "PiFlow: Революция в автоматизированном научном открытии", "desc": "PiFlow - это информационно-теоретическая система для автоматизированного научного открытия на основе многоагентных систем с 
[22.05.2025 08:18] Querying the API.
[22.05.2025 08:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifiers that are fixed (rule-based or frozen pretrained) or trained discriminatively via supervised fine-tuning (SFT). Such designs are susceptible to reward hacking and generalize poorly beyond their training distributions. To overcome these limitations, we propose Tango, a novel framework that uses RL to concurrently train both an LLM generator and a verifier in an interleaved manner. A central innovation of Tango is its generative, process-level LLM verifier, which is trained via RL and co-evolves with the generator. Importantly, the verifier is trained solely based on outcome-level verification correctness rewards without requiring explicit process-level annotations. This generative RL-trained verifier exhibits improved robustness and superior generalization compared to deterministic or SFT-trained verifiers, fostering effective mutual reinforcement with the generator. Extensive experiments demonstrate that both components of Tango achieve state-of-the-art results among 7B/8B-scale models: the generator attains best-in-class performance across five competition-level math benchmarks and four challenging out-of-domain reasoning tasks, while the verifier leads on the ProcessBench dataset. Remarkably, both components exhibit particularly substantial improvements on the most difficult mathematical reasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.
[22.05.2025 08:18] Response: {
  "desc": "Статья представляет новый метод Tango для улучшения способностей больших языковых моделей (БЯМ) к рассуждению с помощью обучения с подкреплением. В отличие от существующих подходов, Tango обучает одновременно и генеративную модель, и верификатор, используя обучение с подкреплением. Генеративный верификатор на основе БЯМ, обученный с помощью RL, демонстрирует улучшенную устойчивость и обобщение по сравнению с детерминированными верификаторами или обученными с помощью SFT. Эксперименты показывают, что обе компоненты Tango достигают наилучших результатов среди моделей масштаба 7B/8B на различных тестах по математическим рассуждениям и задачам вне обучающего распределения.",

  "emoji": "🕺",

  "title": "Tango: Танец обучения с подкреплением для улучшения рассуждений БЯМ"
}
[22.05.2025 08:18] Renaming some terms.
[22.05.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifiers that are fixed (rule-based or frozen pretrained) or trained discriminatively via supervised fine-tuning (SFT). Such designs are susceptible to reward hacking and generalize poorly beyond their training distributions. To overcome these limitations, we propose Tango, a novel framework that uses RL to concurrently train both an LLM generator and a verifier in an interleaved manner. A central innovation of Tango is its generative, process-level LLM verifier, which is trained via RL and co-evolves with the generator. Importantly, the verifier is trained solely based on outcome-level verification correctness rewards without requiring explicit process-level annotations. This generative RL-trained verifier exhibits improved robustness and superior generalization compared to deterministic or SFT-trained verifiers, fostering effective mutual reinforcement with the generator. Extensive experiments demonstrate that both components of Tango achieve state-of-the-art results among 7B/8B-scale models: the generator attains best-in-class performance across five competition-level math benchmarks and four challenging out-of-domain reasoning tasks, while the verifier leads on the ProcessBench dataset. Remarkably, both components exhibit particularly substantial improvements on the most difficult mathematical reasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango."

[22.05.2025 08:18] Response: ```python
['RL', 'RLHF', 'MATH', 'TRAINING']
```
[22.05.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifiers that are fixed (rule-based or frozen pretrained) or trained discriminatively via supervised fine-tuning (SFT). Such designs are susceptible to reward hacking and generalize poorly beyond their training distributions. To overcome these limitations, we propose Tango, a novel framework that uses RL to concurrently train both an LLM generator and a verifier in an interleaved manner. A central innovation of Tango is its generative, process-level LLM verifier, which is trained via RL and co-evolves with the generator. Importantly, the verifier is trained solely based on outcome-level verification correctness rewards without requiring explicit process-level annotations. This generative RL-trained verifier exhibits improved robustness and superior generalization compared to deterministic or SFT-trained verifiers, fostering effective mutual reinforcement with the generator. Extensive experiments demonstrate that both components of Tango achieve state-of-the-art results among 7B/8B-scale models: the generator attains best-in-class performance across five competition-level math benchmarks and four challenging out-of-domain reasoning tasks, while the verifier leads on the ProcessBench dataset. Remarkably, both components exhibit particularly substantial improvements on the most difficult mathematical reasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango."

[22.05.2025 08:18] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[22.05.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Tango, a new framework that enhances large language models (LLMs) using reinforcement learning (RL). Unlike traditional methods that rely on fixed or supervised verifiers, Tango trains both the LLM generator and the verifier together, allowing them to improve each other through mutual reinforcement. The verifier in Tango is generative and learns from outcome-level rewards, making it more robust and capable of generalizing better to new tasks. Experiments show that Tango achieves state-of-the-art performance on various reasoning benchmarks, especially in challenging mathematical problems.","title":"Tango: Reinforcing Language Models with Generative Verifiers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Tango, a new framework that enhances large language models (LLMs) using reinforcement learning (RL). Unlike traditional methods that rely on fixed or supervised verifiers, Tango trains both the LLM generator and the verifier together, allowing them to improve each other through mutual reinforcement. The verifier in Tango is generative and learns from outcome-level rewards, making it more robust and capable of generalizing better to new tasks. Experiments show that Tango achieves state-of-the-art performance on various reasoning benchmarks, especially in challenging mathematical problems.', title='Tango: Reinforcing Language Models with Generative Verifiers'))
[22.05.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"强化学习（RL）最近成为提升大型语言模型（LLM）推理能力的一种有效方法。在现有的RL后训练方法中，通常使用固定的验证器，这可能导致奖励黑客行为和泛化能力差。为了解决这些问题，我们提出了Tango框架，它通过交替训练LLM生成器和验证器来实现更好的性能。Tango的创新在于其生成式的过程级验证器，能够在没有明确过程级注释的情况下，仅基于结果级验证奖励进行训练，从而提高了鲁棒性和泛化能力。","title":"Tango：强化学习提升语言模型推理能力的创新框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='强化学习（RL）最近成为提升大型语言模型（LLM）推理能力的一种有效方法。在现有的RL后训练方法中，通常使用固定的验证器，这可能导致奖励黑客行为和泛化能力差。为了解决这些问题，我们提出了Tango框架，它通过交替训练LLM生成器和验证器来实现更好的性能。Tango的创新在于其生成式的过程级验证器，能够在没有明确过程级注释的情况下，仅基于结果级验证奖励进行训练，从而提高了鲁棒性和泛化能力。', title='Tango：强化学习提升语言模型推理能力的创新框架'))
[22.05.2025 08:18] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#alignment", "#benchmark", "#open_source", "#inference", "#low_resource", "#multilingual"], "emoji": "🌐", "ru": {"title": "Раскрытие потенциала многоязычности в искусственном интеллекте", "desc": "Исследователи изучают феномен языково-специфичных знаний (LS
[22.05.2025 08:18] Loading Chinese text from previous data.
[22.05.2025 08:18] Renaming data file.
[22.05.2025 08:18] Renaming previous data. hf_papers.json to ./d/2025-05-22.json
[22.05.2025 08:18] Saving new data file.
[22.05.2025 08:18] Generating page.
[22.05.2025 08:18] Renaming previous page.
[22.05.2025 08:18] Renaming previous data. index.html to ./d/2025-05-22.html
[22.05.2025 08:18] [Experimental] Generating Chinese page for reading.
[22.05.2025 08:18] Chinese vocab [{'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open source'}, {'word': '基础模型', 'pinyin': 'jī chǔ mó xíng', 'trans': 'foundational model'}, {'word': '统一', 'pinyin': 'tǒng yī', 'trans': 'unify'}, {'word': '处理', 'pinyin': 'chǔ lǐ', 'trans': 'process'}, {'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generate'}, {'word': '模式', 'pinyin': 'mó shì', 'trans': 'mode'}, {'word': '数据', 'pinyin': 'shù jù', 'trans': 'data'}, {'word': '文本', 'pinyin': 'wén běn', 'trans': 'text'}, {'word': '图像', 'pinyin': 'tú xiàng', 'trans': 'image'}, {'word': '视频', 'pinyin': 'shì pín', 'trans': 'video'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pretrain'}, {'word': '展现', 'pinyin': 'zhǎn xiàn', 'trans': 'demonstrate'}, {'word': '复杂', 'pinyin': 'fù zá', 'trans': 'complex'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'}, {'word': '超越', 'pinyin': 'chāo yuè', 'trans': 'surpass'}, {'word': '理解', 'pinyin': 'lǐ jiě', 'trans': 'understanding'}, {'word': '方面', 'pinyin': 'fāng miàn', 'trans': 'aspect'}, {'word': '高级', 'pinyin': 'gāo jí', 'trans': 'advanced'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '团队', 'pinyin': 'tuán duì', 'trans': 'team'}, {'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'discovery'}, {'word': '细节', 'pinyin': 'xì jiě', 'trans': 'detail'}, {'word': '协议', 'pinyin': 'xié yì', 'trans': 'protocol'}, {'word': '检查点', 'pinyin': 'jiǎn chá diǎn', 'trans': 'checkpoint'}, {'word': '促进', 'pinyin': 'cù jìn', 'trans': 'promote'}]
[22.05.2025 08:18] Renaming previous Chinese page.
[22.05.2025 08:18] Renaming previous data. zh.html to ./d/2025-05-21_zh_reading_task.html
[22.05.2025 08:18] Writing Chinese reading task.
[22.05.2025 08:18] Writing result.
[22.05.2025 08:18] Renaming log file.
[22.05.2025 08:18] Renaming previous data. log.txt to ./logs/2025-05-22_last_log.txt
