[22.05.2025 14:12] Read previous papers.
[22.05.2025 14:12] Generating top page (month).
[22.05.2025 14:12] Writing top page (month).
[22.05.2025 15:12] Read previous papers.
[22.05.2025 15:12] Get feed.
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15277
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14302
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15809
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14231
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15045
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13909
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15612
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15400
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14357
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14766
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15779
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15210
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15146
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15765
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15781
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15404
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15817
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15776
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15656
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13934
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13529
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15778
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14827
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12650
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15791
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15034
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15816
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15524
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15047
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15406
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14818
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14336
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14157
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14990
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14101
[22.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11454
[22.05.2025 15:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[22.05.2025 15:12] No deleted papers detected.
[22.05.2025 15:12] Downloading and parsing papers (pdf, html). Total: 36.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15277.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15277.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15277.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14302.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14302.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14302.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15809.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15809.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15809.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14231.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14231.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14231.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15045.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15045.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15045.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.13909.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.13909.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.13909.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15612.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15612.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15612.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15400.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15400.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15400.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14357.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14357.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14357.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14766.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14766.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14766.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15779.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15779.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15779.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15210.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15210.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15210.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15146.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15146.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15146.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15765.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15765.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15765.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15781.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15781.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15781.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15404.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15404.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15404.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15817.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15817.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15817.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15776.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15776.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15776.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15656.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15656.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15656.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.13934.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.13934.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.13934.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.13529.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.13529.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.13529.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15778.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15778.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15778.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14827.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14827.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14827.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.12650.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.12650.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.12650.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15791.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15791.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15791.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15034.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15034.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15034.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15816.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15816.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15816.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15524.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15524.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15524.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15047.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15047.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15047.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15406.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15406.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15406.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14818.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14818.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14818.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14336.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14336.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14336.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14157.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14157.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14157.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14990.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14990.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14990.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14101.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14101.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14101.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.11454.
[22.05.2025 15:12] Extra JSON file exists (./assets/json/2505.11454.json), skip PDF parsing.
[22.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.11454.json), skip HTML parsing.
[22.05.2025 15:12] Success.
[22.05.2025 15:12] Enriching papers with extra data.
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 0. Web navigation is a unique domain that can automate many repetitive real-life tasks and is challenging as it requires long-horizon sequential decision making beyond typical multimodal large language model (MLLM) tasks. Yet, specialized reward models for web navigation that can be utilized during bot...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 1. Large language models (LLMs) demand substantial computational and memory resources, creating deployment challenges. Quantization-aware training (QAT) addresses these challenges by reducing model precision while maintaining performance. However, the scaling behavior of QAT, especially at 4-bit precis...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 2. We introduce MMaDA, a novel class of multimodal diffusion foundation models designed to achieve superior performance across diverse domains such as textual reasoning, multimodal understanding, and text-to-image generation. The approach is distinguished by three key innovations: (i) MMaDA adopts a un...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 3. Traditional visual grounding methods primarily focus on single-image scenarios with simple textual references. However, extending these methods to real-world scenarios that involve implicit and complex instructions, particularly in conjunction with multiple images, poses significant challenges, whic...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 4. Large language model (LLM)-based embedding models, benefiting from large scale pre-training and post-training, have begun to surpass BERT and T5-based models on general-purpose text embedding tasks such as document retrieval. However, a fundamental limitation of LLM embeddings lies in the unidirecti...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 5. Scaling up high-quality trajectory data has long been a critical bottleneck for developing human-like computer use agents. We introduce PC Agent-E, an efficient agent training framework that significantly reduces reliance on large-scale human demonstrations. Starting with just 312 human-annotated co...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 6. Large Reasoning Models (LRMs) have shown remarkable capabilities in solving complex problems through reinforcement learning (RL), particularly by generating long reasoning traces. However, these extended outputs often exhibit substantial redundancy, which limits the efficiency of LRMs. In this paper...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 7. Large reasoning models (LRMs) achieve remarkable performance via long reasoning chains, but often incur excessive computational overhead due to redundant reasoning, especially on simple tasks. In this work, we systematically quantify the upper bounds of LRMs under both Long-Thinking and No-Thinking ...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 8. World models, which predict transitions based on history observation and action sequences, have shown great promise in improving data efficiency for sequential decision making. However, existing world models often require extensive domain-specific training and still produce low-fidelity, coarse pred...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 9. We introduce Toto, a time series forecasting foundation model with 151 million parameters. Toto uses a modern decoder-only architecture coupled with architectural innovations designed to account for specific challenges found in multivariate observability time series data. Toto's pre-training corpus ...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 10. Current text-to-image (T2I) generation models achieve promising results, but they fail on the scenarios where the knowledge implied in the text prompt is uncertain. For example, a T2I model released in February would struggle to generate a suitable poster for a movie premiering in April, because the...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 11. Knowledge graph-based retrieval-augmented generation seeks to mitigate hallucinations in Large Language Models (LLMs) caused by insufficient or outdated knowledge. However, existing methods often fail to fully exploit the prior knowledge embedded in knowledge graphs (KGs), particularly their structu...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 12. Playing video games requires perception, memory, and planning, exactly the faculties modern large language model (LLM) agents are expected to master. We study the major challenges in using popular video games to evaluate modern LLMs and find that directly dropping LLMs into games cannot make an effe...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 13. Acquiring detailed 3D scenes typically demands costly equipment, multi-view data, or labor-intensive modeling. Therefore, a lightweight alternative, generating complex 3D scenes from a single top-down image, plays an essential role in real-world applications. While recent 3D generative models have a...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 14. Diffusion Language Models (DLMs) have been seen as a promising competitor for autoregressive language models. However, diffusion language models have long been constrained by slow inference. A core challenge is that their non-autoregressive architecture and bidirectional attention preclude the key-v...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 15. Large Reasoning Models (LRMs) have achieved remarkable success on reasoning-intensive tasks such as mathematics and programming. However, their enhanced reasoning capabilities do not necessarily translate to improved safety performance-and in some cases, may even degrade it. This raises an important...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 16. Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typ...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 17. Conversational search systems require effective handling of context-dependent queries that often contain ambiguity, omission, and coreference. Conversational Query Reformulation (CQR) addresses this challenge by transforming these queries into self-contained forms suitable for off-the-shelf retrieve...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 18. Fine-tuning on open-source Large Language Models (LLMs) with proprietary data is now a standard practice for downstream developers to obtain task-specific LLMs. Surprisingly, we reveal a new and concerning risk along with the practice: the creator of the open-source LLMs can later extract the privat...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 19. World models predict state transitions in response to actions and are increasingly developed across diverse modalities. However, standard training objectives such as maximum likelihood estimation (MLE) often misalign with task-specific goals of world models, i.e., transition prediction metrics like ...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 20. Recent advances in Large Reasoning Models (LRMs) have shown impressive capabilities in mathematical and logical reasoning. However, current LRMs rarely admit ignorance or respond with "I don't know". Instead, they often produce incorrect answers while showing undue confidence, raising concerns about...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 21. Human cognition typically involves thinking through abstract, fluid concepts rather than strictly using discrete linguistic tokens. Current reasoning models, however, are constrained to reasoning within the boundaries of human language, processing discrete token embeddings that represent fixed point...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 22. In standard autoregressive generation, an LLM predicts the next-token distribution, samples a discrete token, and then discards the distribution, passing only the sampled token as new input. To preserve this distribution's rich information, we propose Mixture of Inputs (MoI), a training-free method ...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 23. Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers a potential source of structural data, c...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 24. Diffusion models have emerged as powerful generative tools across various domains, yet tailoring pre-trained models to exhibit specific desirable properties remains challenging. While reinforcement learning (RL) offers a promising solution,current methods struggle to simultaneously achieve stable, e...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 25. Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifier...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 26. Large multimodal models excel in multimodal tasks but face significant computational challenges due to excessive computation on visual tokens. Unlike token reduction methods that focus on token-level redundancy, we identify and study the computation-level redundancy on vision tokens to ensure no inf...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 27. Bias in Large Language Models (LLMs) significantly undermines their reliability and fairness. We focus on a common form of bias: when two reference concepts in the model's concept space, such as sentiment polarities (e.g., "positive" and "negative"), are asymmetrically correlated with a third, targe...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 28. Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failur...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 29. The rise of Large Audio Language Models (LAMs) brings both potential and risks, as their audio outputs may contain harmful or unethical content. However, current research lacks a systematic, quantitative evaluation of LAM safety especially against jailbreak attacks, which are challenging due to the ...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 30. Robustly evaluating the long-form storytelling capabilities of Large Language Models (LLMs) remains a significant challenge, as existing benchmarks often lack the necessary scale, diversity, or objective measures. To address this, we introduce WebNovelBench, a novel benchmark specifically designed f...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 31. Llama-SMoP, an efficient multimodal LLM incorporating Sparse Mixture of Projectors, enhances AVSR performance without increasing inference costs through modality-specific routers and experts.  					AI-generated summary 				 Audio-Visual Speech Recognition (AVSR) enhances robustness in noisy environm...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 32. This paper investigates prior prompt engineering (pPE) in the context of reinforcement fine-tuning (RFT), where language models (LMs) are incentivized to exhibit behaviors that maximize performance through reward signals. While existing RFT research has primarily focused on algorithms, reward shapin...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 33. Code-switching is a common phenomenon of alternating between different languages in the same utterance, thought, or conversation. We posit that humans code-switch because they feel more comfortable talking about certain topics and domains in one language than another. With the rise of knowledge-inte...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 34. A multilingual, multihop benchmark using knowledge graphs for evaluating and mitigating hallucinations in large language models.  					AI-generated summary 				 Large Language Models (LLMs) have inherent limitations of faithfulness and factuality, commonly referred to as hallucinations. Several benc...
[22.05.2025 15:12] ********************************************************************************
[22.05.2025 15:12] Abstract 35. HumaniBench evaluates state-of-the-art LMMs on seven human-centered AI principles using 32K real-world image-question pairs to ensure fairness, ethics, empathy, and inclusivity.  					AI-generated summary 				 Large multimodal models (LMMs) now excel on many vision language benchmarks, however, they...
[22.05.2025 15:12] Read previous papers.
[22.05.2025 15:12] Generating reviews via LLM API.
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#survey", "#benchmark", "#rl", "#dataset"], "emoji": "🧭", "ru": {"title": "Web-Shepherd: эффективная модель вознаграждения для автоматизации веб-навигации", "desc": "Статья представляет Web-Shepherd - первую модель вознаграждения процесса (PRM) для в
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#training", "#optimization", "#inference"], "emoji": "🔬", "ru": {"title": "Масштабирование квантизации в больших языковых моделях: новые горизонты эффективности", "desc": "Статья исследует масштабируемость квантизации с учетом обучения (QAT) для больших языковых моделей (LLM). Автор
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#training", "#multimodal", "#open_source", "#architecture", "#reasoning", "#diffusion", "#rl"], "emoji": "🧠", "ru": {"title": "MMaDA: Унифицированная мультимодальная диффузионная модель для рассуждений и генерации", "desc": "MMaDA - это новый класс мультимодальных диффузионных фунда
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#training", "#multimodal", "#reasoning", "#rl", "#dataset"], "emoji": "🧠", "ru": {"title": "Улучшение визуальной привязки через обучение с подкреплением и рассуждения", "desc": "Статья представляет UniVG-R1 - мультимодальную большую языковую модель для универсальной визуальной привя
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#diffusion", "#reasoning", "#benchmark", "#training", "#long_context", "#architecture", "#dataset"], "emoji": "🧠", "ru": {"title": "Диффузионные модели: новый подход к текстовым эмбеддингам", "desc": "В этой статье представлено исследование применения диффузионных языковых моделей д
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#synthetic", "#benchmark", "#transfer_learning", "#training", "#dataset", "#agents"], "emoji": "🖥️", "ru": {"title": "Эффективное обучение компьютерных агентов на малых данных", "desc": "Статья представляет PC Agent-E - эффективную систему обучения агентов для использования компьюте
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#training", "#optimization"], "emoji": "💡", "ru": {"title": "Эффективное рассуждение: оптимизация цепочек мыслей в крупных языковых моделях", "desc": "Статья представляет новый метод LASER для повышения эффективности рассуждений в крупных моделях машинного обуче
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training", "#reasoning", "#benchmark"], "emoji": "🧠", "ru": {"title": "Эффективное рассуждение: меньше думай, больше делай", "desc": "Эта статья представляет новый подход к оптимизации работы больших моделей рассуждений (LRM). Авторы предлагают мет
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#architecture", "#games", "#robotics", "#diffusion", "#transfer_learning", "#rl", "#agents", "#video"], "emoji": "🎥", "ru": {"title": "Превращение моделей диффузии видео в интерактивные модели мира", "desc": "В статье представлен метод Vid2World, позволяющий использовать предобученн
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#small_models", "#synthetic", "#architecture"], "emoji": "📈", "ru": {"title": "Toto: революция в прогнозировании временных рядов", "desc": "Представлена модель Toto - фундаментальная модель прогнозирования временных рядов с 151 миллионом пар
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#rag", "#alignment", "#dataset", "#multimodal", "#diffusion"], "emoji": "🖼️", "ru": {"title": "Интернет-augmented T2I: преодоление неопределенности в генерации изображений", "desc": "Статья представляет новый подход к генерации изображений по текстовому описанию (T2I) с использовани
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rag", "#benchmark", "#hallucinations"], "emoji": "🧠", "ru": {"title": "Повышение надежности языковых моделей через осмысление априорных знаний", "desc": "Статья представляет новый метод под названием 'Deliberation over Priors' (DP) для улучшения работ
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#games", "#agents", "#transfer_learning"], "emoji": "🎮", "ru": {"title": "Видеоигры как полигон для оценки и обучения языковых моделей", "desc": "Исследователи изучают возможности использования видеоигр для оценки современных больших языковых моделей (LLM). Они 
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#synthetic", "#3d"], "emoji": "🏙️", "ru": {"title": "Реалистичные 3D-города из одного изображения без обучения", "desc": "3DTown - это новый подход к генерации реалистичных трехмерных сцен на основе единственного вида сверху, не требующий дополнительного обучения. Метод основан на г
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#architecture", "#inference", "#optimization", "#diffusion", "#benchmark"], "emoji": "🚀", "ru": {"title": "Ускорение диффузионных языковых моделей с помощью умного кэширования", "desc": "Статья представляет новый механизм ускорения вывода для диффузионных языковых моделей (DLM) - от
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#data", "#math", "#reasoning", "#training", "#safety"], "emoji": "🛡️", "ru": {"title": "Повышение безопасности LRM: простота может быть ключом", "desc": "Эта статья исследует способы повышения безопасности Моделей Крупномасштабного Рассуждения (LRM) с помощью Контролируемой Тонкой Н
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#training", "#multimodal", "#benchmark", "#reasoning"], "emoji": "🧠", "ru": {"title": "Смешение модальностей для улучшения логических рассуждений ИИ", "desc": "Статья представляет новый подход к обучению языковых моделей - Mixture-of-Thought (MoT). MoT позволяет большим языковым мод
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#dataset", "#rag", "#rl", "#reasoning"], "emoji": "🔍", "ru": {"title": "Самообучающаяся система переформулировки запросов для диалогового поиска", "desc": "Статья представляет ConvSearch-R1 - первую самоуправляемую систему для переформулировки контекстн
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#data", "#security", "#open_source", "#training", "#leakage"], "emoji": "🕵️", "ru": {"title": "Скрытая угроза: как открытые языковые модели могут раскрыть ваши секретные данные", "desc": "Эта статья раскрывает новый риск безопасности при дообучении открытых языковых моделей (LLM) на
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#rlhf", "#training", "#multimodal", "#optimization", "#reasoning", "#games", "#rl", "#agents", "#video"], "emoji": "🌐", "ru": {"title": "RLVR-World: Революция в обучении мировых моделей", "desc": "RLVR-World - это новый подход к обучению мировых моделей, использующий обучение с подк
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#hallucinations", "#reasoning", "#training", "#math"], "emoji": "🧠", "ru": {"title": "Повышение надежности ИИ-рассуждений через осознание границ знаний", "desc": "Это исследование посвящено проблеме чрезмерной уверенности и неточности ответов больших моделей рассуждений (LRM) в мате
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#math", "#interpretability", "#reasoning", "#benchmark", "#training"], "emoji": "🧠", "ru": {"title": "Мягкое мышление: преодоление границ дискретного языкового рассуждения в ИИ", "desc": "Эта статья представляет новый метод машинного обучения под названием 'Soft Thinking', который и
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#math", "#training", "#reasoning", "#optimization"], "emoji": "🧠", "ru": {"title": "Смешивание входов для улучшения генерации языковых моделей", "desc": "Исследователи предложили новый метод автореградивной генерации текста под названием Mixture of Inputs (MoI). В отличие от стандар
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#data", "#multimodal", "#open_source", "#benchmark", "#dataset", "#agents", "#science"], "emoji": "🔬", "ru": {"title": "AutoMat: от микроскопических изображений к атомным структурам", "desc": "AutoMat - это новый конвейер для автоматического преобразования изображений сканирующей пр
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#diffusion", "#rl", "#training", "#optimization"], "emoji": "🚀", "ru": {"title": "VARD: Усиление диффузионных моделей с помощью обучения с подкреплением", "desc": "Статья представляет новый метод под названием VARD (Value-based Reinforced Diffusion) для улучшения диффузионных моделе
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#math", "#rlhf", "#reasoning", "#rl", "#training", "#optimization"], "emoji": "🕺", "ru": {"title": "Tango: Танец обучения с подкреплением для улучшения рассуждений LLM", "desc": "Статья представляет новый метод Tango для улучшения способностей больших языковых моделей (LLM) к рассуж
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#open_source", "#architecture", "#inference"], "emoji": "🔍", "ru": {"title": "ProxyV: Оптимизация вычислений для визуальных токенов в мультимодальных моделях", "desc": "Статья представляет новый подход ProxyV для повышения эффективности мультимодальны
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#ethics", "#multimodal", "#benchmark", "#interpretability", "#data"], "emoji": "🔍", "ru": {"title": "BiasLens: Новый взгляд на предвзятость в языковых моделях", "desc": "Статья представляет BiasLens - новый метод анализа предвзятости в больших языковых моделях (LLM) без использовани
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#multimodal", "#open_source", "#rl", "#agents", "#science"], "emoji": "🧪", "ru": {"title": "PiFlow: Революция в автоматизированном научном открытии", "desc": "PiFlow - это информационно-теоретическая система для автоматизированного научного открытия на основе многоагентных систем с 
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#ethics", "#dataset", "#benchmark", "#security", "#audio"], "emoji": "🎙️", "ru": {"title": "AJailBench: Новый рубеж в оценке безопасности аудио-ИИ", "desc": "Статья представляет AJailBench - первый бенчмарк для оценки уязвимостей к атакам джейлбрейка в больших аудио-языковых моделях
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#story_generation", "#long_context", "#dataset", "#benchmark"], "emoji": "📚", "ru": {"title": "WebNovelBench: новый стандарт оценки генерации длинных текстов языковыми моделями", "desc": "WebNovelBench - это новый бенчмарк для оценки способностей больших языковых моделей (LLM) генер
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#audio", "#multimodal", "#inference", "#architecture", "#low_resource"], "emoji": "🗣️", "ru": {"title": "Эффективное мультимодальное распознавание речи с помощью разреженных экспертов", "desc": "Llama-SMoP - это эффективная мультимодальная языковая модель, использую
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#training", "#optimization", "#reasoning", "#rl", "#benchmark"], "emoji": "🧠", "ru": {"title": "Предварительная инженерия промптов: новый рубеж в обучении языковых моделей с подкреплением", "desc": "Это исследование рассматривает влияние предварительной инженерии промптов (pPE) на о
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#alignment", "#benchmark", "#open_source", "#inference", "#low_resource", "#multilingual"], "emoji": "🌐", "ru": {"title": "Раскрытие потенциала многоязычности в искусственном интеллекте", "desc": "Исследователи изучают феномен языково-специфичных знаний (LS
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#hallucinations", "#benchmark", "#dataset", "#graphs", "#multilingual", "#data", "#rag"], "emoji": "🧠", "ru": {"title": "Графы знаний против галлюцинаций ИИ", "desc": "Статья представляет новый многоязычный бенчмарк MultiHal для оценки и снижения галлюцинаций в больших языковых моде
[22.05.2025 15:12] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#multimodal", "#dataset", "#benchmark"], "emoji": "🧠", "ru": {"title": "Оценка ИИ по человеческим меркам", "desc": "HumaniBench - это новый комплексный бенчмарк для оценки больших мультимодальных моделей (LMM) по семи принципам человекоцентричного ИИ. Он вкл
[22.05.2025 15:12] Loading Chinese text from previous data.
[22.05.2025 15:12] Renaming data file.
[22.05.2025 15:12] Renaming previous data. hf_papers.json to ./d/2025-05-22.json
[22.05.2025 15:12] Saving new data file.
[22.05.2025 15:12] Generating page.
[22.05.2025 15:12] Renaming previous page.
[22.05.2025 15:12] Renaming previous data. index.html to ./d/2025-05-22.html
[22.05.2025 15:12] [Experimental] Generating Chinese page for reading.
[22.05.2025 15:12] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '网页导航', 'pinyin': 'wǎng yè dǎo háng', 'trans': 'web navigation'}, {'word': '自动化', 'pinyin': 'zì dòng huà', 'trans': 'automation'}, {'word': '任务', 'pinyin': 'rèn wu', 'trans': 'task'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '奖励模型', 'pinyin': 'jiǎng lì mó xíng', 'trans': 'reward model'}, {'word': '限制', 'pinyin': 'xiàn zhì', 'trans': 'limit'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '过程奖励模型', 'pinyin': 'guò chéng jiǎng lì mó xíng', 'trans': 'process reward model'}, {'word': '逐步', 'pinyin': 'zhuó bù', 'trans': 'step-by-step'}, {'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluate'}, {'word': '路径', 'pinyin': 'lù jìng', 'trans': 'path'}, {'word': '创建', 'pinyin': 'chuàng jiàn', 'trans': 'create'}, {'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'}, {'word': '评估基准', 'pinyin': 'píng gū jī zhǔn', 'trans': 'evaluation benchmark'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '证明', 'pinyin': 'zhèng míng', 'trans': 'prove'}, {'word': '有效性', 'pinyin': 'yǒu xiào xìng', 'trans': 'effectiveness'}, {'word': '成本效益', 'pinyin': 'chéng běn xiào yì', 'trans': 'cost-effectiveness'}, {'word': '公开可用', 'pinyin': 'gōng kāi kě yòng', 'trans': 'publicly available'}]
[22.05.2025 15:12] Renaming previous Chinese page.
[22.05.2025 15:12] Renaming previous data. zh.html to ./d/2025-05-21_zh_reading_task.html
[22.05.2025 15:12] Writing Chinese reading task.
[22.05.2025 15:12] Writing result.
[22.05.2025 15:12] Renaming log file.
[22.05.2025 15:12] Renaming previous data. log.txt to ./logs/2025-05-22_last_log.txt
