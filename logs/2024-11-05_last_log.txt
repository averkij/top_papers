[04.11.2024 22:11] [Experimental] Generating an image for paper OS-ATLAS: A Foundation Action Model for Generalist GUI Agents.
[04.11.2024 22:11] [Experimental] Image for paper OS-ATLAS: A Foundation Action Model for Generalist GUI Agents already exists.
[04.11.2024 22:11] [Experimental] Generating an image for paper Constant Acceleration Flow.
[04.11.2024 22:11] [Experimental] Image for paper Constant Acceleration Flow already exists.
[04.11.2024 22:11] [Experimental] Generating an image for paper Personalization of Large Language Models: A Survey.
[04.11.2024 22:11] [Experimental] Image for paper Personalization of Large Language Models: A Survey already exists.
[04.11.2024 22:11] [Experimental] Generating an image for paper TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models.
[04.11.2024 22:11] [Experimental] Image for paper TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models already exists.
[04.11.2024 22:11] [Experimental] Generating an image for paper Randomized Autoregressive Visual Generation.
[04.11.2024 22:11] [Experimental] Image for paper Randomized Autoregressive Visual Generation already exists.
[05.11.2024 00:57] Read previous papers.
[05.11.2024 00:57] Get feed.
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.23218
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00322
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.23266
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00027
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00776
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00412
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.23775
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00771
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22370
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22901
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.24159
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00680
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00233
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00369
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21157
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00225
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00762
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00030
[05.11.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2411.00660
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 0. Existing efforts in building GUI agents heavily rely on the availability of robust commercial Vision-Language Models (VLMs) such as GPT-4o and GeminiProVision. Practitioners are often reluctant to use open-source VLMs due to their significant performance lag compared to their closed-source counterpa...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 1. Rectified flow and reflow procedures have significantly advanced fast generation by progressively straightening ordinary differential equation (ODE) flows. They operate under the assumption that image and noise pairs, known as couplings, can be approximated by straight trajectories with constant vel...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 2. Existing benchmarks often highlight the remarkable performance achieved by state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal context for video understanding. However, how well do the models truly perform visual temporal reasoning? Our study of existing benchmarks shows that...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 3. Personalization of Large Language Models (LLMs) has recently become increasingly important with a wide range of applications. Despite the importance and recent progress, most existing works on personalized LLMs have focused either entirely on (a) personalized text generation or (b) leveraging LLMs f...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 4. This paper presents Randomized AutoRegressive modeling (RAR) for visual generation, which sets a new state-of-the-art performance on the image generation task while maintaining full compatibility with language modeling frameworks. The proposed RAR is simple: during a standard autoregressive training...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 5. Large Language Models (LLMs) demonstrate promising capabilities in solving simple scientific problems but often produce hallucinations for complex ones. While integrating LLMs with tools can increase reliability, this approach typically results in over-reliance on tools, diminishing the model's abil...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 6. Recent research arXiv:2410.15027 has explored the use of diffusion transformers (DiTs) for task-agnostic image generation by simply concatenating attention tokens across images. However, despite substantial computational resources, the fidelity of the generated images remains suboptimal. In this stu...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 7. Recently, 3D Gaussian Splatting (3DGS) has revolutionized radiance field reconstruction, manifesting efficient and high-fidelity novel view synthesis. However, accurately representing surfaces, especially in large and complex scenarios, remains a significant challenge due to the unstructured nature ...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 8. The applications of generative AI have become extremely impressive, and the interplay between users and AI is even more so. Current human-AI interaction literature has taken a broad look at how humans interact with generative AI, but it lacks specificity regarding the user interface designs and patt...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 9. We propose an effective method for inserting adapters into text-to-image foundation models, which enables the execution of complex downstream tasks while preserving the generalization ability of the base model. The core idea of this method is to optimize the attention mechanism related to 2D feature...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 10. We present a simple way to merge masked language modeling with causal language modeling. This hybrid training objective results in a model that combines the strengths of both modeling paradigms within a single transformer stack: GPT-BERT can be transparently used like any standard causal or masked l...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 11. The word embedding space in neural models is skewed, and correcting this can improve task performance. We point out that most approaches for modeling, correcting, and measuring the symmetry of an embedding space implicitly assume that the word frequencies are uniform; in reality, word frequencies fo...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 12. The state of health (SOH) of a Li-ion battery is a critical parameter that determines the remaining capacity and the remaining lifetime of the battery. In this paper, we propose SambaMixer a novel structured state space model (SSM) for predicting the state of health of Li-ion batteries. The proposed...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 13. Large Language Models (LLMs) have excelled in multi-hop question-answering (M-QA) due to their advanced reasoning abilities. However, the impact of the inherent reasoning structures on LLM M-QA performance remains unclear, largely due to the absence of QA datasets that provide fine-grained reasoning...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 14. Repository-level code completion has drawn great attention in software engineering, and several benchmark datasets have been introduced. However, existing repository-level code completion benchmarks usually focus on a limited number of languages (<5), which cannot evaluate the general code intellige...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 15. We present Fashion-VDM, a video diffusion model (VDM) for generating virtual try-on videos. Given an input garment image and person video, our method aims to generate a high-quality try-on video of the person wearing the given garment, while preserving the person's identity and motion. Image-based v...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 16. Current face anonymization techniques often depend on identity loss calculated by face recognition models, which can be inaccurate and unreliable. Additionally, many methods require supplementary data such as facial landmarks and masks to guide the synthesis process. In contrast, our approach uses d...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 17. We address in this article the the quality of the WikiNER corpus, a multilingual Named Entity Recognition corpus, and provide a consolidated version of it. The annotation of WikiNER was produced in a semi-supervised manner i.e. no manual verification has been carried out a posteriori. Such corpus is...
[05.11.2024 00:57] ********************************************************************************
[05.11.2024 00:57] Abstract 18. We discovered the underlying physics in Next-token Prediction (NTP). We identified the law of information conservation within NTP and proposed the First Law of Information Capacity (IC-1), demonstrating that the essence of intelligence emergence in auto-regressive models is fundamentally a process o...
[05.11.2024 00:57] Read previous papers.
[05.11.2024 00:57] Generating reviews via LLM API.
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#dataset", "#data", "#agents", "#training", "#benchmark"], "emoji": "ðŸ–¥ï¸", "ru": {"title": "OS-Atlas: ÐžÑ‚ÐºÑ€Ñ‹Ñ‚Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ GUI", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð»Ð¸ OS-Atlas - Ð¾ÑÐ½Ð¾Ð²Ð¾Ð¿Ð¾Ð»Ð°Ð³Ð°ÑŽÑ‰ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ¾Ð¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#cv", "#training", "#optimization"], "emoji": "ðŸš€", "ru": {"title": "CAF: Ð£ÑÐºÐ¾Ñ€ÑÐµÐ¼ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾Ð³Ð¾ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸ÑŽ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸, Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Constant Acceleration Flow (CAF). Ð’ Ð¾
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#benchmark", "#video", "#multimodal"], "emoji": "ðŸ…", "ru": {"title": "TOMATO: ÐÐ¾Ð²Ñ‹Ð¹ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð²Ð¸Ð´ÐµÐ¾Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð»Ð¸ Ð½Ð¾Ð²Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº TOMATO Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (ÐœÐ¤Ðœ) Ðº Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¼Ñƒ
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#survey", "#multimodal", "#dataset"], "emoji": "ðŸŽ­", "ru": {"title": "ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÑ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ñ‹: ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð²Ð·Ð³Ð»ÑÐ´ Ð½Ð° Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ð¾ÑÐ²ÑÑ‰ÐµÐ½Ð° Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) Ð¸ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ð´Ð²Ð° Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð² ÑÑ‚Ð¾Ð¹ Ð¾
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#cv", "#architecture", "#benchmark"], "emoji": "ðŸŽ¨", "ru": {"title": "Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ð°Ñ Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¼ÐµÑ‚Ð¾Ð´ Randomized AutoRegressive modeling (RAR) Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹. RAR Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½ÑƒÑŽ Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ð½Ð¾Ð²ÐºÑƒ Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ð¿Ð¾ÑÐ»
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#rlhf", "#alignment", "#training", "#benchmark", "#math"], "emoji": "ðŸ§ ", "ru": {"title": "Ð£Ð¼Ð½Ð¾Ðµ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ: ÐºÐ°Ðº Ð½Ð°ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð˜Ð˜ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ Ñ€ÐµÑˆÐ°Ñ‚ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ñ€Ð°Ð·Ð½Ð¾Ð¹ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾ÑÐ²ÑÑ‰ÐµÐ½Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑŽ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) Ñ€ÐµÑˆÐ°Ñ‚ÑŒ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸. ÐÐ²Ñ‚Ð¾Ñ€Ñ‹
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#training"], "emoji": "ðŸ–¼ï¸", "ru": {"title": "Ð Ð°ÑÐºÑ€Ñ‹Ñ‚Ð¸Ðµ ÑÐºÑ€Ñ‹Ñ‚Ð¾Ð³Ð¾ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»Ð° DiT Ð´Ð»Ñ Ð¼Ð½Ð¾Ð³Ð¾Ð·Ð°Ð´Ð°Ñ‡Ð½Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ð¾Ð² (DiT) Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡Ð°Ñ….
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#3d", "#benchmark", "#training", "#optimization"], "emoji": "ðŸ™ï¸", "ru": {"title": "CityGaussianV2: Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ñ€ÐµÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ ÐºÑ€ÑƒÐ¿Ð½Ð¾Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ñ‹Ñ… ÑÑ†ÐµÐ½ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð³Ð¾ Gaussian Splatting", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ CityGaussianV2 - Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ñ€ÐµÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ ÐºÑ€ÑƒÐ¿Ð½Ð¾Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ñ‹Ñ… Ñ
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#survey", "#multimodal"], "emoji": "ðŸ¤–", "ru": {"title": "ÐŸÑƒÑ‚ÐµÐ²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ Ð¿Ð¾ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸ÑŽ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ð¸ Ð˜Ð˜", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¾Ð±Ð·Ð¾Ñ€ Ñ‚Ð°ÐºÑÐ¾Ð½Ð¾Ð¼Ð¸Ð¹ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¼ Ð˜Ð˜ Ð¸ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ° Ð´Ð»Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ð¸ÐµÐ² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ. ÐÐ²Ñ‚Ð¾Ñ€Ñ‹ Ñ„Ð¾ÐºÑƒ
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#cv", "#video", "#training", "#architecture"], "emoji": "ðŸŽ¨", "ru": {"title": "ÐÐ´Ð°Ð¿Ñ‚ÐµÑ€Ñ‹ Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚-Ð²-Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼ÐµÐ¼Ð¾Ð²", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð²Ð½ÐµÐ´Ñ€ÐµÐ½Ð¸Ñ Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€Ð¾Ð² Ð² Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ. Ð­Ñ‚Ð¾Ñ‚ Ð¿Ð¾Ð´Ñ…
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#architecture", "#training"], "emoji": "ðŸ¤–", "ru": {"title": "Ð“Ð¸Ð±Ñ€Ð¸Ð´Ð½Ð¾Ðµ ÑÐ·Ñ‹ÐºÐ¾Ð²Ð¾Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ: Ð»ÑƒÑ‡ÑˆÐµÐµ Ð¸Ð· Ð´Ð²ÑƒÑ… Ð¼Ð¸Ñ€Ð¾Ð²", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¸ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð½Ð¾-ÑÐ»ÐµÐ´ÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ¾Ð²Ð¾Ð³Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð¼ ÑÑ‚Ð°Ð»Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ GPT-BERT, ÑÐ¾Ñ‡ÐµÑ‚Ð°
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#data", "#math", "#interpretability", "#transfer_learning"], "emoji": "ðŸ“Š", "ru": {"title": "Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹ ÑÐ»Ð¾Ð² Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð·Ð°ÐºÐ¾Ð½Ð° Ð¦Ð¸Ð¿Ñ„Ð°", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ð¾ÑÐ²ÑÑ‰ÐµÐ½Ð° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ðµ Ð°ÑÐ¸Ð¼Ð¼ÐµÑ‚Ñ€Ð¸Ð¸ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð° Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹ ÑÐ»Ð¾Ð² Ð² Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÑÑ…. ÐÐ²Ñ‚Ð¾Ñ€Ñ‹ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÑŽÑ‚ Ð¼
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#dataset", "#data", "#benchmark", "#architecture", "#training", "#medicine"], "emoji": "ðŸ”‹", "ru": {"title": "Ð¢Ð¾Ñ‡Ð½Ð¾Ðµ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ€Ð¾ÐºÐ° ÑÐ»ÑƒÐ¶Ð±Ñ‹ Ð°ÐºÐºÑƒÐ¼ÑƒÐ»ÑÑ‚Ð¾Ñ€Ð¾Ð² Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ SambaMixer - Ð½Ð¾Ð²ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð° ÑÐ¾ÑÑ‚Ð¾Ñ
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#benchmark"], "emoji": "ðŸ§ ", "ru": {"title": "Ð“Ñ€Ð°Ñ„Ñ‹ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°ÑŽÑ‚ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… GRS-QA Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) Ð² Ð¼Ð½Ð¾Ð³Ð¾Ñ…Ð¾Ð´Ð¾Ð²Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ½Ð¾-Ð¾Ñ‚Ð²ÐµÑ‚Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡Ð°Ñ…. 
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#plp", "#multilingual"], "emoji": "ðŸ–¥ï¸", "ru": {"title": "ÐœÐ½Ð¾Ð³Ð¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ LLM Ð² Ð°Ð²Ñ‚Ð¾Ð´Ð¾Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ ÐºÐ¾Ð´Ð°", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº M2RC-EVAL Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) Ð² Ð·Ð°Ð´Ð°Ñ‡Ðµ Ð°Ð²Ñ‚Ð¾Ð´Ð¾Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð´Ð° Ð½
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#video", "#diffusion", "#cv"], "emoji": "ðŸ‘š", "ru": {"title": "Ð’Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ÐºÐ° Ð¾Ð´ÐµÐ¶Ð´Ñ‹ Ð½Ð° Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Fashion-VDM - ÑÑ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ðº Ð¾Ð´ÐµÐ¶Ð´Ñ‹. ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ð² Ð·Ð°Ð´Ð°Ð½Ð½
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#diffusion"], "emoji": "ðŸŽ­", "ru": {"title": "ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¸ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð°Ð½Ð¾Ð½Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð»Ð¸Ñ† Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð­Ñ‚Ð° ÑÑ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð°Ð½Ð¾Ð½Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð»Ð¸Ñ† Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹. Ð’ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾Ñ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¾Ð², Ð¼ÐµÑ‚Ð¾Ð´ Ð½Ðµ
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#dataset", "#data", "#multilingual"], "emoji": "ðŸ·ï¸", "ru": {"title": "Ð—Ð¾Ð»Ð¾Ñ‚Ð¾Ð¹ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚ Ð´Ð»Ñ Ñ„Ñ€Ð°Ð½Ñ†ÑƒÐ·ÑÐºÐ¾Ð³Ð¾ NER: ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ WikiNER", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ð¾ÑÐ²ÑÑ‰ÐµÐ½Ð° ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑŽ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° ÐºÐ¾Ñ€Ð¿ÑƒÑÐ° WikiNER Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ð¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð½Ð° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ°Ñ…. ÐÐ²Ñ‚Ð¾Ñ€Ñ‹ ÑÐ¾Ð·Ð´Ð°Ð»Ð¸ WikiNER-fr-gold 
[05.11.2024 00:57] Using data from previous issue: {"categories": ["#math", "#training", "#optimization"], "emoji": "ðŸ§ ", "ru": {"title": "Ð¤Ð¸Ð·Ð¸ÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ Ñ‚Ð°Ð¹Ð½Ñ‹ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚Ð°", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶Ð¸Ð»Ð¸ Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ Ð² Ð·Ð°Ð´Ð°Ñ‡Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð° (NTP). ÐžÐ½Ð¸ ÑÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð»Ð¸ ÐŸÐµÑ€Ð²Ñ‹Ð¹ Ð·Ð°ÐºÐ¾Ð½ Ð¸
[05.11.2024 00:57] Loading Chinese text from previous data.
[05.11.2024 00:57] Renaming data file.
[05.11.2024 00:57] Renaming previous data. hf_papers.json to ./d/2024-11-05.json
[05.11.2024 00:57] Saving new data file.
[05.11.2024 00:57] Generating page.
[05.11.2024 00:57] Renaming previous page.
[05.11.2024 00:57] Renaming previous data. index.html to ./d/2024-11-05.html
[05.11.2024 00:57] [Experimental] Generating Chinese page for reading.
[05.11.2024 00:57] Chinese vocab [{'word': 'æž„å»º', 'pinyin': 'gÃ²u jiÃ n', 'trans': 'construct'}, {'word': 'å›¾å½¢ç”¨æˆ·ç•Œé¢', 'pinyin': 'tÃº xÃ­ng yÃ²ng hÃ¹ jiÃ¨ miÃ n', 'trans': 'graphical user interface'}, {'word': 'ä»£ç†', 'pinyin': 'dÃ i lÇ', 'trans': 'agent'}, {'word': 'çŽ°æœ‰', 'pinyin': 'xiÃ n yÇ’u', 'trans': 'existing'}, {'word': 'åŠªåŠ›', 'pinyin': 'nÇ” lÃ¬', 'trans': 'efforts'}, {'word': 'ä¾èµ–', 'pinyin': 'yÄ« lÃ i', 'trans': 'rely on'}, {'word': 'å¼ºå¤§', 'pinyin': 'qiÃ¡ng dÃ ', 'trans': 'powerful'}, {'word': 'å•†ä¸š', 'pinyin': 'shÄng yÃ¨', 'trans': 'commercial'}, {'word': 'è§†è§‰è¯­è¨€æ¨¡åž‹', 'pinyin': 'shÃ¬ juÃ© yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'visual language model'}, {'word': 'å¼€æº', 'pinyin': 'kÄi yuÃ¡n', 'trans': 'open-source'}, {'word': 'ç†è§£', 'pinyin': 'lÇ jiÄ›', 'trans': 'understanding'}, {'word': 'æœªè§åˆ†å¸ƒ', 'pinyin': 'wÃ¨i jiÃ n fÄ“n bÃ¹', 'trans': 'out-of-distribution'}, {'word': 'åœºæ™¯', 'pinyin': 'chÇŽng jÇng', 'trans': 'scenario'}, {'word': 'è¡¨çŽ°', 'pinyin': 'biÇŽo xiÃ n', 'trans': 'performance'}, {'word': 'è¾ƒå·®', 'pinyin': 'jiÃ o chÃ ', 'trans': 'poor'}, {'word': 'å®žè·µè€…', 'pinyin': 'shÃ­ jiÃ n zhÄ›', 'trans': 'practitioner'}, {'word': 'ä¸å¤ªæ„¿æ„', 'pinyin': 'bÃ¹ tÃ i yuÃ n yÃ¬', 'trans': 'not very willing'}, {'word': 'æŽ¨åŠ¨', 'pinyin': 'tuÄ« dÃ²ng', 'trans': 'promote'}, {'word': 'é¢†åŸŸ', 'pinyin': 'lÇng yÃ¹', 'trans': 'field'}, {'word': 'ç ”ç©¶', 'pinyin': 'yÃ¡n jiÅ«', 'trans': 'research'}, {'word': 'å¼€å‘', 'pinyin': 'kÄi fÄ', 'trans': 'develop'}, {'word': 'åŸºç¡€æ¨¡åž‹', 'pinyin': 'jÄ« chÇ” mÃ³ xÃ­ng', 'trans': 'foundation model'}, {'word': 'æ“…é•¿', 'pinyin': 'shÃ n chÃ¡ng', 'trans': 'proficient'}, {'word': 'ä»»åŠ¡', 'pinyin': 'rÃ¨n wÃ¹', 'trans': 'task'}, {'word': 'å‘å¸ƒ', 'pinyin': 'fÄ bÃ¹', 'trans': 'release'}, {'word': 'æ•°æ®é›†', 'pinyin': 'shÃ¹ jÃ¹ jÃ­', 'trans': 'dataset'}, {'word': 'è·¨å¹³å°', 'pinyin': 'kuÃ  pÃ­ng tÃ¡i', 'trans': 'cross-platform'}, {'word': 'å…ƒç´ ', 'pinyin': 'yuÃ¡n sÃ¹', 'trans': 'element'}, {'word': 'è¯æ˜Ž', 'pinyin': 'zhÃ¨ng mÃ­ng', 'trans': 'demonstrate'}, {'word': 'åŸºå‡†æµ‹è¯•', 'pinyin': 'jÄ« zhÇ”n cÃ¨ shÃ¬', 'trans': 'benchmark test'}, {'word': 'æ˜¾è‘—', 'pinyin': 'xiÇŽn zhÃ¹', 'trans': 'significant'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'}, {'word': 'æå‡', 'pinyin': 'tÃ­ shÄ“ng', 'trans': 'improvement'}]
[05.11.2024 00:57] Renaming previous Chinese page.
[05.11.2024 00:57] Renaming previous data. zh.html to ./d/2024-11-04_zh_reading_task.html
[05.11.2024 00:57] Writing result.
[05.11.2024 00:57] Writing Chinese reading task.
[05.11.2024 00:57] Renaming log file.
[05.11.2024 00:57] Renaming previous data. log.txt to ./logs/2024-11-05_last_log.txt
