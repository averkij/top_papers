[20.06.2025 09:13] Read previous papers.
[20.06.2025 09:13] Generating top page (month).
[20.06.2025 09:13] Writing top page (month).
[20.06.2025 10:12] Read previous papers.
[20.06.2025 10:12] Get feed.
[20.06.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14965
[20.06.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15154
[20.06.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09827
[20.06.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2506.14837
[20.06.2025 10:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.06.2025 10:12] No deleted papers detected.
[20.06.2025 10:12] Downloading and parsing papers (pdf, html). Total: 4.
[20.06.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2506.14965.
[20.06.2025 10:12] Extra JSON file exists (./assets/json/2506.14965.json), skip PDF parsing.
[20.06.2025 10:12] Paper image links file exists (./assets/img_data/2506.14965.json), skip HTML parsing.
[20.06.2025 10:12] Success.
[20.06.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2506.15154.
[20.06.2025 10:12] Extra JSON file exists (./assets/json/2506.15154.json), skip PDF parsing.
[20.06.2025 10:12] Paper image links file exists (./assets/img_data/2506.15154.json), skip HTML parsing.
[20.06.2025 10:12] Success.
[20.06.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2506.09827.
[20.06.2025 10:13] Downloading paper 2506.09827 from http://arxiv.org/pdf/2506.09827v2...
[20.06.2025 10:13] Extracting affiliations from text.
[20.06.2025 10:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 1 ] . [ 2 7 2 8 9 0 . 6 0 5 2 : r EMONET-VOICE: Fine-Grained, Expert-Verified Benchmark for Speech Emotion Detection Christoph Schuhmann LAION e.V. christoph.schuhmann@laion.ai Robert Kaczmarczyk LAION e.V. Technical University of Munich Gollam Rabby L3S Research Center Leibniz University of Hannover Felix Friedrich TU Darmstadt Hessian.AI Maurice Kraus TU Darmstadt Kourosh Nadi LAION e.V. Huu Nguyen Ontocord LAION e.V. Kristian Kersting TU Darmstadt Centre for Cognitive Science Hessian.AI DFKI S√∂ren Auer TIBLeibniz Information Centre for Science and Technology L3S Research Center Leibniz University of Hannover "
[20.06.2025 10:13] Response: ```python
[
    "LAION e.V.",
    "Technical University of Munich",
    "L3S Research Center Leibniz University of Hannover",
    "TU Darmstadt",
    "Hessian.AI",
    "Ontocord",
    "Centre for Cognitive Science",
    "DFKI",
    "TIBLeibniz Information Centre for Science and Technology"
]
```
[20.06.2025 10:13] Deleting PDF ./assets/pdf/2506.09827.pdf.
[20.06.2025 10:13] Success.
[20.06.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2506.14837.
[20.06.2025 10:13] Extra JSON file exists (./assets/json/2506.14837.json), skip PDF parsing.
[20.06.2025 10:13] Paper image links file exists (./assets/img_data/2506.14837.json), skip HTML parsing.
[20.06.2025 10:13] Success.
[20.06.2025 10:13] Enriching papers with extra data.
[20.06.2025 10:13] ********************************************************************************
[20.06.2025 10:13] Abstract 0. Guru, a diverse RL reasoning corpus, highlights domain-specific training needs and demonstrates improved performance in complex tasks for RL-enhanced LLMs.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as a promising approach to improve large language model (LLM) reasoning,...
[20.06.2025 10:13] ********************************************************************************
[20.06.2025 10:13] Abstract 1. SonicVerse, a multi-task music captioning model, integrates audio feature detection to enhance caption quality and enable detailed descriptions of music pieces.  					AI-generated summary 				 Detailed captions that accurately reflect the characteristics of a music piece can enrich music databases a...
[20.06.2025 10:13] ********************************************************************************
[20.06.2025 10:13] Abstract 2. EmoNet-Voice, a new resource with large pre-training and benchmark datasets, advances speech emotion recognition by offering fine-grained emotion evaluation with synthetic, privacy-preserving audio.  					AI-generated summary 				 The advancement of text-to-speech and audio generation models necessi...
[20.06.2025 10:13] ********************************************************************************
[20.06.2025 10:13] Abstract 3. ChartIR uses structured instruction and iterative refinement to improve MLLM performance in chart-to-code generation by separating visual understanding and code translation tasks.  					AI-generated summary 				 Recently, multimodal large language models (MLLMs) have attracted increasing research at...
[20.06.2025 10:13] Read previous papers.
[20.06.2025 10:13] Generating reviews via LLM API.
[20.06.2025 10:13] Using data from previous issue: {"categories": ["#training", "#rl", "#open_source", "#reasoning", "#dataset"], "emoji": "üß†", "ru": {"title": "Guru: –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π LLM —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫–æ—Ä–ø—É—Å Guru –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –±–æ–ª—å—à
[20.06.2025 10:13] Using data from previous issue: {"categories": ["#audio", "#games", "#multimodal", "#architecture", "#science", "#dataset", "#training"], "emoji": "üéµ", "ru": {"title": "SonicVerse: –ü–æ–Ω–∏–º–∞–Ω–∏–µ –º—É–∑—ã–∫–∏ —á–µ—Ä–µ–∑ –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "desc": "SonicVerse - —ç—Ç–æ –º—É–ª—å—Ç–∏–∑–∞–¥–∞—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏–π –º—É–∑—ã–∫–∏, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≥–µ–Ω–µ—Ä–∞
[20.06.2025 10:13] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#science", "#synthetic", "#data", "#audio"], "emoji": "üé≠", "ru": {"title": "–¢–æ—á–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —ç–º–æ—Ü–∏–π –≤ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "EmoNet-Voice - —ç—Ç–æ –Ω–æ–≤—ã–π —Ä–µ—Å—É—Ä—Å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —ç–º–æ—Ü–∏–π –≤ —Ä–µ—á–∏, –≤–∫–ª—é—á–∞—é—â–∏–π –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è
[20.06.2025 10:13] Using data from previous issue: {"categories": ["#cv", "#interpretability", "#optimization", "#training", "#multimodal"], "emoji": "üìä", "ru": {"title": "–¢–æ—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ç–æ—á–Ω–µ–Ω–∏—è", "desc": "ChartIR - —ç—Ç–æ –º–µ—Ç–æ–¥ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ç–æ—á–Ω–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å
[20.06.2025 10:13] Renaming data file.
[20.06.2025 10:13] Renaming previous data. hf_papers.json to ./d/2025-06-20.json
[20.06.2025 10:13] Saving new data file.
[20.06.2025 10:13] Generating page.
[20.06.2025 10:13] Renaming previous page.
[20.06.2025 10:13] Renaming previous data. index.html to ./d/2025-06-20.html
[20.06.2025 10:13] Writing result.
[20.06.2025 10:13] Renaming log file.
[20.06.2025 10:13] Renaming previous data. log.txt to ./logs/2025-06-20_last_log.txt
