[15.09.2025 16:14] Read previous papers.
[15.09.2025 16:14] Generating top page (month).
[15.09.2025 16:14] Writing top page (month).
[15.09.2025 17:10] Read previous papers.
[15.09.2025 17:10] Get feed.
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06652
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09677
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10441
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08643
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09713
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09716
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04996
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10147
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10396
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09995
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09926
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10058
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09734
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01535
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09990
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09524
[15.09.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08825
[15.09.2025 17:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.09.2025 17:10] No deleted papers detected.
[15.09.2025 17:10] Downloading and parsing papers (pdf, html). Total: 17.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.06652.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.06652.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.06652.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09677.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09677.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09677.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.10441.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.10441.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.10441.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.08643.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.08643.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.08643.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09713.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09713.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09713.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09716.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09716.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09716.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.04996.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.04996.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.04996.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.10147.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.10147.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.10147.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.10396.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.10396.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.10396.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09995.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09995.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09995.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09926.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09926.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09926.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.10058.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.10058.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.10058.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09734.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09734.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09734.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.01535.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.01535.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.01535.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09990.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09990.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09990.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.09524.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.09524.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.09524.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.08825.
[15.09.2025 17:10] Extra JSON file exists (./assets/json/2509.08825.json), skip PDF parsing.
[15.09.2025 17:10] Paper image links file exists (./assets/img_data/2509.08825.json), skip HTML parsing.
[15.09.2025 17:10] Success.
[15.09.2025 17:10] Enriching papers with extra data.
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 0. IntrEx, a large dataset annotated for interestingness in educational conversations, shows that fine-tuned LLMs can predict human judgments of interestingness better than larger proprietary models, highlighting the role of linguistic and cognitive factors in engagement.  					AI-generated summary 			...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 1. Scaling large language models improves their ability to execute longer tasks by isolating execution capability and mitigating self-conditioning effects, despite diminishing single-step accuracy.  					AI-generated summary 				 Does continued scaling of large language models (LLMs) yield diminishing ...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 2. InfGen, a one-step generator replacing the VAE decoder, enables arbitrary high-resolution image generation from a fixed-size latent, significantly reducing computational complexity and generation time.  					AI-generated summary 				 Arbitrary resolution image generation provides a consistent visual...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 3. X-Part is a generative model that decomposes 3D objects into semantically meaningful parts with high fidelity, using bounding boxes and point-wise semantic features, and supports interactive editing.  					AI-generated summary 				 Generating 3D shapes at part level is pivotal for downstream applica...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 4. HANRAG, a heuristic-based framework, improves question-answering systems by efficiently handling multi-hop queries and reducing noise through query decomposition and filtering.  					AI-generated summary 				 The Retrieval-Augmented Generation (RAG) approach enhances question-answering systems and d...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 5. Voice Style Adaptation (VSA) evaluates the ability of spoken language models to modify their speaking style based on spoken instructions, using a bilingual benchmark and a Large Audio Language Model as a Judge framework.  					AI-generated summary 				 Spoken language models (SLMs) have emerged as a...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 6. FLOWER, a 950 M-parameter VLA policy, achieves competitive performance with reduced computational costs through intermediate-modality fusion and action-specific Global-AdaLN conditioning.  					AI-generated summary 				 Developing efficient Vision-Language-Action (VLA) policies is crucial for practi...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 7. The sandbox economy framework analyzes the emerging AI agent economy, focusing on its origins and permeability, and discusses design choices for safe and steerable AI markets.  					AI-generated summary 				 The rapid adoption of autonomous AI agents is giving rise to a new economic layer where agen...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 8. IGPO, an RL framework utilizing inpainting in masked diffusion large language models, enhances sample efficiency and achieves state-of-the-art results in mathematical benchmarks.  					AI-generated summary 				 Masked diffusion large language models (dLLMs) are emerging as promising alternatives to ...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 9. QuantAgent, a multi-agent LLM framework, excels in high-frequency trading by leveraging specialized agents for technical indicators, chart patterns, trends, and risk, outperforming existing neural and rule-based systems.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs)...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 10. LoFT, a parameter-efficient fine-tuning framework for long-tailed semi-supervised learning, improves reliability of pseudolabels and discriminative ability in open-world scenarios, outperforming previous methods.  					AI-generated summary 				 Long-tailed learning has garnered increasing attention ...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 11. A training-free framework uses a large language model to disambiguate color terms and refine text embeddings for improved color accuracy in text-to-image generation.  					AI-generated summary 				 Accurate color alignment in text-to-image (T2I) generation is critical for applications such as fashio...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 12. MCP-AgentBench is a benchmark designed to evaluate language agents in MCP-mediated tool interactions, providing a standardized framework for assessing real-world performance.  					AI-generated summary 				 The Model Context Protocol (MCP) is rapidly emerging as a pivotal open standard, designed to ...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 13. Causal Attention Tuning (CAT) enhances Large Language Models (LLMs) by injecting causal knowledge into the attention mechanism, improving prediction accuracy and robustness in out-of-distribution scenarios.  					AI-generated summary 				 Large Language Models (LLMs) have achieved remarkable success...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 14. Minority languages in China, such as Tibetan, Uyghur, and Traditional Mongolian, face significant challenges due to their unique writing systems, which differ from international standards. This discrepancy has led to a severe lack of relevant corpora, particularly for supervised tasks like headline ...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 15. DeMeVa explores in-context learning and label distribution learning for predicting annotator-specific annotations and generating soft labels, demonstrating competitive performance and potential for further research.  					AI-generated summary 				 This system paper presents the DeMeVa team's approac...
[15.09.2025 17:10] ********************************************************************************
[15.09.2025 17:10] Abstract 16. LLM hacking introduces significant variability and error in social science research, affecting statistical conclusions and requiring rigorous verification and human annotations to mitigate.  					AI-generated summary 				 Large language models (LLMs) are rapidly transforming social science research ...
[15.09.2025 17:10] Read previous papers.
[15.09.2025 17:10] Generating reviews via LLM API.
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#multimodal", "#rlhf", "#science", "#dataset", "#healthcare"], "emoji": "üß†", "ru": {"title": "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ—Å—Ç—å –¥–∏–∞–ª–æ–≥–æ–≤: –∫–ª—é—á –∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ IntrEx - –∫—Ä—É–ø–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ—Å—Ç–∏ 
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#long_context", "#architecture", "#reasoning", "#benchmark", "#rl"], "emoji": "üìà", "ru": {"title": "–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ LLM: –ø—É—Ç—å –∫ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–º –∑–∞–¥–∞—á–∞–º", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –Ω–∞ –∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω—è—Ç—å –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#cv", "#architecture", "#diffusion"], "emoji": "üñºÔ∏è", "ru": {"title": "InfGen: –º–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ª—é–±–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è", "desc": "InfGen - —ç—Ç–æ –Ω–æ–≤—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∑–∞–º–µ–Ω—è—é—â–∏–π –¥–µ–∫–æ–¥–µ—Ä VAE –≤ –º–æ–¥–µ–ª—è—Ö –ª–∞—Ç–µ–Ω—Ç–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#3d", "#diffusion", "#open_source"], "emoji": "üß©", "ru": {"title": "–£–º–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º—ã–µ —á–∞—Å—Ç–∏", "desc": "X-Part - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —á–∞—Å—Ç–∏ —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ —Ä–∞–º
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#rag", "#benchmark", "#interpretability"], "emoji": "üß†", "ru": {"title": "HANRAG: –£–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤", "desc": "HANRAG - —ç—Ç–æ –Ω–æ–≤–∞—è —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞, —É–ª—É—á—à–∞—é—â–∞—è —Ä–∞–±–æ—Ç—É –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º. –û–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –ø—É—Ç–µ–º 
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#open_source", "#audio", "#dataset", "#alignment", "#multilingual", "#benchmark"], "emoji": "üó£Ô∏è", "ru": {"title": "–ù–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–º –ò–ò: –∞–¥–∞–ø—Ç–∞—Ü–∏—è —Å—Ç–∏–ª—è —Ä–µ—á–∏ –ø–æ –≥–æ–ª–æ—Å–æ–≤—ã–º –∫–æ–º–∞–Ω–¥–∞–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Voice Style Adaptation (VSA), –∫–æ—Ç–æ—Ä–∞—è
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#training", "#robotics", "#optimization", "#architecture", "#agents"], "emoji": "üå∏", "ru": {"title": "FLOWER: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è VLA-–ø–æ–ª–∏—Ç–∏–∫–∞ –¥–ª—è –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–π —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∏", "desc": "FLOWER - —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –∑—Ä–µ–Ω–∏—è-—è–∑—ã–∫–∞-–¥–µ–π—Å—Ç–≤–∏—è (VLA) —Å 950 –º–∏–ª–ª–∏–æ–Ω–∞–º
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#agents", "#ethics", "#alignment"], "emoji": "ü§ñ", "ru": {"title": "–ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—â–µ–≥–æ –±–ª–∞–≥–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é '—ç–∫–æ–Ω–æ–º–∏–∫–∏ –ø–µ—Å–æ—á–Ω–∏—Ü—ã' –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞—Ä–æ–∂–¥–∞—é—â–µ–π—Å—è —ç–∫–æ–Ω–æ–º–∏–∫–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤. –ê–≤—Ç–æ—Ä—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –¥–≤–∞ –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–∞
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#math", "#diffusion", "#synthetic", "#games", "#rl", "#rlhf", "#training", "#optimization", "#architecture"], "emoji": "üß†", "ru": {"title": "–ò–Ω–ø–µ–π–Ω—Ç–∏–Ω–≥ –Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "IGPO - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#training", "#science", "#multimodal", "#agents", "#reasoning", "#games"], "emoji": "üìà", "ru": {"title": "QuantAgent: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "QuantAgent - —ç—Ç–æ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–∞—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#optimization", "#training", "#transfer_learning"], "emoji": "ü¶ö", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –¥–ª–∏–Ω–Ω—ã–º —Ö–≤–æ—Å—Ç–æ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç LoFT - –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è 
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#multimodal", "#data", "#diffusion", "#optimization", "#cv"], "emoji": "üé®", "ru": {"title": "–¢–æ—á–Ω—ã–µ —Ü–≤–µ—Ç–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –±–æ–ª—å—à—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ü–≤–µ—Ç–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#open_source", "#agents", "#benchmark"], "emoji": "ü§ñ", "ru": {"title": "–ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ", "desc": "MCP-AgentBench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª MCP. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —Ç–µ—Å—Ç–æ
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#architecture", "#training", "#reasoning", "#optimization"], "emoji": "üß†", "ru": {"title": "–ü—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Causal Attention Tuning (CAT) –¥–ª—è —É–ª—É—á
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#low_resource", "#synthetic", "#multilingual", "#machine_translation", "#benchmark", "#dataset"], "emoji": "üì∞", "ru": {"title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤–æ–≥–æ –±–∞—Ä—å–µ—Ä–∞: –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–∞ —è–∑—ã–∫–∞—Ö –º–µ–Ω—å—à–∏–Ω—Å—Ç–≤ –ö–∏—Ç–∞—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö CMHG –¥–ª
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#data", "#interpretability", "#transfer_learning", "#training"], "emoji": "üè∑Ô∏è", "ru": {"title": "–ù–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –æ–±—É—á–µ–Ω–∏—é —Å —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è–º–∏: –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –º–µ—Ç–æ–∫", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–¥—Ö–æ–¥—ã –∫–æ–º–∞–Ω–¥—ã DeMeVa –∫ –∑–∞–¥–∞—á–µ –æ–±—É—á–µ–Ω–∏—è —Å —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è–º–∏ (LeWiDi 2025). –ò—Å—Å–ª–µ–¥
[15.09.2025 17:10] Using data from previous issue: {"categories": ["#science", "#data", "#multimodal", "#training", "#ethics"], "emoji": "ü§ñ", "ru": {"title": "–õ–õ–ú-—Ö–∞–∫–∏–Ω–≥: —Å–∫—Ä—ã—Ç–∞—è —É–≥—Ä–æ–∑–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞—É–∫–∞—Ö", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º–µ –õ–õ–ú-—Ö–∞–∫–∏–Ω–≥–∞ –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞—É–∫–∞—Ö, –≥–¥–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥
[15.09.2025 17:10] Renaming data file.
[15.09.2025 17:10] Renaming previous data. hf_papers.json to ./d/2025-09-15.json
[15.09.2025 17:10] Saving new data file.
[15.09.2025 17:10] Generating page.
[15.09.2025 17:10] Renaming previous page.
[15.09.2025 17:10] Renaming previous data. index.html to ./d/2025-09-15.html
[15.09.2025 17:10] Writing result.
[15.09.2025 17:10] Renaming log file.
[15.09.2025 17:10] Renaming previous data. log.txt to ./logs/2025-09-15_last_log.txt
