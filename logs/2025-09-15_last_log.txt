[15.09.2025 07:12] Read previous papers.
[15.09.2025 07:12] Generating top page (month).
[15.09.2025 07:12] Writing top page (month).
[15.09.2025 08:15] Read previous papers.
[15.09.2025 08:15] Get feed.
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09677
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10441
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08643
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09713
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09716
[15.09.2025 08:15] Extract page data from URL. URL: https://huggingface.co/papers/2509.04996
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10396
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10147
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09995
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09734
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09926
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10058
[15.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09990
[15.09.2025 08:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.09.2025 08:15] No deleted papers detected.
[15.09.2025 08:15] Downloading and parsing papers (pdf, html). Total: 13.
[15.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.09677.
[15.09.2025 08:15] Extra JSON file exists (./assets/json/2509.09677.json), skip PDF parsing.
[15.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.09677.json), skip HTML parsing.
[15.09.2025 08:15] Success.
[15.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.10441.
[15.09.2025 08:15] Extra JSON file exists (./assets/json/2509.10441.json), skip PDF parsing.
[15.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.10441.json), skip HTML parsing.
[15.09.2025 08:15] Success.
[15.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.08643.
[15.09.2025 08:15] Extra JSON file exists (./assets/json/2509.08643.json), skip PDF parsing.
[15.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.08643.json), skip HTML parsing.
[15.09.2025 08:15] Success.
[15.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.09713.
[15.09.2025 08:15] Extra JSON file exists (./assets/json/2509.09713.json), skip PDF parsing.
[15.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.09713.json), skip HTML parsing.
[15.09.2025 08:15] Success.
[15.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.09716.
[15.09.2025 08:15] Extra JSON file exists (./assets/json/2509.09716.json), skip PDF parsing.
[15.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.09716.json), skip HTML parsing.
[15.09.2025 08:15] Success.
[15.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.04996.
[15.09.2025 08:15] Downloading paper 2509.04996 from http://arxiv.org/pdf/2509.04996v1...
[15.09.2025 08:15] Extracting affiliations from text.
[15.09.2025 08:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 ] . [ 1 6 9 9 4 0 . 9 0 5 2 : r FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies Moritz Reuss1 Hongyi Zhou1 Marcel uhle1 Omer Erdinc Yagmurlu1 Fabian Otto2 Rudolf Lioutikov1 1Intuitive Robots Lab, Karlsruhe Institute of Technology, Germany 2Microsoft Research Abstract: Developing efficient Vision-Language-Action (VLA) policies is crucial for practical robotics deployment, yet current approaches face prohibitive computational costs and resource requirements. Existing diffusion-based VLA policies require multi-billion-parameter models and massive datasets to achieve strong performance. We tackle this efficiency challenge with two contributions: intermediate-modality fusion, which reallocates capacity to the diffusion head by pruning up to 50% of LLM layers, and action-specific Global-AdaLN conditioning, which cuts parameters by 20% through modular adaptation. We integrate these advances into novel 950 M-parameter VLA called FLOWER. Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance with bigger VLAs across 190 tasks spanning ten simulation and realworld benchmarks and demonstrates robustness across diverse robotic embodiments. In addition, FLOWER achieves new SoTA of 4.53 on the CALVIN ABC benchmark. Demos, code and pretrained weights are available at https: //intuitive-robots.github.io/flower_vla/. Keywords: Imitation Learning, VLA,Language-conditioned Manipulation Generalist robotic manipulation policies that execute diverse tasks across different embodiments remain key goal in robotics. Recent advances in Imitation Learning (IL) have made significant progress toward this vision, particularly along the direction of generalist Vision-Language-ActionModel (VLA) Policies [2, 1, 3]. VLAs fine-tune pretrained Vision-Language-Models (VLMs) to generate robot actions from free-form language commands [2, 1, 3]. These models commonly adopt discrete [4, 1, 5, 6] or diffusion-based objective"
[15.09.2025 08:16] Response: ```python
["Intuitive Robots Lab, Karlsruhe Institute of Technology, Germany", "Microsoft Research"]
```
[15.09.2025 08:16] Deleting PDF ./assets/pdf/2509.04996.pdf.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.10396.
[15.09.2025 08:16] Extra JSON file exists (./assets/json/2509.10396.json), skip PDF parsing.
[15.09.2025 08:16] Paper image links file exists (./assets/img_data/2509.10396.json), skip HTML parsing.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.10147.
[15.09.2025 08:16] Extra JSON file exists (./assets/json/2509.10147.json), skip PDF parsing.
[15.09.2025 08:16] Paper image links file exists (./assets/img_data/2509.10147.json), skip HTML parsing.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.09995.
[15.09.2025 08:16] Extra JSON file exists (./assets/json/2509.09995.json), skip PDF parsing.
[15.09.2025 08:16] Paper image links file exists (./assets/img_data/2509.09995.json), skip HTML parsing.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.09734.
[15.09.2025 08:16] Extra JSON file exists (./assets/json/2509.09734.json), skip PDF parsing.
[15.09.2025 08:16] Paper image links file exists (./assets/img_data/2509.09734.json), skip HTML parsing.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.09926.
[15.09.2025 08:16] Extra JSON file exists (./assets/json/2509.09926.json), skip PDF parsing.
[15.09.2025 08:16] Paper image links file exists (./assets/img_data/2509.09926.json), skip HTML parsing.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.10058.
[15.09.2025 08:16] Extra JSON file exists (./assets/json/2509.10058.json), skip PDF parsing.
[15.09.2025 08:16] Paper image links file exists (./assets/img_data/2509.10058.json), skip HTML parsing.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2509.09990.
[15.09.2025 08:16] Extra JSON file exists (./assets/json/2509.09990.json), skip PDF parsing.
[15.09.2025 08:16] Paper image links file exists (./assets/img_data/2509.09990.json), skip HTML parsing.
[15.09.2025 08:16] Success.
[15.09.2025 08:16] Enriching papers with extra data.
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 0. Scaling large language models improves their ability to execute longer tasks by isolating execution capability and mitigating self-conditioning effects, despite diminishing single-step accuracy.  					AI-generated summary 				 Does continued scaling of large language models (LLMs) yield diminishing ...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 1. InfGen, a one-step generator replacing the VAE decoder, enables arbitrary high-resolution image generation from a fixed-size latent, significantly reducing computational complexity and generation time.  					AI-generated summary 				 Arbitrary resolution image generation provides a consistent visual...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 2. X-Part is a generative model that decomposes 3D objects into semantically meaningful parts with high fidelity, using bounding boxes and point-wise semantic features, and supports interactive editing.  					AI-generated summary 				 Generating 3D shapes at part level is pivotal for downstream applica...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 3. HANRAG, a heuristic-based framework, improves question-answering systems by efficiently handling multi-hop queries and reducing noise through query decomposition and filtering.  					AI-generated summary 				 The Retrieval-Augmented Generation (RAG) approach enhances question-answering systems and d...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 4. Voice Style Adaptation (VSA) evaluates the ability of spoken language models to modify their speaking style based on spoken instructions, using a bilingual benchmark and a Large Audio Language Model as a Judge framework.  					AI-generated summary 				 Spoken language models (SLMs) have emerged as a...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 5. FLOWER, a 950 M-parameter VLA policy, achieves competitive performance with reduced computational costs through intermediate-modality fusion and action-specific Global-AdaLN conditioning.  					AI-generated summary 				 Developing efficient Vision-Language-Action (VLA) policies is crucial for practi...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 6. IGPO, an RL framework utilizing inpainting in masked diffusion large language models, enhances sample efficiency and achieves state-of-the-art results in mathematical benchmarks.  					AI-generated summary 				 Masked diffusion large language models (dLLMs) are emerging as promising alternatives to ...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 7. The sandbox economy framework analyzes the emerging AI agent economy, focusing on its origins and permeability, and discusses design choices for safe and steerable AI markets.  					AI-generated summary 				 The rapid adoption of autonomous AI agents is giving rise to a new economic layer where agen...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 8. QuantAgent, a multi-agent LLM framework, excels in high-frequency trading by leveraging specialized agents for technical indicators, chart patterns, trends, and risk, outperforming existing neural and rule-based systems.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs)...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 9. MCP-AgentBench is a benchmark designed to evaluate language agents in MCP-mediated tool interactions, providing a standardized framework for assessing real-world performance.  					AI-generated summary 				 The Model Context Protocol (MCP) is rapidly emerging as a pivotal open standard, designed to ...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 10. LoFT, a parameter-efficient fine-tuning framework for long-tailed semi-supervised learning, improves reliability of pseudolabels and discriminative ability in open-world scenarios, outperforming previous methods.  					AI-generated summary 				 Long-tailed learning has garnered increasing attention ...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 11. A training-free framework uses a large language model to disambiguate color terms and refine text embeddings for improved color accuracy in text-to-image generation.  					AI-generated summary 				 Accurate color alignment in text-to-image (T2I) generation is critical for applications such as fashio...
[15.09.2025 08:16] ********************************************************************************
[15.09.2025 08:16] Abstract 12. Minority languages in China, such as Tibetan, Uyghur, and Traditional Mongolian, face significant challenges due to their unique writing systems, which differ from international standards. This discrepancy has led to a severe lack of relevant corpora, particularly for supervised tasks like headline ...
[15.09.2025 08:16] Read previous papers.
[15.09.2025 08:16] Generating reviews via LLM API.
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#long_context", "#architecture", "#reasoning", "#benchmark", "#rl"], "emoji": "📈", "ru": {"title": "Масштабирование LLM: путь к длительным задачам", "desc": "Данная статья исследует влияние масштабирования больших языковых моделей (LLM) на их способность выполнять более длительные з
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#cv", "#architecture", "#diffusion"], "emoji": "🖼️", "ru": {"title": "InfGen: мгновенная генерация изображений любого разрешения", "desc": "InfGen - это новый генератор изображений, заменяющий декодер VAE в моделях латентной диффузии. Он позволяет создавать изображе
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#3d", "#diffusion", "#open_source"], "emoji": "🧩", "ru": {"title": "Умная декомпозиция 3D-объектов на редактируемые части", "desc": "X-Part - это генеративная модель для декомпозиции 3D-объектов на семантически значимые части с высокой точностью. Модель использует ограничивающие рам
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#reasoning", "#rag", "#benchmark", "#interpretability"], "emoji": "🧠", "ru": {"title": "HANRAG: Умное решение для сложных вопросов", "desc": "HANRAG - это новая эвристическая система, улучшающая работу вопросно-ответных систем. Она эффективно обрабатывает многоэтапные запросы путем 
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#open_source", "#audio", "#dataset", "#alignment", "#multilingual", "#benchmark"], "emoji": "🗣️", "ru": {"title": "Новый рубеж в разговорном ИИ: адаптация стиля речи по голосовым командам", "desc": "Статья представляет новую задачу под названием Voice Style Adaptation (VSA), которая
[15.09.2025 08:16] Querying the API.
[15.09.2025 08:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FLOWER, a 950 M-parameter VLA policy, achieves competitive performance with reduced computational costs through intermediate-modality fusion and action-specific Global-AdaLN conditioning.  					AI-generated summary 				 Developing efficient Vision-Language-Action (VLA) policies is crucial for practical robotics deployment, yet current approaches face prohibitive computational costs and resource requirements. Existing diffusion-based VLA policies require multi-billion-parameter models and massive datasets to achieve strong performance. We tackle this efficiency challenge with two contributions: intermediate-modality fusion, which reallocates capacity to the diffusion head by pruning up to 50% of LLM layers, and action-specific Global-AdaLN conditioning, which cuts parameters by 20% through modular adaptation. We integrate these advances into a novel 950 M-parameter VLA called FLOWER. Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance with bigger VLAs across 190 tasks spanning ten simulation and real-world benchmarks and demonstrates robustness across diverse robotic embodiments. In addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark. Demos, code and pretrained weights are available at https://intuitive-robots.github.io/flower_vla/.
[15.09.2025 08:16] Response: {
  "desc": "FLOWER - это эффективная политика зрения-языка-действия (VLA) с 950 миллионами параметров. Она использует промежуточное слияние модальностей и специфическое для действий Global-AdaLN кондиционирование для сокращения вычислительных затрат. FLOWER демонстрирует конкурентоспособную производительность на 190 задачах в десяти симуляционных и реальных эталонных тестах. Модель достигает нового рекорда на бенчмарке CALVIN ABC, показывая устойчивость для различных роботизированных воплощений.",
  "emoji": "🌸",
  "title": "FLOWER: Эффективная VLA-политика для интуитивной робототехники"
}
[15.09.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FLOWER, a 950 M-parameter VLA policy, achieves competitive performance with reduced computational costs through intermediate-modality fusion and action-specific Global-AdaLN conditioning.  					AI-generated summary 				 Developing efficient Vision-Language-Action (VLA) policies is crucial for practical robotics deployment, yet current approaches face prohibitive computational costs and resource requirements. Existing diffusion-based VLA policies require multi-billion-parameter models and massive datasets to achieve strong performance. We tackle this efficiency challenge with two contributions: intermediate-modality fusion, which reallocates capacity to the diffusion head by pruning up to 50% of LLM layers, and action-specific Global-AdaLN conditioning, which cuts parameters by 20% through modular adaptation. We integrate these advances into a novel 950 M-parameter VLA called FLOWER. Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance with bigger VLAs across 190 tasks spanning ten simulation and real-world benchmarks and demonstrates robustness across diverse robotic embodiments. In addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark. Demos, code and pretrained weights are available at https://intuitive-robots.github.io/flower_vla/."

[15.09.2025 08:16] Response: ```python
['AGENTS', 'ROBOTICS', 'ARCHITECTURE', 'BENCHMARK', 'TRAINING']
```
[15.09.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FLOWER, a 950 M-parameter VLA policy, achieves competitive performance with reduced computational costs through intermediate-modality fusion and action-specific Global-AdaLN conditioning.  					AI-generated summary 				 Developing efficient Vision-Language-Action (VLA) policies is crucial for practical robotics deployment, yet current approaches face prohibitive computational costs and resource requirements. Existing diffusion-based VLA policies require multi-billion-parameter models and massive datasets to achieve strong performance. We tackle this efficiency challenge with two contributions: intermediate-modality fusion, which reallocates capacity to the diffusion head by pruning up to 50% of LLM layers, and action-specific Global-AdaLN conditioning, which cuts parameters by 20% through modular adaptation. We integrate these advances into a novel 950 M-parameter VLA called FLOWER. Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance with bigger VLAs across 190 tasks spanning ten simulation and real-world benchmarks and demonstrates robustness across diverse robotic embodiments. In addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark. Demos, code and pretrained weights are available at https://intuitive-robots.github.io/flower_vla/."

[15.09.2025 08:16] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```
[15.09.2025 08:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper presents FLOWER, a Vision-Language-Action (VLA) policy with 950 million parameters that enhances efficiency in robotics applications. It introduces intermediate-modality fusion to optimize model capacity by reducing the number of layers in large language models (LLMs) by up to 50%. Additionally, it employs action-specific Global-AdaLN conditioning, which decreases the parameter count by 20% through modular adaptation. FLOWER achieves competitive performance across 190 tasks while significantly reducing computational costs compared to existing multi-billion-parameter models.","title":"Efficient Robotics with FLOWER: A 950M-Parameter VLA Policy"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper presents FLOWER, a Vision-Language-Action (VLA) policy with 950 million parameters that enhances efficiency in robotics applications. It introduces intermediate-modality fusion to optimize model capacity by reducing the number of layers in large language models (LLMs) by up to 50%. Additionally, it employs action-specific Global-AdaLN conditioning, which decreases the parameter count by 20% through modular adaptation. FLOWER achieves competitive performance across 190 tasks while significantly reducing computational costs compared to existing multi-billion-parameter models.', title='Efficient Robotics with FLOWER: A 950M-Parameter VLA Policy'))
[15.09.2025 08:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种名为FLOWER的950M参数的视觉-语言-动作（VLA）策略，旨在降低计算成本并提高效率。通过中间模态融合和特定动作的全局自适应层归一化（Global-AdaLN）条件，FLOWER在保持竞争性能的同时，减少了模型的参数量。该模型在仅200小时的H100 GPU训练后，能够在190个任务中表现出色，并在CALVIN ABC基准测试中达到了新的最优状态。FLOWER的设计使其在多种机器人平台上都表现出良好的鲁棒性。","title":"FLOWER：高效的视觉-语言-动作策略"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种名为FLOWER的950M参数的视觉-语言-动作（VLA）策略，旨在降低计算成本并提高效率。通过中间模态融合和特定动作的全局自适应层归一化（Global-AdaLN）条件，FLOWER在保持竞争性能的同时，减少了模型的参数量。该模型在仅200小时的H100 GPU训练后，能够在190个任务中表现出色，并在CALVIN ABC基准测试中达到了新的最优状态。FLOWER的设计使其在多种机器人平台上都表现出良好的鲁棒性。', title='FLOWER：高效的视觉-语言-动作策略'))
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#math", "#diffusion", "#synthetic", "#games", "#rl", "#rlhf", "#training", "#optimization", "#architecture"], "emoji": "🧠", "ru": {"title": "Инпейнтинг направляет исследование в обучении с подкреплением языковых моделей", "desc": "IGPO - это новая система обучения с подкреплением дл
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#agents", "#ethics", "#alignment"], "emoji": "🤖", "ru": {"title": "Проектирование безопасной экономики ИИ-агентов для общего блага", "desc": "Статья представляет концепцию 'экономики песочницы' для анализа зарождающейся экономики ИИ-агентов. Авторы рассматривают два ключевых аспекта
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#training", "#science", "#multimodal", "#agents", "#reasoning", "#games"], "emoji": "📈", "ru": {"title": "QuantAgent: Революция в высокочастотной торговле с помощью мультиагентных языковых моделей", "desc": "QuantAgent - это инновационная мультиагентная система на основе больших язы
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#open_source", "#agents", "#benchmark"], "emoji": "🤖", "ru": {"title": "Новый стандарт оценки ИИ-агентов в реальном мире", "desc": "MCP-AgentBench - это новый бенчмарк для оценки языковых агентов в контексте взаимодействия с инструментами через протокол MCP. Он включает в себя тесто
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#optimization", "#training", "#transfer_learning"], "emoji": "🦚", "ru": {"title": "Эффективная тонкая настройка для обучения с длинным хвостом", "desc": "Статья представляет LoFT - новый фреймворк для эффективной тонкой настройки моделей машинного обучения 
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#multimodal", "#data", "#diffusion", "#optimization", "#cv"], "emoji": "🎨", "ru": {"title": "Точные цвета в генерации изображений без дообучения", "desc": "Предложена система, использующая большую языковую модель для уточнения цветовых терминов в запросах для генерации изображений п
[15.09.2025 08:16] Using data from previous issue: {"categories": ["#low_resource", "#synthetic", "#multilingual", "#machine_translation", "#benchmark", "#dataset"], "emoji": "📰", "ru": {"title": "Преодоление языкового барьера: новый датасет для генерации заголовков на языках меньшинств Китая", "desc": "Статья представляет новый набор данных CMHG дл
[15.09.2025 08:16] Renaming data file.
[15.09.2025 08:16] Renaming previous data. hf_papers.json to ./d/2025-09-15.json
[15.09.2025 08:16] Saving new data file.
[15.09.2025 08:16] Generating page.
[15.09.2025 08:16] Renaming previous page.
[15.09.2025 08:16] Renaming previous data. index.html to ./d/2025-09-15.html
[15.09.2025 08:16] Writing result.
[15.09.2025 08:16] Renaming log file.
[15.09.2025 08:16] Renaming previous data. log.txt to ./logs/2025-09-15_last_log.txt
