[08.11.2024 12:33] Read previous papers.
[08.11.2024 12:33] Generating top page (month).
[08.11.2024 12:33] Writing top page (month).
[08.11.2024 12:33] Read previous papers.
[08.11.2024 12:33] Generating top page (month).
[08.11.2024 12:33] Writing top page (month).
[08.11.2024 12:33] Read previous papers.
[08.11.2024 12:33] Generating top page (month).
[08.11.2024 12:33] Writing top page (month).
[08.11.2024 09:36] Read previous papers.
[08.11.2024 09:36] Get feed.
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04905
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05003
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04965
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04928
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04996
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04709
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04496
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04999
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04752
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05007
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04335
[08.11.2024 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04989
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 0. Large language models (LLMs) for code have become indispensable in various domains, including code generation, reasoning tasks and agent systems.While open-access code LLMs are increasingly approaching the performance levels of proprietary models, high-quality code LLMs suitable for rigorous scienti...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 1. Recently, breakthroughs in video modeling have allowed for controllable camera trajectories in generated videos. However, these methods cannot be directly applied to user-provided videos that are not generated by a video model. In this paper, we present ReCapture, a method for generating new videos ...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 2. Recent research on the 1-bit Large Language Models (LLMs), such as BitNet b1.58, presents a promising direction for reducing the inference cost of LLMs while maintaining their performance. In this work, we introduce BitNet a4.8, enabling 4-bit activations for 1-bit LLMs. BitNet a4.8 employs a hybrid...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 3. In this paper, we introduce DimensionX, a framework designed to generate photorealistic 3D and 4D scenes from just a single image with video diffusion. Our approach begins with the insight that both the spatial structure of a 3D scene and the temporal evolution of a 4D scene can be effectively repre...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 4. The development of large language models (LLMs) has expanded to multi-modal systems capable of processing text, images, and speech within a unified framework. Training these models demands significantly larger datasets and computational resources compared to text-only LLMs. To address the scaling ch...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 5. Video generation models are revolutionizing content creation, with image-to-video models drawing increasing attention due to their enhanced controllability, visual consistency, and practical applications. However, despite their popularity, these models rely on user-provided text and image prompts, a...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 6. To increase social bonding with interlocutors, humans naturally acquire the ability to respond appropriately in a given situation by considering which conversational skill is most suitable for the response - a process we call skill-of-mind. For large language model (LLM)-based conversational agents,...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 7. Significant progress has been made in open-vocabulary mobile manipulation, where the goal is for a robot to perform tasks in any environment given a natural language description. However, most current systems assume a static environment, which limits the system's applicability in real-world scenario...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 8. Code-mixing, the integration of lexical and grammatical elements from multiple languages within a single sentence, is a widespread linguistic phenomenon, particularly prevalent in multilingual societies. In India, social media users frequently engage in code-mixed conversations using the Roman scrip...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 9. Diffusion models have been proven highly effective at generating high-quality images. However, as these models grow larger, they require significantly more memory and suffer from higher latency, posing substantial challenges for deployment. In this work, we aim to accelerate diffusion models by quan...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 10. We present GazeGen, a user interaction system that generates visual content (images and videos) for locations indicated by the user's eye gaze. GazeGen allows intuitive manipulation of visual content by targeting regions of interest with gaze. Using advanced techniques in object detection and genera...
[08.11.2024 09:36] ********************************************************************************
[08.11.2024 09:36] Abstract 11. Methods for image-to-video generation have achieved impressive, photo-realistic quality. However, adjusting specific elements in generated videos, such as object motion or camera movement, is often a tedious process of trial and error, e.g., involving re-generating videos with different random seeds...
[08.11.2024 09:36] Read previous papers.
[08.11.2024 09:36] Generating reviews via LLM API.
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#dataset", "#data", "#training", "#synthetic", "#agents"], "emoji": "üßë‚Äçüíª", "ru": {"title": "OpenCoder: –æ—Ç–∫—Ä—ã—Ç–∞—è –∫–Ω–∏–≥–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–ø–æ–≤—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–æ–¥–∞", "desc": "OpenCoder - —ç—Ç–æ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º, —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞—è –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#video", "#diffusion", "#hallucinations"], "emoji": "üé•", "ru": {"title": "–ü–µ—Ä–µ—Å–Ω–∏–º–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å: –Ω–æ–≤—ã–µ —Ä–∞–∫—É—Ä—Å—ã –¥–ª—è –ª—é–±–æ–≥–æ –≤–∏–¥–µ–æ", "desc": "ReCapture - —ç—Ç–æ –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –≤–∏–¥–µ–æ —Å –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–º–∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è–º–∏ –∫–∞–º–µ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#inference", "#optimization", "#architecture"], "emoji": "üß†", "ru": {"title": "BitNet a4.8: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º–∏—Ä–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç BitNet a4.8 - —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é 1-–±–∏—Ç–Ω–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç–∞ –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 4-–±–∏—Ç–Ω—ã–µ –∞–∫—Ç
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#3d", "#video", "#synthetic"], "emoji": "üé≠", "ru": {"title": "–û—Ç 2D –∫ 4D: DimensionX —Ä–∞–∑–¥–≤–∏–≥–∞–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "DimensionX - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö 3D –∏ 4D —Å—Ü–µ–Ω –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏–∏. –ö–ª—é—á–µ–≤—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º —è–≤–ª—è–µ—Ç—Å
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#architecture", "#multimodal", "#training", "#optimization"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã: –º–µ–Ω—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, —Ç–∞ –∂–µ –º–æ—â–Ω–æ—Å—Ç—å", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Mixture-of-Transformers (MoT) - –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö 
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#dataset", "#video"], "emoji": "üé¨", "ru": {"title": "TIP-I2V: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∏–∑—É—á–µ–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ TIP-I2V - –ø–µ—Ä–≤—ã–π –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –±–æ–ª–µ–µ 1,70 –º–∏–ª–ª–∏–æ–Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏ 
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#dataset", "#agents", "#multimodal"], "emoji": "üó£Ô∏è", "ru": {"title": "–Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —É—á–∞—Ç—Å—è –∏—Å–∫—É—Å—Å—Ç–≤—É –æ–±—â–µ–Ω–∏—è", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Multifaceted Skill-of-Mind, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –Ω–∞–≤—ã–∫–æ–≤ –≤–µ–¥–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö —Å—Ü–µ
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#robotics", "#3d", "#multimodal", "#agents"], "emoji": "ü§ñ", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤ –≤ –∏–∑–º–µ–Ω—è—é—â–µ–º—Å—è –º–∏—Ä–µ", "desc": "DynaMem - –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–æ–±–∏–ª—å–Ω–æ–π –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º —Å–ª–æ–≤–∞—Ä–µ–º –≤ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ä–µ–¥–∞—Ö. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-—Å–µ–º–∞–Ω
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#multilingual", "#dataset", "#data"], "emoji": "üó£Ô∏è", "ru": {"title": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–º–µ—à–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Å–º–µ—à–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#inference", "#optimization", "#diffusion"], "emoji": "üöÄ", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é 4-–±–∏—Ç–Ω–æ–≥–æ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º SVDQuant –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∏–∑–∫–æ—Ä–∞–Ω–≥–æ–≤—É—é
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#agents", "#cv", "#video", "#edge_computing", "#training"], "emoji": "üëÅÔ∏è", "ru": {"title": "–í–∑–≥–ª—è–¥–æ–º —É–ø—Ä–∞–≤–ª—è–π: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–∏—Å—Ç–µ–º—É GazeGen, –∫–æ—Ç–æ—Ä–∞—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–∑–≥–ª—è–¥–∞ –ø–æ–ª—å–∑–æ
[08.11.2024 09:36] Using data from previous issue: {"categories": ["#video", "#diffusion", "#dataset"], "emoji": "üé¨", "ru": {"title": "–£–ø—Ä–∞–≤–ª—è–µ–º–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "SG-I2V - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ø—Ä–∞–≤–ª—è–µ–º–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–ø–æ–ª
[08.11.2024 09:36] Trying to get texts in Chinese.
[08.11.2024 09:36] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Large language models (LLMs) for code have become indispensable in various domains, including code generation, reasoning tasks and agent systems.While open-access code LLMs are increasingly approaching the performance levels of proprietary models, high-quality code LLMs suitable for rigorous scientific investigation, particularly those with reproducible data processing pipelines and transparent training protocols, remain limited. The scarcity is due to various challenges, including resource constraints, ethical considerations, and the competitive advantages of keeping models advanced. To address the gap, we introduce OpenCoder, a top-tier code LLM that not only achieves performance comparable to leading models but also serves as an ``open cookbook'' for the research community. Unlike most prior efforts, we release not only model weights and inference code, but also the reproducible training data, complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols for open scientific research. Through this comprehensive release, we identify the key ingredients for building a top-tier code LLM: (1) code optimized heuristic rules for data cleaning and methods for data deduplication, (2) recall of text corpus related to code and (3) high-quality synthetic data in both annealing and supervised fine-tuning stages. By offering this level of openness, we aim to broaden access to all aspects of a top-tier code LLM, with OpenCoder serving as both a powerful model and an open foundation to accelerate research, and enable reproducible advancements in code AI.
[08.11.2024 09:36] Mistral response. {"id": "3b9a2690c5a04f5f8c184ca0268342d9", "object": "chat.completion", "created": 1731058570, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u3001\u63a8\u7406\u4efb\u52a1\u548c\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6027\u3002\u867d\u7136\u5f00\u653e\u8bbf\u95ee\u7684\u4ee3\u7801LLMs\u6027\u80fd\u63a5\u8fd1\u4e13\u6709\u6a21\u578b\uff0c\u4f46\u9002\u5408\u4e25\u8c28\u79d1\u5b66\u7814\u7a76\u7684\u9ad8\u8d28\u91cf\u4ee3\u7801LLMs\u4ecd\u7136\u6709\u9650\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6587\u7ae0\u4ecb\u7ecd\u4e86OpenCoder\uff0c\u4e00\u4e2a\u9876\u5c16\u7684\u4ee3\u7801LLMs\uff0c\u5176\u6027\u80fd\u582a\u6bd4\u9886\u5148\u6a21\u578b\uff0c\u5e76\u4e14\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u201c\u5f00\u653e\u7684\u98df\u8c31\u201d\u3002OpenCoder\u4e0d\u4ec5\u53d1\u5e03\u4e86\u6a21\u578b\u6743\u91cd\u548c\u63a8\u7406\u4ee3\u7801\uff0c\u8fd8\u5305\u62ec\u53ef\u91cd\u590d\u7684\u8bad\u7ec3\u6570\u636e\u3001\u5b8c\u6574\u7684\u6570\u636e\u5904\u7406\u6d41\u6c34\u7ebf\u3001\u4e25\u683c\u7684\u5b9e\u9a8c\u6d88\u878d\u7ed3\u679c\u548c\u8be6\u7ec6\u7684\u8bad\u7ec3\u534f\u8bae\uff0c\u4ee5\u4fc3\u8fdb\u79d1\u5b66\u7814\u7a76\u7684\u5f00\u653e\u548c\u53ef\u91cd\u590d\u6027\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 360, "total_tokens": 585, "completion_tokens": 225}}
[08.11.2024 09:36] Response: ËøôÁØáÊñáÁ´†ËÆ®ËÆ∫‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®‰ª£Á†ÅÁîüÊàê„ÄÅÊé®ÁêÜ‰ªªÂä°Âíå‰ª£ÁêÜÁ≥ªÁªü‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇËôΩÁÑ∂ÂºÄÊîæËÆøÈóÆÁöÑ‰ª£Á†ÅLLMsÊÄßËÉΩÊé•Ëøë‰∏ìÊúâÊ®°ÂûãÔºå‰ΩÜÈÄÇÂêà‰∏•Ë∞®ÁßëÂ≠¶Á†îÁ©∂ÁöÑÈ´òË¥®Èáè‰ª£Á†ÅLLMs‰ªçÁÑ∂ÊúâÈôê„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ëøô‰∏ÄÁ©∫ÁôΩÔºåÊñáÁ´†‰ªãÁªç‰∫ÜOpenCoderÔºå‰∏Ä‰∏™È°∂Â∞ñÁöÑ‰ª£Á†ÅLLMsÔºåÂÖ∂ÊÄßËÉΩÂ†™ÊØîÈ¢ÜÂÖàÊ®°ÂûãÔºåÂπ∂‰∏î‰∏∫Á†îÁ©∂Á§æÂå∫Êèê‰æõ‰∫Ü‰∏Ä‰∏™‚ÄúÂºÄÊîæÁöÑÈ£üË∞±‚Äù„ÄÇOpenCoder‰∏ç‰ªÖÂèëÂ∏É‰∫ÜÊ®°ÂûãÊùÉÈáçÂíåÊé®ÁêÜ‰ª£Á†ÅÔºåËøòÂåÖÊã¨ÂèØÈáçÂ§çÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÅÂÆåÊï¥ÁöÑÊï∞ÊçÆÂ§ÑÁêÜÊµÅÊ∞¥Á∫ø„ÄÅ‰∏•Ê†ºÁöÑÂÆûÈ™åÊ∂àËûçÁªìÊûúÂíåËØ¶ÁªÜÁöÑËÆ≠ÁªÉÂçèËÆÆÔºå‰ª•‰øÉËøõÁßëÂ≠¶Á†îÁ©∂ÁöÑÂºÄÊîæÂíåÂèØÈáçÂ§çÊÄß„ÄÇ
[08.11.2024 09:36] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

ËøôÁØáÊñáÁ´†ËÆ®ËÆ∫‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®‰ª£Á†ÅÁîüÊàê„ÄÅÊé®ÁêÜ‰ªªÂä°Âíå‰ª£ÁêÜÁ≥ªÁªü‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇËôΩÁÑ∂ÂºÄÊîæËÆøÈóÆÁöÑ‰ª£Á†ÅLLMsÊÄßËÉΩÊé•Ëøë‰∏ìÊúâÊ®°ÂûãÔºå‰ΩÜÈÄÇÂêà‰∏•Ë∞®ÁßëÂ≠¶Á†îÁ©∂ÁöÑÈ´òË¥®Èáè‰ª£Á†ÅLLMs‰ªçÁÑ∂ÊúâÈôê„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ëøô‰∏ÄÁ©∫ÁôΩÔºåÊñáÁ´†‰ªãÁªç‰∫ÜOpenCoderÔºå‰∏Ä‰∏™È°∂Â∞ñÁöÑ‰ª£Á†ÅLLMsÔºåÂÖ∂ÊÄßËÉΩÂ†™ÊØîÈ¢ÜÂÖàÊ®°ÂûãÔºåÂπ∂‰∏î‰∏∫Á†îÁ©∂Á§æÂå∫Êèê‰æõ‰∫Ü‰∏Ä‰∏™‚ÄúÂºÄÊîæÁöÑÈ£üË∞±‚Äù„ÄÇOpenCoder‰∏ç‰ªÖÂèëÂ∏É‰∫ÜÊ®°ÂûãÊùÉÈáçÂíåÊé®ÁêÜ‰ª£Á†ÅÔºåËøòÂåÖÊã¨ÂèØÈáçÂ§çÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÅÂÆåÊï¥ÁöÑÊï∞ÊçÆÂ§ÑÁêÜÊµÅÊ∞¥Á∫ø„ÄÅ‰∏•Ê†ºÁöÑÂÆûÈ™åÊ∂àËûçÁªìÊûúÂíåËØ¶ÁªÜÁöÑËÆ≠ÁªÉÂçèËÆÆÔºå‰ª•‰øÉËøõÁßëÂ≠¶Á†îÁ©∂ÁöÑÂºÄÊîæÂíåÂèØÈáçÂ§çÊÄß„ÄÇ
[08.11.2024 09:36] Mistral response. {"id": "19573ebf2a1b45eaa83dfac6a4744662", "object": "chat.completion", "created": 1731058578, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "Zh\u00e8 pi\u0101n w\u00e9nzh\u0101ng t\u01ceol\u00f9n le d\u00e0x\u00edng y\u01d4y\u00e1n m\u00f3x\u00edng (LLMs) z\u00e0i d\u00e0im\u01ce sh\u0113ngch\u00e9ng, tu\u012bl\u01d0 r\u00e8nw\u00f9 h\u00e9 d\u00e0il\u01d0 x\u00ect\u01d2ng zh\u014dng de zh\u00f2ngy\u00e0ox\u00ecng. Su\u012br\u00e1n k\u0101if\u00e0ng f\u01cengw\u00e8n de d\u00e0im\u01ce LLMs x\u00ecngn\u00e9ng j\u00ecnk\u00e8 zhu\u0101ny\u01d2u m\u00f3x\u00edng, d\u00e0n sh\u00ech\u00e9 y\u00e1nk\u00e8 k\u0113xu\u00e9 y\u00e1nji\u016b de g\u0101o zh\u00ecli\u00e0ng d\u00e0im\u01ce LLMs r\u00e9ngr\u00e1n y\u01d2uxi\u00e0n. W\u00e8ile ti\u00e1nb\u01d4 zh\u00e8 y\u012b k\u00f2ngb\u00e1i, w\u00e9nzh\u0101ng ji\u00e8sh\u00e0o le OpenCoder, y\u012bg\u00e8 d\u01d0ngji\u0101n de d\u00e0im\u01ce LLMs, q\u00ed x\u00ecngn\u00e9ng k\u0101nb\u01d0 l\u01d0ngxi\u0101n m\u00f3x\u00edng, \u00e9rqi\u011b w\u00e8i y\u00e1nji\u016b sh\u00e8q\u016b ti\u00e1o g\u00f2ngle y\u012bg\u00e8 \u201ck\u0101if\u00e0ng de sh\u00edp\u01d4\u201d. OpenCoder b\u00f9j\u01d0n f\u0101b\u00f9le m\u00f3x\u00edng qu\u00e1nzh\u00f2ng h\u00e9 tu\u012bl\u01d0 d\u00e0im\u01ce, h\u00e1i b\u0101oku\u00f2 k\u011b ch\u00f3ngf\u00f9 de x\u00f9nli\u00e0n sh\u00f9j\u00f9, w\u00e1nzh\u011bng de sh\u00f9j\u00f9 ch\u01d4l\u01d0 li\u00fashu\u01d0xi\u00e0n, y\u00e1nj\u00ecn de sh\u00ecy\u00e0n r\u00f3ngr\u00f3ng ji\u00e9gu\u01d2 h\u00e9 xi\u00e1ngx\u00ec de x\u00f9nli\u00e0n xi\u00e9y\u00ec, y\u01d0 c\u00f9j\u00ecn k\u0113xu\u00e9 y\u00e1nji\u016b de k\u0101if\u00e0ng h\u00e9 k\u011b ch\u00f3ngf\u00f9x\u00ecng.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 241, "total_tokens": 685, "completion_tokens": 444}}
[08.11.2024 09:36] Response: Zh√® piƒÅn w√©nzhƒÅng t«éol√πn le d√†x√≠ng y«îy√°n m√≥x√≠ng (LLMs) z√†i d√†im«é shƒìngch√©ng, tuƒ´l«ê r√®nw√π h√© d√†il«ê x√¨t«íng zh≈çng de zh√≤ngy√†ox√¨ng. Suƒ´r√°n kƒÅif√†ng f«éngw√®n de d√†im«é LLMs x√¨ngn√©ng j√¨nk√® zhuƒÅny«íu m√≥x√≠ng, d√†n sh√¨h√© y√°nk√® kƒìxu√© y√°nji≈´ de gƒÅo zh√¨li√†ng d√†im«é LLMs r√©ngr√°n y«íuxi√†n. W√®ile ti√°nb«î zh√® yƒ´ k√≤ngb√°i, w√©nzhƒÅng ji√®sh√†o le OpenCoder, yƒ´g√® d«êngjiƒÅn de d√†im«é LLMs, q√≠ x√¨ngn√©ng kƒÅnb«ê l«êngxiƒÅn m√≥x√≠ng, √©rqiƒõ w√®i y√°nji≈´ sh√®q≈´ ti√°o g√≤ngle yƒ´g√® ‚ÄúkƒÅif√†ng de sh√≠p«î‚Äù. OpenCoder b√πj«ên fƒÅb√πle m√≥x√≠ng qu√°nzh√≤ng h√© tuƒ´l«ê d√†im«é, h√°i bƒÅoku√≤ kƒõ ch√≥ngf√π de x√πnli√†n sh√πj√π, w√°nzhƒõng de sh√πj√π ch«îl«ê li√∫shu«êxi√†n, y√°nj√¨n de sh√¨y√†n r√≥ngr√≥ng ji√©gu«í h√© xi√°ngx√¨ de x√πnli√†n xi√©y√¨, y«ê c√πj√¨n kƒìxu√© y√°nji≈´ de kƒÅif√†ng h√© kƒõ ch√≥ngf√πx√¨ng.
[08.11.2024 09:36] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

ËøôÁØáÊñáÁ´†ËÆ®ËÆ∫‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®‰ª£Á†ÅÁîüÊàê„ÄÅÊé®ÁêÜ‰ªªÂä°Âíå‰ª£ÁêÜÁ≥ªÁªü‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇËôΩÁÑ∂ÂºÄÊîæËÆøÈóÆÁöÑ‰ª£Á†ÅLLMsÊÄßËÉΩÊé•Ëøë‰∏ìÊúâÊ®°ÂûãÔºå‰ΩÜÈÄÇÂêà‰∏•Ë∞®ÁßëÂ≠¶Á†îÁ©∂ÁöÑÈ´òË¥®Èáè‰ª£Á†ÅLLMs‰ªçÁÑ∂ÊúâÈôê„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ëøô‰∏ÄÁ©∫ÁôΩÔºåÊñáÁ´†‰ªãÁªç‰∫ÜOpenCoderÔºå‰∏Ä‰∏™È°∂Â∞ñÁöÑ‰ª£Á†ÅLLMsÔºåÂÖ∂ÊÄßËÉΩÂ†™ÊØîÈ¢ÜÂÖàÊ®°ÂûãÔºåÂπ∂‰∏î‰∏∫Á†îÁ©∂Á§æÂå∫Êèê‰æõ‰∫Ü‰∏Ä‰∏™‚ÄúÂºÄÊîæÁöÑÈ£üË∞±‚Äù„ÄÇOpenCoder‰∏ç‰ªÖÂèëÂ∏É‰∫ÜÊ®°ÂûãÊùÉÈáçÂíåÊé®ÁêÜ‰ª£Á†ÅÔºåËøòÂåÖÊã¨ÂèØÈáçÂ§çÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÅÂÆåÊï¥ÁöÑÊï∞ÊçÆÂ§ÑÁêÜÊµÅÊ∞¥Á∫ø„ÄÅ‰∏•Ê†ºÁöÑÂÆûÈ™åÊ∂àËûçÁªìÊûúÂíåËØ¶ÁªÜÁöÑËÆ≠ÁªÉÂçèËÆÆÔºå‰ª•‰øÉËøõÁßëÂ≠¶Á†îÁ©∂ÁöÑÂºÄÊîæÂíåÂèØÈáçÂ§çÊÄß„ÄÇ
[08.11.2024 09:37] Mistral response. {"id": "8d3394ac387646a88e1d69fcdf5955cb", "object": "chat.completion", "created": 1731058589, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\n    {\"word\": \"\u8ba8\u8bba\", \"pinyin\": \"t\u01ceo l\u00f9n\", \"trans\": \"discuss\"},\n    {\"word\": \"\u5927\u578b\", \"pinyin\": \"d\u00e0 x\u00edng\", \"trans\": \"large-scale\"},\n    {\"word\": \"\u8bed\u8a00\u6a21\u578b\", \"pinyin\": \"y\u01d4 y\u00e1n m\u00f3 x\u00edng\", \"trans\": \"language model\"},\n    {\"word\": \"\u4ee3\u7801\u751f\u6210\", \"pinyin\": \"d\u00e0i m\u01ce sh\u0113ng ch\u00e9ng\", \"trans\": \"code generation\"},\n    {\"word\": \"\u63a8\u7406\u4efb\u52a1\", \"pinyin\": \"tu\u012b l\u01d0 r\u00e8n w\u00f9\", \"trans\": \"reasoning tasks\"},\n    {\"word\": \"\u4ee3\u7406\u7cfb\u7edf\", \"pinyin\": \"d\u00e0i l\u01d0 x\u00ec t\u01d2ng\", \"trans\": \"proxy system\"},\n    {\"word\": \"\u91cd\u8981\u6027\", \"pinyin\": \"zh\u00f2ng y\u00e0o x\u00ecng\", \"trans\": \"importance\"},\n    {\"word\": \"\u5f00\u653e\u8bbf\u95ee\", \"pinyin\": \"k\u0101i f\u00e0ng f\u01ceng w\u00e8n\", \"trans\": \"open access\"},\n    {\"word\": \"\u4e13\u6709\u6a21\u578b\", \"pinyin\": \"zhu\u0101n y\u01d2u m\u00f3 x\u00edng\", \"trans\": \"proprietary model\"},\n    {\"word\": \"\u4e25\u8c28\", \"pinyin\": \"y\u00e1n j\u01d0n\", \"trans\": \"rigorous\"},\n    {\"word\": \"\u79d1\u5b66\u7814\u7a76\", \"pinyin\": \"k\u0113 xu\u00e9 y\u00e1n ji\u016b\", \"trans\": \"scientific research\"},\n    {\"word\": \"\u9ad8\u8d28\u91cf\", \"pinyin\": \"g\u0101o zh\u00ec li\u00e0ng\", \"trans\": \"high quality\"},\n    {\"word\": \"\u6709\u9650\", \"pinyin\": \"y\u01d2u xi\u00e0n\", \"trans\": \"limited\"},\n    {\"word\": \"\u586b\u8865\", \"pinyin\": \"ti\u00e1n b\u01d4\", \"trans\": \"fill\"},\n    {\"word\": \"\u7a7a\u767d\", \"pinyin\": \"k\u00f2ng b\u00e1i\", \"trans\": \"gap\"},\n    {\"word\": \"\u4ecb\u7ecd\", \"pinyin\": \"ji\u00e8 sh\u00e0o\", \"trans\": \"introduce\"},\n    {\"word\": \"\u9876\u5c16\", \"pinyin\": \"d\u01d0ng ji\u0101n\", \"trans\": \"top-notch\"},\n    {\"word\": \"\u582a\u6bd4\", \"pinyin\": \"k\u0101n b\u01d0\", \"trans\": \"comparable\"},\n    {\"word\": \"\u9886\u5148\u6a21\u578b\", \"pinyin\": \"l\u01d0ng xi\u0101n m\u00f3 x\u00edng\", \"trans\": \"leading model\"},\n    {\"word\": \"\u98df\u8c31\", \"pinyin\": \"sh\u00ed p\u01d4\", \"trans\": \"recipe\"},\n    {\"word\": \"\u6a21\u578b\u6743\u91cd\", \"pinyin\": \"m\u00f3 x\u00edng qu\u00e1n zh\u00f2ng\", \"trans\": \"model weights\"},\n    {\"word\": \"\u63a8\u7406\u4ee3\u7801\", \"pinyin\": \"tu\u012b l\u01d0 d\u00e0i m\u01ce\", \"trans\": \"inference code\"},\n    {\"word\": \"\u53ef\u91cd\u590d\", \"pinyin\": \"k\u011b ch\u00f3ng f\u00f9\", \"trans\": \"reproducible\"},\n    {\"word\": \"\u8bad\u7ec3\u6570\u636e\", \"pinyin\": \"x\u00f9n li\u00e0n sh\u00f9 j\u00f9\", \"trans\": \"training data\"},\n    {\"word\": \"\u5b8c\u6574\", \"pinyin\": \"w\u00e1n zh\u011bng\", \"trans\": \"complete\"},\n    {\"word\": \"\u6570\u636e\u5904\u7406\u6d41\u6c34\u7ebf\", \"pinyin\": \"sh\u00f9 j\u00f9 ch\u01d4 l\u01d0 li\u00fa shu\u01d0 xi\u00e0n\", \"trans\": \"data processing pipeline\"},\n    {\"word\": \"\u4e25\u683c\", \"pinyin\": \"y\u00e1n g\u00e9\", \"trans\": \"strict\"},\n    {\"word\": \"\u5b9e\u9a8c\u6d88\u878d\u7ed3\u679c\", \"pinyin\": \"sh\u00ed y\u00e0n xi\u0101o r\u00f3ng ji\u00e9 gu\u01d2\", \"trans\": \"experimental ablation results\"},\n    {\"word\": \"\u8be6\u7ec6\", \"pinyin\": \"xi\u00e1ng x\u00ec\", \"trans\": \"detailed\"},\n    {\"word\": \"\u8bad\u7ec3\u534f\u8bae\", \"pinyin\": \"x\u00f9n li\u00e0n xi\u00e9 y\u00ec\", \"trans\": \"training protocol\"},\n    {\"word\": \"\u4fc3\u8fdb\", \"pinyin\": \"c\u00f9 j\u00ecn\", \"trans\": \"promote\"},\n    {\"word\": \"\u5f00\u653e\", \"pinyin\": \"k\u0101i f\u00e0ng\", \"trans\": \"open\"},\n    {\"word\": \"\u53ef\u91cd\u590d\u6027\", \"pinyin\": \"k\u011b ch\u00f3ng f\u00f9 x\u00ecng\", \"trans\": \"reproducibility\"}\n]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 273, "total_tokens": 1366, "completion_tokens": 1093}}
[08.11.2024 09:37] Response: [
    {"word": "ËÆ®ËÆ∫", "pinyin": "t«éo l√πn", "trans": "discuss"},
    {"word": "Â§ßÂûã", "pinyin": "d√† x√≠ng", "trans": "large-scale"},
    {"word": "ËØ≠Ë®ÄÊ®°Âûã", "pinyin": "y«î y√°n m√≥ x√≠ng", "trans": "language model"},
    {"word": "‰ª£Á†ÅÁîüÊàê", "pinyin": "d√†i m«é shƒìng ch√©ng", "trans": "code generation"},
    {"word": "Êé®ÁêÜ‰ªªÂä°", "pinyin": "tuƒ´ l«ê r√®n w√π", "trans": "reasoning tasks"},
    {"word": "‰ª£ÁêÜÁ≥ªÁªü", "pinyin": "d√†i l«ê x√¨ t«íng", "trans": "proxy system"},
    {"word": "ÈáçË¶ÅÊÄß", "pinyin": "zh√≤ng y√†o x√¨ng", "trans": "importance"},
    {"word": "ÂºÄÊîæËÆøÈóÆ", "pinyin": "kƒÅi f√†ng f«éng w√®n", "trans": "open access"},
    {"word": "‰∏ìÊúâÊ®°Âûã", "pinyin": "zhuƒÅn y«íu m√≥ x√≠ng", "trans": "proprietary model"},
    {"word": "‰∏•Ë∞®", "pinyin": "y√°n j«ên", "trans": "rigorous"},
    {"word": "ÁßëÂ≠¶Á†îÁ©∂", "pinyin": "kƒì xu√© y√°n ji≈´", "trans": "scientific research"},
    {"word": "È´òË¥®Èáè", "pinyin": "gƒÅo zh√¨ li√†ng", "trans": "high quality"},
    {"word": "ÊúâÈôê", "pinyin": "y«íu xi√†n", "trans": "limited"},
    {"word": "Â°´Ë°•", "pinyin": "ti√°n b«î", "trans": "fill"},
    {"word": "Á©∫ÁôΩ", "pinyin": "k√≤ng b√°i", "trans": "gap"},
    {"word": "‰ªãÁªç", "pinyin": "ji√® sh√†o", "trans": "introduce"},
    {"word": "È°∂Â∞ñ", "pinyin": "d«êng jiƒÅn", "trans": "top-notch"},
    {"word": "Â†™ÊØî", "pinyin": "kƒÅn b«ê", "trans": "comparable"},
    {"word": "È¢ÜÂÖàÊ®°Âûã", "pinyin": "l«êng xiƒÅn m√≥ x√≠ng", "trans": "leading model"},
    {"word": "È£üË∞±", "pinyin": "sh√≠ p«î", "trans": "recipe"},
    {"word": "Ê®°ÂûãÊùÉÈáç", "pinyin": "m√≥ x√≠ng qu√°n zh√≤ng", "trans": "model weights"},
    {"word": "Êé®ÁêÜ‰ª£Á†Å", "pinyin": "tuƒ´ l«ê d√†i m«é", "trans": "inference code"},
    {"word": "ÂèØÈáçÂ§ç", "pinyin": "kƒõ ch√≥ng f√π", "trans": "reproducible"},
    {"word": "ËÆ≠ÁªÉÊï∞ÊçÆ", "pinyin": "x√πn li√†n sh√π j√π", "trans": "training data"},
    {"word": "ÂÆåÊï¥", "pinyin": "w√°n zhƒõng", "trans": "complete"},
    {"word": "Êï∞ÊçÆÂ§ÑÁêÜÊµÅÊ∞¥Á∫ø", "pinyin": "sh√π j√π ch«î l«ê li√∫ shu«ê xi√†n", "trans": "data processing pipeline"},
    {"word": "‰∏•Ê†º", "pinyin": "y√°n g√©", "trans": "strict"},
    {"word": "ÂÆûÈ™åÊ∂àËûçÁªìÊûú", "pinyin": "sh√≠ y√†n xiƒÅo r√≥ng ji√© gu«í", "trans": "experimental ablation results"},
    {"word": "ËØ¶ÁªÜ", "pinyin": "xi√°ng x√¨", "trans": "detailed"},
    {"word": "ËÆ≠ÁªÉÂçèËÆÆ", "pinyin": "x√πn li√†n xi√© y√¨", "trans": "training protocol"},
    {"word": "‰øÉËøõ", "pinyin": "c√π j√¨n", "trans": "promote"},
    {"word": "ÂºÄÊîæ", "pinyin": "kƒÅi f√†ng", "trans": "open"},
    {"word": "ÂèØÈáçÂ§çÊÄß", "pinyin": "kƒõ ch√≥ng f√π x√¨ng", "trans": "reproducibility"}
]
[08.11.2024 09:37] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

ËøôÁØáÊñáÁ´†ËÆ®ËÆ∫‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®‰ª£Á†ÅÁîüÊàê„ÄÅÊé®ÁêÜ‰ªªÂä°Âíå‰ª£ÁêÜÁ≥ªÁªü‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇËôΩÁÑ∂ÂºÄÊîæËÆøÈóÆÁöÑ‰ª£Á†ÅLLMsÊÄßËÉΩÊé•Ëøë‰∏ìÊúâÊ®°ÂûãÔºå‰ΩÜÈÄÇÂêà‰∏•Ë∞®ÁßëÂ≠¶Á†îÁ©∂ÁöÑÈ´òË¥®Èáè‰ª£Á†ÅLLMs‰ªçÁÑ∂ÊúâÈôê„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ëøô‰∏ÄÁ©∫ÁôΩÔºåÊñáÁ´†‰ªãÁªç‰∫ÜOpenCoderÔºå‰∏Ä‰∏™È°∂Â∞ñÁöÑ‰ª£Á†ÅLLMsÔºåÂÖ∂ÊÄßËÉΩÂ†™ÊØîÈ¢ÜÂÖàÊ®°ÂûãÔºåÂπ∂‰∏î‰∏∫Á†îÁ©∂Á§æÂå∫Êèê‰æõ‰∫Ü‰∏Ä‰∏™‚ÄúÂºÄÊîæÁöÑÈ£üË∞±‚Äù„ÄÇOpenCoder‰∏ç‰ªÖÂèëÂ∏É‰∫ÜÊ®°ÂûãÊùÉÈáçÂíåÊé®ÁêÜ‰ª£Á†ÅÔºåËøòÂåÖÊã¨ÂèØÈáçÂ§çÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÅÂÆåÊï¥ÁöÑÊï∞ÊçÆÂ§ÑÁêÜÊµÅÊ∞¥Á∫ø„ÄÅ‰∏•Ê†ºÁöÑÂÆûÈ™åÊ∂àËûçÁªìÊûúÂíåËØ¶ÁªÜÁöÑËÆ≠ÁªÉÂçèËÆÆÔºå‰ª•‰øÉËøõÁßëÂ≠¶Á†îÁ©∂ÁöÑÂºÄÊîæÂíåÂèØÈáçÂ§çÊÄß„ÄÇ
[08.11.2024 09:37] Mistral response. {"id": "9c0aae1b6c9f478982a583db249a5ca9", "object": "chat.completion", "created": 1731058649, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "This article discusses the importance of large language models (LLMs) in code generation, reasoning tasks, and agent systems. Although open-access code LLMs perform nearly as well as proprietary models, high-quality code LLMs suitable for rigorous scientific research remain limited. To fill this gap, the article introduces OpenCoder, a top-tier code LLM with performance comparable to leading models, and provides an \"open recipe\" for the research community. OpenCoder not only releases model weights and inference code but also includes reproducible training data, a complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols to promote openness and reproducibility in scientific research.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 239, "total_tokens": 388, "completion_tokens": 149}}
[08.11.2024 09:37] Response: This article discusses the importance of large language models (LLMs) in code generation, reasoning tasks, and agent systems. Although open-access code LLMs perform nearly as well as proprietary models, high-quality code LLMs suitable for rigorous scientific research remain limited. To fill this gap, the article introduces OpenCoder, a top-tier code LLM with performance comparable to leading models, and provides an "open recipe" for the research community. OpenCoder not only releases model weights and inference code but also includes reproducible training data, a complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols to promote openness and reproducibility in scientific research.
[08.11.2024 09:37] Renaming data file.
[08.11.2024 09:37] Renaming previous data. hf_papers.json to ./d/2024-11-08.json
[08.11.2024 09:37] Saving new data file.
[08.11.2024 09:37] Generating page.
[08.11.2024 09:37] Renaming previous page.
[08.11.2024 09:37] Renaming previous data. index.html to ./d/2024-11-08.html
[08.11.2024 09:37] [Experimental] Generating Chinese page for reading.
[08.11.2024 09:37] Chinese vocab [{'word': 'ËÆ®ËÆ∫', 'pinyin': 't«éo l√πn', 'trans': 'discuss'}, {'word': 'Â§ßÂûã', 'pinyin': 'd√† x√≠ng', 'trans': 'large-scale'}, {'word': 'ËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'y«î y√°n m√≥ x√≠ng', 'trans': 'language model'}, {'word': '‰ª£Á†ÅÁîüÊàê', 'pinyin': 'd√†i m«é shƒìng ch√©ng', 'trans': 'code generation'}, {'word': 'Êé®ÁêÜ‰ªªÂä°', 'pinyin': 'tuƒ´ l«ê r√®n w√π', 'trans': 'reasoning tasks'}, {'word': '‰ª£ÁêÜÁ≥ªÁªü', 'pinyin': 'd√†i l«ê x√¨ t«íng', 'trans': 'proxy system'}, {'word': 'ÈáçË¶ÅÊÄß', 'pinyin': 'zh√≤ng y√†o x√¨ng', 'trans': 'importance'}, {'word': 'ÂºÄÊîæËÆøÈóÆ', 'pinyin': 'kƒÅi f√†ng f«éng w√®n', 'trans': 'open access'}, {'word': '‰∏ìÊúâÊ®°Âûã', 'pinyin': 'zhuƒÅn y«íu m√≥ x√≠ng', 'trans': 'proprietary model'}, {'word': '‰∏•Ë∞®', 'pinyin': 'y√°n j«ên', 'trans': 'rigorous'}, {'word': 'ÁßëÂ≠¶Á†îÁ©∂', 'pinyin': 'kƒì xu√© y√°n ji≈´', 'trans': 'scientific research'}, {'word': 'È´òË¥®Èáè', 'pinyin': 'gƒÅo zh√¨ li√†ng', 'trans': 'high quality'}, {'word': 'ÊúâÈôê', 'pinyin': 'y«íu xi√†n', 'trans': 'limited'}, {'word': 'Â°´Ë°•', 'pinyin': 'ti√°n b«î', 'trans': 'fill'}, {'word': 'Á©∫ÁôΩ', 'pinyin': 'k√≤ng b√°i', 'trans': 'gap'}, {'word': '‰ªãÁªç', 'pinyin': 'ji√® sh√†o', 'trans': 'introduce'}, {'word': 'È°∂Â∞ñ', 'pinyin': 'd«êng jiƒÅn', 'trans': 'top-notch'}, {'word': 'Â†™ÊØî', 'pinyin': 'kƒÅn b«ê', 'trans': 'comparable'}, {'word': 'È¢ÜÂÖàÊ®°Âûã', 'pinyin': 'l«êng xiƒÅn m√≥ x√≠ng', 'trans': 'leading model'}, {'word': 'È£üË∞±', 'pinyin': 'sh√≠ p«î', 'trans': 'recipe'}, {'word': 'Ê®°ÂûãÊùÉÈáç', 'pinyin': 'm√≥ x√≠ng qu√°n zh√≤ng', 'trans': 'model weights'}, {'word': 'Êé®ÁêÜ‰ª£Á†Å', 'pinyin': 'tuƒ´ l«ê d√†i m«é', 'trans': 'inference code'}, {'word': 'ÂèØÈáçÂ§ç', 'pinyin': 'kƒõ ch√≥ng f√π', 'trans': 'reproducible'}, {'word': 'ËÆ≠ÁªÉÊï∞ÊçÆ', 'pinyin': 'x√πn li√†n sh√π j√π', 'trans': 'training data'}, {'word': 'ÂÆåÊï¥', 'pinyin': 'w√°n zhƒõng', 'trans': 'complete'}, {'word': 'Êï∞ÊçÆÂ§ÑÁêÜÊµÅÊ∞¥Á∫ø', 'pinyin': 'sh√π j√π ch«î l«ê li√∫ shu«ê xi√†n', 'trans': 'data processing pipeline'}, {'word': '‰∏•Ê†º', 'pinyin': 'y√°n g√©', 'trans': 'strict'}, {'word': 'ÂÆûÈ™åÊ∂àËûçÁªìÊûú', 'pinyin': 'sh√≠ y√†n xiƒÅo r√≥ng ji√© gu«í', 'trans': 'experimental ablation results'}, {'word': 'ËØ¶ÁªÜ', 'pinyin': 'xi√°ng x√¨', 'trans': 'detailed'}, {'word': 'ËÆ≠ÁªÉÂçèËÆÆ', 'pinyin': 'x√πn li√†n xi√© y√¨', 'trans': 'training protocol'}, {'word': '‰øÉËøõ', 'pinyin': 'c√π j√¨n', 'trans': 'promote'}, {'word': 'ÂºÄÊîæ', 'pinyin': 'kƒÅi f√†ng', 'trans': 'open'}, {'word': 'ÂèØÈáçÂ§çÊÄß', 'pinyin': 'kƒõ ch√≥ng f√π x√¨ng', 'trans': 'reproducibility'}]
[08.11.2024 09:37] Renaming previous Chinese page.
[08.11.2024 09:37] Renaming previous data. zh.html to ./d/2024-11-07_zh_reading_task.html
[08.11.2024 09:37] Writing Chinese reading task.
[08.11.2024 09:37] Writing result.
[08.11.2024 09:37] Renaming log file.
[08.11.2024 09:37] Renaming previous data. log.txt to ./logs/2024-11-08_last_log.txt
