[16.10.2025 23:11] Read previous papers.
[16.10.2025 23:11] Generating top page (month).
[16.10.2025 23:11] Writing top page (month).
[17.10.2025 00:52] Read previous papers.
[17.10.2025 00:52] Get feed.
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13344
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13678
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13554
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13626
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13795
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13809
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13747
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04767
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13802
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07944
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13804
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11062
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13800
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13778
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13621
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13515
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11438
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13786
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13759
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13282
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10274
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10977
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10921
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11958
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13744
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13602
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12560
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10611
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12866
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12831
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10581
[17.10.2025 00:52] Extract page data from URL. URL: https://huggingface.co/papers/2510.13940
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13714
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13586
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13255
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11715
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11653
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11170
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09913
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10930
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10494
[17.10.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07414
[17.10.2025 00:52] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.10.2025 00:52] No deleted papers detected.
[17.10.2025 00:52] Downloading and parsing papers (pdf, html). Total: 42.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13344.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13344.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13344.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13678.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13678.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13678.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13554.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13554.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13554.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13626.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13626.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13626.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13795.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13795.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13795.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13809.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13809.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13809.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13747.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13747.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13747.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.04767.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.04767.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.04767.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13802.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13802.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13802.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.07944.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.07944.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.07944.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13804.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13804.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13804.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11062.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11062.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11062.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13800.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13800.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13800.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13778.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13778.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13778.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13621.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13621.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13621.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13515.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13515.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13515.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11438.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11438.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11438.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13786.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13786.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13786.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13759.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13759.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13759.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13282.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13282.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13282.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.10274.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.10274.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.10274.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.10977.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.10977.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.10977.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.10921.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.10921.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.10921.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11958.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11958.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11958.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13744.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13744.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13744.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13602.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13602.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13602.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12560.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12560.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12560.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.10611.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.10611.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.10611.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12866.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12866.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12866.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.12831.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.12831.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.12831.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.10581.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.10581.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.10581.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13940.
[17.10.2025 00:52] Downloading paper 2510.13940 from http://arxiv.org/pdf/2510.13940v1...
[17.10.2025 00:52] Extracting affiliations from text.
[17.10.2025 00:52] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention Zhen Yang*1, Mingyang Zhang5, Feng Chen3, Ganggui Ding4, Liang Hou2, Xin Tao2, Pengfei Wan2, Ying-Cong Chen1,6 1HKUST(GZ), 2Kuaishou Technology, 3AIML, 4ZJU, 5Ant Group, 6HKUST zheny.cs@gmail.com, yingcongchen@ust.hk 5 2 0 2 5 1 ] . [ 1 0 4 9 3 1 . 0 1 5 2 : r a "
[17.10.2025 00:52] Response: ```python
["HKUST(GZ)", "Kuaishou Technology", "AIML", "ZJU", "Ant Group", "HKUST"]
```
[17.10.2025 00:52] Deleting PDF ./assets/pdf/2510.13940.pdf.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13714.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13714.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13714.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13586.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13586.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13586.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.13255.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.13255.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.13255.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11715.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11715.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11715.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11653.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11653.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11653.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.11170.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.11170.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.11170.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.09913.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.09913.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.09913.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.10930.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.10930.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.10930.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.10494.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.10494.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.10494.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2510.07414.
[17.10.2025 00:52] Extra JSON file exists (./assets/json/2510.07414.json), skip PDF parsing.
[17.10.2025 00:52] Paper image links file exists (./assets/img_data/2510.07414.json), skip HTML parsing.
[17.10.2025 00:52] Success.
[17.10.2025 00:52] Enriching papers with extra data.
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 0. UniMoE-Audio, a unified speech and music generation model using a Dynamic-Capacity Mixture-of-Experts framework, addresses data imbalance and task conflicts, achieving state-of-the-art performance and enhanced cross-domain synergy.  					AI-generated summary 				 Recent advances in unified multimoda...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 1. FlashWorld generates 3D scenes from single images or text prompts quickly and with high quality by combining MV-oriented and 3D-oriented generation methods.  					AI-generated summary 				 We propose FlashWorld, a generative model that produces 3D scenes from a single image or text prompt in seconds...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 2. Attention mechanisms in LLMs are analyzed to reveal reasoning patterns, leading to novel RL strategies that improve performance by focusing on critical tokens.  					AI-generated summary 				 The reasoning pattern of Large language models (LLMs) remains opaque, and Reinforcement learning (RL) typica...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 3. State-of-the-art Visual-Language-Action models show high benchmark scores but are brittle to various perturbations, particularly in camera viewpoints and robot initial states, and often ignore language instructions.  					AI-generated summary 				 Visual-Language-Action (VLA) models report impressiv...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 4. A new dataset and pipeline for data curation improve the performance of fully open multimodal large language models, achieving state-of-the-art results competitive with semi-open models.  					AI-generated summary 				 Fully open multimodal large language models (MLLMs) currently lag behind propriet...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 5. PhysMaster enhances video generation by integrating physical knowledge through PhysEncoder, using reinforcement learning and Direct Preference Optimization to improve physics-awareness.  					AI-generated summary 				 Video generation models nowadays are capable of generating visually realistic vide...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 6. InteractiveOmni is a unified omni-modal large language model for audio-visual multi-turn interactions, offering comprehensive understanding and speech generation capabilities with efficient parameter usage.  					AI-generated summary 				 We introduce InteractiveOmni, a unified and open-source omni-...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 7. Parallel decoding in diffusion LLMs degrades generation quality due to ignored token dependencies, highlighting the need for new decoding methods and benchmarks.  					AI-generated summary 				 While most autoregressive LLMs are constrained to one-by-one decoding, diffusion LLMs (dLLMs) have attract...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 8. Trace Anything, a neural network, predicts video trajectories in a single pass, achieving state-of-the-art performance and demonstrating efficiency and emergent abilities like motion forecasting.  					AI-generated summary 				 Effective spatio-temporal representation is fundamental to modeling, und...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 9. CVD-STORM, a cross-view video diffusion model with a spatial-temporal reconstruction VAE, enhances video generation quality and provides depth estimation for dynamic scenes.  					AI-generated summary 				 Generative models have been widely applied to world modeling for environment simulation and fu...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 10. Generative Universal Verifier enhances multimodal reasoning by providing reliable visual verification through ViVerBench, OmniVerifier-7B, and OmniVerifier-TTS, improving generation and refinement capabilities.  					AI-generated summary 				 We introduce Generative Universal Verifier, a novel conce...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 11. AT-GRPO, a tailored RL algorithm for multi-agent systems, significantly enhances performance across various tasks by addressing unique challenges in on-policy RL.  					AI-generated summary 				 Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to enhance the agentic capabili...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 12. GS-Reasoner, a 3D LLM with a dual-path pooling mechanism, achieves autoregressive grounding and state-of-the-art spatial reasoning without external modules.  					AI-generated summary 				 In this paper, we claim that 3D visual grounding is the cornerstone of spatial reasoning and introduce the Grou...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 13. A unified framework for spatial grounding and robot control, InternVLA-M1, enhances instruction-following robots through spatially guided vision-language-action training, achieving significant improvements across various tasks and simulations.  					AI-generated summary 				 We introduce InternVLA-M...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 14. Increased computing resources are correlated with national funding and citations in foundation model research, but not with research environment, domain, or methodology.  					AI-generated summary 				 Cutting-edge research in Artificial Intelligence (AI) requires considerable resources, including G...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 15. A novel Universal Multimodal Embedding (UniME-V2) model uses MLLMs to enhance representation learning by identifying diverse, high-quality hard negatives and improving discriminative capacity through soft semantic matching scores.  					AI-generated summary 				 Universal multimodal embedding models...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 16. AutoGEO, a framework for optimizing generative engines, learns and applies preference rules to enhance content traction and search utility using large language models.  					AI-generated summary 				 By employing large language models (LLMs) to retrieve documents and generate natural language respon...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 17. A systematic study defines a framework for analyzing and predicting reinforcement learning scaling in large language models, identifying key design choices that affect compute efficiency and proposing a best-practice recipe.  					AI-generated summary 				 Reinforcement learning (RL) has become cent...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 18. Uni-MMMU is a benchmark that evaluates the bidirectional synergy between visual understanding and generation across multiple domains, providing insights into their integration and performance.  					AI-generated summary 				 Unified multimodal models aim to jointly enable visual understanding and ge...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 19. A Masked Degradation Classification Pre-Training method enhances image restoration by using degradation type classification and image reconstruction, improving performance across CNNs and Transformers.  					AI-generated summary 				 This study introduces a Masked Degradation Classification Pre-Trai...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 20. A novel Soft Prompt approach enhances Vision-Language-Action models by using learnable embeddings for diverse robotic data, enabling superior performance across simulations and real-world robots.  					AI-generated summary 				 Successful generalist Vision-Language-Action (VLA) models rely on effect...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 21. Model merging, typically on Instruct and Thinking models, has shown remarkable performance for efficient reasoning. In this paper, we systematically revisit the simplest merging method that interpolates two weights directly. Particularly, we observe that model interpolation follows a three-stage evo...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 22. FG-CLIP 2, a bilingual vision-language model, enhances fine-grained alignment for English and Chinese through rich supervision and a new TIC loss, achieving state-of-the-art performance across multiple datasets and tasks.  					AI-generated summary 				 Fine-grained vision-language understanding req...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 23. Direct Multi-Token Decoding (DMTD) accelerates large language model inference by using only late layers for token generation, achieving significant speedup with minimal performance loss.  					AI-generated summary 				 Decoder-only transformers have become the standard architecture for large languag...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 24. Hard2Verify, a human-annotated benchmark, evaluates step-level verifiers for LLM-based mathematical reasoning systems, highlighting the challenges and performance gaps between open-source and closed-source models.  					AI-generated summary 				 Large language model (LLM)-based reasoning systems hav...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 25. NOSA, a trainable sparse attention framework, enhances decoding throughput by enabling efficient KV cache offloading without compromising performance.  					AI-generated summary 				 Trainable sparse attention has emerged as a promising solution to address the decoding efficiency bottleneck of LLMs ...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 26. End-to-end autonomous driving models trained solely with imitation learning (IL) often suffer from poor generalization. In contrast, reinforcement learning (RL) promotes exploration through reward maximization but faces challenges such as sample inefficiency and unstable convergence. A natural solut...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 27. HyperAgent, a hypergraph-based framework, optimizes communication topologies and captures group collaboration patterns, improving performance and efficiency in multi-agent systems.  					AI-generated summary 				 Recent advances in large language model-powered multi-agent systems have demonstrated r...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 28. Robots can achieve generalizable grasping skills by learning from a small set of simple objects, using an object-centric visual representation, which outperforms state-of-the-art methods with less data.  					AI-generated summary 				 Robotic manipulation policies often struggle to generalize to nov...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 29. MTSQL-R1, an agentic training framework, improves multi-turn Text-to-SQL by treating it as an MDP with iterative propose-execute-verify-refine cycles, enhancing coherence and execution.  					AI-generated summary 				 Multi-turn Text-to-SQL aims to translate a user's conversational utterances into e...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 30. GraphTracer addresses multi-agent system failure attribution by constructing Information Dependency Graphs to trace information flow and improve debugging accuracy.  					AI-generated summary 				 Multi-agent systems powered by Large Language Models excel at complex tasks through coordinated collabo...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 31. Minimal Test-Time Intervention (MTI) enhances reasoning accuracy and stability in large language models with minimal overhead by selectively applying classifier-free guidance and lightweight negative-prompt guidance.  					AI-generated summary 				 Recent progress in large language models (LLMs) has...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 32. Dedelayed, a delay-corrective method, improves real-time semantic segmentation accuracy by fusing local and remote model outputs, mitigating communication network latency.  					AI-generated summary 				 Remote inference allows lightweight devices to leverage powerful cloud models. However, communic...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 33. Participants in the CPDC 2025 used lightweight prompting and fine-tuned large models to achieve high rankings in task-oriented and context-aware dialogue challenges.  					AI-generated summary 				 The emergence of large language models (LLMs) has opened new opportunities for cre- ating dynamic non-...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 34. Hierarchical Frequency Tagging Probe (HFTP) identifies neuron-wise components in LLMs and cortical regions encoding syntactic structures, revealing differences in how LLMs and the human brain process syntax.  					AI-generated summary 				 Large Language Models (LLMs) demonstrate human-level or even...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 35. Pretrained video diffusion models can perform zero-shot point tracking by visually marking points and regenerating video frames, outperforming prior methods and handling occlusions.  					AI-generated summary 				 Trackers and video generators solve closely related problems: the former analyze motio...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 36. MATH-Beyond is a benchmark designed to challenge existing reinforcement learning methods by requiring deeper reasoning capabilities beyond current model capabilities.  					AI-generated summary 				 With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL) methods has emerged that se...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 37. EAGer, a training-free method, uses token-wise entropy to optimize computational resources and improve performance on complex reasoning tasks.  					AI-generated summary 				 With the rise of reasoning language models and test-time scaling methods as a paradigm for improving model performance, subst...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 38. Model collaboration and Switch Generation improve language model performance by leveraging the strengths of different models in a dynamic and complementary manner.  					AI-generated summary 				 Alignment training has tradeoffs: it helps language models (LMs) gain in reasoning and instruction follo...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 39. Modern reasoning models are more aligned with human evaluations of games than non-reasoning models, but their performance can degrade as they approach game-theoretic optimality, especially for subjective assessments like funness.  					AI-generated summary 				 Reasoning is not just about solving pr...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 40. Latent-Trajectory signals improve inference-time efficiency by predicting productive reasoning paths, reducing token usage and enhancing accuracy.  					AI-generated summary 				 Reasoning models improve their problem-solving ability through inference-time scaling, allocating more compute via longer...
[17.10.2025 00:52] ********************************************************************************
[17.10.2025 00:52] Abstract 41. HaystackCraft, a new benchmark using Wikipedia, evaluates long-context LLM robustness by simulating noisy retrieval and agentic workflows, revealing challenges in handling distractors and cascading errors.  					AI-generated summary 				 Modern long-context large language models (LLMs) perform well ...
[17.10.2025 00:52] Read previous papers.
[17.10.2025 00:52] Generating reviews via LLM API.
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#games", "#benchmark", "#optimization", "#multimodal", "#audio", "#training"], "emoji": "🎵", "ru": {"title": "Единая модель для речи и музыки через динамическую Mixture-of-Experts", "desc": "UniMoE-Audio — это унифицированная модель для генерации речи и музыки, осно
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#3d", "#optimization", "#diffusion"], "emoji": "⚡", "ru": {"title": "Мгновенная генерация 3D-миров: скорость и качество вместе", "desc": "FlashWorld — это генеративная модель, которая создаёт 3D-сцены из одного изображения или текстового промпта за считанные секунды, работая в 10-10
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#interpretability", "#training"], "emoji": "🔍", "ru": {"title": "Внимание как карта рассуждений: направленное обучение через ключевые токены", "desc": "Исследователи анализируют механизмы attention в LLM, чтобы понять, как модели рассуждают, выя
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#video", "#interpretability", "#security"], "emoji": "🤖", "ru": {"title": "Хрупкость VLA моделей: высокие бенчмарки скрывают критические уязвимости", "desc": "Исследователи провели систематический анализ уязвимостей современных Visual-Language-Action (VLA) м
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#data", "#transfer_learning", "#dataset", "#optimization", "#open_source"], "emoji": "🐝", "ru": {"title": "Качественные данные — ключ к открытым мультимодальным моделям", "desc": "Исследователи создали новый датасет Honey-Data-15M из 15 миллионов пар вопрос-ответ для обучения мульти
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#rlhf", "#games", "#rl", "#video", "#multimodal", "#optimization"], "emoji": "🎯", "ru": {"title": "Обучение видео-моделей физическим законам через предпочтения", "desc": "PhysMaster улучшает генерацию видео, добавляя понимание физических законов через специальный PhysEncoder. Систем
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#video", "#small_models", "#long_context", "#dataset", "#benchmark", "#multimodal", "#audio", "#open_source", "#training"], "emoji": "🎭", "ru": {"title": "Легковесная омнимодальная модель с долговременной памятью для естественного аудиовизуального взаимодействия", "desc": "Interacti
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#inference", "#diffusion", "#benchmark", "#optimization"], "emoji": "⚡", "ru": {"title": "Проблема скорости против качества в параллельном декодировании диффузионных LLM", "desc": "Статья исследует проблемы параллельного декодирования в диффузионных языковых моделях (dLLM), которые 
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#training", "#games", "#video", "#dataset", "#optimization", "#benchmark"], "emoji": "🎯", "ru": {"title": "Отследить всё: предсказание траекторий всех пикселей видео за один проход", "desc": "Статья представляет Trace Anything — нейросеть, которая предсказывает траектории движения в
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#3d", "#optimization", "#video", "#multimodal", "#diffusion"], "emoji": "🚗", "ru": {"title": "4D-реконструкция динамических сцен через видео диффузию", "desc": "Статья представляет CVD-STORM — модель для генерации видео с нескольких ракурсов, которая также оценивает
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#multimodal", "#optimization", "#benchmark"], "emoji": "🔍", "ru": {"title": "Универсальный верификатор для надежной проверки визуальных результатов в мультимодальных моделях", "desc": "Статья представляет Generative Universal Verifier — новую концепцию для 
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#agents", "#rl", "#optimization", "#reasoning", "#games", "#training"], "emoji": "🤝", "ru": {"title": "Обучение с подкреплением для команды AI-агентов", "desc": "Статья представляет AT-GRPO — алгоритм обучения с подкреплением, специально разработанный для мультиагентных систем на ба
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#games", "#3d", "#dataset", "#cv", "#reasoning"], "emoji": "🎯", "ru": {"title": "3D-reasoning через единое представление: grounding без внешних модулей", "desc": "В статье представлен GS-Reasoner — 3D LLM с механизмом двухпутевого pooling, который объединяет семантическую и геометри
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#science", "#agents", "#agi", "#optimization", "#robotics"], "emoji": "🤖", "ru": {"title": "Роботы учатся действовать через понимание пространства", "desc": "InternVLA-M1 — это единая система для управления роботами, которая связывает инструкции с действиями через пространственное п
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#open_source", "#ethics"], "emoji": "💰", "ru": {"title": "Деньги решают: как вычислительные ресурсы влияют на исследования foundation models", "desc": "Исследование анализирует связь между вычислительными ресурсами и научным прогрессом в области foundation models (больших базовых мо
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#training", "#multimodal"], "emoji": "🎯", "ru": {"title": "MLLM как судья для умного майнинга hard negatives в мультимодальных эмбеддингах", "desc": "Статья представляет UniME-V2 — универсальную мультимодальную модель эмбеддингов, которая использует му
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#multimodal", "#training", "#benchmark", "#optimization", "#dataset"], "emoji": "🔍", "ru": {"title": "Оптимизация контента для эры генеративного поиска с помощью AI", "desc": "Статья представляет AutoGEO — фреймворк для оптимизации контента под генеративные поисковые системы, такие 
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#rl", "#optimization", "#science", "#training"], "emoji": "🔍", "ru": {"title": "Масштабирование RL: от анализа к предсказанию", "desc": "В статье рассматривается систематическое исследование масштабирования обучения с подкреплением в больших языковых моделях. Авторы предлагают струк
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#multimodal", "#survey", "#reasoning", "#benchmark"], "emoji": "🔄", "ru": {"title": "Двусторонняя синергия понимания и генерации изображений", "desc": "Uni-MMMU — это бенчмарк для оценки unified мультимодальных моделей, которые одновременно понимают и генерируют изображения. Существ
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#open_source", "#data", "#dataset", "#synthetic", "#optimization", "#cv"], "emoji": "🎭", "ru": {"title": "Предобучение через распознавание деградации: универсальный подход к восстановлению изображений", "desc": "Статья представляет метод предобучения MaskDCPT для восстановления изоб
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#agi", "#agents", "#training", "#3d", "#optimization"], "emoji": "🤖", "ru": {"title": "Мягкие промпты для универсальных роботов", "desc": "Исследователи предложили новый подход Soft Prompt для обучения Vision-Language-Action моделей, которые управляют разными робота
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#training", "#optimization"], "emoji": "🔀", "ru": {"title": "Три стадии интерполяции: простое слияние моделей побеждает сложные методы", "desc": "Исследователи изучили простейший метод слияния моделей - прямую интерполяцию весов между Instruct и Thinki
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#multilingual", "#dataset", "#benchmark", "#multimodal", "#alignment", "#open_source"], "emoji": "🔍", "ru": {"title": "Детальное двуязычное выравнивание изображений и текста", "desc": "FG-CLIP 2 — это двуязычная vision-language модель для английского и китайского языков, которая улу
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#training", "#inference", "#optimization"], "emoji": "⚡", "ru": {"title": "Генерация нескольких токенов за один проход через поздние слои", "desc": "Исследователи предложили метод Direct Multi-Token Decoding (DMTD), который ускоряет inference больших языковых моделе
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#math", "#benchmark", "#interpretability"], "emoji": "🔍", "ru": {"title": "Проверка математических рассуждений AI на прочность", "desc": "Исследователи создали Hard2Verify — бенчмарк для оценки верификаторов математических рассуждений LLM, созданный с помощью 500 часов
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#inference", "#long_context", "#benchmark", "#optimization", "#training"], "emoji": "🚀", "ru": {"title": "Ускорение декодирования LLM через локальное кэширование", "desc": "NOSA — это новый метод обучаемого разреженного внимания (sparse attention), который решает пр
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#rl", "#agents", "#games", "#optimization", "#training"], "emoji": "🏎️", "ru": {"title": "Конкурентное обучение двух агентов для безопасного автопилота", "desc": "Статья предлагает новый подход к автономному вождению под названием CoIRL-AD, который объединяет imitation learning и re
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#agents", "#optimization", "#graphs", "#games"], "emoji": "🕸️", "ru": {"title": "Гиперграфы для умной коммуникации AI-агентов", "desc": "Статья представляет HyperAgent — фреймворк на основе гиперграфов для оптимизации коммуникации в мультиагентных системах с LLM. В отличие от традиц
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#cv", "#open_source", "#robotics", "#transfer_learning", "#dataset"], "emoji": "🧸", "ru": {"title": "Учимся захватывать сложное через простое: роботы осваивают мир с помощью геометрических примитивов", "desc": "Исследователи показали, что роботы могут научиться универсальным навыкам
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#rl", "#agents", "#reasoning", "#optimization", "#survey"], "emoji": "🔄", "ru": {"title": "Итеративная генерация SQL через взаимодействие с базой данных", "desc": "MTSQL-R1 — это агентный фреймворк для обучения систем преобразования текста в SQL в многошаговых диалогах. Авторы форму
[17.10.2025 00:52] Using data from previous issue: {"categories": ["#agents", "#synthetic", "#dataset", "#graphs", "#optimization", "#benchmark"], "emoji": "🕸️", "ru": {"title": "Графы зависимостей для поиска корневых причин ошибок в мультиагентных системах", "desc": "Статья представляет GraphTracer — фреймворк для диагностики ошибок в мультиагентны
[17.10.2025 00:52] Querying the API.
[17.10.2025 00:52] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Minimal Test-Time Intervention (MTI) enhances reasoning accuracy and stability in large language models with minimal overhead by selectively applying classifier-free guidance and lightweight negative-prompt guidance.  					AI-generated summary 				 Recent progress in large language models (LLMs) has focused on test-time scaling to improve reasoning via increased inference computation, but often at the cost of efficiency. We revisit test-time behavior and uncover a simple yet underexplored phenomenon: reasoning uncertainty is highly localized-only a small subset of high-entropy tokens dominantly affects output correctness. Motivated by this, we propose Minimal Test-Time Intervention (MTI), a training-free framework that enhances reasoning accuracy and stability with minimal overhead. MTI includes: (i) Selective CFG intervention, applying classifier-free guidance only at uncertain positions; and (ii) Lightweight negative-prompt guidance, reusing the main model's KV cache to approximate unconditional decoding efficiently. MTI yields consistent gains across general, coding, and STEM tasks-e.g., +1.35% average improvement on eight benchmarks for Qwen3-8B-Base and +5% on AIME2024 using Qwen3-32B-Reasoning-while remaining highly efficient.
[17.10.2025 00:52] Response: ```json
{
  "title": "Минимальное вмешательство в нужный момент для точных рассуждений",
  "desc": "Исследователи обнаружили, что неопределённость в рассуждениях LLM концентрируется только в небольшом количестве токенов с высокой энтропией, которые критически влияют на корректность ответа. На основе этого наблюдения предложен метод MTI - фреймворк без дополнительного обучения, который выборочно применяет classifier-free guidance только в моменты неопределённости и использует лёгкий negative-prompt guidance с переиспользованием KV-кеша. Метод показывает стабильное улучшение точности рассуждений на задачах по программированию и STEM (например, +1.35% на восьми бенчмарках для Qwen3-8B), при этом требуя минимальных вычислительных затрат. Это эффективная альтернатива затратным методам масштабирования на этапе инференса.",
  "emoji": "🎯",
  "desc": "Исследователи обнаружили, что неопределённость в рассуждениях LLM концентрируется только в небольшом количестве токенов с высокой энтропией, которые критически влияют на корректность ответа. На основе этого наблюдения предложен метод MTI - фреймворк без дополнительного обучения, который выборочно применяет classifier-free guidance только в моменты неопределённости и использует лёгкий negative-prompt guidance с переиспользованием KV-кеша. Метод показывает стабильное улучшение точности рассуждений на задачах по программированию и STEM (например, +1.35% на восьми бенчмарках
[17.10.2025 00:52] Error. Failed to parse JSON from LLM. {
  "title": "Минимальное вмешательство в нужный момент для точных рассуждений",
  "desc": "Исследователи обнаружили, что неопределённость в рассуждениях LLM концентрируется только в небольшом количестве токенов с высокой энтропией, которые критически влияют на корректность ответа. На основе этого наблюдения предложен метод MTI - фреймворк без дополнительного обучения, который выборочно применяет classifier-free guidance только в моменты неопределённости и использует лёгкий negative-prompt guidance с переиспользованием KV-кеша. Метод показывает стабильное улучшение точности рассуждений на задачах по программированию и STEM (например, +1.35% на восьми бенчмарках для Qwen3-8B), при этом требуя минимальных вычислительных затрат. Это эффективная альтернатива затратным методам масштабирования на этапе инференса.",
  "emoji": "🎯",
  "desc": "Исследователи обнаружили, что неопределённость в рассуждениях LLM концентрируется только в небольшом количестве токенов с высокой энтропией, которые критически влияют на корректность ответа. На основе этого наблюдения предложен метод MTI - фреймворк без дополнительного обучения, который выборочно применяет classifier-free guidance только в моменты неопределённости и использует лёгкий negative-prompt guidance с переиспользованием KV-кеша. Метод показывает стабильное улучшение точности рассуждений на задачах по программированию и STEM (например, +1.35% на восьми бенчмарках
[17.10.2025 00:52] Fallback to OpenAI.
[17.10.2025 00:53] Response: ParsedChatCompletionMessage[ArticleFull](content='{"desc":"В статье рассматривается метод минимального вмешательства во время тестирования (MTI) для улучшения точности и стабильности рассуждений в больших языковых моделях (LLM). MTI использует избирательное руководство без классификатора и легкое руководство с отрицательными подсказками, чтобы минимизировать неопределенность в рассуждениях. Это позволяет улучшить результаты на различных задачах, таких как общие, программирование и STEM, без значительных затрат на вычисления. Метод MTI показал улучшение точности на 1,35% на восьми тестах и на 5% на AIME2024, оставаясь при этом эффективным.","emoji":"🧠","title":"Улучшение рассуждений в LLM с минимальными затратами"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=ArticleFull(desc='В статье рассматривается метод минимального вмешательства во время тестирования (MTI) для улучшения точности и стабильности рассуждений в больших языковых моделях (LLM). MTI использует избирательное руководство без классификатора и легкое руководство с отрицательными подсказками, чтобы минимизировать неопределенность в рассуждениях. Это позволяет улучшить результаты на различных задачах, таких как общие, программирование и STEM, без значительных затрат на вычисления. Метод MTI показал улучшение точности на 1,35% на восьми тестах и на 5% на AIME2024, оставаясь при этом эффективным.', emoji='🧠', title='Улучшение рассуждений в LLM с минимальными затратами'))
[17.10.2025 00:53] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Minimal Test-Time Intervention (MTI) enhances reasoning accuracy and stability in large language models with minimal overhead by selectively applying classifier-free guidance and lightweight negative-prompt guidance.  					AI-generated summary 				 Recent progress in large language models (LLMs) has focused on test-time scaling to improve reasoning via increased inference computation, but often at the cost of efficiency. We revisit test-time behavior and uncover a simple yet underexplored phenomenon: reasoning uncertainty is highly localized-only a small subset of high-entropy tokens dominantly affects output correctness. Motivated by this, we propose Minimal Test-Time Intervention (MTI), a training-free framework that enhances reasoning accuracy and stability with minimal overhead. MTI includes: (i) Selective CFG intervention, applying classifier-free guidance only at uncertain positions; and (ii) Lightweight negative-prompt guidance, reusing the main model's KV cache to approximate unconditional decoding efficiently. MTI yields consistent gains across general, coding, and STEM tasks-e.g., +1.35% average improvement on eight benchmarks for Qwen3-8B-Base and +5% on AIME2024 using Qwen3-32B-Reasoning-while remaining highly efficient."

[17.10.2025 00:53] Response: ```python
["INFERENCE", "TRAINING", "BENCHMARK"]
```
[17.10.2025 00:53] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Minimal Test-Time Intervention (MTI) enhances reasoning accuracy and stability in large language models with minimal overhead by selectively applying classifier-free guidance and lightweight negative-prompt guidance.  					AI-generated summary 				 Recent progress in large language models (LLMs) has focused on test-time scaling to improve reasoning via increased inference computation, but often at the cost of efficiency. We revisit test-time behavior and uncover a simple yet underexplored phenomenon: reasoning uncertainty is highly localized-only a small subset of high-entropy tokens dominantly affects output correctness. Motivated by this, we propose Minimal Test-Time Intervention (MTI), a training-free framework that enhances reasoning accuracy and stability with minimal overhead. MTI includes: (i) Selective CFG intervention, applying classifier-free guidance only at uncertain positions; and (ii) Lightweight negative-prompt guidance, reusing the main model's KV cache to approximate unconditional decoding efficiently. MTI yields consistent gains across general, coding, and STEM tasks-e.g., +1.35% average improvement on eight benchmarks for Qwen3-8B-Base and +5% on AIME2024 using Qwen3-32B-Reasoning-while remaining highly efficient."

[17.10.2025 00:53] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[17.10.2025 00:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Minimal Test-Time Intervention (MTI), a method designed to improve the reasoning accuracy and stability of large language models (LLMs) without significant computational costs. It identifies that reasoning uncertainty is localized, meaning only a few uncertain tokens greatly influence the correctness of outputs. MTI employs selective classifier-free guidance at these uncertain positions and utilizes lightweight negative-prompt guidance to enhance performance while efficiently managing resources. The results show that MTI consistently improves performance across various tasks, demonstrating its effectiveness in enhancing LLM capabilities with minimal intervention.","title":"Boosting LLM Reasoning with Minimal Intervention"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces Minimal Test-Time Intervention (MTI), a method designed to improve the reasoning accuracy and stability of large language models (LLMs) without significant computational costs. It identifies that reasoning uncertainty is localized, meaning only a few uncertain tokens greatly influence the correctness of outputs. MTI employs selective classifier-free guidance at these uncertain positions and utilizes lightweight negative-prompt guidance to enhance performance while efficiently managing resources. The results show that MTI consistently improves performance across various tasks, demonstrating its effectiveness in enhancing LLM capabilities with minimal intervention.', title='Boosting LLM Reasoning with Minimal Intervention'))
[17.10.2025 00:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文提出了一种名为最小测试时间干预（MTI）的方法，旨在提高大型语言模型的推理准确性和稳定性，同时保持高效性。MTI通过选择性地在不确定的位置应用无分类器引导（CFG）和轻量级负提示引导，来减少计算开销。研究发现，推理的不确定性主要集中在少数高熵的标记上，这些标记对输出的正确性影响显著。通过MTI，模型在多个任务上表现出一致的性能提升，证明了其有效性。","title":"最小干预，最大推理！"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文提出了一种名为最小测试时间干预（MTI）的方法，旨在提高大型语言模型的推理准确性和稳定性，同时保持高效性。MTI通过选择性地在不确定的位置应用无分类器引导（CFG）和轻量级负提示引导，来减少计算开销。研究发现，推理的不确定性主要集中在少数高熵的标记上，这些标记对输出的正确性影响显著。通过MTI，模型在多个任务上表现出一致的性能提升，证明了其有效性。', title='最小干预，最大推理！'))
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#video", "#optimization", "#inference"], "emoji": "⚡", "ru": {"title": "Компенсация задержек при облачном инференсе для реального времени", "desc": "Статья представляет метод Dedelayed для решения проблемы задержек при удалённом инференсе на облачных моделях. Лёгкая локальная модель
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#agents", "#optimization", "#training", "#games"], "emoji": "🎮", "ru": {"title": "Умные игровые персонажи через промптинг и файн-тюнинг", "desc": "Команда Tu_Character_lab разработала методы для создания диалоговых NPC персонажей в играх на основе LLM. В работе использовались два по
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#multilingual", "#architecture"], "emoji": "🧠", "ru": {"title": "Сравнение синтаксической обработки в LLM и человеческом мозге через частотный анализ", "desc": "Исследователи разработали метод Hierarchical Frequency Tagging Probe (HFTP), который ис
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#video", "#cv", "#games", "#diffusion"], "emoji": "🎯", "ru": {"title": "Трекинг точек через видео-диффузию без обучения", "desc": "Исследователи обнаружили, что предобученные видео диффузионные модели могут выполнять трекинг точек в zero-shot режиме, просто визуально помечая точки н
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#training", "#benchmark", "#reasoning", "#rl", "#open_source"], "emoji": "🧮", "ru": {"title": "MATH-Beyond: бенчмарк, требующий настоящего исследования от RL-моделей", "desc": "MATH-Beyond — это новый бенчмарк для оценки математических способностей языковых моделей, специально разра
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#reasoning", "#training"], "emoji": "🌿", "ru": {"title": "Умное ветвление рассуждений по энтропии токенов", "desc": "EAGer — это метод генерации без обучения, который оптимизирует вычислительные ресурсы при решении сложных задач рассуждения. Вместо выд
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#training", "#multimodal", "#architecture", "#optimization", "#alignment", "#reasoning"], "emoji": "🔄", "ru": {"title": "Переключение между моделями для использования сильных сторон каждой", "desc": "Исследователи предложили метод Switch Generation, который позволяет разным версиям 
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#games", "#benchmark", "#reasoning", "#rl", "#dataset"], "emoji": "🎲", "ru": {"title": "Когда AI оценивает игры: reasoning-модели ближе к людям, но не идеальны", "desc": "Исследователи предложили новую парадигму оценки AI-систем: вместо того чтобы оценивать, как модели решают задачи
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#interpretability", "#reasoning", "#inference", "#math"], "emoji": "🎯", "ru": {"title": "Предсказание успешных путей рассуждений через скрытые траектории", "desc": "Исследователи предложили метод Latent-Trajectory signals, который анализирует изменения внутренних представлений модел
[17.10.2025 00:53] Using data from previous issue: {"categories": ["#games", "#benchmark", "#long_context", "#multimodal", "#agents"], "emoji": "🔍", "ru": {"title": "Когда LLM теряются в шумном стоге сена", "desc": "HaystackCraft — это новый бенчмарк для оценки устойчивости LLM при работе с длинным контекстом, построенный на основе английской Википе
[17.10.2025 00:53] Renaming data file.
[17.10.2025 00:53] Renaming previous data. hf_papers.json to ./d/2025-10-17.json
[17.10.2025 00:53] Saving new data file.
[17.10.2025 00:53] Generating page.
[17.10.2025 00:53] Renaming previous page.
[17.10.2025 00:53] Renaming previous data. index.html to ./d/2025-10-17.html
[17.10.2025 00:53] Writing result.
[17.10.2025 00:53] Renaming log file.
[17.10.2025 00:53] Renaming previous data. log.txt to ./logs/2025-10-17_last_log.txt
