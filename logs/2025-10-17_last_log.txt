[17.10.2025 05:13] Read previous papers.
[17.10.2025 05:13] Generating top page (month).
[17.10.2025 05:13] Writing top page (month).
[17.10.2025 06:17] Read previous papers.
[17.10.2025 06:17] Get feed.
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14975
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14545
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14359
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14979
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14972
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14967
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14943
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14973
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14528
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10518
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13998
[17.10.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2510.14763
[17.10.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2510.14616
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13217
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14300
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09033
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14958
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14211
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14978
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14969
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14276
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13454
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13054
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14974
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14880
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14252
[17.10.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2510.14949
[17.10.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2510.13996
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10390
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14976
[17.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14351
[17.10.2025 06:17] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.10.2025 06:17] No deleted papers detected.
[17.10.2025 06:17] Downloading and parsing papers (pdf, html). Total: 31.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14975.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14975.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14975.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14545.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14545.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14545.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14359.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14359.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14359.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14979.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14979.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14979.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14972.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14972.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14972.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14967.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14967.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14967.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14943.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14943.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14943.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14973.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14973.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14973.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14528.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14528.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14528.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.10518.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.10518.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.10518.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.13998.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.13998.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.13998.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14763.
[17.10.2025 06:17] Downloading paper 2510.14763 from http://arxiv.org/pdf/2510.14763v1...
[17.10.2025 06:17] Extracting affiliations from text.
[17.10.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"COIG-Writer: High-Quality Dataset for Chinese Creative Writing with Thought Processes M-A-P, 2077AI "
[17.10.2025 06:17] Response: []
[17.10.2025 06:17] Extracting affiliations from text.
[17.10.2025 06:17] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"COIG-Writer: High-Quality Dataset for Chinese Creative Writing with Thought Processes M-A-P, 2077AI5 2 0 2 6 1 ] . [ 1 3 6 7 4 1 . 0 1 5 2 : r Large language models exhibit systematic deficiencies in creative writing, particularly in nonEnglish contexts where training data is scarce and lacks process-level supervision. We present COIG-Writer, novel Chinese creative writing dataset that captures both diverse outputs and their underlying thought processes through systematic reverse-engineering of high-quality texts. Unlike existing datasets that provide only input-output pairs, COIG-Writer comprises 1,665 meticulously curated triplets spanning 51 genres, each containing: (1) reverse-engineered prompt, (2) detailed creative reasoning documenting decision-making processes, and (3) the final text. Through comprehensive experiments, we identify two-component model of creative writing: narrative logic (provided by process supervision) and linguistic expression (maintained by general-purpose data). Our findings reveal three critical insights: (1) Process supervision is highly effective but requires stabilisation with general data. ratio of at least one creative sample to twelve general samples is needed to achieve optimal performance; below this threshold, the win rate progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities are culturally-bound with no cross-lingual transfer (89.26pp gap between Chinese and English performance), and (3) lexical diversity inversely correlates with creative quality (TTR paradox), suggesting high diversity signals compensatory behavior for logical deficiencies. These findings establish that creative excellence emerges from the interaction between logical scaffolding and linguistic grounding, analogous to how mathematical reasoning enhances but cannot replace linguistic competence in foundation models. Project Homepage: https://COIG-Writer.github.io/ 1. Introduction Process supervision has transformed structured reasoning, for example, pushing math competition benchmarks to about 93% accuracy [20, 23] and enhancing multi-step reasoning [18, 28], yet creative writing, which accounts for about 40% of LLM applications [1, 24], lacks comparable methodological advances. We hypothesize this gap stems from fundamental misunderstanding: creative writing is not monolithic but compositional, requiring both narrative logic (structural planning) and linguistic expression (stylistic realization). Current creative writing models exhibit systematic failures across three dimensions. First, narrative structures converge to predictable templatesrepetitive narratives with limited variation dominate outputs [30]. Second, stylistic diversity collapsesdistinct authorial voices homogenize into what practitioners term AI flavor [5]. Third, cultural authenticity deteriorates catastrophically in non-English contextsChinese models produce Western narrative Figure 1. Overview of COIG-Writer construction and evaluation. Stage 1 (Data Construction): High-quality Chinese texts spanning 51 genres are collected and filtered, followed by expert reverse-engineering to extract creative prompts and reasoning processes, yielding 1,665 validated triplets. Stage 2 (Human Evaluation): Models trained on COIG-Writer undergo rigorous human preference evaluation through pairwise comparisons, with analysis of win rates and lexical diversity (TTR) to assess creative writing quality. structures with superficial cultural markers rather than authentic qi-cheng-zhuan-he (beginningdevelopment-turn-conclusion) progression [7]. We introduce COIG-Writer, Chinese creative writing dataset that uniquely captures the reasoning process underlying creative decisions. Our 1,665 expert-curated triplets span 51 genres, each containing: (1) reverse-engineered prompts, (2) detailed creative reasoning chains, and (3) final texts. While existing datasets prioritize either scale (e.g. WritingPrompts [9] (300K samples), ROCStories [22] (100K samples)) or breadth (e.g. COIG [35] (67K samples), LCCC [27] (12M samples)), they provide only input-output pairs without process data. COIG-Writer uniquely combines multi-genre coverage with explicit reasoning chains, enabling process-level learning of creative decision-making. Figure 1 illustrates our two-stage construction pipeline: (i) systematic collection and filtering of high-quality texts, followed by (ii) expert reverse-engineering to extract the implicit creative reasoning. Our experiments reveal three key findings: (1) Process supervision achieves 62.75% win rate in Chinese creative writing, but this requires stabilization ratio of approximately one creative-process sample to twelve general-purpose samples. Below this threshold, performance degrades monotonically (with win rates rising from 35.78% to 62.75% as the ratio is approached). (2) No cross-lingual transfer occurs: English performance drops to 46.46%, with pure COIGWriter models generating Chinese text for 12.18% of English prompts. (3) Lexical diversity inversely correlates with qualityhighest Type-Token Ratio (TTR) (0.678) corresponds to lowest preference scores (37.25%). These findings support two-component model of creative writing: narrative logic (enhanced by process supervision) and linguistic expression (maintained by general data). Neither component alone sufficesthe optimal configuration requires both. Contributions: Reverse-engineering methodology: We develop systematic approach to extract reasoning chains from high-quality texts through multi-stage validation (LLM filtering + expert annotation). The methodology achieves 70% acceptance rate and generalizes to other creative domains. COIG-Writer dataset: 1,665 Chinese creative writing triplets spanning 51 genres, with average lengths of 283/1,089/2,214 characters (prompt/reasoning/article). Each triplet 2 undergoes 6-dimensional quality evaluation (score 50), representing expert annotations. Empirical validation of compositional hypothesis: Through controlled experiments, we demonstrate: (1) process supervision improves Chinese creative writing from 35.78% to 62.75% but requires stabilization ratio of approximately 1:12 (creative to general samples), (2) creative capabilities are language-specific with 16.29% performance gap between Chinese and English, and (3) lexical diversity inversely correlates with quality (TTR paradox). 2. The COIG-Writer Dataset Figure 2. The data curation pipeline of COIG-Writer. Our methodology consists of t"
[17.10.2025 06:17] Mistral response. {"id": "64f2f6aedae4465486d2ba88b56f1c03", "created": 1760681848, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1417, "total_tokens": 1419, "completion_tokens": 2}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "[]"}}]}
[17.10.2025 06:17] Response: []
[17.10.2025 06:17] Deleting PDF ./assets/pdf/2510.14763.pdf.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14616.
[17.10.2025 06:17] Downloading paper 2510.14616 from http://arxiv.org/pdf/2510.14616v1...
[17.10.2025 06:17] Extracting affiliations from text.
[17.10.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 6 1 6 4 1 . 0 1 5 2 : r Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures ByteDance Seed, M-A-P Full author list in Contributions "
[17.10.2025 06:17] Response: ```python
["ByteDance Seed"]
```
[17.10.2025 06:17] Deleting PDF ./assets/pdf/2510.14616.pdf.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.13217.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.13217.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.13217.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14300.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14300.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14300.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.09033.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.09033.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.09033.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14958.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14958.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14958.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14211.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14211.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14211.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14978.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14978.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14978.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14969.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14969.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14969.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14276.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14276.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14276.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.13454.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.13454.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.13454.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.13054.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.13054.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.13054.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14974.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14974.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14974.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14880.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14880.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14880.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14252.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14252.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14252.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14949.
[17.10.2025 06:17] Downloading paper 2510.14949 from http://arxiv.org/pdf/2510.14949v1...
[17.10.2025 06:17] Extracting affiliations from text.
[17.10.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 9 4 9 4 1 . 0 1 5 2 : r DIALECTGEN: BENCHMARKING AND IMPROVING DIALECT ROBUSTNESS IN MULTIMODAL GENERATION , Da Yin, Clark Peng, Cho-Jui Hsieh, , Haikang Deng Yu Zhou , Sohyun An Kai-Wei Chang, Nanyun Peng University of California, Los Angeles {yuzhou, kwchang, violetpeng}@cs.ucla.edu Figure 1: Multimodal Generative Model Outputs on semantically identical prompts that differ only in one synonymous lexical feature in Standard American English (top) / lower-resource English dialect (bottom). "
[17.10.2025 06:17] Response: ```python
["University of California, Los Angeles"]
```
[17.10.2025 06:17] Deleting PDF ./assets/pdf/2510.14949.pdf.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.13996.
[17.10.2025 06:17] Downloading paper 2510.13996 from http://arxiv.org/pdf/2510.13996v1...
[17.10.2025 06:17] Extracting affiliations from text.
[17.10.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 1 ] . [ 1 6 9 9 3 1 . 0 1 5 2 : r The German Commons 154 Billion Tokens of Openly Licensed Text for German Language Models Lukas Gienapp University of Kassel, hessian.AI, and ScaDS.AI Kassel, Germany Ferdinand Schlatt Friedrich-SchillerUniversität Jena Jena, Germany Christopher Schröder InfAI and ScaDS.AI Leipzig, Germany Stefan Schweter Independent Researcher Holzkirchen, Germany Arden Zimmermann German National Library Leipzig, Germany Philippe Genêt German National Library Frankfurt, Germany Christopher Akiki Leipzig University and ScaDS.AI Leipzig, Germany Martin Potthast University of Kassel, hessian.AI, and ScaDS.AI Kassel, Germany Abstract Large language model development relies on large-scale training corpora, yet most contain data of unclear licensing status, limiting the development of truly open models. This problem is exacerbated for non-English languages, where openly licensed text remains critically scarce. We introduce the German Commons, the largest collection of openly licensed German text to date. It compiles data from 41 sources across seven domains, encompassing legal, scientific, cultural, political, news, economic, and web text. Through systematic sourcing from established data providers with verifiable licensing, it yields 154.56 billion tokens of high-quality text for language model training. Our processing pipeline implements comprehensive quality filtering, deduplication, and text formatting fixes, ensuring consistent quality across heterogeneous text sources. All domain subsets feature licenses of at least CC-BY-SA 4.0 or equivalent, ensuring legal compliance for model training and redistribution. The German Commons therefore addresses the critical gap in openly licensed German pretraining data, and enables the development of truly open German language models. We also release code for corpus construction and data filtering tailored to German language text, rendering the German Commons fully reproducible and extensible. Data: http"
[17.10.2025 06:17] Response: ```python
[
    "University of Kassel, hessian.AI, and ScaDS.AI",
    "Friedrich-Schiller-Universität Jena",
    "InfAI and ScaDS.AI",
    "Independent Researcher",
    "German National Library",
    "Leipzig University and ScaDS.AI"
]
```
[17.10.2025 06:17] Deleting PDF ./assets/pdf/2510.13996.pdf.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.10390.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.10390.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.10390.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14976.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14976.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14976.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.14351.
[17.10.2025 06:17] Extra JSON file exists (./assets/json/2510.14351.json), skip PDF parsing.
[17.10.2025 06:17] Paper image links file exists (./assets/img_data/2510.14351.json), skip HTML parsing.
[17.10.2025 06:17] Success.
[17.10.2025 06:17] Enriching papers with extra data.
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 0. A diffusion-based model addresses copy-paste artifacts in text-to-image generation by using a large-scale paired dataset and a contrastive identity loss to balance identity fidelity and variation.  					AI-generated summary 				 Identity-consistent generation has become an important focus in text-to...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 1. AEPO, an agentic RL algorithm, addresses entropy-related challenges in web agent training, enhancing performance and stability across various datasets.  					AI-generated summary 				 Recently, Agentic Reinforcement Learning (Agentic RL) has made significant progress in incentivizing the multi-turn,...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 2. Alpha-Service, a unified framework for proactive AI assistance, uses a multi-agent system on AI glasses to detect service opportunities and provide timely, personalized assistance.  					AI-generated summary 				 In an era where AI is evolving from a passive tool into an active and adaptive companio...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 3. NEO, a novel family of native Vision-Language Models, addresses fundamental constraints and integrates vision and language within a unified framework, achieving competitive performance with limited data.  					AI-generated summary 				 The edifice of native Vision-Language Models (VLMs) has emerged ...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 4. Misaligned tokenization in large language models for code leads to inconsistent model behavior, necessitating grammar-aware tokenization.  					AI-generated summary 				 Large language models (LLMs) for code rely on subword tokenizers, such as byte-pair encoding (BPE), learned from mixed natural lan...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 5. Information Gain-based Policy Optimization (IGPO) enhances multi-turn reasoning in large language models by providing dense intrinsic rewards derived from the model's belief updates, improving accuracy and sample efficiency.  					AI-generated summary 				 Large language model (LLM)-based agents are...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 6. LaSeR, a reinforcement learning algorithm, enhances Large Language Models by aligning last-token self-rewarding scores with verifier-based reasoning rewards, improving reasoning performance and inference-time scaling.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RL...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 7. Elastic-Cache optimizes key-value cache management in diffusion large language models to reduce decoding latency without sacrificing prediction accuracy.  					AI-generated summary 				 This work studies how to adaptively recompute key-value (KV) caches for diffusion large language models (DLMs) to ...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 8. PaddleOCR-VL, a vision-language model combining NaViT-style visual encoder and ERNIE-4.5 language model, achieves state-of-the-art performance in document parsing with minimal resource consumption.  					AI-generated summary 				 In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 9. VideoReward Thinker enhances multimodal reward models with visual reasoning operations and a configurable memory window, improving accuracy on video preference benchmarks.  					AI-generated summary 				 Recent advancements in multimodal reward models (RMs) have substantially improved post-training ...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 10. BitNet Distillation fine-tunes large language models to 1.58-bit precision using SubLN, multi-head attention distillation, and continual pre-training, achieving comparable performance with significant memory and inference speed improvements.  					AI-generated summary 				 In this paper, we present ...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 11. COIG-Writer, a Chinese creative writing dataset, reveals that process supervision and general-purpose data are crucial for creative writing, with cultural-bound capabilities and lexical diversity impacting performance.  					AI-generated summary 				 Large language models exhibit systematic deficien...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 12. Generative reward models with explicit reasoning chains outperform sequence-based reward models and zero-shot language models in preference learning for creative writing, indicating the need for intermediate reasoning in capturing subjective quality.  					AI-generated summary 				 Current preferenc...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 13. LATTICE, a hierarchical retrieval framework, enables efficient and accurate reasoning over large document collections using a semantic tree structure and a traversal algorithm that calibrates relevance scores.  					AI-generated summary 				 Modern IR systems are increasingly tasked with answering c...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 14. AdaMoE, a Mixture-of-Experts architecture, enhances VLA models by leveraging pretrained weights and improving computational efficiency, achieving superior performance in robotic manipulation tasks.  					AI-generated summary 				 Vision-Language-Action (VLA) models are experiencing rapid development...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 15. LLMs process factual queries and hallucinations similarly when associated with subject knowledge, leading to indistinguishable internal representations, but produce distinct representations for hallucinations without subject knowledge.  					AI-generated summary 				 Recent work suggests that large ...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 16. MathCanvas enhances Large Multimodal Models with Visual Chain-of-Thought capabilities for mathematics through pre-training on diagram generation and fine-tuning on visual-textual reasoning, achieving significant improvements on math benchmarks.  					AI-generated summary 				 While Large Language Mo...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 17. LiteStage, a latency-aware layer skipping framework, enhances multi-stage reasoning by optimizing layer budgets and suppressing redundant output tokens, achieving significant speedup with minimal accuracy loss.  					AI-generated summary 				 Multi-stage reasoning has emerged as an effective strateg...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 18. A new training paradigm for image editing models uses unrolled diffusion models and vision-language feedback to achieve performance comparable to supervised models without paired data.  					AI-generated summary 				 Recent image editing models have achieved impressive results while following natura...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 19. ...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 20. Qwen3Guard introduces multilingual safety guardrail models with fine-grained tri-class judgments and real-time token-level safety monitoring for large language models.  					AI-generated summary 				 As large language models (LLMs) become more capable and widely used, ensuring the safety of their ou...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 21. VIST3A combines latent text-to-video models and 3D reconstruction systems to generate high-quality 3D scenes from text, improving upon prior methods.  					AI-generated summary 				 The rapid progress of large, pretrained models for both visual content generation and 3D reconstruction opens up new p...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 22. ...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 23. Policy-based flow models enable efficient and high-quality image generation by distilling teacher models into student models with dynamic flow velocities, improving diversity and quality.  					AI-generated summary 				 Few-step diffusion or flow-based generative models typically distill a velocity-...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 24. mxbai-edge-colbert-v0 models, with 17M and 32M parameters, demonstrate superior retrieval performance on short-text and long-context benchmarks compared to ColBERTv2.  					AI-generated summary 				 In this work, we introduce mxbai-edge-colbert-v0 models, at two different parameter counts: 17M and 3...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 25. The MoM framework enhances RAG by transforming text processing from passive chunking to proactive understanding, enabling LLMs to generate structured document memories and SLMs to develop human-like reading abilities.  					AI-generated summary 				 The traditional RAG paradigm, which typically enga...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 26. A new benchmark and encoder-based mitigation strategy improve multimodal generative models' performance on dialectal textual input without degrading performance on Standard American English.  					AI-generated summary 				 Contact languages like English exhibit rich regional variations in the form o...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 27. The German Commons provides a large-scale, openly licensed dataset for training German language models, addressing the scarcity of such data.  					AI-generated summary 				 Large language model development relies on large-scale training corpora, yet most contain data of unclear licensing status, li...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 28. RefusalBench evaluates the selective refusal capability of language models in RAG systems using programmatically generated test cases, revealing systematic failure patterns and offering a path for improvement.  					AI-generated summary 				 The ability of language models in RAG systems to selective...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 29. Ponimator uses conditional diffusion models to generate and synthesize interactive poses from motion capture data, enabling versatile interaction animation tasks.  					AI-generated summary 				 Close-proximity human-human interactive poses convey rich contextual information about interaction dynami...
[17.10.2025 06:17] ********************************************************************************
[17.10.2025 06:17] Abstract 30. Beyond One World benchmark evaluates LLMs' ability to consistently portray version-specific superheroes across different canons through factual recall and ethical reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) are increasingly used as role-playing agents, yet their cap...
[17.10.2025 06:17] Read previous papers.
[17.10.2025 06:17] Generating reviews via LLM API.
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#dataset", "#cv", "#training", "#diffusion", "#benchmark"], "emoji": "🎭", "ru": {"title": "Генерация лиц без копипаста: баланс идентичности и разнообразия", "desc": "Исследователи решают проблему «копипаста» в text-to-image моделях, когда AI просто копирует референсное лицо вместо с
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#rl", "#training", "#optimization"], "emoji": "⚖️", "ru": {"title": "Балансировка энтропии для стабильного обучения веб-агентов", "desc": "AEPO — это алгоритм обучения с подкреплением для агентов, который решает проблемы, связанные с энтропией при обучении веб-агентов. Ал
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#agi", "#multimodal", "#optimization", "#games", "#interpretability"], "emoji": "🤖", "ru": {"title": "Проактивный AI: помощник, который предугадывает ваши нужды", "desc": "В статье представлена система Alpha-Service, которая использует AI-очки для проактивной помощи польз
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#agi", "#multimodal", "#alignment", "#architecture", "#open_source"], "emoji": "🔗", "ru": {"title": "NEO: нативные Vision-Language модели с единым представлением", "desc": "Статья представляет NEO — новое семейство нативных Vision-Language Models (VLM), которые интегрируют визуальну
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#data", "#plp", "#dataset", "#architecture"], "emoji": "🔤", "ru": {"title": "Проблема токенизации кода: когда пробелы меняют поведение модели", "desc": "Исследователи обнаружили серьёзную проблему в языковых моделях для кода: статистические токениз
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#rl", "#reasoning", "#rlhf", "#training", "#optimization"], "emoji": "🎯", "ru": {"title": "Плотные награды через прирост информации для многошагового обучения агентов", "desc": "Статья представляет метод IGPO для улучшения обучения LLM-агентов с помощью reinforcement lear
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#rlhf", "#training", "#optimization"], "emoji": "🎯", "ru": {"title": "Самооценка через последний токен для улучшения reasoning", "desc": "LaSeR — это алгоритм reinforcement learning, который улучшает reasoning способности LLM путём объединения генерации решений 
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#training", "#inference", "#architecture", "#optimization", "#diffusion"], "emoji": "⚡", "ru": {"title": "Умное кэширование для ускорения диффузионных языковых моделей", "desc": "Статья предлагает метод Elastic-Cache для оптимизации управления key-value кэшем в диффузионных LLM. Авт
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#training", "#science", "#low_resource", "#benchmark"], "emoji": "📄", "ru": {"title": "Эффективное распознавание документов с минимальными ресурсами", "desc": "PaddleOCR-VL — это компактная vision-language модель для парсинга документов, объединяющая визуальный
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#multimodal", "#open_source", "#long_context", "#benchmark"], "emoji": "🎬", "ru": {"title": "Обучение AI размышлять визуально при оценке видео", "desc": "Статья представляет VideoReward Thinker — новый подход к мультимодальным моделям вознаграждения, который поз
[17.10.2025 06:17] Using data from previous issue: {"categories": ["#training", "#inference", "#architecture", "#optimization", "#small_models"], "emoji": "🔽", "ru": {"title": "Сжатие LLM до тернарных весов с сохранением качества", "desc": "В статье представлен BitNet Distillation (BitDistill) — легковесный метод для дистилляции полноточных LLM в мо
[17.10.2025 06:17] Querying the API.
[17.10.2025 06:17] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

COIG-Writer, a Chinese creative writing dataset, reveals that process supervision and general-purpose data are crucial for creative writing, with cultural-bound capabilities and lexical diversity impacting performance.  					AI-generated summary 				 Large language models exhibit systematic deficiencies in creative writing, particularly in non-English contexts where training data is scarce and lacks process-level supervision. We present COIG-Writer, a novel Chinese creative writing dataset that captures both diverse outputs and their underlying thought processes through systematic reverse-engineering of high-quality texts. Unlike existing datasets that provide only input-output pairs, COIG-Writer comprises 1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a reverse-engineered prompt, (2) detailed creative reasoning documenting decision-making processes, and (3) the final text. Through comprehensive experiments, we identify a two-component model of creative writing: narrative logic (provided by process supervision) and linguistic expression (maintained by general-purpose data). Our findings reveal three critical insights: (1) Process supervision is highly effective but requires stabilization with general data. A ratio of at least one creative sample to twelve general samples is needed to achieve optimal performance; below this threshold, the win rate progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities are culturally-bound with no cross-lingual transfer (89.26pp gap between Chinese and English performance), and (3) lexical diversity inversely correlates with creative quality (TTR paradox), suggesting high diversity signals compensatory behavior for logical deficiencies. These findings establish that creative excellence emerges from the interaction between logical scaffolding and linguistic grounding, analogous to how mathematical reasoning enhances but cannot replace linguistic competence in foundation models.
[17.10.2025 06:18] Response: ```json
{
  "desc": "Исследователи создали датасет COIG-Writer для обучения LLM креативному письму на китайском языке, содержащий 1665 примеров с промптами, процессом рассуждений и финальным текстом. Эксперименты показали, что для качественного творческого письма необходимо сочетание process supervision (пошаговый контроль процесса создания текста) и общих данных в пропорции минимум 1:12. Креативные способности оказались культурно-обусловленными и не переносятся между языками (разница в 89 процентных пунктов между китайским и английским). Высокое лексическое разнообразие парадоксально коррелирует с низким качеством, что указывает на компенсацию логических недостатков модели.",
  "emoji": "✍️",
  "title": "Креативность AI требует баланса логики и языка"
}
```
[17.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"COIG-Writer, a Chinese creative writing dataset, reveals that process supervision and general-purpose data are crucial for creative writing, with cultural-bound capabilities and lexical diversity impacting performance.  					AI-generated summary 				 Large language models exhibit systematic deficiencies in creative writing, particularly in non-English contexts where training data is scarce and lacks process-level supervision. We present COIG-Writer, a novel Chinese creative writing dataset that captures both diverse outputs and their underlying thought processes through systematic reverse-engineering of high-quality texts. Unlike existing datasets that provide only input-output pairs, COIG-Writer comprises 1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a reverse-engineered prompt, (2) detailed creative reasoning documenting decision-making processes, and (3) the final text. Through comprehensive experiments, we identify a two-component model of creative writing: narrative logic (provided by process supervision) and linguistic expression (maintained by general-purpose data). Our findings reveal three critical insights: (1) Process supervision is highly effective but requires stabilization with general data. A ratio of at least one creative sample to twelve general samples is needed to achieve optimal performance; below this threshold, the win rate progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities are culturally-bound with no cross-lingual transfer (89.26pp gap between Chinese and English performance), and (3) lexical diversity inversely correlates with creative quality (TTR paradox), suggesting high diversity signals compensatory behavior for logical deficiencies. These findings establish that creative excellence emerges from the interaction between logical scaffolding and linguistic grounding, analogous to how mathematical reasoning enhances but cannot replace linguistic competence in foundation models."

[17.10.2025 06:18] Response: ```python
['DATASET', 'MULTILINGUAL']
```
[17.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"COIG-Writer, a Chinese creative writing dataset, reveals that process supervision and general-purpose data are crucial for creative writing, with cultural-bound capabilities and lexical diversity impacting performance.  					AI-generated summary 				 Large language models exhibit systematic deficiencies in creative writing, particularly in non-English contexts where training data is scarce and lacks process-level supervision. We present COIG-Writer, a novel Chinese creative writing dataset that captures both diverse outputs and their underlying thought processes through systematic reverse-engineering of high-quality texts. Unlike existing datasets that provide only input-output pairs, COIG-Writer comprises 1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a reverse-engineered prompt, (2) detailed creative reasoning documenting decision-making processes, and (3) the final text. Through comprehensive experiments, we identify a two-component model of creative writing: narrative logic (provided by process supervision) and linguistic expression (maintained by general-purpose data). Our findings reveal three critical insights: (1) Process supervision is highly effective but requires stabilization with general data. A ratio of at least one creative sample to twelve general samples is needed to achieve optimal performance; below this threshold, the win rate progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities are culturally-bound with no cross-lingual transfer (89.26pp gap between Chinese and English performance), and (3) lexical diversity inversely correlates with creative quality (TTR paradox), suggesting high diversity signals compensatory behavior for logical deficiencies. These findings establish that creative excellence emerges from the interaction between logical scaffolding and linguistic grounding, analogous to how mathematical reasoning enhances but cannot replace linguistic competence in foundation models."

[17.10.2025 06:18] Response: ```python
["LOW_RESOURCE", "STORY_GENERATION"]
```
[17.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces COIG-Writer, a dataset designed to enhance creative writing in Chinese by providing insights into the thought processes behind writing. It emphasizes the importance of process supervision and general-purpose data in improving the performance of large language models, especially in non-English contexts. The dataset includes curated triplets that consist of prompts, reasoning documentation, and final texts, allowing for a deeper understanding of creative writing. Key findings indicate that a balance of creative and general samples is crucial for optimal performance, and that cultural context significantly affects creative capabilities.","title":"Unlocking Creative Writing with COIG-Writer"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces COIG-Writer, a dataset designed to enhance creative writing in Chinese by providing insights into the thought processes behind writing. It emphasizes the importance of process supervision and general-purpose data in improving the performance of large language models, especially in non-English contexts. The dataset includes curated triplets that consist of prompts, reasoning documentation, and final texts, allowing for a deeper understanding of creative writing. Key findings indicate that a balance of creative and general samples is crucial for optimal performance, and that cultural context significantly affects creative capabilities.', title='Unlocking Creative Writing with COIG-Writer'))
[17.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"COIG-Writer是一个中文创意写作数据集，强调过程监督和通用数据对创意写作的重要性。研究发现，文化背景和词汇多样性会影响创作表现，尤其是在非英语环境中。该数据集包含1665个精心策划的三元组，记录了创作过程中的推理和最终文本。实验结果表明，创意写作的成功依赖于叙事逻辑和语言表达的结合。","title":"创意写作的成功源于逻辑与语言的结合"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='COIG-Writer是一个中文创意写作数据集，强调过程监督和通用数据对创意写作的重要性。研究发现，文化背景和词汇多样性会影响创作表现，尤其是在非英语环境中。该数据集包含1665个精心策划的三元组，记录了创作过程中的推理和最终文本。实验结果表明，创意写作的成功依赖于叙事逻辑和语言表达的结合。', title='创意写作的成功源于逻辑与语言的结合'))
[17.10.2025 06:18] Querying the API.
[17.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Generative reward models with explicit reasoning chains outperform sequence-based reward models and zero-shot language models in preference learning for creative writing, indicating the need for intermediate reasoning in capturing subjective quality.  					AI-generated summary 				 Current preference learning methods achieve high accuracy on standard benchmarks but exhibit significant performance degradation when objective quality signals are removed. We introduce WritingPreferenceBench, a dataset of 1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8 creative writing genres, where responses are matched for objective correctness, factual accuracy, and length. On this benchmark, sequence-based reward models--the standard architecture for RLHF--achieve only 52.7% mean accuracy, while zero-shot language model judges perform at 53.9%. In contrast, generative reward models that produce explicit reasoning chains achieve 81.8% accuracy. We observe high within-model variance across genres: individual models range from 18.2% to 81.8% accuracy across different writing categories, with standard deviations averaging 10.1%. This variance persists regardless of model scale, with 27B parameter models showing no consistent improvement over 8B variants. Our results suggest that current RLHF methods primarily learn to detect objective errors rather than capture subjective quality preferences (e.g., creativity, stylistic flair, and emotional resonance), and that successful preference modeling may require intermediate reasoning representations rather than direct classification.
[17.10.2025 06:18] Response: ```json
{
  "title": "Рассуждения важнее классификации для оценки творческих текстов",
  "emoji": "✍️",
  "desc": "Исследователи создали WritingPreferenceBench — датасет из 1800 примеров творческих текстов, где убрали объективные сигналы качества и оставили только субъективные предпочтения. Стандартные reward models показали точность всего 52.7%, в то время как генеративные модели с явными цепочками рассуждений достигли 81.8% точности. Увеличение размера модели с 8B до 27B параметров не улучшило результаты, а разброс точности между жанрами достигал от 18% до 82% для одной модели. Результаты показывают, что современный RLHF учится в основном детектировать объективные ошибки, а не понимать субъективное качество вроде креативности и эмоционального резонанса — для этого нужны промежуточные рассуждения, а не прямая классификация."
}
```
[17.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Generative reward models with explicit reasoning chains outperform sequence-based reward models and zero-shot language models in preference learning for creative writing, indicating the need for intermediate reasoning in capturing subjective quality.  					AI-generated summary 				 Current preference learning methods achieve high accuracy on standard benchmarks but exhibit significant performance degradation when objective quality signals are removed. We introduce WritingPreferenceBench, a dataset of 1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8 creative writing genres, where responses are matched for objective correctness, factual accuracy, and length. On this benchmark, sequence-based reward models--the standard architecture for RLHF--achieve only 52.7% mean accuracy, while zero-shot language model judges perform at 53.9%. In contrast, generative reward models that produce explicit reasoning chains achieve 81.8% accuracy. We observe high within-model variance across genres: individual models range from 18.2% to 81.8% accuracy across different writing categories, with standard deviations averaging 10.1%. This variance persists regardless of model scale, with 27B parameter models showing no consistent improvement over 8B variants. Our results suggest that current RLHF methods primarily learn to detect objective errors rather than capture subjective quality preferences (e.g., creativity, stylistic flair, and emotional resonance), and that successful preference modeling may require intermediate reasoning representations rather than direct classification."

[17.10.2025 06:18] Response: ```python
["DATASET", "BENCHMARK", "RLHF"]
```
[17.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Generative reward models with explicit reasoning chains outperform sequence-based reward models and zero-shot language models in preference learning for creative writing, indicating the need for intermediate reasoning in capturing subjective quality.  					AI-generated summary 				 Current preference learning methods achieve high accuracy on standard benchmarks but exhibit significant performance degradation when objective quality signals are removed. We introduce WritingPreferenceBench, a dataset of 1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8 creative writing genres, where responses are matched for objective correctness, factual accuracy, and length. On this benchmark, sequence-based reward models--the standard architecture for RLHF--achieve only 52.7% mean accuracy, while zero-shot language model judges perform at 53.9%. In contrast, generative reward models that produce explicit reasoning chains achieve 81.8% accuracy. We observe high within-model variance across genres: individual models range from 18.2% to 81.8% accuracy across different writing categories, with standard deviations averaging 10.1%. This variance persists regardless of model scale, with 27B parameter models showing no consistent improvement over 8B variants. Our results suggest that current RLHF methods primarily learn to detect objective errors rather than capture subjective quality preferences (e.g., creativity, stylistic flair, and emotional resonance), and that successful preference modeling may require intermediate reasoning representations rather than direct classification."

[17.10.2025 06:18] Response: ```python
['REASONING', 'STORY_GENERATION', 'LOW_RESOURCE']
```
[17.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the limitations of current preference learning methods in evaluating creative writing, particularly when objective quality signals are absent. It introduces a new dataset, WritingPreferenceBench, which includes 1,800 human-annotated preference pairs across various genres. The study finds that traditional sequence-based reward models and zero-shot language models perform poorly, achieving only around 52-54% accuracy. In contrast, generative reward models that utilize explicit reasoning chains significantly outperform these methods, achieving 81.8% accuracy, highlighting the importance of intermediate reasoning in assessing subjective quality in creative writing.","title":"Unlocking Creativity: Reasoning Chains Enhance Preference Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the limitations of current preference learning methods in evaluating creative writing, particularly when objective quality signals are absent. It introduces a new dataset, WritingPreferenceBench, which includes 1,800 human-annotated preference pairs across various genres. The study finds that traditional sequence-based reward models and zero-shot language models perform poorly, achieving only around 52-54% accuracy. In contrast, generative reward models that utilize explicit reasoning chains significantly outperform these methods, achieving 81.8% accuracy, highlighting the importance of intermediate reasoning in assessing subjective quality in creative writing.', title='Unlocking Creativity: Reasoning Chains Enhance Preference Learning'))
[17.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文探讨了生成奖励模型在创意写作偏好学习中的表现，发现其优于基于序列的奖励模型和零-shot语言模型。研究表明，现有的偏好学习方法在去除客观质量信号后，准确性显著下降。我们引入了WritingPreferenceBench数据集，包含1800对人类标注的偏好对，涵盖8种创意写作类型。结果显示，生成奖励模型通过明确的推理链实现了更高的准确率，强调了中间推理在捕捉主观质量中的重要性。","title":"生成奖励模型：创意写作的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文探讨了生成奖励模型在创意写作偏好学习中的表现，发现其优于基于序列的奖励模型和零-shot语言模型。研究表明，现有的偏好学习方法在去除客观质量信号后，准确性显著下降。我们引入了WritingPreferenceBench数据集，包含1800对人类标注的偏好对，涵盖8种创意写作类型。结果显示，生成奖励模型通过明确的推理链实现了更高的准确率，强调了中间推理在捕捉主观质量中的重要性。', title='生成奖励模型：创意写作的新突破'))
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#rag", "#reasoning", "#optimization", "#benchmark"], "emoji": "🌳", "ru": {"title": "Поиск через семантическое дерево с логарифмической сложностью", "desc": "LATTICE — это фреймворк для information retrieval, который организует большие коллекции документов в виде семантического дерев
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#robotics", "#agi", "#benchmark", "#architecture"], "emoji": "🤖", "ru": {"title": "Совместная работа экспертов для эффективного управления роботами", "desc": "Архитектура AdaMoE использует подход Mixture-of-Experts для масштабирования Vision-Language-Action моделей,
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#data", "#interpretability", "#multimodal", "#hallucinations"], "emoji": "🎭", "ru": {"title": "LLM не знают, что они не знают: галлюцинации неотличимы от фактов", "desc": "Исследование показывает, что LLM обрабатывают фактические запросы и галлюцинации схожим образом, когда они связ
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#multimodal", "#games", "#math", "#benchmark"], "emoji": "📐", "ru": {"title": "Визуальная цепочка рассуждений для математики", "desc": "MathCanvas — это фреймворк для обучения больших мультимодальных моделей решению математических задач с использованием виз
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#small_models", "#training", "#reasoning", "#inference"], "emoji": "⚡", "ru": {"title": "Ускорение многоэтапного рассуждения через умный пропуск слоёв", "desc": "LiteStage — это фреймворк для ускорения многоэтапного рассуждения в малых языковых моделях путём пропуск
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#cv", "#rlhf", "#training", "#optimization", "#synthetic", "#diffusion", "#benchmark"], "emoji": "✂️", "ru": {"title": "Редактирование изображений без парных данных через обратную связь от VLM", "desc": "Авторы предлагают новую парадигму обучения моделей редактирования изображений, 
[17.10.2025 06:18] Using data from previous issue: {"categories": [], "emoji": "🤝", "ru": {"title": "Когда AI модель не уверена — лучше спросить человека", "desc": "Исследователи предлагают метод, который позволяет LLM определять, когда они недостаточно уверены в ответе и нуждаются в помощи человека. Система использует специальный подход к калибровк
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#data", "#open_source", "#alignment", "#training", "#ethics", "#multilingual", "#low_resource", "#benchmark"], "emoji": "🛡️", "ru": {"title": "Многоязычная защита LLM с трёхуровневой классификацией и проверкой в реальном времени", "desc": "Qwen3Guard — это семейство многоязычных мод
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#3d", "#multimodal", "#alignment", "#training", "#optimization"], "emoji": "🎬", "ru": {"title": "От текста к 3D через видео: сшивание моделей для создания сцен", "desc": "VIST3A — это новый фреймворк для генерации 3D-сцен из текста, который объединяет latent text-to-video модели с с
[17.10.2025 06:18] Using data from previous issue: {"categories": [], "emoji": "🎯", "ru": {"title": "Оптимизация промптов через градиентный спуск в пространстве эмбеддингов", "desc": "Исследователи предлагают метод автоматической оптимизации промптов для языковых моделей, используя градиентный спуск непосредственно в пространстве эмбеддингов токенов
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#training", "#optimization", "#cv", "#diffusion"], "emoji": "🌊", "ru": {"title": "Динамические траектории для быстрой генерации изображений", "desc": "Статья представляет pi-Flow — новый подход к дистилляции flow-based моделей генерации изображений. Вместо предсказания прямого пути 
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#long_context", "#training", "#dataset", "#optimization", "#benchmark", "#small_models"], "emoji": "🔍", "ru": {"title": "Мощный поиск в кармане: компактные модели побеждают гигантов", "desc": "Исследователи представили mxbai-edge-colbert-v0 — компактные модели для поиска информации 
[17.10.2025 06:18] Using data from previous issue: {"categories": ["#rag", "#reasoning", "#multimodal", "#training", "#interpretability"], "emoji": "🧠", "ru": {"title": "От пассивных чанков к активной памяти документов", "desc": "Статья представляет фреймворк MoM, который улучшает RAG-системы, превращая пассивное разделение текста на чанки в активно
[17.10.2025 06:18] Querying the API.
[17.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A new benchmark and encoder-based mitigation strategy improve multimodal generative models' performance on dialectal textual input without degrading performance on Standard American English.  					AI-generated summary 				 Contact languages like English exhibit rich regional variations in the form of dialects, which are often used by dialect speakers interacting with generative models. However, can multimodal generative models effectively produce content given dialectal textual input? In this work, we study this question by constructing a new large-scale benchmark spanning six common English dialects. We work with dialect speakers to collect and verify over 4200 unique prompts and evaluate on 17 image and video generative models. Our automatic and human evaluation results show that current state-of-the-art multimodal generative models exhibit 32.26% to 48.17% performance degradation when a single dialect word is used in the prompt. Common mitigation methods such as fine-tuning and prompt rewriting can only improve dialect performance by small margins (< 7%), while potentially incurring significant performance degradation in Standard American English (SAE). To this end, we design a general encoder-based mitigation strategy for multimodal generative models. Our method teaches the model to recognize new dialect features while preserving SAE performance. Experiments on models such as Stable Diffusion 1.5 show that our method is able to simultaneously raise performance on five dialects to be on par with SAE (+34.4%), while incurring near zero cost to SAE performance.
[17.10.2025 06:18] Response: ```json
{
  "title": "Обучение генеративных моделей понимать диалекты английского языка",
  "emoji": "🗣️",
  "desc": "Исследователи создали новый бенчмарк для оценки мультимодальных генеративных моделей на шести диалектах английского языка, включая более 4200 уникальных промптов. Результаты показали, что современные модели демонстрируют падение качества на 32-48% при использовании диалектных слов в промптах. Традиционные методы улучшения, такие как fine-tuning и переписывание промптов, дают незначительный прирост и могут ухудшить работу со стандартным американским английским. Авторы предложили новую стратегию на основе энкодера, которая позволила одновременно поднять качество на пяти диалектах до уровня стандартного английского (+34.4%) без потери производительности на нём."
}
```
[17.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new benchmark and encoder-based mitigation strategy improve multimodal generative models' performance on dialectal textual input without degrading performance on Standard American English.  					AI-generated summary 				 Contact languages like English exhibit rich regional variations in the form of dialects, which are often used by dialect speakers interacting with generative models. However, can multimodal generative models effectively produce content given dialectal textual input? In this work, we study this question by constructing a new large-scale benchmark spanning six common English dialects. We work with dialect speakers to collect and verify over 4200 unique prompts and evaluate on 17 image and video generative models. Our automatic and human evaluation results show that current state-of-the-art multimodal generative models exhibit 32.26% to 48.17% performance degradation when a single dialect word is used in the prompt. Common mitigation methods such as fine-tuning and prompt rewriting can only improve dialect performance by small margins (< 7%), while potentially incurring significant performance degradation in Standard American English (SAE). To this end, we design a general encoder-based mitigation strategy for multimodal generative models. Our method teaches the model to recognize new dialect features while preserving SAE performance. Experiments on models such as Stable Diffusion 1.5 show that our method is able to simultaneously raise performance on five dialects to be on par with SAE (+34.4%), while incurring near zero cost to SAE performance."

[17.10.2025 06:18] Response: ```python
['BENCHMARK', 'MULTIMODAL']
```
[17.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new benchmark and encoder-based mitigation strategy improve multimodal generative models' performance on dialectal textual input without degrading performance on Standard American English.  					AI-generated summary 				 Contact languages like English exhibit rich regional variations in the form of dialects, which are often used by dialect speakers interacting with generative models. However, can multimodal generative models effectively produce content given dialectal textual input? In this work, we study this question by constructing a new large-scale benchmark spanning six common English dialects. We work with dialect speakers to collect and verify over 4200 unique prompts and evaluate on 17 image and video generative models. Our automatic and human evaluation results show that current state-of-the-art multimodal generative models exhibit 32.26% to 48.17% performance degradation when a single dialect word is used in the prompt. Common mitigation methods such as fine-tuning and prompt rewriting can only improve dialect performance by small margins (< 7%), while potentially incurring significant performance degradation in Standard American English (SAE). To this end, we design a general encoder-based mitigation strategy for multimodal generative models. Our method teaches the model to recognize new dialect features while preserving SAE performance. Experiments on models such as Stable Diffusion 1.5 show that our method is able to simultaneously raise performance on five dialects to be on par with SAE (+34.4%), while incurring near zero cost to SAE performance."

[17.10.2025 06:18] Response: ```python
["LOW_RESOURCE", "SYNTHETIC"]
```
[17.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of improving multimodal generative models\' performance when processing dialectal textual input without harming their effectiveness on Standard American English (SAE). The authors introduce a new benchmark that includes a diverse set of prompts from six English dialects, revealing significant performance drops in existing models when dialect words are used. They propose an innovative encoder-based mitigation strategy that enables models to learn dialect features while maintaining SAE performance. Experimental results demonstrate that their approach can enhance dialect performance significantly, achieving parity with SAE without degrading its quality.","title":"Bridging Dialects: Enhancing Generative Models Without Compromise"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper addresses the challenge of improving multimodal generative models' performance when processing dialectal textual input without harming their effectiveness on Standard American English (SAE). The authors introduce a new benchmark that includes a diverse set of prompts from six English dialects, revealing significant performance drops in existing models when dialect words are used. They propose an innovative encoder-based mitigation strategy that enables models to learn dialect features while maintaining SAE performance. Experimental results demonstrate that their approach can enhance dialect performance significantly, achieving parity with SAE without degrading its quality.", title='Bridging Dialects: Enhancing Generative Models Without Compromise'))
[17.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究提出了一种新的基准和基于编码器的缓解策略，以提高多模态生成模型在方言文本输入上的表现，同时不影响标准美式英语的性能。我们构建了一个涵盖六种常见英语方言的大规模基准，并收集了4200多个独特的提示进行评估。结果显示，当前的多模态生成模型在使用方言词汇时，性能下降幅度可达32.26%至48.17%。我们的编码器策略能够让模型识别新的方言特征，同时保持标准美式英语的性能几乎不受影响。","title":"提升方言生成能力，保留标准英语表现"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究提出了一种新的基准和基于编码器的缓解策略，以提高多模态生成模型在方言文本输入上的表现，同时不影响标准美式英语的性能。我们构建了一个涵盖六种常见英语方言的大规模基准，并收集了4200多个独特的提示进行评估。结果显示，当前的多模态生成模型在使用方言词汇时，性能下降幅度可达32.26%至48.17%。我们的编码器策略能够让模型识别新的方言特征，同时保持标准美式英语的性能几乎不受影响。', title='提升方言生成能力，保留标准英语表现'))
[17.10.2025 06:18] Querying the API.
[17.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The German Commons provides a large-scale, openly licensed dataset for training German language models, addressing the scarcity of such data.  					AI-generated summary 				 Large language model development relies on large-scale training corpora, yet most contain data of unclear licensing status, limiting the development of truly open models. This problem is exacerbated for non-English languages, where openly licensed text remains critically scarce. We introduce the German Commons, the largest collection of openly licensed German text to date. It compiles data from 41 sources across seven domains, encompassing legal, scientific, cultural, political, news, economic, and web text. Through systematic sourcing from established data providers with verifiable licensing, it yields 154.56 billion tokens of high-quality text for language model training. Our processing pipeline implements comprehensive quality filtering, deduplication, and text formatting fixes, ensuring consistent quality across heterogeneous text sources. All domain subsets feature licenses of at least CC-BY-SA 4.0 or equivalent, ensuring legal compliance for model training and redistribution. The German Commons therefore addresses the critical gap in openly licensed German pretraining data, and enables the development of truly open German language models. We also release code for corpus construction and data filtering tailored to German language text, rendering the German Commons fully reproducible and extensible.
[17.10.2025 06:19] Response: ```json
{
  "title": "Немецкие общины: открытый датасет для немецких языковых моделей",
  "desc": "Исследователи представили German Commons — крупнейшую коллекцию текстов на немецком языке с открытыми лицензиями для обучения языковых моделей. Датасет включает 154,56 миллиарда токенов из 41 источника, охватывающих семь доменов: юридические, научные, культурные, политические, новостные, экономические и веб-тексты. Все данные имеют лицензии CC-BY-SA 4.0 или эквивалентные, что обеспечивает легальность использования для обучения и распространения моделей. Авторы также публикуют код для создания корпуса и фильтрации данных, делая German Commons полностью воспроизводимым и расширяемым.",
  "emoji": "🇩🇪",
  "desc": "Исследователи представили German Commons — крупнейшую коллекцию текстов на немецком языке с открытыми лицензиями для обучения языковых моделей. Датасет включает 154,56 миллиарда токенов из 41 источника, охватывающих семь доменов: юридические, научные, культурные, политические, новостные, экономические и веб-тексты. Все данные имеют лицензии CC-BY-SA 4.0 или эквивалентные, что обеспечивает легальность использования для обучения и распространения моделей. Авторы также публикуют код для создания корпуса и фильтрации данных, делая German Commons полностью воспроизводимым и расширяемым."
}
```
[17.10.2025 06:19] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The German Commons provides a large-scale, openly licensed dataset for training German language models, addressing the scarcity of such data.  					AI-generated summary 				 Large language model development relies on large-scale training corpora, yet most contain data of unclear licensing status, limiting the development of truly open models. This problem is exacerbated for non-English languages, where openly licensed text remains critically scarce. We introduce the German Commons, the largest collection of openly licensed German text to date. It compiles data from 41 sources across seven domains, encompassing legal, scientific, cultural, political, news, economic, and web text. Through systematic sourcing from established data providers with verifiable licensing, it yields 154.56 billion tokens of high-quality text for language model training. Our processing pipeline implements comprehensive quality filtering, deduplication, and text formatting fixes, ensuring consistent quality across heterogeneous text sources. All domain subsets feature licenses of at least CC-BY-SA 4.0 or equivalent, ensuring legal compliance for model training and redistribution. The German Commons therefore addresses the critical gap in openly licensed German pretraining data, and enables the development of truly open German language models. We also release code for corpus construction and data filtering tailored to German language text, rendering the German Commons fully reproducible and extensible."

[17.10.2025 06:19] Response: ```python
['DATASET', 'DATA']
```
[17.10.2025 06:19] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The German Commons provides a large-scale, openly licensed dataset for training German language models, addressing the scarcity of such data.  					AI-generated summary 				 Large language model development relies on large-scale training corpora, yet most contain data of unclear licensing status, limiting the development of truly open models. This problem is exacerbated for non-English languages, where openly licensed text remains critically scarce. We introduce the German Commons, the largest collection of openly licensed German text to date. It compiles data from 41 sources across seven domains, encompassing legal, scientific, cultural, political, news, economic, and web text. Through systematic sourcing from established data providers with verifiable licensing, it yields 154.56 billion tokens of high-quality text for language model training. Our processing pipeline implements comprehensive quality filtering, deduplication, and text formatting fixes, ensuring consistent quality across heterogeneous text sources. All domain subsets feature licenses of at least CC-BY-SA 4.0 or equivalent, ensuring legal compliance for model training and redistribution. The German Commons therefore addresses the critical gap in openly licensed German pretraining data, and enables the development of truly open German language models. We also release code for corpus construction and data filtering tailored to German language text, rendering the German Commons fully reproducible and extensible."

[17.10.2025 06:19] Response: ```python
['OPEN_SOURCE', 'LOW_RESOURCE']
```
[17.10.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The German Commons is a comprehensive dataset designed to support the training of German language models by providing openly licensed text. It includes 154.56 billion tokens sourced from 41 different domains, ensuring a diverse range of topics such as legal, scientific, and cultural content. The dataset is meticulously processed to maintain high quality through filtering and deduplication, making it suitable for machine learning applications. By offering legally compliant data, the German Commons fills a significant gap in the availability of German language resources for AI development.","title":"Empowering German Language Models with Open Data"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The German Commons is a comprehensive dataset designed to support the training of German language models by providing openly licensed text. It includes 154.56 billion tokens sourced from 41 different domains, ensuring a diverse range of topics such as legal, scientific, and cultural content. The dataset is meticulously processed to maintain high quality through filtering and deduplication, making it suitable for machine learning applications. By offering legally compliant data, the German Commons fills a significant gap in the availability of German language resources for AI development.', title='Empowering German Language Models with Open Data'))
[17.10.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"德国公共数据集提供了一个大规模、开放许可的德语文本数据集，旨在解决德语训练数据稀缺的问题。该数据集汇集了来自41个来源的文本，涵盖法律、科学、文化、政治、新闻、经济和网络等七个领域，共计1545.6亿个高质量标记。通过系统化的数据来源和严格的质量过滤，该数据集确保了文本的一致性和合法性，适合用于语言模型的训练和再分发。德国公共数据集的发布为开放许可的德语预训练数据填补了重要空白，促进了真正开放的德语语言模型的发展。","title":"德国公共数据集：开放德语模型的关键"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='德国公共数据集提供了一个大规模、开放许可的德语文本数据集，旨在解决德语训练数据稀缺的问题。该数据集汇集了来自41个来源的文本，涵盖法律、科学、文化、政治、新闻、经济和网络等七个领域，共计1545.6亿个高质量标记。通过系统化的数据来源和严格的质量过滤，该数据集确保了文本的一致性和合法性，适合用于语言模型的训练和再分发。德国公共数据集的发布为开放许可的德语预训练数据填补了重要空白，促进了真正开放的德语语言模型的发展。', title='德国公共数据集：开放德语模型的关键'))
[17.10.2025 06:19] Using data from previous issue: {"categories": ["#security", "#hallucinations", "#alignment", "#benchmark", "#rag"], "emoji": "🚫", "ru": {"title": "Когда AI должен сказать «не знаю»: тестируем умение моделей отказываться отвечать", "desc": "Исследователи обнаружили критическую проблему в RAG-системах: языковые модели плохо справля
[17.10.2025 06:19] Using data from previous issue: {"categories": ["#diffusion", "#dataset", "#transfer_learning", "#multimodal", "#cv"], "emoji": "🤝", "ru": {"title": "Анимация взаимодействий через позы близкого контакта", "desc": "Ponimator — это фреймворк для генерации анимаций взаимодействия двух людей на основе поз близкого контакта из motion c
[17.10.2025 06:19] Using data from previous issue: {"categories": ["#agents", "#reasoning", "#multimodal", "#alignment", "#ethics", "#benchmark"], "emoji": "🦸", "ru": {"title": "Супергерои из разных вселенных: проверка LLM на последовательность ролевой игры", "desc": "Исследователи создали бенчмарк Beyond One World для оценки способности LLM последо
[17.10.2025 06:19] Renaming data file.
[17.10.2025 06:19] Renaming previous data. hf_papers.json to ./d/2025-10-17.json
[17.10.2025 06:19] Saving new data file.
[17.10.2025 06:19] Generating page.
[17.10.2025 06:19] Renaming previous page.
[17.10.2025 06:19] Renaming previous data. index.html to ./d/2025-10-17.html
[17.10.2025 06:19] Writing result.
[17.10.2025 06:19] Renaming log file.
[17.10.2025 06:19] Renaming previous data. log.txt to ./logs/2025-10-17_last_log.txt
