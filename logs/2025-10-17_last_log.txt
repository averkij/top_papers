[17.10.2025 11:11] Read previous papers.
[17.10.2025 11:11] Generating top page (month).
[17.10.2025 11:11] Writing top page (month).
[17.10.2025 12:22] Read previous papers.
[17.10.2025 12:22] Get feed.
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14545
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14975
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14359
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14979
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14847
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14943
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14972
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14967
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14973
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04849
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14528
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13998
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10518
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14958
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14763
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09033
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14902
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14616
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14300
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13217
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14276
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13054
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14880
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14978
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14211
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14969
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13996
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13454
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14974
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14955
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14949
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14252
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13697
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14976
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14351
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13910
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.10390
[17.10.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06694
[17.10.2025 12:22] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.10.2025 12:22] No deleted papers detected.
[17.10.2025 12:22] Downloading and parsing papers (pdf, html). Total: 38.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14545.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14545.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14545.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14975.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14975.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14975.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14359.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14359.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14359.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14979.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14979.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14979.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14847.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14847.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14847.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14943.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14943.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14943.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14972.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14972.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14972.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14967.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14967.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14967.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14973.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14973.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14973.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.04849.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.04849.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.04849.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14528.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14528.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14528.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.13998.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.13998.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.13998.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.10518.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.10518.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.10518.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14958.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14958.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14958.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14763.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14763.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14763.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.09033.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.09033.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.09033.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14902.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14902.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14902.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14616.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14616.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14616.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14300.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14300.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14300.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.13217.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.13217.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.13217.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14276.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14276.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14276.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.13054.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.13054.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.13054.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14880.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14880.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14880.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14978.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14978.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14978.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14211.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14211.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14211.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14969.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14969.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14969.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.13996.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.13996.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.13996.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.13454.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.13454.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.13454.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14974.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14974.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14974.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14955.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14955.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14955.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14949.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14949.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14949.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14252.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14252.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14252.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.13697.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.13697.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.13697.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14976.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14976.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14976.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.14351.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.14351.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.14351.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.13910.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.13910.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.13910.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.10390.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.10390.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.10390.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2510.06694.
[17.10.2025 12:22] Extra JSON file exists (./assets/json/2510.06694.json), skip PDF parsing.
[17.10.2025 12:22] Paper image links file exists (./assets/img_data/2510.06694.json), skip HTML parsing.
[17.10.2025 12:22] Success.
[17.10.2025 12:22] Enriching papers with extra data.
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 0. AEPO, an agentic RL algorithm, addresses entropy-related challenges in web agent training, enhancing performance and stability across various datasets.  					AI-generated summary 				 Recently, Agentic Reinforcement Learning (Agentic RL) has made significant progress in incentivizing the multi-turn,...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 1. A diffusion-based model addresses copy-paste artifacts in text-to-image generation by using a large-scale paired dataset and a contrastive identity loss to balance identity fidelity and variation.  					AI-generated summary 				 Identity-consistent generation has become an important focus in text-to...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 2. Alpha-Service, a unified framework for proactive AI assistance, uses a multi-agent system on AI glasses to detect service opportunities and provide timely, personalized assistance.  					AI-generated summary 				 In an era where AI is evolving from a passive tool into an active and adaptive companio...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 3. NEO, a novel family of native Vision-Language Models, addresses fundamental constraints and integrates vision and language within a unified framework, achieving competitive performance with limited data.  					AI-generated summary 				 The edifice of native Vision-Language Models (VLMs) has emerged ...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 4. ImagerySearch, a prompt-guided adaptive test-time search strategy, enhances video generation in imaginative scenarios by dynamically adjusting search spaces and reward functions, outperforming existing methods on a new benchmark, LDT-Bench.  					AI-generated summary 				 Video generation models hav...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 5. LaSeR, a reinforcement learning algorithm, enhances Large Language Models by aligning last-token self-rewarding scores with verifier-based reasoning rewards, improving reasoning performance and inference-time scaling.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RL...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 6. Misaligned tokenization in large language models for code leads to inconsistent model behavior, necessitating grammar-aware tokenization.  					AI-generated summary 				 Large language models (LLMs) for code rely on subword tokenizers, such as byte-pair encoding (BPE), learned from mixed natural lan...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 7. Information Gain-based Policy Optimization (IGPO) enhances multi-turn reasoning in large language models by providing dense intrinsic rewards derived from the model's belief updates, improving accuracy and sample efficiency.  					AI-generated summary 				 Large language model (LLM)-based agents are...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 8. Elastic-Cache optimizes key-value cache management in diffusion large language models to reduce decoding latency without sacrificing prediction accuracy.  					AI-generated summary 				 This work studies how to adaptively recompute key-value (KV) caches for diffusion large language models (DLMs) to ...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 9. PsiloQA, a multilingual dataset with span-level hallucinations, enhances hallucination detection in large language models across 14 languages using an automated pipeline and encoder-based models.  					AI-generated summary 				 Hallucination detection remains a fundamental challenge for the safe and...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 10. PaddleOCR-VL, a vision-language model combining NaViT-style visual encoder and ERNIE-4.5 language model, achieves state-of-the-art performance in document parsing with minimal resource consumption.  					AI-generated summary 				 In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 11. BitNet Distillation fine-tunes large language models to 1.58-bit precision using SubLN, multi-head attention distillation, and continual pre-training, achieving comparable performance with significant memory and inference speed improvements.  					AI-generated summary 				 In this paper, we present ...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 12. VideoReward Thinker enhances multimodal reward models with visual reasoning operations and a configurable memory window, improving accuracy on video preference benchmarks.  					AI-generated summary 				 Recent advancements in multimodal reward models (RMs) have substantially improved post-training ...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 13. MathCanvas enhances Large Multimodal Models with Visual Chain-of-Thought capabilities for mathematics through pre-training on diagram generation and fine-tuning on visual-textual reasoning, achieving significant improvements on math benchmarks.  					AI-generated summary 				 While Large Language Mo...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 14. COIG-Writer, a Chinese creative writing dataset, reveals that process supervision and general-purpose data are crucial for creative writing, with cultural-bound capabilities and lexical diversity impacting performance.  					AI-generated summary 				 Large language models exhibit systematic deficien...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 15. LLMs process factual queries and hallucinations similarly when associated with subject knowledge, leading to indistinguishable internal representations, but produce distinct representations for hallucinations without subject knowledge.  					AI-generated summary 				 Recent work suggests that large ...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 16. A novel agentic framework, VLA^2, enhances vision-language-action models by integrating external modules like web retrieval and object detection, improving generalization to unseen objects and descriptions.  					AI-generated summary 				 Current vision-language-action (VLA) models, pre-trained on l...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 17. Generative reward models with explicit reasoning chains outperform sequence-based reward models and zero-shot language models in preference learning for creative writing, indicating the need for intermediate reasoning in capturing subjective quality.  					AI-generated summary 				 Current preferenc...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 18. AdaMoE, a Mixture-of-Experts architecture, enhances VLA models by leveraging pretrained weights and improving computational efficiency, achieving superior performance in robotic manipulation tasks.  					AI-generated summary 				 Vision-Language-Action (VLA) models are experiencing rapid development...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 19. LATTICE, a hierarchical retrieval framework, enables efficient and accurate reasoning over large document collections using a semantic tree structure and a traversal algorithm that calibrates relevance scores.  					AI-generated summary 				 Modern IR systems are increasingly tasked with answering c...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 20. Qwen3Guard introduces multilingual safety guardrail models with fine-grained tri-class judgments and real-time token-level safety monitoring for large language models.  					AI-generated summary 				 As large language models (LLMs) become more capable and widely used, ensuring the safety of their ou...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 21. ...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 22. mxbai-edge-colbert-v0 models, with 17M and 32M parameters, demonstrate superior retrieval performance on short-text and long-context benchmarks compared to ColBERTv2.  					AI-generated summary 				 In this work, we introduce mxbai-edge-colbert-v0 models, at two different parameter counts: 17M and 3...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 23. A new training paradigm for image editing models uses unrolled diffusion models and vision-language feedback to achieve performance comparable to supervised models without paired data.  					AI-generated summary 				 Recent image editing models have achieved impressive results while following natura...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 24. LiteStage, a latency-aware layer skipping framework, enhances multi-stage reasoning by optimizing layer budgets and suppressing redundant output tokens, achieving significant speedup with minimal accuracy loss.  					AI-generated summary 				 Multi-stage reasoning has emerged as an effective strateg...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 25. ...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 26. The German Commons provides a large-scale, openly licensed dataset for training German language models, addressing the scarcity of such data.  					AI-generated summary 				 Large language model development relies on large-scale training corpora, yet most contain data of unclear licensing status, li...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 27. VIST3A combines latent text-to-video models and 3D reconstruction systems to generate high-quality 3D scenes from text, improving upon prior methods.  					AI-generated summary 				 The rapid progress of large, pretrained models for both visual content generation and 3D reconstruction opens up new p...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 28. Policy-based flow models enable efficient and high-quality image generation by distilling teacher models into student models with dynamic flow velocities, improving diversity and quality.  					AI-generated summary 				 Few-step diffusion or flow-based generative models typically distill a velocity-...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 29. RealDPO, a novel preference learning paradigm using real-world data, enhances motion realism in video generative models through Direct Preference Optimization and iterative self-correction.  					AI-generated summary 				 Video generative models have recently achieved notable advancements in synthes...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 30. A new benchmark and encoder-based mitigation strategy improve multimodal generative models' performance on dialectal textual input without degrading performance on Standard American English.  					AI-generated summary 				 Contact languages like English exhibit rich regional variations in the form o...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 31. The MoM framework enhances RAG by transforming text processing from passive chunking to proactive understanding, enabling LLMs to generate structured document memories and SLMs to develop human-like reading abilities.  					AI-generated summary 				 The traditional RAG paradigm, which typically enga...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 32. Extending the context window and adapting to a new rotary positional embedding scaling parameter improve repository-level code completion in OpenCoder, achieving performance comparable to larger models with less data.  					AI-generated summary 				 Repository-level pretraining is commonly used to e...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 33. Ponimator uses conditional diffusion models to generate and synthesize interactive poses from motion capture data, enabling versatile interaction animation tasks.  					AI-generated summary 				 Close-proximity human-human interactive poses convey rich contextual information about interaction dynami...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 34. Beyond One World benchmark evaluates LLMs' ability to consistently portray version-specific superheroes across different canons through factual recall and ethical reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) are increasingly used as role-playing agents, yet their cap...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 35. RAGCap-Bench evaluates intermediate tasks in agentic RAG workflows, highlighting the importance of enhancing these capabilities for better end-to-end performance.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) mitigates key limitations of Large Language Models (LLMs)-such as fa...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 36. RefusalBench evaluates the selective refusal capability of language models in RAG systems using programmatically generated test cases, revealing systematic failure patterns and offering a path for improvement.  					AI-generated summary 				 The ability of language models in RAG systems to selective...
[17.10.2025 12:22] ********************************************************************************
[17.10.2025 12:22] Abstract 37. SCas4D, a cascaded optimization framework using 3D Gaussian Splatting, efficiently models dynamic scenes by leveraging hierarchical deformation patterns, enabling fast convergence and high-quality results in various tasks.  					AI-generated summary 				 Persistent dynamic scene modeling for trackin...
[17.10.2025 12:22] Read previous papers.
[17.10.2025 12:22] Generating reviews via LLM API.
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#agents", "#rl", "#training", "#optimization"], "emoji": "⚖️", "ru": {"title": "Балансировка энтропии для стабильного обучения веб-агентов", "desc": "AEPO — это алгоритм обучения с подкреплением для агентов, который решает проблемы, связанные с энтропией при обучении веб-агентов. Ал
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#dataset", "#cv", "#training", "#diffusion", "#benchmark"], "emoji": "🎭", "ru": {"title": "Генерация лиц без копипаста: баланс идентичности и разнообразия", "desc": "Исследователи решают проблему «копипаста» в text-to-image моделях, когда AI просто копирует референсное лицо вместо с
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#agents", "#agi", "#multimodal", "#optimization", "#games", "#interpretability"], "emoji": "🤖", "ru": {"title": "Проактивный AI: помощник, который предугадывает ваши нужды", "desc": "В статье представлена система Alpha-Service, которая использует AI-очки для проактивной помощи польз
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#agi", "#multimodal", "#alignment", "#architecture", "#open_source"], "emoji": "🔗", "ru": {"title": "NEO: нативные Vision-Language модели с единым представлением", "desc": "Статья представляет NEO — новое семейство нативных Vision-Language Models (VLM), которые интегрируют визуальну
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#video", "#benchmark", "#optimization", "#long_context"], "emoji": "🎨", "ru": {"title": "Адаптивный поиск для креативной видеогенерации", "desc": "Статья представляет ImagerySearch - метод адаптивного поиска во время инференса для улучшения генерации видео в творческих сценариях. Ос
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#rlhf", "#training", "#optimization"], "emoji": "🎯", "ru": {"title": "Самооценка через последний токен для улучшения reasoning", "desc": "LaSeR — это алгоритм reinforcement learning, который улучшает reasoning способности LLM путём объединения генерации решений 
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#data", "#plp", "#dataset", "#architecture"], "emoji": "🔤", "ru": {"title": "Проблема токенизации кода: когда пробелы меняют поведение модели", "desc": "Исследователи обнаружили серьёзную проблему в языковых моделях для кода: статистические токениз
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#agents", "#rl", "#reasoning", "#rlhf", "#training", "#optimization"], "emoji": "🎯", "ru": {"title": "Плотные награды через прирост информации для многошагового обучения агентов", "desc": "Статья представляет метод IGPO для улучшения обучения LLM-агентов с помощью reinforcement lear
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#training", "#inference", "#architecture", "#optimization", "#diffusion"], "emoji": "⚡", "ru": {"title": "Умное кэширование для ускорения диффузионных языковых моделей", "desc": "Статья предлагает метод Elastic-Cache для оптимизации управления key-value кэшем в диффузионных LLM. Авт
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#hallucinations", "#low_resource", "#multilingual", "#dataset"], "emoji": "🍄", "ru": {"title": "Поймать галлюцинацию: детекция на уровне фрагментов в 14 языках", "desc": "В статье представлен PsiloQA — крупный многоязычный датасет для детекции галлюцинаций в LLM на уровне отдельных 
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#training", "#science", "#low_resource", "#benchmark"], "emoji": "📄", "ru": {"title": "Эффективное распознавание документов с минимальными ресурсами", "desc": "PaddleOCR-VL — это компактная vision-language модель для парсинга документов, объединяющая визуальный
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#training", "#inference", "#architecture", "#optimization", "#small_models"], "emoji": "🔽", "ru": {"title": "Сжатие LLM до тернарных весов с сохранением качества", "desc": "В статье представлен BitNet Distillation (BitDistill) — легковесный метод для дистилляции полноточных LLM в мо
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#multimodal", "#open_source", "#long_context", "#benchmark"], "emoji": "🎬", "ru": {"title": "Обучение AI размышлять визуально при оценке видео", "desc": "Статья представляет VideoReward Thinker — новый подход к мультимодальным моделям вознаграждения, который поз
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#multimodal", "#games", "#math", "#benchmark"], "emoji": "📐", "ru": {"title": "Визуальная цепочка рассуждений для математики", "desc": "MathCanvas — это фреймворк для обучения больших мультимодальных моделей решению математических задач с использованием виз
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#story_generation", "#multilingual", "#low_resource", "#dataset"], "emoji": "✍️", "ru": {"title": "Креативность AI требует баланса логики и языка", "desc": "Исследователи создали датасет COIG-Writer для обучения LLM креативному письму на китайском языке, содержащий 1665 примеров с п
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#data", "#interpretability", "#multimodal", "#hallucinations"], "emoji": "🎭", "ru": {"title": "LLM не знают, что они не знают: галлюцинации неотличимы от фактов", "desc": "Исследование показывает, что LLM обрабатывают фактические запросы и галлюцинации схожим образом, когда они связ
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#agi", "#benchmark", "#optimization", "#cv", "#agents"], "emoji": "🤖", "ru": {"title": "Агентный подход к обобщению VLA моделей на невиденные объекты", "desc": "Статья представляет VLA^2 — новый агентный фреймворк для улучшения vision-language-action моделей в робототехнике. Основна
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#reasoning", "#low_resource", "#dataset", "#story_generation"], "emoji": "✍️", "ru": {"title": "Рассуждения важнее классификации для оценки творческих текстов", "desc": "Исследователи создали WritingPreferenceBench — датасет из 1800 примеров творческих текстов
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#optimization", "#robotics", "#agi", "#benchmark", "#architecture"], "emoji": "🤖", "ru": {"title": "Совместная работа экспертов для эффективного управления роботами", "desc": "Архитектура AdaMoE использует подход Mixture-of-Experts для масштабирования Vision-Language-Action моделей,
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#rag", "#reasoning", "#optimization", "#benchmark"], "emoji": "🌳", "ru": {"title": "Поиск через семантическое дерево с логарифмической сложностью", "desc": "LATTICE — это фреймворк для information retrieval, который организует большие коллекции документов в виде семантического дерев
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#data", "#open_source", "#alignment", "#training", "#ethics", "#multilingual", "#low_resource", "#benchmark"], "emoji": "🛡️", "ru": {"title": "Многоязычная защита LLM с трёхуровневой классификацией и проверкой в реальном времени", "desc": "Qwen3Guard — это семейство многоязычных мод
[17.10.2025 12:22] Using data from previous issue: {"categories": [], "emoji": "🎯", "ru": {"title": "Оптимизация промптов через градиентный спуск в пространстве эмбеддингов", "desc": "Исследователи предлагают метод автоматической оптимизации промптов для языковых моделей, используя градиентный спуск непосредственно в пространстве эмбеддингов токенов
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#long_context", "#training", "#dataset", "#optimization", "#benchmark", "#small_models"], "emoji": "🔍", "ru": {"title": "Мощный поиск в кармане: компактные модели побеждают гигантов", "desc": "Исследователи представили mxbai-edge-colbert-v0 — компактные модели для поиска информации 
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#cv", "#rlhf", "#training", "#optimization", "#synthetic", "#diffusion", "#benchmark"], "emoji": "✂️", "ru": {"title": "Редактирование изображений без парных данных через обратную связь от VLM", "desc": "Авторы предлагают новую парадигму обучения моделей редактирования изображений, 
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#optimization", "#small_models", "#training", "#reasoning", "#inference"], "emoji": "⚡", "ru": {"title": "Ускорение многоэтапного рассуждения через умный пропуск слоёв", "desc": "LiteStage — это фреймворк для ускорения многоэтапного рассуждения в малых языковых моделях путём пропуск
[17.10.2025 12:22] Using data from previous issue: {"categories": [], "emoji": "🤝", "ru": {"title": "Когда AI модель не уверена — лучше спросить человека", "desc": "Исследователи предлагают метод, который позволяет LLM определять, когда они недостаточно уверены в ответе и нуждаются в помощи человека. Система использует специальный подход к калибровк
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#open_source", "#data", "#low_resource", "#dataset"], "emoji": "🇩🇪", "ru": {"title": "Немецкие общины: открытый датасет для немецких языковых моделей", "desc": "Исследователи представили German Commons — крупнейшую коллекцию текстов на немецком языке с открытыми лицензиями для обуче
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#3d", "#multimodal", "#alignment", "#training", "#optimization"], "emoji": "🎬", "ru": {"title": "От текста к 3D через видео: сшивание моделей для создания сцен", "desc": "VIST3A — это новый фреймворк для генерации 3D-сцен из текста, который объединяет latent text-to-video модели с с
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#training", "#optimization", "#cv", "#diffusion"], "emoji": "🌊", "ru": {"title": "Динамические траектории для быстрой генерации изображений", "desc": "Статья представляет pi-Flow — новый подход к дистилляции flow-based моделей генерации изображений. Вместо предсказания прямого пути 
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#video", "#dataset", "#alignment", "#optimization", "#training"], "emoji": "🎬", "ru": {"title": "Обучение на реальных видео делает AI-движения естественными", "desc": "RealDPO — новый метод обучения генеративных видео-моделей, который использует реальные видео как эталонные примеры 
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#multimodal", "#low_resource", "#benchmark", "#synthetic"], "emoji": "🗣️", "ru": {"title": "Обучение генеративных моделей понимать диалекты английского языка", "desc": "Исследователи создали новый бенчмарк для оценки мультимодальных генеративных моделей на шести диалектах английског
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#rag", "#reasoning", "#multimodal", "#training", "#interpretability"], "emoji": "🧠", "ru": {"title": "От пассивных чанков к активной памяти документов", "desc": "Статья представляет фреймворк MoM, который улучшает RAG-системы, превращая пассивное разделение текста на чанки в активно
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#transfer_learning", "#long_context", "#dataset", "#benchmark", "#training", "#data", "#architecture"], "emoji": "📁", "ru": {"title": "Эффективное завершение кода на уровне репозитория с минимальными данными", "desc": "Исследователи улучшили модель OpenCoder для завершения кода на у
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#diffusion", "#dataset", "#transfer_learning", "#multimodal", "#cv"], "emoji": "🤝", "ru": {"title": "Анимация взаимодействий через позы близкого контакта", "desc": "Ponimator — это фреймворк для генерации анимаций взаимодействия двух людей на основе поз близкого контакта из motion c
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#agents", "#reasoning", "#multimodal", "#alignment", "#ethics", "#benchmark"], "emoji": "🦸", "ru": {"title": "Супергерои из разных вселенных: проверка LLM на последовательность ролевой игры", "desc": "Исследователи создали бенчмарк Beyond One World для оценки способности LLM последо
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#optimization", "#agents", "#benchmark", "#rag", "#reasoning", "#hallucinations"], "emoji": "🔍", "ru": {"title": "Оценка промежуточных шагов в агентных RAG-системах", "desc": "Статья представляет RAGCap-Bench — новый бенчмарк для детальной оценки промежуточных задач в агентных RAG-с
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#security", "#hallucinations", "#alignment", "#benchmark", "#rag"], "emoji": "🚫", "ru": {"title": "Когда AI должен сказать «не знаю»: тестируем умение моделей отказываться отвечать", "desc": "Исследователи обнаружили критическую проблему в RAG-системах: языковые модели плохо справля
[17.10.2025 12:22] Using data from previous issue: {"categories": ["#optimization", "#3d"], "emoji": "🎯", "ru": {"title": "Быстрое моделирование динамических сцен через каскадную оптимизацию", "desc": "SCas4D — это новый фреймворк для моделирования динамических 3D-сцен с использованием 3D Gaussian Splatting. Ключевая идея заключается в том, что дефо
[17.10.2025 12:22] Renaming data file.
[17.10.2025 12:22] Renaming previous data. hf_papers.json to ./d/2025-10-17.json
[17.10.2025 12:22] Saving new data file.
[17.10.2025 12:22] Generating page.
[17.10.2025 12:22] Renaming previous page.
[17.10.2025 12:22] Renaming previous data. index.html to ./d/2025-10-17.html
[17.10.2025 12:22] Writing result.
[17.10.2025 12:22] Renaming log file.
[17.10.2025 12:22] Renaming previous data. log.txt to ./logs/2025-10-17_last_log.txt
