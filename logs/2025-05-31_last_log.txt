[30.05.2025 23:11] Read previous papers.
[30.05.2025 23:11] Generating top page (month).
[30.05.2025 23:11] Writing top page (month).
[31.05.2025 01:56] Read previous papers.
[31.05.2025 01:56] Get feed.
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23621
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23747
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23693
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22653
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23762
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23359
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23604
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23660
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23646
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23380
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22914
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23419
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22618
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23716
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20088
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22255
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22759
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23758
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23735
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21784
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23606
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23585
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22765
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23559
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22421
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23754
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23751
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23416
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22961
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17818
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22810
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14321
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23742
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23387
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20755
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18087
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23253
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22918
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21114
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18962
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23759
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23745
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23625
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20282
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19716
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23761
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22944
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22943
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22854
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22126
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19360
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19286
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19236
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23764
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23734
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23678
[31.05.2025 01:56] Extract page data from URL. URL: https://huggingface.co/papers/2505.23671
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23183
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22888
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21190
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20199
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18142
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23738
[31.05.2025 01:56] Extract page data from URL. URL: https://huggingface.co/papers/2505.22988
[31.05.2025 01:56] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20099
[31.05.2025 01:56] Extract page data from URL. URL: https://huggingface.co/papers/2505.14599
[31.05.2025 01:56] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.05.2025 01:56] No deleted papers detected.
[31.05.2025 01:56] Downloading and parsing papers (pdf, html). Total: 66.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23621.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23621.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23621.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23747.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23747.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23747.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23693.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23693.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23693.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22653.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22653.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22653.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23762.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23762.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23762.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23359.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23359.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23359.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23604.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23604.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23604.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23660.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23660.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23660.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23646.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23646.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23646.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23380.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23380.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23380.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22914.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22914.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22914.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23419.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23419.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23419.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22618.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22618.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22618.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23716.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23716.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23716.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.20088.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.20088.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.20088.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22255.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22255.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22255.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22759.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22759.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22759.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23758.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23758.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23758.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23735.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23735.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23735.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.21784.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.21784.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.21784.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23606.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23606.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23606.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23585.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23585.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23585.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22765.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22765.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22765.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23559.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23559.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23559.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22421.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22421.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22421.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23754.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23754.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23754.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23751.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23751.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23751.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23416.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23416.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23416.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22961.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22961.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22961.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.17818.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.17818.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.17818.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22810.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22810.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22810.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.14321.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.14321.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.14321.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23742.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23742.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23742.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23387.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23387.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23387.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.20755.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.20755.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.20755.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.18087.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.18087.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.18087.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23253.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23253.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23253.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22918.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22918.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22918.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.21114.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.21114.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.21114.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.18962.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.18962.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.18962.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23759.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23759.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23759.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23745.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23745.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23745.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23625.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23625.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23625.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.20282.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.20282.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.20282.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.19716.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.19716.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.19716.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23761.
[31.05.2025 01:56] Downloading paper 2505.23761 from http://arxiv.org/pdf/2505.23761v1...
[31.05.2025 01:56] Failed to download and parse paper https://huggingface.co/papers/2505.23761: 'LTChar' object is not iterable
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22944.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22944.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22944.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22943.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22943.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22943.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22854.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22854.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22854.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.22126.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.22126.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.22126.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.19360.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.19360.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.19360.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.19286.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.19286.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.19286.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.19236.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.19236.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.19236.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23764.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23764.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23764.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23734.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23734.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23734.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23678.
[31.05.2025 01:56] Extra JSON file exists (./assets/json/2505.23678.json), skip PDF parsing.
[31.05.2025 01:56] Paper image links file exists (./assets/img_data/2505.23678.json), skip HTML parsing.
[31.05.2025 01:56] Success.
[31.05.2025 01:56] Downloading and parsing paper https://huggingface.co/papers/2505.23671.
[31.05.2025 01:56] Downloading paper 2505.23671 from http://arxiv.org/pdf/2505.23671v1...
[31.05.2025 01:57] Extracting affiliations from text.
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 2 ] . [ 1 1 7 6 3 2 . 5 0 5 2 : r GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents Manish Shetty UC Berkeley Naman Jain UC Berkeley Jinjian Liu UC Berkeley Vijay Kethanaboyina UC Berkeley Koushik Sen UC Berkeley Ion Stoica UC Berkeley "
[31.05.2025 01:57] Response: ```python
["UC Berkeley"]
```
[31.05.2025 01:57] Deleting PDF ./assets/pdf/2505.23671.pdf.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.23183.
[31.05.2025 01:57] Extra JSON file exists (./assets/json/2505.23183.json), skip PDF parsing.
[31.05.2025 01:57] Paper image links file exists (./assets/img_data/2505.23183.json), skip HTML parsing.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.22888.
[31.05.2025 01:57] Extra JSON file exists (./assets/json/2505.22888.json), skip PDF parsing.
[31.05.2025 01:57] Paper image links file exists (./assets/img_data/2505.22888.json), skip HTML parsing.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.21190.
[31.05.2025 01:57] Extra JSON file exists (./assets/json/2505.21190.json), skip PDF parsing.
[31.05.2025 01:57] Paper image links file exists (./assets/img_data/2505.21190.json), skip HTML parsing.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.20199.
[31.05.2025 01:57] Extra JSON file exists (./assets/json/2505.20199.json), skip PDF parsing.
[31.05.2025 01:57] Paper image links file exists (./assets/img_data/2505.20199.json), skip HTML parsing.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.18142.
[31.05.2025 01:57] Extra JSON file exists (./assets/json/2505.18142.json), skip PDF parsing.
[31.05.2025 01:57] Paper image links file exists (./assets/img_data/2505.18142.json), skip HTML parsing.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.23738.
[31.05.2025 01:57] Extra JSON file exists (./assets/json/2505.23738.json), skip PDF parsing.
[31.05.2025 01:57] Paper image links file exists (./assets/img_data/2505.23738.json), skip HTML parsing.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.22988.
[31.05.2025 01:57] Downloading paper 2505.22988 from http://arxiv.org/pdf/2505.22988v1...
[31.05.2025 01:57] Extracting affiliations from text.
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 2 ] . [ 1 8 8 9 2 2 . 5 0 5 2 : r Model-Preserving Adaptive Rounding Albert Tseng Cornell University albert@cs.cornell.edu Zhaofeng Sun Cornell University zs453@cornell.edu Christopher De Sa Cornell University cdesa@cs.cornell.edu "
[31.05.2025 01:57] Response: ```python
["Cornell University"]
```
[31.05.2025 01:57] Deleting PDF ./assets/pdf/2505.22988.pdf.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.20099.
[31.05.2025 01:57] Extra JSON file exists (./assets/json/2505.20099.json), skip PDF parsing.
[31.05.2025 01:57] Paper image links file exists (./assets/img_data/2505.20099.json), skip HTML parsing.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Downloading and parsing paper https://huggingface.co/papers/2505.14599.
[31.05.2025 01:57] Downloading paper 2505.14599 from http://arxiv.org/pdf/2505.14599v1...
[31.05.2025 01:57] Extracting affiliations from text.
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 2 ] . [ 1 9 9 5 4 1 . 5 0 5 2 : r Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models Guangzhi Xiong1 , Eric Xie1 , Corey Williams1 , Myles Kim1 , Amir Hassan Shariatmadari1 , Sikun Guo1 , Stefan Bekiranov1 and Aidong Zhang1 1University of Virginia {hhu4zu, jrg4wx, cmw6pa, mbt8hz, ahs5ce, qkm6sq, sb3de, aidong}@virginia.edu "
[31.05.2025 01:57] Response: ```python
["University of Virginia"]
```
[31.05.2025 01:57] Deleting PDF ./assets/pdf/2505.14599.pdf.
[31.05.2025 01:57] Success.
[31.05.2025 01:57] Enriching papers with extra data.
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 0. Two post-training strategies, distillation and RLVR, enable inference-time scaling in table reasoning tasks, resulting in a model (Table-R1-Zero) that matches GPT-4.1's performance using fewer parameters and shows strong generalization.  					AI-generated summary 				 In this work, we present the fi...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 1. Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced performance on 2D visual tasks. However, improving their spatial intelligence remains a challenge. Existing 3D MLLMs always rely on additional 3D or 2.5D data to incorporate spatial awareness, restricting the...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 2. A new benchmark, VF-Eval, evaluates the capabilities of MLLMs in interpreting AI-generated content videos across four tasks, highlighting challenges and demonstrating benefits in video generation through human feedback alignment.  					AI-generated summary 				 MLLMs have been widely studied for vid...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 3. LLMs exhibit robustness to reward noise during post-training and achieve high performance using reasoning pattern rewards (RPR) in conjunction with noisy reward models.  					AI-generated summary 				 Recent studies on post-training large language models (LLMs) for reasoning through reinforcement le...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 4. ZeroGUI is an online learning framework that uses Vision-Language Models for task generation and reward estimation, enhancing GUI Agents' performance with minimal human intervention.  					AI-generated summary 				 The rapid advancement of large Vision-Language Models (VLMs) has propelled the develo...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 5. A new benchmark, VideoReasonBench, evaluates complex vision-centric video reasoning, finding that extended thinking budgets are crucial for improved performance compared to existing benchmarks.  					AI-generated summary 				 Recent studies have shown that long chain-of-thought (CoT) reasoning can s...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 6. EvoScale, an evolutionary and reinforcement learning-based method, enhances small language models' performance on real-world software engineering tasks by iteratively improving and refining outputs.  					AI-generated summary 				 Language models (LMs) perform well on standardized coding benchmarks ...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 7. Diffusion via Autoregressive models (D-AR) recasts the image diffusion process as a standard autoregressive task, achieving high-quality image generation with consistent previews and layout control using a large language model backbone.  					AI-generated summary 				 This paper presents Diffusion v...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 8. Large reasoning models exhibit varying susceptibility to hallucination depending on post-training pipelines, revealing critical cognitive behaviors and uncertainty misalignment as contributing factors.  					AI-generated summary 				 Recently evolved large reasoning models (LRMs) show powerful perfo...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 9. UniRL is a self-improving post-training method for unified multimodal large language models that uses generated images as training data, enhancing both generation and understanding tasks without external data.  					AI-generated summary 				 Unified multimodal large language models such as Show-o an...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 10. A multi-modal CAD reconstruction model leveraging vision-language models and reinforcement learning achieves state-of-the-art performance across various datasets, including real-world ones.  					AI-generated summary 				 Computer-Aided Design (CAD) plays a central role in engineering and manufactur...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 11. The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 12. A novel block-wise approximate KV Cache and confidence-aware parallel decoding strategy improve the inference speed of diffusion-based large language models without significant quality loss.  					AI-generated summary 				 Diffusion-based large language models (Diffusion LLMs) have shown promise for...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 13. AnySplat is a feed forward network that performs novel view synthesis without camera poses, using 3D Gaussian primitives and unified design for efficiency and quality across sparse and dense datasets.  					AI-generated summary 				 We introduce AnySplat, a feed forward network for novel view synthe...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 14. A new automated method using concept-based vectors and a Hierarchical Multi-Domain Regression model improves preference explanations and predictions for large language models.  					AI-generated summary 				 Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and reward models, a...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 15. KronSAE, a novel architecture using Kronecker product decomposition, enhances efficiency in training Sparse Autoencoders, while mAND, a differentiable binary AND function, improves interpretability and performance.  					AI-generated summary 				 Sparse Autoencoders (SAEs) have demonstrated signific...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 16. FAMA, an open science family of speech foundation models, provides transparency and competitive performance by leveraging open-source training data and code.  					AI-generated summary 				 The development of speech foundation models (SFMs) like Whisper and SeamlessM4T has significantly advanced the...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 17. LoRAShop, a framework for multi-concept image editing with LoRA models, leverages spatially coherent feature activation in Flux-style diffusion transformers to achieve seamless integration of multiple subjects or styles while preserving global context and identity.  					AI-generated summary 				 We...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 18. Transformers have been established as the most popular backbones in sequence modeling, mainly due to their effectiveness in in-context retrieval tasks and the ability to learn at scale. Their quadratic memory and time complexity, however, bound their applicability in longer sequences and so has moti...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 19. AIDSAFE uses multi-agent deliberation to create high-quality safety policy datasets, enhancing LLM safety without compromising utility.  					AI-generated summary 				 Safety reasoning is a recent paradigm where LLMs reason over safety policies before generating responses, thereby mitigating limitat...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 20. Muddit, a unified discrete diffusion transformer, achieves fast and high-quality generation across text and image modalities by integrating pretrained visual priors with a lightweight text decoder.  					AI-generated summary 				 Unified generation models aim to handle diverse tasks across modalitie...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 21. Reinforcement learning algorithms are fundamental to align large language models with human preferences and to enhance their reasoning capabilities. However, current reinforcement learning algorithms often suffer from training instability due to loose on-policy constraints and computational ineffici...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 22. A StressTest benchmark and synthetic Stress17k dataset are introduced to improve speech-aware language models' ability to interpret sentence stress in spoken language.  					AI-generated summary 				 Sentence stress refers to emphasis, placed on specific words within a spoken utterance to highlight ...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 23. SafeScientist is an AI framework that enhances safety in AI-driven scientific research through multiple defensive mechanisms and is validated using the SciSafetyBench benchmark.  					AI-generated summary 				 Recent advancements in large language model (LLM) agents have significantly accelerated sc...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 24. GeoDrive integrates robust 3D geometry into driving world models to improve spatial understanding and action controllability in autonomous navigation, enhancing safety and reliability.  					AI-generated summary 				 Recent advancements in world models have revolutionized dynamic environment simulat...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 25. DeepTheorem enhances LLM theorem-proving through a large-scale natural language dataset and a tailored reinforcement learning strategy, achieving state-of-the-art results in informal theorem proving.  					AI-generated summary 				 Theorem proving serves as a major testbed for evaluating complex rea...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 26. REOrder discovers task-optimal patch orderings for long-sequence transformers, significantly improving accuracy over traditional ordering methods.  					AI-generated summary 				 Sequence models such as transformers require inputs to be represented as one-dimensional sequences. In vision, this typic...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 27. Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces KVzip, a query-agnostic KV cache eviction method enabli...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 28. ToMAP enhances LLM persuaders with Theory of Mind modules, improving opponent awareness and argument quality.  					AI-generated summary 				 Large language models (LLMs) have shown promising potential in persuasion, but existing works on training LLM persuaders are still preliminary. Notably, while...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 29. PatientSim generates diverse and realistic patient personas using clinical data to evaluate LLMs in medical dialogue settings.  					AI-generated summary 				 Doctor-patient consultations require multi-turn, context-aware communication tailored to diverse patient personas. Training or evaluating doc...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 30. VidText is a new benchmark that evaluates video text understanding across various tasks, covering global summarization and local retrieval, and highlights challenges for current multimodal models.  					AI-generated summary 				 Visual texts embedded in videos carry rich semantic information, which ...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 31. Existing video understanding benchmarks often conflate knowledge-based and purely image-based questions, rather than clearly isolating a model's temporal reasoning ability, which is the key aspect that distinguishes video understanding from other modalities. We identify two major limitations that ob...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 32. Video generation has made substantial strides with the emergence of deep generative models, especially diffusion-based approaches. However, video generation based on multiple reference subjects still faces significant challenges in maintaining multi-subject consistency and ensuring high generation q...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 33. A novel test-time iterative optimization framework using reinforcement learning continuously enhances code efficiency generated by large language models.  					AI-generated summary 				 Large Language Models (LLMs) generate functionally correct solutions but often fall short in code efficiency, a cr...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 34. Uni-Instruct unifies and enhances one-step diffusion distillation methods through a novel diffusion expansion theory, achieving state-of-the-art performance in unconditional and conditional image generation and text-to-3D generation.  					AI-generated summary 				 In this paper, we unify more than ...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 35. CheXStruct and CXReasonBench evaluate Large Vision-Language Models in clinical diagnosis by assessing structured reasoning, visual grounding, and generalization using the MIMIC-CXR-JPG dataset.  					AI-generated summary 				 Recent progress in Large Vision-Language Models (LVLMs) has enabled promis...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 36. UniTEX generates high-quality, consistent 3D textures by using Texture Functions and adapting Diffusion Transformers directly from images and geometry without UV mapping.  					AI-generated summary 				 We present UniTEX, a novel two-stage 3D texture generation framework to create high-quality, cons...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 37. Re-ttention uses temporal redundancy in diffusion models to enable high sparse attention in visual generation, maintaining quality with minimal computational overhead.  					AI-generated summary 				 Diffusion Transformers (DiT) have become the de-facto model for generating high-quality visual conte...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 38. Researchers propose a novel differentiable solver search algorithm that optimizes the computational efficiency and quality of diffusion models for image generation tasks.  					AI-generated summary 				 Diffusion models have demonstrated remarkable generation quality but at the cost of numerous func...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 39. System-1.5 Reasoning improves the efficiency and performance of large language models by dynamically allocating computation through adaptive shortcuts in latent space, leading to faster inference and reduced token generation.  					AI-generated summary 				 Chain-of-thought (CoT) reasoning enables l...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 40. Rebus puzzles, visual riddles that encode language through imagery, spatial arrangement, and symbolic substitution, pose a unique challenge to current vision-language models (VLMs). Unlike traditional image captioning or question answering tasks, rebus solving requires multi-modal abstraction, symbo...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 41. TrustVLM enhances the reliability of Vision-Language Models by estimating prediction trustworthiness without retraining, improving misclassification detection in multimodal tasks.  					AI-generated summary 				 Vision-Language Models (VLMs) have demonstrated strong capabilities in aligning visual a...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 42. ZeroSep, a text-guided audio diffusion model, achieves zero-shot source separation through pre-trained models and text conditioning, outperforming supervised methods on various benchmarks.  					AI-generated summary 				 Audio source separation is fundamental for machines to understand complex acous...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 43. Entropy minimization with one sample and minimal optimization achieves significant performance improvements for large language models.  					AI-generated summary 				 We trained 13,440 large language models and found that entropy minimization requires only a single unlabeled data and 10 steps optimi...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 44. Existing chain-of-thought (CoT) distillation methods can effectively transfer reasoning abilities to base models but suffer from two major limitations: excessive verbosity of reasoning traces and inadequate adaptability to problem difficulty. Long reasoning traces significantly increase inference co...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 45. Theoretical analysis of Direct Preference Optimization (DPO) reveals that log-ratio reward parameterization is optimal for learning target policy via preference optimization, linked to log-margin ordered policies, and explains policy reinforcement and smoothing based on differential information entr...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 46. We propose a unified framework for motion control in video generation that seamlessly integrates camera movement, object-level translation, and fine-grained local motion using trajectory-based inputs. In contrast to prior methods that address these motion types through separate modules or task-speci...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 47. A benchmark using deceptive text samples to evaluate compositional vulnerabilities in multimodal representations is introduced, and a self-training approach improves zero-shot methods by enhancing attack success and sample diversity.  					AI-generated summary 				 While pre-trained multimodal repre...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 48. Gaussian Splatting (GS) has recently emerged as an efficient representation for rendering 3D scenes from 2D images and has been extended to images, videos, and dynamic 4D content. However, applying style transfer to GS-based representations, especially beyond simple color changes, remains challengin...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 49. The introduction of SridBench, a benchmark for scientific figure generation, reveals that current top-tier models, such as GPT-4o-image, fall short in semantic and structural accuracy compared to human performance, underscoring the need for more advanced multimodal reasoning-driven visual generation...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 50. ChartLens enhances multimodal language models with fine-grained visual attributions, improving the accuracy of chart understanding by 26-66%.  					AI-generated summary 				 The growing capabilities of multimodal large language models (MLLMs) have advanced tasks like chart understanding. However, th...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 51. The study explores the structural patterns of knowledge in large language models from a graph perspective, uncovering knowledge homophily and developing models for graph machine learning to estimate entity knowledge.  					AI-generated summary 				 Large language models have been extensively studied...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 52. A novel pairwise-comparison framework using CreataSet dataset trains CrEval, an LLM-based evaluator that significantly improves the assessment of textual creativity aligned with human judgments.  					AI-generated summary 				 Creativity evaluation remains a challenging frontier for large language m...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 53. Spatial intelligence is essential for multimodal large language models (MLLMs) operating in the complex physical world. Existing benchmarks, however, probe only single-image relations and thus fail to assess the multi-image spatial reasoning that real-world deployments demand. We introduce MMSI-Benc...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 54. ZPressor, a lightweight module, compresses multi-view inputs for feed-forward 3D Gaussian Splatting models, enhancing their scalability and performance under dense view settings.  					AI-generated summary 				 Feed-forward 3D Gaussian Splatting (3DGS) models have recently emerged as a promising sol...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 55. ViGoRL, a vision-language model enhanced with visually grounded reinforcement learning, achieves superior performance across various visual reasoning tasks by dynamically focusing visual attention and grounding reasoning in spatial evidence.  					AI-generated summary 				 While reinforcement learni...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 56. A benchmark evaluates high-performance software development capabilities of language models, identifying significant challenges and failure modes.  					AI-generated summary 				 Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 57. Evaluation of word-level quality estimation techniques leverages model interpretability and uncertainty quantification to identify translation errors with a focus on the impact of label variation and the performance of supervised versus unsupervised metrics.  					AI-generated summary 				 Word-leve...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 58. Recent Large Reasoning Models (LRMs) with thinking traces have shown strong performance on English reasoning tasks. However, their ability to think in other languages is less studied. This capability is as important as answer accuracy for real world applications because users may find the reasoning ...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 59. The paper introduces LUNGUAGE, a benchmark for structured radiology report generation, and LUNGUAGESCORE, an evaluation metric, enabling fine-grained structured report evaluation and longitudinal interpretation.  					AI-generated summary 				 Radiology reports convey detailed clinical observations ...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 60. Adaptive Classifier-Free Guidance (A-CFG) dynamically adjusts the guidance in masked diffusion language models by focusing on areas of low model confidence, leading to significant improvements in language generation performance.  					AI-generated summary 				 Classifier-Free Guidance (CFG) signific...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 61. In this work, we reveal the limitations of visual tokenizers and VAEs in preserving fine-grained features, and propose a benchmark to evaluate reconstruction performance for two challenging visual contents: text and face. Visual tokenizers and VAEs have significantly advanced visual generation and m...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 62. We present a keyframe-based framework for generating music-synchronized, choreography aware animal dance videos. Starting from a few keyframes representing distinct animal poses -- generated via text-to-image prompting or GPT-4o -- we formulate dance synthesis as a graph optimization problem: find t...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 63. The main goal of post-training quantization (PTQ) is to produced a compressed model whose output distribution is as close to the original model's as possible. To do this tractably, almost all LLM PTQ algorithms quantize linear layers by independently minimizing the immediate activation error. Howeve...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 64. Large language models (LLMs) have demonstrated remarkable performance on question-answering (QA) tasks because of their superior capabilities in natural language understanding and generation. However, LLM-based QA struggles with complex QA tasks due to poor reasoning capacity, outdated knowledge, an...
[31.05.2025 01:57] ********************************************************************************
[31.05.2025 01:57] Abstract 65. Large language models (LLMs) have shown significant potential in scientific disciplines such as biomedicine, particularly in hypothesis generation, where they can analyze vast literature, identify patterns, and suggest research directions. However, a key challenge lies in evaluating the truthfulness...
[31.05.2025 01:57] Read previous papers.
[31.05.2025 01:57] Generating reviews via LLM API.
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#inference", "#rl", "#reasoning", "#dataset", "#training"], "emoji": "🧠", "ru": {"title": "Эффективное масштабирование для рассуждений над таблицами", "desc": "В этой статье представлено исследование масштабирования во время вывода для задач рассуждения над таблицам
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#3d", "#dataset", "#multimodal", "#architecture", "#reasoning", "#training"], "emoji": "🧠", "ru": {"title": "Пространственный интеллект из 2D наблюдений", "desc": "Статья представляет Spatial-MLLM - новую модель для пространственного анализа на основе только 2D изображений и видео. 
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#video", "#games", "#interpretability", "#benchmark", "#reasoning", "#alignment", "#rlhf"], "emoji": "🎥", "ru": {"title": "VF-Eval: новый рубеж в оценке ИИ-видео мультимодальными моделями", "desc": "Новый бенчмарк VF-Eval оценивает способности мультимодальных языковых моделей (MLLM)
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#rl", "#optimization", "#reasoning", "#training", "#rlhf"], "emoji": "🧠", "ru": {"title": "LLM устойчивы к шуму: вознаграждение за процесс важнее результата", "desc": "Исследование показывает, что большие языковые модели (LLM) демонстрируют устойчивость к шуму в функции вознагражден
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#agents", "#rl", "#optimization", "#games", "#rlhf"], "emoji": "🤖", "ru": {"title": "Автоматизация обучения ГПИ-агентов без участия человека", "desc": "ZeroGUI - это фреймворк онлайн-обучения, использующий визуально-языковые модели для генерации задач и оценки вознаграждений, что ул
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#reasoning", "#video", "#multimodal", "#benchmark"], "emoji": "🎥", "ru": {"title": "Глубокое рассуждение - ключ к пониманию видео искусственным интеллектом", "desc": "VideoReasonBench - это новый бенчмарк для оценки сложных задач рассуждения на основе видео. Он требует от моделей то
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#small_models", "#rl", "#optimization", "#open_source", "#training"], "emoji": "🧬", "ru": {"title": "Эволюционное масштабирование для повышения эффективности малых языковых моделей", "desc": "EvoScale - это метод, сочетающий эволюционное обучение и обучение с подкреплением для улучш
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#open_source", "#multimodal", "#diffusion", "#cv", "#benchmark"], "emoji": "🖼️", "ru": {"title": "D-AR: Диффузия изображений через авторегрессию", "desc": "Статья представляет новый подход к генерации изображений, называемый Diffusion via Autoregres
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#training", "#rl", "#reasoning", "#hallucinations"], "emoji": "🤖", "ru": {"title": "Галлюцинации в больших моделях рассуждений: причины и решения", "desc": "Это исследование изучает склонность к галлюцинациям у больших моделей рассуждений (LRM) в зависимости от различных методов пос
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#synthetic", "#open_source", "#multimodal", "#training", "#optimization"], "emoji": "🔄", "ru": {"title": "Самосовершенствование мультимодальных ИИ-моделей без внешних данных", "desc": "UniRL - это метод пост-обучения для универсальных мультимодальных языковых моделей, который исполь
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#3d", "#games", "#multimodal", "#benchmark"], "emoji": "🖥️", "ru": {"title": "Мультимодальная реконструкция CAD: объединяя зрение, язык и обучение с подкреплением", "desc": "Эта статья представляет новую мультимодальную модель для реконструкции C
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#benchmark", "#survey"], "emoji": "🔄", "ru": {"title": "SWE-bench-Live: Динамичный эталон для оценки ИИ в реальной разработке ПО", "desc": "Статья представляет SWE-bench-Live - новый эталонный тест для оценки возможностей больших языковых моделей в решен
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization", "#diffusion"], "emoji": "🚀", "ru": {"title": "Ускорение диффузионных ЯМ без потери качества", "desc": "Статья представляет новые методы для улучшения скорости вывода диффузионных языковых моделей. Авторы предлагают блочный приближенный KV-к
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "🎥", "ru": {"title": "Синтез новых ракурсов без калибровки камер", "desc": "AnySplat - это нейронная сеть прямого распространения для синтеза новых ракурсов на основе неоткалиброванных наборов изображений. Она предсказывает 3D гауссовы примитивы, кодирующие ге
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#dataset", "#data", "#interpretability", "#alignment", "#rlhf", "#training"], "emoji": "🧠", "ru": {"title": "Раскрывая тайны предпочтений в больших языковых моделях", "desc": "Этот научный труд представляет новый автоматизированный метод для объяснения и прогнозирования предпочтений
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training", "#interpretability"], "emoji": "🧠", "ru": {"title": "Эффективное обучение разреженных автоэнкодеров с помощью разложения Кронекера", "desc": "KronSAE - это новая архитектура, использующая разложение Кронекера для повышения эффективности 
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#science", "#audio", "#dataset", "#open_source", "#data"], "emoji": "🗣️", "ru": {"title": "FAMA: Открытая наука в речевых технологиях", "desc": "FAMA - это первое семейство открытых речевых фундаментальных моделей для английского и итальянского языков, обученных на более чем 150 тыс
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#story_generation", "#diffusion"], "emoji": "🎨", "ru": {"title": "Умное редактирование изображений с помощью ИИ", "desc": "LoRAShop - это новая система для редактирования изображений с использованием нескольких концепций на основе моделей LoRA. Она использует п
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#long_context", "#benchmark"], "emoji": "🧠", "ru": {"title": "ATLAS: Революция в долговременной памяти нейросетей", "desc": "Статья представляет ATLAS - новый модуль долговременной памяти для нейронных сетей. ATLAS преодолевает ограничения современных 
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#data", "#reasoning", "#agents", "#dataset", "#alignment", "#training", "#hallucinations", "#open_source"], "emoji": "🛡️", "ru": {"title": "Безопасные ИИ-ассистенты через многоагентное обсуждение политик", "desc": "AIDSAFE - это новый метод создания высококачественных наборов данных
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#architecture"], "emoji": "🔄", "ru": {"title": "Унифицированная мультимодальная генерация с помощью дискретной диффузии", "desc": "Muddit - это унифицированный дискретный диффузионный трансформер, объединяющий предобученные визуальные приоры с лег
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#math", "#reasoning", "#alignment", "#rlhf"], "emoji": "🧠", "ru": {"title": "OPO: Стабильное обучение с подкреплением для улучшения языковых моделей", "desc": "Статья представляет новый алгоритм обучения с подкреплением под названием OPO (On-Poli
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#audio", "#optimization", "#training", "#synthetic", "#benchmark", "#dataset"], "emoji": "🗣️", "ru": {"title": "Новый подход к пониманию фразового ударения в речевых ИИ-моделях", "desc": "Представлен бенчмарк StressTest и синтетический набор данных Stress17k для улучшения способност
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#agents", "#healthcare", "#ethics", "#science", "#benchmark", "#open_source", "#security"], "emoji": "🔬", "ru": {"title": "Безопасный ИИ-ученый: этичные исследования без компромиссов", "desc": "SafeScientist - это фреймворк искусственного интеллекта, который повышает безопасность на
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#games", "#agents", "#3d", "#training"], "emoji": "🚗", "ru": {"title": "GeoDrive: 3D-геометрия для безопасного автономного вождения", "desc": "GeoDrive - это новый подход к моделированию мира для автономного вождения, который интегрирует надежную 3D-геометрию для ул
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#math", "#rl", "#training", "#reasoning", "#benchmark", "#dataset"], "emoji": "🧠", "ru": {"title": "Прорыв в автоматическом доказательстве теорем с помощью естественного языка", "desc": "DeepTheorem - это комплексная система для неформального доказательства теорем с использованием б
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#rl", "#optimization", "#cv", "#training", "#long_context", "#architecture"], "emoji": "🧩", "ru": {"title": "Оптимальный порядок патчей - ключ к повышению точности трансформеров", "desc": "REOrder - это новый метод оптимизации порядка патчей для трансформеров с длинными последовател
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#training", "#inference", "#long_context", "#optimization", "#reasoning"], "emoji": "🗜️", "ru": {"title": "KVzip: Эффективное сжатие кэша для ускорения языковых моделей", "desc": "Статья представляет KVzip - метод сжатия кэша ключ-значение (KV) для больших языковых моделей на основе
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#agents", "#rl", "#training", "#reasoning", "#alignment"], "emoji": "🧠", "ru": {"title": "ToMAP: ИИ-убеждающий с пониманием оппонента", "desc": "Статья представляет ToMAP - новый подход к созданию более гибких агентов-убеждающих с использованием модулей теории разума. ToMAP улучшает
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#open_source", "#training", "#healthcare", "#dataset", "#science"], "emoji": "🩺", "ru": {"title": "Реалистичная симуляция пациентов для обучения ИИ в медицине", "desc": "PatientSim - это симулятор, генерирующий разнообразные и реалистичные профили пациентов для оценки языковых модел
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#survey", "#multimodal", "#reasoning", "#benchmark"], "emoji": "🎥", "ru": {"title": "VidText: Новый рубеж в понимании текста в видео", "desc": "VidText - это новый бенчмарк для оценки понимания текста в видео, охватывающий различные задачи от глобального обобщения до локального поис
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#interpretability", "#reasoning", "#video", "#benchmark"], "emoji": "🎥", "ru": {"title": "Детальная оценка понимания видео языковыми моделями", "desc": "Статья представляет VBenchComp - автоматизированный конвейер для категоризации вопросов в задачах понимания видео. Авторы выделяют
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#video", "#diffusion", "#benchmark", "#open_source"], "emoji": "🎬", "ru": {"title": "MAGREF: Революция в генерации видео с несколькими объектами", "desc": "Статья представляет MAGREF - новую систему для генерации видео на основе нескольких референсных изображений и текстового описан
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#rlhf", "#dataset", "#benchmark"], "emoji": "🚀", "ru": {"title": "Обучение с подкреплением: ключ к непрерывному улучшению эффективности кода", "desc": "Эта статья представляет новую систему оптимизации кода, генерируемого большими языковыми модел
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#3d", "#transfer_learning", "#cv", "#diffusion", "#dataset", "#math", "#optimization", "#benchmark"], "emoji": "🚀", "ru": {"title": "Uni-Instruct: Революция в одношаговой дистилляции диффузионных моделей", "desc": "Статья представляет Uni-Instruct - новый подход к одношаговой дистил
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#healthcare", "#dataset", "#science", "#multimodal", "#cv", "#benchmark", "#interpretability", "#reasoning"], "emoji": "🩻", "ru": {"title": "Структурированное рассуждение в медицинском ИИ: новый подход к оценке", "desc": "CheXStruct и CXReasonBench - это новые инструменты для оценки
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#3d", "#open_source", "#diffusion"], "emoji": "🎨", "ru": {"title": "Революция в 3D-текстурировании: UniTEX объединяет функциональное пространство и нейросети", "desc": "UniTEX - это новая двухэтапная система для генерации высококачественных и согласованных 3D-текстур. Она использует
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#training", "#video", "#diffusion", "#cv"], "emoji": "🎥", "ru": {"title": "Эффективное разреженное внимание для генерации видео и изображений", "desc": "Статья представляет новый метод под названием Re-ttention для оптимизации механизма внимания в д
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#training", "#diffusion", "#data", "#cv", "#architecture"], "emoji": "🔍", "ru": {"title": "Эффективный поиск решателя для ускорения диффузионных моделей", "desc": "Исследователи предлагают новый алгоритм дифференцируемого поиска решателя для оптимизации вычислительн
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#inference", "#architecture", "#training", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эффективное рассуждение в латентном пространстве для ускорения работы ИИ", "desc": "Статья представляет метод System-1.5 Reasoning, который повышает эффективность крупных языков
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#interpretability", "#reasoning", "#multimodal", "#benchmark", "#dataset", "#cv"], "emoji": "🧩", "ru": {"title": "Визуально-языковые модели vs. ребусы: вызов для искусственного интеллекта", "desc": "В этой статье исследуется способность современных визуально-языковых моделей (VLM) и
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal", "#interpretability", "#benchmark", "#architecture", "#security"], "emoji": "🔍", "ru": {"title": "Повышение надежности мультимодальных моделей без переобучения", "desc": "TrustVLM - это новый подход к повышению надежности мультимодальных моделей ма
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#transfer_learning", "#audio", "#benchmark", "#diffusion"], "emoji": "🎵", "ru": {"title": "Разделение аудиоисточников без обучения с помощью текстовых подсказок", "desc": "ZeroSep - это модель разделения аудиоисточников на основе диффузии, управляемой текстом. Она достигает разделен
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training"], "emoji": "🚀", "ru": {"title": "Революция в обучении языковых моделей: максимальный эффект при минимальных затратах", "desc": "Исследователи обнаружили, что минимизация энтропии с использованием всего одного образца данных и минимальной оптимизаци
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#benchmark", "#architecture", "#reasoning", "#data", "#training", "#optimization", "#dataset"], "emoji": "🧠", "ru": {"title": "Эффективное обучение рассуждениям с адаптивной сложностью", "desc": "Статья предлагает новый метод дистилляции цепочек рассуждений (CoT) для языковых моделе
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#training", "#alignment", "#synthetic", "#rlhf"], "emoji": "🧠", "ru": {"title": "Теоретическое обоснование DPO через призму дифференциальной информации", "desc": "Данная статья представляет теоретический анализ метода Direct Preference Optimizat
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#video"], "emoji": "🎥", "ru": {"title": "Универсальное управление движением в генерации видео на основе траекторий", "desc": "Предложен единый подход к управлению движением при генерации видео, объединяющий перемещение камеры, движение объектов и локальные изменения на основе траект
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#hallucinations", "#multimodal", "#benchmark", "#security", "#training"], "emoji": "🎭", "ru": {"title": "Раскрытие слабых мест мультимодальных моделей с помощью обманчивых текстов", "desc": "Статья представляет новый бенчмарк Multimodal Adversarial Compositionality (MAC) для оценки 
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#multimodal", "#3d", "#video"], "emoji": "🎨", "ru": {"title": "Универсальный перенос стиля для многомодальных данных с помощью гауссовского сплаттинга", "desc": "CLIPGaussians - это первая универсальная система переноса стиля для гауссовского сплаттинга, поддерживающая стилизацию по
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#benchmark", "#science", "#interpretability", "#multimodal", "#reasoning"], "emoji": "🔬", "ru": {"title": "SridBench: вызов ИИ в создании научных иллюстраций", "desc": "SridBench - это новый эталонный тест для оценки генерации научных иллюстраций искусственным интеллектом. Он включа
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#hallucinations", "#cv", "#benchmark"], "emoji": "📊", "ru": {"title": "Точное понимание графиков с помощью ChartLens", "desc": "ChartLens - это новый алгоритм для улучшения понимания графиков мультимодальными языковыми моделями. Он использует сегментацию
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#data", "#interpretability", "#graphs", "#architecture", "#dataset", "#reasoning", "#benchmark", "#training"], "emoji": "🕸️", "ru": {"title": "Графовый анализ раскрывает структуру знаний в языковых моделях", "desc": "Исследование изучает структурные паттерны знаний в больших языковы
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#creativity", "#dataset", "#open_source", "#data", "#benchmark"], "emoji": "🎨", "ru": {"title": "CrEval: Революция в автоматической оценке креативности текста", "desc": "Статья представляет новый фреймворк для оценки текстовой креативности, основанный на попарном сравнении. Авторы с
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#3d", "#reasoning", "#multimodal", "#open_source", "#interpretability", "#benchmark"], "emoji": "🧠", "ru": {"title": "MMSI-Bench: Новый рубеж в оценке пространственного интеллекта ИИ", "desc": "Статья представляет MMSI-Bench - новый бенчмарк для оценки пространственного интеллекта м
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#3d", "#architecture", "#optimization", "#benchmark"], "emoji": "🔬", "ru": {"title": "ZPressor: Эффективное сжатие многоракурсных данных для улучшения 3D Gaussian Splatting", "desc": "ZPressor - это легковесный модуль для сжатия многоракурсных входных данных в моделях прямого распро
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#games", "#multimodal", "#cv", "#training"], "emoji": "🔍", "ru": {"title": "ViGoRL: Визуальное мышление с опорой на пространство", "desc": "ViGoRL - это модель визуально-языкового обучения с подкреплением, которая динамически фокусирует визуальное внимание и осн
[31.05.2025 01:57] Querying the API.
[31.05.2025 01:57] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A benchmark evaluates high-performance software development capabilities of language models, identifying significant challenges and failure modes.  					AI-generated summary 				 Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research.
[31.05.2025 01:57] Response: {
  "desc": "Статья представляет новый бенчмарк GSO для оценки способностей языковых моделей в разработке высокопроизводительного программного обеспечения. Авторы создали автоматизированный конвейер, который генерирует и выполняет тесты производительности на основе истории коммитов репозиториев. Эксперименты показали, что ведущие ИИ-агенты для разработки ПО достигают менее 5% успеха в оптимизации кода. Анализ выявил ключевые проблемы, включая трудности с низкоуровневыми языками и точной локализацией узких мест в производительности.",
  "emoji": "🚀",
  "title": "Языковые модели пока не могут заменить разработчиков в оптимизации производительности"
}
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A benchmark evaluates high-performance software development capabilities of language models, identifying significant challenges and failure modes.  					AI-generated summary 				 Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research."

[31.05.2025 01:57] Response: ```python
['BENCHMARK', 'AGENTS', 'PLP']
```
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A benchmark evaluates high-performance software development capabilities of language models, identifying significant challenges and failure modes.  					AI-generated summary 				 Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research."

[31.05.2025 01:57] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE']
```
[31.05.2025 01:57] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces GSO, a benchmark designed to assess the capabilities of language models in developing high-performance software. It highlights the complexity of software development and the need for specialized skills to tackle optimization tasks. The study reveals that current software engineering agents have a low success rate of less than 5% in improving runtime efficiency, even when given detailed performance tests. Key challenges identified include difficulties with low-level programming languages and ineffective optimization strategies, which hinder the agents\' ability to localize performance bottlenecks accurately.","title":"Benchmarking Language Models for High-Performance Software Development"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces GSO, a benchmark designed to assess the capabilities of language models in developing high-performance software. It highlights the complexity of software development and the need for specialized skills to tackle optimization tasks. The study reveals that current software engineering agents have a low success rate of less than 5% in improving runtime efficiency, even when given detailed performance tests. Key challenges identified include difficulties with low-level programming languages and ineffective optimization strategies, which hinder the agents' ability to localize performance bottlenecks accurately.", title='Benchmarking Language Models for High-Performance Software Development'))
[31.05.2025 01:57] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一个名为GSO的基准测试，用于评估语言模型在开发高性能软件方面的能力。我们开发了一个自动化流程，生成并执行性能测试，以分析代码库的提交历史，识别出102个具有挑战性的优化任务。研究表明，领先的软件工程代理在这些任务中表现不佳，成功率不足5%。通过定性分析，我们发现了主要的失败模式，包括对低级语言的处理困难、懒惰优化策略的应用以及准确定位瓶颈的挑战。","title":"评估语言模型在高性能软件开发中的能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一个名为GSO的基准测试，用于评估语言模型在开发高性能软件方面的能力。我们开发了一个自动化流程，生成并执行性能测试，以分析代码库的提交历史，识别出102个具有挑战性的优化任务。研究表明，领先的软件工程代理在这些任务中表现不佳，成功率不足5%。通过定性分析，我们发现了主要的失败模式，包括对低级语言的处理困难、懒惰优化策略的应用以及准确定位瓶颈的挑战。', title='评估语言模型在高性能软件开发中的能力'))
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#multilingual", "#machine_translation", "#data", "#benchmark", "#interpretability"], "emoji": "🔍", "ru": {"title": "Эффективная оценка качества перевода: от интерпретируемости к точности", "desc": "Данная статья исследует методы оценки качества перевода на уровне слов, используя инт
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#training", "#long_context", "#reasoning", "#multilingual", "#benchmark"], "emoji": "🌐", "ru": {"title": "Многоязычное мышление ИИ: вызовы и перспективы", "desc": "Статья исследует способность крупных языковых моделей (LLM) рассуждать на разных языках. Авторы обнаружили, что даже пр
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#science", "#data", "#interpretability"], "emoji": "🏥", "ru": {"title": "Новый стандарт для оценки генерации радиологических отчетов", "desc": "Статья представляет LUNGUAGE - набор данных для генерации структурированных радиологических отчетов, и LUNGUAGESC
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#benchmark", "#training"], "emoji": "🎭", "ru": {"title": "Динамическая адаптация руководства для повышения качества генерации текста", "desc": "Статья представляет новый метод под названием Адаптивное Бесклассовое Руководство (A-CFG) для улучшения генера
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#dataset", "#benchmark", "#cv"], "emoji": "🔍", "ru": {"title": "Новый взгляд на ограничения визуальных токенизаторов", "desc": "Исследование раскрывает ограничения визуальных токенизаторов и VAE в сохранении мелких деталей изображений. Авторы предлага
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#video", "#multimodal"], "emoji": "🐾", "ru": {"title": "Танцующие животные: от ключевых кадров к синхронизированной хореографии", "desc": "Эта статья представляет новый подход к созданию синхронизированных с музыкой танцевальных видео животных. Авторы используют ключевые кадры, пред
[31.05.2025 01:57] Querying the API.
[31.05.2025 01:57] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The main goal of post-training quantization (PTQ) is to produced a compressed model whose output distribution is as close to the original model's as possible. To do this tractably, almost all LLM PTQ algorithms quantize linear layers by independently minimizing the immediate activation error. However, this localized objective ignores the effect of subsequent layers, so reducing it does not necessarily give a closer model. In this work, we introduce Yet Another Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses Kronecker-factored approximations of each linear layer's Hessian with respect to the full model KL divergence. YAQA consists of two components: Kronecker-factored sketches of the full layerwise Hessian that can be tractably computed for hundred-billion parameter LLMs, and a quantizer-independent rounding algorithm that uses these sketches and comes with theoretical guarantees. Across a wide range of models and quantizers, YAQA empirically reduces the KL divergence to the original model by approx 30% while achieving state of the art performance on downstream tasks.
[31.05.2025 01:57] Response: {
  "desc": "YAQA - это новый алгоритм пост-тренировочной квантизации для больших языковых моделей. В отличие от традиционных методов, которые минимизируют ошибку активации независимо для каждого слоя, YAQA использует аппроксимацию гессиана полной модели. Алгоритм состоит из двух компонентов: кронекеровых аппроксимаций гессиана и адаптивного алгоритма округления. YAQA эмпирически снижает KL-дивергенцию на 30% и показывает лучшие результаты на прикладных задачах.",
  "emoji": "🔢",
  "title": "Умное округление для эффективной квантизации языковых моделей"
}
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The main goal of post-training quantization (PTQ) is to produced a compressed model whose output distribution is as close to the original model's as possible. To do this tractably, almost all LLM PTQ algorithms quantize linear layers by independently minimizing the immediate activation error. However, this localized objective ignores the effect of subsequent layers, so reducing it does not necessarily give a closer model. In this work, we introduce Yet Another Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses Kronecker-factored approximations of each linear layer's Hessian with respect to the full model KL divergence. YAQA consists of two components: Kronecker-factored sketches of the full layerwise Hessian that can be tractably computed for hundred-billion parameter LLMs, and a quantizer-independent rounding algorithm that uses these sketches and comes with theoretical guarantees. Across a wide range of models and quantizers, YAQA empirically reduces the KL divergence to the original model by approx 30% while achieving state of the art performance on downstream tasks."

[31.05.2025 01:57] Response: ```python
["INFERENCE", "TRAINING"]
```
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The main goal of post-training quantization (PTQ) is to produced a compressed model whose output distribution is as close to the original model's as possible. To do this tractably, almost all LLM PTQ algorithms quantize linear layers by independently minimizing the immediate activation error. However, this localized objective ignores the effect of subsequent layers, so reducing it does not necessarily give a closer model. In this work, we introduce Yet Another Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses Kronecker-factored approximations of each linear layer's Hessian with respect to the full model KL divergence. YAQA consists of two components: Kronecker-factored sketches of the full layerwise Hessian that can be tractably computed for hundred-billion parameter LLMs, and a quantizer-independent rounding algorithm that uses these sketches and comes with theoretical guarantees. Across a wide range of models and quantizers, YAQA empirically reduces the KL divergence to the original model by approx 30% while achieving state of the art performance on downstream tasks."

[31.05.2025 01:57] Response: ```python
["OPTIMIZATION"]
```
[31.05.2025 01:57] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new method called Yet Another Quantization Algorithm (YAQA) for post-training quantization (PTQ) of large language models (LLMs). The goal of YAQA is to create a compressed model that closely matches the output of the original model by addressing the limitations of existing quantization methods. It introduces an adaptive rounding technique that leverages Kronecker-factored approximations of the Hessian matrix, allowing for efficient computation even in very large models. The results show that YAQA significantly reduces the KL divergence from the original model while maintaining high performance on various tasks.","title":"Optimizing Model Compression with Adaptive Rounding"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new method called Yet Another Quantization Algorithm (YAQA) for post-training quantization (PTQ) of large language models (LLMs). The goal of YAQA is to create a compressed model that closely matches the output of the original model by addressing the limitations of existing quantization methods. It introduces an adaptive rounding technique that leverages Kronecker-factored approximations of the Hessian matrix, allowing for efficient computation even in very large models. The results show that YAQA significantly reduces the KL divergence from the original model while maintaining high performance on various tasks.', title='Optimizing Model Compression with Adaptive Rounding'))
[31.05.2025 01:57] Response: ParsedChatCompletionMessage[Article](content='{"desc":"后训练量化（PTQ）的主要目标是生成一个压缩模型，其输出分布尽可能接近原始模型。大多数现有的PTQ算法通过独立最小化线性层的激活误差来量化，但这种方法忽略了后续层的影响。本文提出了一种新的量化算法（YAQA），它使用克罗内克近似来考虑每个线性层的海森矩阵，从而更好地优化模型。YAQA在多个模型和量化器上实验证明，能够将KL散度减少约30%，同时在下游任务中实现了最先进的性能。","title":"提升模型压缩与性能的量化新算法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='后训练量化（PTQ）的主要目标是生成一个压缩模型，其输出分布尽可能接近原始模型。大多数现有的PTQ算法通过独立最小化线性层的激活误差来量化，但这种方法忽略了后续层的影响。本文提出了一种新的量化算法（YAQA），它使用克罗内克近似来考虑每个线性层的海森矩阵，从而更好地优化模型。YAQA在多个模型和量化器上实验证明，能够将KL散度减少约30%，同时在下游任务中实现了最先进的性能。', title='提升模型压缩与性能的量化新算法'))
[31.05.2025 01:57] Using data from previous issue: {"categories": ["#survey", "#hallucinations", "#dataset", "#graphs", "#reasoning", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "Синергия языковых моделей и графов знаний для улучшения вопросно-ответных систем", "desc": "Данная статья представляет обзор методов синтеза больших языковы
[31.05.2025 01:57] Querying the API.
[31.05.2025 01:57] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models (LLMs) have shown significant potential in scientific disciplines such as biomedicine, particularly in hypothesis generation, where they can analyze vast literature, identify patterns, and suggest research directions. However, a key challenge lies in evaluating the truthfulness of generated hypotheses, as verifying their accuracy often requires substantial time and resources. Additionally, the hallucination problem in LLMs can lead to the generation of hypotheses that appear plausible but are ultimately incorrect, undermining their reliability. To facilitate the systematic study of these challenges, we introduce TruthHypo, a benchmark for assessing the capabilities of LLMs in generating truthful biomedical hypotheses, and KnowHD, a knowledge-based hallucination detector to evaluate how well hypotheses are grounded in existing knowledge. Our results show that LLMs struggle to generate truthful hypotheses. By analyzing hallucinations in reasoning steps, we demonstrate that the groundedness scores provided by KnowHD serve as an effective metric for filtering truthful hypotheses from the diverse outputs of LLMs. Human evaluations further validate the utility of KnowHD in identifying truthful hypotheses and accelerating scientific discovery. Our data and source code are available at https://github.com/Teddy-XiongGZ/TruthHypo.
[31.05.2025 01:57] Response: {
  "desc": "Статья представляет новый бенчмарк TruthHypo для оценки способности больших языковых моделей (LLM) генерировать достоверные биомедицинские гипотезы. Авторы также разработали KnowHD - детектор галлюцинаций на основе знаний, для оценки обоснованности гипотез. Результаты показывают, что LLM испытывают трудности с генерацией правдивых гипотез. Анализ галлюцинаций в шагах рассуждений демонстрирует, что оценки обоснованности от KnowHD эффективны для фильтрации достоверных гипотез.",
  "emoji": "🧬",
  "title": "Проверка правдивости гипотез, сгенерированных ИИ в биомедицине"
}
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models (LLMs) have shown significant potential in scientific disciplines such as biomedicine, particularly in hypothesis generation, where they can analyze vast literature, identify patterns, and suggest research directions. However, a key challenge lies in evaluating the truthfulness of generated hypotheses, as verifying their accuracy often requires substantial time and resources. Additionally, the hallucination problem in LLMs can lead to the generation of hypotheses that appear plausible but are ultimately incorrect, undermining their reliability. To facilitate the systematic study of these challenges, we introduce TruthHypo, a benchmark for assessing the capabilities of LLMs in generating truthful biomedical hypotheses, and KnowHD, a knowledge-based hallucination detector to evaluate how well hypotheses are grounded in existing knowledge. Our results show that LLMs struggle to generate truthful hypotheses. By analyzing hallucinations in reasoning steps, we demonstrate that the groundedness scores provided by KnowHD serve as an effective metric for filtering truthful hypotheses from the diverse outputs of LLMs. Human evaluations further validate the utility of KnowHD in identifying truthful hypotheses and accelerating scientific discovery. Our data and source code are available at https://github.com/Teddy-XiongGZ/TruthHypo."

[31.05.2025 01:57] Response: ```python
['BENCHMARK', 'DATASET', 'MULTIMODAL']
```
[31.05.2025 01:57] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models (LLMs) have shown significant potential in scientific disciplines such as biomedicine, particularly in hypothesis generation, where they can analyze vast literature, identify patterns, and suggest research directions. However, a key challenge lies in evaluating the truthfulness of generated hypotheses, as verifying their accuracy often requires substantial time and resources. Additionally, the hallucination problem in LLMs can lead to the generation of hypotheses that appear plausible but are ultimately incorrect, undermining their reliability. To facilitate the systematic study of these challenges, we introduce TruthHypo, a benchmark for assessing the capabilities of LLMs in generating truthful biomedical hypotheses, and KnowHD, a knowledge-based hallucination detector to evaluate how well hypotheses are grounded in existing knowledge. Our results show that LLMs struggle to generate truthful hypotheses. By analyzing hallucinations in reasoning steps, we demonstrate that the groundedness scores provided by KnowHD serve as an effective metric for filtering truthful hypotheses from the diverse outputs of LLMs. Human evaluations further validate the utility of KnowHD in identifying truthful hypotheses and accelerating scientific discovery. Our data and source code are available at https://github.com/Teddy-XiongGZ/TruthHypo."

[31.05.2025 01:57] Response: ```python
['SCIENCE', 'HALLUCINATIONS']
```
[31.05.2025 01:57] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the use of large language models (LLMs) in generating hypotheses in biomedicine, highlighting their ability to analyze literature and suggest research directions. A major issue is the verification of these hypotheses, as they can often be inaccurate due to the hallucination problem, where LLMs produce plausible but false statements. To address this, the authors introduce TruthHypo, a benchmark for evaluating the truthfulness of hypotheses generated by LLMs, and KnowHD, a tool for detecting hallucinations based on existing knowledge. The findings indicate that while LLMs can generate hypotheses, they frequently lack truthfulness, and KnowHD proves effective in filtering out unreliable outputs, thus aiding scientific discovery.","title":"Truthful Hypotheses: Bridging LLMs and Biomedical Research"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the use of large language models (LLMs) in generating hypotheses in biomedicine, highlighting their ability to analyze literature and suggest research directions. A major issue is the verification of these hypotheses, as they can often be inaccurate due to the hallucination problem, where LLMs produce plausible but false statements. To address this, the authors introduce TruthHypo, a benchmark for evaluating the truthfulness of hypotheses generated by LLMs, and KnowHD, a tool for detecting hallucinations based on existing knowledge. The findings indicate that while LLMs can generate hypotheses, they frequently lack truthfulness, and KnowHD proves effective in filtering out unreliable outputs, thus aiding scientific discovery.', title='Truthful Hypotheses: Bridging LLMs and Biomedical Research'))
[31.05.2025 01:57] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型语言模型（LLMs）在生物医学等科学领域展现出显著潜力，尤其是在假设生成方面。本文提出了TruthHypo基准，用于评估LLMs生成真实生物医学假设的能力，并引入KnowHD知识基础的幻觉检测器，以评估假设与现有知识的关联性。研究表明，LLMs在生成真实假设方面存在困难，且幻觉问题可能导致生成看似合理但实际上不正确的假设。通过分析推理步骤中的幻觉，我们证明了KnowHD提供的基础分数是过滤真实假设的有效指标。","title":"评估大型语言模型生成真实假设的能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='大型语言模型（LLMs）在生物医学等科学领域展现出显著潜力，尤其是在假设生成方面。本文提出了TruthHypo基准，用于评估LLMs生成真实生物医学假设的能力，并引入KnowHD知识基础的幻觉检测器，以评估假设与现有知识的关联性。研究表明，LLMs在生成真实假设方面存在困难，且幻觉问题可能导致生成看似合理但实际上不正确的假设。通过分析推理步骤中的幻觉，我们证明了KnowHD提供的基础分数是过滤真实假设的有效指标。', title='评估大型语言模型生成真实假设的能力'))
[31.05.2025 01:57] Loading Chinese text from previous data.
[31.05.2025 01:57] Renaming data file.
[31.05.2025 01:57] Renaming previous data. hf_papers.json to ./d/2025-05-30.json
[31.05.2025 01:57] Saving new data file.
[31.05.2025 01:57] Generating page.
[31.05.2025 01:57] Renaming previous page.
[31.05.2025 01:57] Renaming previous data. index.html to ./d/2025-05-30.html
[31.05.2025 01:57] [Experimental] Generating Chinese page for reading.
[31.05.2025 01:57] Chinese vocab [{'word': '大语言模型', 'pinyin': 'dà yǔyán móxíng', 'trans': 'large language model'}, {'word': '强化学习', 'pinyin': 'qiáng huà xuéxí', 'trans': 'reinforcement learning'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '奖励噪音', 'pinyin': 'jiǎng lì zào yīn', 'trans': 'reward noise'}, {'word': '鲁棒性', 'pinyin': 'lǔ bāng xìng', 'trans': 'robustness'}, {'word': '手动翻转', 'pinyin': 'shǒu dòng fān zhuǎn', 'trans': 'manually flip'}, {'word': '奖励函数', 'pinyin': 'jiǎng lì hán shù', 'trans': 'reward function'}, {'word': '输出', 'pinyin': 'shū chū', 'trans': 'output'}, {'word': '快速收敛', 'pinyin': 'kuài sù shōu liǎn', 'trans': 'rapid convergence'}, {'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'}, {'word': '奖励关键推理短语', 'pinyin': 'jiǎng lì guǎn jiàn tuī lǐ duǎn yǔ', 'trans': 'reward key reasoning phrases'}, {'word': '开放式任务', 'pinyin': 'kāi fàng shì rèn wù', 'trans': 'open-ended tasks'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'findings'}, {'word': '强调', 'pinyin': 'qiáng diào', 'trans': 'emphasize'}, {'word': '改进', 'pinyin': 'gǎi jìn', 'trans': 'improve'}, {'word': '预训练阶段', 'pinyin': 'yù xùn liàn jiē duàn', 'trans': 'pre-training stage'}, {'word': '基础能力', 'pinyin': 'jī chǔ néng lì', 'trans': 'foundational capabilities'}]
[31.05.2025 01:57] Renaming previous Chinese page.
[31.05.2025 01:57] Renaming previous data. zh.html to ./d/2025-05-30_zh_reading_task.html
[31.05.2025 01:57] Writing Chinese reading task.
[31.05.2025 01:57] Writing result.
[31.05.2025 01:57] Renaming log file.
[31.05.2025 01:57] Renaming previous data. log.txt to ./logs/2025-05-31_last_log.txt
