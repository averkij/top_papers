[06.10.2025 06:19] Read previous papers.
[06.10.2025 06:19] Generating top page (month).
[06.10.2025 06:19] Writing top page (month).
[06.10.2025 07:13] Read previous papers.
[06.10.2025 07:13] Get feed.
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00515
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01068
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02665
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03120
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26354
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01879
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03204
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03194
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03230
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01459
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25771
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03160
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02571
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01354
[06.10.2025 07:13] Extract page data from URL. URL: https://huggingface.co/papers/2510.00658
[06.10.2025 07:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.10.2025 07:13] No deleted papers detected.
[06.10.2025 07:13] Downloading and parsing papers (pdf, html). Total: 15.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.00515.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.00515.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.00515.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01068.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01068.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01068.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.02665.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.02665.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.02665.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03120.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03120.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03120.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2509.26354.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2509.26354.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2509.26354.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01879.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01879.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01879.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03204.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03204.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03204.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03194.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03194.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03194.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03230.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03230.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03230.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01459.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01459.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01459.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2509.25771.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2509.25771.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2509.25771.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03160.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03160.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03160.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.02571.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.02571.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.02571.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01354.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01354.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01354.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.00658.
[06.10.2025 07:13] Downloading paper 2510.00658 from http://arxiv.org/pdf/2510.00658v1...
[06.10.2025 07:13] Extracting affiliations from text.
[06.10.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 ] . [ 1 8 5 6 0 0 . 0 1 5 2 : r Preprint. ALIGN YOUR TANGENT: TRAINING BETTER CONSISTENCY MODELS VIA MANIFOLD-ALIGNED TANGENTS Beomsu Kim*, Byunghee Cha*, Jong Chul Ye Graduate School of AI, KAIST *Equal Contribution "
[06.10.2025 07:13] Response: ```python
["Graduate School of AI, KAIST"]
```
[06.10.2025 07:13] Deleting PDF ./assets/pdf/2510.00658.pdf.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Enriching papers with extra data.
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 0. EPIC, a progressive learning framework, improves the efficiency of multi-modal large models by reducing training difficulty through token and layer consistency distillation during visual token compression.  					AI-generated summary 				 Visual tokens consume substantial computational resources in m...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 1. General Policy Composition (GPC) enhances robotic control performance by combining pre-trained diffusion-based policies without additional training, leading to superior results across various benchmarks.  					AI-generated summary 				 Diffusion-based models for robotic control, including vision-lan...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 2. A survey of self-improvement methods in Multimodal Large Language Models (MLLMs) from data collection, organization, and model optimization perspectives.  					AI-generated summary 				 Recent advancements in self-improvement for Large Language Models (LLMs) have efficiently enhanced model capabilit...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 3. A new evaluation framework, SurveyBench, assesses the quality of automatically generated academic surveys using a quiz-driven approach, revealing deficiencies in current LLM4Survey methods.  					AI-generated summary 				 Academic survey writing, which distills vast literature into a coherent and in...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 4. Self-evolving agents based on Large Language Models can deviate in unintended ways, leading to various risks such as safety misalignment and vulnerability introduction, necessitating new safety paradigms.  					AI-generated summary 				 Advances in Large Language Models (LLMs) have enabled a new cla...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 5. REPAIR is a lifelong editing framework for large language models that enhances editing accuracy and reduces knowledge forgetting through progressive adaptive intervention and reintegration.  					AI-generated summary 				 Post-training for large language models (LLMs) is constrained by the high cost...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 6. FocusAgent uses a lightweight LLM retriever to extract relevant content from web page observations, improving efficiency and security in web agents.  					AI-generated summary 				 Web agents powered by large language models (LLMs) must process lengthy web page observations to complete user goals; t...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 7. CoDA, a multi-agent system using specialized LLM agents, enhances visualization automation by managing data complexity and ensuring high-quality visualizations through collaborative workflows.  					AI-generated summary 				 Deep research has revolutionized data analysis, yet data scientists still d...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 8. Explicit coordinate markers and improved spatial encoding enhance GUI grounding accuracy across diverse resolutions and platforms.  					AI-generated summary 				 GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains diff...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 9. Length-aware Sampling for Policy Optimization (LSPO) is a meta-RLVR algorithm that dynamically selects training data based on response length, improving learning effectiveness in large language models.  					AI-generated summary 				 Since the release of Deepseek-R1, reinforcement learning with veri...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 10. A new framework, Text Preference Optimization (TPO), aligns text-to-image models with human preferences without requiring paired image preference data, improving text-to-image alignment and human preference scores.  					AI-generated summary 				 Recent advances in diffusion-based text-to-image (T2I...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 11. SpineMed, an ecosystem with SpineMed-450k and SpineBench, addresses the lack of level-aware, multimodal datasets and benchmarks for AI-assisted diagnosis of spine disorders, improving model performance through fine-grained, level-specific reasoning.  					AI-generated summary 				 Spine disorders af...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 12. A framework for uncertainty quantification in generative video models is introduced, including a metric for calibration, a black-box method called S-QUBED, and a benchmark dataset, demonstrating improved uncertainty estimates and task accuracy.  					AI-generated summary 				 Generative video models...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 13. A comprehensive benchmark study evaluates the detection of prompt injection attacks against web agents, revealing that current detectors perform well against explicit attacks but struggle with subtle ones.  					AI-generated summary 				 Multiple prompt injection attacks have been proposed against w...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 14. Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the communi...
[06.10.2025 07:13] Read previous papers.
[06.10.2025 07:13] Generating reviews via LLM API.
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture", "#multimodal"], "emoji": "üéØ", "ru": {"title": "–ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—é", "desc": "EPIC ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –±–æ–ª—å—à–∏—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#training", "#robotics", "#optimization", "#benchmark", "#diffusion", "#agents"], "emoji": "ü§ù", "ru": {"title": "–ö–æ–º–ø–æ–∑–∏—Ü–∏—è policy –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ General Policy Composition (GPC), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#training", "#survey", "#optimization", "#multimodal", "#data", "#dataset"], "emoji": "üîÑ", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ LLM —É—á–∞—Ç—Å—è —Å–∞–º–∏: –æ–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM.
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#survey", "#benchmark"], "emoji": "üìä", "ru": {"title": "SurveyBench: –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞—É—á–Ω—ã—Ö –æ–±–∑–æ—Ä–æ–≤ —á–µ—Ä–µ–∑ –≤–∏–∫—Ç–æ—Ä–∏–Ω—ã", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ SurveyBench ‚Äî –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –æ–±–∑–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM.
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#agents", "#security", "#safety", "#rl"], "emoji": "üß¨", "ru": {"title": "–ö–æ–≥–¥–∞ AI-–∞–≥–µ–Ω—Ç—ã —ç–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä—É—é—Ç –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–∑—É—á–∞–µ—Ç –Ω–æ–≤—ã–π —Ç–∏–ø —Ä–∏—Å–∫–æ–≤ –≤ —Å–∞–º–æ–æ–±—É—á–∞—é—â–∏—Ö—Å—è –∞–≥–µ–Ω—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∫–æ—Ç–æ—Ä—ã–µ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ —É–ª—É—á—à–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –≤–∑–∞–∏–º–æ
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "üîß", "ru": {"title": "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –∑–∞–±—ã–≤–∞–Ω–∏—è –∑–Ω–∞–Ω–∏–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ REPAIR –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –æ—à–∏–±–∫–∏ –∏ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#long_context", "#inference", "#benchmark", "#agents", "#security", "#reasoning"], "emoji": "üéØ", "ru": {"title": "–§–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "desc": "FocusAgent ‚Äî —ç—Ç–æ –ø–æ–¥—Ö–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª—ë–≥–∫–∏–π re
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#agents", "#optimization", "#data", "#interpretability", "#multimodal"], "emoji": "ü§ù", "ru": {"title": "–ö–æ–º–∞–Ω–¥–∞ AI-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç CoDA ‚Äî –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∫–æ—Ç–æ—Ä–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π 
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#interpretability", "#agents", "#cv", "#optimization"], "emoji": "üéØ", "ru": {"title": "–Ø–≤–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–º–µ—Å—Ç–æ —É–≥–∞–¥—ã–≤–∞–Ω–∏—è: –∫–∞–∫ –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ —Ç–æ—á–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ GUI grounding ‚Äî –∑–∞–¥–∞—á–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl", "#reasoning"], "emoji": "üìè", "ru": {"title": "–£—á—ë—Ç –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è LLM", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω LSPO ‚Äî –º–µ—Ç–∞-–∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –æ—Ç
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#open_source", "#alignment", "#benchmark", "#rlhf", "#multimodal", "#diffusion"], "emoji": "üéØ", "ru": {"title": "–ë–µ—Å–ø–ª–∞—Ç–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –ø–∞—Ä–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Text Preference Optimization (TPO) –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è text-to-image –º–æ–¥–µ–ª–µ–π —Å —á–µ–ª
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#reasoning", "#training", "#healthcare", "#benchmark", "#dataset", "#multimodal", "#science"], "emoji": "ü¶¥", "ru": {"title": "SpineMed: AI-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ç–æ—á–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–æ–∑–≤–æ–Ω–∫–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SpineMed ‚Äî —ç–∫–æ—Å–∏—Å—Ç–µ–º—É –¥–ª—è AI-–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#hallucinations", "#dataset", "#video"], "emoji": "üé¨", "ru": {"title": "–ö–æ–≥–¥–∞ AI –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ —Å–≤–æ—ë–º –≤–∏–¥–µ–æ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –ø–µ—Ä–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –≤–∏–¥–µ–æ–º–æ–¥–µ–ª—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ, –∫–∞–∫ –∏ LLM, —Å
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#agents", "#dataset", "#benchmark", "#security"], "emoji": "üïµÔ∏è", "ru": {"title": "–î–µ—Ç–µ–∫—Ç–æ—Ä—ã –∏–Ω—ä–µ–∫—Ü–∏–π –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å —Ç–æ–Ω–∫–∏–º–∏ –∞—Ç–∞–∫–∞–º–∏ –Ω–∞ –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–æ–≤–µ–ª–∏ –ø–µ—Ä–≤–æ–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞—Ç–∞–∫ —Ç–∏–ø–∞ prompt injection –Ω–∞ –≤–µ–±-–∞–≥–µ–Ω—Ç–æ
[06.10.2025 07:13] Querying the API.
[06.10.2025 07:13] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the community now turned to reducing the inference time without sacrificing sample quality. Consistency Models (CMs), which are trained to be consistent on diffusion or probability flow ordinary differential equation (PF-ODE) trajectories, enable one or two-step flow or diffusion sampling. However, CMs typically require prolonged training with large batch sizes to obtain competitive sample quality. In this paper, we examine the training dynamics of CMs near convergence and discover that CM tangents -- CM output update directions -- are quite oscillatory, in the sense that they move parallel to the data manifold, not towards the manifold. To mitigate oscillatory tangents, we propose a new loss function, called the manifold feature distance (MFD), which provides manifold-aligned tangents that point toward the data manifold. Consequently, our method -- dubbed Align Your Tangent (AYT) -- can accelerate CM training by orders of magnitude and even out-perform the learned perceptual image patch similarity metric (LPIPS). Furthermore, we find that our loss enables training with extremely small batch sizes without compromising sample quality. Code: https://github.com/1202kbs/AYT
[06.10.2025 07:13] Response: ```json
{
  "desc": "Consistency Models (CMs) –ø–æ–∑–≤–æ–ª—è—é—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞ –æ–¥–∏–Ω-–¥–≤–∞ —à–∞–≥–∞, –Ω–æ —Ç—Ä–µ–±—É—é—Ç –¥–æ–ª–≥–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –±–æ–ª—å—à–∏–º–∏ –±–∞—Ç—á–∞–º–∏. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã CM –≤–µ–¥—É—Ç —Å–µ–±—è –æ—Å—Ü–∏–ª–ª—è—Ç–æ—Ä–Ω–æ - –¥–≤–∏–≥–∞—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ data manifold –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –Ω–∞–ø—Ä–∞–≤–ª—è—Ç—å—Å—è –∫ –Ω–µ–º—É. –û–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –Ω–æ–≤—É—é loss-—Ñ—É–Ω–∫—Ü–∏—é MFD (manifold feature distance), –∫–æ—Ç–æ—Ä–∞—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∫ –º–Ω–æ–≥–æ–æ–±—Ä–∞–∑–∏—é –¥–∞–Ω–Ω—ã—Ö. –ú–µ—Ç–æ–¥ Align Your Tangent (AYT) —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ CM –Ω–∞ –ø–æ—Ä—è–¥–∫–∏ –≤–µ–ª–∏—á–∏–Ω—ã –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã –±–∞—Ç—á–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞.",
  "emoji": "üéØ",
  "title": "–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è Consistency Models"
}
```
[06.10.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the community now turned to reducing the inference time without sacrificing sample quality. Consistency Models (CMs), which are trained to be consistent on diffusion or probability flow ordinary differential equation (PF-ODE) trajectories, enable one or two-step flow or diffusion sampling. However, CMs typically require prolonged training with large batch sizes to obtain competitive sample quality. In this paper, we examine the training dynamics of CMs near convergence and discover that CM tangents -- CM output update directions -- are quite oscillatory, in the sense that they move parallel to the data manifold, not towards the manifold. To mitigate oscillatory tangents, we propose a new loss function, called the manifold feature distance (MFD), which provides manifold-aligned tangents that point toward the data manifold. Consequently, our method -- dubbed Align Your Tangent (AYT) -- can accelerate CM training by orders of magnitude and even out-perform the learned perceptual image patch similarity metric (LPIPS). Furthermore, we find that our loss enables training with extremely small batch sizes without compromising sample quality. Code: https://github.com/1202kbs/AYT"

[06.10.2025 07:13] Response: ```python
['TRAINING']
```
[06.10.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the community now turned to reducing the inference time without sacrificing sample quality. Consistency Models (CMs), which are trained to be consistent on diffusion or probability flow ordinary differential equation (PF-ODE) trajectories, enable one or two-step flow or diffusion sampling. However, CMs typically require prolonged training with large batch sizes to obtain competitive sample quality. In this paper, we examine the training dynamics of CMs near convergence and discover that CM tangents -- CM output update directions -- are quite oscillatory, in the sense that they move parallel to the data manifold, not towards the manifold. To mitigate oscillatory tangents, we propose a new loss function, called the manifold feature distance (MFD), which provides manifold-aligned tangents that point toward the data manifold. Consequently, our method -- dubbed Align Your Tangent (AYT) -- can accelerate CM training by orders of magnitude and even out-perform the learned perceptual image patch similarity metric (LPIPS). Furthermore, we find that our loss enables training with extremely small batch sizes without compromising sample quality. Code: https://github.com/1202kbs/AYT"

[06.10.2025 07:13] Response: ```python
["OPTIMIZATION", "DIFFUSION"]
```
[06.10.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Align Your Tangent (AYT), a novel approach to enhance the training of Consistency Models (CMs) by addressing the issue of oscillatory tangents during training. By proposing a new loss function called manifold feature distance (MFD), AYT aligns the output update directions of CMs towards the data manifold, leading to more stable and efficient training dynamics. This method allows for significantly faster convergence, even with small batch sizes, while maintaining high sample quality. The results demonstrate that AYT not only accelerates training but also surpasses existing metrics like LPIPS in performance.","title":"Accelerate Consistency Model Training with AYT!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces Align Your Tangent (AYT), a novel approach to enhance the training of Consistency Models (CMs) by addressing the issue of oscillatory tangents during training. By proposing a new loss function called manifold feature distance (MFD), AYT aligns the output update directions of CMs towards the data manifold, leading to more stable and efficient training dynamics. This method allows for significantly faster convergence, even with small batch sizes, while maintaining high sample quality. The results demonstrate that AYT not only accelerates training but also surpasses existing metrics like LPIPS in performance.', title='Accelerate Consistency Model Training with AYT!'))
[06.10.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËÆ≠ÁªÉÊñπÊ≥ïÔºåÁß∞‰∏∫Align Your Tangent (AYT)ÔºåÊó®Âú®ÊèêÈ´ò‰∏ÄËá¥ÊÄßÊ®°ÂûãÔºàCMÔºâÁöÑËÆ≠ÁªÉÊïàÁéá„ÄÇÈÄöËøáÂºïÂÖ•ÊµÅÂΩ¢ÁâπÂæÅË∑ùÁ¶ªÔºàMFDÔºâÊçüÂ§±ÂáΩÊï∞ÔºåAYTËÉΩÂ§üÂáèÂ∞ëËÆ≠ÁªÉËøáÁ®ã‰∏≠ËæìÂá∫Êõ¥Êñ∞ÊñπÂêëÁöÑÊåØËç°Ôºå‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞ÊåáÂêëÊï∞ÊçÆÊµÅÂΩ¢„ÄÇËøôÊ†∑ÔºåAYTÂèØ‰ª•Âú®Â∞èÊâπÈáèÊï∞ÊçÆ‰∏ãÂä†ÈÄüËÆ≠ÁªÉÔºåÂπ∂‰∏îÂú®Ê†∑Êú¨Ë¥®Èáè‰∏äË∂ÖËøá‰∫ÜÁé∞ÊúâÁöÑËØÑ‰º∞ÊåáÊ†á„ÄÇÊúÄÁªàÔºåAYTÊòæËëóÊèêÈ´ò‰∫ÜCMÁöÑÊî∂ÊïõÈÄüÂ∫¶ÔºåÂáèÂ∞ë‰∫ÜÂØπÂ§ßÊâπÈáèÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ","title":"ÂØπÈΩê‰Ω†ÁöÑÂàáÁ∫øÔºåÊèêÂçá‰∏ÄËá¥ÊÄßÊ®°ÂûãËÆ≠ÁªÉÊïàÁéá"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËÆ≠ÁªÉÊñπÊ≥ïÔºåÁß∞‰∏∫Align Your Tangent (AYT)ÔºåÊó®Âú®ÊèêÈ´ò‰∏ÄËá¥ÊÄßÊ®°ÂûãÔºàCMÔºâÁöÑËÆ≠ÁªÉÊïàÁéá„ÄÇÈÄöËøáÂºïÂÖ•ÊµÅÂΩ¢ÁâπÂæÅË∑ùÁ¶ªÔºàMFDÔºâÊçüÂ§±ÂáΩÊï∞ÔºåAYTËÉΩÂ§üÂáèÂ∞ëËÆ≠ÁªÉËøáÁ®ã‰∏≠ËæìÂá∫Êõ¥Êñ∞ÊñπÂêëÁöÑÊåØËç°Ôºå‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞ÊåáÂêëÊï∞ÊçÆÊµÅÂΩ¢„ÄÇËøôÊ†∑ÔºåAYTÂèØ‰ª•Âú®Â∞èÊâπÈáèÊï∞ÊçÆ‰∏ãÂä†ÈÄüËÆ≠ÁªÉÔºåÂπ∂‰∏îÂú®Ê†∑Êú¨Ë¥®Èáè‰∏äË∂ÖËøá‰∫ÜÁé∞ÊúâÁöÑËØÑ‰º∞ÊåáÊ†á„ÄÇÊúÄÁªàÔºåAYTÊòæËëóÊèêÈ´ò‰∫ÜCMÁöÑÊî∂ÊïõÈÄüÂ∫¶ÔºåÂáèÂ∞ë‰∫ÜÂØπÂ§ßÊâπÈáèÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ', title='ÂØπÈΩê‰Ω†ÁöÑÂàáÁ∫øÔºåÊèêÂçá‰∏ÄËá¥ÊÄßÊ®°ÂûãËÆ≠ÁªÉÊïàÁéá'))
[06.10.2025 07:13] Renaming data file.
[06.10.2025 07:13] Renaming previous data. hf_papers.json to ./d/2025-10-06.json
[06.10.2025 07:13] Saving new data file.
[06.10.2025 07:13] Generating page.
[06.10.2025 07:13] Renaming previous page.
[06.10.2025 07:13] Renaming previous data. index.html to ./d/2025-10-06.html
[06.10.2025 07:13] Writing result.
[06.10.2025 07:13] Renaming log file.
[06.10.2025 07:13] Renaming previous data. log.txt to ./logs/2025-10-06_last_log.txt
