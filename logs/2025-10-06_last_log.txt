[06.10.2025 19:10] Read previous papers.
[06.10.2025 19:10] Generating top page (month).
[06.10.2025 19:10] Writing top page (month).
[06.10.2025 20:12] Read previous papers.
[06.10.2025 20:12] Get feed.
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01141
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00938
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00515
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01068
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03194
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23202
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02665
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26354
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.22033
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01879
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03120
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01698
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03204
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01354
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26388
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03230
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01459
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00177
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25771
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25122
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03232
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03160
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02880
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02730
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02657
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02571
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02110
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01329
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01132
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00658
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24975
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25944
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02375
[06.10.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23291
[06.10.2025 20:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.10.2025 20:12] No deleted papers detected.
[06.10.2025 20:12] Downloading and parsing papers (pdf, html). Total: 34.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01141.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01141.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01141.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.00938.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.00938.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.00938.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.00515.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.00515.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.00515.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01068.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01068.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01068.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.03194.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.03194.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.03194.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.23202.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.23202.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.23202.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.02665.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.02665.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.02665.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.26354.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.26354.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.26354.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.22033.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.22033.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.22033.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01879.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01879.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01879.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.03120.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.03120.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.03120.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01698.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01698.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01698.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.03204.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.03204.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.03204.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01354.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01354.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01354.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.26388.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.26388.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.26388.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.03230.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.03230.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.03230.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01459.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01459.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01459.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.00177.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.00177.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.00177.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.25771.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.25771.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.25771.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.25122.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.25122.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.25122.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.03232.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.03232.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.03232.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.03160.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.03160.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.03160.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.02880.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.02880.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.02880.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.02730.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.02730.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.02730.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.02657.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.02657.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.02657.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.02571.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.02571.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.02571.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.02110.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.02110.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.02110.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01329.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01329.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01329.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.01132.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.01132.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.01132.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.00658.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.00658.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.00658.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.24975.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.24975.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.24975.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.25944.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.25944.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.25944.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2510.02375.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2510.02375.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2510.02375.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2509.23291.
[06.10.2025 20:12] Extra JSON file exists (./assets/json/2509.23291.json), skip PDF parsing.
[06.10.2025 20:12] Paper image links file exists (./assets/img_data/2509.23291.json), skip HTML parsing.
[06.10.2025 20:12] Success.
[06.10.2025 20:12] Enriching papers with extra data.
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 0. A 15-billion parameter multimodal reasoning model achieves competitive performance through a progressive training methodology without reinforcement learning, demonstrating efficient use of computational resources.  					AI-generated summary 				 We present Apriel-1.5-15B-Thinker, a 15-billion parame...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 1. RECAP, a reinforcement learning method, enhances the safety and robustness of large reasoning models by teaching them to override flawed reasoning and maintain safety without additional training costs.  					AI-generated summary 				 Large reasoning models (LRMs) "think" by generating structured cha...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 2. EPIC, a progressive learning framework, improves the efficiency of multi-modal large models by reducing training difficulty through token and layer consistency distillation during visual token compression.  					AI-generated summary 				 Visual tokens consume substantial computational resources in m...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 3. General Policy Composition (GPC) enhances robotic control performance by combining pre-trained diffusion-based policies without additional training, leading to superior results across various benchmarks.  					AI-generated summary 				 Diffusion-based models for robotic control, including vision-lan...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 4. CoDA, a multi-agent system using specialized LLM agents, enhances visualization automation by managing data complexity and ensuring high-quality visualizations through collaborative workflows.  					AI-generated summary 				 Deep research has revolutionized data analysis, yet data scientists still d...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 5. A new quantization method, Micro-Rotated-GPTQ, addresses the challenges of 4-bit floating-point formats MXFP4 and NVFP4, achieving high performance and accuracy in large language model inference.  					AI-generated summary 				 The recent hardware-accelerated microscaling 4-bit floating-point format...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 6. A survey of self-improvement methods in Multimodal Large Language Models (MLLMs) from data collection, organization, and model optimization perspectives.  					AI-generated summary 				 Recent advancements in self-improvement for Large Language Models (LLMs) have efficiently enhanced model capabilit...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 7. Self-evolving agents based on Large Language Models can deviate in unintended ways, leading to various risks such as safety misalignment and vulnerability introduction, necessitating new safety paradigms.  					AI-generated summary 				 Advances in Large Language Models (LLMs) have enabled a new cla...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 8. Orthogonal Sparse Autoencoders (OrtSAE) mitigate feature absorption and composition by enforcing orthogonality, leading to better feature discovery and improved performance on spurious correlation removal.  					AI-generated summary 				 Sparse autoencoders (SAEs) are a technique for sparse decompos...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 9. REPAIR is a lifelong editing framework for large language models that enhances editing accuracy and reduces knowledge forgetting through progressive adaptive intervention and reintegration.  					AI-generated summary 				 Post-training for large language models (LLMs) is constrained by the high cost...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 10. A new evaluation framework, SurveyBench, assesses the quality of automatically generated academic surveys using a quiz-driven approach, revealing deficiencies in current LLM4Survey methods.  					AI-generated summary 				 Academic survey writing, which distills vast literature into a coherent and in...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 11. A unified LLM-based music recommendation system with tool calling integrates various retrieval methods to enhance user intent interpretation and recommendation performance.  					AI-generated summary 				 While the recent developments in large language models (LLMs) have successfully enabled generat...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 12. FocusAgent uses a lightweight LLM retriever to extract relevant content from web page observations, improving efficiency and security in web agents.  					AI-generated summary 				 Web agents powered by large language models (LLMs) must process lengthy web page observations to complete user goals; t...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 13. A comprehensive benchmark study evaluates the detection of prompt injection attacks against web agents, revealing that current detectors perform well against explicit attacks but struggle with subtle ones.  					AI-generated summary 				 Multiple prompt injection attacks have been proposed against w...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 14. The Game-Time Benchmark evaluates the temporal dynamics and real-time interaction capabilities of conversational spoken language models, highlighting performance gaps in instruction-following and synchronized responses.  					AI-generated summary 				 Conversational Spoken Language Models (SLMs) are...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 15. Explicit coordinate markers and improved spatial encoding enhance GUI grounding accuracy across diverse resolutions and platforms.  					AI-generated summary 				 GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains diff...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 16. Length-aware Sampling for Policy Optimization (LSPO) is a meta-RLVR algorithm that dynamically selects training data based on response length, improving learning effectiveness in large language models.  					AI-generated summary 				 Since the release of Deepseek-R1, reinforcement learning with veri...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 17. PREFDISCO evaluates large language models' personalized reasoning capabilities by transforming static benchmarks into interactive tasks with sparse user preferences, revealing significant limitations in current models' ability to adapt to individual needs.  					AI-generated summary 				 Current lar...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 18. A new framework, Text Preference Optimization (TPO), aligns text-to-image models with human preferences without requiring paired image preference data, improving text-to-image alignment and human preference scores.  					AI-generated summary 				 Recent advances in diffusion-based text-to-image (T2I...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 19. Triangle Splatting+ optimizes triangles within a differentiable framework for real-time, high-fidelity 3D scene reconstruction and novel view synthesis, compatible with standard graphics engines.  					AI-generated summary 				 Reconstructing 3D scenes and synthesizing novel views has seen rapid pro...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 20. LEAML, a label-efficient adaptation framework, enhances MLLMs for specialized domains by generating pseudo question-answer pairs and selectively updating relevant neurons, outperforming standard fine-tuning with minimal supervision.  					AI-generated summary 				 Multimodal Large Language Models (M...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 21. SpineMed, an ecosystem with SpineMed-450k and SpineBench, addresses the lack of level-aware, multimodal datasets and benchmarks for AI-assisted diagnosis of spine disorders, improving model performance through fine-grained, level-specific reasoning.  					AI-generated summary 				 Spine disorders af...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 22. MaskGRPO addresses challenges in optimizing discrete diffusion models with rewards through effective importance sampling and modality-specific adaptations, improving reasoning and generation quality.  					AI-generated summary 				 Optimizing discrete diffusion model (DDM) with rewards remains a cha...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 23. A biologically inspired generative model using multiplicative updates based on geometric Brownian motion and exponential gradient descent achieves state-of-the-art performance on image datasets.  					AI-generated summary 				 Gradient descent has proven to be a powerful and effective technique for ...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 24. Expanding the retriever's corpus in Retrieval-Augmented Generation (RAG) can improve performance and reduce reliance on large language models.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) couples document retrieval with large language models (LLMs). While scaling generators i...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 25. A framework for uncertainty quantification in generative video models is introduced, including a metric for calibration, a black-box method called S-QUBED, and a benchmark dataset, demonstrating improved uncertainty estimates and task accuracy.  					AI-generated summary 				 Generative video models...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 26. A novel frame-level online Video-to-Audio generation model, SoundReactor, uses a causal transformer and DINOv2 vision encoder to generate high-quality, synchronized audio with low latency from video frames.  					AI-generated summary 				 Prevailing Video-to-Audio (V2A) generation models operate off...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 27. Continuously Augmented Discrete Diffusion (CADD) enhances generative quality by integrating a continuous latent space into discrete diffusion models, providing informative latent vectors for masked tokens and improving mode-coverage and mode-seeking behaviors.  					AI-generated summary 				 Standar...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 28. Research identifies key design choices for training large language models as agents via multi-turn reinforcement learning, focusing on environment complexity, reward sparsity, and policy methods.  					AI-generated summary 				 We study what actually works and what doesn't for training large languag...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 29. Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the communi...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 30. DiffTester is an acceleration framework for diffusion LLMs in unit test generation, improving efficiency without sacrificing test quality by identifying and leveraging common structural patterns.  					AI-generated summary 				 Software development relies heavily on extensive unit testing, which mak...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 31. NuRisk, a comprehensive VQA dataset, addresses the lack of spatio-temporal reasoning in current VLMs for autonomous driving by providing agent-level risk annotations in sequential images, improving accuracy and reducing latency.  					AI-generated summary 				 Understanding risk in autonomous drivin...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 32. A memory-augmented architecture with hierarchical parametric memory banks improves language model performance while reducing parameter size and computational requirements.  					AI-generated summary 				 The impressive performance gains of modern language models currently rely on scaling parameters:...
[06.10.2025 20:12] ********************************************************************************
[06.10.2025 20:12] Abstract 33. Policy Reasoning Traces (PRT) enhance LLMs' policy compliance assessment by providing detailed reasoning chains, improving accuracy and policy clause citation.  					AI-generated summary 				 Policy compliance assessment is a fundamental task of evaluating whether an input case strictly complies wit...
[06.10.2025 20:12] Read previous papers.
[06.10.2025 20:12] Generating reviews via LLM API.
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#agi", "#dataset", "#training", "#multimodal", "#inference", "#open_source"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –±–µ–∑ –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å Apriel-1.5-15B-Thinker —Å 15 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤,
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#training", "#rl", "#security", "#rlhf", "#reasoning", "#alignment"], "emoji": "üõ°Ô∏è", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ AI –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–µ–æ—Å–º—ã—Å–ª–∏–≤–∞—Ç—å –æ—à–∏–±–æ—á–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ RECAP ‚Äî –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –±–æ–ª—å—à–∏—Ö reasoning –º–æ–¥–µ–ª–µ–π,
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture", "#multimodal"], "emoji": "üéØ", "ru": {"title": "–ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—é", "desc": "EPIC ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –±–æ–ª—å—à–∏—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#training", "#robotics", "#optimization", "#benchmark", "#diffusion", "#agents"], "emoji": "ü§ù", "ru": {"title": "–ö–æ–º–ø–æ–∑–∏—Ü–∏—è policy –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ General Policy Composition (GPC), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#agents", "#optimization", "#data", "#interpretability", "#multimodal"], "emoji": "ü§ù", "ru": {"title": "–ö–æ–º–∞–Ω–¥–∞ AI-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç CoDA ‚Äî –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∫–æ—Ç–æ—Ä–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π 
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "üîÑ", "ru": {"title": "–ú–∏–∫—Ä–æ-–≤—Ä–∞—â–µ–Ω–∏—è —Ä–∞—Å–∫—Ä—ã–≤–∞—é—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª 4-–±–∏—Ç–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–ª—è LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Micro-Rotated-GPTQ ‚Äî –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è 4-–±–∏—Ç–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π MXFP4 –∏ NVFP4, –∫–æ—Ç–æ—Ä—ã–µ 
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#training", "#survey", "#optimization", "#multimodal", "#data", "#dataset"], "emoji": "üîÑ", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ LLM —É—á–∞—Ç—Å—è —Å–∞–º–∏: –æ–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM.
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#agents", "#security", "#safety", "#rl"], "emoji": "üß¨", "ru": {"title": "–ö–æ–≥–¥–∞ AI-–∞–≥–µ–Ω—Ç—ã —ç–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä—É—é—Ç –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–∑—É—á–∞–µ—Ç –Ω–æ–≤—ã–π —Ç–∏–ø —Ä–∏—Å–∫–æ–≤ –≤ —Å–∞–º–æ–æ–±—É—á–∞—é—â–∏—Ö—Å—è –∞–≥–µ–Ω—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∫–æ—Ç–æ—Ä—ã–µ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ —É–ª—É—á—à–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –≤–∑–∞–∏–º–æ
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture"], "emoji": "‚ä•", "ru": {"title": "–û—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–∏–≤ –∑–∞–ø—É—Ç–∞–Ω–Ω–æ—Å—Ç–∏: –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Orthogonal SAE (OrtSAE) ‚Äî —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é sparse autoencoders –¥–ª—è —Ä–∞–∑–ª–æ–∂–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "üîß", "ru": {"title": "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –∑–∞–±—ã–≤–∞–Ω–∏—è –∑–Ω–∞–Ω–∏–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ REPAIR –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –æ—à–∏–±–∫–∏ –∏ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#survey", "#benchmark"], "emoji": "üìä", "ru": {"title": "SurveyBench: –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞—É—á–Ω—ã—Ö –æ–±–∑–æ—Ä–æ–≤ —á–µ—Ä–µ–∑ –≤–∏–∫—Ç–æ—Ä–∏–Ω—ã", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ SurveyBench ‚Äî –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –æ–±–∑–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM.
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#games", "#multimodal", "#rag", "#interpretability"], "emoji": "üéµ", "ru": {"title": "LLM –∫–∞–∫ –¥–∏—Ä–∏–∂—ë—Ä –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Å–æ–∑–¥–∞–ª–∏ —Å–∏—Å—Ç–µ–º—É –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (tool calling) –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#long_context", "#inference", "#benchmark", "#agents", "#security", "#reasoning"], "emoji": "üéØ", "ru": {"title": "–§–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "desc": "FocusAgent ‚Äî —ç—Ç–æ –ø–æ–¥—Ö–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª—ë–≥–∫–∏–π re
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#agents", "#dataset", "#benchmark", "#security"], "emoji": "üïµÔ∏è", "ru": {"title": "–î–µ—Ç–µ–∫—Ç–æ—Ä—ã –∏–Ω—ä–µ–∫—Ü–∏–π –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å —Ç–æ–Ω–∫–∏–º–∏ –∞—Ç–∞–∫–∞–º–∏ –Ω–∞ –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–æ–≤–µ–ª–∏ –ø–µ—Ä–≤–æ–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞—Ç–∞–∫ —Ç–∏–ø–∞ prompt injection –Ω–∞ –≤–µ–±-–∞–≥–µ–Ω—Ç–æ
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#audio", "#alignment", "#benchmark", "#games"], "emoji": "‚è±Ô∏è", "ru": {"title": "–ö–æ–≥–¥–∞ AI –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ —Ç–∞–∫—Ç: —Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —á—É–≤—Å—Ç–≤–æ –≤—Ä–µ–º–µ–Ω–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Game-Time Benchmark ‚Äî –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã—Ö —Ä–µ—á–µ–≤—ã—Ö language 
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#interpretability", "#agents", "#cv", "#optimization"], "emoji": "üéØ", "ru": {"title": "–Ø–≤–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–º–µ—Å—Ç–æ —É–≥–∞–¥—ã–≤–∞–Ω–∏—è: –∫–∞–∫ –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ —Ç–æ—á–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ GUI grounding ‚Äî –∑–∞–¥–∞—á–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl", "#reasoning"], "emoji": "üìè", "ru": {"title": "–£—á—ë—Ç –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è LLM", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω LSPO ‚Äî –º–µ—Ç–∞-–∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –æ—Ç
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#healthcare", "#benchmark", "#alignment", "#multimodal", "#reasoning"], "emoji": "üéØ", "ru": {"title": "–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ: –Ω–∞—É—á–∏—Ç—å AI –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM –Ω–µ —É–º–µ—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#open_source", "#alignment", "#benchmark", "#rlhf", "#multimodal", "#diffusion"], "emoji": "üéØ", "ru": {"title": "–ë–µ—Å–ø–ª–∞—Ç–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –ø–∞—Ä–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Text Preference Optimization (TPO) –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è text-to-image –º–æ–¥–µ–ª–µ–π —Å —á–µ–ª
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#3d", "#games", "#optimization"], "emoji": "üî∫", "ru": {"title": "–¢—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∏ –≤–º–µ—Å—Ç–æ –≥–∞—É—Å—Å–∏–∞–Ω: –ø—Ä—è–º–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è mesh'–µ–π –¥–ª—è real-time 3D —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞", "desc": "Triangle Splatting+ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å—Ü–µ–Ω, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–ø—Ä—è–º—É—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∏ –≤ –¥–∏—Ñ—Ñ–µ—Ä
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#optimization", "#data", "#dataset", "#multimodal", "#training", "#transfer_learning", "#healthcare"], "emoji": "üéØ", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π", "desc": "LEAML ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#reasoning", "#training", "#healthcare", "#benchmark", "#dataset", "#multimodal", "#science"], "emoji": "ü¶¥", "ru": {"title": "SpineMed: AI-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ç–æ—á–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–æ–∑–≤–æ–Ω–∫–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SpineMed ‚Äî —ç–∫–æ—Å–∏—Å—Ç–µ–º—É –¥–ª—è AI-–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#architecture", "#rlhf", "#multimodal", "#benchmark", "#math", "#diffusion", "#reasoning", "#optimization", "#rl"], "emoji": "üé≠", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MaskGRPO ‚Äî –ø–µ—Ä–≤—ã–π 
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#diffusion", "#dataset", "#training", "#cv", "#optimization"], "emoji": "üß†", "ru": {"title": "–ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –≤–¥–æ—Ö–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –º–æ–¥–µ–ª—å, –≤–¥–æ—Ö–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#optimization", "#rag"], "emoji": "üìö", "ru": {"title": "–ë–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–º–µ—Å—Ç–æ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –≤ RAG", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö Retrieval-Augmented Generation (RAG) —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–æ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é 
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#hallucinations", "#dataset", "#video"], "emoji": "üé¨", "ru": {"title": "–ö–æ–≥–¥–∞ AI –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ —Å–≤–æ—ë–º –≤–∏–¥–µ–æ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –ø–µ—Ä–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –≤–∏–¥–µ–æ–º–æ–¥–µ–ª—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ, –∫–∞–∫ –∏ LLM, —Å
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#multimodal", "#video", "#training", "#audio", "#games", "#diffusion"], "emoji": "üé¨üîä", "ru": {"title": "–†–µ–∞–∫—Ç–∏–≤–Ω—ã–π –∑–≤—É–∫: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –±–µ–∑ –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SoundReactor ‚Äî –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∫–∞–¥—Ä–æ–≤–æ–π –æ–Ω–ª–∞–π–Ω-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#multimodal"], "emoji": "üé≠", "ru": {"title": "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏", "desc": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∑–∞–º–µ–Ω—è—é—Ç –≤—Å–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω [MASK], —Ç–µ—Ä—è—è –ø—Ä–∏ —ç—Ç–æ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. CADD —Ä–µ—à–∞–µ—Ç —ç—Ç
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#agents", "#games", "#reasoning", "#rlhf", "#training", "#rl", "#optimization"], "emoji": "ü§ñ", "ru": {"title": "–†–µ—Ü–µ–ø—Ç –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–∞–∫ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ reinforcement learning", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LLM –≤ —Ä–æ–ª–∏ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ mu
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#training", "#diffusion", "#optimization"], "emoji": "üéØ", "ru": {"title": "–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è Consistency Models", "desc": "Consistency Models (CMs) –ø–æ–∑–≤–æ–ª—è—é—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞ –æ–¥–∏–Ω-–¥–≤–∞ —à–∞–≥–∞, –Ω–æ —Ç—Ä–µ–±—É—é—Ç –¥–æ–ª–≥–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –±–æ–ª—å—à–∏–º–∏ –±–∞—Ç—á–∞–º–∏. –ê–≤—Ç–æ—Ä—ã
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#dataset", "#plp", "#benchmark", "#open_source", "#training"], "emoji": "‚ö°", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ unit-—Ç–µ—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã", "desc": "DiffTester - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è diffusion LLM –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ unit-—Ç–µ—Å—Ç–æ–≤. –ö–ª—é—á–µ–≤
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#reasoning", "#games", "#cv", "#dataset", "#training", "#benchmark"], "emoji": "üöó", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ –ø–æ–Ω–∏–º–∞—Ç—å —Ä–∏—Å–∫–∏ –Ω–∞ –¥–æ—Ä–æ–≥–µ –≤–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ NuRisk ‚Äî –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è Vision Language Mo
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#architecture", "#small_models", "#agi", "#optimization", "#training"], "emoji": "üóÑÔ∏è", "ru": {"title": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å –≤–º–µ—Å—Ç–æ —Ä–∞–∑–¥—É—Ç—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≤–Ω–µ—à–Ω–∏–º–∏ –±–∞–Ω–∫–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ö—Ä–∞–Ω–∏
[06.10.2025 20:12] Using data from previous issue: {"categories": ["#alignment", "#training", "#rlhf", "#reasoning"], "emoji": "‚öñÔ∏è", "ru": {"title": "–¶–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø–æ–ª–∏—Ç–∏–∫–∞–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Policy Reasoning Traces (PRT) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ LLM –æ—Ü–µ–Ω–∏–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞–Ω–Ω—ã–º –ø
[06.10.2025 20:12] Renaming data file.
[06.10.2025 20:12] Renaming previous data. hf_papers.json to ./d/2025-10-06.json
[06.10.2025 20:12] Saving new data file.
[06.10.2025 20:12] Generating page.
[06.10.2025 20:12] Renaming previous page.
[06.10.2025 20:12] Renaming previous data. index.html to ./d/2025-10-06.html
[06.10.2025 20:12] Writing result.
[06.10.2025 20:12] Renaming log file.
[06.10.2025 20:12] Renaming previous data. log.txt to ./logs/2025-10-06_last_log.txt
