[06.10.2025 05:12] Read previous papers.
[06.10.2025 05:12] Generating top page (month).
[06.10.2025 05:12] Writing top page (month).
[06.10.2025 06:17] Read previous papers.
[06.10.2025 06:17] Get feed.
[06.10.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2510.00515
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01068
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02665
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26354
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01879
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03204
[06.10.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2510.03194
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03120
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03230
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01459
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25771
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03160
[06.10.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02571
[06.10.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2510.01354
[06.10.2025 06:17] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.10.2025 06:17] No deleted papers detected.
[06.10.2025 06:17] Downloading and parsing papers (pdf, html). Total: 14.
[06.10.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2510.00515.
[06.10.2025 06:17] Downloading paper 2510.00515 from http://arxiv.org/pdf/2510.00515v1...
[06.10.2025 06:18] Extracting affiliations from text.
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 ] . [ 1 5 1 5 0 0 . 0 1 5 2 : r Efficient Multi-modal Large Language Models via Progressive Consistency Distillation Zichen Wen1,2 Shaobo Wang1 Yufa Zhou3 Junyuan Zhang4 Qintong Zhang5 Yifeng Gao1 Zhaorun Chen6 Bin Wang2 Weijia Li7,2 Conghui He2 Linfeng Zhang1 1EPIC Lab, Shanghai Jiao Tong University 2Shanghai AI Laboratory 3Duke University 4The University of Hong Kong 5Peking University 6University of Chicago 7Sun Yat-sen University heconghui@pjlab.org.cn, zhanglinfeng@sjtu.edu.cn (cid:135) Code: https://github.com/ZichenWen1/EPIC "
[06.10.2025 06:18] Response: ```python
[
    "EPIC Lab, Shanghai Jiao Tong University",
    "Shanghai AI Laboratory",
    "Duke University",
    "The University of Hong Kong",
    "Peking University",
    "University of Chicago",
    "Sun Yat-sen University"
]
```
[06.10.2025 06:18] Deleting PDF ./assets/pdf/2510.00515.pdf.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.01068.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.01068.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.01068.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.02665.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.02665.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.02665.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2509.26354.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2509.26354.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2509.26354.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.01879.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.01879.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.01879.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.03204.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.03204.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.03204.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.03194.
[06.10.2025 06:18] Downloading paper 2510.03194 from http://arxiv.org/pdf/2510.03194v1...
[06.10.2025 06:18] Extracting affiliations from text.
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 ] . [ 1 4 9 1 3 0 . 0 1 5 2 : r CoDA: Agentic Systems for Collaborative Data Visualization Zichen Chen1 2 *, Jiefeng Chen1, Sercan Ö. Arık1, Misha Sra2, Tomas Pfister1 and Jinsung Yoon1 1Google Cloud AI Research, 2University of California, Santa Barbara Deep research has revolutionized data analysis, yet data scientists still devote substantial time to manually crafting visualizations, highlighting the need for robust automation from natural language queries. However, current systems struggle with complex datasets containing multiple files and iterative refinement. Existing approaches, including simple singleor multi-agent systems, often oversimplify the task, focusing on initial query parsing while failing to robustly manage data complexity, code errors, or final visualization quality. In this paper, we reframe this challenge as collaborative multi-agent problem. We introduce CoDA, multi-agent system that employs specialized LLM agents for metadata analysis, task planning, code generation, and self-reflection. We formalize this pipeline, demonstrating how metadatafocused analysis bypasses token limits and quality-driven refinement ensures robustness. Extensive evaluations show CoDA achieves substantial gains in the overall score, outperforming competitive baselines by up to 41.5%. This work demonstrates that the future of visualization automation lies not in isolated code generation but in integrated, collaborative agentic workflows. 1. Introduction Data visualization plays an important role in business intelligence, data science and decision-making, enabling professionals to uncover insights from complex datasets through intuitive graphical representations (Beschi et al., 2025; Gahar et al., 2024; Jambor, 2024; Ramesh and Rajabiyazdi, 2024; Rogers et al., 2024). In practice, data analysts might spend over two-thirds of their time on low-level data preparation and visualization tasks, often iterating manually to achieve clarity, accuracy, and aesthetic ap"
[06.10.2025 06:18] Response: ```python
["Google Cloud AI Research", "University of California, Santa Barbara"]
```
[06.10.2025 06:18] Deleting PDF ./assets/pdf/2510.03194.pdf.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.03120.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.03120.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.03120.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.03230.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.03230.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.03230.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.01459.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.01459.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.01459.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2509.25771.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2509.25771.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2509.25771.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.03160.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.03160.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.03160.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.02571.
[06.10.2025 06:18] Extra JSON file exists (./assets/json/2510.02571.json), skip PDF parsing.
[06.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.02571.json), skip HTML parsing.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.01354.
[06.10.2025 06:18] Downloading paper 2510.01354 from http://arxiv.org/pdf/2510.01354v1...
[06.10.2025 06:18] Extracting affiliations from text.
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents Yinuo Liu, Ruohan Xu, Xilong Wang, Yuqi Jia, Neil Zhenqiang Gong Duke University {yinuo.liu, ruohan.xu, xilong.wang, yuqi.jia, neil.gong}@duke.edu Abstract Multiple prompt injection attacks have been proposed against web agents. At the same time, various methods have been developed to detect general prompt injection attacks, but none have been systematically evaluated for web agents. In this work, we bridge this gap by presenting the first comprehensive benchmark study on detecting prompt injection attacks targeting web agents. We begin by introducing fine-grained categorization of such attacks based on the threat model. We then construct datasets containing both malicious and benign samples: malicious text segments generated by different attacks, benign text segments from four categories, malicious images produced by attacks, and benign images from two categories. Next, we systematize both text-based and image-based detection methods. Finally, we evaluate their performance across multiple scenarios. Our key findings show that while some detectors can identify attacks that rely on explicit textual instructions or visible image perturbations with moderate to high accuracy, they largely fail against attacks that omit explicit instructions or employ imperceptible perturbations. Our datasets and code are released at: https://github. com/Norrrrrrr-lyn/WAInjectBench. Web agents [Koh et al., 2024, Zhou et al., 2023] fundamentally reshape web interaction by shifting from manual navigation and information retrieval to goal-driven task delegation. Rather than browsing websites, clicking links, and filling forms, users can issue high-level instructions (e.g., book me nonstop flight to NYC this Saturday morning), which the agent executes autonomously through browsing, extraction, and multi-step reasoning. This paradigm shift holds significant potential for improving both accessibility and efficiency. However"
[06.10.2025 06:18] Response: ```python
["Duke University"]
```
[06.10.2025 06:18] Deleting PDF ./assets/pdf/2510.01354.pdf.
[06.10.2025 06:18] Success.
[06.10.2025 06:18] Enriching papers with extra data.
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 0. EPIC, a progressive learning framework, improves the efficiency of multi-modal large models by reducing training difficulty through token and layer consistency distillation during visual token compression.  					AI-generated summary 				 Visual tokens consume substantial computational resources in m...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 1. General Policy Composition (GPC) enhances robotic control performance by combining pre-trained diffusion-based policies without additional training, leading to superior results across various benchmarks.  					AI-generated summary 				 Diffusion-based models for robotic control, including vision-lan...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 2. A survey of self-improvement methods in Multimodal Large Language Models (MLLMs) from data collection, organization, and model optimization perspectives.  					AI-generated summary 				 Recent advancements in self-improvement for Large Language Models (LLMs) have efficiently enhanced model capabilit...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 3. Self-evolving agents based on Large Language Models can deviate in unintended ways, leading to various risks such as safety misalignment and vulnerability introduction, necessitating new safety paradigms.  					AI-generated summary 				 Advances in Large Language Models (LLMs) have enabled a new cla...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 4. REPAIR is a lifelong editing framework for large language models that enhances editing accuracy and reduces knowledge forgetting through progressive adaptive intervention and reintegration.  					AI-generated summary 				 Post-training for large language models (LLMs) is constrained by the high cost...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 5. FocusAgent uses a lightweight LLM retriever to extract relevant content from web page observations, improving efficiency and security in web agents.  					AI-generated summary 				 Web agents powered by large language models (LLMs) must process lengthy web page observations to complete user goals; t...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 6. CoDA, a multi-agent system using specialized LLM agents, enhances visualization automation by managing data complexity and ensuring high-quality visualizations through collaborative workflows.  					AI-generated summary 				 Deep research has revolutionized data analysis, yet data scientists still d...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 7. A new evaluation framework, SurveyBench, assesses the quality of automatically generated academic surveys using a quiz-driven approach, revealing deficiencies in current LLM4Survey methods.  					AI-generated summary 				 Academic survey writing, which distills vast literature into a coherent and in...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 8. Explicit coordinate markers and improved spatial encoding enhance GUI grounding accuracy across diverse resolutions and platforms.  					AI-generated summary 				 GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains diff...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 9. Length-aware Sampling for Policy Optimization (LSPO) is a meta-RLVR algorithm that dynamically selects training data based on response length, improving learning effectiveness in large language models.  					AI-generated summary 				 Since the release of Deepseek-R1, reinforcement learning with veri...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 10. A new framework, Text Preference Optimization (TPO), aligns text-to-image models with human preferences without requiring paired image preference data, improving text-to-image alignment and human preference scores.  					AI-generated summary 				 Recent advances in diffusion-based text-to-image (T2I...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 11. SpineMed, an ecosystem with SpineMed-450k and SpineBench, addresses the lack of level-aware, multimodal datasets and benchmarks for AI-assisted diagnosis of spine disorders, improving model performance through fine-grained, level-specific reasoning.  					AI-generated summary 				 Spine disorders af...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 12. A framework for uncertainty quantification in generative video models is introduced, including a metric for calibration, a black-box method called S-QUBED, and a benchmark dataset, demonstrating improved uncertainty estimates and task accuracy.  					AI-generated summary 				 Generative video models...
[06.10.2025 06:18] ********************************************************************************
[06.10.2025 06:18] Abstract 13. A comprehensive benchmark study evaluates the detection of prompt injection attacks against web agents, revealing that current detectors perform well against explicit attacks but struggle with subtle ones.  					AI-generated summary 				 Multiple prompt injection attacks have been proposed against w...
[06.10.2025 06:18] Read previous papers.
[06.10.2025 06:18] Generating reviews via LLM API.
[06.10.2025 06:18] Querying the API.
[06.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

EPIC, a progressive learning framework, improves the efficiency of multi-modal large models by reducing training difficulty through token and layer consistency distillation during visual token compression.  					AI-generated summary 				 Visual tokens consume substantial computational resources in multi-modal large models (MLLMs), significantly compromising their efficiency. Recent works have attempted to improve efficiency by compressing visual tokens during training, either through modifications to model components or by introducing additional parameters. However, they often overlook the increased learning difficulty caused by such compression, as the model's parameter space struggles to quickly adapt to the substantial perturbations in the feature space induced by token compression. In this work, we propose to develop Efficient MLLMs via Progressive Consistency Distillation (EPIC), a progressive learning framework. Specifically, by decomposing the feature space perturbations introduced by token compression along the token-wise and layer-wise dimensions, we introduce token consistency distillation and layer consistency distillation, respectively, aiming to reduce the training difficulty by leveraging guidance from a teacher model and following a progressive learning trajectory. Extensive experiments demonstrate the superior effectiveness, robustness, and generalization capabilities of our proposed framework.
[06.10.2025 06:18] Response: ```json
{
  "title": "Прогрессивное сжатие визуальных токенов через дистилляцию",
  "desc": "EPIC — это фреймворк для эффективного обучения мультимодальных LLM, который решает проблему больших вычислительных затрат на обработку визуальных токенов. Основная идея заключается в том, что сжатие токенов во время обучения создаёт сильные возмущения в пространстве признаков, что усложняет обучение модели. Авторы предлагают прогрессивный подход с двумя видами дистилляции: по токенам и по слоям, используя учителя-модель для постепенной адаптации к сжатию. Эксперименты показывают, что метод эффективно снижает сложность обучения и улучшает производительность мультимодальных моделей.",
  "emoji": "🎯"
}
```
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"EPIC, a progressive learning framework, improves the efficiency of multi-modal large models by reducing training difficulty through token and layer consistency distillation during visual token compression.  					AI-generated summary 				 Visual tokens consume substantial computational resources in multi-modal large models (MLLMs), significantly compromising their efficiency. Recent works have attempted to improve efficiency by compressing visual tokens during training, either through modifications to model components or by introducing additional parameters. However, they often overlook the increased learning difficulty caused by such compression, as the model's parameter space struggles to quickly adapt to the substantial perturbations in the feature space induced by token compression. In this work, we propose to develop Efficient MLLMs via Progressive Consistency Distillation (EPIC), a progressive learning framework. Specifically, by decomposing the feature space perturbations introduced by token compression along the token-wise and layer-wise dimensions, we introduce token consistency distillation and layer consistency distillation, respectively, aiming to reduce the training difficulty by leveraging guidance from a teacher model and following a progressive learning trajectory. Extensive experiments demonstrate the superior effectiveness, robustness, and generalization capabilities of our proposed framework."

[06.10.2025 06:18] Response: ```python
['TRAINING', 'MULTIMODAL', 'ARCHITECTURE']
```
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"EPIC, a progressive learning framework, improves the efficiency of multi-modal large models by reducing training difficulty through token and layer consistency distillation during visual token compression.  					AI-generated summary 				 Visual tokens consume substantial computational resources in multi-modal large models (MLLMs), significantly compromising their efficiency. Recent works have attempted to improve efficiency by compressing visual tokens during training, either through modifications to model components or by introducing additional parameters. However, they often overlook the increased learning difficulty caused by such compression, as the model's parameter space struggles to quickly adapt to the substantial perturbations in the feature space induced by token compression. In this work, we propose to develop Efficient MLLMs via Progressive Consistency Distillation (EPIC), a progressive learning framework. Specifically, by decomposing the feature space perturbations introduced by token compression along the token-wise and layer-wise dimensions, we introduce token consistency distillation and layer consistency distillation, respectively, aiming to reduce the training difficulty by leveraging guidance from a teacher model and following a progressive learning trajectory. Extensive experiments demonstrate the superior effectiveness, robustness, and generalization capabilities of our proposed framework."

[06.10.2025 06:18] Response: ```python
["OPTIMIZATION"]
```
[06.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces EPIC, a framework designed to enhance the efficiency of multi-modal large models (MLLMs) by addressing the challenges posed by visual token compression. It focuses on reducing the training difficulty associated with this compression through two key strategies: token consistency distillation and layer consistency distillation. By breaking down the perturbations in the feature space, EPIC allows the model to learn progressively, using guidance from a teacher model to adapt more effectively. Experimental results show that EPIC significantly improves the performance, robustness, and generalization of MLLMs compared to previous methods.","title":"Enhancing MLLM Efficiency with Progressive Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces EPIC, a framework designed to enhance the efficiency of multi-modal large models (MLLMs) by addressing the challenges posed by visual token compression. It focuses on reducing the training difficulty associated with this compression through two key strategies: token consistency distillation and layer consistency distillation. By breaking down the perturbations in the feature space, EPIC allows the model to learn progressively, using guidance from a teacher model to adapt more effectively. Experimental results show that EPIC significantly improves the performance, robustness, and generalization of MLLMs compared to previous methods.', title='Enhancing MLLM Efficiency with Progressive Learning'))
[06.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"EPIC是一种渐进学习框架，通过在视觉令牌压缩过程中进行令牌和层一致性蒸馏，降低训练难度，从而提高多模态大模型的效率。视觉令牌在多模态大模型中消耗大量计算资源，影响模型的效率。以往的研究虽然尝试通过压缩视觉令牌来提高效率，但往往忽视了压缩带来的学习难度。我们的方法通过引导教师模型，分解特征空间的扰动，采用渐进学习轨迹，显著提升了模型的有效性、鲁棒性和泛化能力。","title":"EPIC：提升多模态大模型效率的渐进学习框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='EPIC是一种渐进学习框架，通过在视觉令牌压缩过程中进行令牌和层一致性蒸馏，降低训练难度，从而提高多模态大模型的效率。视觉令牌在多模态大模型中消耗大量计算资源，影响模型的效率。以往的研究虽然尝试通过压缩视觉令牌来提高效率，但往往忽视了压缩带来的学习难度。我们的方法通过引导教师模型，分解特征空间的扰动，采用渐进学习轨迹，显著提升了模型的有效性、鲁棒性和泛化能力。', title='EPIC：提升多模态大模型效率的渐进学习框架'))
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#training", "#robotics", "#optimization", "#benchmark", "#diffusion", "#agents"], "emoji": "🤝", "ru": {"title": "Композиция policy без обучения превосходит отдельные модели", "desc": "Статья представляет метод General Policy Composition (GPC), который позволяет улучшить производител
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#training", "#survey", "#optimization", "#multimodal", "#data", "#dataset"], "emoji": "🔄", "ru": {"title": "Мультимодальные LLM учатся сами: обзор методов самосовершенствования", "desc": "Статья представляет первый комплексный обзор методов самосовершенствования мультимодальных LLM.
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#agents", "#security", "#safety", "#rl"], "emoji": "🧬", "ru": {"title": "Когда AI-агенты эволюционируют в неправильную сторону", "desc": "Исследование изучает новый тип рисков в самообучающихся агентах на основе LLM, которые автономно улучшаются через взаимо
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "🔧", "ru": {"title": "Непрерывное обучение языковых моделей без забывания знаний", "desc": "В статье представлен фреймворк REPAIR для редактирования больших языковых моделей (LLM), который позволяет исправлять ошибки и добавлять н
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#long_context", "#inference", "#benchmark", "#agents", "#security", "#reasoning"], "emoji": "🎯", "ru": {"title": "Фокусировка внимания веб-агентов для эффективности и безопасности", "desc": "FocusAgent — это подход для создания веб-агентов на основе LLM, который использует лёгкий re
[06.10.2025 06:18] Querying the API.
[06.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

CoDA, a multi-agent system using specialized LLM agents, enhances visualization automation by managing data complexity and ensuring high-quality visualizations through collaborative workflows.  					AI-generated summary 				 Deep research has revolutionized data analysis, yet data scientists still devote substantial time to manually crafting visualizations, highlighting the need for robust automation from natural language queries. However, current systems struggle with complex datasets containing multiple files and iterative refinement. Existing approaches, including simple single- or multi-agent systems, often oversimplify the task, focusing on initial query parsing while failing to robustly manage data complexity, code errors, or final visualization quality. In this paper, we reframe this challenge as a collaborative multi-agent problem. We introduce CoDA, a multi-agent system that employs specialized LLM agents for metadata analysis, task planning, code generation, and self-reflection. We formalize this pipeline, demonstrating how metadata-focused analysis bypasses token limits and quality-driven refinement ensures robustness. Extensive evaluations show CoDA achieves substantial gains in the overall score, outperforming competitive baselines by up to 41.5%. This work demonstrates that the future of visualization automation lies not in isolated code generation but in integrated, collaborative agentic workflows.
[06.10.2025 06:18] Response: ```json
{
  "title": "Команда AI-агентов для автоматической визуализации данных",
  "desc": "Статья представляет CoDA — мультиагентную систему на основе LLM, которая автоматизирует создание визуализаций из текстовых запросов. Система использует специализированных агентов для анализа метаданных, планирования задач, генерации кода и самопроверки, что позволяет работать со сложными датасетами. CoDA превосходит существующие подходы на 41.5% благодаря коллаборативному взаимодействию агентов и итеративной проверке качества. Исследование показывает, что будущее автоматизации визуализации — в совместной работе специализированных AI-агентов, а не в изолированной генерации кода.",
  "emoji": "🤝"
}
```
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CoDA, a multi-agent system using specialized LLM agents, enhances visualization automation by managing data complexity and ensuring high-quality visualizations through collaborative workflows.  					AI-generated summary 				 Deep research has revolutionized data analysis, yet data scientists still devote substantial time to manually crafting visualizations, highlighting the need for robust automation from natural language queries. However, current systems struggle with complex datasets containing multiple files and iterative refinement. Existing approaches, including simple single- or multi-agent systems, often oversimplify the task, focusing on initial query parsing while failing to robustly manage data complexity, code errors, or final visualization quality. In this paper, we reframe this challenge as a collaborative multi-agent problem. We introduce CoDA, a multi-agent system that employs specialized LLM agents for metadata analysis, task planning, code generation, and self-reflection. We formalize this pipeline, demonstrating how metadata-focused analysis bypasses token limits and quality-driven refinement ensures robustness. Extensive evaluations show CoDA achieves substantial gains in the overall score, outperforming competitive baselines by up to 41.5%. This work demonstrates that the future of visualization automation lies not in isolated code generation but in integrated, collaborative agentic workflows."

[06.10.2025 06:18] Response: ```python
['AGENTS', 'MULTIMODAL', 'DATA']
```
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CoDA, a multi-agent system using specialized LLM agents, enhances visualization automation by managing data complexity and ensuring high-quality visualizations through collaborative workflows.  					AI-generated summary 				 Deep research has revolutionized data analysis, yet data scientists still devote substantial time to manually crafting visualizations, highlighting the need for robust automation from natural language queries. However, current systems struggle with complex datasets containing multiple files and iterative refinement. Existing approaches, including simple single- or multi-agent systems, often oversimplify the task, focusing on initial query parsing while failing to robustly manage data complexity, code errors, or final visualization quality. In this paper, we reframe this challenge as a collaborative multi-agent problem. We introduce CoDA, a multi-agent system that employs specialized LLM agents for metadata analysis, task planning, code generation, and self-reflection. We formalize this pipeline, demonstrating how metadata-focused analysis bypasses token limits and quality-driven refinement ensures robustness. Extensive evaluations show CoDA achieves substantial gains in the overall score, outperforming competitive baselines by up to 41.5%. This work demonstrates that the future of visualization automation lies not in isolated code generation but in integrated, collaborative agentic workflows."

[06.10.2025 06:18] Response: ```python
["OPTIMIZATION", "INTERPRETABILITY"]
```
[06.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents CoDA, a multi-agent system designed to automate the visualization process by utilizing specialized large language model (LLM) agents. CoDA addresses the challenges of managing complex datasets and improving visualization quality through collaborative workflows, rather than relying on traditional single-agent systems. The system focuses on metadata analysis, task planning, and iterative refinement to enhance the robustness of visualizations. Evaluation results indicate that CoDA significantly outperforms existing methods, highlighting the importance of integrated approaches in visualization automation.","title":"CoDA: Revolutionizing Visualization Automation with Collaborative Agents"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents CoDA, a multi-agent system designed to automate the visualization process by utilizing specialized large language model (LLM) agents. CoDA addresses the challenges of managing complex datasets and improving visualization quality through collaborative workflows, rather than relying on traditional single-agent systems. The system focuses on metadata analysis, task planning, and iterative refinement to enhance the robustness of visualizations. Evaluation results indicate that CoDA significantly outperforms existing methods, highlighting the importance of integrated approaches in visualization automation.', title='CoDA: Revolutionizing Visualization Automation with Collaborative Agents'))
[06.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CoDA是一种多智能体系统，利用专门的语言模型代理来增强可视化自动化。它通过管理数据复杂性和确保高质量的可视化，支持协作工作流程。该系统解决了现有方法在处理复杂数据集时的不足，能够有效进行元数据分析、任务规划和代码生成。研究表明，CoDA在整体评分上显著优于竞争对手，展示了未来可视化自动化的潜力在于集成的协作智能体工作流程。","title":"CoDA：协作智能体驱动的可视化自动化新未来"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CoDA是一种多智能体系统，利用专门的语言模型代理来增强可视化自动化。它通过管理数据复杂性和确保高质量的可视化，支持协作工作流程。该系统解决了现有方法在处理复杂数据集时的不足，能够有效进行元数据分析、任务规划和代码生成。研究表明，CoDA在整体评分上显著优于竞争对手，展示了未来可视化自动化的潜力在于集成的协作智能体工作流程。', title='CoDA：协作智能体驱动的可视化自动化新未来'))
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#survey", "#benchmark"], "emoji": "📊", "ru": {"title": "SurveyBench: бенчмарк для проверки AI-генерации научных обзоров через викторины", "desc": "Исследователи представили SurveyBench — новый фреймворк для оценки качества автоматически сгенерированных научных обзоров с помощью LLM.
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#interpretability", "#agents", "#cv", "#optimization"], "emoji": "🎯", "ru": {"title": "Явные координаты вместо угадывания: как научить модели точно находить элементы интерфейса", "desc": "Статья посвящена проблеме GUI grounding — задаче сопоставления текстовых инструкций с координат
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl", "#reasoning"], "emoji": "📏", "ru": {"title": "Учёт длины ответов для эффективного обучения LLM", "desc": "В статье представлен LSPO — мета-алгоритм обучения с подкреплением, который динамически выбирает обучающие данные на основе длины от
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#open_source", "#alignment", "#benchmark", "#rlhf", "#multimodal", "#diffusion"], "emoji": "🎯", "ru": {"title": "Бесплатное выравнивание: обучение без парных предпочтений", "desc": "Представлен фреймворк Text Preference Optimization (TPO) для выравнивания text-to-image моделей с чел
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#training", "#healthcare", "#benchmark", "#dataset", "#multimodal", "#science"], "emoji": "🦴", "ru": {"title": "SpineMed: AI-система для точной диагностики позвоночника на уровне отдельных позвонков", "desc": "Статья представляет SpineMed — экосистему для AI-диагностик
[06.10.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#hallucinations", "#dataset", "#video"], "emoji": "🎬", "ru": {"title": "Когда AI не уверен в своём видео", "desc": "Исследователи представили первый фреймворк для количественной оценки неопределённости в генеративных видеомоделях, которые, как и LLM, с
[06.10.2025 06:18] Querying the API.
[06.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A comprehensive benchmark study evaluates the detection of prompt injection attacks against web agents, revealing that current detectors perform well against explicit attacks but struggle with subtle ones.  					AI-generated summary 				 Multiple prompt injection attacks have been proposed against web agents. At the same time, various methods have been developed to detect general prompt injection attacks, but none have been systematically evaluated for web agents. In this work, we bridge this gap by presenting the first comprehensive benchmark study on detecting prompt injection attacks targeting web agents. We begin by introducing a fine-grained categorization of such attacks based on the threat model. We then construct datasets containing both malicious and benign samples: malicious text segments generated by different attacks, benign text segments from four categories, malicious images produced by attacks, and benign images from two categories. Next, we systematize both text-based and image-based detection methods. Finally, we evaluate their performance across multiple scenarios. Our key findings show that while some detectors can identify attacks that rely on explicit textual instructions or visible image perturbations with moderate to high accuracy, they largely fail against attacks that omit explicit instructions or employ imperceptible perturbations. Our datasets and code are released at: https://github.com/Norrrrrrr-lyn/WAInjectBench.
[06.10.2025 06:18] Response: ```json
{
  "title": "Детекторы инъекций промптов не справляются с тонкими атаками на веб-агентов",
  "desc": "Исследователи провели первое комплексное тестирование методов обнаружения атак типа prompt injection на веб-агентов с использованием AI. Они создали детальную классификацию таких атак и собрали датасеты с вредоносными и безопасными текстовыми и визуальными примерами. Результаты показали, что существующие детекторы хорошо распознают явные атаки с прямыми инструкциями или видимыми искажениями изображений. Однако они практически беспомощны против скрытых атак без явных инструкций или с незаметными модификациями, что выявляет серьёзные проблемы в защите LLM-агентов.",
  "emoji": "🕵️"
}
```
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A comprehensive benchmark study evaluates the detection of prompt injection attacks against web agents, revealing that current detectors perform well against explicit attacks but struggle with subtle ones.  					AI-generated summary 				 Multiple prompt injection attacks have been proposed against web agents. At the same time, various methods have been developed to detect general prompt injection attacks, but none have been systematically evaluated for web agents. In this work, we bridge this gap by presenting the first comprehensive benchmark study on detecting prompt injection attacks targeting web agents. We begin by introducing a fine-grained categorization of such attacks based on the threat model. We then construct datasets containing both malicious and benign samples: malicious text segments generated by different attacks, benign text segments from four categories, malicious images produced by attacks, and benign images from two categories. Next, we systematize both text-based and image-based detection methods. Finally, we evaluate their performance across multiple scenarios. Our key findings show that while some detectors can identify attacks that rely on explicit textual instructions or visible image perturbations with moderate to high accuracy, they largely fail against attacks that omit explicit instructions or employ imperceptible perturbations. Our datasets and code are released at: https://github.com/Norrrrrrr-lyn/WAInjectBench."

[06.10.2025 06:18] Response: ```python
['BENCHMARK', 'AGENTS', 'DATASET']
```
[06.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A comprehensive benchmark study evaluates the detection of prompt injection attacks against web agents, revealing that current detectors perform well against explicit attacks but struggle with subtle ones.  					AI-generated summary 				 Multiple prompt injection attacks have been proposed against web agents. At the same time, various methods have been developed to detect general prompt injection attacks, but none have been systematically evaluated for web agents. In this work, we bridge this gap by presenting the first comprehensive benchmark study on detecting prompt injection attacks targeting web agents. We begin by introducing a fine-grained categorization of such attacks based on the threat model. We then construct datasets containing both malicious and benign samples: malicious text segments generated by different attacks, benign text segments from four categories, malicious images produced by attacks, and benign images from two categories. Next, we systematize both text-based and image-based detection methods. Finally, we evaluate their performance across multiple scenarios. Our key findings show that while some detectors can identify attacks that rely on explicit textual instructions or visible image perturbations with moderate to high accuracy, they largely fail against attacks that omit explicit instructions or employ imperceptible perturbations. Our datasets and code are released at: https://github.com/Norrrrrrr-lyn/WAInjectBench."

[06.10.2025 06:19] Response: ```python
["SECURITY"]
```
[06.10.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a thorough benchmark study on detecting prompt injection attacks aimed at web agents. It categorizes these attacks based on their threat models and creates datasets with both malicious and benign samples, including text and images. The study evaluates various detection methods, revealing that while some can effectively identify explicit attacks, they struggle with more subtle ones that lack clear instructions or use imperceptible changes. The findings highlight the need for improved detection techniques to address the challenges posed by nuanced prompt injection attacks.","title":"Bridging the Gap in Detecting Subtle Prompt Injection Attacks"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a thorough benchmark study on detecting prompt injection attacks aimed at web agents. It categorizes these attacks based on their threat models and creates datasets with both malicious and benign samples, including text and images. The study evaluates various detection methods, revealing that while some can effectively identify explicit attacks, they struggle with more subtle ones that lack clear instructions or use imperceptible changes. The findings highlight the need for improved detection techniques to address the challenges posed by nuanced prompt injection attacks.', title='Bridging the Gap in Detecting Subtle Prompt Injection Attacks'))
[06.10.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究对针对网络代理的提示注入攻击检测进行了全面的基准评估。我们发现，当前的检测器在识别明显攻击时表现良好，但在处理微妙攻击时却面临挑战。我们构建了包含恶意和良性样本的数据集，并对文本和图像的检测方法进行了系统化。研究结果表明，尽管一些检测器能够有效识别依赖于明确文本指令的攻击，但在面对缺乏明确指令或使用不可察觉扰动的攻击时，它们的表现大幅下降。","title":"全面评估网络代理的提示注入攻击检测"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究对针对网络代理的提示注入攻击检测进行了全面的基准评估。我们发现，当前的检测器在识别明显攻击时表现良好，但在处理微妙攻击时却面临挑战。我们构建了包含恶意和良性样本的数据集，并对文本和图像的检测方法进行了系统化。研究结果表明，尽管一些检测器能够有效识别依赖于明确文本指令的攻击，但在面对缺乏明确指令或使用不可察觉扰动的攻击时，它们的表现大幅下降。', title='全面评估网络代理的提示注入攻击检测'))
[06.10.2025 06:19] Renaming data file.
[06.10.2025 06:19] Renaming previous data. hf_papers.json to ./d/2025-10-06.json
[06.10.2025 06:19] Saving new data file.
[06.10.2025 06:19] Generating page.
[06.10.2025 06:19] Renaming previous page.
[06.10.2025 06:19] Renaming previous data. index.html to ./d/2025-10-06.html
[06.10.2025 06:19] Writing result.
[06.10.2025 06:19] Renaming log file.
[06.10.2025 06:19] Renaming previous data. log.txt to ./logs/2025-10-06_last_log.txt
