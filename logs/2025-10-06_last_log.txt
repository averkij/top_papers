[06.10.2025 06:19] Read previous papers.
[06.10.2025 06:19] Generating top page (month).
[06.10.2025 06:19] Writing top page (month).
[06.10.2025 07:13] Read previous papers.
[06.10.2025 07:13] Get feed.
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00515
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01068
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02665
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03120
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26354
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01879
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03204
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03194
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03230
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01459
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.25771
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03160
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02571
[06.10.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01354
[06.10.2025 07:13] Extract page data from URL. URL: https://huggingface.co/papers/2510.00658
[06.10.2025 07:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.10.2025 07:13] No deleted papers detected.
[06.10.2025 07:13] Downloading and parsing papers (pdf, html). Total: 15.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.00515.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.00515.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.00515.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01068.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01068.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01068.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.02665.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.02665.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.02665.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03120.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03120.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03120.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2509.26354.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2509.26354.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2509.26354.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01879.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01879.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01879.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03204.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03204.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03204.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03194.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03194.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03194.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03230.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03230.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03230.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01459.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01459.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01459.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2509.25771.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2509.25771.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2509.25771.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.03160.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.03160.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.03160.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.02571.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.02571.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.02571.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.01354.
[06.10.2025 07:13] Extra JSON file exists (./assets/json/2510.01354.json), skip PDF parsing.
[06.10.2025 07:13] Paper image links file exists (./assets/img_data/2510.01354.json), skip HTML parsing.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2510.00658.
[06.10.2025 07:13] Downloading paper 2510.00658 from http://arxiv.org/pdf/2510.00658v1...
[06.10.2025 07:13] Extracting affiliations from text.
[06.10.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 ] . [ 1 8 5 6 0 0 . 0 1 5 2 : r Preprint. ALIGN YOUR TANGENT: TRAINING BETTER CONSISTENCY MODELS VIA MANIFOLD-ALIGNED TANGENTS Beomsu Kim*, Byunghee Cha*, Jong Chul Ye Graduate School of AI, KAIST *Equal Contribution "
[06.10.2025 07:13] Response: ```python
["Graduate School of AI, KAIST"]
```
[06.10.2025 07:13] Deleting PDF ./assets/pdf/2510.00658.pdf.
[06.10.2025 07:13] Success.
[06.10.2025 07:13] Enriching papers with extra data.
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 0. EPIC, a progressive learning framework, improves the efficiency of multi-modal large models by reducing training difficulty through token and layer consistency distillation during visual token compression.  					AI-generated summary 				 Visual tokens consume substantial computational resources in m...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 1. General Policy Composition (GPC) enhances robotic control performance by combining pre-trained diffusion-based policies without additional training, leading to superior results across various benchmarks.  					AI-generated summary 				 Diffusion-based models for robotic control, including vision-lan...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 2. A survey of self-improvement methods in Multimodal Large Language Models (MLLMs) from data collection, organization, and model optimization perspectives.  					AI-generated summary 				 Recent advancements in self-improvement for Large Language Models (LLMs) have efficiently enhanced model capabilit...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 3. A new evaluation framework, SurveyBench, assesses the quality of automatically generated academic surveys using a quiz-driven approach, revealing deficiencies in current LLM4Survey methods.  					AI-generated summary 				 Academic survey writing, which distills vast literature into a coherent and in...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 4. Self-evolving agents based on Large Language Models can deviate in unintended ways, leading to various risks such as safety misalignment and vulnerability introduction, necessitating new safety paradigms.  					AI-generated summary 				 Advances in Large Language Models (LLMs) have enabled a new cla...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 5. REPAIR is a lifelong editing framework for large language models that enhances editing accuracy and reduces knowledge forgetting through progressive adaptive intervention and reintegration.  					AI-generated summary 				 Post-training for large language models (LLMs) is constrained by the high cost...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 6. FocusAgent uses a lightweight LLM retriever to extract relevant content from web page observations, improving efficiency and security in web agents.  					AI-generated summary 				 Web agents powered by large language models (LLMs) must process lengthy web page observations to complete user goals; t...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 7. CoDA, a multi-agent system using specialized LLM agents, enhances visualization automation by managing data complexity and ensuring high-quality visualizations through collaborative workflows.  					AI-generated summary 				 Deep research has revolutionized data analysis, yet data scientists still d...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 8. Explicit coordinate markers and improved spatial encoding enhance GUI grounding accuracy across diverse resolutions and platforms.  					AI-generated summary 				 GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains diff...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 9. Length-aware Sampling for Policy Optimization (LSPO) is a meta-RLVR algorithm that dynamically selects training data based on response length, improving learning effectiveness in large language models.  					AI-generated summary 				 Since the release of Deepseek-R1, reinforcement learning with veri...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 10. A new framework, Text Preference Optimization (TPO), aligns text-to-image models with human preferences without requiring paired image preference data, improving text-to-image alignment and human preference scores.  					AI-generated summary 				 Recent advances in diffusion-based text-to-image (T2I...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 11. SpineMed, an ecosystem with SpineMed-450k and SpineBench, addresses the lack of level-aware, multimodal datasets and benchmarks for AI-assisted diagnosis of spine disorders, improving model performance through fine-grained, level-specific reasoning.  					AI-generated summary 				 Spine disorders af...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 12. A framework for uncertainty quantification in generative video models is introduced, including a metric for calibration, a black-box method called S-QUBED, and a benchmark dataset, demonstrating improved uncertainty estimates and task accuracy.  					AI-generated summary 				 Generative video models...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 13. A comprehensive benchmark study evaluates the detection of prompt injection attacks against web agents, revealing that current detectors perform well against explicit attacks but struggle with subtle ones.  					AI-generated summary 				 Multiple prompt injection attacks have been proposed against w...
[06.10.2025 07:13] ********************************************************************************
[06.10.2025 07:13] Abstract 14. Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the communi...
[06.10.2025 07:13] Read previous papers.
[06.10.2025 07:13] Generating reviews via LLM API.
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture", "#multimodal"], "emoji": "🎯", "ru": {"title": "Прогрессивное сжатие визуальных токенов через дистилляцию", "desc": "EPIC — это фреймворк для эффективного обучения мультимодальных LLM, который решает проблему больших вычислительных затрат
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#training", "#robotics", "#optimization", "#benchmark", "#diffusion", "#agents"], "emoji": "🤝", "ru": {"title": "Композиция policy без обучения превосходит отдельные модели", "desc": "Статья представляет метод General Policy Composition (GPC), который позволяет улучшить производител
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#training", "#survey", "#optimization", "#multimodal", "#data", "#dataset"], "emoji": "🔄", "ru": {"title": "Мультимодальные LLM учатся сами: обзор методов самосовершенствования", "desc": "Статья представляет первый комплексный обзор методов самосовершенствования мультимодальных LLM.
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#survey", "#benchmark"], "emoji": "📊", "ru": {"title": "SurveyBench: бенчмарк для проверки AI-генерации научных обзоров через викторины", "desc": "Исследователи представили SurveyBench — новый фреймворк для оценки качества автоматически сгенерированных научных обзоров с помощью LLM.
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#agents", "#security", "#safety", "#rl"], "emoji": "🧬", "ru": {"title": "Когда AI-агенты эволюционируют в неправильную сторону", "desc": "Исследование изучает новый тип рисков в самообучающихся агентах на основе LLM, которые автономно улучшаются через взаимо
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "🔧", "ru": {"title": "Непрерывное обучение языковых моделей без забывания знаний", "desc": "В статье представлен фреймворк REPAIR для редактирования больших языковых моделей (LLM), который позволяет исправлять ошибки и добавлять н
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#long_context", "#inference", "#benchmark", "#agents", "#security", "#reasoning"], "emoji": "🎯", "ru": {"title": "Фокусировка внимания веб-агентов для эффективности и безопасности", "desc": "FocusAgent — это подход для создания веб-агентов на основе LLM, который использует лёгкий re
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#agents", "#optimization", "#data", "#interpretability", "#multimodal"], "emoji": "🤝", "ru": {"title": "Команда AI-агентов для автоматической визуализации данных", "desc": "Статья представляет CoDA — мультиагентную систему на основе LLM, которая автоматизирует создание визуализаций 
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#interpretability", "#agents", "#cv", "#optimization"], "emoji": "🎯", "ru": {"title": "Явные координаты вместо угадывания: как научить модели точно находить элементы интерфейса", "desc": "Статья посвящена проблеме GUI grounding — задаче сопоставления текстовых инструкций с координат
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl", "#reasoning"], "emoji": "📏", "ru": {"title": "Учёт длины ответов для эффективного обучения LLM", "desc": "В статье представлен LSPO — мета-алгоритм обучения с подкреплением, который динамически выбирает обучающие данные на основе длины от
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#open_source", "#alignment", "#benchmark", "#rlhf", "#multimodal", "#diffusion"], "emoji": "🎯", "ru": {"title": "Бесплатное выравнивание: обучение без парных предпочтений", "desc": "Представлен фреймворк Text Preference Optimization (TPO) для выравнивания text-to-image моделей с чел
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#reasoning", "#training", "#healthcare", "#benchmark", "#dataset", "#multimodal", "#science"], "emoji": "🦴", "ru": {"title": "SpineMed: AI-система для точной диагностики позвоночника на уровне отдельных позвонков", "desc": "Статья представляет SpineMed — экосистему для AI-диагностик
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#hallucinations", "#dataset", "#video"], "emoji": "🎬", "ru": {"title": "Когда AI не уверен в своём видео", "desc": "Исследователи представили первый фреймворк для количественной оценки неопределённости в генеративных видеомоделях, которые, как и LLM, с
[06.10.2025 07:13] Using data from previous issue: {"categories": ["#agents", "#dataset", "#benchmark", "#security"], "emoji": "🕵️", "ru": {"title": "Детекторы инъекций промптов не справляются с тонкими атаками на веб-агентов", "desc": "Исследователи провели первое комплексное тестирование методов обнаружения атак типа prompt injection на веб-агенто
[06.10.2025 07:13] Querying the API.
[06.10.2025 07:13] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the community now turned to reducing the inference time without sacrificing sample quality. Consistency Models (CMs), which are trained to be consistent on diffusion or probability flow ordinary differential equation (PF-ODE) trajectories, enable one or two-step flow or diffusion sampling. However, CMs typically require prolonged training with large batch sizes to obtain competitive sample quality. In this paper, we examine the training dynamics of CMs near convergence and discover that CM tangents -- CM output update directions -- are quite oscillatory, in the sense that they move parallel to the data manifold, not towards the manifold. To mitigate oscillatory tangents, we propose a new loss function, called the manifold feature distance (MFD), which provides manifold-aligned tangents that point toward the data manifold. Consequently, our method -- dubbed Align Your Tangent (AYT) -- can accelerate CM training by orders of magnitude and even out-perform the learned perceptual image patch similarity metric (LPIPS). Furthermore, we find that our loss enables training with extremely small batch sizes without compromising sample quality. Code: https://github.com/1202kbs/AYT
[06.10.2025 07:13] Response: ```json
{
  "desc": "Consistency Models (CMs) позволяют генерировать изображения за один-два шага, но требуют долгого обучения с большими батчами. Авторы обнаружили, что градиенты CM ведут себя осцилляторно - двигаются параллельно data manifold вместо того, чтобы направляться к нему. Они предложили новую loss-функцию MFD (manifold feature distance), которая выравнивает градиенты по направлению к многообразию данных. Метод Align Your Tangent (AYT) ускоряет обучение CM на порядки величины и позволяет использовать очень маленькие размеры батчей без потери качества.",
  "emoji": "🎯",
  "title": "Выравнивание градиентов для быстрого обучения Consistency Models"
}
```
[06.10.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the community now turned to reducing the inference time without sacrificing sample quality. Consistency Models (CMs), which are trained to be consistent on diffusion or probability flow ordinary differential equation (PF-ODE) trajectories, enable one or two-step flow or diffusion sampling. However, CMs typically require prolonged training with large batch sizes to obtain competitive sample quality. In this paper, we examine the training dynamics of CMs near convergence and discover that CM tangents -- CM output update directions -- are quite oscillatory, in the sense that they move parallel to the data manifold, not towards the manifold. To mitigate oscillatory tangents, we propose a new loss function, called the manifold feature distance (MFD), which provides manifold-aligned tangents that point toward the data manifold. Consequently, our method -- dubbed Align Your Tangent (AYT) -- can accelerate CM training by orders of magnitude and even out-perform the learned perceptual image patch similarity metric (LPIPS). Furthermore, we find that our loss enables training with extremely small batch sizes without compromising sample quality. Code: https://github.com/1202kbs/AYT"

[06.10.2025 07:13] Response: ```python
['TRAINING']
```
[06.10.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Align Your Tangent (AYT) improves Consistency Model training by reducing oscillatory tangents and enabling faster convergence with small batch sizes.  					AI-generated summary 				 With diffusion and flow matching models achieving state-of-the-art generating performance, the interest of the community now turned to reducing the inference time without sacrificing sample quality. Consistency Models (CMs), which are trained to be consistent on diffusion or probability flow ordinary differential equation (PF-ODE) trajectories, enable one or two-step flow or diffusion sampling. However, CMs typically require prolonged training with large batch sizes to obtain competitive sample quality. In this paper, we examine the training dynamics of CMs near convergence and discover that CM tangents -- CM output update directions -- are quite oscillatory, in the sense that they move parallel to the data manifold, not towards the manifold. To mitigate oscillatory tangents, we propose a new loss function, called the manifold feature distance (MFD), which provides manifold-aligned tangents that point toward the data manifold. Consequently, our method -- dubbed Align Your Tangent (AYT) -- can accelerate CM training by orders of magnitude and even out-perform the learned perceptual image patch similarity metric (LPIPS). Furthermore, we find that our loss enables training with extremely small batch sizes without compromising sample quality. Code: https://github.com/1202kbs/AYT"

[06.10.2025 07:13] Response: ```python
["OPTIMIZATION", "DIFFUSION"]
```
[06.10.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Align Your Tangent (AYT), a novel approach to enhance the training of Consistency Models (CMs) by addressing the issue of oscillatory tangents during training. By proposing a new loss function called manifold feature distance (MFD), AYT aligns the output update directions of CMs towards the data manifold, leading to more stable and efficient training dynamics. This method allows for significantly faster convergence, even with small batch sizes, while maintaining high sample quality. The results demonstrate that AYT not only accelerates training but also surpasses existing metrics like LPIPS in performance.","title":"Accelerate Consistency Model Training with AYT!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces Align Your Tangent (AYT), a novel approach to enhance the training of Consistency Models (CMs) by addressing the issue of oscillatory tangents during training. By proposing a new loss function called manifold feature distance (MFD), AYT aligns the output update directions of CMs towards the data manifold, leading to more stable and efficient training dynamics. This method allows for significantly faster convergence, even with small batch sizes, while maintaining high sample quality. The results demonstrate that AYT not only accelerates training but also surpasses existing metrics like LPIPS in performance.', title='Accelerate Consistency Model Training with AYT!'))
[06.10.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的训练方法，称为Align Your Tangent (AYT)，旨在提高一致性模型（CM）的训练效率。通过引入流形特征距离（MFD）损失函数，AYT能够减少训练过程中输出更新方向的振荡，使其更好地指向数据流形。这样，AYT可以在小批量数据下加速训练，并且在样本质量上超过了现有的评估指标。最终，AYT显著提高了CM的收敛速度，减少了对大批量数据的依赖。","title":"对齐你的切线，提升一致性模型训练效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的训练方法，称为Align Your Tangent (AYT)，旨在提高一致性模型（CM）的训练效率。通过引入流形特征距离（MFD）损失函数，AYT能够减少训练过程中输出更新方向的振荡，使其更好地指向数据流形。这样，AYT可以在小批量数据下加速训练，并且在样本质量上超过了现有的评估指标。最终，AYT显著提高了CM的收敛速度，减少了对大批量数据的依赖。', title='对齐你的切线，提升一致性模型训练效率'))
[06.10.2025 07:13] Renaming data file.
[06.10.2025 07:13] Renaming previous data. hf_papers.json to ./d/2025-10-06.json
[06.10.2025 07:13] Saving new data file.
[06.10.2025 07:13] Generating page.
[06.10.2025 07:13] Renaming previous page.
[06.10.2025 07:13] Renaming previous data. index.html to ./d/2025-10-06.html
[06.10.2025 07:13] Writing result.
[06.10.2025 07:13] Renaming log file.
[06.10.2025 07:13] Renaming previous data. log.txt to ./logs/2025-10-06_last_log.txt
