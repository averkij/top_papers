[15.12.2025 12:51] Read previous papers.
[15.12.2025 12:51] Generating top page (month).
[15.12.2025 12:51] Writing top page (month).
[15.12.2025 13:42] Read previous papers.
[15.12.2025 13:42] Get feed.
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.11558
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.08269
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.11749
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.11799
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.10411
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.11253
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.11792
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.11464
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.06818
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.10605
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.10715
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.06951
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.11393
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.10858
[15.12.2025 13:42] Get page data from previous paper. URL: https://huggingface.co/papers/2512.10685
[15.12.2025 13:42] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.12.2025 13:42] No deleted papers detected.
[15.12.2025 13:42] Downloading and parsing papers (pdf, html). Total: 15.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.11558.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.11558.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.11558.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.08269.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.08269.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.08269.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.11749.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.11749.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.11749.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.11799.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.11799.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.11799.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.10411.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.10411.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.10411.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.11253.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.11253.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.11253.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.11792.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.11792.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.11792.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.11464.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.11464.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.11464.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.06818.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.06818.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.06818.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.10605.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.10605.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.10605.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.10715.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.10715.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.10715.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.06951.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.06951.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.06951.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.11393.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.11393.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.11393.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.10858.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.10858.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.10858.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Downloading and parsing paper https://huggingface.co/papers/2512.10685.
[15.12.2025 13:42] Extra JSON file exists (./assets/json/2512.10685.json), skip PDF parsing.
[15.12.2025 13:42] Paper image links file exists (./assets/img_data/2512.10685.json), skip HTML parsing.
[15.12.2025 13:42] Success.
[15.12.2025 13:42] Enriching papers with extra data.
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 0. DentalGPT, a specialized dental multimodal large language model, achieves superior performance in disease classification and dental VQA tasks through high-quality domain knowledge injection and reinforcement learning.  					AI-generated summary 				 Reliable interpretation of multimodal data in dent...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 1. EgoX framework generates egocentric videos from exocentric inputs using video diffusion models with LoRA adaptation, unified conditioning, and geometry-guided self-attention for coherence and visual fidelity.  					AI-generated summary 				 Egocentric perception enables humans to experience and unde...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 2. SVG-T2I, a scaled SVG framework, enables high-quality text-to-image synthesis directly in the Visual Foundation Model feature domain, achieving competitive performance in generative tasks.  					AI-generated summary 				 Visual generation grounded in Visual Foundation Model (VFM) representations off...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 3. V-RGBX is an end-to-end framework for intrinsic-aware video editing that combines video inverse rendering, photorealistic synthesis, and keyframe-based editing to produce consistent and physically plausible edits.  					AI-generated summary 				 Large-scale video generation models have shown remarka...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 4. Sliding Window Attention Adaptation (SWAA) enables Transformer-based Large Language Models (LLMs) to use sliding window attention without retraining, recovering long-context performance through a combination of adaptation techniques.  					AI-generated summary 				 The self-attention mechanism in Tr...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 5. PersonaLive is a diffusion-based framework for real-time portrait animation that enhances speed and efficiency through multi-stage training, hybrid implicit signals, appearance distillation, and autoregressive micro-chunk streaming.  					AI-generated summary 				 Current diffusion-based portrait an...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 6. SAM2VideoX improves realistic motion generation in video models by integrating structure-preserving priors from an autoregressive model into a bidirectional diffusion model with novel feature fusion and local alignment techniques.  					AI-generated summary 				 Reality is a dance between rigid cons...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 7. MetaCanvas leverages multimodal large language models as latent-space planners to enhance precise and structured image and video generation, outperforming global-conditioning methods.  					AI-generated summary 				 Multimodal learning has rapidly advanced visual understanding, largely via multimoda...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 8. MeshSplatting, a mesh-based reconstruction method, enhances novel view synthesis by optimizing geometry and appearance through differentiable rendering, improving quality and efficiency over existing techniques.  					AI-generated summary 				 Primitive-based splatting methods like 3D Gaussian Splat...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 9. A general-purpose language-driven framework for robots, LEO-RobotAgent, enhances human-robot interaction and task planning using large language models across various robot types and tasks.  					AI-generated summary 				 We propose LEO-RobotAgent, a general-purpose language-driven intelligent agent ...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 10. Uncertainty estimation in landmark-based segmentation of chest X-rays using hybrid neural network architectures improves reliability and robustness in clinical deployment.  					AI-generated summary 				 Uncertainty estimation is essential for the safe clinical deployment of medical image segmentati...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 11. A vision-action policy using correlated noise for flow matching and learnable mixed-layer attention wins the 2025 BEHAVIOR Challenge with high performance across diverse household tasks.  					AI-generated summary 				 We present a vision-action policy that won 1st place in the 2025 BEHAVIOR Challen...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 12. A model learns to parallelize tasks from a single egocentric video by addressing spatial and object conflicts, achieving improved action coverage and reduced collisions.  					AI-generated summary 				 Humans can intuitively parallelise complex activities, but can a model learn this from observing a...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 13. Research on DLMs explores their scaling behavior under different noise types, revealing that uniform diffusion is more parameter-efficient and data-efficient compared to masked diffusion.  					AI-generated summary 				 Modern LLM pre-training consumes vast amounts of compute and training data, maki...
[15.12.2025 13:42] ********************************************************************************
[15.12.2025 13:42] Abstract 14. SHARP synthesizes photorealistic views from a single image using a 3D Gaussian representation, achieving state-of-the-art results with rapid processing.  					AI-generated summary 				 We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHAR...
[15.12.2025 13:42] Read previous papers.
[15.12.2025 13:42] Generating reviews via LLM API.
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#healthcare", "#benchmark", "#multimodal", "#science", "#reasoning", "#open_source", "#synthetic", "#training", "#rl", "#dataset"], "emoji": "ü¶∑", "ru": {"title": "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω–æ–π —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏", "desc": "DentalGPT ‚Äî —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#training", "#architecture", "#diffusion", "#video", "#multimodal", "#transfer_learning"], "emoji": "üëÅÔ∏è", "ru": {"title": "–û—Ç –≤–∑–≥–ª—è–¥–∞ —Å–±–æ–∫—É –∫ –≤–∑–≥–ª—è–¥—É –∏–∑–Ω—É—Ç—Ä–∏: –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ", "desc": "EgoX ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ –æ—Ç —Ç—Ä–µ—Ç—å–µ–≥–æ –ª–∏—Ü–∞ –≤
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#open_source", "#training", "#diffusion", "#architecture"], "emoji": "üé®", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ Visual Foundation Model", "desc": "SVG-T2I ‚Äî —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é, –∫
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#multimodal", "#video"], "emoji": "üé¨", "ru": {"title": "–§–∏–∑–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å–≤–æ–π—Å—Ç–≤ —Å—Ü–µ–Ω—ã", "desc": "V-RGBX ‚Äî —ç—Ç–æ —Å–∫–≤–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç—Ä–∏ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: –æ–±—Ä–∞—Ç–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤–∏–¥–µ–æ –¥–ª—è 
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#long_context", "#open_source", "#optimization"], "emoji": "ü™ü", "ru": {"title": "–ê–¥–∞–ø—Ç–∞—Ü–∏—è —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –º–µ—Ç–æ–¥ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ –≤–Ω–∏–º–∞–Ω–∏—è (SWAA) –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä-–º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –±—ã
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#training", "#inference", "#3d", "#video"], "emoji": "üé¨", "ru": {"title": "–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º –≤ 7-22 —Ä–∞–∑–∞", "desc": "PersonaLive ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –ê–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≥
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#architecture", "#video"], "emoji": "üé¨", "ru": {"title": "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤ –¥–≤–∏–∂–µ–Ω–∏–∏: –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–∏–¥–µ–æ", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ SAM2VideoX, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –¥–≤–∏–∂
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#reasoning", "#diffusion", "#video"], "emoji": "üé®", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–∞–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∏ –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –¥–ª—è —Ç–æ—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ MetaCanvas ‚Äî –ª–µ–≥–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#3d", "#cv"], "emoji": "üé®", "ru": {"title": "–°–µ—Ç–∫–∏ –≤–º–µ—Å—Ç–æ –æ–±–ª–∞–∫–æ–≤: –º–æ—Å—Ç –º–µ–∂–¥—É –Ω–µ–π—Ä–æ–Ω–Ω—ã–º —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–æ–º –∏ —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫–æ–π", "desc": "MeshSplatting ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö —Å—Ü–µ–Ω, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ç–æ—á–µ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –∏ —Å–µ—Ç–æ–∫ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –Ω–æ–≤—ã—Ö –≤–∏–¥–æ–≤. –ü–æ–¥—Ö–æ
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#open_source", "#robotics", "#agents"], "emoji": "ü§ñ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç LEO-RobotAgent ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ —Ä–æ–±–æ—Ç–æ–≤. –§—Ä–µ–π
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#cv", "#healthcare", "#architecture", "#dataset", "#benchmark"], "emoji": "ü´Å", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏", "desc": "–†–∞–±–æ—Ç–∞ –∏–∑—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∞–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∏—Ö –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤ –Ω–∞ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≥—Ä–∞–º–º–∞—Ö –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏ —Å
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#robotics", "#benchmark", "#cv", "#training", "#architecture"], "emoji": "ü§ñ", "ru": {"title": "–ö–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —à—É–º –¥–ª—è –≥–ª–∞–¥–∫–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–∞–Ω–∏–ø—É–ª—è—Ç–æ—Ä–æ–º –≤ –¥–æ–º–∞—à–Ω–∏—Ö –∑–∞–¥–∞—á–∞—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –∑—Ä–∏—Ç–µ–ª—å–Ω–æ-–º–æ—Ç–æ—Ä–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–∏–≥—Ä–∞–ª–∞ –∫–æ–Ω–∫—É—Ä—Å
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#video", "#cv", "#multimodal"], "emoji": "üë•", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏ –¥–µ–π—Å—Ç–≤–∏–π –∏–∑ —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ —Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –∑–∞–¥–∞—á—É –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏ –¥–µ–π—Å—Ç–≤–∏–π –∏–∑ –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞. –ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Vision-Language Model –æ–±—É—á–∞
[15.12.2025 13:42] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization", "#open_source", "#diffusion"], "emoji": "üîÑ", "ru": {"title": "–†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—è ‚Äî –ø—É—Ç—å –∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∂–∏–º–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É—é—Ç—Å—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (DLM) –∏ –∏—Ö –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä
[15.12.2025 13:42] Using data from previous issue: {"categories": [], "emoji": "üì∏", "ru": {"title": "–û—Ç –æ–¥–Ω–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∫ –æ–±—ä—ë–º–Ω–æ–º—É 3D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é —Å—Ü–µ–Ω—ã", "desc": "SHARP ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ–∑–∞ —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –≤–∏–¥–æ–≤ —Å—Ü–µ–Ω—ã –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º 3D –≥–∞—É—Å—Å–æ–≤—Å–∫–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è. –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞ –æ–¥–Ω—É –ø—Ä—è–º—É—é –∏—Ç–µ—Ä–∞—Ü–∏—é –Ω–∞ GPU –º–µ–Ω–µ–µ —á–µ
[15.12.2025 13:42] Renaming data file.
[15.12.2025 13:42] Renaming previous data. hf_papers.json to ./d/2025-12-15.json
[15.12.2025 13:42] Saving new data file.
[15.12.2025 13:42] Generating page.
[15.12.2025 13:42] Renaming previous page.
[15.12.2025 13:42] Renaming previous data. index.html to ./d/2025-12-15.html
[15.12.2025 13:42] Writing result.
[15.12.2025 13:42] Renaming log file.
[15.12.2025 13:42] Renaming previous data. log.txt to ./logs/2025-12-15_last_log.txt
