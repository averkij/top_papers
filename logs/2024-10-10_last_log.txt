[11.10.2024 22:11] Get feed.
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08196
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05265
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03450
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08207
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07869
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08164
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07303
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05248
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04751
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08151
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.06508
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07041
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05210
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.06154
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07137
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08049
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08115
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07484
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08159
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05603
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04808
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07707
[11.10.2024 22:11] Extract page data from URL. URL: https://huggingface.co/papers/2410.05269
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05629
[11.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03437
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 0. Code has been shown to be effective in enhancing the mathematical reasoning abilities of large language models due to its precision and accuracy. Previous works involving continued mathematical pretraining often include code that utilizes math-related packages, which are primarily designed for field...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 1. Quantization is essential for deploying Large Language Models (LLMs) by enhancing memory efficiency and inference speed. Existing methods for activation quantization mainly address channel-wise outliers, often neglecting token-wise outliers, leading to reliance on costly per-token dynamic quantizati...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 2. MLLM agents demonstrate potential for complex embodied tasks by retrieving multimodal task-relevant trajectory data. However, current retrieval methods primarily focus on surface-level similarities of textual or visual cues in trajectories, neglecting their effectiveness for the specific task at han...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 3. Discrete diffusion models have achieved success in tasks like image generation and masked language modeling but face limitations in controlled content editing. We introduce DICE (Discrete Inversion for Controllable Editing), the first approach to enable precise inversion for discrete diffusion model...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 4. Large Language Models (LLMs), with their exceptional ability to handle a wide range of tasks, have driven significant advancements in tackling reasoning and planning tasks, wherein decomposing complex problems into executable workflows is a crucial step in this process. Existing workflow evaluation ...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 5. We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks. Agent S aims to address three key challenges in automating computer tas...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 6. Diffusion models have greatly improved visual generation but are hindered by slow generation speed due to the computationally intensive nature of solving generative ODEs. Rectified flow, a widely recognized solution, improves generation speed by straightening the ODE path. Its key components include...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 7. To induce desired behaviors in large language models (LLMs) for interaction-driven tasks, the instruction-tuning stage typically trains LLMs on instruction-response pairs using the next-token prediction (NTP) loss. Previous work aiming to improve instruction-tuning performance often emphasizes the n...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 8. Recently, large language and vision models (LLVMs) have received significant attention and development efforts due to their remarkable generalization performance across a wide range of tasks requiring perception and cognitive abilities. A key factor behind their success is their simple architecture,...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 9. Current frontier video diffusion models have demonstrated remarkable results at generating high-quality videos. However, they can only generate short video clips, normally around 10 seconds or 240 frames, due to computation limitations during training. In this work, we show that existing models can ...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 10. Monte Carlo Tree Search (MCTS) has recently emerged as a powerful technique for enhancing the reasoning capabilities of LLMs. Techniques such as SFT or DPO have enabled LLMs to distill high-quality behaviors from MCTS, improving their reasoning performance. However, existing distillation methods und...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 11. We study the performance of transformers as a function of the number of repetitions of training examples with algorithmically generated datasets. On three problems of mathematics: the greatest common divisor, modular multiplication, and matrix eigenvalues, we show that for a fixed number of training...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 12. In this paper, we propose a new method to enhance compositional understanding in pre-trained vision and language models (VLMs) without sacrificing performance in zero-shot multi-modal tasks. Traditional fine-tuning approaches often improve compositional reasoning at the cost of degrading multi-modal...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 13. In this work, we propose a novel method (GLOV) enabling Large Language Models (LLMs) to act as implicit Optimizers for Vision-Langugage Models (VLMs) to enhance downstream vision tasks. Our GLOV meta-prompts an LLM with the downstream task description, querying it for suitable VLM prompts (e.g., for...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 14. Automatic LLM benchmarks, such as AlpacaEval 2.0, Arena-Hard-Auto, and MT-Bench, have become popular for evaluating language models due to their cost-effectiveness and scalability compared to human evaluation. Achieving high win rates on these benchmarks can significantly boost the promotional impac...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 15. This paper proposes the paradigm of large convolutional kernels in designing modern Convolutional Neural Networks (ConvNets). We establish that employing a few large kernels, instead of stacking multiple smaller ones, can be a superior design strategy. Our work introduces a set of architecture desig...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 16. Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel ...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 17. Can large language models (LLMs) directly serve as powerful world models for model-based agents? While the gaps between the prior knowledge of LLMs and the specified environment's dynamics do exist, our study reveals that the gaps can be bridged by aligning an LLM with its deployed environment and s...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 18. Diffusion models have become the dominant approach for visual generation. They are trained by denoising a Markovian process that gradually adds noise to the input. We argue that the Markovian property limits the models ability to fully utilize the generation trajectory, leading to inefficiencies dur...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 19. Large Language Models (LLMs) have demonstrated remarkable in-context learning (ICL) capabilities. In this study, we explore a surprising phenomenon related to ICL: LLMs can perform multiple, computationally distinct ICL tasks simultaneously, during a single inference call, a capability we term "task...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 20. In spite of the outstanding performance, Neural Architecture Search (NAS) is criticized for massive computation. Recently, Zero-shot NAS has emerged as a promising approach by exploiting Zero-cost (ZC) proxies, which markedly reduce computational demands. Despite this, existing ZC proxies heavily re...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 21. Dynamic scene reconstruction is a long-term challenge in the field of 3D vision. Recently, the emergence of 3D Gaussian Splatting has provided new insights into this problem. Although subsequent efforts rapidly extend static 3D Gaussian to dynamic scenes, they often lack explicit constraints on obje...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 22. Data is a crucial element in large language model (LLM) alignment. Recent studies have explored using LLMs for efficient data collection. However, LLM-generated data often suffers from quality issues, with underrepresented or absent aspects and low-quality datapoints. To address these problems, we p...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 23. Large language models (LLMs) have shown remarkable in-context learning (ICL) capabilities on textual data. We explore whether these capabilities can be extended to continuous vectors from diverse domains, obtained from black-box pretrained encoders. By aligning input data with an LLM's embedding spa...
[11.10.2024 22:11] ********************************************************************************
[11.10.2024 22:11] Abstract 24. Solving time-dependent parametric partial differential equations (PDEs) is challenging, as models must adapt to variations in parameters such as coefficients, forcing terms, and boundary conditions. Data-driven neural solvers either train on data sampled from the PDE parameters distribution in the h...
[11.10.2024 22:11] Read previous papers.
[11.10.2024 22:11] Generating reviews via LLM API.
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–¥–∞ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —à–∞–≥–∞–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç MathCode-Pile –æ–±—ä–µ–º–æ–º 19.2 –º–ª—Ä–¥ —Ç–æ–∫–µ–Ω–æ–≤, –≤–∫–ª—é—á–∞—é—â–∏–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ–±-–¥–∞–Ω–Ω—ã–µ, –∫–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º 
[11.10.2024 22:11] Using data from previous issue: {"desc": "PrefixQuant - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –∫–æ—Ç–æ—Ä—ã–π –∏–∑–æ–ª–∏—Ä—É–µ—Ç –≤—ã–±—Ä–æ—Å—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ñ–ª–∞–π–Ω –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è. –û–Ω –ø—Ä–µ—Ñ–∏–∫—Å–∏—Ä—É–µ—Ç —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Ç–æ–∫–µ–Ω—ã-–≤—ã–±—Ä–æ—Å—ã –≤ KV-–∫—ç—à–µ, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤. Prefi
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ MART –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –≤–æ–ø–ª–æ—â–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM). MART –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ MLLM-—Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∏ –ø—Ä–∏–æ—Ä–∏
[11.10.2024 22:11] Using data from previous issue: {"desc": "DICE (Discrete Inversion for Controllable Editing) - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ç–æ—á–Ω–æ–π –∏–Ω–≤–µ—Ä—Å–∏–∏ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å —Ç–æ—á–Ω—É—é —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –≥–∏–±–∫–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –º–∞—Å–∫–∞—Ö –∏–ª–∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è—Ö —Å –≤–Ω–∏–º–∞–Ω–∏–µ–º. DI
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç WorFBench - –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç WorFEval - –ø—Ä–æ—Ç–æ–∫–æ–ª –æ—Ü–µ–Ω–∫–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ–¥–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏ –ø–æ–¥–≥—Ä–∞—Ñ–æ–≤. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—ã—è–≤–∏–ª–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É 
[11.10.2024 22:11] Using data from previous issue: {"desc": "Agent S - —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è –∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –°–∏—Å—Ç–µ–º–∞ —Ä–µ—à–∞–µ—Ç —Ç—Ä–∏ –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á: –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á –∏ —Ä–∞–±–æ—Ç–∞ —Å
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Rectified Diffusion, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö. –ê–≤—Ç–æ—Ä—ã —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ —É—Å–ø–µ—Ö —Ä–µ–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞—Ä —à—É–º–∞ –∏ –æ–±—Ä–∞–∑—Ü–æ–≤. 
[11.10.2024 22:11] Using data from previous issue: {"desc": "SFTMix - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏. –ó–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Mixup –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø
[11.10.2024 22:11] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É—é—Ç—Å—è –∫—Ä—É–ø–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (LLVM) —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∏—Ö –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Ä–∞–±–æ—Ç—ã LLVM, –≤–∫–ª—é—á–∞—è –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞–º, —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å, –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è. –≠–∫—Å–ø
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—é—â–∏–µ—Å—è —É—Ä–æ–≤–Ω–∏ —à—É–º–∞ –∫ –ª–∞—Ç–µ–Ω—Ç–Ω—ã–º –∫–∞–¥—Ä–∞–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ–Ω–∫–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –Ω–∏–º–∏. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤
[11.10.2024 22:11] Using data from previous issue: {"desc": "AlphaLLM-CPL - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–æ–∏—Å–∫–∞ –ø–æ –¥–µ—Ä–µ–≤—É –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ (MCTS). –û–Ω —É–ª—É—á—à–∞–µ—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è LLM, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π MCTS. AlphaLLM-CPL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ø–∞—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∑–ª–æ–≤ –¥–µ—Ä–µ–≤–∞ –ø–æ–∏—Å–∫–∞ –∏ –∫—É—Ä—Ä–∏–∫—É–ª—è—Ä–Ω–æ–µ –æ–±—É—á–µ
[11.10.2024 22:11] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –ª—É—á—à–µ –æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ –º–µ–Ω—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º–∏—Å—è –ø—Ä–∏–º–µ—Ä–∞–º–∏, —á–µ–º –Ω–∞ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø—Ä–æ–≤–æ–¥–∏–ª–∏—Å—å –Ω–∞ —Ç—Ä–µ—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö: –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ –æ–±—â–µ–≥–æ –¥–µ–ª–∏—Ç–µ–ª—è, –º–æ–¥—É–ª—å–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ
[11.10.2024 22:11] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö –∑—Ä–µ–Ω–∏—è –∏ —è–∑—ã–∫–∞ (VLM) –±–µ–∑ —É—â–µ—Ä–±–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö —Å –Ω—É–ª–µ–≤—ã–º –æ–±—É—á–µ–Ω–∏–µ–º. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç Fine-grained Selective Calibrated CLIP (FSC-CLIP), –∫–æ—Ç–æ—Ä—ã–π –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ª–æ–∫
[11.10.2024 22:11] Using data from previous issue: {"desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ GLOV, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –≤ –∫–∞—á–µ—Å—Ç–≤–µ –Ω–µ—è–≤–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (VLM) —Å —Ü–µ–ª—å—é —É–ª—É—á—à–µ–Ω–∏—è –∑–∞–¥–∞—á –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è. GLOV –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–∞-–ø—Ä–æ–º–ø—Ç—ã –¥–ª—è LLM —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Ü–µ–ª–µ–≤–æ–π –∑–∞–¥–∞—á–∏, –∑–∞–ø—Ä–∞—à–∏–≤–∞—è –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø—Ä–æ–º
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ–±–º–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç, –∫–∞–∫ –¥–∞–∂–µ '–Ω—É–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å', –≤—Å–µ–≥–¥–∞ –≤—ã–¥–∞—é—â–∞—è –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –æ—Ç–≤–µ—Ç, –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏—á—å –≤—ã—Å–æ–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Ç–∞–∫–∏–µ —Ç—Ä—é–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å 
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —è–¥–µ—Ä –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö (ConvNets). –ê–≤—Ç–æ—Ä—ã —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–æ–ª—å—à–∏—Ö —è–¥–µ—Ä –≤–º–µ—Å—Ç–æ —Å—Ç–µ–∫–∞ –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –º–µ–ª–∫–∏—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –û–Ω–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –∞
[11.10.2024 22:11] Using data from previous issue: {"desc": "Optima - –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, —É–ª—É—á—à–∞—é—â–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –∏ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è, –æ—Ç–±–æ—Ä–∞ –∏ –æ–±—É—á–µ–Ω–∏—è —Å —Ñ—É–Ω–∫—Ü–∏–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, –±–∞–ª–∞–Ω—Å–∏—Ä—É—é—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç–æ–∫–µ–Ω-—ç—Ñ—Ñ–µ–∫—Ç–∏
[11.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–æ—â–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∏—Ä–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–µ–π—Ä–æ—Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª, –ø–æ–∑–≤–æ–ª—è—é—â–∏—Ö —Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è LLM —Å –¥–∏–Ω–∞–º–∏–∫–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ä–µ–¥—ã. –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç
[11.10.2024 22:11] Using data from previous issue: {"desc": "DART - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –¥–∏—Ñ—Ñ—É–∑–∏—é –≤ —Ä–∞–º–∫–∞—Ö –Ω–µ–º–∞—Ä–∫–æ–≤—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–ª—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ç—á–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–º, —Ç–∞–∫ –∏ –≤ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–º –∏–∑–º–µ—Ä–µ–Ω–∏–∏. DART –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∫–≤–∞–Ω—Ç–∏
[11.10.2024 22:11] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—É—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ, –Ω–∞–∑–≤–∞–Ω–Ω—É—é '—Å—É–ø–µ—Ä–ø–æ–∑–∏—Ü–∏–µ–π –∑–∞–¥–∞—á'. –≠—Ç–æ —è–≤–ª–µ–Ω–∏–µ –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–µ–º–µ–π—Å—Ç–≤–∞—Ö LLM –∏ –º–∞—Å—à—Ç–∞–±–∞—Ö, –¥–∞–∂–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ 
[11.10.2024 22:11] Using data from previous issue: {"desc": "LPZero - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∫—Å–∏ —Å –Ω—É–ª–µ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é (ZC) –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –Ω–µ–π—Ä–æ–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (NAS). –û–Ω –º–æ–¥–µ–ª–∏—Ä—É–µ—Ç ZC-–ø—Ä–æ–∫—Å–∏ –∫–∞–∫ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –≤–∫–ª—é—á–∞–µ—Ç –µ–¥–∏–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏. LPZero –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä
[11.10.2024 22:11] Using data from previous issue: {"desc": "MotionGS - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –¥–µ—Ñ–æ—Ä–º–∏—Ä—É–µ–º–æ–≥–æ 3D-—Å–ø–ª–∞—Ç—Ç–∏–Ω–≥–∞ –≥–∞—É—Å—Å–∏–∞–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —è–≤–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω. –°–∏—Å—Ç–µ–º–∞ –≤–∫–ª—é—á–∞–µ—Ç –º–æ–¥—É–ª—å –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –æ–ø—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–æ–∫–∞, —Ä–∞–∑–¥–µ–ª—è—é—â–∏–π –µ–≥–æ –Ω–∞ –ø–æ—Ç–æ–∫ –∫–∞–º–µ—Ä—ã –∏ –ø–æ—Ç–æ–∫ –¥–≤–∏–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç
[11.10.2024 22:11] Querying the API.
[11.10.2024 22:11] Got response. {
  "desc": "Data Advisor - —ç—Ç–æ —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –û–Ω –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –≤—ã—è–≤–ª—è–µ—Ç —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ –≤ —Ç–µ–∫—É—â–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –∏ –¥–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. Data Advisor –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∏—Ö –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –æ—Ö–≤–∞—Ç–∞. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å Data Advisor –≤ –ø–æ–≤—ã—à–µ–Ω–∏–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –±–µ–∑ —É—â–µ—Ä–±–∞ –¥–ª—è –∏—Ö –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏.",
  "tags": ["#DataAdvisor", "#LLMDataGeneration", "#ModelSafetyAlignment"],
  "categories": ["#nlp", "#dataset", "#benchmark", "#rag", "#ai"],
  "emoji": "üß†",
  "title": "Data Advisor: —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LLM"
}
[11.10.2024 22:11] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ –æ–±—É—á–µ–Ω–∏—é –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–µ—Ç–æ–¥ Vector-ICL, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç LLM —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏ —É—á–∏—Ç—å—Å—è –Ω–∞ –ø—Ä–æ–µ—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–∞—Ö. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞
[11.10.2024 22:11] Using data from previous issue: {"desc": "Zebra - —ç—Ç–æ –Ω–æ–≤—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É—Ä–∞–≤–Ω–µ–Ω–∏–π –≤ —á–∞—Å—Ç–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö (–î–£–ß–ü). –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤, Zebra –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≤–æ –≤—Ä–µ–º—è –≤—ã–≤–æ–¥–∞, –∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ –≤–æ–∑
[11.10.2024 22:11] Renaming data file.
[11.10.2024 22:11] Renaming previous data. hf_papers.json to 2024-10-10_hf_papers.json
[11.10.2024 22:11] Saving new data file.
[11.10.2024 22:11] Generating page.
[11.10.2024 22:11] Renaming previous page.
[11.10.2024 22:11] Renaming previous data. index.html to 2024-10-10_hf_papers.html
[11.10.2024 22:11] Writing result.
[11.10.2024 22:11] Renaming log file.
[11.10.2024 22:11] Renaming previous data. log.txt to 2024-10-10_last_log.txt
