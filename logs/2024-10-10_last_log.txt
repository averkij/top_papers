[11.10.2024 06:17] Get feed.
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05265
[11.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.08196
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03450
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08207
[11.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.05248
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08151
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07303
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05210
[11.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.08164
[11.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.04751
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.06508
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08115
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07041
[11.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08049
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 0. Quantization is essential for deploying Large Language Models (LLMs) by enhancing memory efficiency and inference speed. Existing methods for activation quantization mainly address channel-wise outliers, often neglecting token-wise outliers, leading to reliance on costly per-token dynamic quantizati...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 1. Code has been shown to be effective in enhancing the mathematical reasoning abilities of large language models due to its precision and accuracy. Previous works involving continued mathematical pretraining often include code that utilizes math-related packages, which are primarily designed for field...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 2. MLLM agents demonstrate potential for complex embodied tasks by retrieving multimodal task-relevant trajectory data. However, current retrieval methods primarily focus on surface-level similarities of textual or visual cues in trajectories, neglecting their effectiveness for the specific task at han...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 3. Discrete diffusion models have achieved success in tasks like image generation and masked language modeling but face limitations in controlled content editing. We introduce DICE (Discrete Inversion for Controllable Editing), the first approach to enable precise inversion for discrete diffusion model...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 4. To induce desired behaviors in large language models (LLMs) for interaction-driven tasks, the instruction-tuning stage typically trains LLMs on instruction-response pairs using the next-token prediction (NTP) loss. Previous work aiming to improve instruction-tuning performance often emphasizes the n...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 5. Current frontier video diffusion models have demonstrated remarkable results at generating high-quality videos. However, they can only generate short video clips, normally around 10 seconds or 240 frames, due to computation limitations during training. In this work, we show that existing models can ...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 6. Diffusion models have greatly improved visual generation but are hindered by slow generation speed due to the computationally intensive nature of solving generative ODEs. Rectified flow, a widely recognized solution, improves generation speed by straightening the ODE path. Its key components include...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 7. In this paper, we propose a new method to enhance compositional understanding in pre-trained vision and language models (VLMs) without sacrificing performance in zero-shot multi-modal tasks. Traditional fine-tuning approaches often improve compositional reasoning at the cost of degrading multi-modal...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 8. We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks. Agent S aims to address three key challenges in automating computer tas...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 9. Recently, large language and vision models (LLVMs) have received significant attention and development efforts due to their remarkable generalization performance across a wide range of tasks requiring perception and cognitive abilities. A key factor behind their success is their simple architecture,...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 10. Monte Carlo Tree Search (MCTS) has recently emerged as a powerful technique for enhancing the reasoning capabilities of LLMs. Techniques such as SFT or DPO have enabled LLMs to distill high-quality behaviors from MCTS, improving their reasoning performance. However, existing distillation methods und...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 11. Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel ...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 12. We study the performance of transformers as a function of the number of repetitions of training examples with algorithmically generated datasets. On three problems of mathematics: the greatest common divisor, modular multiplication, and matrix eigenvalues, we show that for a fixed number of training...
[11.10.2024 06:17] ********************************************************************************
[11.10.2024 06:17] Abstract 13. This paper proposes the paradigm of large convolutional kernels in designing modern Convolutional Neural Networks (ConvNets). We establish that employing a few large kernels, instead of stacking multiple smaller ones, can be a superior design strategy. Our work introduces a set of architecture desig...
[11.10.2024 06:17] Read previous papers.
[11.10.2024 06:17] Generating reviews via LLM API.
[11.10.2024 06:17] Using data from previous issue: {"desc": "PrefixQuant - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –∫–æ—Ç–æ—Ä—ã–π –∏–∑–æ–ª–∏—Ä—É–µ—Ç –≤—ã–±—Ä–æ—Å—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ñ–ª–∞–π–Ω –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è. –û–Ω –ø—Ä–µ—Ñ–∏–∫—Å–∏—Ä—É–µ—Ç —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Ç–æ–∫–µ–Ω—ã-–≤—ã–±—Ä–æ—Å—ã –≤ KV-–∫—ç—à–µ, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤. Prefi
[11.10.2024 06:17] Querying the API.
[11.10.2024 06:17] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–¥–∞ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —à–∞–≥–∞–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç MathCode-Pile –æ–±—ä–µ–º–æ–º 19.2 –º–ª—Ä–¥ —Ç–æ–∫–µ–Ω–æ–≤, –≤–∫–ª—é—á–∞—é—â–∏–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ–±-–¥–∞–Ω–Ω—ã–µ, –∫–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫, —É—á–µ–±–Ω–∏–∫–∏ –∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ. –ú–µ—Ç–æ–¥ –≤–∫–ª—é—á–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–π LaTeX, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —É—Å–ª–æ–≤–∏–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ –∑–∞—Ç–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–¥–∞. –û–±—É—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —ç—Ç–æ–º –∫–æ—Ä–ø—É—Å–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–æ –∏—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.",
  "tags": ["#MathCode-Pile", "#–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ_—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", "#–≥–µ–Ω–µ—Ä–∞—Ü–∏—è_–∫–æ–¥–∞"],
  "categories": ["#nlp", "#dataset", "#code", "#benchmark", "#rag"],
  "emoji": "üßÆ",
  "title": "–£–ª—É—á—à–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –∫–æ–¥–∞"
}
[11.10.2024 06:17] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ MART –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –≤–æ–ø–ª–æ—â–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM). MART –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ MLLM-—Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∏ –ø—Ä–∏–æ—Ä–∏
[11.10.2024 06:17] Using data from previous issue: {"desc": "DICE (Discrete Inversion for Controllable Editing) - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ç–æ—á–Ω–æ–π –∏–Ω–≤–µ—Ä—Å–∏–∏ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å —Ç–æ—á–Ω—É—é —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –≥–∏–±–∫–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –º–∞—Å–∫–∞—Ö –∏–ª–∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è—Ö —Å –≤–Ω–∏–º–∞–Ω–∏–µ–º. DI
[11.10.2024 06:17] Querying the API.
[11.10.2024 06:17] Got response. {
  "desc": "SFTMix - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏. –ó–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Mixup –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö –∏ —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –º–µ–Ω–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö. SFTMix –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤ —Ç—â–∞—Ç–µ–ª—å–Ω–æ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö.",

  "tags": ["#instructionTuning", "#SFTMix", "#mixupRegularization"],

  "categories": ["#nlp", "#dataset", "#benchmark", "#code", "#rag"],

  "emoji": "üîÄ",

  "title": "SFTMix: —É–ª—É—á—à–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM –±–µ–∑ –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–µ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"
}
[11.10.2024 06:17] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—é—â–∏–µ—Å—è —É—Ä–æ–≤–Ω–∏ —à—É–º–∞ –∫ –ª–∞—Ç–µ–Ω—Ç–Ω—ã–º –∫–∞–¥—Ä–∞–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ–Ω–∫–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –Ω–∏–º–∏. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤
[11.10.2024 06:17] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Rectified Diffusion, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö. –ê–≤—Ç–æ—Ä—ã —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ —É—Å–ø–µ—Ö —Ä–µ–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞—Ä —à—É–º–∞ –∏ –æ–±—Ä–∞–∑—Ü–æ–≤. 
[11.10.2024 06:17] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö –∑—Ä–µ–Ω–∏—è –∏ —è–∑—ã–∫–∞ (VLM) –±–µ–∑ —É—â–µ—Ä–±–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö —Å –Ω—É–ª–µ–≤—ã–º –æ–±—É—á–µ–Ω–∏–µ–º. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç Fine-grained Selective Calibrated CLIP (FSC-CLIP), –∫–æ—Ç–æ—Ä—ã–π –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ª–æ–∫
[11.10.2024 06:17] Querying the API.
[11.10.2024 06:17] Got response. {
  "desc": "Agent S - —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è –∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –°–∏—Å—Ç–µ–º–∞ —Ä–µ—à–∞–µ—Ç —Ç—Ä–∏ –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á: –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á –∏ —Ä–∞–±–æ—Ç–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏. Agent S –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, —É—Å–∏–ª–µ–Ω–Ω–æ–µ –æ–ø—ã—Ç–æ–º, –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Agent-Computer Interface –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å GUI –Ω–∞ –æ—Å–Ω–æ–≤–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.",

  "tags": ["#AgentS", "#ExperienceAugmentedPlanning", "#GUIAutomation"],

  "categories": ["#nlp", "#rl", "#benchmark", "#code", "#humancomputerinteraction"],

  "emoji": "ü§ñ",

  "title": "Agent S: –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º"
}
[11.10.2024 06:17] Querying the API.
[11.10.2024 06:17] Got response. {
  "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É—é—Ç—Å—è –∫—Ä—É–ø–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (LLVM) —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∏—Ö –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Ä–∞–±–æ—Ç—ã LLVM, –≤–∫–ª—é—á–∞—è –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞–º, —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å, –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ LLVM –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–ª–æ–±–∞–ª—å–Ω–æ, –º–æ–≥—É—Ç —Ä–µ—à–∞—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è —á–∏—Å–ª–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∏ —á—Ç–æ –Ω–∏–∂–Ω–∏–µ —Å–ª–æ–∏ –º–æ–¥–µ–ª–∏ –∏–≥—Ä–∞—é—Ç –∫–ª—é—á–µ–≤—É—é —Ä–æ–ª—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç—Å—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è LLVM –∏ —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –Ω–∞–±–æ—Ä–æ–≤.",
  "tags": [
    "#LLVM",
    "#–í–æ—Å–ø—Ä–∏—è—Ç–∏–µ–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
    "#–ê–Ω–∞–ª–∏–∑–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"
  ],
  "categories": [
    "#cv",
    "#nlp",
    "#benchmark",
    "#multimodal",
    "#analysis"
  ],
  "emoji": "üîç",
  "title": "–†–∞—Å–∫—Ä—ã–≤–∞—è —Ç–∞–π–Ω—ã –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –≤ –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤–æ-–≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö"
}
[11.10.2024 06:17] Using data from previous issue: {"desc": "AlphaLLM-CPL - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–æ–∏—Å–∫–∞ –ø–æ –¥–µ—Ä–µ–≤—É –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ (MCTS). –û–Ω —É–ª—É—á—à–∞–µ—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è LLM, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π MCTS. AlphaLLM-CPL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ø–∞—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∑–ª–æ–≤ –¥–µ—Ä–µ–≤–∞ –ø–æ–∏—Å–∫–∞ –∏ –∫—É—Ä—Ä–∏–∫—É–ª—è—Ä–Ω–æ–µ –æ–±—É—á–µ
[11.10.2024 06:17] Using data from previous issue: {"desc": "Optima - –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, —É–ª—É—á—à–∞—é—â–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –∏ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è, –æ—Ç–±–æ—Ä–∞ –∏ –æ–±—É—á–µ–Ω–∏—è —Å —Ñ—É–Ω–∫—Ü–∏–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, –±–∞–ª–∞–Ω—Å–∏—Ä—É—é—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç–æ–∫–µ–Ω-—ç—Ñ—Ñ–µ–∫—Ç–∏
[11.10.2024 06:17] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –ª—É—á—à–µ –æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ –º–µ–Ω—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º–∏—Å—è –ø—Ä–∏–º–µ—Ä–∞–º–∏, —á–µ–º –Ω–∞ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø—Ä–æ–≤–æ–¥–∏–ª–∏—Å—å –Ω–∞ —Ç—Ä–µ—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö: –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ –æ–±—â–µ–≥–æ –¥–µ–ª–∏—Ç–µ–ª—è, –º–æ–¥—É–ª—å–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ
[11.10.2024 06:17] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —è–¥–µ—Ä –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö (ConvNets). –ê–≤—Ç–æ—Ä—ã —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–æ–ª—å—à–∏—Ö —è–¥–µ—Ä –≤–º–µ—Å—Ç–æ —Å—Ç–µ–∫–∞ –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –º–µ–ª–∫–∏—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –û–Ω–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –∞
[11.10.2024 06:17] Renaming data file.
[11.10.2024 06:17] Renaming previous data. hf_papers.json to 2024-10-10_hf_papers.json
[11.10.2024 06:17] Saving new data file.
[11.10.2024 06:17] Generating page.
[11.10.2024 06:17] Renaming previous page.
[11.10.2024 06:17] Renaming previous data. index.html to 2024-10-10_hf_papers.html
[11.10.2024 06:17] Writing result.
[11.10.2024 06:17] Renaming log file.
[11.10.2024 06:17] Renaming previous data. log.txt to 2024-10-10_last_log.txt
