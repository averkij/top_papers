[17.12.2025 01:42] Read previous papers.
[17.12.2025 01:42] Generating top page (month).
[17.12.2025 01:42] Writing top page (month).
[17.12.2025 03:22] Read previous papers.
[17.12.2025 03:22] Get feed.
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.12675
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.14531
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.14691
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.13961
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.13678
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.14614
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.14503
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.13655
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.14699
[17.12.2025 03:22] Extract page data from URL. URL: https://huggingface.co/papers/2512.14067
[17.12.2025 03:22] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.12.2025 03:22] Downloading and parsing papers (pdf, html). Total: 10.
[17.12.2025 03:22] Downloading and parsing paper https://huggingface.co/papers/2512.12675.
[17.12.2025 03:22] Downloading paper 2512.12675 from https://arxiv.org/pdf/2512.12675v1...
[17.12.2025 03:22] Extracting affiliations from text.
[17.12.2025 03:22] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 1 ] . [ 1 5 7 6 2 1 . 2 1 5 2 : r Scone: Bridging Composition and Distinction in Subject-Driven Image Generation via Unified Understanding-Generation Modeling Yuran Wang1,2* Bohan Zeng1,2* Chengzhuo Tong1,2 Wenxuan Liu1 Yang Shi1,2, Xiaochen Ma1 Hao Liang1 Yuanxing Zhang2 Wentao Zhang1 1Peking University 2Kling Team, Kuaishou Technology "
[17.12.2025 03:22] Response: ```python
[
    "Peking University",
    "Kling Team, Kuaishou Technology"
]
```
[17.12.2025 03:22] Deleting PDF ./assets/pdf/2512.12675.pdf.
[17.12.2025 03:22] Success.
[17.12.2025 03:22] Downloading and parsing paper https://huggingface.co/papers/2512.14531.
[17.12.2025 03:22] Downloading paper 2512.14531 from https://arxiv.org/pdf/2512.14531v1...
[17.12.2025 03:22] Extracting affiliations from text.
[17.12.2025 03:22] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse Ying Nie 1 Kai Han 1 Hongguang Li 1 Hang Zhou 1 Tianyu Guo 1 Enhua Wu 2 3 Xinghao Chen 1 Yunhe Wang 1 5 2 0 2 6 1 ] . [ 1 1 3 5 4 1 . 2 1 5 2 : r Abstract The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: width-versatile path that generates mixture of sub-experts from single shared FFN, mimicking sparse expert routing without increasing parameters, and depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. difficulty-aware gating dynamically balances the two pathways, steering easy tokens through the efficient width-wise route and allocating deeper iterative refinement to hard tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github. com/huawei-noah/noah-research/ tree/master/VersatileFFN. 1. Introduction The remarkable success of Large Language Models (LLMs) is largely governed by scaling laws, which posit power1Huawei Noahs Ark Lab 2ISCAS 3University of Macau.Correspondence to: Kai Han <kai.han@huawei.com>, Yunhe Wang <yunhe.wang@huawei.com>. Technical Report. law relationship between model performance and parameter count (Kaplan et al., 2020; Hoffmann"
[17.12.2025 03:22] Response: ```python
[
    "Huawei Noah's Ark Lab",
    "ISCAS",
    "University of Macau"
]
```
[17.12.2025 03:22] Deleting PDF ./assets/pdf/2512.14531.pdf.
[17.12.2025 03:22] Success.
[17.12.2025 03:22] Downloading and parsing paper https://huggingface.co/papers/2512.14691.
[17.12.2025 03:22] Downloading paper 2512.14691 from https://arxiv.org/pdf/2512.14691v1...
[17.12.2025 03:22] Extracting affiliations from text.
[17.12.2025 03:22] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 1 9 6 4 1 . 2 1 5 2 : r MMGR: Multi-Modal Generative Reasoning Zefan Cai,1, Haoyi Qiu,2, Tianyi Ma,3,, Haozhe Zhao,4, Gengze Zhou5, Kung-Hsiang Huang6, Parisa Kordjamshidi3, Minjia Zhang4, Xiao Wen7, Jiuxiang Gu8, Nanyun Peng2, Junjie Hu1 1University of WisconsinMadison, 2University of California, Los Angeles, 3Michigan State University, 4University of Illinois UrbanaChampaign, 5University of Adelaide, 6Salesforce AI Research, 7Microsoft, 8Adobe Research Equal Contribution, Done during visit to the University of California, Los Angeles. Video foundation models have made striking progress in synthesizing visually compelling and temporally coherent content, yet their viability as world simulators hinges on whether they internalize the physical, logical, and spatial constraints that govern reality. Existing evaluation metricssuch as Fréchet Video Distance (FVD)largely emphasize perceptual fidelity, leaving critical reasoning failures undetected, including hallucinations that violate causal structure, physical laws, and global consistency. To address this gap, we propose principled evaluation framework grounded in five core reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal reasoning. Building on this framework, we introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), comprehensive benchmark suite designed to assess generative reasoning across three complementary domains: Abstract Reasoning (e.g., ARC-AGI, Sudoku), Embodied Navigation (e.g., real-world 3D navigation and localization), and Physical Commonsense (e.g., sports and compositional physical interactions). MMGR evaluates both video and image generative models using fine-grained, domainspecific metrics that require holistic correctness rather than partial success. We benchmark state-ofthe-art video generation modelsincluding Veo-3, Sora-2, and Wan-2.2alongside leading image generation models such as Nano-banana, Nano-banana Pro, GPT-4o-image, and"
[17.12.2025 03:23] Response: ```python
[
    "University of Wisconsin-Madison",
    "University of California, Los Angeles",
    "Michigan State University",
    "University of Illinois Urbana-Champaign",
    "University of Adelaide",
    "Salesforce AI Research",
    "Microsoft",
    "Adobe Research"
]
```
[17.12.2025 03:23] Deleting PDF ./assets/pdf/2512.14691.pdf.
[17.12.2025 03:23] Success.
[17.12.2025 03:23] Downloading and parsing paper https://huggingface.co/papers/2512.13961.
[17.12.2025 03:23] Downloading paper 2512.13961 from https://arxiv.org/pdf/2512.13961v1...
[17.12.2025 03:23] Extracting affiliations from text.
[17.12.2025 03:23] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 1 ] . [ 1 1 6 9 3 1 . 2 1 5 2 : r Olmo Allyson Ettinger 1 Amanda Bertsch 1, 3 Bailey Kuehl David Heineman 1 Dirk Groeneveld 1 Faeze Brahman 1 Finbarr Timbers 1 Hamish Ivison 1, 2 Jacob Morrison 1, 2 Jake Poznanski Matt Jordan 1 Mayee Chen 1, 4 Michael Noukhovitch 1, 5, 6 Nathan Lambert 1 Pete Walsh 1 Pradeep Dasigi 1 Robert Berry 1 Saumya Malik 1 Saurabh Shah 1 Scott Geng 1, 2 Shane Arora 1 Shashank Gupta 1 Taira Anderson 1 Teng Xiao 1 Tyler Murray 1 Tyler Romero 1 Victoria Graf 1, 2 1 Kyle Lo 1, 2 Luca Soldaini 1 David Graham 1 1 Akari Asai1, 3 Akshita Bhagia1 Alexander Wettig7 Alisa Liu2 Aman Rangapur1 Ian Magnusson1, 2 Chloe Anastasiades1 Costa Huang1 Dustin Schwenk1 Harsh Trivedi1 Jaron Lochner1 Jiacheng Liu1 Lester James V. Miranda1 Maarten Sap1, 3 Malia Morgan1 Michael Schmitz1 Michal Guerquin1 Michael Wilson1 Regan Huff1 Ronan Le Bras1 Rui Xin2 Rulin Shao2 Sam Skjonsberg1 Shannon Zejiang Shen8 Shuyue Stella Li2 Tucker Wilde1 Valentina Pyatkin1 Will Merrill1 Yapei Chang9 Yuling Gu1 Zhiyuan Zeng1, 2 Ashish Sabharwal1 Luke Zettlemoyer2 Pang Wei Koh1, 2 Ali Farhadi1, 2 Noah A. Smith 1, 2 Hannaneh Hajishirzi 1, 2 1Allen Institute for AI 6Université de Montréal 2University of Washington 3Carnegie Mellon University 4Stanford University 5Mila 7Princeton University 8Massachusetts Institute of Technology 9University of Maryland Olmo 3 was team effort; authors sorted alphabetically. marks core contributors. See author contributions here. Olmo 3 Base: Olmo-3-1025-7B Olmo-3-1125-32B Olmo 3 Think: Olmo-3-7B-Think Olmo-{33.1}-32B-Think Olmo 3 Instruct: Olmo-3-7B-Instruct Olmo 3 RL Zero: Olmo-3-7B-RL-Zero-{MathCodeIFGeneralMix} Olmo-3.1-32B-Instruct Olmo-3.1-7B-RL-Zero-{MathCode} Base Data: Pretrain: Dolma 3 Mix Think Data: Dolci-Think-{SFTDPORL}-7B Instruct Data: Dolci-Instruct-{SFTDPORL} RL-Zero Data: Dolci-RL-Zero-{MathCodeIFGeneral}-7B Dolci-Think-{SFTDPORL}-32B Dolci-RL-Zero-Mix-7B Midtrain: Dolma 3 Dolmino Mix Long-ctx: Dolma 3 Longmino Mix Training Code: OLM"
[17.12.2025 03:23] Response: ```python
[
    "Allen Institute for AI",
    "University of Washington",
    "Carnegie Mellon University",
    "Stanford University",
    "Mila",
    "Université de Montréal",
    "Princeton University",
    "Massachusetts Institute of Technology",
    "University of Maryland"
]
```
[17.12.2025 03:23] Deleting PDF ./assets/pdf/2512.13961.pdf.
[17.12.2025 03:23] Success.
[17.12.2025 03:23] Downloading and parsing paper https://huggingface.co/papers/2512.13678.
[17.12.2025 03:23] Downloading paper 2512.13678 from https://arxiv.org/pdf/2512.13678v1...
[17.12.2025 03:23] Extracting affiliations from text.
[17.12.2025 03:23] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Feedforward 3D Editing via Text-Steerable Image-to-3D 5 2 0 2 5 1 ] . [ 1 8 7 6 3 1 . 2 1 5 2 : r Figure 1. We present Steer3D, which enables feedforward editing of generated 3D assets by ingesting text steerability to image-to-3D models. Steer3D uses an architecture inspired by ControlNet to leverage image-to-3D pretraining and achieve data efficiency. We build an automated data engine that generates 96k synthetic editing pairs for scalable training. Steer3D shows strong editing capabilities while staying consistent with the original 3D asset, as shown on the right side. "
[17.12.2025 03:23] Response: ```python
[]
```
[17.12.2025 03:23] Extracting affiliations from text.
[17.12.2025 03:23] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Feedforward 3D Editing via Text-Steerable Image-to-3D5 2 0 2 5 1 ] . [ 1 8 7 6 3 1 . 2 1 5 2 : r Figure 1. We present Steer3D, which enables feedforward editing of generated 3D assets by ingesting text steerability to image-to-3D models. Steer3D uses an architecture inspired by ControlNet to leverage image-to-3D pretraining and achieve data efficiency. We build an automated data engine that generates 96k synthetic editing pairs for scalable training. Steer3D shows strong editing capabilities while staying consistent with the original 3D asset, as shown on the right side.Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, critical requirement is the capability to edit them easily. We present feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in forward pass. We build scalable data engine for automatic data generation, and develop two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4 to 28.5 faster. Steer3D demonstrates that it is possible to add new modality (text) to steer the generation of pretrained imageto-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/ 1. Introduction Generative image-to-3D models [18, 40, 45] enable users to create 3D assets from single image, unlocking new applications in design, AR/VR, and robotic simulation. However, integrating AI generations into real applications requires editing and customizing the generated 3D assets, capability not supported by these models. Existing solutions to 3D editing include 2D-3D pipelines which use image editing to change the object views and then lift to 3D [6, 34, 37]. However, they suffer from inconsistent image edit outputs, which are reflected in the reconstructed 3D shape. These methods are also slow they take several minutes per edit. To address these inherent limitations with pipeline methods, we want to train feedforward model that directly perform editing in 3D. The most intuitive approach is to design generative model which takes the original 3D asset as input, and generates the edited asset conditioned on the edit instruction. However, such models rely on paired 3D editing data with text instructions, which is very difficult 1 to obtain. Due to this challenge, training such model from scratch is impractical. We propose solution from different perspective: instead of training an editing model from scratch, we can turn any image-to-3D model into an editing model by augmenting it with text steerability. Fig. 1 shows an overview of our method, Steer3D. We start from pretrained image-to-3D generator and augment it with ControlNet [43]. ControlNet ingests the steering prompt and guides the base model toward the desired 3D edit. To edit any asset generated by the base model, we can run Steer3D with the input image plus the editing text, and directly obtain an edited asset that follows the instruction and remains consistent with the original asset. By leveraging shape and object priors from pretrained image-to-3D models, this design is more data-efficient than training standalone editing model from scratch. data-efficient architecture makes feedforward 3D editing tractable, yet we still need to collect paired 3D edit data for training. We develop an automated data engine that combines image editing models, large visionlanguage models, and image-to-3D generators to synthesize diverse geometryand texture-edit pairs. In total, we produce 96k training pairs covering wide range of shape and appearance changes. We then train Steer3D with flow matching [25], and apply Direct Preference Optimization (DPO; [35]) to avoid the trivial no-edit solution. Our analysis shows that both the data engine and the training recipe scale effectively. Fig. 1 (right) shows outputs from Steer3D. Our main contributions are as follows: We build feedforward model for 3D editing which demonstrates stronger instruction following and better consistency preservation than existing methods, while being 2.4 to 28.5 faster. We propose novel architecture that adapts ControlNet to image-to-3D generation to enable language steering. We design scalable, automatic data engine that can generate 3D editing paired data. We develop two-stage training recipe that integrates flow-matching and Direct Preference Optimization to add text steering capability to pretrained image-to-3D models. We release EDIT3D-BENCH, 3D editing benchmark with diverse object types and editing instructions. 2. Related Work Image-to-3D Models. Image-to-3D models generate 3D assets based on single image. Recent state-of-art models [38, 40, 45] formulate image-to-3D as conditional generation via rectified flow [25]. These models dont allow direct text-based editing, even though TRELLIS [40] can be combined with inpainting methods [29] to perform limited editing, assuming the additional input of 3D bounding box. We study editing with language guidance and no additional input, and via forward pass. 3D Editing Pipelines Based on 2D Editing. Starting from Instruct-NeRF2NeRF [13], various methods [46, 10, 22, 39] build pipelines with 2D editing models to perform 3D editing. [13, 17] are based on NeRF [30], [13, 17, 37] are based on Gaussian splatting [21], and [34] is based on triplane. While there is active effort on improving multiview editing consistency [4, 20, 37], this issue is still challenging, limiting editing quality. Furthermore, these pipelines are also slow due to rendering, multiple model invocations and NeRF or Gaussian optimization. Test-Time Optimization. Test-time optimization for 3D editing includes score-distillation-based methods and inversion-based methods. Score distillation [33] is adapted for 3D editing in [14, 23, 36, 46]. These methods use the score distillation loss from 2D text-to-image models to guide optimization. 3D-LATTE [31] is an inversion-based method that uses attention injection. These methods are slow due to the optimization required, and oftentimes contain instance-specific hyperparameters. Feedforward"
[17.12.2025 03:23] Mistral response. {"id": "1d6998c199a04949801c46100ebd763e", "created": 1765941832, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1572, "total_tokens": 1581, "completion_tokens": 9}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Caltech\"]\n```"}}]}
[17.12.2025 03:23] Response: ```python
["Caltech"]
```
[17.12.2025 03:23] Deleting PDF ./assets/pdf/2512.13678.pdf.
[17.12.2025 03:23] Success.
[17.12.2025 03:23] Downloading and parsing paper https://huggingface.co/papers/2512.14614.
[17.12.2025 03:23] Downloading paper 2512.14614 from https://arxiv.org/pdf/2512.14614v1...
[17.12.2025 03:24] Extracting affiliations from text.
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 4 1 6 4 1 . 2 1 5 2 : r WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling Wenqiang Sun* 1,3, Haiyu Zhang* 2,3, Haoyuan Wang* 3, Junta Wu3, Zehan Wang3, Zhenwei Wang3, Yunhong Wang2, Jun Zhang 1, Tengfei Wang 3, Chunchao Guo 3 1Hong Kong University of Science and Technology 2Beihang University 3 Tencent Hunyuan Figure 1. WorldPlay is real-time, interactive world model that achieves long-term geometric consistency. It responds to user navigation commands in streaming fashion, while maintaining scenes remain coherent when revisiting (shown in red boxes). Our model shows remarkable generalization across diverse scenes, including (a) real world, (b) stylized world, and (c) third-person agent control. Furthermore, it supports (d) 3D scene generation via reconstruction and (e) dynamic world events triggered by text-based manipulation. "
[17.12.2025 03:24] Response: ```python
[
    "Hong Kong University of Science and Technology",
    "Beihang University",
    "Tencent Hunyuan"
]
```
[17.12.2025 03:24] Deleting PDF ./assets/pdf/2512.14614.pdf.
[17.12.2025 03:24] Success.
[17.12.2025 03:24] Downloading and parsing paper https://huggingface.co/papers/2512.14503.
[17.12.2025 03:24] Downloading paper 2512.14503 from https://arxiv.org/pdf/2512.14503v1...
[17.12.2025 03:24] Extracting affiliations from text.
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2025-12-17 RecGPT-V2 Technical Report Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards. To address these challenges, we present RecGPT-V2 with four key innovations. First, Hierarchical MultiAgent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility. 5 2 0 2 6 1 ] . [ 1 3 0 5 4 1 . 2 1 5 2 : r Figure 1 Comparison between RecGPT-V2 and RecGPT-V1: (a) online A/B performance in"
[17.12.2025 03:24] Response: ```python
[]
```
[17.12.2025 03:24] Extracting affiliations from text.
[17.12.2025 03:24] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2025-12-17 RecGPT-V2 Technical ReportLarge language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards. To address these challenges, we present RecGPT-V2 with four key innovations. First, Hierarchical MultiAgent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility. 5 2 0 2 6 1 ] . [ 1 3 0 5 4 1 . 2 1 5 2 : r Figure 1 Comparison between RecGPT-V2 and RecGPT-V1: (a) online A/B performance in Taobaos Guess What You Like; (b) 60% compute savings via optimization pipeline; and (c) Superior timeliness in capturing seasonal trends, exemplified by PVR trends for Halloween and Winter-related products. 2025 Taobao. All rights reserved RecGPT-V2 Technical Report1 Introduction 2 Agentic Intent Reasoning 2.1 Hybrid Representation Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 6 2.2 Hierarchical Multi-Agent System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3 Dynamic Explanation Generation 17 3.1 Meta-Prompting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 3.2 Preference-Aware Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . 4 Agentic Judge Framework 20 4.1 Agent-as-a-Judge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 4.2 Judge-as-a-Reward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .23 5.1 Online A/B Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 5.2 Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .26 26 28 29 29 RecGPT-V2 Technical Report 1. Introduction Recommender systems have evolved significantly over the past two decades, progressing from matrix factorization (Koren et al., 2009) to deep neural networks (Tang et al., 2025). Despite these advances, contemporary industrial systems remain fundamentally constrained by their reliance on historical behavioral patterns and log-fitting objectives, optimizing for behavioral pattern matching without explicitly reasoning about underlying user intent. To address these issues, RecGPT-V1 (Yi et al., 2025) emerged as paradigm-shifting framework that elevates user intent from implicit behavioral signals to explicit reasoning objectives. By integrating large language models (LLMs) into key stages, such as user interest mining and item tag prediction, RecGPT-V1 transforms traditional pattern matching into an intent-centric recommendation objective grounded in semantic understanding and logical reasoning. This analytical reasoning paradigm enables the decomposition of complex recommendation tasks into interpretable and modular stages, facilitating transparent and controllable mapping from user intent understanding to item relevance prediction. While RecGPT-V1 successfully leverages LLM-based knowledge and reasoning to improve recommendation quality and demonstrates promising online performance in industrial deployment, it still exhibits several limitations that hinder its scalability, efficiency, and effectiveness: Limitation 1: Computational inefficiency and redundant intent reasoning in multi-route architectures. RecGPT"
[17.12.2025 03:24] Mistral response. {"id": "ab1f7d8f2e4648f3ae0f6de6b46784e6", "created": 1765941853, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1247, "total_tokens": 1256, "completion_tokens": 9}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Taobao\"]\n```"}}]}
[17.12.2025 03:24] Response: ```python
["Taobao"]
```
[17.12.2025 03:24] Deleting PDF ./assets/pdf/2512.14503.pdf.
[17.12.2025 03:24] Success.
[17.12.2025 03:24] Downloading and parsing paper https://huggingface.co/papers/2512.13655.
[17.12.2025 03:24] Downloading paper 2512.13655 from https://arxiv.org/pdf/2512.13655v1...
[17.12.2025 03:24] Extracting affiliations from text.
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 1 ] . [ 1 5 5 6 3 1 . 2 1 5 2 : r Comparative Analysis of LLM Abliteration Methods: Cross-Architecture Evaluation Richard J. Young University of Nevada Las Vegas, Department of Neuroscience ryoung@unlv.edu Abstract Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support (Heretic: KL divergence + refusal rate on eight models; benchmark preservation on three models with baselines plus Zephyr-7B-beta). Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K across three models: ErisForge 0.28 pp; DECCP 0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.0431.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to 18.81 pp (26.5% relative) depending on tool selection and model architecture. Keywords: abliteration, language models, refusal removal, model editing, representation engineering, LLM safety, safety alignment, jailbreaking Large language models deployed for commercial and research applications undergo ext"
[17.12.2025 03:24] Response: ```python
["University of Nevada Las Vegas, Department of Neuroscience"]
```
[17.12.2025 03:24] Deleting PDF ./assets/pdf/2512.13655.pdf.
[17.12.2025 03:24] Success.
[17.12.2025 03:24] Downloading and parsing paper https://huggingface.co/papers/2512.14699.
[17.12.2025 03:24] Failed to download and parse paper https://huggingface.co/papers/2512.14699: 
[17.12.2025 03:24] Downloading and parsing paper https://huggingface.co/papers/2512.14067.
[17.12.2025 03:24] Downloading paper 2512.14067 from https://arxiv.org/pdf/2512.14067v1...
[17.12.2025 03:24] Extracting affiliations from text.
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 7 6 0 4 1 . 2 1 5 2 : r 2025-11-01 Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed Yonggan Fu*, Lexington Whalen*1, Zhifan Ye1, Xin Dong, Shizhe Diao, Jingyu Liu2, Chengyue Wu3, Hao Zhang, Enze Xie, Song Han4, Maksim Khadkevich, Jan Kautz, Yingyan (Celine) Lin1, Pavlo Molchanov Diffusion language models (dLMs) have emerged as promising paradigm that enables parallel, nonautoregressive generation for higher throughput, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce continuous pretraining scheme with block-wise attention pattern, which remains causal across blocks and conditions each block on clean context while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models weight distributions than the fully bidirectional modeling used in prior work such as Dream, in addition to its known benefit of enabling KV caching, and leads to winwin in accuracy and efficiency. Second, to mitigate the trainingtest gap in mask token distributions (uniform vs. highly left-to-right), we propose position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs attention patterns, training dynamics, and"
[17.12.2025 03:24] Response: ```python
[]
```
[17.12.2025 03:24] Extracting affiliations from text.
[17.12.2025 03:24] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 7 6 0 4 1 . 2 1 5 2 : r 2025-11-01 Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed Yonggan Fu*, Lexington Whalen*1, Zhifan Ye1, Xin Dong, Shizhe Diao, Jingyu Liu2, Chengyue Wu3, Hao Zhang, Enze Xie, Song Han4, Maksim Khadkevich, Jan Kautz, Yingyan (Celine) Lin1, Pavlo Molchanov Diffusion language models (dLMs) have emerged as promising paradigm that enables parallel, nonautoregressive generation for higher throughput, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce continuous pretraining scheme with block-wise attention pattern, which remains causal across blocks and conditions each block on clean context while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models weight distributions than the fully bidirectional modeling used in prior work such as Dream, in addition to its known benefit of enabling KV caching, and leads to winwin in accuracy and efficiency. Second, to mitigate the trainingtest gap in mask token distributions (uniform vs. highly left-to-right), we propose position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM model family, which outperforms state-of-the-art AR models and dLMs in accuracythroughput trade-offs. For example, our Efficient-DLM 8B maintains comparable (slightly better) accuracy than Qwen3 8B and achieves +5.4%/+2.7% higher accuracy with 4.5/2.7 higher throughput compared to Dream 7B and Qwen3 4B, respectively. 1. Introduction The success of large language models (LLMs) has been largely driven by autoregressive (AR) modeling, where tokens are generated sequentially left to right. Despite strong benchmark performance, AR models are constrained by token-by-token decoding, which limits generation throughput, especially in memorybounded scenarios (e.g., small batch sizes) where hardware utilization is low. To overcome the sequential bottleneck of AR decoding, diffusion language models (dLMs) [1, 2, 3, 4] have recently emerged as an alternative paradigm. By leveraging iterative denoising steps, dLMs enable parallel, non-autoregressive generation and hold promise for higher throughput. However, despite their conceptual appeal, most existing dLMs have not delivered faster speed than AR models in practice [3, 4], due to the limited compatibility with key-value (KV) caching and the limited parallelism during decoding. Although pioneering works [5, 6, 7] demonstrate potential speed-up on small-scale models (e.g., 110M [5]) with limited downstream accuracy, successful scaling of dLMs to larger model sizes has been restricted by prohibitive training costs [8]. This is because AR models learn only left-to-right modeling, while dLMs learn all possible permutations [9], which is more difficult and requires longer training. This work leverages pretrained AR models for initialization and systematically explores how to continuously pretrain them into dLMs that achieve high generation speed while preserving task accuracy. The key insight is that, with an appropriate training scheme in terms of attention patterns and objectives, pretrained AR models can be converted into faster dLMs that support parallel decoding with KV cache at low training cost (on the order of 10B tokens), and extended continuous training (on the order of 100B tokens) enables more aggressive parallel generation. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-todLM methods and proposing continuous pretraining scheme that features block-wise attention pattern [5] and position-dependent token masking. Specifically, our extensive study of attention patterns shows that * Co-first author; additional affiliation: 1Georgia Tech, 2University of Chicago, 3University of Hong Kong, 4MIT. 2025 NVIDIA. All rights reserved. Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in SpeedAttention pattern is key to AR-to-dLM conversion: Continuous training with block attention better preserves pretrained AR models abilities than fully bidirectional modeling; Conditioning each corrupted block on clean context is essential for model accuracy. Training block size matters: Too-small block sizes lack sufficient context for denoising, while too-large block sizes induce excessive corruption and weight changes. Evaluation block size matters: Training with proper block sizes can generalize well to other evaluation block sizes; Larger evaluation block sizes generally provide more opportunities for parallel decoding. Whether to preserve the token shift of AR models: We find it unnecessary and potentially harmful. Left-to-right generation tendency: dLLMs still exhibit this tendency during parallel generation, and mimicking it in training can boost generation quality. Training dynamics: Likelihood estimation improves steadily with training, allowing for more aggressive parallel decoding. 2. Efficient-DLM: Study of Attention Patterns 2.1. Analyzing Different Attention Patterns Fully bidirectional attention in existing works. Existing works that transform AR models into dLMs [10, 4] adopt fully bidirectional modeling, i.e., the entire sequence is randomly corrupted and all tokens are visible to each other, as shown in Fig. 2 (a) and (b). This training scheme suffers from the following drawbacks: (1) fully bidirectional attention increases the difficulty of applying KV caching; (2) the context is overly corrupted, particularly for later tokens, which increases training difficulty; (3) the fully"
[17.12.2025 03:24] Mistral response. {"id": "85e7a5456f0c42f38f3b511cac224534", "created": 1765941870, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1405, "total_tokens": 1440, "completion_tokens": 35}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Georgia Tech\",\n    \"University of Chicago\",\n    \"University of Hong Kong\",\n    \"MIT\",\n    \"NVIDIA\"\n]\n```"}}]}
[17.12.2025 03:24] Response: ```python
[
    "Georgia Tech",
    "University of Chicago",
    "University of Hong Kong",
    "MIT",
    "NVIDIA"
]
```
[17.12.2025 03:24] Deleting PDF ./assets/pdf/2512.14067.pdf.
[17.12.2025 03:24] Success.
[17.12.2025 03:24] Enriching papers with extra data.
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 0. Scone integrates composition and distinction in image generation by using a two-stage training scheme with semantic alignment and attention-based masking, outperforming existing models on benchmarks.  					AI-generated summary 				 Subject-driven image generation has advanced from single- to multi-s...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 1. The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting t...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 2. MMGR evaluates video and image models across reasoning abilities in multiple domains, revealing performance gaps and highlighting limitations in perceptual data and causal correctness.  					AI-generated summary 				 Video foundation models generate visually realistic and temporally coherent content...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 3. Olmo 3, a family of state-of-the-art fully-open language models at 7B and 32B parameter scales, excels in long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall.  					AI-generated summary 				 We introduce Olmo 3, a family of state-of-the-art, fu...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 4. Steer3D enables text-based editing of AI-generated 3D assets by adapting ControlNet for image-to-3D generation with flow-matching training and Direct Preference Optimization.  					AI-generated summary 				 Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and rob...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 5. WorldPlay is a streaming video diffusion model that achieves real-time, interactive world modeling with long-term geometric consistency by using a Dual Action Representation, Reconstituted Context Memory, and Context Forcing.  					AI-generated summary 				 This paper presents WorldPlay, a streaming...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 6. RecGPT-V2 enhances recommender systems by integrating a Hierarchical Multi-Agent System, Hybrid Representation Inference, Meta-Prompting, constrained reinforcement learning, and an Agent-as-a-Judge framework to improve efficiency, explanation diversity, generalization, and human preference alignment...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 7. Four abliteration tools are evaluated for their effectiveness in removing refusal representations from large language models, with findings showing variability in capability preservation and distribution shift across different models and tools.  					AI-generated summary 				 Safety alignment mechan...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 8. MemFlow dynamically updates a memory bank by retrieving relevant historical frames for each video chunk, ensuring narrative coherence and generation efficiency with minimal computational overhead.  					AI-generated summary 				 The core challenge for streaming video generation is maintaining the co...
[17.12.2025 03:24] ********************************************************************************
[17.12.2025 03:24] Abstract 9. AR-to-dLM conversion enhances diffusion language models' efficiency and speed while maintaining task accuracy through refined attention patterns and token masking strategies.  					AI-generated summary 				 Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, ...
[17.12.2025 03:24] Read previous papers.
[17.12.2025 03:24] Generating reviews via LLM API.
[17.12.2025 03:24] Querying the API.
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Scone integrates composition and distinction in image generation by using a two-stage training scheme with semantic alignment and attention-based masking, outperforming existing models on benchmarks.  					AI-generated summary 				 Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates. This limitation restricts effectiveness in complex, realistic visual settings. We propose Scone, a unified understanding-generation method that integrates composition and distinction. Scone enables the understanding expert to act as a semantic bridge, conveying semantic information and guiding the generation expert to preserve subject identity while minimizing interference. A two-stage training scheme first learns composition, then enhances distinction through semantic alignment and attention-based masking. We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios. Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks. Our model, benchmark, and training data are available at: https://github.com/Ryann-Ran/Scone.
[17.12.2025 03:24] Response: ```json
{
  "desc": "Scone — это метод генерации изображений, который решает проблему различения объектов при создании композиций с несколькими субъектами. Модель использует двухэтапную схему обучения: сначала изучается композиция, затем улучшается различение через семантическое выравнивание и маскирование внимания. Эксперт понимания действует как семантический мост между входными данными и экспертом генерации, сохраняя идентичность каждого объекта и минимизируя взаимное влияние. Авторы также представили SconeEval — бенчмарк для комплексной оценки качества композиции и различения объектов в разнообразных сценариях.",
  "emoji": "🎨",
  "title": "Композиция с различением: объединение понимания и генерации в создании многообъектных изображений"
}
```
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scone integrates composition and distinction in image generation by using a two-stage training scheme with semantic alignment and attention-based masking, outperforming existing models on benchmarks.  					AI-generated summary 				 Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates. This limitation restricts effectiveness in complex, realistic visual settings. We propose Scone, a unified understanding-generation method that integrates composition and distinction. Scone enables the understanding expert to act as a semantic bridge, conveying semantic information and guiding the generation expert to preserve subject identity while minimizing interference. A two-stage training scheme first learns composition, then enhances distinction through semantic alignment and attention-based masking. We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios. Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks. Our model, benchmark, and training data are available at: https://github.com/Ryann-Ran/Scone."

[17.12.2025 03:24] Response: ```python
['CV', 'DATASET', 'BENCHMARK', 'TRAINING', 'MULTIMODAL']
```
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scone integrates composition and distinction in image generation by using a two-stage training scheme with semantic alignment and attention-based masking, outperforming existing models on benchmarks.  					AI-generated summary 				 Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates. This limitation restricts effectiveness in complex, realistic visual settings. We propose Scone, a unified understanding-generation method that integrates composition and distinction. Scone enables the understanding expert to act as a semantic bridge, conveying semantic information and guiding the generation expert to preserve subject identity while minimizing interference. A two-stage training scheme first learns composition, then enhances distinction through semantic alignment and attention-based masking. We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios. Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks. Our model, benchmark, and training data are available at: https://github.com/Ryann-Ran/Scone."

[17.12.2025 03:24] Response: ```python
['OPEN_SOURCE']
```
[17.12.2025 03:24] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Scone, a novel approach to image generation that effectively combines composition and distinction. It addresses the challenge of generating images with multiple subjects by ensuring that each subject is accurately represented and distinguished. Scone employs a two-stage training process that first focuses on learning how to compose images and then enhances the model\'s ability to distinguish between subjects using semantic alignment and attention-based masking techniques. The results show that Scone outperforms existing models in both composition and distinction tasks, and a new benchmark, SconeEval, is introduced for evaluating these capabilities.","title":"Scone: Bridging Composition and Distinction in Image Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces Scone, a novel approach to image generation that effectively combines composition and distinction. It addresses the challenge of generating images with multiple subjects by ensuring that each subject is accurately represented and distinguished. Scone employs a two-stage training process that first focuses on learning how to compose images and then enhances the model's ability to distinguish between subjects using semantic alignment and attention-based masking techniques. The results show that Scone outperforms existing models in both composition and distinction tasks, and a new benchmark, SconeEval, is introduced for evaluating these capabilities.", title='Scone: Bridging Composition and Distinction in Image Generation'))
[17.12.2025 03:24] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Scone是一种图像生成方法，它结合了组合和区分的能力。通过两阶段的训练方案，Scone首先学习组合，然后通过语义对齐和基于注意力的掩蔽来增强区分能力。这种方法使得生成模型能够在复杂的视觉场景中更好地识别和生成正确的主题。实验结果表明，Scone在组合和区分任务上优于现有的开源模型。","title":"Scone：图像生成中的组合与区分的完美结合"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Scone是一种图像生成方法，它结合了组合和区分的能力。通过两阶段的训练方案，Scone首先学习组合，然后通过语义对齐和基于注意力的掩蔽来增强区分能力。这种方法使得生成模型能够在复杂的视觉场景中更好地识别和生成正确的主题。实验结果表明，Scone在组合和区分任务上优于现有的开源模型。', title='Scone：图像生成中的组合与区分的完美结合'))
[17.12.2025 03:24] Querying the API.
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering "easy" tokens through the efficient width-wise route and allocating deeper iterative refinement to "hard" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN.
[17.12.2025 03:24] Response: ```json
{
  "desc": "Работа предлагает VersatileFFN — новую архитектуру полносвязного слоя для больших языковых моделей, которая увеличивает их представительную способность без увеличения памяти. Метод использует двухпроцессную стратегию: путь по ширине генерирует смесь экспертов из одной сети, а путь по глубине рекурсивно применяет ту же сеть для сложных токенов. Адаптивный гейтинг динамически распределяет простые токены через эффективный маршрут, а сложные отправляет на более глубокую обработку. Все дополнительные возможности получаются за счёт вычислений, а не увеличения параметров модели.",
  "emoji": "🧠",
  "title": "Гибкое переиспользование параметров для эффективного масштабирования LLM"
}
```
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering "easy" tokens through the efficient width-wise route and allocating deeper iterative refinement to "hard" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN."

[17.12.2025 03:24] Response: ```python
["ARCHITECTURE", "TRAINING", "INFERENCE"]
```
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering "easy" tokens through the efficient width-wise route and allocating deeper iterative refinement to "hard" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN."

[17.12.2025 03:24] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **OPTIMIZATION**: The paper proposes VersatileFFN, a novel approach to reduce memory costs and improve parameter efficiency in LLMs through architectural innovations. It addresses training optimization by enabling flexible parameter reuse within a fixed budget, which is directly related to optimization methods.

- **OPEN_SOURCE**: The paper explicitly states "The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN," indicating the authors are releasing their code/framework publicly.
[17.12.2025 03:24] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **OPTIMIZATION**: The paper proposes VersatileFFN, a novel approach to reduce memory costs and improve parameter efficiency in LLMs through architectural innovations. It addresses training optimization by enabling flexible parameter reuse within a fixed budget, which is directly related to optimization methods.

- **OPEN_SOURCE**: The paper explicitly states "The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN," indicating the authors are releasing their code/framework publicly.
[17.12.2025 03:24] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces VersatileFFN, a new type of feed-forward network designed to improve the efficiency of Large Language Models (LLMs) without increasing memory costs. It features two adaptive pathways: one that allows for flexible width adjustments to create a mixture of sub-experts, and another that enables deeper processing for complex inputs. By using a difficulty-aware gating mechanism, the model can efficiently route simpler tokens through a less complex path while applying deeper processing to more challenging tokens. This innovative approach allows for enhanced model capacity through computation rather than additional parameters, making it a significant advancement in parameter-efficient model design.","title":"Enhancing LLM Efficiency with VersatileFFN"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces VersatileFFN, a new type of feed-forward network designed to improve the efficiency of Large Language Models (LLMs) without increasing memory costs. It features two adaptive pathways: one that allows for flexible width adjustments to create a mixture of sub-experts, and another that enables deeper processing for complex inputs. By using a difficulty-aware gating mechanism, the model can efficiently route simpler tokens through a less complex path while applying deeper processing to more challenging tokens. This innovative approach allows for enhanced model capacity through computation rather than additional parameters, making it a significant advancement in parameter-efficient model design.', title='Enhancing LLM Efficiency with VersatileFFN'))
[17.12.2025 03:24] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新型的前馈网络VersatileFFN，旨在提高大语言模型的参数利用效率。该网络通过在固定的参数预算内灵活地重用参数，增强了模型的表示能力。VersatileFFN包含两个自适应路径，分别处理简单和复杂的输入，从而实现高效的计算而不增加内存消耗。实验结果表明，该方法在多个基准测试中表现出色，证明了其有效性。","title":"灵活重用参数，提升模型能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新型的前馈网络VersatileFFN，旨在提高大语言模型的参数利用效率。该网络通过在固定的参数预算内灵活地重用参数，增强了模型的表示能力。VersatileFFN包含两个自适应路径，分别处理简单和复杂的输入，从而实现高效的计算而不增加内存消耗。实验结果表明，该方法在多个基准测试中表现出色，证明了其有效性。', title='灵活重用参数，提升模型能力'))
[17.12.2025 03:24] Querying the API.
[17.12.2025 03:24] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MMGR evaluates video and image models across reasoning abilities in multiple domains, revealing performance gaps and highlighting limitations in perceptual data and causal correctness.  					AI-generated summary 				 Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.
[17.12.2025 03:25] Response: ```json
{
  "desc": "Авторы представляют MMGR — комплексный框架для оценки видео и изображений моделей на основе способностей к рассуждению в пяти категориях: физическое, логическое, пространственное (3D и 2D) и временное мышление. Бенчмарк охватывает три области: абстрактное рассуждение, воплощённую навигацию и здравомысленное понимание физики. Исследование показывает, что ведущие генеративные модели демонстрируют значительные пробелы в способности к рассуждению, особенно в абстрактных задачах (менее 10% точности на ARC-AGI). Анализ выявляет критические ограничения современных моделей: чрезмерная зависимость от перцептивных данных и приоритизация визуального правдоподобия над причинной корректностью.",
  "emoji": "🧠",
  "title": "Логика важнее красоты: оценка рассуждений в генеративных моделях"
}
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MMGR evaluates video and image models across reasoning abilities in multiple domains, revealing performance gaps and highlighting limitations in perceptual data and causal correctness.  					AI-generated summary 				 Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models."

[17.12.2025 03:25] Response: ```python
['BENCHMARK', 'VIDEO', 'MULTIMODAL', 'DATASET']
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MMGR evaluates video and image models across reasoning abilities in multiple domains, revealing performance gaps and highlighting limitations in perceptual data and causal correctness.  					AI-generated summary 				 Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models."

[17.12.2025 03:25] Response: ```python
['REASONING', 'SURVEY']
```
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces MMGR, a new evaluation framework designed to assess the reasoning abilities of video and image models across various domains. It identifies significant performance gaps in current models, particularly in tasks requiring abstract reasoning and long-term spatial planning. The framework emphasizes the importance of causal correctness and global consistency, rather than just perceptual quality. By benchmarking leading models, the study reveals their limitations and suggests a need for more reasoning-aware generative models.","title":"Bridging the Gap: Evaluating Reasoning in Video and Image Models with MMGR"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces MMGR, a new evaluation framework designed to assess the reasoning abilities of video and image models across various domains. It identifies significant performance gaps in current models, particularly in tasks requiring abstract reasoning and long-term spatial planning. The framework emphasizes the importance of causal correctness and global consistency, rather than just perceptual quality. By benchmarking leading models, the study reveals their limitations and suggests a need for more reasoning-aware generative models.', title='Bridging the Gap: Evaluating Reasoning in Video and Image Models with MMGR'))
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MMGR（多模态生成推理评估与基准）是一个评估框架，旨在测试视频和图像模型在多个领域的推理能力。它基于五种推理能力：物理、逻辑、三维空间、二维空间和时间。通过对现有视频和图像生成模型的评估，MMGR揭示了它们在抽象推理和长时间空间规划方面的性能差距。该框架强调了当前模型的局限性，包括对感知数据的过度依赖和因果正确性的不足。","title":"推理能力评估：揭示生成模型的局限性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MMGR（多模态生成推理评估与基准）是一个评估框架，旨在测试视频和图像模型在多个领域的推理能力。它基于五种推理能力：物理、逻辑、三维空间、二维空间和时间。通过对现有视频和图像生成模型的评估，MMGR揭示了它们在抽象推理和长时间空间规划方面的性能差距。该框架强调了当前模型的局限性，包括对感知数据的过度依赖和因果正确性的不足。', title='推理能力评估：揭示生成模型的局限性'))
[17.12.2025 03:25] Querying the API.
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Olmo 3, a family of state-of-the-art fully-open language models at 7B and 32B parameter scales, excels in long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall.  					AI-generated summary 				 We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, including every stage, checkpoint, data point, and dependency used to build it. Our flagship model, Olmo 3 Think 32B, is the strongest fully-open thinking model released to-date.
[17.12.2025 03:25] Response: ```json
{
  "desc": "Представлена семья моделей Olmo 3 — полностью открытых больших языковых моделей размером 7 млрд и 32 млрд параметров, которые демонстрируют высокую производительность в задачах логического рассуждения на длинных контекстах, вызове функций и написании кода. Модели были оптимизированы для следования инструкциям, общего диалога и воспроизведения знаний. Авторы предоставили полный открытый жизненный цикл моделей, включая все этапы разработки, промежуточные контрольные точки, данные обучения и зависимости. Флагманская модель Olmo 3 Think 32B признана самой мощной полностью открытой языковой моделью с встроенным механизмом рассуждения на данный момент.",
  "emoji": "🧠",
  "title": "Олмо 3: полностью открытые языковые модели нового поколения с улучшенным рассуждением"
}
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Olmo 3, a family of state-of-the-art fully-open language models at 7B and 32B parameter scales, excels in long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall.  					AI-generated summary 				 We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, including every stage, checkpoint, data point, and dependency used to build it. Our flagship model, Olmo 3 Think 32B, is the strongest fully-open thinking model released to-date."

[17.12.2025 03:25] Response: ```python
["ARCHITECTURE", "TRAINING", "DATASET"]
```

**Justification:**
- **ARCHITECTURE**: The paper introduces Olmo 3, a new family of language models, which represents novel model architectures/variants at different scales (7B and 32B parameters).
- **TRAINING**: The paper discusses the full model construction lifecycle and training process, including stages, checkpoints, and dependencies used to build the models.
- **DATASET**: The paper mentions releasing "every stage, checkpoint, data point, and dependency," indicating the release includes dataset components and data used in model construction.
[17.12.2025 03:25] Error. Failed to parse JSON from LLM. ["ARCHITECTURE", "TRAINING", "DATASET"]


**Justification:**
- **ARCHITECTURE**: The paper introduces Olmo 3, a new family of language models, which represents novel model architectures/variants at different scales (7B and 32B parameters).
- **TRAINING**: The paper discusses the full model construction lifecycle and training process, including stages, checkpoints, and dependencies used to build the models.
- **DATASET**: The paper mentions releasing "every stage, checkpoint, data point, and dependency," indicating the release includes dataset components and data used in model construction.
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Olmo 3, a family of state-of-the-art fully-open language models at 7B and 32B parameter scales, excels in long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall.  					AI-generated summary 				 We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, including every stage, checkpoint, data point, and dependency used to build it. Our flagship model, Olmo 3 Think 32B, is the strongest fully-open thinking model released to-date."

[17.12.2025 03:25] Response: ```python
["OPEN_SOURCE", "LONG_CONTEXT", "REASONING"]
```
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Olmo 3 is a new family of advanced language models with 7 billion and 32 billion parameters, designed to perform well in various tasks such as long-context reasoning and coding. These models are fully open, meaning that researchers and developers can access the entire model lifecycle, including all stages and data used in their creation. The models excel in instruction following, general chat, and knowledge recall, making them versatile tools for different applications. The standout model, Olmo 3 Think 32B, is highlighted as the most powerful open thinking model available so far.","title":"Unlocking Advanced Language Understanding with Olmo 3"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Olmo 3 is a new family of advanced language models with 7 billion and 32 billion parameters, designed to perform well in various tasks such as long-context reasoning and coding. These models are fully open, meaning that researchers and developers can access the entire model lifecycle, including all stages and data used in their creation. The models excel in instruction following, general chat, and knowledge recall, making them versatile tools for different applications. The standout model, Olmo 3 Think 32B, is highlighted as the most powerful open thinking model available so far.', title='Unlocking Advanced Language Understanding with Olmo 3'))
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Olmo 3是一系列最先进的完全开放的语言模型，具有7B和32B参数规模。该模型专注于长上下文推理、函数调用、编码、指令跟随、一般聊天和知识回忆等任务。此次发布包括模型的完整生命周期，涵盖了构建模型所需的每个阶段、检查点、数据点和依赖关系。我们的旗舰模型Olmo 3 Think 32B是迄今为止发布的最强大的完全开放思维模型。","title":"Olmo 3：最强大的开放语言模型"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Olmo 3是一系列最先进的完全开放的语言模型，具有7B和32B参数规模。该模型专注于长上下文推理、函数调用、编码、指令跟随、一般聊天和知识回忆等任务。此次发布包括模型的完整生命周期，涵盖了构建模型所需的每个阶段、检查点、数据点和依赖关系。我们的旗舰模型Olmo 3 Think 32B是迄今为止发布的最强大的完全开放思维模型。', title='Olmo 3：最强大的开放语言模型'))
[17.12.2025 03:25] Querying the API.
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Steer3D enables text-based editing of AI-generated 3D assets by adapting ControlNet for image-to-3D generation with flow-matching training and Direct Preference Optimization.  					AI-generated summary 				 Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/
[17.12.2025 03:25] Response: ```json
{
  "desc": "Steer3D — это метод для редактирования трёхмерных объектов, созданных нейросетями, с помощью текстовых команд. Авторы адаптировали архитектуру ControlNet для модели, которая создаёт 3D из изображений, добавив управление через естественный язык. Обучение проводится в два этапа с использованием flow-matching и Direct Preference Optimization, что позволяет лучше следовать инструкциям и сохранять качество исходного объекта. Метод работает в 2.4-28.5 раз быстрее аналогов и требует всего 100 тысяч синтетических примеров для обучения.",
  "emoji": "🎨",
  "title": "Управление 3D генерацией текстовыми командами через адаптированный ControlNet"
}
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Steer3D enables text-based editing of AI-generated 3D assets by adapting ControlNet for image-to-3D generation with flow-matching training and Direct Preference Optimization.  					AI-generated summary 				 Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/"

[17.12.2025 03:25] Response: ```python
["3D", "MULTIMODAL", "TRAINING", "RLHF"]
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Steer3D enables text-based editing of AI-generated 3D assets by adapting ControlNet for image-to-3D generation with flow-matching training and Direct Preference Optimization.  					AI-generated summary 				 Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/"

[17.12.2025 03:25] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE']
```

**Reasoning:**

- **OPTIMIZATION**: The paper discusses training optimization methods, specifically "flow-matching training and Direct Preference Optimization (DPO)" which are advanced training techniques used to optimize the model.

- **OPEN_SOURCE**: The paper includes a project website link and describes releasing a method/framework (Steer3D) for the community, indicating contribution to open-source resources.
[17.12.2025 03:25] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Reasoning:**

- **OPTIMIZATION**: The paper discusses training optimization methods, specifically "flow-matching training and Direct Preference Optimization (DPO)" which are advanced training techniques used to optimize the model.

- **OPEN_SOURCE**: The paper includes a project website link and describes releasing a method/framework (Steer3D) for the community, indicating contribution to open-source resources.
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Steer3D is a novel method that enhances the editing of AI-generated 3D assets by integrating text-based commands into the image-to-3D generation process. It builds on the ControlNet framework, allowing users to modify 3D models directly through language inputs during a single forward pass. The method employs flow-matching training and Direct Preference Optimization to ensure that the generated assets align closely with user instructions while maintaining high fidelity to the original designs. Steer3D significantly improves the speed and accuracy of 3D asset editing, making it a powerful tool for applications in design, AR/VR, and robotics.","title":"Text-Driven Editing for 3D Assets with Steer3D"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Steer3D is a novel method that enhances the editing of AI-generated 3D assets by integrating text-based commands into the image-to-3D generation process. It builds on the ControlNet framework, allowing users to modify 3D models directly through language inputs during a single forward pass. The method employs flow-matching training and Direct Preference Optimization to ensure that the generated assets align closely with user instructions while maintaining high fidelity to the original designs. Steer3D significantly improves the speed and accuracy of 3D asset editing, making it a powerful tool for applications in design, AR/VR, and robotics.', title='Text-Driven Editing for 3D Assets with Steer3D'))
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Steer3D 是一种新方法，允许用户通过文本编辑 AI 生成的 3D 资产。它基于 ControlNet 的理念，适用于图像到 3D 的生成，能够在前向传递中直接进行文本引导。该方法使用流匹配训练和直接偏好优化（DPO）进行两阶段训练，显著提高了生成速度和与原始 3D 资产的一致性。Steer3D 展示了如何将文本这一新模态添加到预训练的图像到 3D 生成模型中，提升了用户的编辑体验。","title":"文本引导，轻松编辑3D资产"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Steer3D 是一种新方法，允许用户通过文本编辑 AI 生成的 3D 资产。它基于 ControlNet 的理念，适用于图像到 3D 的生成，能够在前向传递中直接进行文本引导。该方法使用流匹配训练和直接偏好优化（DPO）进行两阶段训练，显著提高了生成速度和与原始 3D 资产的一致性。Steer3D 展示了如何将文本这一新模态添加到预训练的图像到 3D 生成模型中，提升了用户的编辑体验。', title='文本引导，轻松编辑3D资产'))
[17.12.2025 03:25] Querying the API.
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

WorldPlay is a streaming video diffusion model that achieves real-time, interactive world modeling with long-term geometric consistency by using a Dual Action Representation, Reconstituted Context Memory, and Context Forcing.  					AI-generated summary 				 This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.
[17.12.2025 03:25] Response: ```json
{
  "desc": "WorldPlay — это потоковая модель диффузии видео, которая генерирует видео в реальном времени с сохранением долгосрочной геометрической консистентности. Модель использует трёхкомпонентный подход: двойное представление действий для робастного управления через пользовательский ввод, восстановленную память контекста для доступа к геометрически важным кадрам из прошлого, и Context Forcing — метод дистилляции для сохранения способности модели использовать долгодальную информацию. Архитектура решает классический компромисс между скоростью вывода и объёмом памяти, достигая генерации видео разрешением 720p при 24 FPS с высокой консистентностью. Модель показывает хорошую генерализацию на разнообразных сценах и сцен внутри игровых сред.",
  "emoji": "🎮",
  "title": "Интерактивное моделирование трёхмерных миров в реальном времени с долгосрочной геометрической консистентностью"
}
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"WorldPlay is a streaming video diffusion model that achieves real-time, interactive world modeling with long-term geometric consistency by using a Dual Action Representation, Reconstituted Context Memory, and Context Forcing.  					AI-generated summary 				 This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D."

[17.12.2025 03:25] Response: ```python
["VIDEO", "3D", "ARCHITECTURE", "TRAINING"]
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"WorldPlay is a streaming video diffusion model that achieves real-time, interactive world modeling with long-term geometric consistency by using a Dual Action Representation, Reconstituted Context Memory, and Context Forcing.  					AI-generated summary 				 This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D."

[17.12.2025 03:25] Response: ```python
["DIFFUSION", "LONG_CONTEXT"]
```
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"WorldPlay is a novel streaming video diffusion model that allows for real-time interactive world modeling while maintaining long-term geometric consistency. It introduces a Dual Action Representation to effectively manage user inputs, ensuring responsive action control. The model employs a Reconstituted Context Memory that dynamically reconstructs context from previous frames, which helps retain important geometric information over time. Additionally, Context Forcing is utilized to align memory context between teacher and student models, enabling efficient use of long-range information and achieving high-quality video output at 24 frames per second.","title":"Real-Time Interactive World Modeling with Long-Term Consistency"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='WorldPlay is a novel streaming video diffusion model that allows for real-time interactive world modeling while maintaining long-term geometric consistency. It introduces a Dual Action Representation to effectively manage user inputs, ensuring responsive action control. The model employs a Reconstituted Context Memory that dynamically reconstructs context from previous frames, which helps retain important geometric information over time. Additionally, Context Forcing is utilized to align memory context between teacher and student models, enabling efficient use of long-range information and achieving high-quality video output at 24 frames per second.', title='Real-Time Interactive World Modeling with Long-Term Consistency'))
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"WorldPlay是一种流媒体视频扩散模型，能够实现实时、互动的世界建模，并保持长期的几何一致性。该模型通过三项关键创新来解决速度和内存之间的权衡。首先，双重动作表示使得模型能够根据用户的键盘和鼠标输入进行稳健的动作控制。其次，重构上下文记忆动态重建过去帧的上下文，并通过时间重构保持几何重要的旧帧可访问，从而减轻内存衰减的问题。","title":"实时互动世界建模的创新解决方案"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='WorldPlay是一种流媒体视频扩散模型，能够实现实时、互动的世界建模，并保持长期的几何一致性。该模型通过三项关键创新来解决速度和内存之间的权衡。首先，双重动作表示使得模型能够根据用户的键盘和鼠标输入进行稳健的动作控制。其次，重构上下文记忆动态重建过去帧的上下文，并通过时间重构保持几何重要的旧帧可访问，从而减轻内存衰减的问题。', title='实时互动世界建模的创新解决方案'))
[17.12.2025 03:25] Querying the API.
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

RecGPT-V2 enhances recommender systems by integrating a Hierarchical Multi-Agent System, Hybrid Representation Inference, Meta-Prompting, constrained reinforcement learning, and an Agent-as-a-Judge framework to improve efficiency, explanation diversity, generalization, and human preference alignment.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.   To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility.
[17.12.2025 03:25] Response: ```json
{
  "desc": "RecGPT-V2 улучшает рекомендательные системы путём интеграции иерархической многоагентной системы, которая эффективно координирует процессы рассуждения об интентах пользователей и снижает вычислительные затраты на 60%. Гибридная инференция представлений и мета-промптинг позволяют генерировать разнообразные объяснения рекомендаций, адаптивные к контексту пользователя. Ограниченное обучение с подкреплением решает конфликты между несколькими целевыми функциями, значительно улучшая качество предсказания тегов и принятие объяснений. Фреймворк Agent-as-a-Judge применяет многошаговое рассуждение для оценки результатов, обеспечивая лучшее соответствие предпочтениям пользователей в масштабах промышленного применения.",
  "emoji": "🤖",
  "title": "Многоагентные LLM для масштабируемых рекомендаций с явным рассуждением об интентах"
}
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RecGPT-V2 enhances recommender systems by integrating a Hierarchical Multi-Agent System, Hybrid Representation Inference, Meta-Prompting, constrained reinforcement learning, and an Agent-as-a-Judge framework to improve efficiency, explanation diversity, generalization, and human preference alignment.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.   To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility."

[17.12.2025 03:25] Response: ```python
["AGENTS", "RL", "RLHF", "TRAINING"]
```
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RecGPT-V2 enhances recommender systems by integrating a Hierarchical Multi-Agent System, Hybrid Representation Inference, Meta-Prompting, constrained reinforcement learning, and an Agent-as-a-Judge framework to improve efficiency, explanation diversity, generalization, and human preference alignment.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.   To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility."

[17.12.2025 03:25] Response: ```python
['REASONING', 'ALIGNMENT', 'OPTIMIZATION']
```
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RecGPT-V2 improves recommender systems by using a Hierarchical Multi-Agent System that enhances intent reasoning while reducing computational redundancy. It introduces Hybrid Representation Inference to optimize user behavior context, leading to significant reductions in GPU usage and better recall rates. The Meta-Prompting framework increases the diversity of explanations provided to users, while constrained reinforcement learning resolves conflicts in reward systems, enhancing tag prediction and user acceptance of explanations. Finally, the Agent-as-a-Judge framework refines evaluation processes to align more closely with human preferences, demonstrating substantial performance gains in real-world applications.","title":"Revolutionizing Recommendations with Intelligent Intent Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RecGPT-V2 improves recommender systems by using a Hierarchical Multi-Agent System that enhances intent reasoning while reducing computational redundancy. It introduces Hybrid Representation Inference to optimize user behavior context, leading to significant reductions in GPU usage and better recall rates. The Meta-Prompting framework increases the diversity of explanations provided to users, while constrained reinforcement learning resolves conflicts in reward systems, enhancing tag prediction and user acceptance of explanations. Finally, the Agent-as-a-Judge framework refines evaluation processes to align more closely with human preferences, demonstrating substantial performance gains in real-world applications.', title='Revolutionizing Recommendations with Intelligent Intent Reasoning'))
[17.12.2025 03:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RecGPT-V2通过整合层次多智能体系统、混合表示推理、元提示、受限强化学习和代理评判框架，提升了推荐系统的效率和解释多样性。该系统解决了RecGPT-V1的计算效率低、解释多样性不足、泛化能力有限和评估标准简单等问题。通过动态生成适应上下文的提示，RecGPT-V2提高了用户兴趣挖掘和标签预测的准确性。在线测试结果显示，RecGPT-V2在多个关键指标上均有显著提升，证明了其在大规模应用中的技术可行性和商业价值。","title":"RecGPT-V2：智能推荐系统的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RecGPT-V2通过整合层次多智能体系统、混合表示推理、元提示、受限强化学习和代理评判框架，提升了推荐系统的效率和解释多样性。该系统解决了RecGPT-V1的计算效率低、解释多样性不足、泛化能力有限和评估标准简单等问题。通过动态生成适应上下文的提示，RecGPT-V2提高了用户兴趣挖掘和标签预测的准确性。在线测试结果显示，RecGPT-V2在多个关键指标上均有显著提升，证明了其在大规模应用中的技术可行性和商业价值。', title='RecGPT-V2：智能推荐系统的新突破'))
[17.12.2025 03:25] Querying the API.
[17.12.2025 03:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Four abliteration tools are evaluated for their effectiveness in removing refusal representations from large language models, with findings showing variability in capability preservation and distribution shift across different models and tools.  					AI-generated summary 				 Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B-14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support. Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K change across three models: ErisForge -0.28 pp; DECCP -0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.043-1.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to -18.81 pp (-26.5% relative) depending on tool selection and model architecture.
[17.12.2025 03:26] Response: ```json
{
  "desc": "В работе оценивается эффективность четырёх инструментов абляции для удаления механизмов отказа из больших языковых моделей. Исследователи тестировали эти инструменты на 16 моделях и обнаружили, что однопроходные методы лучше сохраняют способности модели, в то время как байесовская оптимизация вызывает вариативное смещение распределения. Ключевой вывод показывает, что математическое мышление наиболее чувствительно к абляции, с изменениями производительности от +1.51% до -26.5% в зависимости от выбранного инструмента. Работа предоставляет исследователям практические критерии для выбора оптимального инструмента при работе с различными архитектурами моделей.",
  "emoji": "🔪",
  "title": "Хирургическое удаление отказов: сравнение инструментов абляции для LLM"
}
```
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Four abliteration tools are evaluated for their effectiveness in removing refusal representations from large language models, with findings showing variability in capability preservation and distribution shift across different models and tools.  					AI-generated summary 				 Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B-14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support. Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K change across three models: ErisForge -0.28 pp; DECCP -0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.043-1.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to -18.81 pp (-26.5% relative) depending on tool selection and model architecture."

[17.12.2025 03:26] Response: ```python
["BENCHMARK", "TRAINING"]
```
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Four abliteration tools are evaluated for their effectiveness in removing refusal representations from large language models, with findings showing variability in capability preservation and distribution shift across different models and tools.  					AI-generated summary 				 Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B-14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support. Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K change across three models: ErisForge -0.28 pp; DECCP -0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.043-1.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to -18.81 pp (-26.5% relative) depending on tool selection and model architecture."

[17.12.2025 03:26] Response: ```python
['ALIGNMENT', 'SECURITY', 'INTERPRETABILITY']
```
[17.12.2025 03:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper evaluates four different abliteration tools designed to remove refusal representations from large language models. The study finds that these tools vary in their ability to preserve model capabilities and manage distribution shifts across different model architectures. It highlights that single-pass methods tend to maintain better performance compared to Bayesian-optimized approaches, which can lead to significant variability in model behavior. The results provide valuable insights for researchers on how to choose the right abliteration tool based on the specific model and application needs.","title":"Choosing the Right Tool for Effective Abliteration in Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper evaluates four different abliteration tools designed to remove refusal representations from large language models. The study finds that these tools vary in their ability to preserve model capabilities and manage distribution shifts across different model architectures. It highlights that single-pass methods tend to maintain better performance compared to Bayesian-optimized approaches, which can lead to significant variability in model behavior. The results provide valuable insights for researchers on how to choose the right abliteration tool based on the specific model and application needs.', title='Choosing the Right Tool for Effective Abliteration in Language Models'))
[17.12.2025 03:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究评估了四种消除工具在去除大型语言模型中的拒绝表示的有效性。这些工具在不同模型和工具之间的能力保留和分布变化上表现出差异。研究发现，数学推理能力对消除干预的敏感性最高，变化范围从+1.51 pp到-18.81 pp。研究结果为研究人员在不同模型架构中选择消除工具提供了基于证据的标准。","title":"消除工具的有效性评估与选择标准"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究评估了四种消除工具在去除大型语言模型中的拒绝表示的有效性。这些工具在不同模型和工具之间的能力保留和分布变化上表现出差异。研究发现，数学推理能力对消除干预的敏感性最高，变化范围从+1.51 pp到-18.81 pp。研究结果为研究人员在不同模型架构中选择消除工具提供了基于证据的标准。', title='消除工具的有效性评估与选择标准'))
[17.12.2025 03:26] Querying the API.
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MemFlow dynamically updates a memory bank by retrieving relevant historical frames for each video chunk, ensuring narrative coherence and generation efficiency with minimal computational overhead.  					AI-generated summary 				 The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming chunk, we dynamically update the memory bank by retrieving the most relevant historical frames with the text prompt of this chunk. This design enables narrative coherence even if new event happens or scenario switches in future frames. In addition, during generation, we only activate the most relevant tokens in the memory bank for each query in the attention layers, which effectively guarantees the generation efficiency. In this way, MemFlow achieves outstanding long-context consistency with negligible computation burden (7.9% speed reduction compared with the memory-free baseline) and keeps the compatibility with any streaming video generation model with KV cache.
[17.12.2025 03:26] Response: ```json
{
  "desc": "MemFlow — это метод для генерации длинных видеопотоков, который решает проблему поддержания консистентности контента. Система использует динамическое управление памятью, извлекая наиболее релевантные исторические кадры для каждого генерируемого фрагмента на основе текстового запроса. Во время генерации активируются только самые важные токены из памяти, что обеспечивает высокую эффективность с минимальными вычислительными затратами. Подход совместим с любыми моделями потоковой генерации видео с KV-кэшем и сохраняет нарративную связность даже при смене сцен.",
  "emoji": "🎬",
  "title": "Динамическая память для связного потокового видеогенерирования"
}
```
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MemFlow dynamically updates a memory bank by retrieving relevant historical frames for each video chunk, ensuring narrative coherence and generation efficiency with minimal computational overhead.  					AI-generated summary 				 The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming chunk, we dynamically update the memory bank by retrieving the most relevant historical frames with the text prompt of this chunk. This design enables narrative coherence even if new event happens or scenario switches in future frames. In addition, during generation, we only activate the most relevant tokens in the memory bank for each query in the attention layers, which effectively guarantees the generation efficiency. In this way, MemFlow achieves outstanding long-context consistency with negligible computation burden (7.9% speed reduction compared with the memory-free baseline) and keeps the compatibility with any streaming video generation model with KV cache."

[17.12.2025 03:26] Response: ```python
['VIDEO', 'INFERENCE']
```

**Justification:**

- **VIDEO**: The paper explicitly focuses on streaming video generation, maintaining consistency in long-context video generation, and proposes MemFlow as a solution for video chunk generation with narrative coherence.

- **INFERENCE**: The paper addresses generation efficiency and computational optimization through selective token activation in attention layers, achieving minimal computational overhead (7.9% speed reduction), which relates to optimizing model deployment and inference efficiency.
[17.12.2025 03:26] Error. Failed to parse JSON from LLM. ["VIDEO", "INFERENCE"]


**Justification:**

- **VIDEO**: The paper explicitly focuses on streaming video generation, maintaining consistency in long-context video generation, and proposes MemFlow as a solution for video chunk generation with narrative coherence.

- **INFERENCE**: The paper addresses generation efficiency and computational optimization through selective token activation in attention layers, achieving minimal computational overhead (7.9% speed reduction), which relates to optimizing model deployment and inference efficiency.
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MemFlow dynamically updates a memory bank by retrieving relevant historical frames for each video chunk, ensuring narrative coherence and generation efficiency with minimal computational overhead.  					AI-generated summary 				 The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming chunk, we dynamically update the memory bank by retrieving the most relevant historical frames with the text prompt of this chunk. This design enables narrative coherence even if new event happens or scenario switches in future frames. In addition, during generation, we only activate the most relevant tokens in the memory bank for each query in the attention layers, which effectively guarantees the generation efficiency. In this way, MemFlow achieves outstanding long-context consistency with negligible computation burden (7.9% speed reduction compared with the memory-free baseline) and keeps the compatibility with any streaming video generation model with KV cache."

[17.12.2025 03:26] Response: ```python
['LONG_CONTEXT']
```
[17.12.2025 03:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MemFlow is a novel approach for streaming video generation that enhances narrative coherence by dynamically updating a memory bank. Instead of using fixed strategies to compress historical frames, MemFlow retrieves relevant frames based on the specific text prompt of the upcoming video chunk. This allows the model to maintain content consistency even when new events or scenarios arise. Additionally, by activating only the most pertinent tokens during the generation process, MemFlow achieves efficient computation with minimal speed reduction compared to traditional methods.","title":"Dynamic Memory for Coherent Video Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MemFlow is a novel approach for streaming video generation that enhances narrative coherence by dynamically updating a memory bank. Instead of using fixed strategies to compress historical frames, MemFlow retrieves relevant frames based on the specific text prompt of the upcoming video chunk. This allows the model to maintain content consistency even when new events or scenarios arise. Additionally, by activating only the most pertinent tokens during the generation process, MemFlow achieves efficient computation with minimal speed reduction compared to traditional methods.', title='Dynamic Memory for Coherent Video Generation'))
[17.12.2025 03:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MemFlow是一种动态更新记忆库的方法，通过检索与每个视频片段相关的历史帧，确保叙事的一致性和生成的高效性。传统方法通常使用预定义策略压缩历史帧，难以满足不同视频片段对历史线索的不同需求。MemFlow在生成新片段之前，动态更新记忆库，提取与当前文本提示最相关的历史帧。这样，即使在未来帧中发生新事件或场景切换，MemFlow也能保持叙事的连贯性，同时在生成过程中仅激活最相关的记忆令牌，从而有效提高生成效率。","title":"动态记忆更新，确保视频生成一致性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MemFlow是一种动态更新记忆库的方法，通过检索与每个视频片段相关的历史帧，确保叙事的一致性和生成的高效性。传统方法通常使用预定义策略压缩历史帧，难以满足不同视频片段对历史线索的不同需求。MemFlow在生成新片段之前，动态更新记忆库，提取与当前文本提示最相关的历史帧。这样，即使在未来帧中发生新事件或场景切换，MemFlow也能保持叙事的连贯性，同时在生成过程中仅激活最相关的记忆令牌，从而有效提高生成效率。', title='动态记忆更新，确保视频生成一致性'))
[17.12.2025 03:26] Querying the API.
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

AR-to-dLM conversion enhances diffusion language models' efficiency and speed while maintaining task accuracy through refined attention patterns and token masking strategies.  					AI-generated summary 				 Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively.
[17.12.2025 03:26] Response: ```json
{
  "desc": "В статье предлагается метод преобразования предобученных авторегрессивных языковых моделей в диффузионные языковые модели, которые генерируют текст параллельно вместо последовательного режима. Авторы выявили критические ограничения существующих методов конвертации и предложили блочный паттерн внимания, который сохраняет распределение весов исходной модели, обеспечивая баланс между точностью и эффективностью. Кроме того, они разработали стратегию маскирования токенов, зависимую от позиции, чтобы уменьшить разрыв между распределением масок на этапе обучения и тестирования. Результирующее семейство моделей Efficient-DLM демонстрирует превосходную производительность с значительным увеличением пропускной способности при сохранении или улучшении точности на различных задачах.",
  "emoji": "⚡",
  "title": "Превращение последовательных моделей в параллельные без потери качества"
}
```
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AR-to-dLM conversion enhances diffusion language models' efficiency and speed while maintaining task accuracy through refined attention patterns and token masking strategies.  					AI-generated summary 				 Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively."

[17.12.2025 03:26] Response: ```python
["ARCHITECTURE", "TRAINING", "INFERENCE"]
```

**Justification:**

- **ARCHITECTURE**: The paper proposes novel neural architecture modifications, specifically introducing a block-wise attention pattern that maintains causal attention across blocks while enabling bidirectional modeling within blocks. This is a core architectural contribution.

- **TRAINING**: The paper focuses on improving model training and fine-tuning methods, including the AR-to-dLM conversion process, continuous pretraining schemes, and position-dependent token masking strategies to improve training efficiency and mitigate training-test gaps.

- **INFERENCE**: The paper emphasizes optimization for model deployment, specifically addressing efficiency and speed improvements (4.5x/2.7x higher throughput) while maintaining accuracy, which is central to inference optimization.
[17.12.2025 03:26] Error. Failed to parse JSON from LLM. ["ARCHITECTURE", "TRAINING", "INFERENCE"]


**Justification:**

- **ARCHITECTURE**: The paper proposes novel neural architecture modifications, specifically introducing a block-wise attention pattern that maintains causal attention across blocks while enabling bidirectional modeling within blocks. This is a core architectural contribution.

- **TRAINING**: The paper focuses on improving model training and fine-tuning methods, including the AR-to-dLM conversion process, continuous pretraining schemes, and position-dependent token masking strategies to improve training efficiency and mitigate training-test gaps.

- **INFERENCE**: The paper emphasizes optimization for model deployment, specifically addressing efficiency and speed improvements (4.5x/2.7x higher throughput) while maintaining accuracy, which is central to inference optimization.
[17.12.2025 03:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AR-to-dLM conversion enhances diffusion language models' efficiency and speed while maintaining task accuracy through refined attention patterns and token masking strategies.  					AI-generated summary 				 Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively."

[17.12.2025 03:26] Response: ```python
['DIFFUSION', 'OPTIMIZATION', 'TRANSFER_LEARNING']
```
[17.12.2025 03:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses a method to improve diffusion language models (dLMs) by converting pretrained autoregressive (AR) models into more efficient dLMs. The authors identify issues with existing AR-to-dLM conversion techniques, particularly in attention patterns and token masking strategies. They propose a continuous pretraining scheme that maintains the weight distributions of AR models while allowing for efficient bidirectional modeling. Their approach results in significant improvements in both speed and accuracy, leading to the development of the Efficient-DLM family, which surpasses current state-of-the-art models.","title":"Transforming AR Models for Faster, Accurate dLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses a method to improve diffusion language models (dLMs) by converting pretrained autoregressive (AR) models into more efficient dLMs. The authors identify issues with existing AR-to-dLM conversion techniques, particularly in attention patterns and token masking strategies. They propose a continuous pretraining scheme that maintains the weight distributions of AR models while allowing for efficient bidirectional modeling. Their approach results in significant improvements in both speed and accuracy, leading to the development of the Efficient-DLM family, which surpasses current state-of-the-art models.', title='Transforming AR Models for Faster, Accurate dLMs'))
[17.12.2025 03:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文研究了将自回归（AR）语言模型转换为扩散语言模型（dLM）的过程，以提高模型的效率和速度，同时保持任务的准确性。我们发现，保持预训练AR模型的权重分布对于有效的AR到dLM转换至关重要，因此提出了一种连续预训练方案，采用块级注意力模式。为了缩小训练和测试之间的差距，我们还提出了一种位置依赖的标记掩蔽策略，以更好地模拟测试时的行为。通过这些方法，我们的Efficient-DLM系列模型在准确性和效率上均优于现有的AR和dLM模型。","title":"高效转换：提升扩散语言模型的速度与准确性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文研究了将自回归（AR）语言模型转换为扩散语言模型（dLM）的过程，以提高模型的效率和速度，同时保持任务的准确性。我们发现，保持预训练AR模型的权重分布对于有效的AR到dLM转换至关重要，因此提出了一种连续预训练方案，采用块级注意力模式。为了缩小训练和测试之间的差距，我们还提出了一种位置依赖的标记掩蔽策略，以更好地模拟测试时的行为。通过这些方法，我们的Efficient-DLM系列模型在准确性和效率上均优于现有的AR和dLM模型。', title='高效转换：提升扩散语言模型的速度与准确性'))
[17.12.2025 03:26] Renaming data file.
[17.12.2025 03:26] Renaming previous data. hf_papers.json to ./d/2025-12-17.json
[17.12.2025 03:26] Saving new data file.
[17.12.2025 03:26] Generating page.
[17.12.2025 03:26] Renaming previous page.
[17.12.2025 03:26] Renaming previous data. index.html to ./d/2025-12-17.html
[17.12.2025 03:26] Writing result.
[17.12.2025 03:26] Renaming log file.
[17.12.2025 03:26] Renaming previous data. log.txt to ./logs/2025-12-17_last_log.txt
