[01.02.2025 06:28] Read previous papers.
[01.02.2025 06:28] Generating top page (month).
[01.02.2025 06:28] Writing top page (month).
[01.02.2025 12:37] Read previous papers.
[01.02.2025 12:37] Get feed.
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18492
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18585
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18512
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18362
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18009
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.16411
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18511
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18438
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18427
[01.02.2025 12:37] Get page data from previous paper. URL: https://huggingface.co/papers/2501.16609
[01.02.2025 12:37] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[01.02.2025 12:37] No deleted papers detected.
[01.02.2025 12:37] Downloading and parsing papers (pdf, html). Total: 10.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18492.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18492.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18492.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18585.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18585.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18585.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18512.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18512.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18512.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18362.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18362.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18362.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18009.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18009.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18009.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.16411.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.16411.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.16411.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18511.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18511.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18511.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18438.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18438.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18438.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.18427.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.18427.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.18427.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Downloading and parsing paper https://huggingface.co/papers/2501.16609.
[01.02.2025 12:37] Extra JSON file exists (./assets/json/2501.16609.json), skip PDF parsing.
[01.02.2025 12:37] Paper image links file exists (./assets/img_data/2501.16609.json), skip HTML parsing.
[01.02.2025 12:37] Success.
[01.02.2025 12:37] Enriching papers with extra data.
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 0. As LLMs increasingly impact safety-critical applications, ensuring their safety using guardrails remains a key challenge. This paper proposes GuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to reason. Concretely, we first create the GuardReasonerTrain dataset, which cons...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 1. Large language models (LLMs) such as OpenAI's o1 have demonstrated remarkable abilities in complex reasoning tasks by scaling test-time compute and exhibiting human-like deep thinking. However, we identify a phenomenon we term underthinking, where o1-like LLMs frequently switch between different rea...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 2. Training of large language models (LLMs) is typically distributed across a large number of accelerators to reduce training time. Since internal states and parameter gradients need to be exchanged at each and every single gradient step, all devices need to be co-located using low-latency high-bandwid...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 3. We introduce MedXpertQA, a highly challenging and comprehensive benchmark to evaluate expert-level medical knowledge and advanced reasoning. MedXpertQA includes 4,460 questions spanning 17 specialties and 11 body systems. It includes two subsets, Text for text evaluation and MM for multimodal evalua...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 4. Large Language Models have emerged many intellectual capacities. While numerous benchmarks assess their intelligence, limited attention has been given to their ability to explore, an essential capacity for discovering new information and adapting to novel environments in both natural and artificial ...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 5. Understanding the physical world is a fundamental challenge in embodied AI, critical for enabling agents to perform complex tasks and operate safely in real-world environments. While Vision-Language Models (VLMs) have shown great promise in reasoning and task planning for embodied agents, their abil...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 6. Language model (LLM) post-training, from DPO to distillation, can refine behaviors and unlock new skills, but the open science supporting these post-training techniques is still in its infancy. One limiting factor has been the difficulty of conducting large-scale comparative analyses of synthetic da...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 7. The irruption of DeepSeek-R1 constitutes a turning point for the AI industry in general and the LLMs in particular. Its capabilities have demonstrated outstanding performance in several tasks, including creative thinking, code generation, maths and automated program repair, at apparently lower execu...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 8. This paper presents SANA-1.5, a linear Diffusion Transformer for efficient scaling in text-to-image generation. Building upon SANA-1.0, we introduce three key innovations: (1) Efficient Training Scaling: A depth-growth paradigm that enables scaling from 1.6B to 4.8B parameters with significantly red...
[01.02.2025 12:37] ********************************************************************************
[01.02.2025 12:37] Abstract 9. While much work on web agents emphasizes the promise of autonomously performing tasks on behalf of users, in reality, agents often fall short on complex tasks in real-world contexts and modeling user preference. This presents an opportunity for humans to collaborate with the agent and leverage the a...
[01.02.2025 12:37] Read previous papers.
[01.02.2025 12:37] Generating reviews via LLM API.
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#small_models", "#training", "#open_source", "#dataset", "#reasoning", "#benchmark", "#alignment"], "emoji": "ğŸ›¡ï¸", "ru": {"title": "Ğ Ğ°Ğ·ÑƒĞ¼Ğ½Ğ°Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ°: Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğ¼Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ GuardReasoner - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… 
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#math", "#reasoning", "#training", "#optimization"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ“Ğ»ÑƒĞ±Ğ¶Ğµ Ğ¼Ñ‹ÑĞ»Ğ¸, Ñ‚Ğ¾Ñ‡Ğ½ĞµĞµ Ğ¾Ñ‚Ğ²ĞµÑ‚: Ğ±Ğ¾Ñ€ÑŒĞ±Ğ° Ñ 'Ğ½ĞµĞ´Ğ¾Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼' Ğ² Ğ˜Ğ˜", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ Ñ„ĞµĞ½Ğ¾Ğ¼ĞµĞ½ 'Ğ½ĞµĞ´Ğ¾Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ' Ğ² ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ñ‚Ğ¸Ğ¿Ğ° GPT-3, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°ÑÑ‚ÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#inference", "#training", "#optimization"], "emoji": "ğŸš€", "ru": {"title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ LLM Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğº ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒÑÑ‚ Ğ°
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#multimodal", "#dataset", "#leakage"], "emoji": "ğŸ©º", "ru": {"title": "MedXpertQA: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¾Ğ³Ğ¾ Ğ˜Ğ˜", "desc": "MedXpertQA - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ñ‹Ñ… Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ñ… Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ²
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#agents", "#agi", "#rl", "#reasoning", "#benchmark"], "emoji": "ğŸ§ ", "ru": {"title": "ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğº Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¸Ğ³Ñ€Ñƒ Little Alch
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#games", "#agents", "#multimodal", "#reasoning", "#benchmark"], "emoji": "ğŸ§ª", "ru": {"title": "ĞĞ°ÑƒÑ‡Ğ¸Ğ¼ Ğ˜Ğ˜ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ·Ğ¸ĞºÑƒ", "desc": "PhysBench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (VLM) Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¼Ğ¸Ñ€. ĞĞ½ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ĞµĞµ 10 
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#synthetic", "#training", "#data", "#dataset"], "emoji": "ğŸ—¨ï¸", "ru": {"title": "WILDCHAT-50M: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¿Ğ¾ÑÑ‚-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ WILDCHAT-50M - ĞºÑ€ÑƒĞ¿Ğ½ĞµĞ¹ÑˆĞ¸Ğ¹ Ğ¾Ğ±Ñ‰ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ñ‡Ğ°Ñ‚-Ğ±Ğ¾Ñ‚Ğ¾Ğ², Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#ethics", "#alignment", "#security", "#training"], "emoji": "ğŸ›¡ï¸", "ru": {"title": "Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞµ Ğ²ÑĞµĞ³Ğ¾: ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ²ÑƒÑ… ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: DeepSeek-R1 Ğ¸ Op
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#architecture", "#training", "#diffusion", "#inference", "#benchmark"], "emoji": "ğŸ–¼ï¸", "ru": {"title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ SANA-1.5, Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğ¹ Diffusion Transformer Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼
[01.02.2025 12:37] Using data from previous issue: {"categories": ["#agents", "#benchmark"], "emoji": "ğŸ¤–", "ru": {"title": "CowPilot: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑĞ¾Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ğ¸ Ğ˜Ğ˜ Ğ² Ğ²ĞµĞ±-Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸", "desc": "CowPilot - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¹ Ğ¸ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğ¹ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾ Ğ²ĞµĞ±-ÑĞ°Ğ¹Ñ‚Ğ°Ğ¼. ĞĞ½ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸, Ğ° Ğ¿Ğ¾Ğ»
[01.02.2025 12:37] Trying to get texts in Chinese.
[01.02.2025 12:37] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

As LLMs increasingly impact safety-critical applications, ensuring their safety using guardrails remains a key challenge. This paper proposes GuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to reason. Concretely, we first create the GuardReasonerTrain dataset, which consists of 127K samples with 460K detailed reasoning steps. Then, we introduce reasoning SFT to unlock the reasoning capability of guard models. In addition, we present hard sample DPO to further strengthen their reasoning ability. In this manner, GuardReasoner achieves better performance, explainability, and generalizability. Extensive experiments and analyses on 13 benchmarks of 3 guardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B surpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on average. We release the training data, code, and models with different scales (1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.
[01.02.2025 12:37] Mistral response. {"id": "2091dbc9f11440fe9b23151c854d7d68", "object": "chat.completion", "created": 1738413422, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5982\u4f55\u786e\u4fdd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u3002\u4f5c\u8005\u63d0\u51fa\u4e86GuardReasoner\uff0c\u4e00\u79cd\u901a\u8fc7\u5f15\u5bfc\u5b88\u62a4\u6a21\u578b\u5b66\u4e60\u63a8\u7406\u6765\u4fdd\u969cLLMs\u5b89\u5168\u7684\u65b0\u65b9\u6cd5\u3002\u4ed6\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b127K\u6837\u672c\u548c460K\u8be6\u7ec6\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86\u63a8\u7406SFT\u548c\u96be\u6837\u672cDPO\u6765\u589e\u5f3a\u5b88\u62a4\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGuardReasoner\u5728\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u66f4\u4f73\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 289, "total_tokens": 454, "completion_tokens": 165}}
[01.02.2025 12:37] Response: è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œä¸€ç§é€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMså®‰å…¨çš„æ–°æ–¹æ³•ã€‚ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥å¢å¼ºå®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´ä½³ã€‚
[01.02.2025 12:37] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œä¸€ç§é€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMså®‰å…¨çš„æ–°æ–¹æ³•ã€‚ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥å¢å¼ºå®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´ä½³ã€‚
[01.02.2025 12:37] Mistral response. {"id": "57492a3bf257496a84e2fabc6da6b864", "object": "chat.completion", "created": 1738413425, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5982\u4f55\u786e\u4fdd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u3002\nZh\u00e8 pi\u0101n w\u00e9nzh\u0101ng t\u01ceol\u00f9n le r\u00fah\u00e9 qu\u00e8b\u01ceo d\u00e0 y\u01d4y\u00e1n m\u00f3x\u00edng (LLMs) z\u00e0i \u0101nqu\u00e1n gu\u01cenji\u00e0n y\u00ecngy\u00f2ng zh\u014dng de \u0101nqu\u00e1nx\u00ecng.\n\n\u4f5c\u8005\u63d0\u51fa\u4e86GuardReasoner\uff0c\u4e00\u79cd\u901a\u8fc7\u5f15\u5bfc\u5b88\u62a4\u6a21\u578b\u5b66\u4e60\u63a8\u7406\u6765\u4fdd\u969cLLMs\u5b89\u5168\u7684\u65b0\u65b9\u6cd5\u3002\nZu\u00f2zh\u011b t\u00edch\u016b le GuardReasoner, y\u012bzh\u01d2ng t\u014dnggu\u00f2 y\u01d0nd\u01ceo sh\u01d2uh\u00f9 m\u00f3x\u00edng xu\u00e9x\u00ed tu\u012bl\u01d0 l\u00e1i b\u01ceozh\u00e0ng LLMs \u0101nqu\u00e1n de x\u012bn f\u0101ngf\u01ce.\n\n\u4ed6\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b127K\u6837\u672c\u548c460K\u8be6\u7ec6\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86\u63a8\u7406SFT\u548c\u96be\u6837\u672cDPO\u6765\u589e\u5f3a\u5b88\u62a4\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\nT\u0101men chu\u00e0ngji\u00e0n le y\u012bg\u00e8 b\u0101oh\u00e1n 127K y\u00e0ngb\u011bn h\u00e9 460K xi\u00e1ngx\u00ec tu\u012bl\u01d0 b\u00f9zh\u00f2u de sh\u00f9j\u00f9j\u00ed, b\u00ecng y\u01d0nr\u00f9 le tu\u012bl\u01d0 SFT h\u00e9 n\u00e1n y\u00e0ngb\u011bn DPO l\u00e1i z\u0113ngqi\u00e1ng sh\u01d2uh\u00f9 m\u00f3x\u00edng de tu\u012bl\u01d0 n\u00e9ngl\u00ec.\n\n\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGuardReasoner\u5728\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u66f4\u4f73\u3002\nSh\u00edy\u00e0n ji\u00e9gu\u01d2 xi\u01censh\u00ec, GuardReasoner z\u00e0i x\u00ecngn\u00e9ng, k\u011b ji\u011bsh\u00ecx\u00ecng h\u00e9 f\u00e0nhu\u00e0 n\u00e9ngl\u00ec f\u0101ngmi\u00e0n bi\u01ceoxi\u00e0n g\u00e8ng ji\u0101."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 180, "total_tokens": 684, "completion_tokens": 504}}
[01.02.2025 12:37] Response: è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚
ZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le rÃºhÃ© quÃ¨bÇo dÃ  yÇ”yÃ¡n mÃ³xÃ­ng (LLMs) zÃ i ÄnquÃ¡n guÇnjiÃ n yÃ¬ngyÃ²ng zhÅng de ÄnquÃ¡nxÃ¬ng.

ä½œè€…æå‡ºäº†GuardReasonerï¼Œä¸€ç§é€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMså®‰å…¨çš„æ–°æ–¹æ³•ã€‚
ZuÃ²zhÄ› tÃ­chÅ« le GuardReasoner, yÄ«zhÇ’ng tÅngguÃ² yÇndÇo shÇ’uhÃ¹ mÃ³xÃ­ng xuÃ©xÃ­ tuÄ«lÇ lÃ¡i bÇozhÃ ng LLMs ÄnquÃ¡n de xÄ«n fÄngfÇ.

ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥å¢å¼ºå®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
TÄmen chuÃ ngjiÃ n le yÄ«gÃ¨ bÄohÃ¡n 127K yÃ ngbÄ›n hÃ© 460K xiÃ¡ngxÃ¬ tuÄ«lÇ bÃ¹zhÃ²u de shÃ¹jÃ¹jÃ­, bÃ¬ng yÇnrÃ¹ le tuÄ«lÇ SFT hÃ© nÃ¡n yÃ ngbÄ›n DPO lÃ¡i zÄ“ngqiÃ¡ng shÇ’uhÃ¹ mÃ³xÃ­ng de tuÄ«lÇ nÃ©nglÃ¬.

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´ä½³ã€‚
ShÃ­yÃ n jiÃ©guÇ’ xiÇnshÃ¬, GuardReasoner zÃ i xÃ¬ngnÃ©ng, kÄ› jiÄ›shÃ¬xÃ¬ng hÃ© fÃ nhuÃ  nÃ©nglÃ¬ fÄngmiÃ n biÇoxiÃ n gÃ¨ng jiÄ.
[01.02.2025 12:37] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œä¸€ç§é€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMså®‰å…¨çš„æ–°æ–¹æ³•ã€‚ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥å¢å¼ºå®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´ä½³ã€‚
[01.02.2025 12:37] Mistral response. {"id": "217b05e929234d098bc3ba739088a94d", "object": "chat.completion", "created": 1738413435, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\n    {\"word\": \"\u8ba8\u8bba\", \"pinyin\": \"t\u01ceo l\u00f9n\", \"trans\": \"discuss\"},\n    {\"word\": \"\u786e\u4fdd\", \"pinyin\": \"qu\u00e8 b\u01ceo\", \"trans\": \"ensure\"},\n    {\"word\": \"\u5b89\u5168\", \"pinyin\": \"\u0101n qu\u00e1n\", \"trans\": \"safety\"},\n    {\"word\": \"\u5173\u952e\", \"pinyin\": \"gu\u0101n ji\u00e0n\", \"trans\": \"key\"},\n    {\"word\": \"\u5e94\u7528\", \"pinyin\": \"y\u00ecng y\u00f2ng\", \"trans\": \"application\"},\n    {\"word\": \"\u63d0\u51fa\", \"pinyin\": \"t\u00ed ch\u016b\", \"trans\": \"propose\"},\n    {\"word\": \"\u5b88\u62a4\", \"pinyin\": \"sh\u01d2u h\u00f9\", \"trans\": \"guard\"},\n    {\"word\": \"\u63a8\u7406\", \"pinyin\": \"tu\u012b l\u01d0\", \"trans\": \"reasoning\"},\n    {\"word\": \"\u4fdd\u969c\", \"pinyin\": \"b\u01ceo zh\u00e0ng\", \"trans\": \"guarantee\"},\n    {\"word\": \"\u65b0\u65b9\u6cd5\", \"pinyin\": \"x\u012bn f\u0101ng f\u01ce\", \"trans\": \"new method\"},\n    {\"word\": \"\u5305\u542b\", \"pinyin\": \"b\u0101o h\u00e1n\", \"trans\": \"contain\"},\n    {\"word\": \"\u6837\u672c\", \"pinyin\": \"y\u00e0ng b\u011bn\", \"trans\": \"sample\"},\n    {\"word\": \"\u8be6\u7ec6\", \"pinyin\": \"xi\u00e1ng x\u00ec\", \"trans\": \"detailed\"},\n    {\"word\": \"\u6b65\u9aa4\", \"pinyin\": \"b\u00f9 zh\u00f2u\", \"trans\": \"step\"},\n    {\"word\": \"\u5f15\u5165\", \"pinyin\": \"y\u01d0n r\u00f9\", \"trans\": \"introduce\"},\n    {\"word\": \"\u589e\u5f3a\", \"pinyin\": \"z\u0113ng qi\u00e1ng\", \"trans\": \"enhance\"},\n    {\"word\": \"\u80fd\u529b\", \"pinyin\": \"n\u00e9ng l\u00ec\", \"trans\": \"ability\"},\n    {\"word\": \"\u6027\u80fd\", \"pinyin\": \"x\u00ecng n\u00e9ng\", \"trans\": \"performance\"},\n    {\"word\": \"\u53ef\u89e3\u91ca\u6027\", \"pinyin\": \"k\u011b ji\u011b sh\u00ec x\u00ecng\", \"trans\": \"interpretability\"},\n    {\"word\": \"\u6cdb\u5316\", \"pinyin\": \"f\u00e0n hu\u00e0\", \"trans\": \"generalization\"},\n    {\"word\": \"\u8868\u73b0\", \"pinyin\": \"bi\u01ceo xi\u00e0n\", \"trans\": \"performance\"},\n    {\"word\": \"\u66f4\u4f73\", \"pinyin\": \"g\u00e8ng ji\u0101\", \"trans\": \"better\"}\n]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 212, "total_tokens": 853, "completion_tokens": 641}}
[01.02.2025 12:37] Response: [
    {"word": "è®¨è®º", "pinyin": "tÇo lÃ¹n", "trans": "discuss"},
    {"word": "ç¡®ä¿", "pinyin": "quÃ¨ bÇo", "trans": "ensure"},
    {"word": "å®‰å…¨", "pinyin": "Än quÃ¡n", "trans": "safety"},
    {"word": "å…³é”®", "pinyin": "guÄn jiÃ n", "trans": "key"},
    {"word": "åº”ç”¨", "pinyin": "yÃ¬ng yÃ²ng", "trans": "application"},
    {"word": "æå‡º", "pinyin": "tÃ­ chÅ«", "trans": "propose"},
    {"word": "å®ˆæŠ¤", "pinyin": "shÇ’u hÃ¹", "trans": "guard"},
    {"word": "æ¨ç†", "pinyin": "tuÄ« lÇ", "trans": "reasoning"},
    {"word": "ä¿éšœ", "pinyin": "bÇo zhÃ ng", "trans": "guarantee"},
    {"word": "æ–°æ–¹æ³•", "pinyin": "xÄ«n fÄng fÇ", "trans": "new method"},
    {"word": "åŒ…å«", "pinyin": "bÄo hÃ¡n", "trans": "contain"},
    {"word": "æ ·æœ¬", "pinyin": "yÃ ng bÄ›n", "trans": "sample"},
    {"word": "è¯¦ç»†", "pinyin": "xiÃ¡ng xÃ¬", "trans": "detailed"},
    {"word": "æ­¥éª¤", "pinyin": "bÃ¹ zhÃ²u", "trans": "step"},
    {"word": "å¼•å…¥", "pinyin": "yÇn rÃ¹", "trans": "introduce"},
    {"word": "å¢å¼º", "pinyin": "zÄ“ng qiÃ¡ng", "trans": "enhance"},
    {"word": "èƒ½åŠ›", "pinyin": "nÃ©ng lÃ¬", "trans": "ability"},
    {"word": "æ€§èƒ½", "pinyin": "xÃ¬ng nÃ©ng", "trans": "performance"},
    {"word": "å¯è§£é‡Šæ€§", "pinyin": "kÄ› jiÄ› shÃ¬ xÃ¬ng", "trans": "interpretability"},
    {"word": "æ³›åŒ–", "pinyin": "fÃ n huÃ ", "trans": "generalization"},
    {"word": "è¡¨ç°", "pinyin": "biÇo xiÃ n", "trans": "performance"},
    {"word": "æ›´ä½³", "pinyin": "gÃ¨ng jiÄ", "trans": "better"}
]
[01.02.2025 12:37] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œä¸€ç§é€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMså®‰å…¨çš„æ–°æ–¹æ³•ã€‚ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥å¢å¼ºå®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´ä½³ã€‚
[01.02.2025 12:37] Mistral response. {"id": "986fd62d56b242fab9a37c60b79efea8", "object": "chat.completion", "created": 1738413448, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "This article discusses how to ensure the safety of large language models (LLMs) in safety-critical applications. The authors propose GuardReasoner, a new method to safeguard LLMs by guiding the guardian model to learn reasoning. They created a dataset containing 127K samples and 460K detailed reasoning steps and introduced reasoning SFT and hard sample DPO to enhance the reasoning capabilities of the guardian model. Experimental results show that GuardReasoner performs better in terms of performance, explainability, and generalization."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 178, "total_tokens": 292, "completion_tokens": 114}}
[01.02.2025 12:37] Response: This article discusses how to ensure the safety of large language models (LLMs) in safety-critical applications. The authors propose GuardReasoner, a new method to safeguard LLMs by guiding the guardian model to learn reasoning. They created a dataset containing 127K samples and 460K detailed reasoning steps and introduced reasoning SFT and hard sample DPO to enhance the reasoning capabilities of the guardian model. Experimental results show that GuardReasoner performs better in terms of performance, explainability, and generalization.
[01.02.2025 12:37] Renaming data file.
[01.02.2025 12:37] Renaming previous data. hf_papers.json to ./d/2025-01-31.json
[01.02.2025 12:37] Saving new data file.
[01.02.2025 12:37] Generating page.
[01.02.2025 12:37] Renaming previous page.
[01.02.2025 12:37] Renaming previous data. index.html to ./d/2025-01-31.html
[01.02.2025 12:37] [Experimental] Generating Chinese page for reading.
[01.02.2025 12:37] Chinese vocab [{'word': 'è®¨è®º', 'pinyin': 'tÇo lÃ¹n', 'trans': 'discuss'}, {'word': 'ç¡®ä¿', 'pinyin': 'quÃ¨ bÇo', 'trans': 'ensure'}, {'word': 'å®‰å…¨', 'pinyin': 'Än quÃ¡n', 'trans': 'safety'}, {'word': 'å…³é”®', 'pinyin': 'guÄn jiÃ n', 'trans': 'key'}, {'word': 'åº”ç”¨', 'pinyin': 'yÃ¬ng yÃ²ng', 'trans': 'application'}, {'word': 'æå‡º', 'pinyin': 'tÃ­ chÅ«', 'trans': 'propose'}, {'word': 'å®ˆæŠ¤', 'pinyin': 'shÇ’u hÃ¹', 'trans': 'guard'}, {'word': 'æ¨ç†', 'pinyin': 'tuÄ« lÇ', 'trans': 'reasoning'}, {'word': 'ä¿éšœ', 'pinyin': 'bÇo zhÃ ng', 'trans': 'guarantee'}, {'word': 'æ–°æ–¹æ³•', 'pinyin': 'xÄ«n fÄng fÇ', 'trans': 'new method'}, {'word': 'åŒ…å«', 'pinyin': 'bÄo hÃ¡n', 'trans': 'contain'}, {'word': 'æ ·æœ¬', 'pinyin': 'yÃ ng bÄ›n', 'trans': 'sample'}, {'word': 'è¯¦ç»†', 'pinyin': 'xiÃ¡ng xÃ¬', 'trans': 'detailed'}, {'word': 'æ­¥éª¤', 'pinyin': 'bÃ¹ zhÃ²u', 'trans': 'step'}, {'word': 'å¼•å…¥', 'pinyin': 'yÇn rÃ¹', 'trans': 'introduce'}, {'word': 'å¢å¼º', 'pinyin': 'zÄ“ng qiÃ¡ng', 'trans': 'enhance'}, {'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©ng lÃ¬', 'trans': 'ability'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'}, {'word': 'å¯è§£é‡Šæ€§', 'pinyin': 'kÄ› jiÄ› shÃ¬ xÃ¬ng', 'trans': 'interpretability'}, {'word': 'æ³›åŒ–', 'pinyin': 'fÃ n huÃ ', 'trans': 'generalization'}, {'word': 'è¡¨ç°', 'pinyin': 'biÇo xiÃ n', 'trans': 'performance'}, {'word': 'æ›´ä½³', 'pinyin': 'gÃ¨ng jiÄ', 'trans': 'better'}]
[01.02.2025 12:37] Renaming previous Chinese page.
[01.02.2025 12:37] Renaming previous data. zh.html to ./d/2025-01-31_zh_reading_task.html
[01.02.2025 12:37] Writing Chinese reading task.
[01.02.2025 12:37] Writing result.
[01.02.2025 12:37] Renaming log file.
[01.02.2025 12:37] Renaming previous data. log.txt to ./logs/2025-02-01_last_log.txt
