[09.10.2024 06:17] Get feed.
[09.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04199
[09.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04717
[09.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02743
[09.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05193
[09.10.2024 06:17] ********************************************************************************
[09.10.2024 06:17] Abstract 0. Current long-context benchmarks primarily focus on retrieval-based tests, requiring Large Language Models (LLMs) to locate specific information within extensive input contexts, such as the needle-in-a-haystack (NIAH) benchmark. Long-context generation refers to the ability of a language model to gen...
[09.10.2024 06:17] ********************************************************************************
[09.10.2024 06:17] Abstract 1. Understanding and accurately following instructions is critical for large language models (LLMs) to be effective across diverse tasks. In this work, we rigorously examine the key factors that enable models to generalize to unseen instructions, providing insights to guide the collection of data for i...
[09.10.2024 06:17] ********************************************************************************
[09.10.2024 06:17] Abstract 2. Reinforcement learning from human feedback (RLHF) has demonstrated effectiveness in aligning large language models (LLMs) with human preferences. However, token-level RLHF suffers from the credit assignment problem over long sequences, where delayed rewards make it challenging for the model to disce...
[09.10.2024 06:17] ********************************************************************************
[09.10.2024 06:17] Abstract 3. With significant efforts in recent studies, LLM-as-a-Judge has become a cost-effective alternative to human evaluation for assessing the text generation quality in a wide range of tasks. However, there still remains a reliability gap between LLM-as-a-Judge and human evaluation. One important reason ...
[09.10.2024 06:17] Read previous papers.
[09.10.2024 06:17] Generating reviews via LLM API.
[09.10.2024 06:17] Using data from previous issue: {"desc": "LongGenBench - это новый синтетический бенчмарк для оценки способности языковых моделей к генерации длинных контекстов. В отличие от существующих тестов, фокусирующихся на поиске информации, LongGenBench требует от моделей создания целостных длинных ответов. Исследование показало, что все 
[09.10.2024 06:17] Using data from previous issue: {"desc": "Статья исследует факторы, позволяющие языковым моделям обобщать навыки на новые инструкции. Авторы проводят эксперименты, демонстрирующие, что такое обобщение возникает только при достаточном разнообразии обучающих данных по семантическим доменам. Исследование показывает, что диверсификаци
[09.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет новый подход к обучению с подкреплением на основе обратной связи от человека (RLHF) для больших языковых моделей. Предложенный метод MA-RLHF использует макродействия - последовательности токенов или высокоуровневые языковые конструкции - для улучшения процесса обучения.
[09.10.2024 06:17] Using data from previous issue: {"desc": "RevisEval - это новая парадигма оценки генерации текста, использующая адаптированные под ответ эталоны. Метод задействует возможности больших языковых моделей для пересмотра ответа и создания релевантного эталона. Эксперименты показывают, что RevisEval превосходит традиционные методы оценк
[09.10.2024 06:17] Renaming data file.
[09.10.2024 06:17] Renaming previous data. hf_papers.json to 2024-10-08_hf_papers.json
[09.10.2024 06:17] Saving new data file.
[09.10.2024 06:17] Generating page.
[09.10.2024 06:17] Renaming previous page.
[09.10.2024 06:17] Renaming previous data. index.html to 2024-10-08_hf_papers.html
[09.10.2024 06:17] Writing result.
[09.10.2024 06:17] Renaming log file.
[09.10.2024 06:17] Renaming previous data. log.txt to 2024-10-08_last_log.txt
