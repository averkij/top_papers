[09.10.2024 12:22] Get feed.
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04199
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04717
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05193
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.01912
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02705
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02743
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03290
[09.10.2024 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04422
[09.10.2024 12:22] Extract page data from URL. URL: https://huggingface.co/papers/2410.03399
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 0. Current long-context benchmarks primarily focus on retrieval-based tests, requiring Large Language Models (LLMs) to locate specific information within extensive input contexts, such as the needle-in-a-haystack (NIAH) benchmark. Long-context generation refers to the ability of a language model to gen...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 1. Understanding and accurately following instructions is critical for large language models (LLMs) to be effective across diverse tasks. In this work, we rigorously examine the key factors that enable models to generalize to unseen instructions, providing insights to guide the collection of data for i...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 2. With significant efforts in recent studies, LLM-as-a-Judge has become a cost-effective alternative to human evaluation for assessing the text generation quality in a wide range of tasks. However, there still remains a reliability gap between LLM-as-a-Judge and human evaluation. One important reason ...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 3. This work tackles the information loss bottleneck of vector-quantization (VQ) autoregressive image generation by introducing a novel model architecture called the 2-Dimensional Autoregression (DnD) Transformer. The DnD-Transformer predicts more codes for an image by introducing a new autoregression ...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 4. Autoregressive (AR) models have reformulated image generation as next-token prediction, demonstrating remarkable potential and emerging as strong competitors to diffusion models. However, control-to-image generation, akin to ControlNet, remains largely unexplored within AR models. Although a natural...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 5. Reinforcement learning from human feedback (RLHF) has demonstrated effectiveness in aligning large language models (LLMs) with human preferences. However, token-level RLHF suffers from the credit assignment problem over long sequences, where delayed rewards make it challenging for the model to disce...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 6. Video Large Language Models (Video-LLMs) have demonstrated remarkable capabilities in coarse-grained video understanding, however, they struggle with fine-grained temporal grounding. In this paper, we introduce Grounded-VideoLLM, a novel Video-LLM adept at perceiving and reasoning over specific vide...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 7. Long-context language models (LCLM), characterized by their extensive context window, is becoming increasingly popular. Meanwhile, many long-context benchmarks present challenging tasks that even the most advanced LCLMs struggle to complete. However, the underlying sources of various challenging lon...
[09.10.2024 12:22] ********************************************************************************
[09.10.2024 12:22] Abstract 8. Event sequences, characterized by irregular sampling intervals and a mix of categorical and numerical features, are common data structures in various real-world domains such as healthcare, finance, and user interaction logs. Despite advances in temporal data modeling techniques, there is no standard...
[09.10.2024 12:22] Read previous papers.
[09.10.2024 12:22] Generating reviews via LLM API.
[09.10.2024 12:22] Using data from previous issue: {"desc": "LongGenBench - это новый синтетический бенчмарк для оценки способности языковых моделей к генерации длинных контекстов. В отличие от существующих тестов, фокусирующихся на поиске информации, LongGenBench требует от моделей создания целостных длинных ответов. Исследование показало, что все 
[09.10.2024 12:22] Using data from previous issue: {"desc": "Статья исследует факторы, позволяющие языковым моделям обобщать навыки на новые инструкции. Авторы проводят эксперименты, демонстрирующие, что такое обобщение возникает только при достаточном разнообразии обучающих данных по семантическим доменам. Исследование показывает, что диверсификаци
[09.10.2024 12:22] Using data from previous issue: {"desc": "RevisEval - это новая парадигма оценки генерации текста, использующая адаптированные под ответ эталоны. Метод задействует возможности больших языковых моделей для пересмотра ответа и создания релевантного эталона. Эксперименты показывают, что RevisEval превосходит традиционные методы оценк
[09.10.2024 12:22] Using data from previous issue: {"desc": "Статья представляет новую архитектуру модели под названием 2-Dimensional Autoregression (DnD) Transformer для генерации изображений. DnD-Transformer решает проблему потери информации при векторном квантовании, вводя новое направление авторегрессии - глубину модели. По сравнению с традицион
[09.10.2024 12:22] Using data from previous issue: {"desc": "ControlAR - это новый эффективный метод для интеграции пространственного контроля в авторегрессионные модели генерации изображений. Он использует легковесный энкодер для преобразования пространственных входных данных в контрольные токены. ControlAR применяет условное декодирование для гене
[09.10.2024 12:22] Using data from previous issue: {"desc": "Статья представляет новый подход к обучению с подкреплением на основе обратной связи от человека (RLHF) для больших языковых моделей. Предложенный метод MA-RLHF использует макродействия - последовательности токенов или высокоуровневые языковые конструкции - для улучшения процесса обучения.
[09.10.2024 12:22] Using data from previous issue: {"desc": "Grounded-VideoLLM - это новая модель Video-LLM, способная к детальному пониманию видео и временной локализации. Модель использует дополнительный временной поток для кодирования связей между кадрами и дискретные временные токены для представления временных меток. Обучение проводится поэтапн
[09.10.2024 12:22] Using data from previous issue: {"desc": "Исследование посвящено языковым моделям с длинным контекстом (LCLM) и их трудностям в решении сложных задач. Авторы выявили две основные проблемы: многократное сопоставление при извлечении информации и логическое извлечение данных. Эти задачи оказываются гипермногоступенчатыми, что превыша
[09.10.2024 12:22] Querying the API.
[09.10.2024 12:23] Got response. {
  "desc": "Статья представляет EBES - инструмент для стандартизированного бенчмаркинга моделей, работающих с последовательностями событий. EBES фокусируется на задачах регрессии и классификации с целевыми переменными на уровне последовательности. Инструмент включает синтетический датасет и предобработанные реальные данные, в том числе крупнейший публично доступный банковский датасет. Авторы анализируют важность моделирования временных и последовательных компонентов, а также исследуют робастность и масштабируемость моделей.",

  "tags": [
    "#EventSequenceModeling",
    "#BenchmarkingTool",
    "#TemporalDataAnalysis"
  ],

  "emoji": "📊",

  "title": "EBES: Стандартизация оценки моделей для последовательностей событий"
}
[09.10.2024 12:23] Renaming data file.
[09.10.2024 12:23] Renaming previous data. hf_papers.json to 2024-10-08_hf_papers.json
[09.10.2024 12:23] Saving new data file.
[09.10.2024 12:23] Generating page.
[09.10.2024 12:23] Renaming previous page.
[09.10.2024 12:23] Renaming previous data. index.html to 2024-10-08_hf_papers.html
[09.10.2024 12:23] Writing result.
[09.10.2024 12:23] Renaming log file.
[09.10.2024 12:23] Renaming previous data. log.txt to 2024-10-08_last_log.txt
