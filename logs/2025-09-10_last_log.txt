[10.09.2025 17:10] Read previous papers.
[10.09.2025 17:10] Generating top page (month).
[10.09.2025 17:10] Writing top page (month).
[10.09.2025 18:16] Read previous papers.
[10.09.2025 18:16] Get feed.
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07980
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07979
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07969
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07295
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06818
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06951
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06923
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06830
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07414
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03646
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07301
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07968
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06942
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01624
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07558
[10.09.2025 18:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07253
[10.09.2025 18:16] Extract page data from URL. URL: https://huggingface.co/papers/2509.06938
[10.09.2025 18:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[10.09.2025 18:16] No deleted papers detected.
[10.09.2025 18:16] Downloading and parsing papers (pdf, html). Total: 17.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07980.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07980.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07980.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07979.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07979.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07979.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07969.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07969.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07969.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07295.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07295.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07295.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.06818.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.06818.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.06818.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.06951.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.06951.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.06951.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.06923.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.06923.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.06923.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.06830.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.06830.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.06830.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07414.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07414.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07414.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.03646.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.03646.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.03646.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07301.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07301.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07301.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07968.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07968.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07968.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.06942.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.06942.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.06942.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.01624.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.01624.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.01624.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07558.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07558.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07558.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.07253.
[10.09.2025 18:16] Extra JSON file exists (./assets/json/2509.07253.json), skip PDF parsing.
[10.09.2025 18:16] Paper image links file exists (./assets/img_data/2509.07253.json), skip HTML parsing.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Downloading and parsing paper https://huggingface.co/papers/2509.06938.
[10.09.2025 18:16] Downloading paper 2509.06938 from http://arxiv.org/pdf/2509.06938v1...
[10.09.2025 18:16] Extracting affiliations from text.
[10.09.2025 18:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 ] . [ 1 8 3 9 6 0 . 9 0 5 2 : r From Noise to Narrative: Tracing the Origins of Hallucinations in Transformers Praneet Suresh1 Jack Stanley1 Sonia Joseph1,2 Luca Scimeca1 Danilo Bzdok1 1Mila - Quebec AI Institute 2Meta AI "
[10.09.2025 18:16] Response: ```python
["Mila - Quebec AI Institute", "Meta AI"]
```
[10.09.2025 18:16] Deleting PDF ./assets/pdf/2509.06938.pdf.
[10.09.2025 18:16] Success.
[10.09.2025 18:16] Enriching papers with extra data.
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 0. Parallel-R1, a reinforcement learning framework, enhances large language models' reasoning capabilities by enabling parallel thinking through a progressive curriculum, leading to significant performance improvements on math benchmarks.  					AI-generated summary 				 Parallel thinking has emerged as...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 1. VIRAL, a regularization strategy, aligns MLLMs' visual representations with pre-trained VFMs, enhancing performance on vision-centric tasks.  					AI-generated summary 				 Multimodal large language models (MLLMs) trained with visual instruction tuning have achieved strong performance across diverse...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 2. Mini-o3, a system for deep, multi-turn reasoning in visual search tasks, uses an iterative data collection pipeline and over-turn masking strategy to achieve state-of-the-art performance with rich reasoning patterns.  					AI-generated summary 				 Recent advances in large multimodal models have lev...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 3. Reconstruction Alignment (RecA) is a post-training method that enhances multimodal models by using visual embeddings as dense prompts, improving image generation and editing fidelity.  					AI-generated summary 				 Unified multimodal models (UMMs) unify visual understanding and generation within a ...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 4. UMO, a Unified Multi-identity Optimization framework, enhances identity consistency and reduces confusion in multi-reference image customization using reinforcement learning on diffusion models.  					AI-generated summary 				 Recent advancements in image customization exhibit a wide range of applic...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 5. F1, a pretrained VLA framework with foresight generation, improves task success and generalization in dynamic environments through a Mixture-of-Transformer architecture and next-scale prediction.  					AI-generated summary 				 Executing language-conditioned tasks in dynamic visual environments rema...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 6. SEELE, a novel RLVR framework, dynamically adjusts problem difficulty using adaptive hint lengths to enhance exploration efficiency and improve performance in math reasoning tasks.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success i...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 7. Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 8. Language Self-Play (LSP) enhances large language models' performance on instruction-following tasks through self-play, surpassing data-driven methods.  					AI-generated summary 				 Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training d...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 9. Reinforcement Learning enhances LLM reasoning through a two-phase process involving procedural correctness and strategic planning, with HICRA algorithm focusing on high-impact planning tokens to improve performance.  					AI-generated summary 				 Reinforcement Learning (RL) has proven highly effect...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 10. CASTLE, an attention mechanism that updates keys with future context while maintaining autoregressive properties, outperforms standard causal attention in language modeling.  					AI-generated summary 				 In standard causal attention, each token's query, key, and value (QKV) are static and encode o...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 11. SimpleQA Verified is a refined benchmark for evaluating the factuality of Large Language Models, addressing issues in previous benchmarks and providing a more reliable evaluation tool.  					AI-generated summary 				 We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large Langu...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 12. Direct-Align and Semantic Relative Preference Optimization improve diffusion models' alignment with human preferences by reducing computational costs and minimizing offline reward adaptation.  					AI-generated summary 				 Recent studies have demonstrated the effectiveness of directly aligning diff...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 13. Q-Sched, a novel post-training quantization method for diffusion models, reduces model size by 4x while maintaining full-precision accuracy and improving image quality metrics.  					AI-generated summary 				 Text-to-image diffusion models are computationally intensive, often requiring dozens of for...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 14. ΔL Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the charact...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 15. A benchmark of complex retrieval tasks reveals that even state-of-the-art models struggle with high-quality retrieval, and LLM-based query expansion does not consistently improve performance.  					AI-generated summary 				 Large language models (LLMs) are incredible and versatile tools for text-bas...
[10.09.2025 18:16] ********************************************************************************
[10.09.2025 18:16] Abstract 16. Transformer models tend to activate input-insensitive semantic features under uncertainty, leading to hallucinations that can be predicted from their internal activations.  					AI-generated summary 				 As generative AI systems become competent and democratized in science, business, and government,...
[10.09.2025 18:16] Read previous papers.
[10.09.2025 18:16] Generating reviews via LLM API.
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#math", "#open_source", "#rl", "#optimization", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Параллельное мышление для ИИ: новый уровень рассуждений", "desc": "Parallel-R1 - это фреймворк обучения с подкреплением, который улучшает способности больших языковых моделей к
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#alignment", "#training", "#multimodal", "#reasoning"], "emoji": "🔍", "ru": {"title": "Усиление визуального понимания языковых моделей через выравнивание представлений", "desc": "Статья представляет VIRAL - стратегию регуляризации для мультимодальных больших язы
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#data", "#open_source", "#cv", "#rl", "#training", "#multimodal", "#dataset", "#reasoning"], "emoji": "🔍", "ru": {"title": "Глубокое мышление в визуальном поиске: Mini-o3 раздвигает границы рассуждений", "desc": "Система Mini-o3 представляет собой подход к глубокому многоступенчатом
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#alignment", "#benchmark", "#open_source", "#multimodal", "#optimization", "#diffusion", "#training"], "emoji": "🔄", "ru": {"title": "RecA: Эффективное выравнивание мультимодальных моделей для улучшения генерации изображений", "desc": "Reconstruction Alignment (RecA) - это метод пос
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#dataset", "#rl", "#open_source", "#optimization", "#diffusion", "#training"], "emoji": "🎭", "ru": {"title": "UMO: Улучшение идентичности в кастомизации изображений", "desc": "UMO - это новая система оптимизации для улучшения согласованности идентичности и уменьшения путаницы в каст
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#agi", "#cv", "#reasoning", "#benchmark", "#agents", "#transfer_learning", "#training"], "emoji": "🔮", "ru": {"title": "Визуальное предвидение для улучшения принятия решений ИИ", "desc": "F1 - это предварительно обученная система для выполнения задач в динамических визуальных средах
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#math", "#rl", "#optimization", "#training", "#rlhf", "#reasoning"], "emoji": "🧠", "ru": {"title": "Динамическая настройка сложности для эффективного обучения ИИ математическому мышлению", "desc": "SEELE - это новая система обучения с подкреплением с проверяемыми наградами (RLVR), к
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#dataset", "#healthcare", "#benchmark", "#data", "#low_resource", "#open_source"], "emoji": "🧠", "ru": {"title": "Curia: универсальная модель для радиологической интерпретации", "desc": "Модель Curia - это фундаментальная модель машинного обучения, обученная на обширном наборе данны
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#games", "#rl", "#optimization", "#training", "#rlhf"], "emoji": "🎮", "ru": {"title": "Самоигра языковых моделей: путь к улучшению без новых данных", "desc": "Статья представляет новый метод улучшения больших языковых моделей (LLM) под названием Language Self-Play (LSP). LSP использ
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#rlhf", "#training", "#optimization", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "Иерархическое обучение с подкреплением для улучшения рассуждений ИИ", "desc": "Статья описывает двухфазный процесс улучшения рассуждений больших языковых моделей с помощью обучения с подкрепле
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#architecture", "#optimization", "#training"], "emoji": "🏰", "ru": {"title": "CASTLE: Взгляд в будущее для улучшения языкового моделирования", "desc": "Статья представляет новый механизм внимания под названием CASTLE для языкового моделирования. В отли
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#dataset", "#hallucinations", "#interpretability", "#benchmark"], "emoji": "🎯", "ru": {"title": "Точный бенчмарк для оценки фактической достоверности языковых моделей", "desc": "SimpleQA Verified - это усовершенствованный бенчмарк для оценки фактической точности больших языковых мод
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#diffusion", "#alignment", "#rlhf", "#training", "#optimization"], "emoji": "🖼️", "ru": {"title": "Эффективное улучшение диффузионных моделей с учетом человеческих предпочтений", "desc": "В статье представлены два метода улучшения диффузионных моделей: Direct-Align и Semantic Relati
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#training", "#diffusion", "#inference", "#optimization"], "emoji": "🖼️", "ru": {"title": "Q-Sched: Эффективная квантизация диффузионных моделей без потери качества", "desc": "Q-Sched - это новый метод пост-тренировочной квантизации для диффузионных моделей. Он уменьшает размер модел
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#reasoning"], "emoji": "📊", "ru": {"title": "Стабилизация обучения языковых моделей с помощью Delta L Normalization", "desc": "Статья представляет метод Delta L Normalization для обучения с подкреплением с проверяемыми наградами (RLVR). Этот подх
[10.09.2025 18:16] Using data from previous issue: {"categories": ["#survey", "#rag", "#benchmark", "#reasoning"], "emoji": "🔍", "ru": {"title": "Сложный поиск: современные модели не справляются", "desc": "Исследование показало, что современные модели поиска испытывают трудности с выполнением сложных задач извлечения информации. Даже самые продвинут
[10.09.2025 18:16] Querying the API.
[10.09.2025 18:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Transformer models tend to activate input-insensitive semantic features under uncertainty, leading to hallucinations that can be predicted from their internal activations.  					AI-generated summary 				 As generative AI systems become competent and democratized in science, business, and government, deeper insight into their failure modes now poses an acute need. The occasional volatility in their behavior, such as the propensity of transformer models to hallucinate, impedes trust and adoption of emerging AI solutions in high-stakes areas. In the present work, we establish how and when hallucinations arise in pre-trained transformer models through concept representations captured by sparse autoencoders, under scenarios with experimentally controlled uncertainty in the input space. Our systematic experiments reveal that the number of semantic concepts used by the transformer model grows as the input information becomes increasingly unstructured. In the face of growing uncertainty in the input space, the transformer model becomes prone to activate coherent yet input-insensitive semantic features, leading to hallucinated output. At its extreme, for pure-noise inputs, we identify a wide variety of robustly triggered and meaningful concepts in the intermediate activations of pre-trained transformer models, whose functional integrity we confirm through targeted steering. We also show that hallucinations in the output of a transformer model can be reliably predicted from the concept patterns embedded in transformer layer activations. This collection of insights on transformer internal processing mechanics has immediate consequences for aligning AI models with human values, AI safety, opening the attack surface for potential adversarial attacks, and providing a basis for automatic quantification of a model's hallucination risk.
[10.09.2025 18:16] Response: {
  "desc": "Исследование показывает, что трансформерные модели активируют семантические признаки, нечувствительные к входным данным, в условиях неопределенности, что приводит к галлюцинациям. Эти галлюцинации можно предсказать по внутренним активациям модели. Авторы обнаружили, что количество семантических концепций, используемых моделью, растет по мере увеличения неструктурированности входных данных. Результаты исследования имеют важное значение для безопасности ИИ, выявления потенциальных уязвимостей и количественной оценки риска галлюцинаций модели.",

  "emoji": "🧠",

  "title": "Раскрытие механизмов галлюцинаций в трансформерных моделях"
}
[10.09.2025 18:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Transformer models tend to activate input-insensitive semantic features under uncertainty, leading to hallucinations that can be predicted from their internal activations.  					AI-generated summary 				 As generative AI systems become competent and democratized in science, business, and government, deeper insight into their failure modes now poses an acute need. The occasional volatility in their behavior, such as the propensity of transformer models to hallucinate, impedes trust and adoption of emerging AI solutions in high-stakes areas. In the present work, we establish how and when hallucinations arise in pre-trained transformer models through concept representations captured by sparse autoencoders, under scenarios with experimentally controlled uncertainty in the input space. Our systematic experiments reveal that the number of semantic concepts used by the transformer model grows as the input information becomes increasingly unstructured. In the face of growing uncertainty in the input space, the transformer model becomes prone to activate coherent yet input-insensitive semantic features, leading to hallucinated output. At its extreme, for pure-noise inputs, we identify a wide variety of robustly triggered and meaningful concepts in the intermediate activations of pre-trained transformer models, whose functional integrity we confirm through targeted steering. We also show that hallucinations in the output of a transformer model can be reliably predicted from the concept patterns embedded in transformer layer activations. This collection of insights on transformer internal processing mechanics has immediate consequences for aligning AI models with human values, AI safety, opening the attack surface for potential adversarial attacks, and providing a basis for automatic quantification of a model's hallucination risk."

[10.09.2025 18:16] Response: ```python
['ARCHITECTURE', 'TRAINING', 'RLHF']
```
[10.09.2025 18:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Transformer models tend to activate input-insensitive semantic features under uncertainty, leading to hallucinations that can be predicted from their internal activations.  					AI-generated summary 				 As generative AI systems become competent and democratized in science, business, and government, deeper insight into their failure modes now poses an acute need. The occasional volatility in their behavior, such as the propensity of transformer models to hallucinate, impedes trust and adoption of emerging AI solutions in high-stakes areas. In the present work, we establish how and when hallucinations arise in pre-trained transformer models through concept representations captured by sparse autoencoders, under scenarios with experimentally controlled uncertainty in the input space. Our systematic experiments reveal that the number of semantic concepts used by the transformer model grows as the input information becomes increasingly unstructured. In the face of growing uncertainty in the input space, the transformer model becomes prone to activate coherent yet input-insensitive semantic features, leading to hallucinated output. At its extreme, for pure-noise inputs, we identify a wide variety of robustly triggered and meaningful concepts in the intermediate activations of pre-trained transformer models, whose functional integrity we confirm through targeted steering. We also show that hallucinations in the output of a transformer model can be reliably predicted from the concept patterns embedded in transformer layer activations. This collection of insights on transformer internal processing mechanics has immediate consequences for aligning AI models with human values, AI safety, opening the attack surface for potential adversarial attacks, and providing a basis for automatic quantification of a model's hallucination risk."

[10.09.2025 18:16] Response: ```python
['HALLUCINATIONS', 'ALIGNMENT', 'SECURITY']
```
[10.09.2025 18:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how transformer models generate hallucinations, which are incorrect outputs, particularly under uncertain input conditions. It shows that as the input becomes less structured, the model activates more semantic concepts that are not directly related to the input, leading to these hallucinations. The authors use sparse autoencoders to analyze the internal activations of the models and find that they can predict hallucinations based on these activations. The findings highlight the importance of understanding transformer behavior to improve AI safety and align models with human values.","title":"Understanding Hallucinations in Transformer Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates how transformer models generate hallucinations, which are incorrect outputs, particularly under uncertain input conditions. It shows that as the input becomes less structured, the model activates more semantic concepts that are not directly related to the input, leading to these hallucinations. The authors use sparse autoencoders to analyze the internal activations of the models and find that they can predict hallucinations based on these activations. The findings highlight the importance of understanding transformer behavior to improve AI safety and align models with human values.', title='Understanding Hallucinations in Transformer Models'))
[10.09.2025 18:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究探讨了变换器模型在输入不确定性下如何产生幻觉现象。我们发现，当输入信息变得更加无结构时，模型激活的语义概念数量会增加。特别是在纯噪声输入的情况下，模型会激活一些与输入无关的语义特征，导致输出幻觉。通过分析模型内部激活，我们能够预测这些幻觉的出现，从而为提高AI模型的安全性和可靠性提供了重要依据。","title":"揭示变换器模型幻觉的秘密"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究探讨了变换器模型在输入不确定性下如何产生幻觉现象。我们发现，当输入信息变得更加无结构时，模型激活的语义概念数量会增加。特别是在纯噪声输入的情况下，模型会激活一些与输入无关的语义特征，导致输出幻觉。通过分析模型内部激活，我们能够预测这些幻觉的出现，从而为提高AI模型的安全性和可靠性提供了重要依据。', title='揭示变换器模型幻觉的秘密'))
[10.09.2025 18:16] Renaming data file.
[10.09.2025 18:16] Renaming previous data. hf_papers.json to ./d/2025-09-10.json
[10.09.2025 18:16] Saving new data file.
[10.09.2025 18:16] Generating page.
[10.09.2025 18:16] Renaming previous page.
[10.09.2025 18:16] Renaming previous data. index.html to ./d/2025-09-10.html
[10.09.2025 18:16] Writing result.
[10.09.2025 18:16] Renaming log file.
[10.09.2025 18:16] Renaming previous data. log.txt to ./logs/2025-09-10_last_log.txt
