[10.09.2025 07:11] Read previous papers.
[10.09.2025 07:11] Generating top page (month).
[10.09.2025 07:11] Writing top page (month).
[10.09.2025 08:15] Read previous papers.
[10.09.2025 08:15] Get feed.
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07980
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07969
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07979
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07295
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06818
[10.09.2025 08:15] Extract page data from URL. URL: https://huggingface.co/papers/2509.06830
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06923
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06951
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07414
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07301
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07968
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01624
[10.09.2025 08:15] Extract page data from URL. URL: https://huggingface.co/papers/2509.07558
[10.09.2025 08:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[10.09.2025 08:15] No deleted papers detected.
[10.09.2025 08:15] Downloading and parsing papers (pdf, html). Total: 13.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07980.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07980.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07980.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07969.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07969.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07969.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07979.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07979.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07979.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07295.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07295.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07295.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.06818.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.06818.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.06818.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.06830.
[10.09.2025 08:15] Downloading paper 2509.06830 from http://arxiv.org/pdf/2509.06830v1...
[10.09.2025 08:17] Extracting affiliations from text.
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Curia: Multi-Modal Foundation Model for Radiology Corentin Dancette1*, Julien Khlaut1,2,3, Antoine Saporta1, Helene Philippe1,3,6, Elodie Ferreres1, Baptiste Callard1, Theo Danielou1, Leo Alberge1, Leo Machado1,6, Daniel Tordjman1, Julie Dupuis1, Korentin Le Floch1,2,3,4, Jean Du Terrail7, Mariam Moshiri8, Laurent Dercle9, Tom Boeken2,3,4, Jules Gregory6, Maxime Ronot6, Francois Legou10, Pascal Roux10, Marc Sapoval2,3,5, Pierre Manceron1, Paul Herent1 1*Raidium, 27 rue du faubourg Saint-Jacques, Paris, 75014, France. 2Department of Vascular and Oncological Interventional Radiology, HË†opital Europeen Georges Pompidou, AP-HP, Paris, France. 3Faculte de Sante, Universite Paris-Cite, Paris, France. 4HEKA, INRIA, Paris, France. 5PARCC 970, INSERM, Paris, France. 6Department of Radiology, FHU MOSAIC, Beaujon Hospital, APHP.Nord, Clichy, France. 7.omics, Paris, France. 8Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA. 9Department of Radiology, Columbia University Irving Medical Center, New York, NY, 10032, USA. 10Centre Cardiologique du Nord, Saint-Denis, 93200, France. *Corresponding author(s). E-mail(s): corentin.dancette@raidium.eu; These authors contributed equally to this work. Abstract AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, foundation model trained on the entire cross-sectional imaging output of major hospital over several yearswhich to our knowledge is the largest such corpus of real-world dataencompassing 150,000 exams (130 TB). On newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions l"
[10.09.2025 08:17] Response: ```python
[
    "Raidium, 27 rue du faubourg Saint-Jacques, Paris, 75014, France",
    "Department of Vascular and Oncological Interventional Radiology, HË†opital Europeen Georges Pompidou, AP-HP, Paris, France",
    "Faculte de Sante, Universite Paris-Cite, Paris, France",
    "HEKA, INRIA, Paris, France",
    "PARCC 970, INSERM, Paris, France",
    "Department of Radiology, FHU MOSAIC, Beaujon Hospital, APHP.Nord, Clichy, France",
    ".omics, Paris, France",
    "Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA",
    "Department of Radiology, Columbia University Irving Medical Center, New York, NY, 10032, USA",
    "Centre Cardiologique du Nord, Saint-Denis, 93200, France"
]
```
[10.09.2025 08:17] Deleting PDF ./assets/pdf/2509.06830.pdf.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.06923.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.06923.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.06923.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.06951.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.06951.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.06951.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07414.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.07414.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.07414.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07301.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.07301.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.07301.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07968.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.07968.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.07968.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.01624.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.01624.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.01624.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07558.
[10.09.2025 08:17] Downloading paper 2509.07558 from http://arxiv.org/pdf/2509.07558v1...
[10.09.2025 08:17] Extracting affiliations from text.
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 ] . [ 1 8 5 5 7 0 . 9 0 5 2 : r Preprint Normalization: RETHINK LOSS AGGREGATION IN RLVR Zhiyuan He1, Xufang Luo1, Yike Zhang2, Yuqing Yang1, Lili Qiu1 1Microsoft Research, 2Tsinghua University zhiyuhe@microsoft.com, xufluo@microsoft.com "
[10.09.2025 08:17] Response: ```python
["Microsoft Research", "Tsinghua University"]
```
[10.09.2025 08:17] Deleting PDF ./assets/pdf/2509.07558.pdf.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Enriching papers with extra data.
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 0. Parallel-R1, a reinforcement learning framework, enhances large language models' reasoning capabilities by enabling parallel thinking through a progressive curriculum, leading to significant performance improvements on math benchmarks.  					AI-generated summary 				 Parallel thinking has emerged as...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 1. Mini-o3, a system for deep, multi-turn reasoning in visual search tasks, uses an iterative data collection pipeline and over-turn masking strategy to achieve state-of-the-art performance with rich reasoning patterns.  					AI-generated summary 				 Recent advances in large multimodal models have lev...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 2. VIRAL, a regularization strategy, aligns MLLMs' visual representations with pre-trained VFMs, enhancing performance on vision-centric tasks.  					AI-generated summary 				 Multimodal large language models (MLLMs) trained with visual instruction tuning have achieved strong performance across diverse...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 3. Reconstruction Alignment (RecA) is a post-training method that enhances multimodal models by using visual embeddings as dense prompts, improving image generation and editing fidelity.  					AI-generated summary 				 Unified multimodal models (UMMs) unify visual understanding and generation within a ...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 4. UMO, a Unified Multi-identity Optimization framework, enhances identity consistency and reduces confusion in multi-reference image customization using reinforcement learning on diffusion models.  					AI-generated summary 				 Recent advancements in image customization exhibit a wide range of applic...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 5. Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 6. SEELE, a novel RLVR framework, dynamically adjusts problem difficulty using adaptive hint lengths to enhance exploration efficiency and improve performance in math reasoning tasks.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success i...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 7. F1, a pretrained VLA framework with foresight generation, improves task success and generalization in dynamic environments through a Mixture-of-Transformer architecture and next-scale prediction.  					AI-generated summary 				 Executing language-conditioned tasks in dynamic visual environments rema...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 8. Language Self-Play (LSP) enhances large language models' performance on instruction-following tasks through self-play, surpassing data-driven methods.  					AI-generated summary 				 Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training d...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 9. CASTLE, an attention mechanism that updates keys with future context while maintaining autoregressive properties, outperforms standard causal attention in language modeling.  					AI-generated summary 				 In standard causal attention, each token's query, key, and value (QKV) are static and encode o...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 10. SimpleQA Verified is a refined benchmark for evaluating the factuality of Large Language Models, addressing issues in previous benchmarks and providing a more reliable evaluation tool.  					AI-generated summary 				 We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large Langu...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 11. Q-Sched, a novel post-training quantization method for diffusion models, reduces model size by 4x while maintaining full-precision accuracy and improving image quality metrics.  					AI-generated summary 				 Text-to-image diffusion models are computationally intensive, often requiring dozens of for...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 12. Î”L Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the charact...
[10.09.2025 08:17] Read previous papers.
[10.09.2025 08:17] Generating reviews via LLM API.
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#math", "#open_source", "#rl", "#optimization", "#training", "#reasoning"], "emoji": "ğŸ§ ", "ru": {"title": "ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ˜Ğ˜: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹", "desc": "Parallel-R1 - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#data", "#open_source", "#cv", "#rl", "#training", "#multimodal", "#dataset", "#reasoning"], "emoji": "ğŸ”", "ru": {"title": "Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ² Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞµ: Mini-o3 Ñ€Ğ°Ğ·Ğ´Ğ²Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹", "desc": "Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Mini-o3 Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ¼Ñƒ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½Ñ‡Ğ°Ñ‚Ğ¾Ğ¼
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#alignment", "#training", "#multimodal", "#reasoning"], "emoji": "ğŸ”", "ru": {"title": "Ğ£ÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ VIRAL - ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#alignment", "#benchmark", "#open_source", "#multimodal", "#optimization", "#diffusion", "#training"], "emoji": "ğŸ”„", "ru": {"title": "RecA: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹", "desc": "Reconstruction Alignment (RecA) - ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ñ
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#dataset", "#rl", "#open_source", "#optimization", "#diffusion", "#training"], "emoji": "ğŸ­", "ru": {"title": "UMO: Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹", "desc": "UMO - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ñ Ğ¿ÑƒÑ‚Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ² ĞºĞ°ÑÑ‚
[10.09.2025 08:17] Querying the API.
[10.09.2025 08:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, a foundation model trained on the entire cross-sectional imaging output of a major hospital over several years, which to our knowledge is the largest such corpus of real-world data-encompassing 150,000 exams (130 TB). On a newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions like brain hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging. Curia meets or surpasses the performance of radiologists and recent foundation models, and exhibits clinically significant emergent properties in cross-modality, and low-data regimes. To accelerate progress, we release our base model's weights at https://huggingface.co/raidium/curia.
[10.09.2025 08:17] Response: {
  "desc": "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Curia - ÑÑ‚Ğ¾ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ¾Ğ±ÑˆĞ¸Ñ€Ğ½Ğ¾Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¾Ğ¹ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. ĞĞ½Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¾Ğ², Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ÑÑ…Ğ¾Ğ´Ğ¾Ğ² Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¾Ğ¿ÑƒÑ…Ğ¾Ğ»ĞµĞ¹. Curia Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑĞ¼ĞµÑ€Ğ´Ğ¶ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° Ğ² ĞºÑ€Ğ¾ÑÑ-Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¾Ñ€ĞµÑÑƒÑ€ÑĞ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ½Ğ° 150 000 Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ (130 Ğ¢Ğ‘ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…) Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ĞºĞ°Ğº Ñ€Ğ°Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¾Ğ², Ñ‚Ğ°Ğº Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸.",
  "emoji": "ğŸ§ ",
  "title": "Curia: ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ğ¸"
}
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, a foundation model trained on the entire cross-sectional imaging output of a major hospital over several years, which to our knowledge is the largest such corpus of real-world data-encompassing 150,000 exams (130 TB). On a newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions like brain hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging. Curia meets or surpasses the performance of radiologists and recent foundation models, and exhibits clinically significant emergent properties in cross-modality, and low-data regimes. To accelerate progress, we release our base model's weights at https://huggingface.co/raidium/curia."

[10.09.2025 08:17] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'HEALTHCARE']
```
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, a foundation model trained on the entire cross-sectional imaging output of a major hospital over several years, which to our knowledge is the largest such corpus of real-world data-encompassing 150,000 exams (130 TB). On a newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions like brain hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging. Curia meets or surpasses the performance of radiologists and recent foundation models, and exhibits clinically significant emergent properties in cross-modality, and low-data regimes. To accelerate progress, we release our base model's weights at https://huggingface.co/raidium/curia."

[10.09.2025 08:17] Response: ```python
['LOW_RESOURCE', 'OPEN_SOURCE']
```
[10.09.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Curia is a foundation model designed for radiology, trained on a vast dataset of cross-sectional imaging from a major hospital. It excels in various radiological tasks, outperforming traditional narrow models by demonstrating strong generalization across different imaging modalities and in scenarios with limited data. The model has been validated on a comprehensive benchmark, showing its ability to accurately identify organs and detect critical conditions. By releasing its weights, Curia aims to foster further advancements in AI-assisted radiological interpretation.","title":"Curia: Revolutionizing Radiology with a Foundation Model"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Curia is a foundation model designed for radiology, trained on a vast dataset of cross-sectional imaging from a major hospital. It excels in various radiological tasks, outperforming traditional narrow models by demonstrating strong generalization across different imaging modalities and in scenarios with limited data. The model has been validated on a comprehensive benchmark, showing its ability to accurately identify organs and detect critical conditions. By releasing its weights, Curia aims to foster further advancements in AI-assisted radiological interpretation.', title='Curia: Revolutionizing Radiology with a Foundation Model'))
[10.09.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Curiaæ˜¯ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼Œç»è¿‡å¤§é‡æ¨ªæ–­é¢å½±åƒæ•°æ®çš„è®­ç»ƒï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªæ”¾å°„å­¦ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚å®ƒåœ¨è·¨æ¨¡æ€å’Œä½æ•°æ®ç¯å¢ƒä¸‹å±•ç°å‡ºæ–°å…´ç‰¹æ€§ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„å•ä»»åŠ¡æ¨¡å‹ã€‚Curiaä½¿ç”¨äº†æ¥è‡ªä¸€å®¶å¤§å‹åŒ»é™¢çš„150,000ä¸ªæ£€æŸ¥æ•°æ®ï¼Œæˆä¸ºç°å®ä¸–ç•Œæ•°æ®ä¸­æœ€å¤§çš„è®­ç»ƒé›†ä¹‹ä¸€ã€‚é€šè¿‡åœ¨19ä¸ªä»»åŠ¡çš„å¤–éƒ¨éªŒè¯åŸºå‡†ä¸Šæµ‹è¯•ï¼ŒCuriaçš„è¡¨ç°ä¸æ”¾å°„ç§‘åŒ»ç”Ÿç›¸å½“ï¼Œç”šè‡³æ›´ä¼˜ï¼Œæ˜¾ç¤ºå‡ºå…¶å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚","title":"Curiaï¼šæ”¾å°„å­¦çš„åŸºç¡€æ¨¡å‹æ–°çªç ´"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Curiaæ˜¯ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼Œç»è¿‡å¤§é‡æ¨ªæ–­é¢å½±åƒæ•°æ®çš„è®­ç»ƒï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªæ”¾å°„å­¦ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚å®ƒåœ¨è·¨æ¨¡æ€å’Œä½æ•°æ®ç¯å¢ƒä¸‹å±•ç°å‡ºæ–°å…´ç‰¹æ€§ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„å•ä»»åŠ¡æ¨¡å‹ã€‚Curiaä½¿ç”¨äº†æ¥è‡ªä¸€å®¶å¤§å‹åŒ»é™¢çš„150,000ä¸ªæ£€æŸ¥æ•°æ®ï¼Œæˆä¸ºç°å®ä¸–ç•Œæ•°æ®ä¸­æœ€å¤§çš„è®­ç»ƒé›†ä¹‹ä¸€ã€‚é€šè¿‡åœ¨19ä¸ªä»»åŠ¡çš„å¤–éƒ¨éªŒè¯åŸºå‡†ä¸Šæµ‹è¯•ï¼ŒCuriaçš„è¡¨ç°ä¸æ”¾å°„ç§‘åŒ»ç”Ÿç›¸å½“ï¼Œç”šè‡³æ›´ä¼˜ï¼Œæ˜¾ç¤ºå‡ºå…¶å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚', title='Curiaï¼šæ”¾å°„å­¦çš„åŸºç¡€æ¨¡å‹æ–°çªç ´'))
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#math", "#rl", "#optimization", "#training", "#rlhf", "#reasoning"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ˜Ğ˜ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ", "desc": "SEELE - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ°Ğ¼Ğ¸ (RLVR), Ğº
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#agi", "#cv", "#reasoning", "#benchmark", "#agents", "#transfer_learning", "#training"], "emoji": "ğŸ”®", "ru": {"title": "Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ²Ğ¸Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ˜Ğ˜", "desc": "F1 - ÑÑ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑÑ€ĞµĞ´Ğ°Ñ…
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#games", "#rl", "#optimization", "#training", "#rlhf"], "emoji": "ğŸ®", "ru": {"title": "Ğ¡Ğ°Ğ¼Ğ¾Ğ¸Ğ³Ñ€Ğ° ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: Ğ¿ÑƒÑ‚ÑŒ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Language Self-Play (LSP). LSP Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#architecture", "#optimization", "#training"], "emoji": "ğŸ°", "ru": {"title": "CASTLE: Ğ’Ğ·Ğ³Ğ»ÑĞ´ Ğ² Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞµ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ CASTLE Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#dataset", "#hallucinations", "#interpretability", "#benchmark"], "emoji": "ğŸ¯", "ru": {"title": "Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "SimpleQA Verified - ÑÑ‚Ğ¾ ÑƒÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#training", "#diffusion", "#inference", "#optimization"], "emoji": "ğŸ–¼ï¸", "ru": {"title": "Q-Sched: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°", "desc": "Q-Sched - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾ÑÑ‚-Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ½ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¼Ğ¾Ğ´ĞµĞ»
[10.09.2025 08:17] Querying the API.
[10.09.2025 08:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Î”L Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed Delta L Normalization not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. Our code will be made public at https://github.com/zerolllin/Delta-L-Normalization.
[10.09.2025 08:18] Response: {
    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Delta L Normalization Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ°Ğ¼Ğ¸ (RLVR). Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¸ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ², Ğ²Ñ‹Ğ·Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ². Delta L Normalization Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½ĞµÑĞ¼ĞµÑ‰ĞµĞ½Ğ½ÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ»Ğ¸Ğ½ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡.",
    "emoji": "ğŸ“Š",
    "title": "Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Delta L Normalization"
}
[10.09.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Î”L Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed Delta L Normalization not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. Our code will be made public at https://github.com/zerolllin/Delta-L-Normalization."

[10.09.2025 08:18] Response: ```python
["RL", "TRAINING"]
```
[10.09.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Î”L Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed Delta L Normalization not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. Our code will be made public at https://github.com/zerolllin/Delta-L-Normalization."

[10.09.2025 08:18] Response: ```python
["OPTIMIZATION", "REASONING"]
```
[10.09.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Delta L Normalization is a novel method designed to reduce gradient variance in Reinforcement Learning with Verifiable Rewards (RLVR). It addresses the challenge of high variability in response lengths during training, which can lead to unstable optimization. Unlike previous methods that either introduce bias or fail to minimize variance, Delta L Normalization provides an unbiased estimate of policy loss while effectively reducing gradient variance. Experimental results demonstrate its effectiveness across various model sizes and tasks, showcasing its potential to enhance the performance of large language models.","title":"Minimizing Variance for Unbiased Policy Loss in RL"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Delta L Normalization is a novel method designed to reduce gradient variance in Reinforcement Learning with Verifiable Rewards (RLVR). It addresses the challenge of high variability in response lengths during training, which can lead to unstable optimization. Unlike previous methods that either introduce bias or fail to minimize variance, Delta L Normalization provides an unbiased estimate of policy loss while effectively reducing gradient variance. Experimental results demonstrate its effectiveness across various model sizes and tasks, showcasing its potential to enhance the performance of large language models.', title='Minimizing Variance for Unbiased Policy Loss in RL'))
[10.09.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Î”Lå½’ä¸€åŒ–æ˜¯ä¸€ç§é’ˆå¯¹å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ä¸­æ¢¯åº¦æ–¹å·®é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚å®ƒé€šè¿‡æä¾›æ— åçš„ç­–ç•¥æŸå¤±ä¼°è®¡ï¼Œæ˜¾è‘—é™ä½äº†æ¢¯åº¦æ–¹å·®ï¼Œä»è€Œå®ç°æ›´ç¨³å®šçš„ä¼˜åŒ–ã€‚è¯¥æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºåŠ¨æ€ç”Ÿæˆé•¿åº¦çš„æƒ…å†µï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ”¹å–„å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒÎ”Lå½’ä¸€åŒ–åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ã€æœ€å¤§é•¿åº¦å’Œä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚","title":"Î”Lå½’ä¸€åŒ–ï¼šç¨³å®šå¼ºåŒ–å­¦ä¹ çš„æ— åæŸå¤±ä¼°è®¡"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Î”Lå½’ä¸€åŒ–æ˜¯ä¸€ç§é’ˆå¯¹å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ä¸­æ¢¯åº¦æ–¹å·®é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚å®ƒé€šè¿‡æä¾›æ— åçš„ç­–ç•¥æŸå¤±ä¼°è®¡ï¼Œæ˜¾è‘—é™ä½äº†æ¢¯åº¦æ–¹å·®ï¼Œä»è€Œå®ç°æ›´ç¨³å®šçš„ä¼˜åŒ–ã€‚è¯¥æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºåŠ¨æ€ç”Ÿæˆé•¿åº¦çš„æƒ…å†µï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ”¹å–„å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒÎ”Lå½’ä¸€åŒ–åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ã€æœ€å¤§é•¿åº¦å’Œä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚', title='Î”Lå½’ä¸€åŒ–ï¼šç¨³å®šå¼ºåŒ–å­¦ä¹ çš„æ— åæŸå¤±ä¼°è®¡'))
[10.09.2025 08:18] Renaming data file.
[10.09.2025 08:18] Renaming previous data. hf_papers.json to ./d/2025-09-10.json
[10.09.2025 08:18] Saving new data file.
[10.09.2025 08:18] Generating page.
[10.09.2025 08:18] Renaming previous page.
[10.09.2025 08:18] Renaming previous data. index.html to ./d/2025-09-10.html
[10.09.2025 08:18] Writing result.
[10.09.2025 08:18] Renaming log file.
[10.09.2025 08:18] Renaming previous data. log.txt to ./logs/2025-09-10_last_log.txt
