[10.09.2025 07:11] Read previous papers.
[10.09.2025 07:11] Generating top page (month).
[10.09.2025 07:11] Writing top page (month).
[10.09.2025 08:15] Read previous papers.
[10.09.2025 08:15] Get feed.
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07980
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07969
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07979
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07295
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06818
[10.09.2025 08:15] Extract page data from URL. URL: https://huggingface.co/papers/2509.06830
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06923
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06951
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07414
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07301
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07968
[10.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01624
[10.09.2025 08:15] Extract page data from URL. URL: https://huggingface.co/papers/2509.07558
[10.09.2025 08:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[10.09.2025 08:15] No deleted papers detected.
[10.09.2025 08:15] Downloading and parsing papers (pdf, html). Total: 13.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07980.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07980.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07980.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07969.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07969.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07969.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07979.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07979.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07979.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.07295.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.07295.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.07295.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.06818.
[10.09.2025 08:15] Extra JSON file exists (./assets/json/2509.06818.json), skip PDF parsing.
[10.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.06818.json), skip HTML parsing.
[10.09.2025 08:15] Success.
[10.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.06830.
[10.09.2025 08:15] Downloading paper 2509.06830 from http://arxiv.org/pdf/2509.06830v1...
[10.09.2025 08:17] Extracting affiliations from text.
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Curia: Multi-Modal Foundation Model for Radiology Corentin Dancette1*, Julien Khlaut1,2,3, Antoine Saporta1, Helene Philippe1,3,6, Elodie Ferreres1, Baptiste Callard1, Theo Danielou1, Leo Alberge1, Leo Machado1,6, Daniel Tordjman1, Julie Dupuis1, Korentin Le Floch1,2,3,4, Jean Du Terrail7, Mariam Moshiri8, Laurent Dercle9, Tom Boeken2,3,4, Jules Gregory6, Maxime Ronot6, Francois Legou10, Pascal Roux10, Marc Sapoval2,3,5, Pierre Manceron1, Paul Herent1 1*Raidium, 27 rue du faubourg Saint-Jacques, Paris, 75014, France. 2Department of Vascular and Oncological Interventional Radiology, Hˆopital Europeen Georges Pompidou, AP-HP, Paris, France. 3Faculte de Sante, Universite Paris-Cite, Paris, France. 4HEKA, INRIA, Paris, France. 5PARCC 970, INSERM, Paris, France. 6Department of Radiology, FHU MOSAIC, Beaujon Hospital, APHP.Nord, Clichy, France. 7.omics, Paris, France. 8Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA. 9Department of Radiology, Columbia University Irving Medical Center, New York, NY, 10032, USA. 10Centre Cardiologique du Nord, Saint-Denis, 93200, France. *Corresponding author(s). E-mail(s): corentin.dancette@raidium.eu; These authors contributed equally to this work. Abstract AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, foundation model trained on the entire cross-sectional imaging output of major hospital over several yearswhich to our knowledge is the largest such corpus of real-world dataencompassing 150,000 exams (130 TB). On newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions l"
[10.09.2025 08:17] Response: ```python
[
    "Raidium, 27 rue du faubourg Saint-Jacques, Paris, 75014, France",
    "Department of Vascular and Oncological Interventional Radiology, Hˆopital Europeen Georges Pompidou, AP-HP, Paris, France",
    "Faculte de Sante, Universite Paris-Cite, Paris, France",
    "HEKA, INRIA, Paris, France",
    "PARCC 970, INSERM, Paris, France",
    "Department of Radiology, FHU MOSAIC, Beaujon Hospital, APHP.Nord, Clichy, France",
    ".omics, Paris, France",
    "Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA",
    "Department of Radiology, Columbia University Irving Medical Center, New York, NY, 10032, USA",
    "Centre Cardiologique du Nord, Saint-Denis, 93200, France"
]
```
[10.09.2025 08:17] Deleting PDF ./assets/pdf/2509.06830.pdf.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.06923.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.06923.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.06923.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.06951.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.06951.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.06951.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07414.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.07414.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.07414.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07301.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.07301.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.07301.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07968.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.07968.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.07968.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.01624.
[10.09.2025 08:17] Extra JSON file exists (./assets/json/2509.01624.json), skip PDF parsing.
[10.09.2025 08:17] Paper image links file exists (./assets/img_data/2509.01624.json), skip HTML parsing.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2509.07558.
[10.09.2025 08:17] Downloading paper 2509.07558 from http://arxiv.org/pdf/2509.07558v1...
[10.09.2025 08:17] Extracting affiliations from text.
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 ] . [ 1 8 5 5 7 0 . 9 0 5 2 : r Preprint Normalization: RETHINK LOSS AGGREGATION IN RLVR Zhiyuan He1, Xufang Luo1, Yike Zhang2, Yuqing Yang1, Lili Qiu1 1Microsoft Research, 2Tsinghua University zhiyuhe@microsoft.com, xufluo@microsoft.com "
[10.09.2025 08:17] Response: ```python
["Microsoft Research", "Tsinghua University"]
```
[10.09.2025 08:17] Deleting PDF ./assets/pdf/2509.07558.pdf.
[10.09.2025 08:17] Success.
[10.09.2025 08:17] Enriching papers with extra data.
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 0. Parallel-R1, a reinforcement learning framework, enhances large language models' reasoning capabilities by enabling parallel thinking through a progressive curriculum, leading to significant performance improvements on math benchmarks.  					AI-generated summary 				 Parallel thinking has emerged as...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 1. Mini-o3, a system for deep, multi-turn reasoning in visual search tasks, uses an iterative data collection pipeline and over-turn masking strategy to achieve state-of-the-art performance with rich reasoning patterns.  					AI-generated summary 				 Recent advances in large multimodal models have lev...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 2. VIRAL, a regularization strategy, aligns MLLMs' visual representations with pre-trained VFMs, enhancing performance on vision-centric tasks.  					AI-generated summary 				 Multimodal large language models (MLLMs) trained with visual instruction tuning have achieved strong performance across diverse...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 3. Reconstruction Alignment (RecA) is a post-training method that enhances multimodal models by using visual embeddings as dense prompts, improving image generation and editing fidelity.  					AI-generated summary 				 Unified multimodal models (UMMs) unify visual understanding and generation within a ...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 4. UMO, a Unified Multi-identity Optimization framework, enhances identity consistency and reduces confusion in multi-reference image customization using reinforcement learning on diffusion models.  					AI-generated summary 				 Recent advancements in image customization exhibit a wide range of applic...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 5. Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 6. SEELE, a novel RLVR framework, dynamically adjusts problem difficulty using adaptive hint lengths to enhance exploration efficiency and improve performance in math reasoning tasks.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success i...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 7. F1, a pretrained VLA framework with foresight generation, improves task success and generalization in dynamic environments through a Mixture-of-Transformer architecture and next-scale prediction.  					AI-generated summary 				 Executing language-conditioned tasks in dynamic visual environments rema...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 8. Language Self-Play (LSP) enhances large language models' performance on instruction-following tasks through self-play, surpassing data-driven methods.  					AI-generated summary 				 Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training d...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 9. CASTLE, an attention mechanism that updates keys with future context while maintaining autoregressive properties, outperforms standard causal attention in language modeling.  					AI-generated summary 				 In standard causal attention, each token's query, key, and value (QKV) are static and encode o...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 10. SimpleQA Verified is a refined benchmark for evaluating the factuality of Large Language Models, addressing issues in previous benchmarks and providing a more reliable evaluation tool.  					AI-generated summary 				 We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large Langu...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 11. Q-Sched, a novel post-training quantization method for diffusion models, reduces model size by 4x while maintaining full-precision accuracy and improving image quality metrics.  					AI-generated summary 				 Text-to-image diffusion models are computationally intensive, often requiring dozens of for...
[10.09.2025 08:17] ********************************************************************************
[10.09.2025 08:17] Abstract 12. ΔL Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the charact...
[10.09.2025 08:17] Read previous papers.
[10.09.2025 08:17] Generating reviews via LLM API.
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#math", "#open_source", "#rl", "#optimization", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Параллельное мышление для ИИ: новый уровень рассуждений", "desc": "Parallel-R1 - это фреймворк обучения с подкреплением, который улучшает способности больших языковых моделей к
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#data", "#open_source", "#cv", "#rl", "#training", "#multimodal", "#dataset", "#reasoning"], "emoji": "🔍", "ru": {"title": "Глубокое мышление в визуальном поиске: Mini-o3 раздвигает границы рассуждений", "desc": "Система Mini-o3 представляет собой подход к глубокому многоступенчатом
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#alignment", "#training", "#multimodal", "#reasoning"], "emoji": "🔍", "ru": {"title": "Усиление визуального понимания языковых моделей через выравнивание представлений", "desc": "Статья представляет VIRAL - стратегию регуляризации для мультимодальных больших язы
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#alignment", "#benchmark", "#open_source", "#multimodal", "#optimization", "#diffusion", "#training"], "emoji": "🔄", "ru": {"title": "RecA: Эффективное выравнивание мультимодальных моделей для улучшения генерации изображений", "desc": "Reconstruction Alignment (RecA) - это метод пос
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#dataset", "#rl", "#open_source", "#optimization", "#diffusion", "#training"], "emoji": "🎭", "ru": {"title": "UMO: Улучшение идентичности в кастомизации изображений", "desc": "UMO - это новая система оптимизации для улучшения согласованности идентичности и уменьшения путаницы в каст
[10.09.2025 08:17] Querying the API.
[10.09.2025 08:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, a foundation model trained on the entire cross-sectional imaging output of a major hospital over several years, which to our knowledge is the largest such corpus of real-world data-encompassing 150,000 exams (130 TB). On a newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions like brain hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging. Curia meets or surpasses the performance of radiologists and recent foundation models, and exhibits clinically significant emergent properties in cross-modality, and low-data regimes. To accelerate progress, we release our base model's weights at https://huggingface.co/raidium/curia.
[10.09.2025 08:17] Response: {
  "desc": "Модель Curia - это фундаментальная модель машинного обучения, обученная на обширном наборе данных медицинской визуализации. Она демонстрирует превосходную производительность в различных радиологических задачах, включая идентификацию органов, обнаружение заболеваний и прогнозирование исходов при стадировании опухолей. Curia показывает эмерджентные свойства в кросс-модальных и низкоресурсных сценариях. Модель обучена на 150 000 исследований (130 ТБ данных) и превосходит как радиологов, так и другие современные фундаментальные модели по точности.",
  "emoji": "🧠",
  "title": "Curia: универсальная модель для радиологической интерпретации"
}
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, a foundation model trained on the entire cross-sectional imaging output of a major hospital over several years, which to our knowledge is the largest such corpus of real-world data-encompassing 150,000 exams (130 TB). On a newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions like brain hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging. Curia meets or surpasses the performance of radiologists and recent foundation models, and exhibits clinically significant emergent properties in cross-modality, and low-data regimes. To accelerate progress, we release our base model's weights at https://huggingface.co/raidium/curia."

[10.09.2025 08:17] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'HEALTHCARE']
```
[10.09.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, a foundation model trained on the entire cross-sectional imaging output of a major hospital over several years, which to our knowledge is the largest such corpus of real-world data-encompassing 150,000 exams (130 TB). On a newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions like brain hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging. Curia meets or surpasses the performance of radiologists and recent foundation models, and exhibits clinically significant emergent properties in cross-modality, and low-data regimes. To accelerate progress, we release our base model's weights at https://huggingface.co/raidium/curia."

[10.09.2025 08:17] Response: ```python
['LOW_RESOURCE', 'OPEN_SOURCE']
```
[10.09.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Curia is a foundation model designed for radiology, trained on a vast dataset of cross-sectional imaging from a major hospital. It excels in various radiological tasks, outperforming traditional narrow models by demonstrating strong generalization across different imaging modalities and in scenarios with limited data. The model has been validated on a comprehensive benchmark, showing its ability to accurately identify organs and detect critical conditions. By releasing its weights, Curia aims to foster further advancements in AI-assisted radiological interpretation.","title":"Curia: Revolutionizing Radiology with a Foundation Model"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Curia is a foundation model designed for radiology, trained on a vast dataset of cross-sectional imaging from a major hospital. It excels in various radiological tasks, outperforming traditional narrow models by demonstrating strong generalization across different imaging modalities and in scenarios with limited data. The model has been validated on a comprehensive benchmark, showing its ability to accurately identify organs and detect critical conditions. By releasing its weights, Curia aims to foster further advancements in AI-assisted radiological interpretation.', title='Curia: Revolutionizing Radiology with a Foundation Model'))
[10.09.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Curia是一个基础模型，经过大量横断面影像数据的训练，能够在多个放射学任务中表现出色。它在跨模态和低数据环境下展现出新兴特性，超越了传统的单任务模型。Curia使用了来自一家大型医院的150,000个检查数据，成为现实世界数据中最大的训练集之一。通过在19个任务的外部验证基准上测试，Curia的表现与放射科医生相当，甚至更优，显示出其广泛的应用潜力。","title":"Curia：放射学的基础模型新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Curia是一个基础模型，经过大量横断面影像数据的训练，能够在多个放射学任务中表现出色。它在跨模态和低数据环境下展现出新兴特性，超越了传统的单任务模型。Curia使用了来自一家大型医院的150,000个检查数据，成为现实世界数据中最大的训练集之一。通过在19个任务的外部验证基准上测试，Curia的表现与放射科医生相当，甚至更优，显示出其广泛的应用潜力。', title='Curia：放射学的基础模型新突破'))
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#math", "#rl", "#optimization", "#training", "#rlhf", "#reasoning"], "emoji": "🧠", "ru": {"title": "Динамическая настройка сложности для эффективного обучения ИИ математическому мышлению", "desc": "SEELE - это новая система обучения с подкреплением с проверяемыми наградами (RLVR), к
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#agi", "#cv", "#reasoning", "#benchmark", "#agents", "#transfer_learning", "#training"], "emoji": "🔮", "ru": {"title": "Визуальное предвидение для улучшения принятия решений ИИ", "desc": "F1 - это предварительно обученная система для выполнения задач в динамических визуальных средах
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#games", "#rl", "#optimization", "#training", "#rlhf"], "emoji": "🎮", "ru": {"title": "Самоигра языковых моделей: путь к улучшению без новых данных", "desc": "Статья представляет новый метод улучшения больших языковых моделей (LLM) под названием Language Self-Play (LSP). LSP использ
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#architecture", "#optimization", "#training"], "emoji": "🏰", "ru": {"title": "CASTLE: Взгляд в будущее для улучшения языкового моделирования", "desc": "Статья представляет новый механизм внимания под названием CASTLE для языкового моделирования. В отли
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#dataset", "#hallucinations", "#interpretability", "#benchmark"], "emoji": "🎯", "ru": {"title": "Точный бенчмарк для оценки фактической достоверности языковых моделей", "desc": "SimpleQA Verified - это усовершенствованный бенчмарк для оценки фактической точности больших языковых мод
[10.09.2025 08:17] Using data from previous issue: {"categories": ["#training", "#diffusion", "#inference", "#optimization"], "emoji": "🖼️", "ru": {"title": "Q-Sched: Эффективная квантизация диффузионных моделей без потери качества", "desc": "Q-Sched - это новый метод пост-тренировочной квантизации для диффузионных моделей. Он уменьшает размер модел
[10.09.2025 08:17] Querying the API.
[10.09.2025 08:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ΔL Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed Delta L Normalization not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. Our code will be made public at https://github.com/zerolllin/Delta-L-Normalization.
[10.09.2025 08:18] Response: {
    "desc": "Статья представляет метод Delta L Normalization для обучения с подкреплением с проверяемыми наградами (RLVR). Этот подход решает проблему высокой дисперсии градиентов, вызванную переменной длиной генерируемых ответов. Delta L Normalization обеспечивает несмещенную оценку функции потерь с минимальной дисперсией. Эксперименты показывают превосходство метода для различных размеров моделей, максимальных длин и задач.",
    "emoji": "📊",
    "title": "Стабилизация обучения языковых моделей с помощью Delta L Normalization"
}
[10.09.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ΔL Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed Delta L Normalization not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. Our code will be made public at https://github.com/zerolllin/Delta-L-Normalization."

[10.09.2025 08:18] Response: ```python
["RL", "TRAINING"]
```
[10.09.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ΔL Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the characteristic of dynamic generation lengths in Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has demonstrated strong potential in improving the reasoning capabilities of large language models (LLMs), but a major challenge lies in the large variability of response lengths during training, which leads to high gradient variance and unstable optimization. Although previous methods such as GRPO, DAPO, and Dr. GRPO introduce different loss normalization terms to address this issue, they either produce biased estimates or still suffer from high gradient variance. By analyzing the effect of varying lengths on policy loss both theoretically and empirically, we reformulate the problem as finding a minimum-variance unbiased estimator. Our proposed Delta L Normalization not only provides an unbiased estimate of the true policy loss but also minimizes gradient variance in theory. Extensive experiments show that it consistently achieves superior results across different model sizes, maximum lengths, and tasks. Our code will be made public at https://github.com/zerolllin/Delta-L-Normalization."

[10.09.2025 08:18] Response: ```python
["OPTIMIZATION", "REASONING"]
```
[10.09.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Delta L Normalization is a novel method designed to reduce gradient variance in Reinforcement Learning with Verifiable Rewards (RLVR). It addresses the challenge of high variability in response lengths during training, which can lead to unstable optimization. Unlike previous methods that either introduce bias or fail to minimize variance, Delta L Normalization provides an unbiased estimate of policy loss while effectively reducing gradient variance. Experimental results demonstrate its effectiveness across various model sizes and tasks, showcasing its potential to enhance the performance of large language models.","title":"Minimizing Variance for Unbiased Policy Loss in RL"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Delta L Normalization is a novel method designed to reduce gradient variance in Reinforcement Learning with Verifiable Rewards (RLVR). It addresses the challenge of high variability in response lengths during training, which can lead to unstable optimization. Unlike previous methods that either introduce bias or fail to minimize variance, Delta L Normalization provides an unbiased estimate of policy loss while effectively reducing gradient variance. Experimental results demonstrate its effectiveness across various model sizes and tasks, showcasing its potential to enhance the performance of large language models.', title='Minimizing Variance for Unbiased Policy Loss in RL'))
[10.09.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ΔL归一化是一种针对可验证奖励的强化学习中梯度方差问题的解决方案。它通过提供无偏的策略损失估计，显著降低了梯度方差，从而实现更稳定的优化。该方法特别适用于动态生成长度的情况，能够有效改善大语言模型的推理能力。实验结果表明，ΔL归一化在不同模型规模、最大长度和任务上均表现出色。","title":"ΔL归一化：稳定强化学习的无偏损失估计"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ΔL归一化是一种针对可验证奖励的强化学习中梯度方差问题的解决方案。它通过提供无偏的策略损失估计，显著降低了梯度方差，从而实现更稳定的优化。该方法特别适用于动态生成长度的情况，能够有效改善大语言模型的推理能力。实验结果表明，ΔL归一化在不同模型规模、最大长度和任务上均表现出色。', title='ΔL归一化：稳定强化学习的无偏损失估计'))
[10.09.2025 08:18] Renaming data file.
[10.09.2025 08:18] Renaming previous data. hf_papers.json to ./d/2025-09-10.json
[10.09.2025 08:18] Saving new data file.
[10.09.2025 08:18] Generating page.
[10.09.2025 08:18] Renaming previous page.
[10.09.2025 08:18] Renaming previous data. index.html to ./d/2025-09-10.html
[10.09.2025 08:18] Writing result.
[10.09.2025 08:18] Renaming log file.
[10.09.2025 08:18] Renaming previous data. log.txt to ./logs/2025-09-10_last_log.txt
