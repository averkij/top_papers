[10.09.2025 19:09] Read previous papers.
[10.09.2025 19:09] Generating top page (month).
[10.09.2025 19:09] Writing top page (month).
[10.09.2025 20:13] Read previous papers.
[10.09.2025 20:13] Get feed.
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07980
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07979
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07969
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07295
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06818
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06951
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06923
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06830
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07414
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03646
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07301
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07968
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06942
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01624
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07558
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07253
[10.09.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06938
[10.09.2025 20:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[10.09.2025 20:13] No deleted papers detected.
[10.09.2025 20:13] Downloading and parsing papers (pdf, html). Total: 17.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07980.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07980.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07980.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07979.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07979.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07979.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07969.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07969.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07969.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07295.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07295.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07295.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.06818.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.06818.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.06818.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.06951.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.06951.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.06951.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.06923.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.06923.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.06923.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.06830.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.06830.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.06830.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07414.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07414.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07414.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.03646.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.03646.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.03646.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07301.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07301.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07301.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07968.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07968.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07968.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.06942.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.06942.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.06942.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.01624.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.01624.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.01624.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07558.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07558.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07558.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.07253.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.07253.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.07253.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2509.06938.
[10.09.2025 20:13] Extra JSON file exists (./assets/json/2509.06938.json), skip PDF parsing.
[10.09.2025 20:13] Paper image links file exists (./assets/img_data/2509.06938.json), skip HTML parsing.
[10.09.2025 20:13] Success.
[10.09.2025 20:13] Enriching papers with extra data.
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 0. Parallel-R1, a reinforcement learning framework, enhances large language models' reasoning capabilities by enabling parallel thinking through a progressive curriculum, leading to significant performance improvements on math benchmarks.  					AI-generated summary 				 Parallel thinking has emerged as...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 1. VIRAL, a regularization strategy, aligns MLLMs' visual representations with pre-trained VFMs, enhancing performance on vision-centric tasks.  					AI-generated summary 				 Multimodal large language models (MLLMs) trained with visual instruction tuning have achieved strong performance across diverse...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 2. Mini-o3, a system for deep, multi-turn reasoning in visual search tasks, uses an iterative data collection pipeline and over-turn masking strategy to achieve state-of-the-art performance with rich reasoning patterns.  					AI-generated summary 				 Recent advances in large multimodal models have lev...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 3. Reconstruction Alignment (RecA) is a post-training method that enhances multimodal models by using visual embeddings as dense prompts, improving image generation and editing fidelity.  					AI-generated summary 				 Unified multimodal models (UMMs) unify visual understanding and generation within a ...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 4. UMO, a Unified Multi-identity Optimization framework, enhances identity consistency and reduces confusion in multi-reference image customization using reinforcement learning on diffusion models.  					AI-generated summary 				 Recent advancements in image customization exhibit a wide range of applic...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 5. F1, a pretrained VLA framework with foresight generation, improves task success and generalization in dynamic environments through a Mixture-of-Transformer architecture and next-scale prediction.  					AI-generated summary 				 Executing language-conditioned tasks in dynamic visual environments rema...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 6. SEELE, a novel RLVR framework, dynamically adjusts problem difficulty using adaptive hint lengths to enhance exploration efficiency and improve performance in math reasoning tasks.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success i...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 7. Curia, a foundation model trained on extensive cross-sectional imaging data, demonstrates superior performance across multiple radiological tasks and shows emergent properties in cross-modality and low-data settings.  					AI-generated summary 				 AI-assisted radiological interpretation is based on...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 8. Language Self-Play (LSP) enhances large language models' performance on instruction-following tasks through self-play, surpassing data-driven methods.  					AI-generated summary 				 Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training d...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 9. Reinforcement Learning enhances LLM reasoning through a two-phase process involving procedural correctness and strategic planning, with HICRA algorithm focusing on high-impact planning tokens to improve performance.  					AI-generated summary 				 Reinforcement Learning (RL) has proven highly effect...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 10. CASTLE, an attention mechanism that updates keys with future context while maintaining autoregressive properties, outperforms standard causal attention in language modeling.  					AI-generated summary 				 In standard causal attention, each token's query, key, and value (QKV) are static and encode o...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 11. SimpleQA Verified is a refined benchmark for evaluating the factuality of Large Language Models, addressing issues in previous benchmarks and providing a more reliable evaluation tool.  					AI-generated summary 				 We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large Langu...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 12. Direct-Align and Semantic Relative Preference Optimization improve diffusion models' alignment with human preferences by reducing computational costs and minimizing offline reward adaptation.  					AI-generated summary 				 Recent studies have demonstrated the effectiveness of directly aligning diff...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 13. Q-Sched, a novel post-training quantization method for diffusion models, reduces model size by 4x while maintaining full-precision accuracy and improving image quality metrics.  					AI-generated summary 				 Text-to-image diffusion models are computationally intensive, often requiring dozens of for...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 14. ŒîL Normalization addresses gradient variance in Reinforcement Learning with Verifiable Rewards by providing an unbiased policy loss estimate with minimal variance.  					AI-generated summary 				 We propose Delta L Normalization, a simple yet effective loss aggregation method tailored to the charact...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 15. A benchmark of complex retrieval tasks reveals that even state-of-the-art models struggle with high-quality retrieval, and LLM-based query expansion does not consistently improve performance.  					AI-generated summary 				 Large language models (LLMs) are incredible and versatile tools for text-bas...
[10.09.2025 20:13] ********************************************************************************
[10.09.2025 20:13] Abstract 16. Transformer models tend to activate input-insensitive semantic features under uncertainty, leading to hallucinations that can be predicted from their internal activations.  					AI-generated summary 				 As generative AI systems become competent and democratized in science, business, and government,...
[10.09.2025 20:13] Read previous papers.
[10.09.2025 20:13] Generating reviews via LLM API.
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#math", "#open_source", "#rl", "#optimization", "#training", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –¥–ª—è –ò–ò: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "Parallel-R1 - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#alignment", "#training", "#multimodal", "#reasoning"], "emoji": "üîç", "ru": {"title": "–£—Å–∏–ª–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç VIRAL - —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#data", "#open_source", "#cv", "#rl", "#training", "#multimodal", "#dataset", "#reasoning"], "emoji": "üîç", "ru": {"title": "–ì–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ–º –ø–æ–∏—Å–∫–µ: Mini-o3 —Ä–∞–∑–¥–≤–∏–≥–∞–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "–°–∏—Å—Ç–µ–º–∞ Mini-o3 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–ª—É–±–æ–∫–æ–º—É –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç–æ–º
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#alignment", "#benchmark", "#open_source", "#multimodal", "#optimization", "#diffusion", "#training"], "emoji": "üîÑ", "ru": {"title": "RecA: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "Reconstruction Alignment (RecA) - —ç—Ç–æ –º–µ—Ç–æ–¥ –ø–æ—Å
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#dataset", "#rl", "#open_source", "#optimization", "#diffusion", "#training"], "emoji": "üé≠", "ru": {"title": "UMO: –£–ª—É—á—à–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –≤ –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "UMO - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è –ø—É—Ç–∞–Ω–∏—Ü—ã –≤ –∫–∞—Å—Ç
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#agi", "#cv", "#reasoning", "#benchmark", "#agents", "#transfer_learning", "#training"], "emoji": "üîÆ", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–≤–∏–¥–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –ò–ò", "desc": "F1 - —ç—Ç–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –≤ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#math", "#rl", "#optimization", "#training", "#rlhf", "#reasoning"], "emoji": "üß†", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ò–ò –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –º—ã—à–ª–µ–Ω–∏—é", "desc": "SEELE - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏ (RLVR), –∫
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#dataset", "#healthcare", "#benchmark", "#data", "#low_resource", "#open_source"], "emoji": "üß†", "ru": {"title": "Curia: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏", "desc": "–ú–æ–¥–µ–ª—å Curia - —ç—Ç–æ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –æ–±—à–∏—Ä–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#games", "#rl", "#optimization", "#training", "#rlhf"], "emoji": "üéÆ", "ru": {"title": "–°–∞–º–æ–∏–≥—Ä–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –ø—É—Ç—å –∫ —É–ª—É—á—à–µ–Ω–∏—é –±–µ–∑ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Language Self-Play (LSP). LSP –∏—Å–ø–æ–ª—å–∑
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#rlhf", "#training", "#optimization", "#rl", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –¥–≤—É—Ö—Ñ–∞–∑–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#architecture", "#optimization", "#training"], "emoji": "üè∞", "ru": {"title": "CASTLE: –í–∑–≥–ª—è–¥ –≤ –±—É–¥—É—â–µ–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º CASTLE –¥–ª—è —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è. –í –æ—Ç–ª–∏
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#dataset", "#hallucinations", "#interpretability", "#benchmark"], "emoji": "üéØ", "ru": {"title": "–¢–æ—á–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "SimpleQA Verified - —ç—Ç–æ —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#diffusion", "#alignment", "#rlhf", "#training", "#optimization"], "emoji": "üñºÔ∏è", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —É—á–µ—Ç–æ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–≤–∞ –º–µ—Ç–æ–¥–∞ —É–ª—É—á—à–µ–Ω–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: Direct-Align –∏ Semantic Relati
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#training", "#diffusion", "#inference", "#optimization"], "emoji": "üñºÔ∏è", "ru": {"title": "Q-Sched: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "Q-Sched - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ—Å—Ç-—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#reasoning"], "emoji": "üìä", "ru": {"title": "–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é Delta L Normalization", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Delta L Normalization –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏ (RLVR). –≠—Ç–æ—Ç –ø–æ–¥—Ö
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#survey", "#rag", "#benchmark", "#reasoning"], "emoji": "üîç", "ru": {"title": "–°–ª–æ–∂–Ω—ã–π –ø–æ–∏—Å–∫: —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–∏—Å–∫–∞ –∏—Å–ø—ã—Ç—ã–≤–∞—é—Ç —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –î–∞–∂–µ —Å–∞–º—ã–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç
[10.09.2025 20:13] Using data from previous issue: {"categories": ["#architecture", "#security", "#alignment", "#training", "#rlhf", "#hallucinations"], "emoji": "üß†", "ru": {"title": "–†–∞—Å–∫—Ä—ã—Ç–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ
[10.09.2025 20:13] Renaming data file.
[10.09.2025 20:13] Renaming previous data. hf_papers.json to ./d/2025-09-10.json
[10.09.2025 20:13] Saving new data file.
[10.09.2025 20:13] Generating page.
[10.09.2025 20:13] Renaming previous page.
[10.09.2025 20:13] Renaming previous data. index.html to ./d/2025-09-10.html
[10.09.2025 20:13] Writing result.
[10.09.2025 20:13] Renaming log file.
[10.09.2025 20:13] Renaming previous data. log.txt to ./logs/2025-09-10_last_log.txt
