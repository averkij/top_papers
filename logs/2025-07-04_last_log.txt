[04.07.2025 00:56] Read previous papers.
[04.07.2025 00:56] Generating top page (month).
[04.07.2025 00:56] Writing top page (month).
[04.07.2025 02:44] Read previous papers.
[04.07.2025 02:44] Get feed.
[04.07.2025 02:44] Extract page data from URL. URL: https://huggingface.co/papers/2507.02813
[04.07.2025 02:44] Extract page data from URL. URL: https://huggingface.co/papers/2507.01352
[04.07.2025 02:44] Extract page data from URL. URL: https://huggingface.co/papers/2507.02592
[04.07.2025 02:44] Extract page data from URL. URL: https://huggingface.co/papers/2507.02652
[04.07.2025 02:44] Extract page data from URL. URL: https://huggingface.co/papers/2507.02754
[04.07.2025 02:44] Extract page data from URL. URL: https://huggingface.co/papers/2507.02726
[04.07.2025 02:44] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[04.07.2025 02:44] Downloading and parsing papers (pdf, html). Total: 6.
[04.07.2025 02:44] Downloading and parsing paper https://huggingface.co/papers/2507.02813.
[04.07.2025 02:44] Downloading paper 2507.02813 from http://arxiv.org/pdf/2507.02813v1...
[04.07.2025 02:44] Extracting affiliations from text.
[04.07.2025 02:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion Fangfu Liu1, Hao Li2, Jiawei Chi1, Hanyang Wang1, Minghui Yang3, Fudong Wang3, Yueqi Duan1 1Tsinghua University, 2NTU, 3Ant Group 5 2 0 2 3 ] . [ 1 3 1 8 2 0 . 7 0 5 2 : r Figure 1. LangScene-X: Given sparse views as input (e.g., as few as two images), we design generative paradigm to build the 3D generalizable language-embedded surface fields with TriMap video diffusion and language quantized compressor (LQC), which supports open-ended language queries in any 3D scenes. For example, given prompt like stuffed bear in the Teatime scene, relevancy map can be rendered focusing on the location with maximum relevancy activation. "
[04.07.2025 02:44] Response: ```python
["Tsinghua University", "NTU", "Ant Group"]
```
[04.07.2025 02:44] Deleting PDF ./assets/pdf/2507.02813.pdf.
[04.07.2025 02:44] Success.
[04.07.2025 02:44] Downloading and parsing paper https://huggingface.co/papers/2507.01352.
[04.07.2025 02:44] Downloading paper 2507.01352 from http://arxiv.org/pdf/2507.01352v2...
[04.07.2025 02:44] Extracting affiliations from text.
[04.07.2025 02:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2025-07-04 Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy Chris Yuhao Liu Liang Zeng Yuzhen Xiao Jujie He Jiacai Liu Chaojie Wang Rui Yan Wei Shen Fuxiang Zhang Jiacheng Xu Yang Liu Yahui Zhou 2050 Research, Skywork AI https://huggingface.co/Skywork https://modelscope.cn/organization/Skywork https://github.com/SkyworkAI/Skywork-Reward-V "
[04.07.2025 02:44] Response: ```python
["2050 Research, Skywork AI"]
```
[04.07.2025 02:44] Deleting PDF ./assets/pdf/2507.01352.pdf.
[04.07.2025 02:44] Success.
[04.07.2025 02:44] Downloading and parsing paper https://huggingface.co/papers/2507.02592.
[04.07.2025 02:44] Downloading paper 2507.02592 from http://arxiv.org/pdf/2507.02592v1...
[04.07.2025 02:44] Extracting affiliations from text.
[04.07.2025 02:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 ] . [ 1 2 9 5 2 0 . 7 0 5 2 : r 2025-07WebSailor: Navigating Super-human Reasoning for Web Agent Kuan Li, Zhongwang Zhang, Huifeng Yin((cid:0)), Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin, Baixuan Li, Zhengwei Tao, Xinyu Wang, Weizhou Shen, Junkai Zhang, Dingchu Zhang, Xixi Wu, Yong Jiang((cid:0)), Ming Yan, Pengjun Xie, Fei Huang, Jingren Zhou Tongyi Lab , Alibaba Group https://github.com/Alibaba-NLP/WebAgent "
[04.07.2025 02:44] Response: ```python
["Tongyi Lab, Alibaba Group"]
```
[04.07.2025 02:44] Deleting PDF ./assets/pdf/2507.02592.pdf.
[04.07.2025 02:44] Success.
[04.07.2025 02:44] Downloading and parsing paper https://huggingface.co/papers/2507.02652.
[04.07.2025 02:44] Downloading paper 2507.02652 from http://arxiv.org/pdf/2507.02652v1...
[04.07.2025 02:44] Extracting affiliations from text.
[04.07.2025 02:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Decoupled Planning and Execution: Hierarchical Reasoning Framework for Deep Search Jiajie Jin1, Xiaoxi Li1, Guanting Dong1, Yuyao Zhang1, Yutao Zhu1, Yang Zhao1, Hongjin Qian2, Zhicheng Dou1* Gaoling School of Artificial Intelligence, Renmin University of China BAAI {jinjiajie, dou}@ruc.edu.cn 5 2 0 2 3 ] A . [ 1 2 5 6 2 0 . 7 0 5 2 : r a "
[04.07.2025 02:44] Response: ```python
["Gaoling School of Artificial Intelligence, Renmin University of China"]
```
[04.07.2025 02:44] Deleting PDF ./assets/pdf/2507.02652.pdf.
[04.07.2025 02:44] Success.
[04.07.2025 02:44] Downloading and parsing paper https://huggingface.co/papers/2507.02754.
[04.07.2025 02:44] Downloading paper 2507.02754 from http://arxiv.org/pdf/2507.02754v1...
[04.07.2025 02:44] Extracting affiliations from text.
[04.07.2025 02:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 ] . [ 1 4 5 7 2 0 . 7 0 5 2 : r FAST AND SIMPLEX: 2-SIMPLICIAL ATTENTION IN TRITON Aurko Roy Meta Menlo Park, CA roy.aurko@gmail.com Timothy Chou Meta Menlo Park, CA timchou@meta.com Sai Surya Duvvuri Department of Computer Science University of Texas at Austin saisurya@cs.utexas.edu Sijia Chen Meta Menlo Park, CA sijiac@meta.com Jiecao Yu Meta Menlo Park, CA jiecaoyu@meta.com Xiaodong Wang Meta Menlo Park, CA xdwang@meta.com Manzil Zaheer Meta Menlo Park, CA manzilzaheer@meta.com Rohan Anil San Francisco, CA rohan.anil@gmail.com "
[04.07.2025 02:44] Response: ```python
["Meta Menlo Park, CA", "Department of Computer Science University of Texas at Austin"]
```
[04.07.2025 02:44] Deleting PDF ./assets/pdf/2507.02754.pdf.
[04.07.2025 02:44] Success.
[04.07.2025 02:44] Downloading and parsing paper https://huggingface.co/papers/2507.02726.
[04.07.2025 02:44] Downloading paper 2507.02726 from http://arxiv.org/pdf/2507.02726v1...
[04.07.2025 02:44] Extracting affiliations from text.
[04.07.2025 02:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"BOURBAKI: CONDITIONED MDPS FOR THEOREM PROVING SELF-GENERATED AND GOAL5 2 0 2 ] . [ 1 6 2 7 2 0 . 7 0 5 2 : r Matthieu Zimmer Huawei Noahs Ark Lab Xiaotong Ji Huawei Noahs Ark Lab Imperial College London Rasul Tutunov Huawei Noahs Ark Lab Anthony Bordg Huawei Lagrange Center Jun Wang UCL Centre for AI Haitham Bou Ammar Huawei Noahs Ark Lab UCL Centre for AI "
[04.07.2025 02:44] Response: ```python
["Huawei Noahs Ark Lab", "Imperial College London", "Lagrange Center", "UCL Centre for AI"]
```
[04.07.2025 02:44] Deleting PDF ./assets/pdf/2507.02726.pdf.
[04.07.2025 02:44] Success.
[04.07.2025 02:44] Enriching papers with extra data.
[04.07.2025 02:44] ********************************************************************************
[04.07.2025 02:44] Abstract 0. Recovering 3D structures with open-vocabulary scene understanding from 2D images is a fundamental but daunting task. Recent developments have achieved this by performing per-scene optimization with embedded language information. However, they heavily rely on the calibrated dense-view reconstruction ...
[04.07.2025 02:44] ********************************************************************************
[04.07.2025 02:44] Abstract 1. Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorpo...
[04.07.2025 02:44] ********************************************************************************
[04.07.2025 02:44] Abstract 2. Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their...
[04.07.2025 02:44] ********************************************************************************
[04.07.2025 02:44] Abstract 3. Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: th...
[04.07.2025 02:44] ********************************************************************************
[04.07.2025 02:44] Abstract 4. Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-b...
[04.07.2025 02:44] ********************************************************************************
[04.07.2025 02:44] Abstract 5. Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains univers...
[04.07.2025 02:44] Read previous papers.
[04.07.2025 02:44] Generating reviews via LLM API.
[04.07.2025 02:44] Querying the API.
[04.07.2025 02:44] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recovering 3D structures with open-vocabulary scene understanding from 2D images is a fundamental but daunting task. Recent developments have achieved this by performing per-scene optimization with embedded language information. However, they heavily rely on the calibrated dense-view reconstruction paradigm, thereby suffering from severe rendering artifacts and implausible semantic synthesis when limited views are available. In this paper, we introduce a novel generative framework, coined LangScene-X, to unify and generate 3D consistent multi-modality information for reconstruction and understanding. Powered by the generative capability of creating more consistent novel observations, we can build generalizable 3D language-embedded scenes from only sparse views. Specifically, we first train a TriMap video diffusion model that can generate appearance (RGBs), geometry (normals), and semantics (segmentation maps) from sparse inputs through progressive knowledge integration. Furthermore, we propose a Language Quantized Compressor (LQC), trained on large-scale image datasets, to efficiently encode language embeddings, enabling cross-scene generalization without per-scene retraining. Finally, we reconstruct the language surface fields by aligning language information onto the surface of 3D scenes, enabling open-ended language queries. Extensive experiments on real-world data demonstrate the superiority of our LangScene-X over state-of-the-art methods in terms of quality and generalizability. Project Page: https://liuff19.github.io/LangScene-X.
[04.07.2025 02:44] Response: {
  "desc": "LangScene-X - это новая генеративная система для восстановления и понимания 3D-сцен с открытым словарем на основе 2D-изображений. Она использует видео-диффузионную модель TriMap для генерации согласованной мультимодальной информации (RGB, нормали, сегментация) из ограниченного числа ракурсов. Система включает языковой квантованный компрессор (LQC) для эффективного кодирования языковых эмбеддингов, что позволяет обобщать на новые сцены без переобучения. LangScene-X превосходит современные методы по качеству и обобщаемости при реконструкции 3D-сцен с языковой привязкой.",
  "emoji": "🏙️",
  "title": "Генерация 3D-сцен с языковым пониманием по нескольким изображениям"
}
[04.07.2025 02:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recovering 3D structures with open-vocabulary scene understanding from 2D images is a fundamental but daunting task. Recent developments have achieved this by performing per-scene optimization with embedded language information. However, they heavily rely on the calibrated dense-view reconstruction paradigm, thereby suffering from severe rendering artifacts and implausible semantic synthesis when limited views are available. In this paper, we introduce a novel generative framework, coined LangScene-X, to unify and generate 3D consistent multi-modality information for reconstruction and understanding. Powered by the generative capability of creating more consistent novel observations, we can build generalizable 3D language-embedded scenes from only sparse views. Specifically, we first train a TriMap video diffusion model that can generate appearance (RGBs), geometry (normals), and semantics (segmentation maps) from sparse inputs through progressive knowledge integration. Furthermore, we propose a Language Quantized Compressor (LQC), trained on large-scale image datasets, to efficiently encode language embeddings, enabling cross-scene generalization without per-scene retraining. Finally, we reconstruct the language surface fields by aligning language information onto the surface of 3D scenes, enabling open-ended language queries. Extensive experiments on real-world data demonstrate the superiority of our LangScene-X over state-of-the-art methods in terms of quality and generalizability. Project Page: https://liuff19.github.io/LangScene-X."

[04.07.2025 02:45] Response: ```python
['3D', 'MULTIMODAL']
```
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recovering 3D structures with open-vocabulary scene understanding from 2D images is a fundamental but daunting task. Recent developments have achieved this by performing per-scene optimization with embedded language information. However, they heavily rely on the calibrated dense-view reconstruction paradigm, thereby suffering from severe rendering artifacts and implausible semantic synthesis when limited views are available. In this paper, we introduce a novel generative framework, coined LangScene-X, to unify and generate 3D consistent multi-modality information for reconstruction and understanding. Powered by the generative capability of creating more consistent novel observations, we can build generalizable 3D language-embedded scenes from only sparse views. Specifically, we first train a TriMap video diffusion model that can generate appearance (RGBs), geometry (normals), and semantics (segmentation maps) from sparse inputs through progressive knowledge integration. Furthermore, we propose a Language Quantized Compressor (LQC), trained on large-scale image datasets, to efficiently encode language embeddings, enabling cross-scene generalization without per-scene retraining. Finally, we reconstruct the language surface fields by aligning language information onto the surface of 3D scenes, enabling open-ended language queries. Extensive experiments on real-world data demonstrate the superiority of our LangScene-X over state-of-the-art methods in terms of quality and generalizability. Project Page: https://liuff19.github.io/LangScene-X."

[04.07.2025 02:45] Response: ```python
['GAMES', 'DIFFUSION', 'OPEN_SOURCE']
```
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents LangScene-X, a new framework for creating 3D structures from 2D images using language information. It addresses the limitations of previous methods that relied on dense-view reconstructions, which often resulted in poor quality when only limited views were available. LangScene-X utilizes a TriMap video diffusion model to generate consistent visual and semantic data from sparse inputs, enhancing the reconstruction process. Additionally, it introduces a Language Quantized Compressor to efficiently encode language embeddings, allowing for better generalization across different scenes without needing to retrain for each one.","title":"Revolutionizing 3D Reconstruction with Language-Embedded Insights"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents LangScene-X, a new framework for creating 3D structures from 2D images using language information. It addresses the limitations of previous methods that relied on dense-view reconstructions, which often resulted in poor quality when only limited views were available. LangScene-X utilizes a TriMap video diffusion model to generate consistent visual and semantic data from sparse inputs, enhancing the reconstruction process. Additionally, it introduces a Language Quantized Compressor to efficiently encode language embeddings, allowing for better generalization across different scenes without needing to retrain for each one.', title='Revolutionizing 3D Reconstruction with Language-Embedded Insights'))
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新颖的生成框架LangScene-X，用于从稀疏视图中恢复3D结构并进行场景理解。该框架结合了语言信息和多模态数据，能够生成一致的3D场景。我们首先训练了一个TriMap视频扩散模型，从稀疏输入中生成外观、几何和语义信息。通过引入语言量化压缩器（LQC），我们实现了跨场景的泛化，避免了逐场景的重新训练。","title":"LangScene-X：从稀疏视图生成一致的3D场景"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新颖的生成框架LangScene-X，用于从稀疏视图中恢复3D结构并进行场景理解。该框架结合了语言信息和多模态数据，能够生成一致的3D场景。我们首先训练了一个TriMap视频扩散模型，从稀疏输入中生成外观、几何和语义信息。通过引入语言量化压缩器（LQC），我们实现了跨场景的泛化，避免了逐场景的重新训练。', title='LangScene-X：从稀疏视图生成一致的3D场景'))
[04.07.2025 02:45] Querying the API.
[04.07.2025 02:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.
[04.07.2025 02:45] Response: {
  "desc": "Статья представляет новый набор данных предпочтений SynPref-40M, содержащий 40 миллионов пар предпочтений, созданный с помощью двухэтапного процесса, сочетающего человеческую аннотацию и масштабируемость ИИ. На основе этих данных авторы разработали набор моделей вознаграждения Skywork-Reward-V2 с параметрами от 0.6B до 8B. Модели демонстрируют высокую эффективность в различных задачах, включая соответствие человеческим предпочтениям, объективную корректность и безопасность. Исследование подчеркивает важность качественной курации данных и синергии человека и ИИ для улучшения моделей вознаграждения в обучении с подкреплением на основе обратной связи от человека (RLHF).",
  "emoji": "🤖",
  "title": "Синергия человека и ИИ для создания передовых моделей вознаграждения"
}
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality."

[04.07.2025 02:45] Response: ```python
["DATASET", "DATA", "RLHF", "TRAINING"]
```
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality."

[04.07.2025 02:45] Response: ```python
["ALIGNMENT", "OPEN_SOURCE"]
```
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the limitations of current reward models (RMs) in reinforcement learning from human feedback (RLHF), which struggle to accurately reflect complex human preferences. The authors propose a new large-scale preference dataset, SynPref-40M, containing 40 million preference pairs, to improve the training of RMs. They introduce a two-stage human-AI curation pipeline that combines human annotation with AI scalability to ensure high-quality data. The resulting Skywork-Reward-V2 models, trained on a refined subset of this dataset, demonstrate superior performance across various benchmarks, showcasing the importance of quality data in enhancing reward model effectiveness.","title":"Unlocking Human Preferences with Skywork-Reward-V2"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the limitations of current reward models (RMs) in reinforcement learning from human feedback (RLHF), which struggle to accurately reflect complex human preferences. The authors propose a new large-scale preference dataset, SynPref-40M, containing 40 million preference pairs, to improve the training of RMs. They introduce a two-stage human-AI curation pipeline that combines human annotation with AI scalability to ensure high-quality data. The resulting Skywork-Reward-V2 models, trained on a refined subset of this dataset, demonstrate superior performance across various benchmarks, showcasing the importance of quality data in enhancing reward model effectiveness.', title='Unlocking Human Preferences with Skywork-Reward-V2'))
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文探讨了奖励模型在从人类反馈中进行强化学习的重要性。当前的开放奖励模型在评估基准上表现不佳，无法有效捕捉人类偏好的复杂性。为了解决这一问题，作者提出了一个包含4000万对偏好的大规模数据集SynPref-40M，并设计了一个人机协作的两阶段数据处理流程。通过高质量的数据标注和AI的自动化处理，作者训练了Skywork-Reward-V2系列奖励模型，展示了其在多项基准测试中的优越性能。","title":"提升奖励模型的质量与性能"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文探讨了奖励模型在从人类反馈中进行强化学习的重要性。当前的开放奖励模型在评估基准上表现不佳，无法有效捕捉人类偏好的复杂性。为了解决这一问题，作者提出了一个包含4000万对偏好的大规模数据集SynPref-40M，并设计了一个人机协作的两阶段数据处理流程。通过高质量的数据标注和AI的自动化处理，作者训练了Skywork-Reward-V2系列奖励模型，展示了其在多项基准测试中的优越性能。', title='提升奖励模型的质量与性能'))
[04.07.2025 02:45] Querying the API.
[04.07.2025 02:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.
[04.07.2025 02:45] Response: {
  "desc": "Статья представляет новый метод обучения языковых моделей под названием WebSailor. Он направлен на преодоление когнитивных ограничений человека в задачах поиска сложной информации. WebSailor использует генерацию задач с высокой неопределенностью и обучение с подкреплением для развития способности моделей систематически снижать неопределенность. Результаты показывают, что WebSailor позволяет открытым моделям достичь производительности проприетарных систем в сложных информационных задачах.",
  "emoji": "🧭",
  "title": "WebSailor: навигация в океане неопределенности для ИИ"
}
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap."

[04.07.2025 02:45] Response: ```python
["RL", "AGENTS", "TRAINING"]
```
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap."

[04.07.2025 02:45] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses advancements in training large language models (LLMs) to surpass human cognitive limitations. It highlights the success of proprietary systems like DeepResearch, which excel in complex information-seeking tasks due to their unique reasoning abilities. The authors introduce WebSailor, a post-training methodology that enhances LLMs by generating high-uncertainty tasks and employing a novel reinforcement learning algorithm called Duplicating Sampling Policy Optimization (DUPO). The results show that WebSailor significantly improves the performance of open-source agents, enabling them to compete with proprietary models in challenging information retrieval scenarios.","title":"Empowering Open-Source Agents to Compete with the Best"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses advancements in training large language models (LLMs) to surpass human cognitive limitations. It highlights the success of proprietary systems like DeepResearch, which excel in complex information-seeking tasks due to their unique reasoning abilities. The authors introduce WebSailor, a post-training methodology that enhances LLMs by generating high-uncertainty tasks and employing a novel reinforcement learning algorithm called Duplicating Sampling Policy Optimization (DUPO). The results show that WebSailor significantly improves the performance of open-source agents, enabling them to compete with proprietary models in challenging information retrieval scenarios.', title='Empowering Open-Source Agents to Compete with the Best'))
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文探讨了超越人类认知局限性在大型语言模型（LLM）训练中的重要性。我们提出的WebSailor方法通过系统性地减少在广阔信息环境中导航时的极端不确定性，来提升模型的推理能力。该方法结合了结构化采样和信息模糊化等技术，生成新的高不确定性任务，并采用高效的强化学习算法进行训练。实验结果表明，WebSailor在复杂的信息检索任务中显著优于所有开源代理，缩小了与专有代理的能力差距。","title":"超越认知局限，提升信息检索能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文探讨了超越人类认知局限性在大型语言模型（LLM）训练中的重要性。我们提出的WebSailor方法通过系统性地减少在广阔信息环境中导航时的极端不确定性，来提升模型的推理能力。该方法结合了结构化采样和信息模糊化等技术，生成新的高不确定性任务，并采用高效的强化学习算法进行训练。实验结果表明，WebSailor在复杂的信息检索任务中显著优于所有开源代理，缩小了与专有代理的能力差距。', title='超越认知局限，提升信息检索能力'))
[04.07.2025 02:45] Querying the API.
[04.07.2025 02:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at https://github.com/ignorejjj/HiRA.
[04.07.2025 02:45] Response: {
  "desc": "Статья представляет HiRA - иерархическую систему для сложных информационных запросов. HiRA разделяет стратегическое планирование и специализированное выполнение задач, что позволяет эффективнее обрабатывать многоэтапные запросы. Система декомпозирует сложные задачи на подзадачи и назначает их специализированным агентам с внешними инструментами. Эксперименты показали, что HiRA превосходит современные RAG-системы и агентные подходы по качеству ответов и эффективности.",
  "emoji": "🧠",
  "title": "HiRA: Иерархический подход к сложному информационному поиску"
}
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at https://github.com/ignorejjj/HiRA."

[04.07.2025 02:45] Response: ```python
['RAG', 'AGENTS', 'MULTIMODAL', 'BENCHMARK']
```
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at https://github.com/ignorejjj/HiRA."

[04.07.2025 02:45] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents HiRA, a new framework designed to improve complex information retrieval tasks by separating high-level planning from detailed execution. Traditional methods often struggle because they use a single model for both tasks, which can lead to inefficiencies. HiRA addresses this by breaking down complex search tasks into smaller subtasks, each handled by specialized agents that have their own tools and reasoning abilities. The results show that HiRA outperforms existing systems in both the quality of answers and overall efficiency, demonstrating the benefits of this hierarchical approach.","title":"HiRA: Enhancing Search Efficiency through Hierarchical Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents HiRA, a new framework designed to improve complex information retrieval tasks by separating high-level planning from detailed execution. Traditional methods often struggle because they use a single model for both tasks, which can lead to inefficiencies. HiRA addresses this by breaking down complex search tasks into smaller subtasks, each handled by specialized agents that have their own tools and reasoning abilities. The results show that HiRA outperforms existing systems in both the quality of answers and overall efficiency, demonstrating the benefits of this hierarchical approach.', title='HiRA: Enhancing Search Efficiency through Hierarchical Reasoning'))
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"在现实世界的搜索场景中，复杂的信息需求需要深度推理和知识综合，而传统的检索增强生成（RAG）管道难以有效应对。当前的推理方法存在一个根本性限制：它们使用单一模型处理高层次规划和详细执行，导致推理效率低下和可扩展性有限。本文提出了HiRA，一个分层框架，将战略规划与专业执行分开。我们的研究表明，HiRA在复杂的跨模态深度搜索基准测试中显著优于现有的RAG和基于代理的系统，提升了答案质量和系统效率。","title":"HiRA：分层框架提升搜索效率与质量"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='在现实世界的搜索场景中，复杂的信息需求需要深度推理和知识综合，而传统的检索增强生成（RAG）管道难以有效应对。当前的推理方法存在一个根本性限制：它们使用单一模型处理高层次规划和详细执行，导致推理效率低下和可扩展性有限。本文提出了HiRA，一个分层框架，将战略规划与专业执行分开。我们的研究表明，HiRA在复杂的跨模态深度搜索基准测试中显著优于现有的RAG和基于代理的系统，提升了答案质量和系统效率。', title='HiRA：分层框架提升搜索效率与质量'))
[04.07.2025 02:45] Querying the API.
[04.07.2025 02:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency.   In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that 2-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention.
[04.07.2025 02:45] Response: {
  "desc": "В статье исследуется архитектура 2-симплициального трансформера, обобщающая стандартное внимание на основе скалярного произведения до трилинейных функций. Авторы показывают, что эта архитектура достигает лучшей эффективности использования токенов по сравнению со стандартными трансформерами. При фиксированном бюджете токенов модели сопоставимого размера превосходят аналоги со скалярным произведением в задачах математики, программирования, рассуждений и логики. Количественно преимущества выражаются в изменении показателя степени в законах масштабирования для задач, связанных со знаниями и рассуждениями.",
  "emoji": "🧠",
  "title": "Повышение эффективности языковых моделей с помощью 2-симплициального внимания"
}
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency.   In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that 2-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention."

[04.07.2025 02:45] Response: ```python
["ARCHITECTURE", "TRAINING", "MATH"]
```
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency.   In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that 2-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention."

[04.07.2025 02:45] Response: ```python
["OPTIMIZATION", "REASONING"]
```
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the limitations of current scaling laws in machine learning, particularly in the context of large language models that are no longer purely compute-bound due to their reliance on vast datasets. It introduces the 2-simplicial Transformer, a new architecture that enhances standard attention mechanisms by using trilinear functions, which improves token efficiency. The authors show that this new architecture allows models to perform better on various tasks, such as mathematics and reasoning, while using the same number of tokens. By quantifying the improvements, they reveal that the 2-simplicial attention modifies the scaling laws, leading to better performance in knowledge and reasoning tasks compared to traditional dot-product attention.","title":"Enhancing Token Efficiency with 2-Simplicial Transformers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores the limitations of current scaling laws in machine learning, particularly in the context of large language models that are no longer purely compute-bound due to their reliance on vast datasets. It introduces the 2-simplicial Transformer, a new architecture that enhances standard attention mechanisms by using trilinear functions, which improves token efficiency. The authors show that this new architecture allows models to perform better on various tasks, such as mathematics and reasoning, while using the same number of tokens. By quantifying the improvements, they reveal that the 2-simplicial attention modifies the scaling laws, leading to better performance in knowledge and reasoning tasks compared to traditional dot-product attention.', title='Enhancing Token Efficiency with 2-Simplicial Transformers'))
[04.07.2025 02:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"最近的研究表明，训练损失与模型大小和标记数量呈幂律关系，达到计算最优模型需要同时扩大模型大小和标记数量。然而，这些缩放法则假设数据是无限的，并主要适用于计算受限的环境。随着现代大型语言模型越来越依赖于大规模互联网数据集，这种假设变得不再有效。因此，我们需要优先考虑标记效率的架构。","title":"提升标记效率的2-单纯形变换器"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='最近的研究表明，训练损失与模型大小和标记数量呈幂律关系，达到计算最优模型需要同时扩大模型大小和标记数量。然而，这些缩放法则假设数据是无限的，并主要适用于计算受限的环境。随着现代大型语言模型越来越依赖于大规模互联网数据集，这种假设变得不再有效。因此，我们需要优先考虑标记效率的架构。', title='提升标记效率的2-单纯形变换器'))
[04.07.2025 02:45] Querying the API.
[04.07.2025 02:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale.
[04.07.2025 02:45] Response: {
  "desc": "Статья представляет новый подход к автоматическому доказательству теорем с использованием больших языковых моделей (LLM). Авторы предлагают фреймворк sG-MDP, в котором агенты генерируют и преследуют подцели на основе текущего состояния доказательства. Они применяют алгоритмы, подобные Monte Carlo Tree Search, для решения sG-MDP. Результатом является система Bourbaki (7B), которая достигает новых рекордных результатов на бенчмарке PutnamBench для моделей своего масштаба.",
  "emoji": "🧠",
  "title": "Самогенерируемые цели улучшают автоматическое доказательство теорем"
}
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale."

[04.07.2025 02:45] Response: ```python
['RL', 'BENCHMARK', 'AGENTS', 'ARCHITECTURE']
```
[04.07.2025 02:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale."

[04.07.2025 02:46] Response: ```python
["REASONING"]
```
[04.07.2025 02:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the difficulties that large language models (LLMs) face in reasoning tasks, particularly in automated theorem proving (ATP) where rewards are sparse and proofs are complex. The authors propose a novel framework called self-generated goal-conditioned MDPs (sG-MDPs), which allows agents to create and pursue subgoals based on the current state of the proof. By structuring goal generation, the problem becomes easier to navigate and search. The framework is implemented in a system called Bourbaki (7B), which utilizes multiple LLMs to enhance subgoal generation and tactic synthesis, achieving state-of-the-art results on the challenging PutnamBench benchmark.","title":"Empowering Reasoning with Self-Generated Goals in Theorem Proving"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the difficulties that large language models (LLMs) face in reasoning tasks, particularly in automated theorem proving (ATP) where rewards are sparse and proofs are complex. The authors propose a novel framework called self-generated goal-conditioned MDPs (sG-MDPs), which allows agents to create and pursue subgoals based on the current state of the proof. By structuring goal generation, the problem becomes easier to navigate and search. The framework is implemented in a system called Bourbaki (7B), which utilizes multiple LLMs to enhance subgoal generation and tactic synthesis, achieving state-of-the-art results on the challenging PutnamBench benchmark.', title='Empowering Reasoning with Self-Generated Goals in Theorem Proving'))
[04.07.2025 02:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了大型语言模型（LLMs）在自动定理证明（ATP）中的推理挑战，尤其是在稀疏奖励和证明规模庞大的情况下。为了解决这些问题，提出了一种新的框架——自生成目标条件马尔可夫决策过程（sG-MDPs），使得智能体能够根据不断变化的证明状态生成和追求子目标。通过这种结构化的目标生成，问题变得更易于搜索。最后，应用类似蒙特卡洛树搜索（MCTS）的算法解决sG-MDP，并在Bourbaki（7B）系统中实现，成功在PutnamBench上解决了26个问题，创造了新的最先进结果。","title":"自生成目标助力推理挑战"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了大型语言模型（LLMs）在自动定理证明（ATP）中的推理挑战，尤其是在稀疏奖励和证明规模庞大的情况下。为了解决这些问题，提出了一种新的框架——自生成目标条件马尔可夫决策过程（sG-MDPs），使得智能体能够根据不断变化的证明状态生成和追求子目标。通过这种结构化的目标生成，问题变得更易于搜索。最后，应用类似蒙特卡洛树搜索（MCTS）的算法解决sG-MDP，并在Bourbaki（7B）系统中实现，成功在PutnamBench上解决了26个问题，创造了新的最先进结果。', title='自生成目标助力推理挑战'))
[04.07.2025 02:46] Renaming data file.
[04.07.2025 02:46] Renaming previous data. hf_papers.json to ./d/2025-07-04.json
[04.07.2025 02:46] Saving new data file.
[04.07.2025 02:46] Generating page.
[04.07.2025 02:46] Renaming previous page.
[04.07.2025 02:46] Renaming previous data. index.html to ./d/2025-07-04.html
[04.07.2025 02:46] Writing result.
[04.07.2025 02:46] Renaming log file.
[04.07.2025 02:46] Renaming previous data. log.txt to ./logs/2025-07-04_last_log.txt
