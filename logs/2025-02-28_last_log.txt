[28.02.2025 03:19] Read previous papers.
[28.02.2025 03:19] Generating top page (month).
[28.02.2025 03:19] Writing top page (month).
[28.02.2025 04:13] Read previous papers.
[28.02.2025 04:13] Get feed.
[28.02.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19613
[28.02.2025 04:13] Extract page data from URL. URL: https://huggingface.co/papers/2502.20082
[28.02.2025 04:13] Extract page data from URL. URL: https://huggingface.co/papers/2502.20395
[28.02.2025 04:13] Extract page data from URL. URL: https://huggingface.co/papers/2502.16645
[28.02.2025 04:13] Extract page data from URL. URL: https://huggingface.co/papers/2502.20127
[28.02.2025 04:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.02.2025 04:13] No deleted papers detected.
[28.02.2025 04:13] Downloading and parsing papers (pdf, html). Total: 5.
[28.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.19613.
[28.02.2025 04:13] Extra JSON file exists (./assets/json/2502.19613.json), skip PDF parsing.
[28.02.2025 04:13] Paper image links file exists (./assets/img_data/2502.19613.json), skip HTML parsing.
[28.02.2025 04:13] Success.
[28.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.20082.
[28.02.2025 04:13] Downloading paper 2502.20082 from http://arxiv.org/pdf/2502.20082v1...
[28.02.2025 04:13] Extracting affiliations from text.
[28.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"LongRoPE2: Near-Lossless LLM Context Window Scaling Ning Shang * Li Lyna Zhang * Siyuan Wang Gaokai Zhang Gilsinia Lopez Fan Yang Weizhu Chen Mao Yang Microsoft 5 2 0 2 7 2 ] . [ 1 2 8 0 0 2 . 2 0 5 2 : r Abstract LongRoPE2 is novel approach that extends the effective context window of pre-trained large language models (LLMs) to the target length, while preserving the performance on the original shorter context window. This is achieved by three contributions: (1) hypothesis that insufficient training in higher RoPE dimensions contributes to the persistent out-of-distribution (OOD) issues observed in existing methods; (2) an effective RoPE rescaling algorithm that adopts evolutionary search guided by needle-driven perplexity to address the insufficient training problem; (3) mixed context window training approach that fine-tunes model weights to adopt rescaled RoPE for long-context sequences while preserving the short-context performance with the original RoPE. Extensive experiments on LLaMA38B and Phi3-mini-3.8B across various benchmarks validate the hypothesis and demonstrate the effectiveness of LongRoPE2. Remarkably, LongRoPE2 extends LLaMA3-8B to achieve 128K effective context length while retaining over 98.5% of short-context performance, using only 10B tokens 80x fewer than Metas approach, which fails to reach the target effective context length. Code will be available at https://github.com/microsoft/LongRoPE. A long context window has become an essential feature of Large Language Models (LLMs) (Achiam et al., 2023; Dubey et al., 2024; Abdin et al., 2024; Zhu et al., 2024; Team, 2024). For instance, 128k context window is now standard in recent LLMs like GPT-4o and LLaMA3.1. Context window extension is achieved through mid-training *Equal contribution. Siyuan Wang and Gaokai Zhang did this work during the internship at MSRA. Siyuan Wang: Shanghai Jiao Tong University; Gaokai Zhang: Zhejiang University. Correspondence to: Li Lyna Zhang <lzhani@microsoft.com>. 1 "
[28.02.2025 04:13] Response: ```python
["Microsoft", "Shanghai Jiao Tong University", "Zhejiang University"]
```
[28.02.2025 04:13] Deleting PDF ./assets/pdf/2502.20082.pdf.
[28.02.2025 04:13] Success.
[28.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.20395.
[28.02.2025 04:13] Downloading paper 2502.20395 from http://arxiv.org/pdf/2502.20395v1...
[28.02.2025 04:13] Extracting affiliations from text.
[28.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"R2-T2: Re-Routing in Test-Time for Multimodal Mixture-of-Experts Zhongyang Li 1 Ziyue Li 2 Tianyi Zhou 2 1Johns Hopkins University; 2University of Maryland, College Park zli300@jh.edu, {litzy619,tianyi}@umd.edu Project: https://github.com/tianyi-lab/R2-T2 5 2 0 2 7 2 ] . [ 1 5 9 3 0 2 . 2 0 5 2 : r a "
[28.02.2025 04:13] Response: ```python
["Johns Hopkins University", "University of Maryland, College Park"]
```
[28.02.2025 04:13] Deleting PDF ./assets/pdf/2502.20395.pdf.
[28.02.2025 04:13] Success.
[28.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.16645.
[28.02.2025 04:13] Downloading paper 2502.16645 from http://arxiv.org/pdf/2502.16645v1...
[28.02.2025 04:13] Extracting affiliations from text.
[28.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale Chenlong Wang * 1 Zhaoyang Chu * 1 Zhengxiang Cheng * 1 Xuyi Yang 2 Kaiyue Qiu 1 Yao Wan 1 Zhou Zhao 3 Xuanhua Shi 1 Dongping Chen 1 5 2 0 2 3 2 ] . [ 1 5 4 6 6 1 . 2 0 5 2 : r Abstract Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces identifying CODESYNC, data engine for outdated code patterns and collecting real-time code knowledge updates from Python thirdparty libraries. Building upon CODESYNC, we develop CODESYNCBENCH, comprehensive benchmark for assessing LLMs ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an updateaware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: https://github. com/Lucky-voyage/Code-Sync. 1. Introduction Large Language Models (LLMs), exemplified by DeepSeekR1 (Guo et al., 2025), CodeLlama (Roziere et al., 2023), and GPT-4o (OpenAI, 2024), have demonstrated remarkable *Equal contribution 1Huazhong University of Science and Technology 2Wuhuan University 3Zhejiang University. Correspondence to: Yao Wan <wanyao@hust.edu.c"
[28.02.2025 04:13] Response: ```python
["Huazhong University of Science and Technology", "Wuhuan University", "Zhejiang University"]
```
[28.02.2025 04:13] Deleting PDF ./assets/pdf/2502.16645.pdf.
[28.02.2025 04:13] Success.
[28.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.20127.
[28.02.2025 04:13] Downloading paper 2502.20127 from http://arxiv.org/pdf/2502.20127v1...
[28.02.2025 04:13] Extracting affiliations from text.
[28.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning Zexiong Ma* , Chao Peng, Pengfei Gao ,Xiangxin Meng , Yanzhen Zou, Bing Xie School of Computer Science, Peking University, ByteDance mazexiong@stu.pku.edu.cn, {zouyz, xiebing}@pku.edu.cn, {pengchao.x, gaopengfei.se, mengxiangxin.1219}@bytedance.com 5 2 0 2 7 2 ] . [ 1 7 2 1 0 2 . 2 0 5 2 : r a "
[28.02.2025 04:13] Response: ```python
["School of Computer Science, Peking University", "ByteDance"]
```
[28.02.2025 04:13] Deleting PDF ./assets/pdf/2502.20127.pdf.
[28.02.2025 04:13] Success.
[28.02.2025 04:13] Enriching papers with extra data.
[28.02.2025 04:13] ********************************************************************************
[28.02.2025 04:13] Abstract 0. We study self-rewarding reasoning large language models (LLMs), which can simultaneously generate step-by-step reasoning and evaluate the correctness of their outputs during the inference time-without external feedback. This integrated approach allows a single model to independently guide its reason...
[28.02.2025 04:13] ********************************************************************************
[28.02.2025 04:13] Abstract 1. LongRoPE2 is a novel approach that extends the effective context window of pre-trained large language models (LLMs) to the target length, while preserving the performance on the original shorter context window. This is achieved by three contributions: (1) a hypothesis that insufficient training in h...
[28.02.2025 04:13] ********************************************************************************
[28.02.2025 04:13] Abstract 2. In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks. This weakness has been recently mitig...
[28.02.2025 04:13] ********************************************************************************
[28.02.2025 04:13] Abstract 3. Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, of...
[28.02.2025 04:13] ********************************************************************************
[28.02.2025 04:13] Abstract 4. Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose Subtask-oriented Rein...
[28.02.2025 04:13] Read previous papers.
[28.02.2025 04:13] Generating reviews via LLM API.
[28.02.2025 04:13] Using data from previous issue: {"categories": ["#reasoning", "#training", "#inference", "#optimization", "#rl"], "emoji": "🤖", "ru": {"title": "Самокорректирующиеся языковые модели: новый шаг к автономному ИИ", "desc": "Исследователи изучают языковые модели с самовознаграждением, способные генерировать пошаговые рассуждения и оце
[28.02.2025 04:13] Querying the API.
[28.02.2025 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

LongRoPE2 is a novel approach that extends the effective context window of pre-trained large language models (LLMs) to the target length, while preserving the performance on the original shorter context window. This is achieved by three contributions: (1) a hypothesis that insufficient training in higher RoPE dimensions contributes to the persistent out-of-distribution (OOD) issues observed in existing methods; (2) an effective RoPE rescaling algorithm that adopts evolutionary search guided by "needle-driven" perplexity to address the insufficient training problem; (3) a mixed context window training approach that fine-tunes model weights to adopt rescaled RoPE for long-context sequences while preserving the short-context performance with the original RoPE. Extensive experiments on LLaMA3-8B and Phi3-mini-3.8B across various benchmarks validate the hypothesis and demonstrate the effectiveness of LongRoPE2. Remarkably, LongRoPE2 extends LLaMA3-8B to achieve a 128K effective context length while retaining over 98.5% of short-context performance, using only 10B tokens -- 80x fewer than Meta's approach, which fails to reach the target effective context length. Code will be available at https://github.com/microsoft/LongRoPE.
[28.02.2025 04:13] Response: {
  "desc": "LongRoPE2 - это новый подход к расширению эффективного контекстного окна предобученных больших языковых моделей (LLM) до целевой длины. Метод основан на гипотезе о недостаточном обучении в высших измерениях RoPE и использует эволюционный поиск для эффективного масштабирования RoPE. LongRoPE2 применяет смешанное обучение на контекстах разной длины для адаптации весов модели. Эксперименты показали, что LongRoPE2 может расширить контекст LLaMA3-8B до 128 тысяч токенов, сохраняя производительность на коротких контекстах.",
  "emoji": "🔬",
  "title": "Расширение контекста языковых моделей без потери качества"
}
[28.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LongRoPE2 is a novel approach that extends the effective context window of pre-trained large language models (LLMs) to the target length, while preserving the performance on the original shorter context window. This is achieved by three contributions: (1) a hypothesis that insufficient training in higher RoPE dimensions contributes to the persistent out-of-distribution (OOD) issues observed in existing methods; (2) an effective RoPE rescaling algorithm that adopts evolutionary search guided by "needle-driven" perplexity to address the insufficient training problem; (3) a mixed context window training approach that fine-tunes model weights to adopt rescaled RoPE for long-context sequences while preserving the short-context performance with the original RoPE. Extensive experiments on LLaMA3-8B and Phi3-mini-3.8B across various benchmarks validate the hypothesis and demonstrate the effectiveness of LongRoPE2. Remarkably, LongRoPE2 extends LLaMA3-8B to achieve a 128K effective context length while retaining over 98.5% of short-context performance, using only 10B tokens -- 80x fewer than Meta's approach, which fails to reach the target effective context length. Code will be available at https://github.com/microsoft/LongRoPE."

[28.02.2025 04:13] Response: ```python
["TRAINING", "ARCHITECTURE", "BENCHMARK"]
```
[28.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LongRoPE2 is a novel approach that extends the effective context window of pre-trained large language models (LLMs) to the target length, while preserving the performance on the original shorter context window. This is achieved by three contributions: (1) a hypothesis that insufficient training in higher RoPE dimensions contributes to the persistent out-of-distribution (OOD) issues observed in existing methods; (2) an effective RoPE rescaling algorithm that adopts evolutionary search guided by "needle-driven" perplexity to address the insufficient training problem; (3) a mixed context window training approach that fine-tunes model weights to adopt rescaled RoPE for long-context sequences while preserving the short-context performance with the original RoPE. Extensive experiments on LLaMA3-8B and Phi3-mini-3.8B across various benchmarks validate the hypothesis and demonstrate the effectiveness of LongRoPE2. Remarkably, LongRoPE2 extends LLaMA3-8B to achieve a 128K effective context length while retaining over 98.5% of short-context performance, using only 10B tokens -- 80x fewer than Meta's approach, which fails to reach the target effective context length. Code will be available at https://github.com/microsoft/LongRoPE."

[28.02.2025 04:13] Response: ```python
["LONG_CONTEXT"]
```
[28.02.2025 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LongRoPE2 is a new method that enhances the context length of large language models (LLMs) while maintaining their performance on shorter contexts. It introduces a hypothesis that inadequate training in higher dimensions of RoPE leads to out-of-distribution issues in existing models. The method employs a RoPE rescaling algorithm that uses evolutionary search to improve training effectiveness. Additionally, it utilizes a mixed context window training strategy to fine-tune model weights, allowing for long-context sequences without sacrificing short-context performance.","title":"Extending Context Length Without Compromise"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LongRoPE2 is a new method that enhances the context length of large language models (LLMs) while maintaining their performance on shorter contexts. It introduces a hypothesis that inadequate training in higher dimensions of RoPE leads to out-of-distribution issues in existing models. The method employs a RoPE rescaling algorithm that uses evolutionary search to improve training effectiveness. Additionally, it utilizes a mixed context window training strategy to fine-tune model weights, allowing for long-context sequences without sacrificing short-context performance.', title='Extending Context Length Without Compromise'))
[28.02.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LongRoPE2是一种新方法，旨在扩展预训练大型语言模型（LLMs）的有效上下文窗口，同时保持在原始较短上下文窗口上的性能。该方法通过三个贡献实现：首先，提出了一个假设，认为在更高RoPE维度上的训练不足导致了现有方法中持续存在的分布外（OOD）问题；其次，提出了一种有效的RoPE重缩放算法，通过“针驱动”的困惑度指导的进化搜索来解决训练不足的问题；最后，采用混合上下文窗口训练方法，微调模型权重以适应长上下文序列的重缩放RoPE，同时保持短上下文的原始RoPE性能。","title":"扩展上下文窗口，保持性能的创新方法"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LongRoPE2是一种新方法，旨在扩展预训练大型语言模型（LLMs）的有效上下文窗口，同时保持在原始较短上下文窗口上的性能。该方法通过三个贡献实现：首先，提出了一个假设，认为在更高RoPE维度上的训练不足导致了现有方法中持续存在的分布外（OOD）问题；其次，提出了一种有效的RoPE重缩放算法，通过“针驱动”的困惑度指导的进化搜索来解决训练不足的问题；最后，采用混合上下文窗口训练方法，微调模型权重以适应长上下文序列的重缩放RoPE，同时保持短上下文的原始RoPE性能。', title='扩展上下文窗口，保持性能的创新方法'))
[28.02.2025 04:14] Querying the API.
[28.02.2025 04:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks. This weakness has been recently mitigated by replacing the vision encoder with a mixture-of-experts (MoE), which provides rich, multi-granularity, and diverse representations required by diverse downstream tasks. The performance of multimodal MoE largely depends on its router, which reweights and mixes the representations of different experts for each input. However, we find that the end-to-end trained router does not always produce the optimal routing weights for every test sample. To bridge the gap, we propose a novel and efficient method "Re-Routing in Test-Time(R2-T2) that locally optimizes the vector of routing weights in test-time by moving it toward those vectors of the correctly predicted samples in a neighborhood of the test sample. We propose three R2-T2 strategies with different optimization objectives and neighbor-search spaces. R2-T2 consistently and greatly improves state-of-the-art LMMs' performance on challenging benchmarks of diverse tasks, without training any base-model parameters.
[28.02.2025 04:14] Response: {
  "desc": "В статье представлен метод Re-Routing in Test-Time (R2-T2) для улучшения работы мультимодальных моделей на основе смеси экспертов (MoE). Авторы обнаружили, что маршрутизатор, обученный по принципу end-to-end, не всегда оптимально распределяет веса между экспертами для тестовых образцов. R2-T2 оптимизирует вектор весов маршрутизации во время тестирования, приближая его к векторам правильно предсказанных соседних образцов. Предложены три стратегии R2-T2 с различными целями оптимизации и пространствами поиска соседей.",
  "emoji": "🔀",
  "title": "Оптимизация маршрутизации на лету для повышения эффективности мультимодальных моделей"
}
[28.02.2025 04:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks. This weakness has been recently mitigated by replacing the vision encoder with a mixture-of-experts (MoE), which provides rich, multi-granularity, and diverse representations required by diverse downstream tasks. The performance of multimodal MoE largely depends on its router, which reweights and mixes the representations of different experts for each input. However, we find that the end-to-end trained router does not always produce the optimal routing weights for every test sample. To bridge the gap, we propose a novel and efficient method "Re-Routing in Test-Time(R2-T2) that locally optimizes the vector of routing weights in test-time by moving it toward those vectors of the correctly predicted samples in a neighborhood of the test sample. We propose three R2-T2 strategies with different optimization objectives and neighbor-search spaces. R2-T2 consistently and greatly improves state-of-the-art LMMs' performance on challenging benchmarks of diverse tasks, without training any base-model parameters."

[28.02.2025 04:14] Response: ```python
['MULTIMODAL', 'BENCHMARK', 'ARCHITECTURE', 'TRAINING']
```
[28.02.2025 04:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks. This weakness has been recently mitigated by replacing the vision encoder with a mixture-of-experts (MoE), which provides rich, multi-granularity, and diverse representations required by diverse downstream tasks. The performance of multimodal MoE largely depends on its router, which reweights and mixes the representations of different experts for each input. However, we find that the end-to-end trained router does not always produce the optimal routing weights for every test sample. To bridge the gap, we propose a novel and efficient method "Re-Routing in Test-Time(R2-T2) that locally optimizes the vector of routing weights in test-time by moving it toward those vectors of the correctly predicted samples in a neighborhood of the test sample. We propose three R2-T2 strategies with different optimization objectives and neighbor-search spaces. R2-T2 consistently and greatly improves state-of-the-art LMMs' performance on challenging benchmarks of diverse tasks, without training any base-model parameters."

[28.02.2025 04:14] Response: ```python
["OPTIMIZATION"]
```
[28.02.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the performance gap in large multimodal models (LMMs) when processing non-language data compared to large language models (LLMs). The authors introduce a mixture-of-experts (MoE) approach to enhance the vision encoder, allowing for richer and more diverse representations. They identify that the router, which determines how to mix these expert representations, often fails to optimize routing weights effectively during testing. To solve this, they propose a method called Re-Routing in Test-Time (R2-T2), which fine-tunes routing weights based on nearby correctly predicted samples, significantly boosting the performance of LMMs on various challenging tasks without retraining the base model.","title":"Optimizing Multimodal Performance with Test-Time Re-Routing"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the performance gap in large multimodal models (LMMs) when processing non-language data compared to large language models (LLMs). The authors introduce a mixture-of-experts (MoE) approach to enhance the vision encoder, allowing for richer and more diverse representations. They identify that the router, which determines how to mix these expert representations, often fails to optimize routing weights effectively during testing. To solve this, they propose a method called Re-Routing in Test-Time (R2-T2), which fine-tunes routing weights based on nearby correctly predicted samples, significantly boosting the performance of LMMs on various challenging tasks without retraining the base model.', title='Optimizing Multimodal Performance with Test-Time Re-Routing'))
[28.02.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"在大型多模态模型（LMMs）中，视觉表示的感知能力通常不如大型语言模型（LLMs）的推理能力，这影响了LMMs在复杂任务上的表现。最近，通过用专家混合（MoE）替换视觉编码器，缓解了这一弱点，提供了丰富且多样的表示。我们发现，端到端训练的路由器并不总能为每个测试样本生成最佳的路由权重。为了解决这个问题，我们提出了一种新颖且高效的方法“测试时重新路由（R2-T2）”，通过在测试时优化路由权重向量，显著提升了LMMs在多样化任务基准上的表现。","title":"提升多模态模型性能的新方法"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='在大型多模态模型（LMMs）中，视觉表示的感知能力通常不如大型语言模型（LLMs）的推理能力，这影响了LMMs在复杂任务上的表现。最近，通过用专家混合（MoE）替换视觉编码器，缓解了这一弱点，提供了丰富且多样的表示。我们发现，端到端训练的路由器并不总能为每个测试样本生成最佳的路由权重。为了解决这个问题，我们提出了一种新颖且高效的方法“测试时重新路由（R2-T2）”，通过在测试时优化路由权重向量，显著提升了LMMs在多样化任务基准上的表现。', title='提升多模态模型性能的新方法'))
[28.02.2025 04:14] Querying the API.
[28.02.2025 04:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces CODESYNC, a data engine for identifying outdated code patterns and collecting real-time code knowledge updates from Python third-party libraries. Building upon CODESYNC, we develop CODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an update-aware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer a strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: https://github.com/Lucky-voyage/Code-Sync.
[28.02.2025 04:14] Response: {
  "desc": "Статья представляет CODESYNC - инструмент для выявления устаревших паттернов кода и сбора обновлений знаний о коде из сторонних библиотек Python в реальном времени. На основе CODESYNC разработан CODESYNCBENCH - комплексный бенчмарк для оценки способности моделей большого языка (LLM) синхронизироваться с эволюцией кода, охватывающий реальные обновления для 220 API из шести библиотек Python. Эксперименты на 14 современных LLM показали, что они испытывают трудности с динамической эволюцией кода даже при поддержке продвинутых методов обновления знаний. Авторы полагают, что их бенчмарк может стать основой для разработки более эффективных методов обновления знаний о коде в реальном времени.",
  "emoji": "🔄",
  "title": "Синхронизация языковых моделей с эволюцией кода"
}
[28.02.2025 04:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces CODESYNC, a data engine for identifying outdated code patterns and collecting real-time code knowledge updates from Python third-party libraries. Building upon CODESYNC, we develop CODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an update-aware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer a strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: https://github.com/Lucky-voyage/Code-Sync."

[28.02.2025 04:14] Response: ```python
['DATASET', 'DATA', 'BENCHMARK']
```
[28.02.2025 04:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces CODESYNC, a data engine for identifying outdated code patterns and collecting real-time code knowledge updates from Python third-party libraries. Building upon CODESYNC, we develop CODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an update-aware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer a strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: https://github.com/Lucky-voyage/Code-Sync."

[28.02.2025 04:14] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```
[28.02.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the limitations of Large Language Models (LLMs) in adapting to changes in third-party library APIs, which can lead to outdated or inefficient code. It introduces CODESYNC, a data engine designed to identify outdated code patterns and gather real-time updates from Python libraries. Additionally, the authors present CODESYNCBENCH, a benchmark for evaluating LLMs\' performance in keeping up with code evolution, featuring 3,300 test cases across various tasks. The findings indicate that even advanced LLMs struggle with dynamic code changes, highlighting the need for improved methods for real-time code knowledge updating.","title":"CODESYNC: Keeping Code Knowledge Fresh for LLMs"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper addresses the limitations of Large Language Models (LLMs) in adapting to changes in third-party library APIs, which can lead to outdated or inefficient code. It introduces CODESYNC, a data engine designed to identify outdated code patterns and gather real-time updates from Python libraries. Additionally, the authors present CODESYNCBENCH, a benchmark for evaluating LLMs' performance in keeping up with code evolution, featuring 3,300 test cases across various tasks. The findings indicate that even advanced LLMs struggle with dynamic code changes, highlighting the need for improved methods for real-time code knowledge updating.", title='CODESYNC: Keeping Code Knowledge Fresh for LLMs'))
[28.02.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型语言模型（LLMs）在软件工程中表现出色，但在适应不断变化的代码知识方面面临挑战，尤其是第三方库API的频繁更新。由于静态的预训练数据集，这种限制常常导致生成的代码无法执行或实现的安全性和效率不佳。为了解决这个问题，本文提出了CODESYNC，一个用于识别过时代码模式并收集来自Python第三方库的实时代码知识更新的数据引擎。基于CODESYNC，我们开发了CODESYNCBENCH，一个全面的基准测试，用于评估LLMs在代码演变中的同步能力，涵盖了来自六个Python库的220个API的真实更新。","title":"实时代码知识更新的基准测试"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='大型语言模型（LLMs）在软件工程中表现出色，但在适应不断变化的代码知识方面面临挑战，尤其是第三方库API的频繁更新。由于静态的预训练数据集，这种限制常常导致生成的代码无法执行或实现的安全性和效率不佳。为了解决这个问题，本文提出了CODESYNC，一个用于识别过时代码模式并收集来自Python第三方库的实时代码知识更新的数据引擎。基于CODESYNC，我们开发了CODESYNCBENCH，一个全面的基准测试，用于评估LLMs在代码演变中的同步能力，涵盖了来自六个Python库的220个API的真实更新。', title='实时代码知识更新的基准测试'))
[28.02.2025 04:14] Querying the API.
[28.02.2025 04:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose Subtask-oriented Reinforced Fine-Tuning (SoRFT), a novel training approach to enhance the issue resolving capability of LLMs. We decomposes issue resolving into structured subtasks: file localization, function localization, line localization, and code edit generation. SoRFT consists of two training stages: (1) rejection-sampled supervised fine-tuning, Chain of Thought (CoT) data is filtered using ground-truth before fine-tuning the LLM, and (2) rule-based reinforcement learning, which leverages PPO with ground-truth based rewards. We evaluate the SoRFT-trained model on SWE-Bench Verified and SWE-Bench Lite, achieving state-of-the-art (SOTA) performance among open-source models (e.g., resolve 21.4% issues on SWE-Bench Verified with SoRFT-Qwen-7B). The experimental results demonstrate that SoRFT significantly enhances issue-resolving performance, improves model generalization, and provides a cost-efficient alternative to commercial models.
[28.02.2025 04:14] Response: {
  "desc": "Авторы предлагают новый подход к обучению языковых моделей для решения проблем в программном коде - Subtask-oriented Reinforced Fine-Tuning (SoRFT). Метод разбивает задачу на подзадачи: локализацию файла, функции и строки кода, а также генерацию исправлений. SoRFT включает два этапа обучения: тонкую настройку с отбором данных и обучение с подкреплением на основе правил. Эксперименты показывают, что SoRFT значительно улучшает способность моделей решать проблемы в коде и обеспечивает экономичную альтернативу коммерческим моделям.",
  "emoji": "🔧",
  "title": "SoRFT: Эффективное обучение ЯМ для автоматического исправления кода"
}
[28.02.2025 04:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose Subtask-oriented Reinforced Fine-Tuning (SoRFT), a novel training approach to enhance the issue resolving capability of LLMs. We decomposes issue resolving into structured subtasks: file localization, function localization, line localization, and code edit generation. SoRFT consists of two training stages: (1) rejection-sampled supervised fine-tuning, Chain of Thought (CoT) data is filtered using ground-truth before fine-tuning the LLM, and (2) rule-based reinforcement learning, which leverages PPO with ground-truth based rewards. We evaluate the SoRFT-trained model on SWE-Bench Verified and SWE-Bench Lite, achieving state-of-the-art (SOTA) performance among open-source models (e.g., resolve 21.4% issues on SWE-Bench Verified with SoRFT-Qwen-7B). The experimental results demonstrate that SoRFT significantly enhances issue-resolving performance, improves model generalization, and provides a cost-efficient alternative to commercial models."

[28.02.2025 04:14] Response: ```python
["TRAINING", "RL", "RLHF"]
```
[28.02.2025 04:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose Subtask-oriented Reinforced Fine-Tuning (SoRFT), a novel training approach to enhance the issue resolving capability of LLMs. We decomposes issue resolving into structured subtasks: file localization, function localization, line localization, and code edit generation. SoRFT consists of two training stages: (1) rejection-sampled supervised fine-tuning, Chain of Thought (CoT) data is filtered using ground-truth before fine-tuning the LLM, and (2) rule-based reinforcement learning, which leverages PPO with ground-truth based rewards. We evaluate the SoRFT-trained model on SWE-Bench Verified and SWE-Bench Lite, achieving state-of-the-art (SOTA) performance among open-source models (e.g., resolve 21.4% issues on SWE-Bench Verified with SoRFT-Qwen-7B). The experimental results demonstrate that SoRFT significantly enhances issue-resolving performance, improves model generalization, and provides a cost-efficient alternative to commercial models."

[28.02.2025 04:14] Response: ```python
["OPEN_SOURCE", "OPTIMIZATION"]
```
[28.02.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Subtask-oriented Reinforced Fine-Tuning (SoRFT), a new method designed to improve the issue-resolving capabilities of large language models (LLMs). It breaks down the issue resolution process into specific subtasks, such as file and function localization, and code editing. The training process involves two stages: first, a supervised fine-tuning phase that uses filtered data, and second, a reinforcement learning phase that applies Proximal Policy Optimization (PPO) with rewards based on ground-truth data. The results show that models trained with SoRFT outperform existing open-source models, achieving state-of-the-art results while being more cost-effective and maintaining better privacy.","title":"Enhancing Issue Resolution with SoRFT: A Cost-Effective Approach"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Subtask-oriented Reinforced Fine-Tuning (SoRFT), a new method designed to improve the issue-resolving capabilities of large language models (LLMs). It breaks down the issue resolution process into specific subtasks, such as file and function localization, and code editing. The training process involves two stages: first, a supervised fine-tuning phase that uses filtered data, and second, a reinforcement learning phase that applies Proximal Policy Optimization (PPO) with rewards based on ground-truth data. The results show that models trained with SoRFT outperform existing open-source models, achieving state-of-the-art results while being more cost-effective and maintaining better privacy.', title='Enhancing Issue Resolution with SoRFT: A Cost-Effective Approach'))
[28.02.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种新的训练方法，称为子任务导向强化微调（SoRFT），旨在提高大型语言模型（LLMs）在问题解决方面的能力。我们将问题解决分解为结构化的子任务，包括文件定位、功能定位、行定位和代码编辑生成。SoRFT包含两个训练阶段：首先是基于拒绝采样的监督微调，其次是基于规则的强化学习，利用基于真实数据的奖励进行训练。实验结果表明，SoRFT显著提升了问题解决性能，改善了模型的泛化能力，并为商业模型提供了一种成本效益高的替代方案。","title":"提升问题解决能力的新方法"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种新的训练方法，称为子任务导向强化微调（SoRFT），旨在提高大型语言模型（LLMs）在问题解决方面的能力。我们将问题解决分解为结构化的子任务，包括文件定位、功能定位、行定位和代码编辑生成。SoRFT包含两个训练阶段：首先是基于拒绝采样的监督微调，其次是基于规则的强化学习，利用基于真实数据的奖励进行训练。实验结果表明，SoRFT显著提升了问题解决性能，改善了模型的泛化能力，并为商业模型提供了一种成本效益高的替代方案。', title='提升问题解决能力的新方法'))
[28.02.2025 04:14] Loading Chinese text from previous data.
[28.02.2025 04:14] Renaming data file.
[28.02.2025 04:14] Renaming previous data. hf_papers.json to ./d/2025-02-28.json
[28.02.2025 04:14] Saving new data file.
[28.02.2025 04:14] Generating page.
[28.02.2025 04:14] Renaming previous page.
[28.02.2025 04:14] Renaming previous data. index.html to ./d/2025-02-28.html
[28.02.2025 04:14] [Experimental] Generating Chinese page for reading.
[28.02.2025 04:14] Chinese vocab [{'word': '介绍', 'pinyin': 'jièshào', 'trans': 'introduce'}, {'word': '双语', 'pinyin': 'shuāngyǔ', 'trans': 'bilingual'}, {'word': '计算成本', 'pinyin': 'jìsuàn chéngběn', 'trans': 'computational cost'}, {'word': '显著', 'pinyin': 'xiǎnzhù', 'trans': 'significant'}, {'word': '预训练', 'pinyin': 'yù xùnliàn', 'trans': 'pre-training'}, {'word': '高质量', 'pinyin': 'gāo zhìliàng', 'trans': 'high-quality'}, {'word': '过滤', 'pinyin': 'guòlǜ', 'trans': 'filter'}, {'word': '分阶段', 'pinyin': 'fēn jiēduàn', 'trans': 'phased'}, {'word': '深度扩展', 'pinyin': 'shēndù kuòzhǎn', 'trans': 'deep expansion'}, {'word': '剪枝', 'pinyin': 'jiǎnzhī', 'trans': 'pruning'}, {'word': '蒸馏', 'pinyin': 'zhēngliú', 'trans': 'distillation'}, {'word': '监督微调', 'pinyin': 'jiàndū wēitiáo', 'trans': 'supervised fine-tuning'}, {'word': '偏好优化', 'pinyin': 'piānhào yōuhuà', 'trans': 'preference optimization'}, {'word': '互动', 'pinyin': 'hùdòng', 'trans': 'interaction'}, {'word': '嵌入', 'pinyin': 'qiànrù', 'trans': 'embedding'}, {'word': '检索增强生成', 'pinyin': 'jiǎnsuǒ zēngqiáng shēngchéng', 'trans': 'retrieval-augmented generation'}, {'word': '函数调用', 'pinyin': 'hánshù diàoyòng', 'trans': 'function call'}, {'word': '参数', 'pinyin': 'cānshù', 'trans': 'parameters'}, {'word': '公开发布', 'pinyin': 'gōngkāi fābù', 'trans': 'publicly released'}, {'word': '促进', 'pinyin': 'cùjìn', 'trans': 'promote'}]
[28.02.2025 04:14] Renaming previous Chinese page.
[28.02.2025 04:14] Renaming previous data. zh.html to ./d/2025-02-27_zh_reading_task.html
[28.02.2025 04:14] Writing Chinese reading task.
[28.02.2025 04:14] Writing result.
[28.02.2025 04:14] Renaming log file.
[28.02.2025 04:14] Renaming previous data. log.txt to ./logs/2025-02-28_last_log.txt
