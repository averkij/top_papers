[05.09.2025 04:14] Read previous papers.
[05.09.2025 04:14] Generating top page (month).
[05.09.2025 04:14] Writing top page (month).
[05.09.2025 05:11] Read previous papers.
[05.09.2025 05:11] Get feed.
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04419
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01396
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04394
[05.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.04338
[05.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.04406
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18733
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04434
[05.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.04292
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03888
[05.09.2025 05:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.09.2025 05:11] No deleted papers detected.
[05.09.2025 05:11] Downloading and parsing papers (pdf, html). Total: 9.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04419.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.04419.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.04419.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.01396.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.01396.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.01396.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04394.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.04394.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.04394.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04338.
[05.09.2025 05:11] Downloading paper 2509.04338 from http://arxiv.org/pdf/2509.04338v1...
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 ] . [ 1 8 3 3 4 0 . 9 0 5 2 : r FROM EDITOR TO DENSE GEOMETRY ESTIMATOR Jiyuan Wang1,2 Chunyu Lin1 (cid:66) Lei Sun2 Rongying Liu1 Lang Nie3 Mingxing Li2 Kang Liao4 Xiangxiang Chu2 Yao Zhao1 1BJTU 2AMAP Alibaba Group 3CQUPT 4NTU Figure 1: We present FE2E, DiT-based foundation model for monocular dense geometry prediction. Trained with limited supervision, FE2E achieves promising performance improvements in zero-shot depth and normal estimation. Bar length indicates the average ranking across all metrics from multiple datasets, where lower values are better. represents the amount of training data used. ABSTRACT Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be more suitable foundation for fine-tuning. Motivated by this, we conduct systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by refining their innate features, and ultimately achieve higher performance than their generative counterparts. Based on these findings, we introduce FE2E, framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editors original flow matching loss into the consistent velocity training objective. And we use logarithmic quantization to resolve the precision conflict between the editors native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiTs global attention for cost-free joint estimation of depth and normals in single forward pass, enabling their supervisory signals to mutually enhance eac"
[05.09.2025 05:11] Response: ```python
["BJTU", "AMAP Alibaba Group", "CQUPT", "NTU"]
```
[05.09.2025 05:11] Deleting PDF ./assets/pdf/2509.04338.pdf.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04406.
[05.09.2025 05:11] Downloading paper 2509.04406 from http://arxiv.org/pdf/2509.04406v1...
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 ] . [ 1 6 0 4 4 0 . 9 0 5 2 : r Few-step Flow for 3D Generation via Marginal-Data Transport Distillation Zanwei Zhou1, Taoran Yi2, Jiemin Fang3, Chen Yang3 Lingxi Xie3 Xinggang Wang2 Wei Shen1, Qi Tian3 1Shanghai Jiao Tong University 2Huazhong University of Science and Technology 3Huawei Inc. sjtu19zzw, wei.shen @sjtu.edu.cn { jaminfong, chenyang.res, 198808xc } taoranyi, xgwang @hust.edu.cn } tian.qi1@huawei.com { @gmail.com } https://github.com/Zanue/MDT-dist { "
[05.09.2025 05:11] Response: ```python
["Shanghai Jiao Tong University", "Huazhong University of Science and Technology", "Huawei Inc."]
```
[05.09.2025 05:11] Deleting PDF ./assets/pdf/2509.04406.pdf.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2508.18733.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2508.18733.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2508.18733.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04434.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.04434.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.04434.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04292.
[05.09.2025 05:11] Downloading paper 2509.04292 from http://arxiv.org/pdf/2509.04292v1...
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions? 5 2 0 2 4 ] . [ 1 2 9 2 4 0 . 9 0 5 2 : r a "
[05.09.2025 05:11] Response: []
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?5 2 0 2 4 ] . [ 1 2 9 2 4 0 . 9 0 5 2 : r aLarge Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using human-in-the-loop pipeline, we construct dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both diagnostic tool and foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios. Date: September 5, 2025 Correspondence: Jiaheng Liu at liujiaheng@nju.edu.cn, Zaiyuan Wang at wangzaiyuan@bytedance.com, Qinyan Zhang at zhangqinyan.25@jiyunhudong.com Project Page: https://huggingface.co/datasets/m-a-p/Inverse_IFEvalLarge Language Models (LLMs) have rapidly advanced in recent years, achieving remarkable success across wide spectrum of natural language processing (NLP) tasks, including question answering [23, 35], reasoning [9, 26], summarization [33], and code generation [16, 25, 27]. Their capabilities are largely attributed to massive pretraining on large-scale corpora followed by supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). However, while these models excel under conventional conditions, their robustness in handling atypical or counterintuitive instructions remains underexplored. As shown in Figure 1, there exists marked difference in the models instruction-following performance when responding to conventional instructions versus counterintuitive instructions. Specifically, when confronted with directives such as You must strictly avoid using bullet point format, the model frequently fails to comply. In such cases, users often respond with frustration, exclaiming: 1 Do As Say, Not As You Were Trained !! This raises several important questions: What underlying factors lead to such failures? Which types of counterintuitive instructions are models more prone to disregard? Ultimately, we are left with fundamental inquiry: Can LLMs unlearn stubborn training conventions in order to follow real instructions? key limitation arises from the nature of data annotation. In practice, annotation processes tend to follow an idealized paradigmthat is, annotators generate responses aligned with standardized formats, correctness norms, and readability principles. As result, LLMs trained on such corpora inherit strong inductive bias toward these conventions. While this paradigm ensures fluent and factual outputs, it also creates what we term cognitive inertia: models struggle when tasked with instructions that explicitly deviate from their training norms. Closely related is the risk of overfitting: when models become overly attuned to post-training patterns, they may lose flexibility and fail to generalize beyond the narrow conventions reinforced during annotation. For instance, an instruction requiring an unstructured essay with no paragraph breaks, or deliberately incorrect answers to simple factual questions, directly conflicts with patterns reinforced during SFT. This tension motivates the development of new evaluation dimensionCounterintuitive Abilitywhich measures whether an LLM can override its ingrained training conventions and faithfully follow counterintuitive instructions. Such an ability is crucial for assessing genuine instruction-following robustness, as real-world applications often involve unconventional, ambiguous, or dynamically shifting requirements. To this end, we introduce Inverse IFEval, novel benchmark specifically designed to evaluate LLMs under counter-intuitive instruction scenarios, which we refer to as inverse instructions. In practice, there will always be long-tail user needs that post-training fails to cover. Although such instructions may not be as extreme as those deliberately constructed in Inverse IFEval, we argue that this benchmark captures an essential aspect of model robustness: the ability to follow out-of-distribution (OOD) instructions. Unlike prior benchmarks such as MMLU or IFEval, which primarily assess factuality or knowledge recall, Inverse IFEval systematically inverts conventional training paradigms to create eight categories of challenging instructions: (1) Question Correction, (2) Intentional Textual Flaws, (3) Code without Comments, (4) Counter-Conventional Formatting, (5) Deliberately Incorrect Answers, (6) Instructional Induction, (7) Mid-turn Instruction Modification, and (8) Counterfactual Answering. These categories target situations rarely represented in standard training corpora, thereby providing more rigorous test of instruction-following fidelity. Moreover, we construct the benchmark through multi-stage human-in-the-loop pipeline, combining expert seed question design, large-scale LLM-based generation, automatic filtering, and rigorous expert review. The final dataset comprises 1012 high-quality questions across 23 diverse domains, ranging from computer science and mathematics to law, literature, and biology. In summary, our contributions are threefold: We identify Counter-Cognitive Ability as critical but underexplored dimension of LLM evaluation. We introduce Inverse IFEval, the first large-scale benchmark explicitly designed to test LLMs under counterintuitive instruction conditions. The dataset is publicly available on Hugging Face at Inverse IFEval. We provide extensive experimental analyses across multiple languages and model families, offering fresh insights into the limitations of current alignment methods a"
[05.09.2025 05:11] Mistral response. {"id": "f659e6fff3b94568b134cd26af699f69", "created": 1757049115, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1339, "total_tokens": 1365, "completion_tokens": 26}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Nanjing University\",\n    \"ByteDance\",\n    \"Jiyun Hudong\"\n]\n```"}}]}
[05.09.2025 05:11] Response: ```python
[
    "Nanjing University",
    "ByteDance",
    "Jiyun Hudong"
]
```
[05.09.2025 05:11] Deleting PDF ./assets/pdf/2509.04292.pdf.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.03888.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.03888.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.03888.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Enriching papers with extra data.
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 0. A unified policy gradient estimator and Hybrid Post-Training algorithm effectively combine online and offline data for post-training language models, improving performance across various benchmarks.  					AI-generated summary 				 Two major sources of training data exist for post-training modern lan...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 1. DeepResearch Arena, a benchmark using academic seminar transcripts, provides high-quality research tasks to evaluate deep research agents across multiple disciplines.  					AI-generated summary 				 Deep research agents have attracted growing attention for their potential to orchestrate multi-stage ...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 2. A novel generative paradigm, Transition Models (TiM), addresses the trade-off between computational cost and output quality in generative modeling by using a continuous-time dynamics equation.  					AI-generated summary 				 A fundamental dilemma in generative modeling persists: iterative diffusion ...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 3. FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) gene...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 4. A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models ...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 5. Drawing2CAD is a framework that converts 2D vector drawings into parametric CAD models using a sequence-to-sequence learning approach with a dual-decoder transformer architecture and a soft target distribution loss function.  					AI-generated summary 				 Computer-Aided Design (CAD) generative mode...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 6. Durian uses dual reference networks and a diffusion model to generate high-fidelity portrait animations with attribute transfer from a reference image to a target portrait in a zero-shot manner.  					AI-generated summary 				 We present Durian, the first method for generating portrait animation vid...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 7. Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often e...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 8. Probing-based approaches for detecting harmful instructions in LLMs are found to rely on superficial patterns rather than semantic understanding, indicating a need for redesigning models and evaluation methods.  					AI-generated summary 				 Large Language Models (LLMs) can comply with harmful inst...
[05.09.2025 05:11] Read previous papers.
[05.09.2025 05:11] Generating reviews via LLM API.
[05.09.2025 05:11] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "ğŸ§ ", "ru": {"title": "ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½ Ğ¸ Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸Ğº Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑÑ‚-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²
[05.09.2025 05:11] Using data from previous issue: {"categories": ["#leakage", "#science", "#agents", "#benchmark", "#survey", "#dataset"], "emoji": "ğŸ§ ", "ru": {"title": "ĞĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€Ñ‹ ĞºĞ°Ğº Ğ¾ÑĞ½Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ˜Ğ˜-Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹", "desc": "DeepResearch Arena - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½Ñ
[05.09.2025 05:11] Using data from previous issue: {"categories": ["#small_models", "#optimization", "#generative_modeling", "#diffusion", "#training"], "emoji": "ğŸ”„", "ru": {"title": "TiM: Ğ³Ğ¸Ğ±ĞºĞ¾Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñƒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ - Transition Models (TiM). TiM
[05.09.2025 05:11] Querying the API.
[05.09.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.   Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining" their innate features, and ultimately achieve higher performance than their generative counterparts.   Based on these findings, we introduce FE2E, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.   Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100times data. The project page can be accessed https://amap-ml.github.io/FE2E/{here}.
[05.09.2025 05:12] Response: {
  "desc": "FE2E - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Diffusion Transformer Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸. ĞĞ½ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ĞµĞ¹ Ñ Ğ½ÑƒĞ»ĞµĞ²Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼. FE2E Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ DiT Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. Ğ‘ĞµĞ· ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, FE2E Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¼Ğ¾Ğ½Ğ¾ĞºÑƒĞ»ÑÑ€Ğ½Ğ¾Ğ¹ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ĞµĞ¹ Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….",
  "emoji": "ğŸ”¬",
  "title": "FE2E: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Diffusion Transformer"
}
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.   Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining" their innate features, and ultimately achieve higher performance than their generative counterparts.   Based on these findings, we introduce FE2E, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.   Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100times data. The project page can be accessed https://amap-ml.github.io/FE2E/{here}."

[05.09.2025 05:12] Response: ```python
['CV', 'TRAINING', 'INFERENCE']
```
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.   Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining" their innate features, and ultimately achieve higher performance than their generative counterparts.   Based on these findings, we introduce FE2E, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.   Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100times data. The project page can be accessed https://amap-ml.github.io/FE2E/{here}."

[05.09.2025 05:12] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces FE2E, a novel framework that utilizes a Diffusion Transformer for predicting dense geometry, specifically focusing on monocular depth and normal estimation. It demonstrates that editing models, which refine existing features, outperform generative models in this context due to their structural priors. The authors reformulate the training objective to enhance the model\'s performance and employ logarithmic quantization to address precision issues. FE2E achieves significant improvements in performance without requiring additional training data, showcasing its efficiency and effectiveness across various datasets.","title":"FE2E: Revolutionizing Dense Geometry Prediction with Diffusion Transformers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces FE2E, a novel framework that utilizes a Diffusion Transformer for predicting dense geometry, specifically focusing on monocular depth and normal estimation. It demonstrates that editing models, which refine existing features, outperform generative models in this context due to their structural priors. The authors reformulate the training objective to enhance the model's performance and employ logarithmic quantization to address precision issues. FE2E achieves significant improvements in performance without requiring additional training data, showcasing its efficiency and effectiveness across various datasets.", title='FE2E: Revolutionizing Dense Geometry Prediction with Diffusion Transformers'))
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FE2Eæ˜¯ä¸€ä¸ªä½¿ç”¨æ‰©æ•£å˜æ¢å™¨çš„æ¡†æ¶ï¼Œä¸“æ³¨äºå¯†é›†å‡ ä½•é¢„æµ‹ï¼Œè¡¨ç°ä¼˜äºç”Ÿæˆæ¨¡å‹ï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬å•ç›®æ·±åº¦å’Œæ³•çº¿ä¼°è®¡æ–¹é¢ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œå›¾åƒç¼–è¾‘æ¨¡å‹æ¯”æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹æ›´é€‚åˆè¿›è¡Œå¯†é›†é¢„æµ‹ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰æ›´ç¨³å®šçš„æ”¶æ•›æ€§å’Œæ›´é«˜çš„æ€§èƒ½ã€‚é€šè¿‡é‡æ–°è®¾è®¡ç¼–è¾‘æ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œä½¿ç”¨å¯¹æ•°é‡åŒ–ï¼ŒFE2Eæœ‰æ•ˆè§£å†³äº†ç²¾åº¦é—®é¢˜ï¼Œå¹¶åˆ©ç”¨å…¨å±€æ³¨æ„åŠ›å®ç°æ·±åº¦å’Œæ³•çº¿çš„è”åˆä¼°è®¡ã€‚æœ€ç»ˆï¼ŒFE2Eåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨ETH3Dæ•°æ®é›†ä¸Šè¶…è¿‡äº†35%çš„æ€§èƒ½å¢ç›Šã€‚","title":"FE2Eï¼šå¯†é›†å‡ ä½•é¢„æµ‹çš„æ–°çªç ´"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FE2Eæ˜¯ä¸€ä¸ªä½¿ç”¨æ‰©æ•£å˜æ¢å™¨çš„æ¡†æ¶ï¼Œä¸“æ³¨äºå¯†é›†å‡ ä½•é¢„æµ‹ï¼Œè¡¨ç°ä¼˜äºç”Ÿæˆæ¨¡å‹ï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬å•ç›®æ·±åº¦å’Œæ³•çº¿ä¼°è®¡æ–¹é¢ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œå›¾åƒç¼–è¾‘æ¨¡å‹æ¯”æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹æ›´é€‚åˆè¿›è¡Œå¯†é›†é¢„æµ‹ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰æ›´ç¨³å®šçš„æ”¶æ•›æ€§å’Œæ›´é«˜çš„æ€§èƒ½ã€‚é€šè¿‡é‡æ–°è®¾è®¡ç¼–è¾‘æ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œä½¿ç”¨å¯¹æ•°é‡åŒ–ï¼ŒFE2Eæœ‰æ•ˆè§£å†³äº†ç²¾åº¦é—®é¢˜ï¼Œå¹¶åˆ©ç”¨å…¨å±€æ³¨æ„åŠ›å®ç°æ·±åº¦å’Œæ³•çº¿çš„è”åˆä¼°è®¡ã€‚æœ€ç»ˆï¼ŒFE2Eåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨ETH3Dæ•°æ®é›†ä¸Šè¶…è¿‡äº†35%çš„æ€§èƒ½å¢ç›Šã€‚', title='FE2Eï¼šå¯†é›†å‡ ä½•é¢„æµ‹çš„æ–°çªç ´'))
[05.09.2025 05:12] Querying the API.
[05.09.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation.
[05.09.2025 05:12] Response: {
  "desc": "MDT-dist - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ². ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ñ€Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ĞµĞ¹. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑˆĞ°Ğ³Ğ¾Ğ² ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ 25 Ğ´Ğ¾ 1-2, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒÑĞºĞ¾Ñ€ÑÑ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ. MDT-dist Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹.",
  "emoji": "ğŸš€",
  "title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ 3D-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²"
}
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation."

[05.09.2025 05:12] Response: ```python
["3D", "INFERENCE", "TRAINING"]
```
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation."

[05.09.2025 05:12] Response: ```python
["OPTIMIZATION", "DIFFUSION"]
```
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces MDT-dist, a new framework designed to speed up 3D flow generation by using a technique called distillation on pretrained models. It focuses on learning Marginal-Data Transport through two main strategies: Velocity Matching (VM) and Velocity Distillation (VD). VM helps align the velocity fields of the student and teacher models, while VD improves the process by distilling probability densities from the learned velocity fields. This approach significantly reduces the number of sampling steps needed, achieving faster generation times while maintaining high quality in the output.","title":"Accelerating 3D Flow Generation with MDT-dist"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces MDT-dist, a new framework designed to speed up 3D flow generation by using a technique called distillation on pretrained models. It focuses on learning Marginal-Data Transport through two main strategies: Velocity Matching (VM) and Velocity Distillation (VD). VM helps align the velocity fields of the student and teacher models, while VD improves the process by distilling probability densities from the learned velocity fields. This approach significantly reduces the number of sampling steps needed, achieving faster generation times while maintaining high quality in the output.', title='Accelerating 3D Flow Generation with MDT-dist'))
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶MDT-distï¼Œç”¨äºåŠ é€Ÿ3Dæµç”Ÿæˆã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè’¸é¦ï¼Œå­¦ä¹ è¾¹é™…æ•°æ®ä¼ è¾“ï¼Œç»“åˆé€Ÿåº¦åŒ¹é…å’Œé€Ÿåº¦è’¸é¦ï¼Œæ˜¾è‘—å‡å°‘äº†é‡‡æ ·æ­¥éª¤ï¼Œæé«˜äº†ç”Ÿæˆé€Ÿåº¦å’Œä¿çœŸåº¦ã€‚ä¸ä¼ ç»Ÿçš„3Dç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒMDT-distèƒ½å¤Ÿå°†æ¯ä¸ªæµå˜æ¢å™¨çš„é‡‡æ ·æ­¥éª¤ä»25å‡å°‘åˆ°1æˆ–2ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„è§†è§‰å’Œå‡ ä½•ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°‘æ­¥3Dç”Ÿæˆä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„è’¸é¦æ–¹æ³•ã€‚","title":"MDT-distï¼šåŠ é€Ÿ3Dæµç”Ÿæˆçš„æ–°æ–¹æ³•"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶MDT-distï¼Œç”¨äºåŠ é€Ÿ3Dæµç”Ÿæˆã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè’¸é¦ï¼Œå­¦ä¹ è¾¹é™…æ•°æ®ä¼ è¾“ï¼Œç»“åˆé€Ÿåº¦åŒ¹é…å’Œé€Ÿåº¦è’¸é¦ï¼Œæ˜¾è‘—å‡å°‘äº†é‡‡æ ·æ­¥éª¤ï¼Œæé«˜äº†ç”Ÿæˆé€Ÿåº¦å’Œä¿çœŸåº¦ã€‚ä¸ä¼ ç»Ÿçš„3Dç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒMDT-distèƒ½å¤Ÿå°†æ¯ä¸ªæµå˜æ¢å™¨çš„é‡‡æ ·æ­¥éª¤ä»25å‡å°‘åˆ°1æˆ–2ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„è§†è§‰å’Œå‡ ä½•ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°‘æ­¥3Dç”Ÿæˆä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„è’¸é¦æ–¹æ³•ã€‚', title='MDT-distï¼šåŠ é€Ÿ3Dæµç”Ÿæˆçš„æ–°æ–¹æ³•'))
[05.09.2025 05:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#architecture", "#dataset", "#open_source"], "emoji": "ğŸ“", "ru": {"title": "ĞÑ‚ Ñ‡ĞµÑ€Ñ‚ĞµĞ¶Ğ° Ğº CAD: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ· 2D-Ñ‡ĞµÑ€Ñ‚ĞµĞ¶ĞµĞ¹", "desc": "Drawing2CAD - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ 2D Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ñ‡ĞµÑ€Ñ‚ĞµĞ¶Ğ¸ Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ CAD-Ğ¼Ğ¾Ğ´ĞµĞ»
[05.09.2025 05:12] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#video"], "emoji": "ğŸ", "ru": {"title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ€Ñ‚Ñ€ĞµÑ‚Ğ¾Ğ²: Ğ¿ĞµÑ€ĞµĞ½Ğ¾Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ² Ğ±ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Durian Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ½Ğ¸Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ñ€Ñ‚Ñ€ĞµÑ‚Ğ¾Ğ² Ñ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ¼ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ² Ñ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶
[05.09.2025 05:12] Querying the API.
[05.09.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios.
[05.09.2025 05:12] Response: {
  "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Inverse IFEval Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ² Ñ…Ğ¾Ğ´Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ¸ ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ²Ğ¾ÑĞµĞ¼ÑŒ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ 1012 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ° ĞºĞ¸Ñ‚Ğ°Ğ¹ÑĞºĞ¾Ğ¼ Ğ¸ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞ°Ñ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ°ĞºĞ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… LLM. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¸ Ğ½ĞµĞ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·ÑƒĞµĞ¼Ñ‹Ñ… Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ….",
  "emoji": "ğŸ§ ",
  "title": "ĞŸÑ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¸Ğ½ĞµÑ€Ñ†Ğ¸Ğ¸ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…"
}
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios."

[05.09.2025 05:12] Response: ```python
['BENCHMARK', 'DATASET', 'MULTILINGUAL']
```
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios."

[05.09.2025 05:12] Response: ```python
['ALIGNMENT', 'HALLUCINATIONS']
```
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Inverse IFEval, a benchmark designed to assess the ability of Large Language Models (LLMs) to overcome biases from their training and follow unconventional instructions. It highlights that while LLMs perform well on many tasks, they often struggle with instructions that deviate from their learned patterns, a phenomenon known as cognitive inertia. The benchmark includes eight challenge types, such as Question Correction and Counterfactual Answering, to evaluate models\' adaptability across various contexts. The findings suggest that improving LLMs requires not just fluency and accuracy, but also the ability to adapt to unexpected instructions in real-world applications.","title":"Enhancing LLMs: Overcoming Biases for Better Adaptability"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces Inverse IFEval, a benchmark designed to assess the ability of Large Language Models (LLMs) to overcome biases from their training and follow unconventional instructions. It highlights that while LLMs perform well on many tasks, they often struggle with instructions that deviate from their learned patterns, a phenomenon known as cognitive inertia. The benchmark includes eight challenge types, such as Question Correction and Counterfactual Answering, to evaluate models' adaptability across various contexts. The findings suggest that improving LLMs requires not just fluency and accuracy, but also the ability to adapt to unexpected instructions in real-world applications.", title='Enhancing LLMs: Overcoming Biases for Better Adaptability'))
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬æ–‡æå‡ºäº†Inverse IFEvalåŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢å¯¹ä¸è®­ç»ƒåè§ç›¸æ‚–çš„æŒ‡ä»¤æ—¶çš„é€‚åº”èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡LLMsåœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨éµå¾ªä¸æ ‡å‡†åŒ–æ¨¡å¼ç›¸å†²çªçš„æŒ‡ä»¤æ—¶å¸¸å¸¸è¡¨ç°å‡ºè®¤çŸ¥æƒ¯æ€§ã€‚Inverse IFEvalå¼•å…¥äº†å…«ç§æŒ‘æˆ˜ç±»å‹ï¼Œæ—¨åœ¨æµ‹é‡æ¨¡å‹å…‹æœè®­ç»ƒåè§çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæœªæ¥çš„å¯¹é½å·¥ä½œä¸ä»…è¦å…³æ³¨æµç•…æ€§å’Œäº‹å®æ­£ç¡®æ€§ï¼Œè¿˜è¦è€ƒè™‘åœ¨éå¸¸è§„ç¯å¢ƒä¸‹çš„é€‚åº”æ€§ã€‚","title":"è¯„ä¼°è¯­è¨€æ¨¡å‹çš„é€‚åº”èƒ½åŠ›"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬æ–‡æå‡ºäº†Inverse IFEvalåŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢å¯¹ä¸è®­ç»ƒåè§ç›¸æ‚–çš„æŒ‡ä»¤æ—¶çš„é€‚åº”èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡LLMsåœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨éµå¾ªä¸æ ‡å‡†åŒ–æ¨¡å¼ç›¸å†²çªçš„æŒ‡ä»¤æ—¶å¸¸å¸¸è¡¨ç°å‡ºè®¤çŸ¥æƒ¯æ€§ã€‚Inverse IFEvalå¼•å…¥äº†å…«ç§æŒ‘æˆ˜ç±»å‹ï¼Œæ—¨åœ¨æµ‹é‡æ¨¡å‹å…‹æœè®­ç»ƒåè§çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæœªæ¥çš„å¯¹é½å·¥ä½œä¸ä»…è¦å…³æ³¨æµç•…æ€§å’Œäº‹å®æ­£ç¡®æ€§ï¼Œè¿˜è¦è€ƒè™‘åœ¨éå¸¸è§„ç¯å¢ƒä¸‹çš„é€‚åº”æ€§ã€‚', title='è¯„ä¼°è¯­è¨€æ¨¡å‹çš„é€‚åº”èƒ½åŠ›'))
[05.09.2025 05:12] Using data from previous issue: {"categories": ["#security", "#training", "#alignment", "#benchmark", "#data", "#open_source"], "emoji": "ğŸ•µï¸", "ru": {"title": "Ğ—Ğ¾Ğ½Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ LLM: Ğ·Ğ° Ñ„Ğ°ÑĞ°Ğ´Ğ¾Ğ¼ ĞºĞ°Ğ¶ÑƒÑ‰ĞµĞ¹ÑÑ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ·Ğ¾Ğ½Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´Ğµ
[05.09.2025 05:12] Renaming data file.
[05.09.2025 05:12] Renaming previous data. hf_papers.json to ./d/2025-09-05.json
[05.09.2025 05:12] Saving new data file.
[05.09.2025 05:12] Generating page.
[05.09.2025 05:12] Renaming previous page.
[05.09.2025 05:12] Renaming previous data. index.html to ./d/2025-09-05.html
[05.09.2025 05:12] Writing result.
[05.09.2025 05:12] Renaming log file.
[05.09.2025 05:12] Renaming previous data. log.txt to ./logs/2025-09-05_last_log.txt
