[05.09.2025 20:12] Read previous papers.
[05.09.2025 20:12] Generating top page (month).
[05.09.2025 20:12] Writing top page (month).
[05.09.2025 21:10] Read previous papers.
[05.09.2025 21:10] Get feed.
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03867
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04338
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04419
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01396
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04292
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04394
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20478
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04011
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04406
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04434
[05.09.2025 21:10] Extract page data from URL. URL: https://huggingface.co/papers/2509.03059
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18733
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04442
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03888
[05.09.2025 21:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.09.2025 21:10] No deleted papers detected.
[05.09.2025 21:10] Downloading and parsing papers (pdf, html). Total: 14.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.03867.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.03867.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.03867.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04338.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04338.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04338.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04419.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04419.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04419.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.01396.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.01396.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.01396.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04292.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04292.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04292.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04394.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04394.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04394.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.20478.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2508.20478.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2508.20478.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04011.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04011.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04011.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04406.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04406.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04406.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04434.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04434.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04434.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.03059.
[05.09.2025 21:10] Downloading paper 2509.03059 from http://arxiv.org/pdf/2509.03059v1...
[05.09.2025 21:10] Extracting affiliations from text.
[05.09.2025 21:10] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 ] . [ 1 9 5 0 3 0 . 9 0 5 2 : r Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers Xingyue Huang*, Rishabh*, Gregor Franke*, Ziyi Yang*, Jiamu Bai, Weijie Bai, Jinhe Bi, Zifeng Ding, Yiqun Duan, Chengyu Fan, Wendong Fan, Xin Gao, Ruohao Guo, Yuan He, Zhuangzhuang He, Xianglong Hu, Neil Johnson, Bowen Li, Fangru Lin, Siyu Lin, Tong Liu, Yunpu Ma, Hao Shen, Hao Sun, Beibei Wang, Fangyijie Wang, Hao Wang, Haoran Wang, Yang Wang, Yifeng Wang, Zhaowei Wang, Ziyang Wang, Yifan Wu, Zikai Xiao, Chengxing Xie, Fan Yang, Junxiao Yang, Qianshuo Ye, Ziyu Ye, Guangtao Zeng, Yuwen Ebony Zhang, Zeyu Zhang, Zihao Zhu, Bernard Ghanem, Philip Torr, Guohao Li CAMEL-AI.org Equal Contribution, Corresponding author, Authors listed here are in alphabetical order "
[05.09.2025 21:10] Response: ```python
[]
```
[05.09.2025 21:10] Extracting affiliations from text.
[05.09.2025 21:10] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 ] . [ 1 9 5 0 3 0 . 9 0 5 2 : r Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers Xingyue Huang*, Rishabh*, Gregor Franke*, Ziyi Yang*, Jiamu Bai, Weijie Bai, Jinhe Bi, Zifeng Ding, Yiqun Duan, Chengyu Fan, Wendong Fan, Xin Gao, Ruohao Guo, Yuan He, Zhuangzhuang He, Xianglong Hu, Neil Johnson, Bowen Li, Fangru Lin, Siyu Lin, Tong Liu, Yunpu Ma, Hao Shen, Hao Sun, Beibei Wang, Fangyijie Wang, Hao Wang, Haoran Wang, Yang Wang, Yifeng Wang, Zhaowei Wang, Ziyang Wang, Yifan Wu, Zikai Xiao, Chengxing Xie, Fan Yang, Junxiao Yang, Qianshuo Ye, Ziyu Ye, Guangtao Zeng, Yuwen Ebony Zhang, Zeyu Zhang, Zihao Zhu, Bernard Ghanem, Philip Torr, Guohao Li CAMEL-AI.org Equal Contribution, Corresponding author, Authors listed here are in alphabetical orderRecent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LOONGBENCH, curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LOONGENV, modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LOONGBENCH on broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct comprehensive analysis of synthetic data generated by LOONGENV, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong. Date: September 4, 2025 Correspondence: Guohao Li at guohao.li@eigent.ai Project Page: https://github.com/camel-ai/loongRecent Large Reasoning Models such as DeepSeek-R1 [1] and o3 [2] have demonstrated that the general reasoning capabilities of LLMs greatly improve when base models undergo post-training with Reinforcement Learning (RL) with verifiable reward [35]. Mathematics and programming [3, 6] have particularly benefited from this approach, as these domains can be verified quite easily, allowing accurate interpretation of LLM responses and effective comparison to the ground truth on semantic level. This idea that the ease of verification is crucial to improving domain-specific capabilities has become widely accepted in the research community [79]. Another critical prerequisite which is often overlooked is the abundance of high-quality datasets, featuring questions paired with verified correct answers in the domains of Maths and Coding [6, 10]. These curated datasets provided the necessary signal for models to learn to construct coherent Chains-of-Thought (CoTs) [6], leading reliably to correct answers. However, many other domains also require reliable reasoning, such as logic, graph theory, physics, and finance. These domains lack comparable datasets [4, 1113], and human-supervised data production at scale is prohibitively expensive [5, 13, 14]. Without abundant correct answers to learn from, models cannot easily acquire domain-specific reasoning patterns. This raises crucial question: Can similar reasoning performance be achieved in domains beyond maths and programming? Approach. We present the Loong Project: an open framework for scaling synthetic data generation with verifiable supervision across diverse set of reasoning-centric domains. The framework comprises two key components: 1. LOONGBENCH, meticulously curated seed dataset comprising 8,729 examples across 12 reasoningintensive domains, each accompanied by executable code and verified answers. 2. LOONGENV, modular and versatile synthetic data generation environment, capable of generating diverse and semantically verifiable question-answer pairs using various automated generation strategies. As illustrated in Figure 1, the overall agent-environment loop operates as follows: First, given collection of seed datasets, our generator produces synthetic data points consisting of automatically generated questions and corresponding executable codes that answer these questions. Second, these codes are executed within the environment to yield synthetic answers. Third, trainable agent is prompted to solve the synthetic questions by generating natural language CoT responses. Finally, verifier compares the agents CoT-derived answer to the code-generated answer. This setup will enable large-scale reinforcement learning with minimal human supervision while preserving semantic correctness through automated verification in the future. Contributions. Our main contributions are: We introduce LOONGBENCH, high-quality seed dataset of 8,729 examples spanning 12 reasoningintensive domains, each paired with executable code and semantically verified answers. Figure 1 Agent-Environment Loop We develop LOONGENV, synthetic data generation environment that supports multiple generation strategies to produce diverse and verifiable question-answer pairs. We benchmark LOONGBENCH across diverse suite of large language models-including both opensource and proprietary, general-purpose and reasoning-specialized models-to establish baseline performance and identify domain-specific challenges. We conduct detailed analysis of the synthetic data generated by LOONGENV, evaluating it in terms of semantic correctness, question difficulty, and diversity.The Loong Project is focused on scaling up synthetic data generation with verification mechanisms across broad spectrum of domains. We believe that generating synthetic data is essential not just to overcome the lack of datasets in under-represented fields, but also to strengthen reasoning abilities in areas like mathematics an"
[05.09.2025 21:10] Mistral response. {"id": "898237d6789f44648689f767ec52a308", "created": 1757106611, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1421, "total_tokens": 1439, "completion_tokens": 18}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"CAMEL-AI.org\", \"eigent.ai\"]\n```"}}]}
[05.09.2025 21:10] Response: ```python
["CAMEL-AI.org", "eigent.ai"]
```
[05.09.2025 21:10] Deleting PDF ./assets/pdf/2509.03059.pdf.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.18733.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2508.18733.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2508.18733.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04442.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04442.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04442.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.03888.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.03888.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.03888.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Enriching papers with extra data.
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 0. LLMs struggle with understanding the nuanced, context-dependent meanings of Drivelological text, which appears nonsensical but contains deeper semantic layers.  					AI-generated summary 				 We introduce Drivelology, a unique linguistic phenomenon characterised as "nonsense with depth", utterances ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 1. FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) gene...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 2. A unified policy gradient estimator and Hybrid Post-Training algorithm effectively combine online and offline data for post-training language models, improving performance across various benchmarks.  					AI-generated summary 				 Two major sources of training data exist for post-training modern lan...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 3. DeepResearch Arena, a benchmark using academic seminar transcripts, provides high-quality research tasks to evaluate deep research agents across multiple disciplines.  					AI-generated summary 				 Deep research agents have attracted growing attention for their potential to orchestrate multi-stage ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 4. Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often e...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 5. A novel generative paradigm, Transition Models (TiM), addresses the trade-off between computational cost and output quality in generative modeling by using a continuous-time dynamics equation.  					AI-generated summary 				 A fundamental dilemma in generative modeling persists: iterative diffusion ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 6. Video-MTR, a reinforced multi-turn reasoning framework, improves long-form video understanding by iteratively selecting key segments and comprehending questions, outperforming existing methods in accuracy and efficiency.  					AI-generated summary 				 Long-form video understanding, characterized by...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 7. NER Retriever uses internal representations from large language models to perform zero-shot named entity retrieval by embedding entity mentions and type descriptions into a shared semantic space, outperforming lexical and dense sentence-level retrieval methods.  					AI-generated summary 				 We pre...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 8. A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 9. Durian uses dual reference networks and a diffusion model to generate high-fidelity portrait animations with attribute transfer from a reference image to a target portrait in a zero-shot manner.  					AI-generated summary 				 We present Durian, the first method for generating portrait animation vid...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 10. The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 11. Drawing2CAD is a framework that converts 2D vector drawings into parametric CAD models using a sequence-to-sequence learning approach with a dual-decoder transformer architecture and a soft target distribution loss function.  					AI-generated summary 				 Computer-Aided Design (CAD) generative mode...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 12. Delta Activations represent fine-tuned models as vector embeddings based on internal activation shifts, enabling effective clustering and model reuse.  					AI-generated summary 				 The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collectio...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 13. Probing-based approaches for detecting harmful instructions in LLMs are found to rely on superficial patterns rather than semantic understanding, indicating a need for redesigning models and evaluation methods.  					AI-generated summary 				 Large Language Models (LLMs) can comply with harmful inst...
[05.09.2025 21:10] Read previous papers.
[05.09.2025 21:10] Generating reviews via LLM API.
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#hallucinations", "#multilingual", "#benchmark", "#reasoning", "#alignment", "#dataset"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ‘ĞµÑÑĞ¼Ñ‹ÑĞ»Ğ¸Ñ†Ğ° Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ¾Ğ¹: Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ 'Ğ´Ñ€Ğ¸Ğ²ĞµĞ»Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸' - Ğ»Ğ¸Ğ½Ğ³Ğ²Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ„ĞµĞ½Ğ¾Ğ¼ĞµĞ½Ğ°, Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸Ğ·Ñƒ
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#inference", "#cv", "#diffusion", "#optimization", "#training"], "emoji": "ğŸ”¬", "ru": {"title": "FE2E: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Diffusion Transformer", "desc": "FE2E - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Diffusion Transformer Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸. Ğ
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "ğŸ§ ", "ru": {"title": "ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½ Ğ¸ Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸Ğº Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑÑ‚-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#leakage", "#science", "#agents", "#benchmark", "#survey", "#dataset"], "emoji": "ğŸ§ ", "ru": {"title": "ĞĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€Ñ‹ ĞºĞ°Ğº Ğ¾ÑĞ½Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ˜Ğ˜-Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹", "desc": "DeepResearch Arena - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½Ñ
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#multilingual", "#hallucinations", "#dataset", "#benchmark", "#alignment"], "emoji": "ğŸ§ ", "ru": {"title": "ĞŸÑ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¸Ğ½ĞµÑ€Ñ†Ğ¸Ğ¸ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Inverse IFEval Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¿Ñ€
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#small_models", "#optimization", "#generative_modeling", "#diffusion", "#training"], "emoji": "ğŸ”„", "ru": {"title": "TiM: Ğ³Ğ¸Ğ±ĞºĞ¾Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñƒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ - Transition Models (TiM). TiM
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#long_context", "#video", "#rl", "#reasoning"], "emoji": "ğŸ¥", "ru": {"title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾: Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½Ñ‡Ğ°Ñ‚Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ»Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ", "desc": "Video-MTR - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ²Ñ‹Ğ±Ğ¾Ñ€Ñƒ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ñƒ Ğ²Ğ¾Ğ¿
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#transfer_learning", "#multimodal", "#open_source"], "emoji": "ğŸ”", "ru": {"title": "Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ÑÑƒÑ‰Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±ĞµĞ· ÑÑ…ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "NER Retriever - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑÑƒÑ‰Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#3d", "#inference", "#diffusion", "#optimization", "#training"], "emoji": "ğŸš€", "ru": {"title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ 3D-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²", "desc": "MDT-dist - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ². ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#video"], "emoji": "ğŸ", "ru": {"title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ€Ñ‚Ñ€ĞµÑ‚Ğ¾Ğ²: Ğ¿ĞµÑ€ĞµĞ½Ğ¾Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ² Ğ±ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Durian Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ½Ğ¸Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ñ€Ñ‚Ñ€ĞµÑ‚Ğ¾Ğ² Ñ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ¼ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ² Ñ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶
[05.09.2025 21:10] Querying the API.
[05.09.2025 21:10] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong.
[05.09.2025 21:10] Response: {
  "desc": "ĞŸÑ€Ğ¾ĞµĞºÑ‚ Loong Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ñ†ĞµĞ»ÑŒÑ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM) Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼Ñ‹Ğ¼ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ (RLVR). Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ LoongBench - ĞºÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· 8,729 Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ² 12 Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ…, Ğ¸ LoongEnv - ÑÑ€ĞµĞ´Ñƒ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­Ñ‚Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒÑÑ‚ Ñ†Ğ¸ĞºĞ» Ğ°Ğ³ĞµĞ½Ñ‚-ÑÑ€ĞµĞ´Ğ°, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ğ³Ğ´Ğµ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ LLM Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ·Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ñ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¾Ğ¹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (CoT), ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ğ¼, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸ĞµĞ¼ ĞºĞ¾Ğ´Ğ°. ĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ° Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑ…Ğ° RLVR Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, Ğ³Ğ´Ğµ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….",
  "emoji": "ğŸ‰",
  "title": "Loong: ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"
}
[05.09.2025 21:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong."

[05.09.2025 21:10] Response: ```python
['DATASET', 'DATA', 'RL', 'BENCHMARK', 'MULTIMODAL']
```
[05.09.2025 21:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong."

[05.09.2025 21:10] Response: ```python
['SYNTHETIC', 'REASONING', 'OPEN_SOURCE']
```
[05.09.2025 21:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Loong Project presents a new framework designed to enhance the reasoning abilities of Large Language Models (LLMs) using Reinforcement Learning with Verifiable Reward (RLVR). It addresses the challenge of generating high-quality synthetic data for reasoning-intensive tasks by providing a curated dataset called LoongBench and a modular environment for synthetic data generation, known as LoongEnv. LoongBench includes thousands of human-verified examples across various domains, while LoongEnv allows for the creation of new question-answer-code triples through different prompting strategies. This framework enables LLMs to learn and improve their reasoning by rewarding them for producing correct Chain-of-Thought solutions that match executable code outputs.","title":"Empowering LLMs with Synthetic Data for Enhanced Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Loong Project presents a new framework designed to enhance the reasoning abilities of Large Language Models (LLMs) using Reinforcement Learning with Verifiable Reward (RLVR). It addresses the challenge of generating high-quality synthetic data for reasoning-intensive tasks by providing a curated dataset called LoongBench and a modular environment for synthetic data generation, known as LoongEnv. LoongBench includes thousands of human-verified examples across various domains, while LoongEnv allows for the creation of new question-answer-code triples through different prompting strategies. This framework enables LLMs to learn and improve their reasoning by rewarding them for producing correct Chain-of-Thought solutions that match executable code outputs.', title='Empowering LLMs with Synthetic Data for Enhanced Reasoning'))
[05.09.2025 21:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Loongé¡¹ç›®æå‡ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå’ŒéªŒè¯åˆæˆæ•°æ®ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œé‡‡ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼šLoongBenchï¼Œä¸€ä¸ªåŒ…å«8729ä¸ªç»è¿‡äººå·¥å®¡æ ¸çš„ç¤ºä¾‹çš„ç§å­æ•°æ®é›†ï¼Œæ¶µç›–12ä¸ªé¢†åŸŸï¼›ä»¥åŠLoongEnvï¼Œä¸€ä¸ªæ¨¡å—åŒ–çš„åˆæˆæ•°æ®ç”Ÿæˆç¯å¢ƒï¼Œæ”¯æŒå¤šç§æç¤ºç­–ç•¥ç”Ÿæˆæ–°çš„é—®ç­”ä»£ç ä¸‰å…ƒç»„ã€‚é€šè¿‡è¿™äº›ç»„ä»¶ï¼Œå½¢æˆäº†ä¸€ä¸ªä»£ç†-ç¯å¢ƒå¾ªç¯ï¼Œä½¿å¾—åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†èƒ½å¤Ÿé€šè¿‡ç”Ÿæˆç¬¦åˆä»£ç æ‰§è¡Œç­”æ¡ˆçš„æ€ç»´é“¾è§£å†³æ–¹æ¡ˆæ¥è·å¾—å¥–åŠ±ã€‚æˆ‘ä»¬å¯¹LoongBenchè¿›è¡Œäº†å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥è¯„ä¼°é¢†åŸŸè¦†ç›–ç‡å¹¶æ­ç¤ºæ€§èƒ½ç“¶é¢ˆã€‚","title":"åˆæˆæ•°æ®ç”Ÿæˆä¸éªŒè¯çš„åˆ›æ–°æ¡†æ¶"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Loongé¡¹ç›®æå‡ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå’ŒéªŒè¯åˆæˆæ•°æ®ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œé‡‡ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼šLoongBenchï¼Œä¸€ä¸ªåŒ…å«8729ä¸ªç»è¿‡äººå·¥å®¡æ ¸çš„ç¤ºä¾‹çš„ç§å­æ•°æ®é›†ï¼Œæ¶µç›–12ä¸ªé¢†åŸŸï¼›ä»¥åŠLoongEnvï¼Œä¸€ä¸ªæ¨¡å—åŒ–çš„åˆæˆæ•°æ®ç”Ÿæˆç¯å¢ƒï¼Œæ”¯æŒå¤šç§æç¤ºç­–ç•¥ç”Ÿæˆæ–°çš„é—®ç­”ä»£ç ä¸‰å…ƒç»„ã€‚é€šè¿‡è¿™äº›ç»„ä»¶ï¼Œå½¢æˆäº†ä¸€ä¸ªä»£ç†-ç¯å¢ƒå¾ªç¯ï¼Œä½¿å¾—åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†èƒ½å¤Ÿé€šè¿‡ç”Ÿæˆç¬¦åˆä»£ç æ‰§è¡Œç­”æ¡ˆçš„æ€ç»´é“¾è§£å†³æ–¹æ¡ˆæ¥è·å¾—å¥–åŠ±ã€‚æˆ‘ä»¬å¯¹LoongBenchè¿›è¡Œäº†å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥è¯„ä¼°é¢†åŸŸè¦†ç›–ç‡å¹¶æ­ç¤ºæ€§èƒ½ç“¶é¢ˆã€‚', title='åˆæˆæ•°æ®ç”Ÿæˆä¸éªŒè¯çš„åˆ›æ–°æ¡†æ¶'))
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#optimization", "#training", "#architecture", "#dataset", "#open_source"], "emoji": "ğŸ“", "ru": {"title": "ĞÑ‚ Ñ‡ĞµÑ€Ñ‚ĞµĞ¶Ğ° Ğº CAD: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ· 2D-Ñ‡ĞµÑ€Ñ‚ĞµĞ¶ĞµĞ¹", "desc": "Drawing2CAD - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ 2D Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ñ‡ĞµÑ€Ñ‚ĞµĞ¶Ğ¸ Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ CAD-Ğ¼Ğ¾Ğ´ĞµĞ»
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#transfer_learning", "#dataset", "#data", "#open_source"], "emoji": "ğŸ§ ", "ru": {"title": "Delta Activations: ĞĞ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ Ğ² Ğ¼Ğ¸Ñ€Ğµ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "ĞœĞµÑ‚Ğ¾Ğ´ Delta Activations Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ², Ğ¾
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#security", "#training", "#alignment", "#benchmark", "#data", "#open_source"], "emoji": "ğŸ•µï¸", "ru": {"title": "Ğ—Ğ¾Ğ½Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ LLM: Ğ·Ğ° Ñ„Ğ°ÑĞ°Ğ´Ğ¾Ğ¼ ĞºĞ°Ğ¶ÑƒÑ‰ĞµĞ¹ÑÑ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ·Ğ¾Ğ½Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´Ğµ
[05.09.2025 21:10] Renaming data file.
[05.09.2025 21:10] Renaming previous data. hf_papers.json to ./d/2025-09-05.json
[05.09.2025 21:10] Saving new data file.
[05.09.2025 21:10] Generating page.
[05.09.2025 21:10] Renaming previous page.
[05.09.2025 21:10] Renaming previous data. index.html to ./d/2025-09-05.html
[05.09.2025 21:10] Writing result.
[05.09.2025 21:10] Renaming log file.
[05.09.2025 21:10] Renaming previous data. log.txt to ./logs/2025-09-05_last_log.txt
