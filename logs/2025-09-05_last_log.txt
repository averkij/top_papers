[05.09.2025 20:12] Read previous papers.
[05.09.2025 20:12] Generating top page (month).
[05.09.2025 20:12] Writing top page (month).
[05.09.2025 21:10] Read previous papers.
[05.09.2025 21:10] Get feed.
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03867
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04338
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04419
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01396
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04292
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04394
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20478
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04011
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04406
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04434
[05.09.2025 21:10] Extract page data from URL. URL: https://huggingface.co/papers/2509.03059
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18733
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04442
[05.09.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03888
[05.09.2025 21:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.09.2025 21:10] No deleted papers detected.
[05.09.2025 21:10] Downloading and parsing papers (pdf, html). Total: 14.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.03867.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.03867.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.03867.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04338.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04338.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04338.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04419.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04419.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04419.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.01396.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.01396.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.01396.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04292.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04292.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04292.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04394.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04394.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04394.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.20478.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2508.20478.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2508.20478.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04011.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04011.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04011.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04406.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04406.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04406.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04434.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04434.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04434.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.03059.
[05.09.2025 21:10] Downloading paper 2509.03059 from http://arxiv.org/pdf/2509.03059v1...
[05.09.2025 21:10] Extracting affiliations from text.
[05.09.2025 21:10] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 ] . [ 1 9 5 0 3 0 . 9 0 5 2 : r Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers Xingyue Huang*, Rishabh*, Gregor Franke*, Ziyi Yang*, Jiamu Bai, Weijie Bai, Jinhe Bi, Zifeng Ding, Yiqun Duan, Chengyu Fan, Wendong Fan, Xin Gao, Ruohao Guo, Yuan He, Zhuangzhuang He, Xianglong Hu, Neil Johnson, Bowen Li, Fangru Lin, Siyu Lin, Tong Liu, Yunpu Ma, Hao Shen, Hao Sun, Beibei Wang, Fangyijie Wang, Hao Wang, Haoran Wang, Yang Wang, Yifeng Wang, Zhaowei Wang, Ziyang Wang, Yifan Wu, Zikai Xiao, Chengxing Xie, Fan Yang, Junxiao Yang, Qianshuo Ye, Ziyu Ye, Guangtao Zeng, Yuwen Ebony Zhang, Zeyu Zhang, Zihao Zhu, Bernard Ghanem, Philip Torr, Guohao Li CAMEL-AI.org Equal Contribution, Corresponding author, Authors listed here are in alphabetical order "
[05.09.2025 21:10] Response: ```python
[]
```
[05.09.2025 21:10] Extracting affiliations from text.
[05.09.2025 21:10] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 ] . [ 1 9 5 0 3 0 . 9 0 5 2 : r Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers Xingyue Huang*, Rishabh*, Gregor Franke*, Ziyi Yang*, Jiamu Bai, Weijie Bai, Jinhe Bi, Zifeng Ding, Yiqun Duan, Chengyu Fan, Wendong Fan, Xin Gao, Ruohao Guo, Yuan He, Zhuangzhuang He, Xianglong Hu, Neil Johnson, Bowen Li, Fangru Lin, Siyu Lin, Tong Liu, Yunpu Ma, Hao Shen, Hao Sun, Beibei Wang, Fangyijie Wang, Hao Wang, Haoran Wang, Yang Wang, Yifeng Wang, Zhaowei Wang, Ziyang Wang, Yifan Wu, Zikai Xiao, Chengxing Xie, Fan Yang, Junxiao Yang, Qianshuo Ye, Ziyu Ye, Guangtao Zeng, Yuwen Ebony Zhang, Zeyu Zhang, Zihao Zhu, Bernard Ghanem, Philip Torr, Guohao Li CAMEL-AI.org Equal Contribution, Corresponding author, Authors listed here are in alphabetical orderRecent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LOONGBENCH, curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LOONGENV, modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LOONGBENCH on broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct comprehensive analysis of synthetic data generated by LOONGENV, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong. Date: September 4, 2025 Correspondence: Guohao Li at guohao.li@eigent.ai Project Page: https://github.com/camel-ai/loongRecent Large Reasoning Models such as DeepSeek-R1 [1] and o3 [2] have demonstrated that the general reasoning capabilities of LLMs greatly improve when base models undergo post-training with Reinforcement Learning (RL) with verifiable reward [35]. Mathematics and programming [3, 6] have particularly benefited from this approach, as these domains can be verified quite easily, allowing accurate interpretation of LLM responses and effective comparison to the ground truth on semantic level. This idea that the ease of verification is crucial to improving domain-specific capabilities has become widely accepted in the research community [79]. Another critical prerequisite which is often overlooked is the abundance of high-quality datasets, featuring questions paired with verified correct answers in the domains of Maths and Coding [6, 10]. These curated datasets provided the necessary signal for models to learn to construct coherent Chains-of-Thought (CoTs) [6], leading reliably to correct answers. However, many other domains also require reliable reasoning, such as logic, graph theory, physics, and finance. These domains lack comparable datasets [4, 1113], and human-supervised data production at scale is prohibitively expensive [5, 13, 14]. Without abundant correct answers to learn from, models cannot easily acquire domain-specific reasoning patterns. This raises crucial question: Can similar reasoning performance be achieved in domains beyond maths and programming? Approach. We present the Loong Project: an open framework for scaling synthetic data generation with verifiable supervision across diverse set of reasoning-centric domains. The framework comprises two key components: 1. LOONGBENCH, meticulously curated seed dataset comprising 8,729 examples across 12 reasoningintensive domains, each accompanied by executable code and verified answers. 2. LOONGENV, modular and versatile synthetic data generation environment, capable of generating diverse and semantically verifiable question-answer pairs using various automated generation strategies. As illustrated in Figure 1, the overall agent-environment loop operates as follows: First, given collection of seed datasets, our generator produces synthetic data points consisting of automatically generated questions and corresponding executable codes that answer these questions. Second, these codes are executed within the environment to yield synthetic answers. Third, trainable agent is prompted to solve the synthetic questions by generating natural language CoT responses. Finally, verifier compares the agents CoT-derived answer to the code-generated answer. This setup will enable large-scale reinforcement learning with minimal human supervision while preserving semantic correctness through automated verification in the future. Contributions. Our main contributions are: We introduce LOONGBENCH, high-quality seed dataset of 8,729 examples spanning 12 reasoningintensive domains, each paired with executable code and semantically verified answers. Figure 1 Agent-Environment Loop We develop LOONGENV, synthetic data generation environment that supports multiple generation strategies to produce diverse and verifiable question-answer pairs. We benchmark LOONGBENCH across diverse suite of large language models-including both opensource and proprietary, general-purpose and reasoning-specialized models-to establish baseline performance and identify domain-specific challenges. We conduct detailed analysis of the synthetic data generated by LOONGENV, evaluating it in terms of semantic correctness, question difficulty, and diversity.The Loong Project is focused on scaling up synthetic data generation with verification mechanisms across broad spectrum of domains. We believe that generating synthetic data is essential not just to overcome the lack of datasets in under-represented fields, but also to strengthen reasoning abilities in areas like mathematics an"
[05.09.2025 21:10] Mistral response. {"id": "898237d6789f44648689f767ec52a308", "created": 1757106611, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1421, "total_tokens": 1439, "completion_tokens": 18}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"CAMEL-AI.org\", \"eigent.ai\"]\n```"}}]}
[05.09.2025 21:10] Response: ```python
["CAMEL-AI.org", "eigent.ai"]
```
[05.09.2025 21:10] Deleting PDF ./assets/pdf/2509.03059.pdf.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.18733.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2508.18733.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2508.18733.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.04442.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.04442.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.04442.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2509.03888.
[05.09.2025 21:10] Extra JSON file exists (./assets/json/2509.03888.json), skip PDF parsing.
[05.09.2025 21:10] Paper image links file exists (./assets/img_data/2509.03888.json), skip HTML parsing.
[05.09.2025 21:10] Success.
[05.09.2025 21:10] Enriching papers with extra data.
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 0. LLMs struggle with understanding the nuanced, context-dependent meanings of Drivelological text, which appears nonsensical but contains deeper semantic layers.  					AI-generated summary 				 We introduce Drivelology, a unique linguistic phenomenon characterised as "nonsense with depth", utterances ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 1. FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) gene...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 2. A unified policy gradient estimator and Hybrid Post-Training algorithm effectively combine online and offline data for post-training language models, improving performance across various benchmarks.  					AI-generated summary 				 Two major sources of training data exist for post-training modern lan...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 3. DeepResearch Arena, a benchmark using academic seminar transcripts, provides high-quality research tasks to evaluate deep research agents across multiple disciplines.  					AI-generated summary 				 Deep research agents have attracted growing attention for their potential to orchestrate multi-stage ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 4. Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often e...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 5. A novel generative paradigm, Transition Models (TiM), addresses the trade-off between computational cost and output quality in generative modeling by using a continuous-time dynamics equation.  					AI-generated summary 				 A fundamental dilemma in generative modeling persists: iterative diffusion ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 6. Video-MTR, a reinforced multi-turn reasoning framework, improves long-form video understanding by iteratively selecting key segments and comprehending questions, outperforming existing methods in accuracy and efficiency.  					AI-generated summary 				 Long-form video understanding, characterized by...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 7. NER Retriever uses internal representations from large language models to perform zero-shot named entity retrieval by embedding entity mentions and type descriptions into a shared semantic space, outperforming lexical and dense sentence-level retrieval methods.  					AI-generated summary 				 We pre...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 8. A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models ...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 9. Durian uses dual reference networks and a diffusion model to generate high-fidelity portrait animations with attribute transfer from a reference image to a target portrait in a zero-shot manner.  					AI-generated summary 				 We present Durian, the first method for generating portrait animation vid...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 10. The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 11. Drawing2CAD is a framework that converts 2D vector drawings into parametric CAD models using a sequence-to-sequence learning approach with a dual-decoder transformer architecture and a soft target distribution loss function.  					AI-generated summary 				 Computer-Aided Design (CAD) generative mode...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 12. Delta Activations represent fine-tuned models as vector embeddings based on internal activation shifts, enabling effective clustering and model reuse.  					AI-generated summary 				 The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collectio...
[05.09.2025 21:10] ********************************************************************************
[05.09.2025 21:10] Abstract 13. Probing-based approaches for detecting harmful instructions in LLMs are found to rely on superficial patterns rather than semantic understanding, indicating a need for redesigning models and evaluation methods.  					AI-generated summary 				 Large Language Models (LLMs) can comply with harmful inst...
[05.09.2025 21:10] Read previous papers.
[05.09.2025 21:10] Generating reviews via LLM API.
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#hallucinations", "#multilingual", "#benchmark", "#reasoning", "#alignment", "#dataset"], "emoji": "🧠", "ru": {"title": "Бессмыслица с глубиной: вызов для искусственного интеллекта", "desc": "Исследователи представили концепцию 'дривелологии' - лингвистического феномена, характеризу
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#inference", "#cv", "#diffusion", "#optimization", "#training"], "emoji": "🔬", "ru": {"title": "FE2E: Революция в оценке глубины и нормалей с помощью Diffusion Transformer", "desc": "FE2E - это новый фреймворк, использующий Diffusion Transformer для предсказания плотной геометрии. О
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "🧠", "ru": {"title": "Объединение онлайн и офлайн данных для улучшения языковых моделей", "desc": "В статье представлен унифицированный оценщик градиента политики и алгоритм гибридного пост-обучения для языков
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#leakage", "#science", "#agents", "#benchmark", "#survey", "#dataset"], "emoji": "🧠", "ru": {"title": "Академические семинары как основа для оценки ИИ-исследователей", "desc": "DeepResearch Arena - это новый бенчмарк для оценки глубоких исследовательских агентов, основанный на транс
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#multilingual", "#hallucinations", "#dataset", "#benchmark", "#alignment"], "emoji": "🧠", "ru": {"title": "Преодоление когнитивной инерции в больших языковых моделях", "desc": "Статья представляет новый бенчмарк Inverse IFEval для оценки способности больших языковых моделей (LLM) пр
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#small_models", "#optimization", "#generative_modeling", "#diffusion", "#training"], "emoji": "🔄", "ru": {"title": "TiM: гибкое генеративное моделирование с непрерывным временем", "desc": "Статья представляет новую парадигму генеративного моделирования - Transition Models (TiM). TiM
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#long_context", "#video", "#rl", "#reasoning"], "emoji": "🎥", "ru": {"title": "Умное видео: многоступенчатый анализ для глубокого понимания", "desc": "Video-MTR - это новая система для понимания длинных видео, использующая итеративный подход к выбору ключевых сегментов и анализу воп
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#transfer_learning", "#multimodal", "#open_source"], "emoji": "🔍", "ru": {"title": "Извлечение сущностей без схем с помощью внутренних представлений языковых моделей", "desc": "NER Retriever - это фреймворк для извлечения именованных сущностей без предварит
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#3d", "#inference", "#diffusion", "#optimization", "#training"], "emoji": "🚀", "ru": {"title": "Революционное ускорение 3D-генерации с помощью дистилляции потоков", "desc": "MDT-dist - это новая система для ускорения генерации 3D-моделей на основе потоков. Она использует дистилляцию
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#video"], "emoji": "🍍", "ru": {"title": "Революция в анимации портретов: перенос атрибутов без предварительного обучения", "desc": "Статья представляет метод Durian для генерации анимированных портретов с переносом атрибутов с референсного изображ
[05.09.2025 21:10] Querying the API.
[05.09.2025 21:10] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong.
[05.09.2025 21:10] Response: {
  "desc": "Проект Loong представляет фреймворк для генерации и верификации синтетических данных с целью улучшения способностей к рассуждению в больших языковых моделях (LLM) с помощью обучения с подкреплением с проверяемым вознаграждением (RLVR). Фреймворк включает в себя LoongBench - курированный набор данных из 8,729 примеров в 12 областях, и LoongEnv - среду для генерации синтетических данных. Эти компоненты формируют цикл агент-среда, позволяющий проводить обучение с подкреплением, где агент на основе LLM получает вознаграждение за генерацию решений с цепочкой рассуждений (CoT), соответствующих ответам, полученным выполнением кода. Проект направлен на расширение успеха RLVR на различные области, требующие рассуждений, где сложно получить качественные проверяемые наборы данных.",
  "emoji": "🐉",
  "title": "Loong: усиление рассуждений ИИ через синтетические данные"
}
[05.09.2025 21:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong."

[05.09.2025 21:10] Response: ```python
['DATASET', 'DATA', 'RL', 'BENCHMARK', 'MULTIMODAL']
```
[05.09.2025 21:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Loong Project introduces a framework for generating and verifying synthetic data to improve reasoning capabilities in Large Language Models through Reinforcement Learning with Verifiable Reward.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong."

[05.09.2025 21:10] Response: ```python
['SYNTHETIC', 'REASONING', 'OPEN_SOURCE']
```
[05.09.2025 21:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Loong Project presents a new framework designed to enhance the reasoning abilities of Large Language Models (LLMs) using Reinforcement Learning with Verifiable Reward (RLVR). It addresses the challenge of generating high-quality synthetic data for reasoning-intensive tasks by providing a curated dataset called LoongBench and a modular environment for synthetic data generation, known as LoongEnv. LoongBench includes thousands of human-verified examples across various domains, while LoongEnv allows for the creation of new question-answer-code triples through different prompting strategies. This framework enables LLMs to learn and improve their reasoning by rewarding them for producing correct Chain-of-Thought solutions that match executable code outputs.","title":"Empowering LLMs with Synthetic Data for Enhanced Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Loong Project presents a new framework designed to enhance the reasoning abilities of Large Language Models (LLMs) using Reinforcement Learning with Verifiable Reward (RLVR). It addresses the challenge of generating high-quality synthetic data for reasoning-intensive tasks by providing a curated dataset called LoongBench and a modular environment for synthetic data generation, known as LoongEnv. LoongBench includes thousands of human-verified examples across various domains, while LoongEnv allows for the creation of new question-answer-code triples through different prompting strategies. This framework enables LLMs to learn and improve their reasoning by rewarding them for producing correct Chain-of-Thought solutions that match executable code outputs.', title='Empowering LLMs with Synthetic Data for Enhanced Reasoning'))
[05.09.2025 21:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Loong项目提出了一个框架，用于生成和验证合成数据，以提高大型语言模型的推理能力，采用可验证奖励的强化学习方法。该框架包括两个主要组件：LoongBench，一个包含8729个经过人工审核的示例的种子数据集，涵盖12个领域；以及LoongEnv，一个模块化的合成数据生成环境，支持多种提示策略生成新的问答代码三元组。通过这些组件，形成了一个代理-环境循环，使得基于大型语言模型的代理能够通过生成符合代码执行答案的思维链解决方案来获得奖励。我们对LoongBench进行了广泛的基准测试，以评估领域覆盖率并揭示性能瓶颈。","title":"合成数据生成与验证的创新框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Loong项目提出了一个框架，用于生成和验证合成数据，以提高大型语言模型的推理能力，采用可验证奖励的强化学习方法。该框架包括两个主要组件：LoongBench，一个包含8729个经过人工审核的示例的种子数据集，涵盖12个领域；以及LoongEnv，一个模块化的合成数据生成环境，支持多种提示策略生成新的问答代码三元组。通过这些组件，形成了一个代理-环境循环，使得基于大型语言模型的代理能够通过生成符合代码执行答案的思维链解决方案来获得奖励。我们对LoongBench进行了广泛的基准测试，以评估领域覆盖率并揭示性能瓶颈。', title='合成数据生成与验证的创新框架'))
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#optimization", "#training", "#architecture", "#dataset", "#open_source"], "emoji": "📐", "ru": {"title": "От чертежа к CAD: автоматическая генерация 3D-моделей из 2D-чертежей", "desc": "Drawing2CAD - это фреймворк, который преобразует 2D векторные чертежи в параметрические CAD-модел
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#transfer_learning", "#dataset", "#data", "#open_source"], "emoji": "🧠", "ru": {"title": "Delta Activations: Навигация в мире дообученных языковых моделей", "desc": "Метод Delta Activations представляет дообученные модели в виде векторных эмбеддингов, о
[05.09.2025 21:10] Using data from previous issue: {"categories": ["#security", "#training", "#alignment", "#benchmark", "#data", "#open_source"], "emoji": "🕵️", "ru": {"title": "Зондирование LLM: за фасадом кажущейся безопасности", "desc": "Исследование показало, что методы зондирования для обнаружения вредоносных инструкций в больших языковых моде
[05.09.2025 21:10] Renaming data file.
[05.09.2025 21:10] Renaming previous data. hf_papers.json to ./d/2025-09-05.json
[05.09.2025 21:10] Saving new data file.
[05.09.2025 21:10] Generating page.
[05.09.2025 21:10] Renaming previous page.
[05.09.2025 21:10] Renaming previous data. index.html to ./d/2025-09-05.html
[05.09.2025 21:10] Writing result.
[05.09.2025 21:10] Renaming log file.
[05.09.2025 21:10] Renaming previous data. log.txt to ./logs/2025-09-05_last_log.txt
