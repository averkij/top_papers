[05.09.2025 15:12] Read previous papers.
[05.09.2025 15:12] Generating top page (month).
[05.09.2025 15:12] Writing top page (month).
[05.09.2025 16:13] Read previous papers.
[05.09.2025 16:13] Get feed.
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03867
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04338
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01396
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04419
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04292
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04394
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20478
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04011
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04406
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04434
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18733
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04442
[05.09.2025 16:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03888
[05.09.2025 16:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.09.2025 16:13] No deleted papers detected.
[05.09.2025 16:13] Downloading and parsing papers (pdf, html). Total: 13.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.03867.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.03867.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.03867.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04338.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04338.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04338.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.01396.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.01396.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.01396.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04419.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04419.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04419.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04292.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04292.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04292.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04394.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04394.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04394.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2508.20478.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2508.20478.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2508.20478.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04011.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04011.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04011.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04406.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04406.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04406.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04434.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04434.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04434.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2508.18733.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2508.18733.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2508.18733.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.04442.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.04442.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.04442.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2509.03888.
[05.09.2025 16:13] Extra JSON file exists (./assets/json/2509.03888.json), skip PDF parsing.
[05.09.2025 16:13] Paper image links file exists (./assets/img_data/2509.03888.json), skip HTML parsing.
[05.09.2025 16:13] Success.
[05.09.2025 16:13] Enriching papers with extra data.
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 0. LLMs struggle with understanding the nuanced, context-dependent meanings of Drivelological text, which appears nonsensical but contains deeper semantic layers.  					AI-generated summary 				 We introduce Drivelology, a unique linguistic phenomenon characterised as "nonsense with depth", utterances ...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 1. FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) gene...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 2. DeepResearch Arena, a benchmark using academic seminar transcripts, provides high-quality research tasks to evaluate deep research agents across multiple disciplines.  					AI-generated summary 				 Deep research agents have attracted growing attention for their potential to orchestrate multi-stage ...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 3. A unified policy gradient estimator and Hybrid Post-Training algorithm effectively combine online and offline data for post-training language models, improving performance across various benchmarks.  					AI-generated summary 				 Two major sources of training data exist for post-training modern lan...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 4. Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often e...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 5. A novel generative paradigm, Transition Models (TiM), addresses the trade-off between computational cost and output quality in generative modeling by using a continuous-time dynamics equation.  					AI-generated summary 				 A fundamental dilemma in generative modeling persists: iterative diffusion ...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 6. Video-MTR, a reinforced multi-turn reasoning framework, improves long-form video understanding by iteratively selecting key segments and comprehending questions, outperforming existing methods in accuracy and efficiency.  					AI-generated summary 				 Long-form video understanding, characterized by...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 7. NER Retriever uses internal representations from large language models to perform zero-shot named entity retrieval by embedding entity mentions and type descriptions into a shared semantic space, outperforming lexical and dense sentence-level retrieval methods.  					AI-generated summary 				 We pre...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 8. A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models ...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 9. Durian uses dual reference networks and a diffusion model to generate high-fidelity portrait animations with attribute transfer from a reference image to a target portrait in a zero-shot manner.  					AI-generated summary 				 We present Durian, the first method for generating portrait animation vid...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 10. Drawing2CAD is a framework that converts 2D vector drawings into parametric CAD models using a sequence-to-sequence learning approach with a dual-decoder transformer architecture and a soft target distribution loss function.  					AI-generated summary 				 Computer-Aided Design (CAD) generative mode...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 11. Delta Activations represent fine-tuned models as vector embeddings based on internal activation shifts, enabling effective clustering and model reuse.  					AI-generated summary 				 The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collectio...
[05.09.2025 16:13] ********************************************************************************
[05.09.2025 16:13] Abstract 12. Probing-based approaches for detecting harmful instructions in LLMs are found to rely on superficial patterns rather than semantic understanding, indicating a need for redesigning models and evaluation methods.  					AI-generated summary 				 Large Language Models (LLMs) can comply with harmful inst...
[05.09.2025 16:13] Read previous papers.
[05.09.2025 16:13] Generating reviews via LLM API.
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#hallucinations", "#multilingual", "#benchmark", "#reasoning", "#alignment", "#dataset"], "emoji": "üß†", "ru": {"title": "–ë–µ—Å—Å–º—ã—Å–ª–∏—Ü–∞ —Å –≥–ª—É–±–∏–Ω–æ–π: –≤—ã–∑–æ–≤ –¥–ª—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—é '–¥—Ä–∏–≤–µ–ª–æ–ª–æ–≥–∏–∏' - –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ñ–µ–Ω–æ–º–µ–Ω–∞, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#inference", "#cv", "#diffusion", "#optimization", "#training"], "emoji": "üî¨", "ru": {"title": "FE2E: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ—Ü–µ–Ω–∫–µ –≥–ª—É–±–∏–Ω—ã –∏ –Ω–æ—Ä–º–∞–ª–µ–π —Å –ø–æ–º–æ—â—å—é Diffusion Transformer", "desc": "FE2E - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π Diffusion Transformer –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–ª–æ—Ç–Ω–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–∏. –û
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#leakage", "#science", "#agents", "#benchmark", "#survey", "#dataset"], "emoji": "üß†", "ru": {"title": "–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ —Å–µ–º–∏–Ω–∞—Ä—ã –∫–∞–∫ –æ—Å–Ω–æ–≤–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ò–ò-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π", "desc": "DeepResearch Arena - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≥–ª—É–±–æ–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ç—Ä–∞–Ω—Å
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "üß†", "ru": {"title": "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –æ–Ω–ª–∞–π–Ω –∏ –æ—Ñ–ª–∞–π–Ω –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ü–µ–Ω—â–∏–∫ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ—Å—Ç-–æ–±—É—á–µ–Ω–∏—è –¥–ª—è —è–∑—ã–∫–æ–≤
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#multilingual", "#hallucinations", "#dataset", "#benchmark", "#alignment"], "emoji": "üß†", "ru": {"title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–π –∏–Ω–µ—Ä—Ü–∏–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ Inverse IFEval –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø—Ä
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#small_models", "#optimization", "#generative_modeling", "#diffusion", "#training"], "emoji": "üîÑ", "ru": {"title": "TiM: –≥–∏–±–∫–æ–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è - Transition Models (TiM). TiM
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#long_context", "#video", "#rl", "#reasoning"], "emoji": "üé•", "ru": {"title": "–£–º–Ω–æ–µ –≤–∏–¥–µ–æ: –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è", "desc": "Video-MTR - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≤—ã–±–æ—Ä—É –∫–ª—é—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑—É –≤–æ–ø
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#transfer_learning", "#multimodal", "#open_source"], "emoji": "üîç", "ru": {"title": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π –±–µ–∑ —Å—Ö–µ–º —Å –ø–æ–º–æ—â—å—é –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "NER Retriever - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#3d", "#inference", "#diffusion", "#optimization", "#training"], "emoji": "üöÄ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ 3D-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –ø–æ—Ç–æ–∫–æ–≤", "desc": "MDT-dist - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ç–æ–∫–æ–≤. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—é
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#video"], "emoji": "üçç", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–Ω–∏–º–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤: –ø–µ—Ä–µ–Ω–æ—Å –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Durian –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#architecture", "#dataset", "#open_source"], "emoji": "üìê", "ru": {"title": "–û—Ç —á–µ—Ä—Ç–µ–∂–∞ –∫ CAD: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 3D-–º–æ–¥–µ–ª–µ–π –∏–∑ 2D-—á–µ—Ä—Ç–µ–∂–µ–π", "desc": "Drawing2CAD - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç 2D –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —á–µ—Ä—Ç–µ–∂–∏ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ CAD-–º–æ–¥–µ–ª
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#architecture", "#training", "#transfer_learning", "#dataset", "#data", "#open_source"], "emoji": "üß†", "ru": {"title": "Delta Activations: –ù–∞–≤–∏–≥–∞—Ü–∏—è –≤ –º–∏—Ä–µ –¥–æ–æ–±—É—á–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ú–µ—Ç–æ–¥ Delta Activations –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –æ
[05.09.2025 16:13] Using data from previous issue: {"categories": ["#security", "#training", "#alignment", "#benchmark", "#data", "#open_source"], "emoji": "üïµÔ∏è", "ru": {"title": "–ó–æ–Ω–¥–∏—Ä–æ–≤–∞–Ω–∏–µ LLM: –∑–∞ —Ñ–∞—Å–∞–¥–æ–º –∫–∞–∂—É—â–µ–π—Å—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ –º–µ—Ç–æ–¥—ã –∑–æ–Ω–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ
[05.09.2025 16:13] Renaming data file.
[05.09.2025 16:13] Renaming previous data. hf_papers.json to ./d/2025-09-05.json
[05.09.2025 16:13] Saving new data file.
[05.09.2025 16:13] Generating page.
[05.09.2025 16:13] Renaming previous page.
[05.09.2025 16:13] Renaming previous data. index.html to ./d/2025-09-05.html
[05.09.2025 16:13] Writing result.
[05.09.2025 16:13] Renaming log file.
[05.09.2025 16:13] Renaming previous data. log.txt to ./logs/2025-09-05_last_log.txt
