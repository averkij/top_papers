[05.09.2025 04:14] Read previous papers.
[05.09.2025 04:14] Generating top page (month).
[05.09.2025 04:14] Writing top page (month).
[05.09.2025 05:11] Read previous papers.
[05.09.2025 05:11] Get feed.
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04419
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01396
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04394
[05.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.04338
[05.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.04406
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18733
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04434
[05.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.04292
[05.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.03888
[05.09.2025 05:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.09.2025 05:11] No deleted papers detected.
[05.09.2025 05:11] Downloading and parsing papers (pdf, html). Total: 9.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04419.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.04419.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.04419.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.01396.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.01396.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.01396.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04394.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.04394.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.04394.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04338.
[05.09.2025 05:11] Downloading paper 2509.04338 from http://arxiv.org/pdf/2509.04338v1...
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 ] . [ 1 8 3 3 4 0 . 9 0 5 2 : r FROM EDITOR TO DENSE GEOMETRY ESTIMATOR Jiyuan Wang1,2 Chunyu Lin1 (cid:66) Lei Sun2 Rongying Liu1 Lang Nie3 Mingxing Li2 Kang Liao4 Xiangxiang Chu2 Yao Zhao1 1BJTU 2AMAP Alibaba Group 3CQUPT 4NTU Figure 1: We present FE2E, DiT-based foundation model for monocular dense geometry prediction. Trained with limited supervision, FE2E achieves promising performance improvements in zero-shot depth and normal estimation. Bar length indicates the average ranking across all metrics from multiple datasets, where lower values are better. represents the amount of training data used. ABSTRACT Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be more suitable foundation for fine-tuning. Motivated by this, we conduct systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by refining their innate features, and ultimately achieve higher performance than their generative counterparts. Based on these findings, we introduce FE2E, framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editors original flow matching loss into the consistent velocity training objective. And we use logarithmic quantization to resolve the precision conflict between the editors native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiTs global attention for cost-free joint estimation of depth and normals in single forward pass, enabling their supervisory signals to mutually enhance eac"
[05.09.2025 05:11] Response: ```python
["BJTU", "AMAP Alibaba Group", "CQUPT", "NTU"]
```
[05.09.2025 05:11] Deleting PDF ./assets/pdf/2509.04338.pdf.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04406.
[05.09.2025 05:11] Downloading paper 2509.04406 from http://arxiv.org/pdf/2509.04406v1...
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 ] . [ 1 6 0 4 4 0 . 9 0 5 2 : r Few-step Flow for 3D Generation via Marginal-Data Transport Distillation Zanwei Zhou1, Taoran Yi2, Jiemin Fang3, Chen Yang3 Lingxi Xie3 Xinggang Wang2 Wei Shen1, Qi Tian3 1Shanghai Jiao Tong University 2Huazhong University of Science and Technology 3Huawei Inc. sjtu19zzw, wei.shen @sjtu.edu.cn { jaminfong, chenyang.res, 198808xc } taoranyi, xgwang @hust.edu.cn } tian.qi1@huawei.com { @gmail.com } https://github.com/Zanue/MDT-dist { "
[05.09.2025 05:11] Response: ```python
["Shanghai Jiao Tong University", "Huazhong University of Science and Technology", "Huawei Inc."]
```
[05.09.2025 05:11] Deleting PDF ./assets/pdf/2509.04406.pdf.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2508.18733.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2508.18733.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2508.18733.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04434.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.04434.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.04434.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.04292.
[05.09.2025 05:11] Downloading paper 2509.04292 from http://arxiv.org/pdf/2509.04292v1...
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions? 5 2 0 2 4 ] . [ 1 2 9 2 4 0 . 9 0 5 2 : r a "
[05.09.2025 05:11] Response: []
[05.09.2025 05:11] Extracting affiliations from text.
[05.09.2025 05:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?5 2 0 2 4 ] . [ 1 2 9 2 4 0 . 9 0 5 2 : r aLarge Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using human-in-the-loop pipeline, we construct dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both diagnostic tool and foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios. Date: September 5, 2025 Correspondence: Jiaheng Liu at liujiaheng@nju.edu.cn, Zaiyuan Wang at wangzaiyuan@bytedance.com, Qinyan Zhang at zhangqinyan.25@jiyunhudong.com Project Page: https://huggingface.co/datasets/m-a-p/Inverse_IFEvalLarge Language Models (LLMs) have rapidly advanced in recent years, achieving remarkable success across wide spectrum of natural language processing (NLP) tasks, including question answering [23, 35], reasoning [9, 26], summarization [33], and code generation [16, 25, 27]. Their capabilities are largely attributed to massive pretraining on large-scale corpora followed by supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). However, while these models excel under conventional conditions, their robustness in handling atypical or counterintuitive instructions remains underexplored. As shown in Figure 1, there exists marked difference in the models instruction-following performance when responding to conventional instructions versus counterintuitive instructions. Specifically, when confronted with directives such as You must strictly avoid using bullet point format, the model frequently fails to comply. In such cases, users often respond with frustration, exclaiming: 1 Do As Say, Not As You Were Trained !! This raises several important questions: What underlying factors lead to such failures? Which types of counterintuitive instructions are models more prone to disregard? Ultimately, we are left with fundamental inquiry: Can LLMs unlearn stubborn training conventions in order to follow real instructions? key limitation arises from the nature of data annotation. In practice, annotation processes tend to follow an idealized paradigmthat is, annotators generate responses aligned with standardized formats, correctness norms, and readability principles. As result, LLMs trained on such corpora inherit strong inductive bias toward these conventions. While this paradigm ensures fluent and factual outputs, it also creates what we term cognitive inertia: models struggle when tasked with instructions that explicitly deviate from their training norms. Closely related is the risk of overfitting: when models become overly attuned to post-training patterns, they may lose flexibility and fail to generalize beyond the narrow conventions reinforced during annotation. For instance, an instruction requiring an unstructured essay with no paragraph breaks, or deliberately incorrect answers to simple factual questions, directly conflicts with patterns reinforced during SFT. This tension motivates the development of new evaluation dimensionCounterintuitive Abilitywhich measures whether an LLM can override its ingrained training conventions and faithfully follow counterintuitive instructions. Such an ability is crucial for assessing genuine instruction-following robustness, as real-world applications often involve unconventional, ambiguous, or dynamically shifting requirements. To this end, we introduce Inverse IFEval, novel benchmark specifically designed to evaluate LLMs under counter-intuitive instruction scenarios, which we refer to as inverse instructions. In practice, there will always be long-tail user needs that post-training fails to cover. Although such instructions may not be as extreme as those deliberately constructed in Inverse IFEval, we argue that this benchmark captures an essential aspect of model robustness: the ability to follow out-of-distribution (OOD) instructions. Unlike prior benchmarks such as MMLU or IFEval, which primarily assess factuality or knowledge recall, Inverse IFEval systematically inverts conventional training paradigms to create eight categories of challenging instructions: (1) Question Correction, (2) Intentional Textual Flaws, (3) Code without Comments, (4) Counter-Conventional Formatting, (5) Deliberately Incorrect Answers, (6) Instructional Induction, (7) Mid-turn Instruction Modification, and (8) Counterfactual Answering. These categories target situations rarely represented in standard training corpora, thereby providing more rigorous test of instruction-following fidelity. Moreover, we construct the benchmark through multi-stage human-in-the-loop pipeline, combining expert seed question design, large-scale LLM-based generation, automatic filtering, and rigorous expert review. The final dataset comprises 1012 high-quality questions across 23 diverse domains, ranging from computer science and mathematics to law, literature, and biology. In summary, our contributions are threefold: We identify Counter-Cognitive Ability as critical but underexplored dimension of LLM evaluation. We introduce Inverse IFEval, the first large-scale benchmark explicitly designed to test LLMs under counterintuitive instruction conditions. The dataset is publicly available on Hugging Face at Inverse IFEval. We provide extensive experimental analyses across multiple languages and model families, offering fresh insights into the limitations of current alignment methods a"
[05.09.2025 05:11] Mistral response. {"id": "f659e6fff3b94568b134cd26af699f69", "created": 1757049115, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1339, "total_tokens": 1365, "completion_tokens": 26}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Nanjing University\",\n    \"ByteDance\",\n    \"Jiyun Hudong\"\n]\n```"}}]}
[05.09.2025 05:11] Response: ```python
[
    "Nanjing University",
    "ByteDance",
    "Jiyun Hudong"
]
```
[05.09.2025 05:11] Deleting PDF ./assets/pdf/2509.04292.pdf.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.03888.
[05.09.2025 05:11] Extra JSON file exists (./assets/json/2509.03888.json), skip PDF parsing.
[05.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.03888.json), skip HTML parsing.
[05.09.2025 05:11] Success.
[05.09.2025 05:11] Enriching papers with extra data.
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 0. A unified policy gradient estimator and Hybrid Post-Training algorithm effectively combine online and offline data for post-training language models, improving performance across various benchmarks.  					AI-generated summary 				 Two major sources of training data exist for post-training modern lan...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 1. DeepResearch Arena, a benchmark using academic seminar transcripts, provides high-quality research tasks to evaluate deep research agents across multiple disciplines.  					AI-generated summary 				 Deep research agents have attracted growing attention for their potential to orchestrate multi-stage ...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 2. A novel generative paradigm, Transition Models (TiM), addresses the trade-off between computational cost and output quality in generative modeling by using a continuous-time dynamics equation.  					AI-generated summary 				 A fundamental dilemma in generative modeling persists: iterative diffusion ...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 3. FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) gene...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 4. A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models ...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 5. Drawing2CAD is a framework that converts 2D vector drawings into parametric CAD models using a sequence-to-sequence learning approach with a dual-decoder transformer architecture and a soft target distribution loss function.  					AI-generated summary 				 Computer-Aided Design (CAD) generative mode...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 6. Durian uses dual reference networks and a diffusion model to generate high-fidelity portrait animations with attribute transfer from a reference image to a target portrait in a zero-shot manner.  					AI-generated summary 				 We present Durian, the first method for generating portrait animation vid...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 7. Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often e...
[05.09.2025 05:11] ********************************************************************************
[05.09.2025 05:11] Abstract 8. Probing-based approaches for detecting harmful instructions in LLMs are found to rely on superficial patterns rather than semantic understanding, indicating a need for redesigning models and evaluation methods.  					AI-generated summary 				 Large Language Models (LLMs) can comply with harmful inst...
[05.09.2025 05:11] Read previous papers.
[05.09.2025 05:11] Generating reviews via LLM API.
[05.09.2025 05:11] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "🧠", "ru": {"title": "Объединение онлайн и офлайн данных для улучшения языковых моделей", "desc": "В статье представлен унифицированный оценщик градиента политики и алгоритм гибридного пост-обучения для языков
[05.09.2025 05:11] Using data from previous issue: {"categories": ["#leakage", "#science", "#agents", "#benchmark", "#survey", "#dataset"], "emoji": "🧠", "ru": {"title": "Академические семинары как основа для оценки ИИ-исследователей", "desc": "DeepResearch Arena - это новый бенчмарк для оценки глубоких исследовательских агентов, основанный на транс
[05.09.2025 05:11] Using data from previous issue: {"categories": ["#small_models", "#optimization", "#generative_modeling", "#diffusion", "#training"], "emoji": "🔄", "ru": {"title": "TiM: гибкое генеративное моделирование с непрерывным временем", "desc": "Статья представляет новую парадигму генеративного моделирования - Transition Models (TiM). TiM
[05.09.2025 05:11] Querying the API.
[05.09.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.   Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining" their innate features, and ultimately achieve higher performance than their generative counterparts.   Based on these findings, we introduce FE2E, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.   Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100times data. The project page can be accessed https://amap-ml.github.io/FE2E/{here}.
[05.09.2025 05:12] Response: {
  "desc": "FE2E - это новый фреймворк, использующий Diffusion Transformer для предсказания плотной геометрии. Он превосходит генеративные модели в задачах оценки глубины и нормалей с нулевым обучением. FE2E адаптирует продвинутую модель редактирования на основе архитектуры DiT для этой задачи. Без увеличения объема обучающих данных, FE2E достигает значительных улучшений производительности в оценке монокулярной глубины и нормалей на нескольких наборах данных.",
  "emoji": "🔬",
  "title": "FE2E: Революция в оценке глубины и нормалей с помощью Diffusion Transformer"
}
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.   Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining" their innate features, and ultimately achieve higher performance than their generative counterparts.   Based on these findings, we introduce FE2E, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.   Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100times data. The project page can be accessed https://amap-ml.github.io/FE2E/{here}."

[05.09.2025 05:12] Response: ```python
['CV', 'TRAINING', 'INFERENCE']
```
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FE2E, a framework using a Diffusion Transformer for dense geometry prediction, outperforms generative models in zero-shot monocular depth and normal estimation with improved performance and efficiency.  					AI-generated summary 				 Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.   Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining" their innate features, and ultimately achieve higher performance than their generative counterparts.   Based on these findings, we introduce FE2E, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.   Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100times data. The project page can be accessed https://amap-ml.github.io/FE2E/{here}."

[05.09.2025 05:12] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces FE2E, a novel framework that utilizes a Diffusion Transformer for predicting dense geometry, specifically focusing on monocular depth and normal estimation. It demonstrates that editing models, which refine existing features, outperform generative models in this context due to their structural priors. The authors reformulate the training objective to enhance the model\'s performance and employ logarithmic quantization to address precision issues. FE2E achieves significant improvements in performance without requiring additional training data, showcasing its efficiency and effectiveness across various datasets.","title":"FE2E: Revolutionizing Dense Geometry Prediction with Diffusion Transformers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces FE2E, a novel framework that utilizes a Diffusion Transformer for predicting dense geometry, specifically focusing on monocular depth and normal estimation. It demonstrates that editing models, which refine existing features, outperform generative models in this context due to their structural priors. The authors reformulate the training objective to enhance the model's performance and employ logarithmic quantization to address precision issues. FE2E achieves significant improvements in performance without requiring additional training data, showcasing its efficiency and effectiveness across various datasets.", title='FE2E: Revolutionizing Dense Geometry Prediction with Diffusion Transformers'))
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FE2E是一个使用扩散变换器的框架，专注于密集几何预测，表现优于生成模型，尤其在零样本单目深度和法线估计方面。该研究表明，图像编辑模型比文本到图像生成模型更适合进行密集预测，因为它们具有更稳定的收敛性和更高的性能。通过重新设计编辑模型的损失函数和使用对数量化，FE2E有效解决了精度问题，并利用全局注意力实现深度和法线的联合估计。最终，FE2E在多个数据集上取得了显著的性能提升，尤其是在ETH3D数据集上超过了35%的性能增益。","title":"FE2E：密集几何预测的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FE2E是一个使用扩散变换器的框架，专注于密集几何预测，表现优于生成模型，尤其在零样本单目深度和法线估计方面。该研究表明，图像编辑模型比文本到图像生成模型更适合进行密集预测，因为它们具有更稳定的收敛性和更高的性能。通过重新设计编辑模型的损失函数和使用对数量化，FE2E有效解决了精度问题，并利用全局注意力实现深度和法线的联合估计。最终，FE2E在多个数据集上取得了显著的性能提升，尤其是在ETH3D数据集上超过了35%的性能增益。', title='FE2E：密集几何预测的新突破'))
[05.09.2025 05:12] Querying the API.
[05.09.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation.
[05.09.2025 05:12] Response: {
  "desc": "MDT-dist - это новая система для ускорения генерации 3D-моделей на основе потоков. Она использует дистилляцию предобученных моделей для изучения маргинального транспорта данных через сопоставление и дистилляцию скоростей. Это позволяет сократить количество шагов сэмплирования с 25 до 1-2, значительно ускоряя процесс. MDT-dist превосходит существующие методы дистилляции и обеспечивает высокое качество генерируемых 3D-моделей.",
  "emoji": "🚀",
  "title": "Революционное ускорение 3D-генерации с помощью дистилляции потоков"
}
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation."

[05.09.2025 05:12] Response: ```python
["3D", "INFERENCE", "TRAINING"]
```
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework, MDT-dist, accelerates 3D flow generation by distilling pretrained models to learn Marginal-Data Transport through Velocity Matching and Velocity Distillation, reducing sampling steps and improving speed and fidelity.  					AI-generated summary 				 Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation."

[05.09.2025 05:12] Response: ```python
["OPTIMIZATION", "DIFFUSION"]
```
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces MDT-dist, a new framework designed to speed up 3D flow generation by using a technique called distillation on pretrained models. It focuses on learning Marginal-Data Transport through two main strategies: Velocity Matching (VM) and Velocity Distillation (VD). VM helps align the velocity fields of the student and teacher models, while VD improves the process by distilling probability densities from the learned velocity fields. This approach significantly reduces the number of sampling steps needed, achieving faster generation times while maintaining high quality in the output.","title":"Accelerating 3D Flow Generation with MDT-dist"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces MDT-dist, a new framework designed to speed up 3D flow generation by using a technique called distillation on pretrained models. It focuses on learning Marginal-Data Transport through two main strategies: Velocity Matching (VM) and Velocity Distillation (VD). VM helps align the velocity fields of the student and teacher models, while VD improves the process by distilling probability densities from the learned velocity fields. This approach significantly reduces the number of sampling steps needed, achieving faster generation times while maintaining high quality in the output.', title='Accelerating 3D Flow Generation with MDT-dist'))
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新颖的框架MDT-dist，用于加速3D流生成。该方法通过对预训练模型进行蒸馏，学习边际数据传输，结合速度匹配和速度蒸馏，显著减少了采样步骤，提高了生成速度和保真度。与传统的3D生成模型相比，MDT-dist能够将每个流变换器的采样步骤从25减少到1或2，同时保持高质量的视觉和几何保真度。实验结果表明，该方法在少步3D生成任务中显著优于现有的蒸馏方法。","title":"MDT-dist：加速3D流生成的新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新颖的框架MDT-dist，用于加速3D流生成。该方法通过对预训练模型进行蒸馏，学习边际数据传输，结合速度匹配和速度蒸馏，显著减少了采样步骤，提高了生成速度和保真度。与传统的3D生成模型相比，MDT-dist能够将每个流变换器的采样步骤从25减少到1或2，同时保持高质量的视觉和几何保真度。实验结果表明，该方法在少步3D生成任务中显著优于现有的蒸馏方法。', title='MDT-dist：加速3D流生成的新方法'))
[05.09.2025 05:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#architecture", "#dataset", "#open_source"], "emoji": "📐", "ru": {"title": "От чертежа к CAD: автоматическая генерация 3D-моделей из 2D-чертежей", "desc": "Drawing2CAD - это фреймворк, который преобразует 2D векторные чертежи в параметрические CAD-модел
[05.09.2025 05:12] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#video"], "emoji": "🍍", "ru": {"title": "Революция в анимации портретов: перенос атрибутов без предварительного обучения", "desc": "Статья представляет метод Durian для генерации анимированных портретов с переносом атрибутов с референсного изображ
[05.09.2025 05:12] Querying the API.
[05.09.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios.
[05.09.2025 05:12] Response: {
  "desc": "Статья представляет новый бенчмарк Inverse IFEval для оценки способности больших языковых моделей (LLM) преодолевать предвзятости, полученные в ходе обучения, и следовать нестандартным инструкциям. Бенчмарк включает восемь типов задач, таких как исправление вопросов и контрфактический ответ, охватывая 1012 вопросов на китайском и английском языках. Эксперименты показали необходимость такой оценки для выявления ограничений существующих LLM. Авторы подчеркивают важность развития адаптивности моделей в разнообразных и непредсказуемых реальных сценариях.",
  "emoji": "🧠",
  "title": "Преодоление когнитивной инерции в больших языковых моделях"
}
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios."

[05.09.2025 05:12] Response: ```python
['BENCHMARK', 'DATASET', 'MULTILINGUAL']
```
[05.09.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Inverse IFEval evaluates Large Language Models' ability to override training biases and follow unconventional instructions, highlighting the need for adaptability in diverse contexts.  					AI-generated summary 				 Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios."

[05.09.2025 05:12] Response: ```python
['ALIGNMENT', 'HALLUCINATIONS']
```
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Inverse IFEval, a benchmark designed to assess the ability of Large Language Models (LLMs) to overcome biases from their training and follow unconventional instructions. It highlights that while LLMs perform well on many tasks, they often struggle with instructions that deviate from their learned patterns, a phenomenon known as cognitive inertia. The benchmark includes eight challenge types, such as Question Correction and Counterfactual Answering, to evaluate models\' adaptability across various contexts. The findings suggest that improving LLMs requires not just fluency and accuracy, but also the ability to adapt to unexpected instructions in real-world applications.","title":"Enhancing LLMs: Overcoming Biases for Better Adaptability"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces Inverse IFEval, a benchmark designed to assess the ability of Large Language Models (LLMs) to overcome biases from their training and follow unconventional instructions. It highlights that while LLMs perform well on many tasks, they often struggle with instructions that deviate from their learned patterns, a phenomenon known as cognitive inertia. The benchmark includes eight challenge types, such as Question Correction and Counterfactual Answering, to evaluate models' adaptability across various contexts. The findings suggest that improving LLMs requires not just fluency and accuracy, but also the ability to adapt to unexpected instructions in real-world applications.", title='Enhancing LLMs: Overcoming Biases for Better Adaptability'))
[05.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了Inverse IFEval基准，用于评估大型语言模型（LLMs）在面对与训练偏见相悖的指令时的适应能力。研究发现，尽管LLMs在多种任务上表现出色，但它们在遵循与标准化模式相冲突的指令时常常表现出认知惯性。Inverse IFEval引入了八种挑战类型，旨在测量模型克服训练偏见的能力。我们的实验结果表明，未来的对齐工作不仅要关注流畅性和事实正确性，还要考虑在非常规环境下的适应性。","title":"评估语言模型的适应能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了Inverse IFEval基准，用于评估大型语言模型（LLMs）在面对与训练偏见相悖的指令时的适应能力。研究发现，尽管LLMs在多种任务上表现出色，但它们在遵循与标准化模式相冲突的指令时常常表现出认知惯性。Inverse IFEval引入了八种挑战类型，旨在测量模型克服训练偏见的能力。我们的实验结果表明，未来的对齐工作不仅要关注流畅性和事实正确性，还要考虑在非常规环境下的适应性。', title='评估语言模型的适应能力'))
[05.09.2025 05:12] Using data from previous issue: {"categories": ["#security", "#training", "#alignment", "#benchmark", "#data", "#open_source"], "emoji": "🕵️", "ru": {"title": "Зондирование LLM: за фасадом кажущейся безопасности", "desc": "Исследование показало, что методы зондирования для обнаружения вредоносных инструкций в больших языковых моде
[05.09.2025 05:12] Renaming data file.
[05.09.2025 05:12] Renaming previous data. hf_papers.json to ./d/2025-09-05.json
[05.09.2025 05:12] Saving new data file.
[05.09.2025 05:12] Generating page.
[05.09.2025 05:12] Renaming previous page.
[05.09.2025 05:12] Renaming previous data. index.html to ./d/2025-09-05.html
[05.09.2025 05:12] Writing result.
[05.09.2025 05:12] Renaming log file.
[05.09.2025 05:12] Renaming previous data. log.txt to ./logs/2025-09-05_last_log.txt
