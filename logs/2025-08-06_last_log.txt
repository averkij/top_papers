[06.08.2025 08:17] Read previous papers.
[06.08.2025 08:17] Generating top page (month).
[06.08.2025 08:17] Writing top page (month).
[06.08.2025 09:20] Read previous papers.
[06.08.2025 09:20] Get feed.
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02193
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03320
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03694
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03686
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02091
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03012
[06.08.2025 09:20] Extract page data from URL. URL: https://huggingface.co/papers/2508.03613
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03050
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01780
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00477
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02079
[06.08.2025 09:20] Extract page data from URL. URL: https://huggingface.co/papers/2508.03164
[06.08.2025 09:20] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02063
[06.08.2025 09:20] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.08.2025 09:20] No deleted papers detected.
[06.08.2025 09:20] Downloading and parsing papers (pdf, html). Total: 13.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.02193.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.02193.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.02193.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.03320.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.03320.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.03320.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.03694.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.03694.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.03694.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.03686.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.03686.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.03686.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.02091.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.02091.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.02091.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.03012.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.03012.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.03012.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.03613.
[06.08.2025 09:20] Downloading paper 2508.03613 from http://arxiv.org/pdf/2508.03613v1...
[06.08.2025 09:20] Extracting affiliations from text.
[06.08.2025 09:20] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 ] . [ 1 3 1 6 3 0 . 8 0 5 2 : r a GOEDEL-PROVER-V2: SCALING FORMAL THEOREM PROVING WITH SCAFFOLDED DATA SYNTHESIS AND SELF-CORRECTION Yong Lin1, Shange Tang1 2 , Bohan Lyu3 , Ziran Yang1 , Jui-Hui Chung1 , Haoyu Zhao1 , Lai Jiang7 , Yihan Geng8 , Jiawei Ge1, Jingruo Sun4, Jiayun Wu3, Jiri Gesi6 , Ximing Lu2, David Acuna2, Kaiyu Yang5 , Hongzhou Lin6 , Yejin Choi2 4, Danqi Chen1, Sanjeev Arora1, Chi Jin1 1Princeton Language and Intelligence, Princeton University 3Tsinghua University 7Shanghai Jiao Tong University 2NVIDIA 5Meta FAIR 6Amazon 4Stanford University 8Peking University "
[06.08.2025 09:20] Response: ```python
[
    "Princeton Language and Intelligence, Princeton University",
    "Tsinghua University",
    "Shanghai Jiao Tong University",
    "NVIDIA",
    "Meta FAIR",
    "Amazon",
    "Stanford University",
    "Peking University"
]
```
[06.08.2025 09:20] Deleting PDF ./assets/pdf/2508.03613.pdf.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.03050.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.03050.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.03050.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.01780.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.01780.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.01780.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.00477.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.00477.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.00477.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.02079.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.02079.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.02079.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.03164.
[06.08.2025 09:20] Downloading paper 2508.03164 from http://arxiv.org/pdf/2508.03164v1...
[06.08.2025 09:20] Extracting affiliations from text.
[06.08.2025 09:20] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"CHARTCAP: Mitigating Hallucination of Dense Chart Captioning Junyoung Lim Jaewoo Ahn Gunhee Kim Seoul National University {junyoung.lim, jaewoo.ahn}@vision.snu.ac.kr, gunhee@snu.ac.kr https://junyoung-00.github.io/ChartCap/ 5 2 0 2 5 ] . [ 1 4 6 1 3 0 . 8 0 5 2 : r a "
[06.08.2025 09:20] Response: ```python
["Seoul National University"]
```
[06.08.2025 09:20] Deleting PDF ./assets/pdf/2508.03164.pdf.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Downloading and parsing paper https://huggingface.co/papers/2508.02063.
[06.08.2025 09:20] Extra JSON file exists (./assets/json/2508.02063.json), skip PDF parsing.
[06.08.2025 09:20] Paper image links file exists (./assets/img_data/2508.02063.json), skip HTML parsing.
[06.08.2025 09:20] Success.
[06.08.2025 09:20] Enriching papers with extra data.
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 0. Seed Diffusion Preview, a discrete-state diffusion language model, achieves fast inference speeds through parallel generation, outperforming Mercury and Gemini Diffusion in speed and quality.  					AI-generated summary 				 We present Seed Diffusion Preview, a large-scale language model based on dis...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 1. Skywork UniPic, a 1.5 billion-parameter autoregressive model, unifies image understanding, text-to-image generation, and image editing with state-of-the-art performance on commodity hardware.  					AI-generated summary 				 We introduce Skywork UniPic, a 1.5 billion-parameter autoregressive model th...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 2. LongVie, an end-to-end autoregressive framework, addresses temporal consistency and visual degradation in ultra-long video generation through unified noise initialization, global control signal normalization, multi-modal control, and degradation-aware training.  					AI-generated summary 				 Contro...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 3. CompassVerifier is a lightweight, robust model for verifying LLM outputs across various domains, supported by VerifierBench, a comprehensive benchmark dataset.  					AI-generated summary 				 Answer verification is crucial not only for evaluating large language models (LLMs) by matching their unstru...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 4. CRINN, a reinforcement learning-based approach, optimizes approximate nearest-neighbor search algorithms for speed while maintaining accuracy, outperforming state-of-the-art methods on several benchmarks.  					AI-generated summary 				 Approximate nearest-neighbor search (ANNS) algorithms have beco...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 5. ToolTrain, a two-stage training framework combining supervised fine-tuning and reinforcement learning, enhances LLMs for issue localization by integrating repository retrieval tools, achieving state-of-the-art performance.  					AI-generated summary 				 Issue localization, the process of identifyin...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 6. Goedel-Prover-V2, a series of open-source language models, achieves state-of-the-art performance in automated theorem proving through scaffolded data synthesis, verifier-guided self-correction, and model averaging.  					AI-generated summary 				 We introduce Goedel-Prover-V2, a series of open-sourc...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 7. MIT, a large-scale dataset for multi-human talking video generation, includes fine-grained annotations and is used to demonstrate CovOG, a baseline model integrating a Multi-Human Pose Encoder and an Interactive Audio Driver.  					AI-generated summary 				 Existing studies on talking video generati...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 8. LiveMCPBench provides a comprehensive benchmark for evaluating LLM agents across a diverse set of real-world tasks in the MCP ecosystem, using a scalable evaluation pipeline and adaptive judging framework.  					AI-generated summary 				 With the rapid development of Model Context Protocol (MCP), th...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 9. LAMIC, a Layout-Aware Multi-Image Composition framework, extends single-reference diffusion models to multi-reference scenarios using attention mechanisms, achieving state-of-the-art performance in controllable image synthesis without training.  					AI-generated summary 				 In controllable image s...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 10. AlignGuard-LoRA (AGL) is a framework that preserves alignment during fine-tuning of large language models by introducing regularization techniques and a diagnostic benchmark to mitigate alignment drift.  					AI-generated summary 				 Low-rank adaptation (LoRA) has become a standard tool for efficie...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 11. ChartCap, a large-scale dataset with dense, type-specific captions for real-world charts, improves caption accuracy and reduces hallucinations in vision language models.  					AI-generated summary 				 Generating accurate, informative, and hallucination-free captions for charts remains challenging f...
[06.08.2025 09:20] ********************************************************************************
[06.08.2025 09:20] Abstract 12. TraceAlign is a framework that identifies and mitigates alignment drift in LLMs by tracing unsafe completions to their training sources and applying interventions to reduce drift while maintaining utility.  					AI-generated summary 				 Large Language Models (LLMs) fine-tuned to align with human va...
[06.08.2025 09:20] Read previous papers.
[06.08.2025 09:20] Generating reviews via LLM API.
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#diffusion", "#inference", "#benchmark", "#architecture", "#optimization"], "emoji": "🚀", "ru": {"title": "Революция в скорости генерации текста без потери качества", "desc": "Seed Diffusion Preview - это новая языковая модель, основанная на дискретной диффузии. Она обеспечивает оче
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#dataset", "#training", "#multimodal", "#architecture", "#open_source"], "emoji": "🖼️", "ru": {"title": "Единая модель для понимания, создания и редактирования изображений", "desc": "Skywork UniPic - это авторегрессионная модель с 1,5 миллиардами параметров, объединяющая понимание и
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#multimodal", "#long_context", "#video"], "emoji": "🎬", "ru": {"title": "LongVie: прорыв в генерации сверхдлинных видео с сохранением качества", "desc": "LongVie - это новая автореградная модель для генерации сверхдлинных видео. Она решает проблемы времен
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#benchmark", "#dataset", "#interpretability", "#optimization"], "emoji": "🧭", "ru": {"title": "CompassVerifier: Надежная проверка ответов LLM во многих областях", "desc": "CompassVerifier - это легковесная модель для проверки выходных данных больших языковых м
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#rag", "#rl", "#optimization"], "emoji": "🚀", "ru": {"title": "CRINN: Революция в поиске ближайших соседей с помощью ИИ", "desc": "CRINN - это новый подход к оптимизации алгоритмов поиска приближенных ближайших соседей (ANNS), использующий обучение с по
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#agents", "#optimization"], "emoji": "🔍", "ru": {"title": "ToolTrain: Эффективная локализация проблем в коде с помощью обученных языковых моделей", "desc": "ToolTrain - это двухэтапная система обучения, объединяющая контролируемую тонкую настройку и
[06.08.2025 09:20] Querying the API.
[06.08.2025 09:20] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Goedel-Prover-V2, a series of open-source language models, achieves state-of-the-art performance in automated theorem proving through scaffolded data synthesis, verifier-guided self-correction, and model averaging.  					AI-generated summary 				 We introduce Goedel-Prover-V2, a series of open-source language models that set a new state-of-the-art in automated theorem proving. Built on the standard expert iteration and reinforcement learning pipeline, our approach incorporates three key innovations: (1) Scaffolded data synthesis: We generate synthetic tasks of increasing difficulty to train the model to master increasingly complex theorems; (2) Verifier-guided self-correction: We enable the model to iteratively revise its proofs by leveraging feedback from the Lean compiler; (3) Model averaging: We merge model checkpoints to mitigate the decrease in model output diversity in later stages of training. Our small model, Goedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms DeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our flagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in standard mode and 90.4% in self-correction mode, outperforming prior SOTA by a large margin. Additionally, our flagship model solves 86 problems on PutnamBench at pass@184, securing the first place among open-source models on the leaderboard, surpassing DeepSeek-Prover-V2-671B's record of solving 47 problems by pass@1024 with a significantly smaller model size and compute budget. At the time of its release (July-August 2025), Goedel-Prover-V2 achieves the strongest overall performance among all open-source theorem provers. It also ranks among the top-performing models--including closed-source systems with publicly reported performance--under a constrained test-time compute budget. Our models, code, and data are released at https://github.com/Goedel-LM/Goedel-Prover-V2.
[06.08.2025 09:20] Response: {
  "desc": "Goedel-Prover-V2 - это серия открытых языковых моделей для автоматического доказательства теорем. Модель использует синтез структурированных данных, самокоррекцию на основе верификатора и усреднение моделей для достижения наилучших результатов. Несмотря на небольшой размер, Goedel-Prover-V2-8B превосходит гораздо более крупные модели на бенчмарках MiniF2F и PutnamBench. На момент выпуска Goedel-Prover-V2 демонстрирует лучшую производительность среди открытых систем автоматического доказательства теорем.",
  "emoji": "🧠",
  "title": "Маленькая модель - большие доказательства: Goedel-Prover-V2 переворачивает мир автоматического доказательства теорем"
}
[06.08.2025 09:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Goedel-Prover-V2, a series of open-source language models, achieves state-of-the-art performance in automated theorem proving through scaffolded data synthesis, verifier-guided self-correction, and model averaging.  					AI-generated summary 				 We introduce Goedel-Prover-V2, a series of open-source language models that set a new state-of-the-art in automated theorem proving. Built on the standard expert iteration and reinforcement learning pipeline, our approach incorporates three key innovations: (1) Scaffolded data synthesis: We generate synthetic tasks of increasing difficulty to train the model to master increasingly complex theorems; (2) Verifier-guided self-correction: We enable the model to iteratively revise its proofs by leveraging feedback from the Lean compiler; (3) Model averaging: We merge model checkpoints to mitigate the decrease in model output diversity in later stages of training. Our small model, Goedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms DeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our flagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in standard mode and 90.4% in self-correction mode, outperforming prior SOTA by a large margin. Additionally, our flagship model solves 86 problems on PutnamBench at pass@184, securing the first place among open-source models on the leaderboard, surpassing DeepSeek-Prover-V2-671B's record of solving 47 problems by pass@1024 with a significantly smaller model size and compute budget. At the time of its release (July-August 2025), Goedel-Prover-V2 achieves the strongest overall performance among all open-source theorem provers. It also ranks among the top-performing models--including closed-source systems with publicly reported performance--under a constrained test-time compute budget. Our models, code, and data are released at https://github.com/Goedel-LM/Goedel-Prover-V2."

[06.08.2025 09:20] Response: ```python
['DATASET', 'RL', 'TRAINING', 'SMALL_MODELS']
```
[06.08.2025 09:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Goedel-Prover-V2, a series of open-source language models, achieves state-of-the-art performance in automated theorem proving through scaffolded data synthesis, verifier-guided self-correction, and model averaging.  					AI-generated summary 				 We introduce Goedel-Prover-V2, a series of open-source language models that set a new state-of-the-art in automated theorem proving. Built on the standard expert iteration and reinforcement learning pipeline, our approach incorporates three key innovations: (1) Scaffolded data synthesis: We generate synthetic tasks of increasing difficulty to train the model to master increasingly complex theorems; (2) Verifier-guided self-correction: We enable the model to iteratively revise its proofs by leveraging feedback from the Lean compiler; (3) Model averaging: We merge model checkpoints to mitigate the decrease in model output diversity in later stages of training. Our small model, Goedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms DeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our flagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in standard mode and 90.4% in self-correction mode, outperforming prior SOTA by a large margin. Additionally, our flagship model solves 86 problems on PutnamBench at pass@184, securing the first place among open-source models on the leaderboard, surpassing DeepSeek-Prover-V2-671B's record of solving 47 problems by pass@1024 with a significantly smaller model size and compute budget. At the time of its release (July-August 2025), Goedel-Prover-V2 achieves the strongest overall performance among all open-source theorem provers. It also ranks among the top-performing models--including closed-source systems with publicly reported performance--under a constrained test-time compute budget. Our models, code, and data are released at https://github.com/Goedel-LM/Goedel-Prover-V2."

[06.08.2025 09:20] Response: ```python
['OPEN_SOURCE', 'REASONING', 'SYNTHETIC']
```
[06.08.2025 09:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Goedel-Prover-V2 is a series of open-source language models that excel in automated theorem proving. It introduces innovative techniques such as scaffolded data synthesis for training on progressively complex tasks, verifier-guided self-correction for iterative proof refinement, and model averaging to enhance output diversity. The models achieve impressive performance metrics, with the smaller Goedel-Prover-V2-8B outperforming larger models like DeepSeek-Prover-V2-671B. Overall, Goedel-Prover-V2 sets a new benchmark in the field, demonstrating superior capabilities in solving mathematical problems with a reduced computational footprint.","title":"Revolutionizing Theorem Proving with Goedel-Prover-V2"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Goedel-Prover-V2 is a series of open-source language models that excel in automated theorem proving. It introduces innovative techniques such as scaffolded data synthesis for training on progressively complex tasks, verifier-guided self-correction for iterative proof refinement, and model averaging to enhance output diversity. The models achieve impressive performance metrics, with the smaller Goedel-Prover-V2-8B outperforming larger models like DeepSeek-Prover-V2-671B. Overall, Goedel-Prover-V2 sets a new benchmark in the field, demonstrating superior capabilities in solving mathematical problems with a reduced computational footprint.', title='Revolutionizing Theorem Proving with Goedel-Prover-V2'))
[06.08.2025 09:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Goedel-Prover-V2是一系列开源语言模型，在自动定理证明领域达到了最先进的性能。该模型通过三项创新技术实现了这一目标：首先，使用支架数据合成生成逐渐增加难度的合成任务，以帮助模型掌握复杂的定理；其次，采用验证器引导的自我修正，使模型能够根据Lean编译器的反馈迭代修正其证明；最后，通过模型平均技术合并模型检查点，以减少训练后期模型输出多样性的下降。Goedel-Prover-V2-32B模型在MiniF2F上达到了88.1%的通过率，显著超越了之前的最先进模型。","title":"Goedel-Prover-V2：自动定理证明的新标杆"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Goedel-Prover-V2是一系列开源语言模型，在自动定理证明领域达到了最先进的性能。该模型通过三项创新技术实现了这一目标：首先，使用支架数据合成生成逐渐增加难度的合成任务，以帮助模型掌握复杂的定理；其次，采用验证器引导的自我修正，使模型能够根据Lean编译器的反馈迭代修正其证明；最后，通过模型平均技术合并模型检查点，以减少训练后期模型输出多样性的下降。Goedel-Prover-V2-32B模型在MiniF2F上达到了88.1%的通过率，显著超越了之前的最先进模型。', title='Goedel-Prover-V2：自动定理证明的新标杆'))
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#dataset"], "emoji": "🗣️", "ru": {"title": "Новый датасет и модель для генерации видео с разговорами нескольких людей", "desc": "Исследователи представили MIT - крупномасштабный набор данных для генерации видео с разговорами нескольких людей. Этот датасет включа
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#open_source", "#survey", "#agents", "#benchmark"], "emoji": "🤖", "ru": {"title": "LiveMCPBench: Новый стандарт оценки LLM-агентов в реальных MCP-средах", "desc": "LiveMCPBench представляет собой комплексный бенчмарк для оценки агентов на основе больших языковых моделей (LLM) в реал
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#optimization", "#cv", "#training"], "emoji": "🖼️", "ru": {"title": "LAMIC: Революция в синтезе изображений с несколькими референсами", "desc": "LAMIC - это фреймворк для композиции нескольких изображений с учетом макета, который расширяет возможности ди
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#alignment", "#open_source", "#training"], "emoji": "🛡️", "ru": {"title": "Сохранение безопасности при дообучении языковых моделей", "desc": "AlignGuard-LoRA (AGL) - это фреймворк для сохранения выравнивания при дообучении больших языковых моделей. Он вводи
[06.08.2025 09:20] Querying the API.
[06.08.2025 09:20] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ChartCap, a large-scale dataset with dense, type-specific captions for real-world charts, improves caption accuracy and reduces hallucinations in vision language models.  					AI-generated summary 				 Generating accurate, informative, and hallucination-free captions for charts remains challenging for vision language models, primarily due to the lack of large-scale, high-quality datasets of real-world charts. However, existing real-world chart datasets suffer from the inclusion of extraneous information that cannot be inferred from the chart and failure to sufficiently capture structural elements and key insights. Therefore, we introduce ChartCap, a large-scale dataset of 565K real-world chart images paired with type-specific, dense captions that exclude extraneous information and highlight both structural elements and key insights in detail. To build ChartCap, we design a four-stage pipeline that generates captions using only the discernible data from the chart and employ a cycle consistency-based human verification, which accelerates quality control without sacrificing accuracy. Additionally, we propose a novel metric, the Visual Consistency Score, which evaluates caption quality by measuring the similarity between the chart regenerated from a caption and the original chart, independent of reference captions. Extensive experiments confirms that models fine-tuned on ChartCap consistently generate more accurate and informative captions with reduced hallucinations, surpassing both open-source and proprietary models and even human-annotated captions.
[06.08.2025 09:20] Response: {
  "desc": "ChartCap - это масштабный набор данных, содержащий 565 тысяч реальных графиков с детальными подписями. Датасет разработан для улучшения точности генерации подписей и уменьшения галлюцинаций в мультимодальных языковых моделях. ChartCap использует четырехэтапный конвейер для создания подписей, основанных только на видимых данных графика, и применяет верификацию на основе циклической согласованности. Авторы также предлагают новую метрику - Visual Consistency Score, для оценки качества подписей без опоры на эталонные подписи.",
  "emoji": "📊",
  "title": "ChartCap: Точные подписи к графикам без галлюцинаций"
}
[06.08.2025 09:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ChartCap, a large-scale dataset with dense, type-specific captions for real-world charts, improves caption accuracy and reduces hallucinations in vision language models.  					AI-generated summary 				 Generating accurate, informative, and hallucination-free captions for charts remains challenging for vision language models, primarily due to the lack of large-scale, high-quality datasets of real-world charts. However, existing real-world chart datasets suffer from the inclusion of extraneous information that cannot be inferred from the chart and failure to sufficiently capture structural elements and key insights. Therefore, we introduce ChartCap, a large-scale dataset of 565K real-world chart images paired with type-specific, dense captions that exclude extraneous information and highlight both structural elements and key insights in detail. To build ChartCap, we design a four-stage pipeline that generates captions using only the discernible data from the chart and employ a cycle consistency-based human verification, which accelerates quality control without sacrificing accuracy. Additionally, we propose a novel metric, the Visual Consistency Score, which evaluates caption quality by measuring the similarity between the chart regenerated from a caption and the original chart, independent of reference captions. Extensive experiments confirms that models fine-tuned on ChartCap consistently generate more accurate and informative captions with reduced hallucinations, surpassing both open-source and proprietary models and even human-annotated captions."

[06.08.2025 09:20] Response: ```python
["DATASET", "DATA", "BENCHMARK"]
```
[06.08.2025 09:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ChartCap, a large-scale dataset with dense, type-specific captions for real-world charts, improves caption accuracy and reduces hallucinations in vision language models.  					AI-generated summary 				 Generating accurate, informative, and hallucination-free captions for charts remains challenging for vision language models, primarily due to the lack of large-scale, high-quality datasets of real-world charts. However, existing real-world chart datasets suffer from the inclusion of extraneous information that cannot be inferred from the chart and failure to sufficiently capture structural elements and key insights. Therefore, we introduce ChartCap, a large-scale dataset of 565K real-world chart images paired with type-specific, dense captions that exclude extraneous information and highlight both structural elements and key insights in detail. To build ChartCap, we design a four-stage pipeline that generates captions using only the discernible data from the chart and employ a cycle consistency-based human verification, which accelerates quality control without sacrificing accuracy. Additionally, we propose a novel metric, the Visual Consistency Score, which evaluates caption quality by measuring the similarity between the chart regenerated from a caption and the original chart, independent of reference captions. Extensive experiments confirms that models fine-tuned on ChartCap consistently generate more accurate and informative captions with reduced hallucinations, surpassing both open-source and proprietary models and even human-annotated captions."

[06.08.2025 09:20] Response: ```python
["HALLUCINATIONS", "OPEN_SOURCE"]
```
[06.08.2025 09:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ChartCap is a new dataset designed to enhance the performance of vision language models in generating captions for charts. It contains 565,000 real-world chart images with detailed, type-specific captions that focus on essential structural elements and insights, avoiding irrelevant information. The dataset is created through a four-stage process that ensures high-quality captions, verified by a cycle consistency method for efficient quality control. Experiments show that models trained on ChartCap produce more accurate and informative captions, with fewer hallucinations compared to existing models and even human-generated captions.","title":"ChartCap: Elevating Chart Captioning Accuracy and Reducing Hallucinations"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ChartCap is a new dataset designed to enhance the performance of vision language models in generating captions for charts. It contains 565,000 real-world chart images with detailed, type-specific captions that focus on essential structural elements and insights, avoiding irrelevant information. The dataset is created through a four-stage process that ensures high-quality captions, verified by a cycle consistency method for efficient quality control. Experiments show that models trained on ChartCap produce more accurate and informative captions, with fewer hallucinations compared to existing models and even human-generated captions.', title='ChartCap: Elevating Chart Captioning Accuracy and Reducing Hallucinations'))
[06.08.2025 09:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ChartCap是一个大规模的数据集，包含565K个真实世界图表图像及其特定类型的详细说明。该数据集旨在提高视觉语言模型的说明准确性，并减少虚假信息的生成。通过设计四阶段的生成管道，ChartCap确保说明仅基于图表中可辨别的数据，并通过循环一致性的人类验证加速质量控制。实验结果表明，基于ChartCap微调的模型在生成准确和信息丰富的说明方面表现优于其他开源和专有模型，甚至超过人类标注的说明。","title":"ChartCap：提升图表说明准确性的关键数据集"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ChartCap是一个大规模的数据集，包含565K个真实世界图表图像及其特定类型的详细说明。该数据集旨在提高视觉语言模型的说明准确性，并减少虚假信息的生成。通过设计四阶段的生成管道，ChartCap确保说明仅基于图表中可辨别的数据，并通过循环一致性的人类验证加速质量控制。实验结果表明，基于ChartCap微调的模型在生成准确和信息丰富的说明方面表现优于其他开源和专有模型，甚至超过人类标注的说明。', title='ChartCap：提升图表说明准确性的关键数据集'))
[06.08.2025 09:20] Using data from previous issue: {"categories": ["#security", "#benchmark", "#rlhf", "#alignment", "#open_source", "#training"], "emoji": "🛡️", "ru": {"title": "TraceAlign: отслеживание и устранение дрейфа выравнивания в больших языковых моделях", "desc": "TraceAlign - это фреймворк для выявления и снижения дрейфа выравнивания в бо
[06.08.2025 09:20] Renaming data file.
[06.08.2025 09:20] Renaming previous data. hf_papers.json to ./d/2025-08-06.json
[06.08.2025 09:20] Saving new data file.
[06.08.2025 09:20] Generating page.
[06.08.2025 09:20] Renaming previous page.
[06.08.2025 09:20] Renaming previous data. index.html to ./d/2025-08-06.html
[06.08.2025 09:20] Writing result.
[06.08.2025 09:20] Renaming log file.
[06.08.2025 09:20] Renaming previous data. log.txt to ./logs/2025-08-06_last_log.txt
