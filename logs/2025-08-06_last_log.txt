[06.08.2025 21:11] Read previous papers.
[06.08.2025 21:11] Generating top page (month).
[06.08.2025 21:11] Writing top page (month).
[06.08.2025 22:13] Read previous papers.
[06.08.2025 22:13] Get feed.
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02193
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03320
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03694
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03686
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03012
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02091
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00367
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03050
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01119
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03613
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01780
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00477
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03164
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02629
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02079
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02630
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02455
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02063
[06.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01126
[06.08.2025 22:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.08.2025 22:13] No deleted papers detected.
[06.08.2025 22:13] Downloading and parsing papers (pdf, html). Total: 19.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02193.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02193.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02193.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03320.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03320.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03320.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03694.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03694.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03694.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03686.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03686.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03686.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03012.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03012.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03012.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02091.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02091.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02091.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.00367.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.00367.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.00367.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03050.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03050.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03050.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01119.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01119.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01119.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03613.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03613.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03613.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01780.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01780.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01780.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.00477.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.00477.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.00477.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03164.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03164.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03164.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02629.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02629.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02629.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02079.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02079.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02079.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02630.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02630.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02630.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02455.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02455.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02455.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02063.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02063.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02063.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01126.
[06.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01126.json), skip PDF parsing.
[06.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01126.json), skip HTML parsing.
[06.08.2025 22:13] Success.
[06.08.2025 22:13] Enriching papers with extra data.
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 0. Seed Diffusion Preview, a discrete-state diffusion language model, achieves fast inference speeds through parallel generation, outperforming Mercury and Gemini Diffusion in speed and quality.  					AI-generated summary 				 We present Seed Diffusion Preview, a large-scale language model based on dis...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 1. Skywork UniPic, a 1.5 billion-parameter autoregressive model, unifies image understanding, text-to-image generation, and image editing with state-of-the-art performance on commodity hardware.  					AI-generated summary 				 We introduce Skywork UniPic, a 1.5 billion-parameter autoregressive model th...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 2. LongVie, an end-to-end autoregressive framework, addresses temporal consistency and visual degradation in ultra-long video generation through unified noise initialization, global control signal normalization, multi-modal control, and degradation-aware training.  					AI-generated summary 				 Contro...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 3. CompassVerifier is a lightweight, robust model for verifying LLM outputs across various domains, supported by VerifierBench, a comprehensive benchmark dataset.  					AI-generated summary 				 Answer verification is crucial not only for evaluating large language models (LLMs) by matching their unstru...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 4. ToolTrain, a two-stage training framework combining supervised fine-tuning and reinforcement learning, enhances LLMs for issue localization by integrating repository retrieval tools, achieving state-of-the-art performance.  					AI-generated summary 				 Issue localization, the process of identifyin...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 5. CRINN, a reinforcement learning-based approach, optimizes approximate nearest-neighbor search algorithms for speed while maintaining accuracy, outperforming state-of-the-art methods on several benchmarks.  					AI-generated summary 				 Approximate nearest-neighbor search (ANNS) algorithms have beco...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 6. Representation Shift is a training-free, model-agnostic metric that integrates token compression with FlashAttention, enabling significant speedups in video-text retrieval and video QA.  					AI-generated summary 				 Transformers have demonstrated remarkable success across vision, language, and vid...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 7. MIT, a large-scale dataset for multi-human talking video generation, includes fine-grained annotations and is used to demonstrate CovOG, a baseline model integrating a Multi-Human Pose Encoder and an Interactive Audio Driver.  					AI-generated summary 				 Existing studies on talking video generati...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 8. Reinforcement learning combined with a large multimodal language model verifier enhances image editing performance in an autoregressive multimodal framework.  					AI-generated summary 				 We explore three strategies to enhance performance on a wide range of image editing tasks: supervised fine-tun...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 9. Goedel-Prover-V2, a series of open-source language models, achieves state-of-the-art performance in automated theorem proving through scaffolded data synthesis, verifier-guided self-correction, and model averaging.  					AI-generated summary 				 We introduce Goedel-Prover-V2, a series of open-sourc...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 10. LiveMCPBench provides a comprehensive benchmark for evaluating LLM agents across a diverse set of real-world tasks in the MCP ecosystem, using a scalable evaluation pipeline and adaptive judging framework.  					AI-generated summary 				 With the rapid development of Model Context Protocol (MCP), th...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 11. LAMIC, a Layout-Aware Multi-Image Composition framework, extends single-reference diffusion models to multi-reference scenarios using attention mechanisms, achieving state-of-the-art performance in controllable image synthesis without training.  					AI-generated summary 				 In controllable image s...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 12. ChartCap, a large-scale dataset with dense, type-specific captions for real-world charts, improves caption accuracy and reduces hallucinations in vision language models.  					AI-generated summary 				 Generating accurate, informative, and hallucination-free captions for charts remains challenging f...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 13. HyCodePolicy integrates code synthesis, geometric grounding, perceptual monitoring, and iterative repair to enhance the robustness and efficiency of embodied agent policies.  					AI-generated summary 				 Recent advances in multimodal large language models (MLLMs) have enabled richer perceptual gro...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 14. AlignGuard-LoRA (AGL) is a framework that preserves alignment during fine-tuning of large language models by introducing regularization techniques and a diagnostic benchmark to mitigate alignment drift.  					AI-generated summary 				 Low-rank adaptation (LoRA) has become a standard tool for efficie...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 15. ACES, a sandbox environment, studies AI agents' shopping behavior in a mock marketplace, revealing position effects, sensitivity to sponsored tags, endorsements, prices, ratings, and reviews, and highlighting implications for seller strategies and platform design.  					AI-generated summary 				 Onl...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 16. A new scoring approach using language models ranks static code completions in IDEs by organizing them into a prefix tree and performing a single greedy decoding pass.  					AI-generated summary 				 Token-level code completion is one of the most critical features in modern Integrated Development Env...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 17. TraceAlign is a framework that identifies and mitigates alignment drift in LLMs by tracing unsafe completions to their training sources and applying interventions to reduce drift while maintaining utility.  					AI-generated summary 				 Large Language Models (LLMs) fine-tuned to align with human va...
[06.08.2025 22:13] ********************************************************************************
[06.08.2025 22:13] Abstract 18. A unified conditional motion diffusion model, UniEgoMotion, is introduced for egocentric motion generation and forecasting using first-person images, achieving state-of-the-art performance and generating motion from a single image.  					AI-generated summary 				 Egocentric human motion generation a...
[06.08.2025 22:13] Read previous papers.
[06.08.2025 22:13] Generating reviews via LLM API.
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#diffusion", "#inference", "#benchmark", "#architecture", "#optimization"], "emoji": "üöÄ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "Seed Diffusion Preview - —ç—Ç–æ –Ω–æ–≤–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏. –û–Ω–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ—á–µ
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#dataset", "#training", "#multimodal", "#architecture", "#open_source"], "emoji": "üñºÔ∏è", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "Skywork UniPic - —ç—Ç–æ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å 1,5 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#multimodal", "#long_context", "#video"], "emoji": "üé¨", "ru": {"title": "LongVie: –ø—Ä–æ—Ä—ã–≤ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–µ—Ä—Ö–¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "LongVie - —ç—Ç–æ –Ω–æ–≤–∞—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–∞–¥–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–µ—Ä—Ö–¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ. –û–Ω–∞ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –≤—Ä–µ–º–µ–Ω
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#benchmark", "#dataset", "#interpretability", "#optimization"], "emoji": "üß≠", "ru": {"title": "CompassVerifier: –ù–∞–¥–µ–∂–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ LLM –≤–æ –º–Ω–æ–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö", "desc": "CompassVerifier - —ç—Ç–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#agents", "#optimization"], "emoji": "üîç", "ru": {"title": "ToolTrain: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º –≤ –∫–æ–¥–µ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "ToolTrain - —ç—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—É—é —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#rag", "#rl", "#optimization"], "emoji": "üöÄ", "ru": {"title": "CRINN: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–æ–∏—Å–∫–µ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "CRINN - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ø–æ–∏—Å–∫–∞ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω—ã—Ö –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π (ANNS), –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#training", "#architecture", "#data", "#optimization", "#video"], "emoji": "üöÄ", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –∏ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫—É Representation Shift, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Å–∂–∏–º–∞—Ç—å —Ç–æ–∫–µ–Ω—ã –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞—Ö –±–µ–∑ –ø–µ—Ä–µ–æ–±
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#dataset"], "emoji": "üó£Ô∏è", "ru": {"title": "–ù–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª—é–¥–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ MIT - –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª—é–¥–µ–π. –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤–∫–ª—é—á–∞
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#rl", "#optimization", "#multimodal", "#open_source", "#training", "#games"], "emoji": "üñºÔ∏è", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –ø–æ–≤—ã—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É—é—Ç—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–≤—Ç–æ—Ä–µ–≥
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#rl", "#dataset", "#synthetic", "#reasoning", "#small_models", "#training", "#open_source"], "emoji": "üß†", "ru": {"title": "–ú–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å - –±–æ–ª—å—à–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞: Goedel-Prover-V2 –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –º–∏—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Ç–µ–æ—Ä–µ–º", "desc": "Goedel-Prover-V2 - —ç—Ç–æ —Å–µ—Ä–∏—è –æ—Ç
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#open_source", "#survey", "#agents", "#benchmark"], "emoji": "ü§ñ", "ru": {"title": "LiveMCPBench: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ LLM-–∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö MCP-—Å—Ä–µ–¥–∞—Ö", "desc": "LiveMCPBench –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ —Ä–µ–∞–ª
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#optimization", "#cv", "#training"], "emoji": "üñºÔ∏è", "ru": {"title": "LAMIC: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–∏–Ω—Ç–µ–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏", "desc": "LAMIC - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —É—á–µ—Ç–æ–º –º–∞–∫–µ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—à–∏—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∏
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#benchmark", "#hallucinations", "#dataset", "#data", "#open_source"], "emoji": "üìä", "ru": {"title": "ChartCap: –¢–æ—á–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ –∫ –≥—Ä–∞—Ñ–∏–∫–∞–º –±–µ–∑ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π", "desc": "ChartCap - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 565 —Ç—ã—Å—è—á —Ä–µ–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏. –î–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑—Ä–∞–±–æ
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#robotics", "#optimization", "#agents", "#reasoning", "#games", "#multimodal"], "emoji": "ü§ñ", "ru": {"title": "–°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—â–∏–µ—Å—è –ø—Ä–æ–≥—Ä–∞–º–º—ã –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ò–ò", "desc": "HyCodePolicy - —ç—Ç–æ –≥–∏–±—Ä–∏–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –≤–æ–ø–ª–æ—â–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º—É
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#alignment", "#open_source", "#training"], "emoji": "üõ°Ô∏è", "ru": {"title": "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "AlignGuard-LoRA (AGL) - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –≤–≤–æ–¥–∏
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#ethics", "#games", "#alignment"], "emoji": "üõí", "ru": {"title": "–ò–ò –∏–¥–µ—Ç –∑–∞ –ø–æ–∫—É–ø–∫–∞–º–∏: –Ω–æ–≤–∞—è —ç—Ä–∞ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –∫–æ–º–º–µ—Ä—Ü–∏–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ ACES –∏–∑—É—á–∞–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –ø—Ä–∏ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–∏ –ø–æ–∫—É–ø–æ–∫ –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–æ–π —Å—Ä–µ–¥–µ. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –≤—ã—è–≤–∏–ª–∏ –≤–ª–∏—è–Ω
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#plp", "#training", "#optimization"], "emoji": "üå≥", "ru": {"title": "–£–º–Ω–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—é —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π –∫–æ–¥–∞ –≤ IDE —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ú–µ—Ç–æ–¥ –æ—Ä–≥–∞–Ω–∏–∑—É–µ—Ç –≤
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#security", "#benchmark", "#rlhf", "#alignment", "#open_source", "#training"], "emoji": "üõ°Ô∏è", "ru": {"title": "TraceAlign: –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥—Ä–µ–π—Ñ–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "TraceAlign - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∏ —Å–Ω–∏–∂–µ–Ω–∏—è –¥—Ä–µ–π—Ñ–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –≤ –±–æ
[06.08.2025 22:13] Using data from previous issue: {"categories": ["#dataset", "#games", "#benchmark", "#video", "#diffusion", "#multimodal", "#cv", "#healthcare"], "emoji": "üï∂Ô∏è", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —É—Å–ª–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∏—Ñ—Ñ—É–∑–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è UniEgoMotion –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ 
[06.08.2025 22:13] Renaming data file.
[06.08.2025 22:13] Renaming previous data. hf_papers.json to ./d/2025-08-06.json
[06.08.2025 22:13] Saving new data file.
[06.08.2025 22:13] Generating page.
[06.08.2025 22:13] Renaming previous page.
[06.08.2025 22:13] Renaming previous data. index.html to ./d/2025-08-06.html
[06.08.2025 22:13] Writing result.
[06.08.2025 22:13] Renaming log file.
[06.08.2025 22:13] Renaming previous data. log.txt to ./logs/2025-08-06_last_log.txt
