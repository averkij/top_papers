[06.08.2025 12:25] Read previous papers.
[06.08.2025 12:25] Generating top page (month).
[06.08.2025 12:25] Writing top page (month).
[06.08.2025 13:37] Read previous papers.
[06.08.2025 13:37] Get feed.
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02193
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03320
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03694
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03686
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02091
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03012
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03050
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03613
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01780
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00477
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03164
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02079
[06.08.2025 13:37] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02063
[06.08.2025 13:37] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[06.08.2025 13:37] No deleted papers detected.
[06.08.2025 13:37] Downloading and parsing papers (pdf, html). Total: 13.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.02193.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.02193.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.02193.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.03320.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.03320.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.03320.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.03694.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.03694.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.03694.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.03686.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.03686.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.03686.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.02091.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.02091.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.02091.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.03012.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.03012.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.03012.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.03050.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.03050.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.03050.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.03613.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.03613.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.03613.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.01780.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.01780.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.01780.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.00477.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.00477.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.00477.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.03164.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.03164.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.03164.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.02079.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.02079.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.02079.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Downloading and parsing paper https://huggingface.co/papers/2508.02063.
[06.08.2025 13:37] Extra JSON file exists (./assets/json/2508.02063.json), skip PDF parsing.
[06.08.2025 13:37] Paper image links file exists (./assets/img_data/2508.02063.json), skip HTML parsing.
[06.08.2025 13:37] Success.
[06.08.2025 13:37] Enriching papers with extra data.
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 0. Seed Diffusion Preview, a discrete-state diffusion language model, achieves fast inference speeds through parallel generation, outperforming Mercury and Gemini Diffusion in speed and quality.  					AI-generated summary 				 We present Seed Diffusion Preview, a large-scale language model based on dis...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 1. Skywork UniPic, a 1.5 billion-parameter autoregressive model, unifies image understanding, text-to-image generation, and image editing with state-of-the-art performance on commodity hardware.  					AI-generated summary 				 We introduce Skywork UniPic, a 1.5 billion-parameter autoregressive model th...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 2. LongVie, an end-to-end autoregressive framework, addresses temporal consistency and visual degradation in ultra-long video generation through unified noise initialization, global control signal normalization, multi-modal control, and degradation-aware training.  					AI-generated summary 				 Contro...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 3. CompassVerifier is a lightweight, robust model for verifying LLM outputs across various domains, supported by VerifierBench, a comprehensive benchmark dataset.  					AI-generated summary 				 Answer verification is crucial not only for evaluating large language models (LLMs) by matching their unstru...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 4. CRINN, a reinforcement learning-based approach, optimizes approximate nearest-neighbor search algorithms for speed while maintaining accuracy, outperforming state-of-the-art methods on several benchmarks.  					AI-generated summary 				 Approximate nearest-neighbor search (ANNS) algorithms have beco...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 5. ToolTrain, a two-stage training framework combining supervised fine-tuning and reinforcement learning, enhances LLMs for issue localization by integrating repository retrieval tools, achieving state-of-the-art performance.  					AI-generated summary 				 Issue localization, the process of identifyin...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 6. MIT, a large-scale dataset for multi-human talking video generation, includes fine-grained annotations and is used to demonstrate CovOG, a baseline model integrating a Multi-Human Pose Encoder and an Interactive Audio Driver.  					AI-generated summary 				 Existing studies on talking video generati...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 7. Goedel-Prover-V2, a series of open-source language models, achieves state-of-the-art performance in automated theorem proving through scaffolded data synthesis, verifier-guided self-correction, and model averaging.  					AI-generated summary 				 We introduce Goedel-Prover-V2, a series of open-sourc...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 8. LiveMCPBench provides a comprehensive benchmark for evaluating LLM agents across a diverse set of real-world tasks in the MCP ecosystem, using a scalable evaluation pipeline and adaptive judging framework.  					AI-generated summary 				 With the rapid development of Model Context Protocol (MCP), th...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 9. LAMIC, a Layout-Aware Multi-Image Composition framework, extends single-reference diffusion models to multi-reference scenarios using attention mechanisms, achieving state-of-the-art performance in controllable image synthesis without training.  					AI-generated summary 				 In controllable image s...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 10. ChartCap, a large-scale dataset with dense, type-specific captions for real-world charts, improves caption accuracy and reduces hallucinations in vision language models.  					AI-generated summary 				 Generating accurate, informative, and hallucination-free captions for charts remains challenging f...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 11. AlignGuard-LoRA (AGL) is a framework that preserves alignment during fine-tuning of large language models by introducing regularization techniques and a diagnostic benchmark to mitigate alignment drift.  					AI-generated summary 				 Low-rank adaptation (LoRA) has become a standard tool for efficie...
[06.08.2025 13:37] ********************************************************************************
[06.08.2025 13:37] Abstract 12. TraceAlign is a framework that identifies and mitigates alignment drift in LLMs by tracing unsafe completions to their training sources and applying interventions to reduce drift while maintaining utility.  					AI-generated summary 				 Large Language Models (LLMs) fine-tuned to align with human va...
[06.08.2025 13:37] Read previous papers.
[06.08.2025 13:37] Generating reviews via LLM API.
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#diffusion", "#inference", "#benchmark", "#architecture", "#optimization"], "emoji": "üöÄ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "Seed Diffusion Preview - —ç—Ç–æ –Ω–æ–≤–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏. –û–Ω–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ—á–µ
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#dataset", "#training", "#multimodal", "#architecture", "#open_source"], "emoji": "üñºÔ∏è", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "Skywork UniPic - —ç—Ç–æ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å 1,5 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#multimodal", "#long_context", "#video"], "emoji": "üé¨", "ru": {"title": "LongVie: –ø—Ä–æ—Ä—ã–≤ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–µ—Ä—Ö–¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "LongVie - —ç—Ç–æ –Ω–æ–≤–∞—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–∞–¥–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–µ—Ä—Ö–¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ. –û–Ω–∞ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –≤—Ä–µ–º–µ–Ω
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#benchmark", "#dataset", "#interpretability", "#optimization"], "emoji": "üß≠", "ru": {"title": "CompassVerifier: –ù–∞–¥–µ–∂–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ LLM –≤–æ –º–Ω–æ–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö", "desc": "CompassVerifier - —ç—Ç–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#rag", "#rl", "#optimization"], "emoji": "üöÄ", "ru": {"title": "CRINN: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–æ–∏—Å–∫–µ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "CRINN - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ø–æ–∏—Å–∫–∞ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω—ã—Ö –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π (ANNS), –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#agents", "#optimization"], "emoji": "üîç", "ru": {"title": "ToolTrain: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º –≤ –∫–æ–¥–µ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "ToolTrain - —ç—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—É—é —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#dataset"], "emoji": "üó£Ô∏è", "ru": {"title": "–ù–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª—é–¥–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ MIT - –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª—é–¥–µ–π. –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤–∫–ª—é—á–∞
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#rl", "#dataset", "#synthetic", "#reasoning", "#small_models", "#training", "#open_source"], "emoji": "üß†", "ru": {"title": "–ú–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å - –±–æ–ª—å—à–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞: Goedel-Prover-V2 –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –º–∏—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Ç–µ–æ—Ä–µ–º", "desc": "Goedel-Prover-V2 - —ç—Ç–æ —Å–µ—Ä–∏—è –æ—Ç
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#open_source", "#survey", "#agents", "#benchmark"], "emoji": "ü§ñ", "ru": {"title": "LiveMCPBench: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ LLM-–∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö MCP-—Å—Ä–µ–¥–∞—Ö", "desc": "LiveMCPBench –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ —Ä–µ–∞–ª
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#optimization", "#cv", "#training"], "emoji": "üñºÔ∏è", "ru": {"title": "LAMIC: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–∏–Ω—Ç–µ–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏", "desc": "LAMIC - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —É—á–µ—Ç–æ–º –º–∞–∫–µ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—à–∏—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∏
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#benchmark", "#hallucinations", "#dataset", "#data", "#open_source"], "emoji": "üìä", "ru": {"title": "ChartCap: –¢–æ—á–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ –∫ –≥—Ä–∞—Ñ–∏–∫–∞–º –±–µ–∑ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π", "desc": "ChartCap - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 565 —Ç—ã—Å—è—á —Ä–µ–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏. –î–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑—Ä–∞–±–æ
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#alignment", "#open_source", "#training"], "emoji": "üõ°Ô∏è", "ru": {"title": "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "AlignGuard-LoRA (AGL) - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –≤–≤–æ–¥–∏
[06.08.2025 13:37] Using data from previous issue: {"categories": ["#security", "#benchmark", "#rlhf", "#alignment", "#open_source", "#training"], "emoji": "üõ°Ô∏è", "ru": {"title": "TraceAlign: –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥—Ä–µ–π—Ñ–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "TraceAlign - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∏ —Å–Ω–∏–∂–µ–Ω–∏—è –¥—Ä–µ–π—Ñ–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –≤ –±–æ
[06.08.2025 13:37] Renaming data file.
[06.08.2025 13:37] Renaming previous data. hf_papers.json to ./d/2025-08-06.json
[06.08.2025 13:37] Saving new data file.
[06.08.2025 13:37] Generating page.
[06.08.2025 13:37] Renaming previous page.
[06.08.2025 13:37] Renaming previous data. index.html to ./d/2025-08-06.html
[06.08.2025 13:37] Writing result.
[06.08.2025 13:37] Renaming log file.
[06.08.2025 13:37] Renaming previous data. log.txt to ./logs/2025-08-06_last_log.txt
