[05.06.2025 12:23] Read previous papers.
[05.06.2025 12:23] Generating top page (month).
[05.06.2025 12:23] Writing top page (month).
[05.06.2025 13:27] Read previous papers.
[05.06.2025 13:27] Get feed.
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03569
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04207
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04089
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16968
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.02921
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04180
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04141
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01320
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04225
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04158
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04228
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04142
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03139
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03295
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03150
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24500
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03930
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04108
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03517
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.02592
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03106
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03099
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03355
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21541
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03956
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03448
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.02945
[05.06.2025 13:27] Extract page data from URL. URL: https://huggingface.co/papers/2506.03610
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.02294
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.00482
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23807
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04133
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04034
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03951
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03614
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01344
[05.06.2025 13:27] Extract page data from URL. URL: https://huggingface.co/papers/2506.03837
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03817
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03538
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.02680
[05.06.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.02515
[05.06.2025 13:27] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.06.2025 13:27] No deleted papers detected.
[05.06.2025 13:27] Downloading and parsing papers (pdf, html). Total: 41.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03569.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03569.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03569.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04207.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04207.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04207.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04089.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04089.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04089.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.16968.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2505.16968.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2505.16968.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.02921.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.02921.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.02921.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04180.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04180.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04180.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04141.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04141.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04141.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.01320.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.01320.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.01320.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04225.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04225.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04225.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04158.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04158.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04158.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04228.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04228.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04228.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04142.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04142.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04142.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03139.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03139.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03139.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03295.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03295.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03295.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03150.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03150.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03150.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.24500.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2505.24500.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2505.24500.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03930.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03930.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03930.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04108.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04108.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04108.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03517.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03517.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03517.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.02592.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.02592.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.02592.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03106.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03106.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03106.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03099.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03099.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03099.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03355.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03355.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03355.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21541.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2505.21541.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2505.21541.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03956.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03956.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03956.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03448.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03448.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03448.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.02945.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.02945.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.02945.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03610.
[05.06.2025 13:27] Downloading paper 2506.03610 from http://arxiv.org/pdf/2506.03610v1...
[05.06.2025 13:27] Extracting affiliations from text.
[05.06.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 ] . [ 1 0 1 6 3 0 . 6 0 5 2 : r Orak: Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games Dongmin Park1, Minkyu Kim1, Beongjun Choi1, Junhyuck Kim1, Keon Lee1, Jonghyun Lee1, Inkyu Park1, Byeong-Uk Lee1, Jaeyoung Hwang1, Jaewoo Ahn1,2, Ameya S. Mahabaleshwarkar3, Bilal Kartal3, Pritam Biswas3, Yoshi Suhara3, Kangwook Lee1,4, Jaewoong Cho1 1KRAFTON, 2Seoul National University, 3NVIDIA, 4University of Wisconsin-Madison "
[05.06.2025 13:27] Response: ```python
["KRAFTON", "Seoul National University", "NVIDIA", "University of Wisconsin-Madison"]
```
[05.06.2025 13:27] Deleting PDF ./assets/pdf/2506.03610.pdf.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.02294.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.02294.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.02294.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.00482.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.00482.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.00482.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.23807.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2505.23807.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2505.23807.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04133.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04133.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04133.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.04034.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.04034.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.04034.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03951.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03951.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03951.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03614.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03614.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03614.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.01344.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.01344.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.01344.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03837.
[05.06.2025 13:27] Downloading paper 2506.03837 from http://arxiv.org/pdf/2506.03837v1...
[05.06.2025 13:27] Extracting affiliations from text.
[05.06.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"HTSC-2025: Benchmark Dataset of Ambient-Pressure High-Temperature Superconductors for AI-Driven Critical Temperature Prediction Xiao-Qi Han1,2, Ze-Feng Gao1,2, Xin-De Wang1,2, Zhenfeng Ouyang1,2, Peng-Jie Guo1,2, and Zhong-Yi Lu1,2,3 1. School of Physics and Beijing Key Laboratory of Opto-electronic Functional Materials & Micro-nano Devices. Renmin University of China, Beijing 100872, China 2. Key Laboratory of Quantum State Construction and Manipulation (Ministry of Education), Renmin University of China, Beijing 100872, China and 3. Hefei National Laboratory, Hefei 230088, China (Dated: June 5, 2025) The discovery of high-temperature superconducting materials holds great significance for human In recent years, research on predicting superconducting transition temindustry and daily life. peratures using artificial intelligence (AI) has gained popularity, with most of these tools claiming to achieve remarkable accuracy. However, the lack of widely accepted benchmark datasets in this field has severely hindered fair comparisons between different AI algorithms and impeded further advancement of these methods. In this work, we present HTSC-2025, an ambient-pressure hightemperature superconducting benchmark dataset. This comprehensive compilation encompasses theoretically predicted superconducting materials discovered by theoretical physicists from 2023 to 2025 based on BCS superconductivity theory, including the renowned X2YH6 system, perovskite MXH3 system, M3XH8 system, cage-like BCN-doped metal atomic systems derived from LaH10 structural evolution, and two-dimensional honeycomb-structured systems evolving from MgB2. In addition, we note range of approaches inspired by physical intuition for designing high-temperature superconductors, such as hole doping, the introduction of light elements to form strong covalent bonds, and the tuning of spinorbit coupling. The HTSC-2025 benchmark has been open-sourced at [https://github.com/xqh19970407/HTSC-2025] and will be contin"
[05.06.2025 13:27] Response: ```python
[
    "School of Physics and Beijing Key Laboratory of Opto-electronic Functional Materials & Micro-nano Devices, Renmin University of China, Beijing 100872, China",
    "Key Laboratory of Quantum State Construction and Manipulation (Ministry of Education), Renmin University of China, Beijing 100872, China",
    "Hefei National Laboratory, Hefei 230088, China"
]
```
[05.06.2025 13:27] Deleting PDF ./assets/pdf/2506.03837.pdf.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03817.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03817.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03817.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.03538.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.03538.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.03538.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.02680.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.02680.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.02680.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2506.02515.
[05.06.2025 13:27] Extra JSON file exists (./assets/json/2506.02515.json), skip PDF parsing.
[05.06.2025 13:27] Paper image links file exists (./assets/img_data/2506.02515.json), skip HTML parsing.
[05.06.2025 13:27] Success.
[05.06.2025 13:27] Enriching papers with extra data.
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 0. We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language models delivering state-of-the-art performance in both general visual understanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B on 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpa...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 1. Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex textual tasks, many works attempt to incentivize similar capabilities in Multimodal Large Language Models (MLLMs) by directly applying reinforcement learning (RL). However, they still struggle to activate complex reasoning. ...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 2. AmbiK, a textual dataset of ambiguous instructions for kitchen robots, enables unified comparison of ambiguity detection methods.  					AI-generated summary 				 As a part of an embodied agent, Large Language Models (LLMs) are typically used for behavior planning given natural language instructions ...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 3. CASS is a dataset and model suite for GPU code transpilation at both source and assembly levels, achieving high accuracy and performance matching with native code.  					AI-generated summary 				 We introduce CASS, the first large-scale dataset and model suite for cross-architecture GPU code transpi...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 4. LongBioBench is a new benchmark using artificially generated biographies to evaluate long-context language models across understanding, reasoning, and trustworthiness dimensions, addressing limitations in existing frameworks.  					AI-generated summary 				 Existing frameworks for evaluating long-co...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 5. Long-form text generation remains a significant challenge for large language models (LLMs), particularly in maintaining coherence, ensuring logical consistency, and preserving text quality as sequence length increases. To address these limitations, we propose SuperWriter-Agent, an agent-based framew...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 6. A new benchmark, MMR-V, is proposed to challenge multimodal large language models with long-range, multi-frame reasoning and hidden information processing in videos, revealing their limitations and inspiring further research.  					AI-generated summary 				 The sequential structure of videos poses a...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 7. We introduce Psi-Sampler, an SMC-based framework incorporating pCNL-based initial particle sampling for effective inference-time reward alignment with a score-based generative model. Inference-time reward alignment with score-based generative models has recently gained significant traction, followin...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 8. Voyager is a video diffusion framework that generates world-consistent 3D point-cloud sequences from a single image, enabling long-range, consistent 3D scene exploration with user-defined camera paths.  					AI-generated summary 				 Real-world applications like video gaming and virtual reality ofte...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 9. While diffusion models have achieved remarkable success in text-to-image generation, they encounter significant challenges with instruction-driven image editing. Our research highlights a key challenge: these models particularly struggle with structurally inconsistent edits that involve substantial ...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 10. LayerFlow is a unified framework for generating layer-aware videos using a text-to-video diffusion transformer and layer embeddings, supporting various video generation tasks with a multi-stage training strategy.  					AI-generated summary 				 We present LayerFlow, a unified solution for layer-awar...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 11. A method called shortcut neuron patching identifies and suppresses shortcut neurons in language models to mitigate data contamination issues in trustworthy evaluations.  					AI-generated summary 				 The development of large language models (LLMs) depends on trustworthy evaluation. However, most cu...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 12. SVGenius evaluates Large Language Models and Multimodal LLMs for SVG processing using a comprehensive benchmark across three dimensions: understanding, editing, and generation, revealing insights into model capabilities and limitations.  					AI-generated summary 				 Large Language Models (LLMs) an...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 13. Critique Fine-Tuning on a single problem can efficiently enhance the reasoning capabilities of large language models with significant performance gains and reduced computational cost compared to reinforcement learning.  					AI-generated summary 				 We have witnessed that strong LLMs like Qwen-Math...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 14. IllumiCraft integrates geometric cues in a diffusion framework to generate high-fidelity, temporally coherent videos from textual or image inputs.  					AI-generated summary 				 Although diffusion-based models can generate high-quality and high-resolution video sequences from textual or image input...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 15. Temporal-aware Hierarchical Cognitive Reinforcement Learning enhances LLMs' social intelligence by addressing the distinct cognitive demands of social domains.  					AI-generated summary 				 Recently, Large Language Models (LLMs) have made significant progress in IQ-related domains that require car...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 16. VisCode-200K, a large-scale dataset for visualization, improves plot generation performance by integrating execution-grounded supervision and iterative code correction, outperforming open-source models and rivaling proprietary ones.  					AI-generated summary 				 Large language models (LLMs) often ...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 17. Rectified Sparse Attention (ReSA) improves the efficiency of long-sequence generation in Large Language Models by combining block-sparse attention with periodic dense rectification, maintaining high-quality generation.  					AI-generated summary 				 Efficient long-sequence generation is a critical ...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 18. Direct Preference Optimization (DPO) has recently been applied as a post-training technique for text-to-video diffusion models. To obtain training data, annotators are asked to provide preferences between two videos generated from independent noise. However, this approach prohibits fine-grained comp...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 19. The DBG score is introduced to measure self-preference bias in large language models by using gold judgments as proxies for response quality, addressing the confounding effect of response quality.  					AI-generated summary 				 Recent studies show that large language models (LLMs) exhibit self-pref...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 20. Critique-GRPO, an RL framework combining numerical and natural language feedback, enhances LLM reasoning across tasks and outperforms existing methods.  					AI-generated summary 				 Recent advances in reinforcement learning (RL) with numerical feedback, such as scalar rewards, have significantly e...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 21. TalkingMachines transforms a pretrained image-to-video model into an audio-driven avatar generator, supports infinite video streaming, and uses engineering optimizations for real-time performance.  					AI-generated summary 				 In this paper, we present TalkingMachines -- an efficient framework tha...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 22. LEAF, an adversarial finetuning method, enhances the robustness of CLIP text encoders, improving zero-shot accuracy and multimodal retrieval performance under adversarial noise.  					AI-generated summary 				 Adversarial input attacks can cause a significant shift of CLIP embeddings. This can affec...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 23. DiffDecompose, a diffusion Transformer-based framework, effectively decomposes images into constituent layers with semantic prompts, addressing challenges in transparent layer decomposition.  					AI-generated summary 				 Diffusion models have recently motivated great success in many generation tas...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 24. Adapting Pre-trained Models before the core CL process (ACL) improves Continual Learning by enhancing plasticity while maintaining stability.  					AI-generated summary 				 Continual Learning (CL) seeks to enable neural networks to incrementally acquire new knowledge (plasticity) while retaining ex...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 25. RefEdit, an instruction-based editing model trained on synthetic data, outperforms baselines in complex scene editing and referring expression tasks.  					AI-generated summary 				 Despite recent advances in inversion and instruction-based image editing, existing approaches primarily excel at editi...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 26. LLM-as-a-judge is a framework in which a large language model (LLM) automatically evaluates the output of another LLM. We propose quantitative LLM judges, which align evaluation scores of existing LLM judges to human scores in a given domain using regression models. The models are trained to improve...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 27. Orak is a benchmark for training and evaluating LLM agents across diverse video games, featuring a plug-and-play interface and fine-tuning datasets to enhance agentic modules and gameplay.  					AI-generated summary 				 Large Language Model (LLM) agents are reshaping the game industry, particularly...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 28. A diffusion-based data augmentation strategy improves robustness in knowledge distillation by generating challenging samples, enhancing accuracy and spurious feature resilience.  					AI-generated summary 				 Large foundation models trained on extensive datasets demonstrate strong zero-shot capabil...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 29. BenchHub is a dynamic benchmark repository that aggregates and classifies datasets for large language models, facilitating domain-specific evaluations and improving model comparisons.  					AI-generated summary 				 As large language models (LLMs) continue to advance, the need for up-to-date and wel...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 30. A dynamic layerwise pruning method adaptively determines layer importance by combining model weights and activation information to maintain performance in large language models at high sparsity.  					AI-generated summary 				 Pruning has recently been widely adopted to reduce the parameter scale an...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 31. A review of trust, risk, and security management in LLM-based agentic multi-agent systems, examining governance, explainability, ModelOps, and privacy/security.  					AI-generated summary 				 Agentic AI systems, built on large language models (LLMs) and deployed in multi-agent configurations, are r...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 32. Object referring aims to detect all objects in an image that match a given natural language description. We argue that a robust object referring model should be grounded, meaning its predictions should be both explainable and faithful to the visual content. Specifically, it should satisfy two key pr...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 33. A novel framework, Dual-Arch, enhances Continual Learning by addressing the stability-plasticity dilemma at the architectural level using two specialized networks.  					AI-generated summary 				 The quest for Continual Learning (CL) seeks to empower neural networks with the ability to learn and ada...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 34. VLMs exhibit visual stitching, an ability to integrate fragmented visual information, which enables harmful content to evade data moderation and be reconstructed during inference.  					AI-generated summary 				 One way to mitigate risks in vision-language models (VLMs) is to remove dangerous sample...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 35. Flowcharts are a critical tool for visualizing decision-making processes. However, their non-linear structure and complex visual-textual relationships make it challenging to interpret them using LLMs, as vision-language models frequently hallucinate nonexistent connections and decision paths when an...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 36. HTSC-2025, a benchmark dataset for high-temperature superconducting materials, is presented to facilitate AI-based discovery in this field.  					AI-generated summary 				 The discovery of high-temperature superconducting materials holds great significance for human industry and daily life. In recen...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 37. Annotating data is a time-consuming and costly task, but it is inherently required for supervised machine learning. Active Learning (AL) is an established method that minimizes human labeling effort by iteratively selecting the most informative unlabeled samples for expert annotation, thereby improv...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 38. A novel Asymmetric Dual 3DGS framework improves 3D reconstruction by training dual models with consistency constraints and divergent masking, outperforming existing methods with high efficiency.  					AI-generated summary 				 3D reconstruction from in-the-wild images remains a challenging task due ...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 39. FLAIR, a novel training-free variational framework, leverages flow-based generative models to enhance inverse problem solutions, achieving superior reconstruction quality and sample diversity.  					AI-generated summary 				 Flow-based latent generative models such as Stable Diffusion 3 are able to ...
[05.06.2025 13:27] ********************************************************************************
[05.06.2025 13:27] Abstract 40. A new benchmark called FinChain evaluates multi-step symbolic reasoning in financial tasks with a focus on intermediate reasoning steps, introducing ChainEval as a metric for assessing both final answers and reasoning processes.  					AI-generated summary 				 Multi-step symbolic reasoning is critic...
[05.06.2025 13:27] Read previous papers.
[05.06.2025 13:27] Generating reviews via LLM API.
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#training", "#rl", "#reasoning", "#multimodal", "#rlhf", "#benchmark", "#dataset", "#open_source"], "emoji": "🧠", "ru": {"title": "Прорыв в мультимодальном ИИ: MiMo-VL устанавливает новые стандарты", "desc": "Исследователи представили две мощные мультимодальные модели MiMo-VL-7B-SFT
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#multimodal", "#training", "#benchmark", "#rl"], "emoji": "🧠", "ru": {"title": "Улучшение рассуждений MLLM: от инициализации до многоэтапного RL", "desc": "Статья посвящена улучшению способностей мультимодальных больших языковых моделей (MLLM) к рассужд
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#interpretability", "#agents", "#data", "#dataset", "#alignment"], "emoji": "🍳", "ru": {"title": "AmbiK: унифицированный бенчмарк для обнаружения неоднозначности в инструкциях для роботов", "desc": "AmbiK - это текстовый датасет неоднозначных инструкций для кухонных роботов, созданн
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#low_resource", "#benchmark", "#open_source"], "emoji": "🔄", "ru": {"title": "CASS: Преодоление барьеров между GPU-архитектурами", "desc": "CASS представляет собой набор данных и набор моделей для транспиляции GPU-кода между архитектурами как на уровне исходного кода, та
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#long_context", "#reasoning", "#interpretability"], "emoji": "📊", "ru": {"title": "LongBioBench: Новый стандарт оценки языковых моделей с длинным контекстом", "desc": "LongBioBench - это новый бенчмарк для оценки языковых моделей с длинным контекстом, исп
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#training", "#optimization", "#agents", "#long_context", "#rlhf", "#benchmark", "#dataset", "#story_generation"], "emoji": "✍️", "ru": {"title": "Структурированное мышление для улучшения генерации длинных текстов", "desc": "SuperWriter-Agent - это новая система для улучшения качеств
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#long_context", "#benchmark", "#video"], "emoji": "🎥", "ru": {"title": "MMR-V: Новый рубеж в мультимодальных рассуждениях по видео", "desc": "Предложен новый бенчмарк MMR-V для оценки мультимодальных языковых моделей в задачах рассуждения по видео. Он тр
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#inference", "#alignment", "#rlhf", "#optimization"], "emoji": "🎨", "ru": {"title": "Эффективное согласование наград в генеративных моделях с помощью умной выборки", "desc": "Статья представляет Psi-Sampler - новый метод для улучшения согласования наград при инференсе в генеративных
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#games", "#dataset", "#diffusion", "#3d", "#video"], "emoji": "🚀", "ru": {"title": "Исследуй 3D-миры из одного кадра", "desc": "Voyager - это система видеодиффузии, которая генерирует согласованные последовательности 3D-облаков точек из одного изображения. Она позволяет исследовать 
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#diffusion", "#benchmark", "#cv", "#architecture"], "emoji": "🖼️", "ru": {"title": "Редактирование изображений как программирование: новый подход к ИИ-обработке визуального контента", "desc": "Исследователи представили новый подход к редактированию изображений с использованием искус
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#synthetic", "#video", "#training"], "emoji": "🎞️", "ru": {"title": "LayerFlow: Умная генерация многослойного видео по текстовым подсказкам", "desc": "LayerFlow - это унифицированная система для генерации видео с учетом слоев, использующая трансформер ди
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#data", "#hallucinations", "#benchmark", "#ethics", "#training"], "emoji": "🧠", "ru": {"title": "Борьба с загрязнением данных в языковых моделях через патчинг нейронов-шорткатов", "desc": "Метод 'shortcut neuron patching' идентифицирует и подавляет нейроны-шорткаты в языковых моделя
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#optimization", "#multimodal", "#benchmark", "#interpretability"], "emoji": "📊", "ru": {"title": "SVGenius: комплексная оценка возможностей ИИ в работе с векторной графикой", "desc": "SVGenius - это комплексный бенчмарк для оценки способностей больших я
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#training", "#rl", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эффективное раскрытие потенциала ИИ через обучение на критике", "desc": "Статья представляет метод Critique Fine-Tuning (CFT) для улучшения способностей рассуждения больших языковых моделей (LLM). CFT 
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#architecture", "#3d", "#video"], "emoji": "🎥", "ru": {"title": "Геометрия света: новый уровень контроля в генерации видео", "desc": "IllumiCraft - это инновационная диффузионная модель для генерации видео, интегрирующая геометрические подсказки для улуч
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#reasoning", "#training"], "emoji": "🧠", "ru": {"title": "Новый метод обучения для повышения социального интеллекта языковых моделей", "desc": "Исследователи представили метод Temporal-aware Hierarchical Cognitive Reinforcement Learning (TimeHC-RL) для улучшения соци
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#story_generation", "#data", "#dataset", "#optimization", "#training"], "emoji": "📊", "ru": {"title": "VisCode-200K: Большие данные для умного построения графиков", "desc": "VisCode-200K - это крупномасштабный набор данных для задач визуализации, который улучшает генерацию графиков 
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#architecture", "#inference", "#long_context", "#optimization", "#training"], "emoji": "🚀", "ru": {"title": "Эффективная генерация длинных текстов без потери качества", "desc": "Метод Rectified Sparse Attention (ReSA) улучшает эффективность генерации длинных последовательностей в бо
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#video", "#optimization", "#diffusion", "#rlhf"], "emoji": "🎬", "ru": {"title": "DenseDPO: Точная оптимизация предпочтений для улучшения генерации видео", "desc": "DenseDPO - это новый метод для улучшения текст-в-видео диффузионных моделей. Он решает проблему смещения в сторону клип
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#benchmark", "#data", "#hallucinations", "#interpretability", "#ethics", "#training"], "emoji": "⚖️", "ru": {"title": "DBG: Новый способ измерения предвзятости в языковых моделях", "desc": "Статья представляет новый метод измерения предвзятости самопредпочтения в больших языковых мо
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#math", "#rl", "#reasoning", "#optimization", "#rlhf", "#training"], "emoji": "🧠", "ru": {"title": "Critique-GRPO: Улучшение рассуждений ИИ через комбинированную обратную связь", "desc": "Статья представляет Critique-GRPO - новую систему обучения с подкреплением для улучшения рассуж
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#architecture", "#multimodal", "#inference", "#games", "#audio", "#video", "#optimization"], "emoji": "🗣️", "ru": {"title": "Оживляем аватары: аудио-управляемая генерация видео в реальном времени", "desc": "TalkingMachines - это эффективная система, преобразующая предобученные модел
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#training", "#optimization", "#diffusion", "#rlhf", "#security"], "emoji": "🛡️", "ru": {"title": "LEAF: Повышение устойчивости CLIP к состязательным атакам", "desc": "LEAF - это метод состязательной доводки (adversarial finetuning), который повышает устойчивость текст
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#diffusion", "#open_source", "#cv", "#dataset"], "emoji": "🖼️", "ru": {"title": "Умное разделение изображений на слои с помощью ИИ", "desc": "DiffDecompose - это новая система на основе диффузионного трансформера для декомпозиции изображений на семантические слои. Она решает проблем
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#benchmark", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Балансировка стабильности и пластичности в непрерывном обучении", "desc": "Статья представляет новый подход к непрерывному обучению (Continual Learning) с использованием предобученных моделей. Авторы предлага
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#synthetic", "#cv", "#optimization", "#open_source"], "emoji": "🖼️", "ru": {"title": "RefEdit: Прорыв в редактировании сложных изображений с помощью ИИ", "desc": "RefEdit - это модель редактирования изображений на основе инструкций, обученная на синтетическ
[05.06.2025 13:27] Using data from previous issue: {"categories": ["#training", "#optimization", "#alignment", "#rlhf", "#dataset"], "emoji": "⚖️", "ru": {"title": "LLM-судьи: автоматическая оценка языковых моделей с помощью регрессии", "desc": "Статья представляет фреймворк LLM-as-a-judge, где большая языковая модель оценивает результаты другой мод
[05.06.2025 13:27] Querying the API.
[05.06.2025 13:27] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Orak is a benchmark for training and evaluating LLM agents across diverse video games, featuring a plug-and-play interface and fine-tuning datasets to enhance agentic modules and gameplay.  					AI-generated summary 				 Large Language Model (LLM) agents are reshaping the game industry, particularly with more intelligent and human-preferable game characters. However, existing game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets for aligning pre-trained LLMs into gaming agents. To fill these gaps, we present \benchname{}, a foundational benchmark designed to train and evaluate LLM agents across diverse real-world video games. Unlike existing benchmarks, Orak includes 12 popular video games spanning all major genres, enabling comprehensive studies of LLM capabilities and agentic modules essential for intricate game scenarios. To support consistent evaluation of LLMs, we introduce a plug-and-play interface based on Model Context Protocol (MCP) that enables LLMs to seamlessly connect with games and manipulate agentic modules. Additionally, we propose a fine-tuning dataset, consisting of LLM gameplay trajectories across diverse game genres. Orak offers a comprehensive evaluation framework, encompassing general game score leaderboards, LLM battle arenas, and in-depth analyses of visual input state, agentic strategies, and fine-tuning effects, establishing a foundation towards building generic gaming agents. Code is available at https://github.com/krafton-ai/Orak.
[05.06.2025 13:28] Response: {
  "desc": "Orak - это новый бенчмарк для обучения и оценки агентов на основе больших языковых моделей (LLM) в разнообразных видеоиграх. Он включает в себя интерфейс plug-and-play и наборы данных для тонкой настройки, чтобы улучшить агентские модули и игровой процесс. Orak охватывает 12 популярных видеоигр различных жанров, что позволяет проводить комплексные исследования возможностей LLM и агентских модулей. Бенчмарк также предлагает всестороннюю систему оценки, включая таблицы лидеров по общим игровым показателям, арены для сражений LLM и углубленный анализ визуального ввода, агентских стратегий и эффектов тонкой настройки.",

  "emoji": "🎮",

  "title": "Orak: универсальный бенчмарк для создания игровых ИИ-агентов нового поколения"
}
[05.06.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Orak is a benchmark for training and evaluating LLM agents across diverse video games, featuring a plug-and-play interface and fine-tuning datasets to enhance agentic modules and gameplay.  					AI-generated summary 				 Large Language Model (LLM) agents are reshaping the game industry, particularly with more intelligent and human-preferable game characters. However, existing game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets for aligning pre-trained LLMs into gaming agents. To fill these gaps, we present \benchname{}, a foundational benchmark designed to train and evaluate LLM agents across diverse real-world video games. Unlike existing benchmarks, Orak includes 12 popular video games spanning all major genres, enabling comprehensive studies of LLM capabilities and agentic modules essential for intricate game scenarios. To support consistent evaluation of LLMs, we introduce a plug-and-play interface based on Model Context Protocol (MCP) that enables LLMs to seamlessly connect with games and manipulate agentic modules. Additionally, we propose a fine-tuning dataset, consisting of LLM gameplay trajectories across diverse game genres. Orak offers a comprehensive evaluation framework, encompassing general game score leaderboards, LLM battle arenas, and in-depth analyses of visual input state, agentic strategies, and fine-tuning effects, establishing a foundation towards building generic gaming agents. Code is available at https://github.com/krafton-ai/Orak."

[05.06.2025 13:28] Response: ```python
['BENCHMARK', 'AGENTS', 'VIDEO']
```
[05.06.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Orak is a benchmark for training and evaluating LLM agents across diverse video games, featuring a plug-and-play interface and fine-tuning datasets to enhance agentic modules and gameplay.  					AI-generated summary 				 Large Language Model (LLM) agents are reshaping the game industry, particularly with more intelligent and human-preferable game characters. However, existing game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets for aligning pre-trained LLMs into gaming agents. To fill these gaps, we present \benchname{}, a foundational benchmark designed to train and evaluate LLM agents across diverse real-world video games. Unlike existing benchmarks, Orak includes 12 popular video games spanning all major genres, enabling comprehensive studies of LLM capabilities and agentic modules essential for intricate game scenarios. To support consistent evaluation of LLMs, we introduce a plug-and-play interface based on Model Context Protocol (MCP) that enables LLMs to seamlessly connect with games and manipulate agentic modules. Additionally, we propose a fine-tuning dataset, consisting of LLM gameplay trajectories across diverse game genres. Orak offers a comprehensive evaluation framework, encompassing general game score leaderboards, LLM battle arenas, and in-depth analyses of visual input state, agentic strategies, and fine-tuning effects, establishing a foundation towards building generic gaming agents. Code is available at https://github.com/krafton-ai/Orak."

[05.06.2025 13:28] Response: ```python
['GAMES', 'TRANSFER_LEARNING']
```
[05.06.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Orak is a new benchmark designed for training and evaluating Large Language Model (LLM) agents in various video games. It addresses the limitations of existing benchmarks by providing a plug-and-play interface and fine-tuning datasets that enhance the performance of LLMs in complex gameplay scenarios. The benchmark includes 12 popular video games from different genres, allowing for a thorough assessment of LLM capabilities and agentic modules. With features like game score leaderboards and detailed analyses of gameplay strategies, Orak aims to advance the development of intelligent gaming agents.","title":"Orak: Elevating LLM Agents in Gaming"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Orak is a new benchmark designed for training and evaluating Large Language Model (LLM) agents in various video games. It addresses the limitations of existing benchmarks by providing a plug-and-play interface and fine-tuning datasets that enhance the performance of LLMs in complex gameplay scenarios. The benchmark includes 12 popular video games from different genres, allowing for a thorough assessment of LLM capabilities and agentic modules. With features like game score leaderboards and detailed analyses of gameplay strategies, Orak aims to advance the development of intelligent gaming agents.', title='Orak: Elevating LLM Agents in Gaming'))
[05.06.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Orak是一个用于训练和评估大型语言模型（LLM）代理的基准，涵盖多种视频游戏。它提供了即插即用的接口和微调数据集，以增强代理模块和游戏玩法。与现有基准不同，Orak支持12款流行视频游戏，允许对LLM能力和代理模块进行全面研究。该基准还引入了基于模型上下文协议（MCP）的接口，确保LLM能够与游戏无缝连接并操作代理模块。","title":"Orak：多样化视频游戏的LLM代理基准"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Orak是一个用于训练和评估大型语言模型（LLM）代理的基准，涵盖多种视频游戏。它提供了即插即用的接口和微调数据集，以增强代理模块和游戏玩法。与现有基准不同，Orak支持12款流行视频游戏，允许对LLM能力和代理模块进行全面研究。该基准还引入了基于模型上下文协议（MCP）的接口，确保LLM能够与游戏无缝连接并操作代理模块。', title='Orak：多样化视频游戏的LLM代理基准'))
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#data", "#transfer_learning", "#training", "#optimization", "#diffusion", "#dataset"], "emoji": "🧠", "ru": {"title": "Повышение устойчивости моделей через генерацию сложных примеров", "desc": "Статья представляет новую стратегию аугментации данных на основе диффузии для улучшения ро
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#survey", "#benchmark"], "emoji": "📊", "ru": {"title": "BenchHub: Универсальный инструмент для оценки языковых моделей", "desc": "BenchHub - это динамическое хранилище бенчмарков, которое агрегирует и классифицирует наборы данных для больших языковых мод
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#optimization", "#inference", "#training"], "emoji": "✂️", "ru": {"title": "Умная обрезка слоев для эффективных языковых моделей", "desc": "Предложен новый метод динамической послойной обрезки (DLP) для больших языковых моделей. DLP адаптивно определяет важность каждого слоя, комбин
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#training", "#architecture", "#survey", "#agents", "#multimodal", "#security", "#alignment", "#benchmark", "#interpretability"], "emoji": "🤖", "ru": {"title": "Безопасность и доверие в эпоху агентного ИИ", "desc": "Статья представляет структурированный анализ управления доверием, ри
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#cv", "#rl", "#training", "#reasoning", "#hallucinations", "#interpretability", "#dataset"], "emoji": "🔍", "ru": {"title": "Интерпретируемое объектное реферирование через пошаговые рассуждения", "desc": "Статья представляет новый подход к задаче объектного реферирования в компьютерн
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Двойная архитектура для эффективного непрерывного обучения", "desc": "Статья представляет новую архитектуру Dual-Arch для непрерывного обучения, которая решает дилемму стабильности-пластичности на архитект
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#open_source", "#data", "#dataset", "#multimodal", "#cv", "#benchmark", "#security", "#ethics"], "emoji": "🧩", "ru": {"title": "Визуальное сшивание: скрытая угроза в моделях компьютерного зрения", "desc": "Это исследование раскрывает феномен 'визуального сшивания' в моделях компьюте
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#graphs", "#cv", "#reasoning", "#agents", "#hallucinations", "#multimodal", "#benchmark", "#interpretability"], "emoji": "🔀", "ru": {"title": "Точная интерпретация блок-схем с помощью нейросимволического агента", "desc": "Статья представляет задачу точной атрибуции блок-схем и агент
[05.06.2025 13:28] Querying the API.
[05.06.2025 13:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

HTSC-2025, a benchmark dataset for high-temperature superconducting materials, is presented to facilitate AI-based discovery in this field.  					AI-generated summary 				 The discovery of high-temperature superconducting materials holds great significance for human industry and daily life. In recent years, research on predicting superconducting transition temperatures using artificial intelligence~(AI) has gained popularity, with most of these tools claiming to achieve remarkable accuracy. However, the lack of widely accepted benchmark datasets in this field has severely hindered fair comparisons between different AI algorithms and impeded further advancement of these methods. In this work, we present the HTSC-2025, an ambient-pressure high-temperature superconducting benchmark dataset. This comprehensive compilation encompasses theoretically predicted superconducting materials discovered by theoretical physicists from 2023 to 2025 based on BCS superconductivity theory, including the renowned X_2YH_6 system, perovskite MXH_3 system, M_3XH_8 system, cage-like BCN-doped metal atomic systems derived from LaH_{10} structural evolution, and two-dimensional honeycomb-structured systems evolving from MgB_2. The HTSC-2025 benchmark has been open-sourced at https://github.com/xqh19970407/HTSC-2025 and will be continuously updated. This benchmark holds significant importance for accelerating the discovery of superconducting materials using AI-based methods.
[05.06.2025 13:28] Response: {
  "desc": "Представлен набор данных HTSC-2025 для исследования высокотемпературных сверхпроводящих материалов с помощью методов искусственного интеллекта. Этот набор включает теоретически предсказанные сверхпроводящие материалы, открытые физиками-теоретиками с 2023 по 2025 год на основе теории сверхпроводимости БКШ. HTSC-2025 охватывает различные системы, включая X_2YH_6, перовскитную MXH_3, M_3XH_8 и другие. Данный бенчмарк имеет большое значение для ускорения открытия сверхпроводящих материалов с использованием методов, основанных на ИИ.",

  "emoji": "⚡",

  "title": "HTSC-2025: эталонный набор данных для прорыва в сверхпроводимости"
}
[05.06.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"HTSC-2025, a benchmark dataset for high-temperature superconducting materials, is presented to facilitate AI-based discovery in this field.  					AI-generated summary 				 The discovery of high-temperature superconducting materials holds great significance for human industry and daily life. In recent years, research on predicting superconducting transition temperatures using artificial intelligence~(AI) has gained popularity, with most of these tools claiming to achieve remarkable accuracy. However, the lack of widely accepted benchmark datasets in this field has severely hindered fair comparisons between different AI algorithms and impeded further advancement of these methods. In this work, we present the HTSC-2025, an ambient-pressure high-temperature superconducting benchmark dataset. This comprehensive compilation encompasses theoretically predicted superconducting materials discovered by theoretical physicists from 2023 to 2025 based on BCS superconductivity theory, including the renowned X_2YH_6 system, perovskite MXH_3 system, M_3XH_8 system, cage-like BCN-doped metal atomic systems derived from LaH_{10} structural evolution, and two-dimensional honeycomb-structured systems evolving from MgB_2. The HTSC-2025 benchmark has been open-sourced at https://github.com/xqh19970407/HTSC-2025 and will be continuously updated. This benchmark holds significant importance for accelerating the discovery of superconducting materials using AI-based methods."

[05.06.2025 13:28] Response: ```python
["DATASET", "BENCHMARK"]
```
[05.06.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"HTSC-2025, a benchmark dataset for high-temperature superconducting materials, is presented to facilitate AI-based discovery in this field.  					AI-generated summary 				 The discovery of high-temperature superconducting materials holds great significance for human industry and daily life. In recent years, research on predicting superconducting transition temperatures using artificial intelligence~(AI) has gained popularity, with most of these tools claiming to achieve remarkable accuracy. However, the lack of widely accepted benchmark datasets in this field has severely hindered fair comparisons between different AI algorithms and impeded further advancement of these methods. In this work, we present the HTSC-2025, an ambient-pressure high-temperature superconducting benchmark dataset. This comprehensive compilation encompasses theoretically predicted superconducting materials discovered by theoretical physicists from 2023 to 2025 based on BCS superconductivity theory, including the renowned X_2YH_6 system, perovskite MXH_3 system, M_3XH_8 system, cage-like BCN-doped metal atomic systems derived from LaH_{10} structural evolution, and two-dimensional honeycomb-structured systems evolving from MgB_2. The HTSC-2025 benchmark has been open-sourced at https://github.com/xqh19970407/HTSC-2025 and will be continuously updated. This benchmark holds significant importance for accelerating the discovery of superconducting materials using AI-based methods."

[05.06.2025 13:28] Response: ```python
['OPEN_SOURCE', 'SCIENCE']
```
[05.06.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces HTSC-2025, a new benchmark dataset designed for high-temperature superconducting materials to enhance AI-driven research in this area. It addresses the current challenge of insufficient benchmark datasets, which limits the ability to compare different AI algorithms effectively. The dataset includes a variety of theoretically predicted superconductors, derived from advanced theories and recent discoveries. By providing this resource, the authors aim to facilitate faster and more accurate discoveries of superconducting materials using artificial intelligence techniques.","title":"Accelerating Superconductor Discovery with HTSC-2025"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces HTSC-2025, a new benchmark dataset designed for high-temperature superconducting materials to enhance AI-driven research in this area. It addresses the current challenge of insufficient benchmark datasets, which limits the ability to compare different AI algorithms effectively. The dataset includes a variety of theoretically predicted superconductors, derived from advanced theories and recent discoveries. By providing this resource, the authors aim to facilitate faster and more accurate discoveries of superconducting materials using artificial intelligence techniques.', title='Accelerating Superconductor Discovery with HTSC-2025'))
[05.06.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"HTSC-2025是一个用于高温超导材料的基准数据集，旨在促进基于人工智能的发现。该数据集包含了2023至2025年间理论物理学家预测的超导材料，基于BCS超导理论。通过提供一个统一的基准，HTSC-2025可以帮助不同的AI算法进行公平比较，从而推动该领域的进一步发展。该数据集已开源，并将持续更新，以加速超导材料的发现。","title":"HTSC-2025：加速高温超导材料发现的基准数据集"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='HTSC-2025是一个用于高温超导材料的基准数据集，旨在促进基于人工智能的发现。该数据集包含了2023至2025年间理论物理学家预测的超导材料，基于BCS超导理论。通过提供一个统一的基准，HTSC-2025可以帮助不同的AI算法进行公平比较，从而推动该领域的进一步发展。该数据集已开源，并将持续更新，以加速超导材料的发现。', title='HTSC-2025：加速高温超导材料发现的基准数据集'))
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#training", "#data", "#optimization"], "emoji": "🔍", "ru": {"title": "Раскрывая секреты гиперпараметров в активном обучении", "desc": "Это исследование посвящено активному обучению (Active Learning, AL) в машинном обучении, которое помогает минимизировать усилия по разметке данных. 
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#training", "#3d", "#optimization"], "emoji": "🔍", "ru": {"title": "Двойное зрение для точной 3D-реконструкции", "desc": "Предложен новый метод Asymmetric Dual 3DGS для улучшения 3D-реконструкции изображений. Он основан на обучении двух параллельных моделей 3D Gaussian Splatting с о
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#diffusion", "#data", "#training", "#optimization"], "emoji": "🔄", "ru": {"title": "FLAIR: Революция в решении обратных задач с помощью потоковых генеративных моделей", "desc": "FLAIR - это новая вариационная система, использующая генеративные модели на основе п
[05.06.2025 13:28] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#dataset", "#benchmark"], "emoji": "💹", "ru": {"title": "FinChain: новый рубеж в оценке финансовых рассуждений ИИ", "desc": "FinChain - это новый бенчмарк для оценки многоэтапных символьных рассуждений в финансовых задачах, фокусирующийся на промежуточ
[05.06.2025 13:28] Loading Chinese text from previous data.
[05.06.2025 13:28] Renaming data file.
[05.06.2025 13:28] Renaming previous data. hf_papers.json to ./d/2025-06-05.json
[05.06.2025 13:28] Saving new data file.
[05.06.2025 13:28] Generating page.
[05.06.2025 13:28] Renaming previous page.
[05.06.2025 13:28] Renaming previous data. index.html to ./d/2025-06-05.html
[05.06.2025 13:28] [Experimental] Generating Chinese page for reading.
[05.06.2025 13:28] Chinese vocab [{'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open source'}, {'word': '视觉-语言模型', 'pinyin': 'shì jué yǔ yán mó xíng', 'trans': 'vision-language model'}, {'word': '表现出色', 'pinyin': 'biǎo xiàn chū sè', 'trans': 'perform excellently'}, {'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '超越', 'pinyin': 'chāo yuè', 'trans': 'surpass'}, {'word': '参数量', 'pinyin': 'cān shǔ liàng', 'trans': 'parameter quantity'}, {'word': 'GUI', 'pinyin': 'GUI', 'trans': 'Graphical User Interface'}, {'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'application'}, {'word': '专门', 'pinyin': 'zhuān mén', 'trans': 'specialized'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-training'}, {'word': '混合', 'pinyin': 'hùn hé', 'trans': 'hybrid'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '强化学习', 'pinyin': 'qiáng huà xué xí', 'trans': 'reinforcement learning'}, {'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluation'}, {'word': '套件', 'pinyin': 'tào jiàn', 'trans': 'suite'}, {'word': '可重复性', 'pinyin': 'kě chóng fù xìng', 'trans': 'reproducibility'}, {'word': '推动', 'pinyin': 'tuī dòng', 'trans': 'promote'}, {'word': '领域', 'pinyin': 'lǐng yù', 'trans': 'field'}, {'word': '检查点', 'pinyin': 'jiǎn chá diǎn', 'trans': 'checkpoint'}]
[05.06.2025 13:28] Renaming previous Chinese page.
[05.06.2025 13:28] Renaming previous data. zh.html to ./d/2025-06-04_zh_reading_task.html
[05.06.2025 13:28] Writing Chinese reading task.
[05.06.2025 13:28] Writing result.
[05.06.2025 13:28] Renaming log file.
[05.06.2025 13:28] Renaming previous data. log.txt to ./logs/2025-06-05_last_log.txt
