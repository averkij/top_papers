[28.05.2025 03:41] Read previous papers.
[28.05.2025 03:41] Generating top page (month).
[28.05.2025 03:41] Writing top page (month).
[28.05.2025 04:16] Read previous papers.
[28.05.2025 04:16] Get feed.
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21497
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19000
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21374
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20355
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18445
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21333
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18875
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21327
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21297
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18943
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16459
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20292
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20275
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20322
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19099
[28.05.2025 04:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.21473
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21457
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21070
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19314
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21491
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21205
[28.05.2025 04:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.17813
[28.05.2025 04:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.21494
[28.05.2025 04:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20289
[28.05.2025 04:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.05.2025 04:16] No deleted papers detected.
[28.05.2025 04:16] Downloading and parsing papers (pdf, html). Total: 24.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21497.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21497.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21497.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.19000.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.19000.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.19000.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21374.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21374.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21374.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.20355.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.20355.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.20355.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.18445.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.18445.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.18445.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21333.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21333.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21333.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.18875.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.18875.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.18875.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21327.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21327.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21327.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21297.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21297.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21297.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.18943.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.18943.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.18943.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.16459.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.16459.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.16459.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.20292.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.20292.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.20292.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.20275.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.20275.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.20275.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.20322.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.20322.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.20322.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.19099.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.19099.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.19099.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21473.
[28.05.2025 04:16] Downloading paper 2505.21473 from http://arxiv.org/pdf/2505.21473v1...
[28.05.2025 04:16] Extracting affiliations from text.
[28.05.2025 04:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 2 ] . [ 1 3 7 4 1 2 . 5 0 5 2 : r DetailFlow: 1D Coarse-to-Fine Autoregressive Image Generation via Next-Detail Prediction Yiheng Liu, Liao Qu, Huichao Zhang, Xu Wang, Yi Jiang, Yiming Gao, Hu Ye, Xian Li, Shuai Wang, Daniel K. Du, Shu Cheng, Zehuan Yuan, Xinglong Wu ByteDance Inc. https://github.com/ByteFlow-AI/DetailFlow Figure 1: (a) Progressive generation results from DetailFlow. Our proposed 1D tokenizer encodes tokens with an inherent semantic ordering, where each subsequent token contributes additional high-resolution information. The sequences illustrate how image resolution and inferred 1D tokens incrementally increase from left to right. (b) Comparison of our DetailFlow approach with existing methods, showing that DetailFlow achieves better image quality with fewer tokens and times. "
[28.05.2025 04:16] Response: ```python
["ByteDance Inc."]
```
[28.05.2025 04:16] Deleting PDF ./assets/pdf/2505.21473.pdf.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21457.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21457.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21457.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21070.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21070.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21070.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.19314.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.19314.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.19314.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21491.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21491.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21491.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21205.
[28.05.2025 04:16] Extra JSON file exists (./assets/json/2505.21205.json), skip PDF parsing.
[28.05.2025 04:16] Paper image links file exists (./assets/img_data/2505.21205.json), skip HTML parsing.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.17813.
[28.05.2025 04:16] Downloading paper 2505.17813 from http://arxiv.org/pdf/2505.17813v1...
[28.05.2025 04:16] Extracting affiliations from text.
[28.05.2025 04:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 2 ] . [ 1 3 1 8 7 1 . 5 0 5 2 : r Dont Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning Michael Hassid1,2, Gabriel Synnaeve1, Yossi Adi1,2, Roy Schwartz 1FAIR Team, Meta 2The Hebrew University of Jerusalem "
[28.05.2025 04:16] Response: ```python
["FAIR Team, Meta", "The Hebrew University of Jerusalem"]
```
[28.05.2025 04:16] Deleting PDF ./assets/pdf/2505.17813.pdf.
[28.05.2025 04:16] Success.
[28.05.2025 04:16] Downloading and parsing paper https://huggingface.co/papers/2505.21494.
[28.05.2025 04:16] Downloading paper 2505.21494 from http://arxiv.org/pdf/2505.21494v1...
[28.05.2025 04:17] Extracting affiliations from text.
[28.05.2025 04:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 2 ] . [ 1 4 9 4 1 2 . 5 0 5 2 : r Adversarial Attacks against Closed-Source MLLMs via Feature Optimal Alignment Xiaojun Jia1, Sensen Gao2, Simeng Qin1, Tianyu Pang3, Chao Du3, Yihao Huang1, Xinfeng Li1, Yiming Li1, Bo Li4, Yang Liu1 1Nanyang Technological University, Singapore 2 MBZUAI, United Arab Emirates 3Sea AI Lab, Singapore 4 University of Illinois Urbana-Champaign, USA {jiaxiaojunqaq, sensen.gao2002, qinsimeng670}@gmail.com; {tianyupang3, duchao, lxfmakeit, liyiming.tech}@gmail.com; lbo@illinois.edu; yangliu@ntu.edu.sg; "
[28.05.2025 04:17] Response: ```python
[
    "Nanyang Technological University, Singapore",
    "MBZUAI, United Arab Emirates",
    "Sea AI Lab, Singapore",
    "University of Illinois Urbana-Champaign, USA"
]
```
[28.05.2025 04:17] Deleting PDF ./assets/pdf/2505.21494.pdf.
[28.05.2025 04:17] Success.
[28.05.2025 04:17] Downloading and parsing paper https://huggingface.co/papers/2505.20289.
[28.05.2025 04:17] Extra JSON file exists (./assets/json/2505.20289.json), skip PDF parsing.
[28.05.2025 04:17] Paper image links file exists (./assets/img_data/2505.20289.json), skip HTML parsing.
[28.05.2025 04:17] Success.
[28.05.2025 04:17] Enriching papers with extra data.
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 0. Academic poster generation is a crucial yet challenging task in scientific communication, requiring the compression of long-context interleaved documents into a single, visually coherent page. To address this challenge, we introduce the first benchmark and metric suite for poster generation, which p...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 1. A Verifier-guided Iterative Policy Optimization method enhances Video-LLMs' reasoning capabilities by integrating a Rollout-Aware Verifier between GRPO and DPO phases, leading to faster and more effective optimization.  					AI-generated summary 				 Applying Reinforcement Learning (RL) to Video Lar...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 2. Video-Holmes benchmark evaluates complex video reasoning capabilities of MLLMs using suspense short films and reveals significant challenges in information integration compared to human experts.  					AI-generated summary 				 Recent advances in CoT reasoning and RL post-training have been reported ...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 3. Low-Rank Adaptation (LoRA) is a popular method for parameter-efficient fine-tuning (PEFT) of generative models, valued for its simplicity and effectiveness. Despite recent enhancements, LoRA still suffers from a fundamental limitation: overfitting when the bottleneck is widened. It performs best at ...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 4. OmniConsistency, using large-scale Diffusion Transformers, enhances stylization consistency and generalization in image-to-image pipelines without style degradation.  					AI-generated summary 				 Diffusion models have advanced image stylization significantly, yet two core challenges persist: (1) m...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 5. MLLMs achieve modest accuracy in video OCR due to motion blur, temporal variations, and visual effects; MME-VideoOCR benchmark reveals limitations in spatio-temporal reasoning and language bias.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have achieved considerable accur...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 6. SVG2 is a training-free framework that enhances video generation efficiency and quality by accurately identifying and processing critical tokens using semantic-aware permutation and dynamic budget control.  					AI-generated summary 				 Diffusion Transformers (DiTs) are essential for video generati...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 7. MME-Reasoning evaluates the logical reasoning capabilities of multimodal large language models, revealing significant limitations and performance imbalances across inductive, deductive, and abductive reasoning types.  					AI-generated summary 				 Logical reasoning is a fundamental aspect of human ...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 8. A large-scale dataset called rStar-Coder enhances code reasoning in LLMs by providing verified code problems and solutions, leading to improved performance on various benchmarks.  					AI-generated summary 				 Advancing code reasoning in large language models (LLMs) is fundamentally limited by the ...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 9. MetaMind, a multi-agent framework inspired by metacognition, enhances LLMs' ability to perform Theory of Mind tasks by decomposing social understanding into hypothesis generation, refinement, and response generation, achieving human-like performance.  					AI-generated summary 				 Human social inte...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 10. The MMMR benchmark evaluates multi-modal reasoning in MLLMs by assessing thinking quality through diverse reasoning types and a modular evaluation pipeline.  					AI-generated summary 				 Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled unified processing of language, visio...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 11. Subject-to-Video (S2V) generation aims to create videos that faithfully incorporate reference content, providing enhanced flexibility in the production of videos. To establish the infrastructure for S2V generation, we propose OpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, a...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 12. Recent advancements in generative models have enabled high-fidelity text-to-image generation. However, open-source image-editing models still lag behind their proprietary counterparts, primarily due to limited high-quality data and insufficient benchmarks. To overcome these limitations, we introduce...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 13. Precise control over language model generation is vital for ensuring both safety and reliability. Although prompt engineering and steering are commonly used to intervene in model behaviors, the vast number of parameters in models often results in highly intertwined internal representations. This int...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 14. SeePhys, a multimodal benchmark, highlights challenges in LLMs' visual reasoning and physics-grounded problem-solving capabilities, especially in interpreting diagrams and reducing reliance on textual cues.  					AI-generated summary 				 We present SeePhys, a large-scale multimodal benchmark for LL...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 15. This paper presents DetailFlow, a coarse-to-fine 1D autoregressive (AR) image generation method that models images through a novel next-detail prediction strategy. By learning a resolution-aware token sequence supervised with progressively degraded images, DetailFlow enables the generation process t...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 16. Active vision, also known as active perception, refers to the process of actively selecting where and how to look in order to gather task-relevant information. It is a critical component of efficient perception and decision-making in humans and advanced embodied agents. Recently, the use of Multimod...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 17. Diffusion Transformer (DiT)-based video diffusion models generate high-quality videos at scale but incur prohibitive processing latency and memory costs for long videos. To address this, we propose a novel distributed inference strategy, termed DualParal. The core idea is that, instead of generating...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 18. Target Speech Extraction (TSE) aims to isolate a target speaker's voice from a mixture of multiple speakers by leveraging speaker-specific cues, typically provided as auxiliary audio (a.k.a. cue audio). Although recent advancements in TSE have primarily employed discriminative models that offer high...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 19. Controllability, temporal coherence, and detail synthesis remain the most critical challenges in video generation. In this paper, we focus on a commonly used yet underexplored cinematic technique known as Frame In and Frame Out. Specifically, starting from image-to-video generation, users can contro...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 20. Frame inbetweening aims to synthesize intermediate video sequences conditioned on the given start and end frames. Current state-of-the-art methods mainly extend large-scale pre-trained Image-to-Video Diffusion models (I2V-DMs) by incorporating end-frame constraints via directly fine-tuning or omitti...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 21. Reasoning large language models (LLMs) heavily rely on scaling test-time compute to perform complex reasoning tasks by generating extensive "thinking" chains. While demonstrating impressive results, this approach incurs significant computational costs and inference time. In this work, we challenge t...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 22. Multimodal large language models (MLLMs) remain vulnerable to transferable adversarial examples. While existing methods typically achieve targeted attacks by aligning global features-such as CLIP's [CLS] token-between adversarial and target samples, they often overlook the rich local information enc...
[28.05.2025 04:17] ********************************************************************************
[28.05.2025 04:17] Abstract 23. VisTA, a reinforcement learning framework, enhances visual reasoning by autonomously selecting and combining tools from a diverse library without extensive human supervision.  					AI-generated summary 				 We introduce VisTA, a new reinforcement learning framework that empowers visual agents to dyn...
[28.05.2025 04:17] Read previous papers.
[28.05.2025 04:17] Generating reviews via LLM API.
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#open_source", "#agents", "#science"], "emoji": "🖼️", "ru": {"title": "Автоматическая генерация научных постеров: от статьи к визуализации", "desc": "Эта статья представляет первый эталонный тест и набор метрик для генерации академических постеров, сопос
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#reasoning", "#training", "#video", "#optimization", "#rl", "#rlhf"], "emoji": "🎥", "ru": {"title": "VerIPO: Улучшение рассуждений видео-LLM с помощью верификатора", "desc": "Статья представляет метод VerIPO для улучшения способностей видео-LLM к рассуждениям. Метод использует Verif
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark", "#video"], "emoji": "🕵️", "ru": {"title": "Шерлок Холмс для ИИ: новый вызов в понимании видео", "desc": "Video-Holmes - это новый бенчмарк для оценки способностей мультимодальных языковых моделей к сложным рассуждениям на основе видео. Он ис
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#dataset", "#training", "#benchmark", "#optimization"], "emoji": "🧩", "ru": {"title": "GraLoRA: Гранулярная низкоранговая адаптация для эффективной настройки генеративных моделей", "desc": "Статья представляет новый метод адаптации моделей машинного обучения под названием Granular L
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#diffusion", "#cv", "#training"], "emoji": "🎨", "ru": {"title": "Универсальная согласованность стиля в генерации изображений", "desc": "OmniConsistency - это универсальный плагин для улучшения согласованности стилизации в задачах преобразования изобра
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#multimodal", "#games", "#benchmark", "#reasoning", "#video"], "emoji": "🎥", "ru": {"title": "Ограничения мультимодальных моделей в задаче OCR на видео", "desc": "Мультимодальные большие языковые модели (MLLM) показывают невысокую точность в задаче оптического распознавания символов
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#diffusion", "#training", "#video", "#optimization"], "emoji": "🎞️", "ru": {"title": "Семантическая оптимизация для быстрой и качественной генерации видео", "desc": "SVG2 - это фреймворк для улучшения эффективности и качества генерации видео без дополнительного обучения. Он использу
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark"], "emoji": "🧠", "ru": {"title": "Раскрывая пробелы в логике искусственного интеллекта", "desc": "MME-Reasoning - это новый комплексный бенчмарк для оценки способностей мультимодальных больших языковых моделей (MLLM) к логическому рассуждению.
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#synthetic", "#reasoning", "#data"], "emoji": "🧠", "ru": {"title": "rStar-Coder: прорыв в обучении языковых моделей рассуждениям о коде", "desc": "Исследователи представили rStar-Coder - крупномасштабный датасет для улучшения способностей языковых моделей (
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#agents", "#reasoning", "#alignment"], "emoji": "🧠", "ru": {"title": "MetaMind: Искусственный интеллект с человеческим социальным пониманием", "desc": "MetaMind - это многоагентная система, улучшающая способность больших языковых моделей выполнять задачи
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark"], "emoji": "🧠", "ru": {"title": "MMMR: Новый стандарт оценки мультимодального мышления ИИ", "desc": "Статья представляет новый бенчмарк MMMR для оценки мультимодального рассуждения в крупных языковых моделях (MLLM). MMMR включает набор данных
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#synthetic", "#video"], "emoji": "🎬", "ru": {"title": "OpenS2V-Nexus: Революция в генерации видео на основе заданного содержания", "desc": "Статья представляет OpenS2V-Nexus - инфраструктуру для генерации видео на основе заданного содержания
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#optimization", "#cv", "#data"], "emoji": "🖼️", "ru": {"title": "ImgEdit: прорыв в редактировании изображений с помощью ИИ", "desc": "Исследователи представили ImgEdit - крупномасштабный набор данных для редактирования изображений, содержащи
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#security", "#training", "#alignment"], "emoji": "🎯", "ru": {"title": "Точное управление языковыми моделями через атомарные компоненты знаний", "desc": "Статья представляет новый метод под названием Steering Target Atoms (STA) для точного контроля над генерацией
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#benchmark", "#cv", "#multimodal"], "emoji": "🔬", "ru": {"title": "SeePhys: выявление ограничений визуального мышления LLM в физике", "desc": "SeePhys - это новый мультимодальный бенчмарк для оценки способностей больших языковых моделей (LLM) в обл
[28.05.2025 04:17] Querying the API.
[28.05.2025 04:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

This paper presents DetailFlow, a coarse-to-fine 1D autoregressive (AR) image generation method that models images through a novel next-detail prediction strategy. By learning a resolution-aware token sequence supervised with progressively degraded images, DetailFlow enables the generation process to start from the global structure and incrementally refine details. This coarse-to-fine 1D token sequence aligns well with the autoregressive inference mechanism, providing a more natural and efficient way for the AR model to generate complex visual content. Our compact 1D AR model achieves high-quality image synthesis with significantly fewer tokens than previous approaches, i.e. VAR/VQGAN. We further propose a parallel inference mechanism with self-correction that accelerates generation speed by approximately 8x while reducing accumulation sampling error inherent in teacher-forcing supervision. On the ImageNet 256x256 benchmark, our method achieves 2.96 gFID with 128 tokens, outperforming VAR (3.3 FID) and FlexVAR (3.05 FID), which both require 680 tokens in their AR models. Moreover, due to the significantly reduced token count and parallel inference mechanism, our method runs nearly 2x faster inference speed compared to VAR and FlexVAR. Extensive experimental results demonstrate DetailFlow's superior generation quality and efficiency compared to existing state-of-the-art methods.
[28.05.2025 04:17] Response: {
  "desc": "DetailFlow - это новый метод генерации изображений, использующий авторегрессионный подход с последовательным уточнением деталей. Модель обучается на токенизированных последовательностях изображений с прогрессивно ухудшающимся разрешением, что позволяет начинать генерацию с глобальной структуры и постепенно добавлять детали. Этот подход позволяет достичь высокого качества синтеза изображений при значительно меньшем количестве токенов по сравнению с предыдущими методами. Авторы также предлагают механизм параллельного вывода с самокоррекцией, который ускоряет генерацию примерно в 8 раз.",
  "emoji": "🖼️",
  "title": "Эффективная генерация изображений от общего к частному"
}
[28.05.2025 04:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"This paper presents DetailFlow, a coarse-to-fine 1D autoregressive (AR) image generation method that models images through a novel next-detail prediction strategy. By learning a resolution-aware token sequence supervised with progressively degraded images, DetailFlow enables the generation process to start from the global structure and incrementally refine details. This coarse-to-fine 1D token sequence aligns well with the autoregressive inference mechanism, providing a more natural and efficient way for the AR model to generate complex visual content. Our compact 1D AR model achieves high-quality image synthesis with significantly fewer tokens than previous approaches, i.e. VAR/VQGAN. We further propose a parallel inference mechanism with self-correction that accelerates generation speed by approximately 8x while reducing accumulation sampling error inherent in teacher-forcing supervision. On the ImageNet 256x256 benchmark, our method achieves 2.96 gFID with 128 tokens, outperforming VAR (3.3 FID) and FlexVAR (3.05 FID), which both require 680 tokens in their AR models. Moreover, due to the significantly reduced token count and parallel inference mechanism, our method runs nearly 2x faster inference speed compared to VAR and FlexVAR. Extensive experimental results demonstrate DetailFlow's superior generation quality and efficiency compared to existing state-of-the-art methods."

[28.05.2025 04:17] Response: ```python
['CV', 'BENCHMARK', 'ARCHITECTURE', 'TRAINING']
```
[28.05.2025 04:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"This paper presents DetailFlow, a coarse-to-fine 1D autoregressive (AR) image generation method that models images through a novel next-detail prediction strategy. By learning a resolution-aware token sequence supervised with progressively degraded images, DetailFlow enables the generation process to start from the global structure and incrementally refine details. This coarse-to-fine 1D token sequence aligns well with the autoregressive inference mechanism, providing a more natural and efficient way for the AR model to generate complex visual content. Our compact 1D AR model achieves high-quality image synthesis with significantly fewer tokens than previous approaches, i.e. VAR/VQGAN. We further propose a parallel inference mechanism with self-correction that accelerates generation speed by approximately 8x while reducing accumulation sampling error inherent in teacher-forcing supervision. On the ImageNet 256x256 benchmark, our method achieves 2.96 gFID with 128 tokens, outperforming VAR (3.3 FID) and FlexVAR (3.05 FID), which both require 680 tokens in their AR models. Moreover, due to the significantly reduced token count and parallel inference mechanism, our method runs nearly 2x faster inference speed compared to VAR and FlexVAR. Extensive experimental results demonstrate DetailFlow's superior generation quality and efficiency compared to existing state-of-the-art methods."

[28.05.2025 04:17] Response: ```python
["DIFFUSION"]
```
[28.05.2025 04:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces DetailFlow, a new method for generating images using a 1D autoregressive approach. It employs a next-detail prediction strategy that allows the model to start with a broad image structure and gradually add finer details. By using a resolution-aware token sequence and a parallel inference mechanism, DetailFlow significantly improves generation speed and reduces the number of tokens needed for high-quality image synthesis. The results show that DetailFlow outperforms existing models in both image quality and efficiency, achieving better performance with fewer resources.","title":"DetailFlow: Efficient 1D Image Generation with Coarse-to-Fine Refinement"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces DetailFlow, a new method for generating images using a 1D autoregressive approach. It employs a next-detail prediction strategy that allows the model to start with a broad image structure and gradually add finer details. By using a resolution-aware token sequence and a parallel inference mechanism, DetailFlow significantly improves generation speed and reduces the number of tokens needed for high-quality image synthesis. The results show that DetailFlow outperforms existing models in both image quality and efficiency, achieving better performance with fewer resources.', title='DetailFlow: Efficient 1D Image Generation with Coarse-to-Fine Refinement'))
[28.05.2025 04:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为DetailFlow的粗到细的1D自回归图像生成方法，采用了一种新颖的下一个细节预测策略来建模图像。通过学习一个分辨率感知的标记序列，并使用逐步降级的图像进行监督，DetailFlow使生成过程能够从全局结构开始，逐步细化细节。该粗到细的1D标记序列与自回归推理机制很好地对齐，为自回归模型生成复杂视觉内容提供了一种更自然和高效的方法。实验结果表明，DetailFlow在图像合成质量和效率上优于现有的最先进方法。","title":"DetailFlow：高效的自回归图像生成方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为DetailFlow的粗到细的1D自回归图像生成方法，采用了一种新颖的下一个细节预测策略来建模图像。通过学习一个分辨率感知的标记序列，并使用逐步降级的图像进行监督，DetailFlow使生成过程能够从全局结构开始，逐步细化细节。该粗到细的1D标记序列与自回归推理机制很好地对齐，为自回归模型生成复杂视觉内容提供了一种更自然和高效的方法。实验结果表明，DetailFlow在图像合成质量和效率上优于现有的最先进方法。', title='DetailFlow：高效的自回归图像生成方法'))
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#optimization", "#rl", "#agents", "#reasoning"], "emoji": "👁️", "ru": {"title": "ACTIVE-O3: Наделение MLLM активным восприятием для эффективного принятия решений", "desc": "Статья представляет ACTIVE-O3 - фреймворк обучения с подкреплением для наделения 
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#video", "#inference"], "emoji": "🎞️", "ru": {"title": "Ускорение генерации длинных видео с помощью распределенного вывода", "desc": "Статья представляет новую стратегию распределенного вывода для видео-диффузионных моделей на основе Diffusion Transfor
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#audio"], "emoji": "🎙️", "ru": {"title": "SoloSpeech: генеративное извлечение целевой речи нового поколения", "desc": "SoloSpeech - это новый генеративный подход к извлечению целевой речи из смеси голосов. Он использует каскадный пайплайн, включающий сжатие, извлечение, реконструкци
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#games", "#diffusion", "#architecture", "#video"], "emoji": "🎬", "ru": {"title": "Управляемая генерация видео: новый уровень контроля над объектами в кадре", "desc": "Статья посвящена улучшению контролируемости, временной согласованности и детализации в ген
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#architecture", "#video", "#training"], "emoji": "🎞️", "ru": {"title": "Симметричное внедрение граничных кадров для улучшенного синтеза видео", "desc": "Статья представляет новый подход к синтезу промежуточных видеокадров между заданными начальным и ко
[28.05.2025 04:17] Querying the API.
[28.05.2025 04:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Reasoning large language models (LLMs) heavily rely on scaling test-time compute to perform complex reasoning tasks by generating extensive "thinking" chains. While demonstrating impressive results, this approach incurs significant computational costs and inference time. In this work, we challenge the assumption that long thinking chains results in better reasoning capabilities. We first demonstrate that shorter reasoning chains within individual questions are significantly more likely to yield correct answers - up to 34.5% more accurate than the longest chain sampled for the same question. Based on these results, we suggest short-m@k, a novel reasoning LLM inference method. Our method executes k independent generations in parallel and halts computation once the first m thinking processes are done. The final answer is chosen using majority voting among these m chains. Basic short-1@k demonstrates similar or even superior performance over standard majority voting in low-compute settings - using up to 40% fewer thinking tokens. short-3@k, while slightly less efficient than short-1@k, consistently surpasses majority voting across all compute budgets, while still being substantially faster (up to 33% wall time reduction). Inspired by our results, we finetune an LLM using short, long, and randomly selected reasoning chains. We then observe that training on the shorter ones leads to better performance. Our findings suggest rethinking current methods of test-time compute in reasoning LLMs, emphasizing that longer "thinking" does not necessarily translate to improved performance and can, counter-intuitively, lead to degraded results.
[28.05.2025 04:17] Response: {
  "desc": "Статья исследует эффективность коротких цепочек рассуждений в крупных языковых моделях (LLM) для задач рассуждения. Авторы предлагают метод short-m@k, который выполняет параллельные генерации и выбирает ответ голосованием среди первых m завершенных процессов. Эксперименты показывают, что короткие цепочки часто дают более точные результаты, чем длинные, при меньших вычислительных затратах. Дополнительно, авторы обнаружили, что обучение на коротких цепочках рассуждений приводит к лучшей производительности модели.",
  "emoji": "⚡",
  "title": "Короче мысль - быстрее вывод: оптимизация рассуждений в LLM"
}
[28.05.2025 04:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reasoning large language models (LLMs) heavily rely on scaling test-time compute to perform complex reasoning tasks by generating extensive "thinking" chains. While demonstrating impressive results, this approach incurs significant computational costs and inference time. In this work, we challenge the assumption that long thinking chains results in better reasoning capabilities. We first demonstrate that shorter reasoning chains within individual questions are significantly more likely to yield correct answers - up to 34.5% more accurate than the longest chain sampled for the same question. Based on these results, we suggest short-m@k, a novel reasoning LLM inference method. Our method executes k independent generations in parallel and halts computation once the first m thinking processes are done. The final answer is chosen using majority voting among these m chains. Basic short-1@k demonstrates similar or even superior performance over standard majority voting in low-compute settings - using up to 40% fewer thinking tokens. short-3@k, while slightly less efficient than short-1@k, consistently surpasses majority voting across all compute budgets, while still being substantially faster (up to 33% wall time reduction). Inspired by our results, we finetune an LLM using short, long, and randomly selected reasoning chains. We then observe that training on the shorter ones leads to better performance. Our findings suggest rethinking current methods of test-time compute in reasoning LLMs, emphasizing that longer "thinking" does not necessarily translate to improved performance and can, counter-intuitively, lead to degraded results."

[28.05.2025 04:17] Response: ```python
['INFERENCE', 'TRAINING']
```
[28.05.2025 04:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reasoning large language models (LLMs) heavily rely on scaling test-time compute to perform complex reasoning tasks by generating extensive "thinking" chains. While demonstrating impressive results, this approach incurs significant computational costs and inference time. In this work, we challenge the assumption that long thinking chains results in better reasoning capabilities. We first demonstrate that shorter reasoning chains within individual questions are significantly more likely to yield correct answers - up to 34.5% more accurate than the longest chain sampled for the same question. Based on these results, we suggest short-m@k, a novel reasoning LLM inference method. Our method executes k independent generations in parallel and halts computation once the first m thinking processes are done. The final answer is chosen using majority voting among these m chains. Basic short-1@k demonstrates similar or even superior performance over standard majority voting in low-compute settings - using up to 40% fewer thinking tokens. short-3@k, while slightly less efficient than short-1@k, consistently surpasses majority voting across all compute budgets, while still being substantially faster (up to 33% wall time reduction). Inspired by our results, we finetune an LLM using short, long, and randomly selected reasoning chains. We then observe that training on the shorter ones leads to better performance. Our findings suggest rethinking current methods of test-time compute in reasoning LLMs, emphasizing that longer "thinking" does not necessarily translate to improved performance and can, counter-intuitively, lead to degraded results."

[28.05.2025 04:17] Response: ```python
["REASONING"]
```
[28.05.2025 04:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the effectiveness of reasoning in large language models (LLMs) by comparing long and short reasoning chains. The authors find that shorter reasoning chains can yield significantly more accurate answers, with improvements of up to 34.5% compared to longer chains. They introduce a new method called short-m@k, which allows for parallel processing of multiple reasoning chains and selects the final answer based on majority voting. Their results indicate that shorter reasoning processes not only enhance performance but also reduce computational costs and inference time, challenging the traditional belief that longer reasoning leads to better outcomes.","title":"Shorter Chains, Smarter Reasoning!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the effectiveness of reasoning in large language models (LLMs) by comparing long and short reasoning chains. The authors find that shorter reasoning chains can yield significantly more accurate answers, with improvements of up to 34.5% compared to longer chains. They introduce a new method called short-m@k, which allows for parallel processing of multiple reasoning chains and selects the final answer based on majority voting. Their results indicate that shorter reasoning processes not only enhance performance but also reduce computational costs and inference time, challenging the traditional belief that longer reasoning leads to better outcomes.', title='Shorter Chains, Smarter Reasoning!'))
[28.05.2025 04:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文探讨了大型语言模型（LLMs）在推理任务中依赖长思维链的假设。研究表明，较短的推理链在回答问题时更可能产生正确答案，准确率比最长链高出34.5%。基于此，提出了一种新的推理方法short-m@k，通过并行生成k个独立的思维过程，并在第一个m个完成后停止计算，最终答案通过多数投票选出。研究结果表明，短思维链的训练可以提高模型性能，挑战了长思维链必然带来更好推理能力的传统观念。","title":"短思维链，提升推理能力！"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文探讨了大型语言模型（LLMs）在推理任务中依赖长思维链的假设。研究表明，较短的推理链在回答问题时更可能产生正确答案，准确率比最长链高出34.5%。基于此，提出了一种新的推理方法short-m@k，通过并行生成k个独立的思维过程，并在第一个m个完成后停止计算，最终答案通过多数投票选出。研究结果表明，短思维链的训练可以提高模型性能，挑战了长思维链必然带来更好推理能力的传统观念。', title='短思维链，提升推理能力！'))
[28.05.2025 04:17] Querying the API.
[28.05.2025 04:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Multimodal large language models (MLLMs) remain vulnerable to transferable adversarial examples. While existing methods typically achieve targeted attacks by aligning global features-such as CLIP's [CLS] token-between adversarial and target samples, they often overlook the rich local information encoded in patch tokens. This leads to suboptimal alignment and limited transferability, particularly for closed-source models. To address this limitation, we propose a targeted transferable adversarial attack method based on feature optimal alignment, called FOA-Attack, to improve adversarial transfer capability. Specifically, at the global level, we introduce a global feature loss based on cosine similarity to align the coarse-grained features of adversarial samples with those of target samples. At the local level, given the rich local representations within Transformers, we leverage clustering techniques to extract compact local patterns to alleviate redundant local features. We then formulate local feature alignment between adversarial and target samples as an optimal transport (OT) problem and propose a local clustering optimal transport loss to refine fine-grained feature alignment. Additionally, we propose a dynamic ensemble model weighting strategy to adaptively balance the influence of multiple models during adversarial example generation, thereby further improving transferability. Extensive experiments across various models demonstrate the superiority of the proposed method, outperforming state-of-the-art methods, especially in transferring to closed-source MLLMs. The code is released at https://github.com/jiaxiaojunQAQ/FOA-Attack.
[28.05.2025 04:17] Response: {
  "desc": "Статья представляет новый метод атаки на мультимодальные языковые модели, называемый FOA-Attack. Он использует оптимальное выравнивание признаков на глобальном и локальном уровнях для улучшения переносимости состязательных примеров. Метод включает глобальное выравнивание с помощью косинусного сходства и локальное выравнивание с использованием кластеризации и оптимального транспорта. Также предлагается динамическая стратегия взвешивания ансамбля моделей для адаптивной балансировки влияния нескольких моделей при генерации состязательных примеров.",
  "emoji": "🎯",
  "title": "Усовершенствованная атака на мультимодальные языковые модели через оптимальное выравнивание признаков"
}
[28.05.2025 04:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multimodal large language models (MLLMs) remain vulnerable to transferable adversarial examples. While existing methods typically achieve targeted attacks by aligning global features-such as CLIP's [CLS] token-between adversarial and target samples, they often overlook the rich local information encoded in patch tokens. This leads to suboptimal alignment and limited transferability, particularly for closed-source models. To address this limitation, we propose a targeted transferable adversarial attack method based on feature optimal alignment, called FOA-Attack, to improve adversarial transfer capability. Specifically, at the global level, we introduce a global feature loss based on cosine similarity to align the coarse-grained features of adversarial samples with those of target samples. At the local level, given the rich local representations within Transformers, we leverage clustering techniques to extract compact local patterns to alleviate redundant local features. We then formulate local feature alignment between adversarial and target samples as an optimal transport (OT) problem and propose a local clustering optimal transport loss to refine fine-grained feature alignment. Additionally, we propose a dynamic ensemble model weighting strategy to adaptively balance the influence of multiple models during adversarial example generation, thereby further improving transferability. Extensive experiments across various models demonstrate the superiority of the proposed method, outperforming state-of-the-art methods, especially in transferring to closed-source MLLMs. The code is released at https://github.com/jiaxiaojunQAQ/FOA-Attack."

[28.05.2025 04:17] Response: ```python
['MULTIMODAL', 'TRAINING']
```
[28.05.2025 04:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multimodal large language models (MLLMs) remain vulnerable to transferable adversarial examples. While existing methods typically achieve targeted attacks by aligning global features-such as CLIP's [CLS] token-between adversarial and target samples, they often overlook the rich local information encoded in patch tokens. This leads to suboptimal alignment and limited transferability, particularly for closed-source models. To address this limitation, we propose a targeted transferable adversarial attack method based on feature optimal alignment, called FOA-Attack, to improve adversarial transfer capability. Specifically, at the global level, we introduce a global feature loss based on cosine similarity to align the coarse-grained features of adversarial samples with those of target samples. At the local level, given the rich local representations within Transformers, we leverage clustering techniques to extract compact local patterns to alleviate redundant local features. We then formulate local feature alignment between adversarial and target samples as an optimal transport (OT) problem and propose a local clustering optimal transport loss to refine fine-grained feature alignment. Additionally, we propose a dynamic ensemble model weighting strategy to adaptively balance the influence of multiple models during adversarial example generation, thereby further improving transferability. Extensive experiments across various models demonstrate the superiority of the proposed method, outperforming state-of-the-art methods, especially in transferring to closed-source MLLMs. The code is released at https://github.com/jiaxiaojunQAQ/FOA-Attack."

[28.05.2025 04:17] Response: ```python
['SECURITY']
```
[28.05.2025 04:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the vulnerability of multimodal large language models (MLLMs) to transferable adversarial examples. The authors introduce a new attack method called FOA-Attack, which focuses on aligning both global and local features to enhance the transferability of adversarial samples. By utilizing cosine similarity for global feature alignment and optimal transport for local feature alignment, the method improves the effectiveness of attacks on closed-source models. The proposed approach outperforms existing methods in various experiments, demonstrating its robustness in generating transferable adversarial examples.","title":"Enhancing Adversarial Transferability with FOA-Attack"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the vulnerability of multimodal large language models (MLLMs) to transferable adversarial examples. The authors introduce a new attack method called FOA-Attack, which focuses on aligning both global and local features to enhance the transferability of adversarial samples. By utilizing cosine similarity for global feature alignment and optimal transport for local feature alignment, the method improves the effectiveness of attacks on closed-source models. The proposed approach outperforms existing methods in various experiments, demonstrating its robustness in generating transferable adversarial examples.', title='Enhancing Adversarial Transferability with FOA-Attack'))
[28.05.2025 04:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"多模态大型语言模型（MLLMs）容易受到可转移的对抗样本攻击。现有方法通常通过对齐全局特征来实现目标攻击，但忽视了局部信息的丰富性。为了解决这个问题，我们提出了一种基于特征最优对齐的针对性可转移对抗攻击方法，称为FOA-Attack。通过引入全局特征损失和局部聚类最优传输损失，我们显著提高了对抗样本的转移能力。","title":"提升对抗样本转移能力的FOA-Attack方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='多模态大型语言模型（MLLMs）容易受到可转移的对抗样本攻击。现有方法通常通过对齐全局特征来实现目标攻击，但忽视了局部信息的丰富性。为了解决这个问题，我们提出了一种基于特征最优对齐的针对性可转移对抗攻击方法，称为FOA-Attack。通过引入全局特征损失和局部聚类最优传输损失，我们显著提高了对抗样本的转移能力。', title='提升对抗样本转移能力的FOA-Attack方法'))
[28.05.2025 04:17] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#benchmark", "#optimization", "#cv", "#rl"], "emoji": "🧠", "ru": {"title": "VisTA: Автономное улучшение визуального мышления с помощью обучения с подкреплением", "desc": "VisTA - это новая система обучения с подкреплением для улучшения визуального мышления. 
[28.05.2025 04:17] Loading Chinese text from previous data.
[28.05.2025 04:17] Renaming data file.
[28.05.2025 04:17] Renaming previous data. hf_papers.json to ./d/2025-05-28.json
[28.05.2025 04:17] Saving new data file.
[28.05.2025 04:17] Generating page.
[28.05.2025 04:17] Renaming previous page.
[28.05.2025 04:17] Renaming previous data. index.html to ./d/2025-05-28.html
[28.05.2025 04:17] [Experimental] Generating Chinese page for reading.
[28.05.2025 04:17] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '大型', 'pinyin': 'dà xíng', 'trans': 'large-scale'}, {'word': '语言模型', 'pinyin': 'yǔ yán mó xíng', 'trans': 'language model'}, {'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '快速', 'pinyin': 'kuài sù', 'trans': 'rapid'}, {'word': '发展', 'pinyin': 'fā zhǎn', 'trans': 'development'}, {'word': '主要', 'pinyin': 'zhǔ yào', 'trans': 'main'}, {'word': '通过', 'pinyin': 'tōng guò', 'trans': 'through'}, {'word': '增加', 'pinyin': 'zēng jiā', 'trans': 'increase'}, {'word': '参数', 'pinyin': 'cān shǔ', 'trans': 'parameter'}, {'word': '数量', 'pinyin': 'shù liàng', 'trans': 'quantity'}, {'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '硬件', 'pinyin': 'yìng jiàn', 'trans': 'hardware'}, {'word': '限制', 'pinyin': 'xiàn zhì', 'trans': 'limit'}, {'word': '自注意力', 'pinyin': 'zì zhù yì lì', 'trans': 'self-attention'}, {'word': '成本', 'pinyin': 'chéng běn', 'trans': 'cost'}, {'word': '瓶颈', 'pinyin': 'píng lóng', 'trans': 'bottleneck'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '重点', 'pinyin': 'zhòng diǎn', 'trans': 'focus'}, {'word': '模型压缩', 'pinyin': 'mó xíng yā suō', 'trans': 'model compression'}, {'word': '转向', 'pinyin': 'zhuǎn xiàng', 'trans': 'turn to'}, {'word': '数据压缩', 'pinyin': 'shù jù yā suō', 'trans': 'data compression'}, {'word': '令牌', 'pinyin': 'lìng pái', 'trans': 'token'}, {'word': '压缩', 'pinyin': 'yā suō', 'trans': 'compression'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'training'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '作者', 'pinyin': 'zuò zhě', 'trans': 'author'}, {'word': '分析', 'pinyin': 'fēn xī', 'trans': 'analyze'}, {'word': '长上下文', 'pinyin': 'cháng shàng xià wén', 'trans': 'long context'}, {'word': '数学框架', 'pinyin': 'shù xué kuàng jià', 'trans': 'mathematical framework'}, {'word': '探讨', 'pinyin': 'tàn tǎo', 'trans': 'explore'}, {'word': '优势', 'pinyin': 'yōu shì', 'trans': 'advantage'}, {'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'}]
[28.05.2025 04:17] Renaming previous Chinese page.
[28.05.2025 04:17] Renaming previous data. zh.html to ./d/2025-05-27_zh_reading_task.html
[28.05.2025 04:17] Writing Chinese reading task.
[28.05.2025 04:17] Writing result.
[28.05.2025 04:17] Renaming log file.
[28.05.2025 04:17] Renaming previous data. log.txt to ./logs/2025-05-28_last_log.txt
