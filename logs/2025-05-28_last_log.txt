[28.05.2025 12:22] Read previous papers.
[28.05.2025 12:22] Generating top page (month).
[28.05.2025 12:22] Writing top page (month).
[28.05.2025 13:27] Read previous papers.
[28.05.2025 13:27] Get feed.
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21327
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18445
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21497
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19641
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21189
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19000
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17813
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21496
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20292
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18875
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16459
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21333
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20355
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21374
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21297
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18943
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21334
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20275
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21505
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17952
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14064
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21457
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21491
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21500
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20322
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16901
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21473
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19099
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21494
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20561
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21205
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21178
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21070
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20289
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19433
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17005
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19973
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19314
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18657
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17908
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16673
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11277
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21499
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19650
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19377
[28.05.2025 13:27] Extract page data from URL. URL: https://huggingface.co/papers/2505.20321
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16340
[28.05.2025 13:27] Extract page data from URL. URL: https://huggingface.co/papers/2505.21471
[28.05.2025 13:27] Extract page data from URL. URL: https://huggingface.co/papers/2505.20286
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20052
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20036
[28.05.2025 13:27] Extract page data from URL. URL: https://huggingface.co/papers/2505.19954
[28.05.2025 13:27] Extract page data from URL. URL: https://huggingface.co/papers/2505.17855
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17190
[28.05.2025 13:27] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15561
[28.05.2025 13:27] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.05.2025 13:27] No deleted papers detected.
[28.05.2025 13:27] Downloading and parsing papers (pdf, html). Total: 55.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21327.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21327.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21327.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.18445.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.18445.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.18445.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21497.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21497.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21497.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19641.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19641.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19641.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21189.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21189.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21189.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19000.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19000.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19000.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.17813.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.17813.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.17813.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21496.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21496.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21496.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20292.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20292.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20292.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.18875.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.18875.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.18875.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.16459.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.16459.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.16459.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21333.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21333.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21333.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20355.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20355.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20355.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21374.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21374.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21374.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21297.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21297.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21297.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.18943.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.18943.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.18943.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21334.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21334.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21334.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20275.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20275.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20275.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21505.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21505.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21505.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.17952.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.17952.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.17952.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.14064.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.14064.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.14064.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21457.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21457.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21457.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21491.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21491.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21491.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21500.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21500.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21500.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20322.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20322.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20322.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.16901.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.16901.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.16901.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21473.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21473.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21473.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19099.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19099.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19099.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21494.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21494.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21494.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20561.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20561.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20561.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21205.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21205.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21205.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21178.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21178.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21178.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21070.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21070.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21070.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20289.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20289.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20289.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19433.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19433.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19433.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.17005.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.17005.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.17005.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19973.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19973.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19973.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19314.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19314.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19314.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.18657.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.18657.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.18657.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.17908.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.17908.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.17908.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.16673.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.16673.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.16673.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.11277.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.11277.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.11277.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21499.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.21499.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.21499.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19650.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19650.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19650.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19377.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.19377.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.19377.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20321.
[28.05.2025 13:27] Downloading paper 2505.20321 from http://arxiv.org/pdf/2505.20321v1...
[28.05.2025 13:27] Extracting affiliations from text.
[28.05.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases Mathew J. Koretsky1,2 Maya Willey1,2 Adi Asija2,3 Owen Bianchi1,2 Chelsea X. Alvarado1,2 Tanay Nayak2,3 Nicole Kuznetsov1,2 Mike A. Nalls1,2,4 Daniel Khashabi2,3* Faraz Faghri1,2,4* Sungwon Kim2,3 5 2 0 M 3 2 ] . [ 1 1 2 3 0 2 . 5 0 5 2 : r 1Center for Alzheimers Disease and Related Dementias, NIA, NIH; 2DataTecnica LLC; 3 Johns Hopkins University; 4Laboratory of Neurogenetics, NIA, NIH "
[28.05.2025 13:27] Response: ```python
["Center for Alzheimers Disease and Related Dementias, NIA, NIH", "DataTecnica LLC", "Johns Hopkins University", "Laboratory of Neurogenetics, NIA, NIH"]
```
[28.05.2025 13:27] Deleting PDF ./assets/pdf/2505.20321.pdf.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.16340.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.16340.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.16340.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.21471.
[28.05.2025 13:27] Downloading paper 2505.21471 from http://arxiv.org/pdf/2505.21471v1...
[28.05.2025 13:27] Extracting affiliations from text.
[28.05.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 2 ] . [ 1 1 7 4 1 2 . 5 0 5 2 : r Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration Zijun Liu1*, Zhennan Wan1*, Peng Li2, Ming Yan3, Ji Zhang3, Fei Huang3, Yang Liu1,2 1Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University 2Institute for AI Industry Research (AIR), Tsinghua University 3Tongyi Lab, Alibaba Group zj-liu24@mails.tsinghua.edu.cn, wanzn21@mails.tsinghua.edu.cn "
[28.05.2025 13:27] Response: ```python
[
    "Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University",
    "Institute for AI Industry Research (AIR), Tsinghua University",
    "Tongyi Lab, Alibaba Group"
]
```
[28.05.2025 13:27] Deleting PDF ./assets/pdf/2505.21471.pdf.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20286.
[28.05.2025 13:27] Downloading paper 2505.20286 from http://arxiv.org/pdf/2505.20286v1...
[28.05.2025 13:27] Extracting affiliations from text.
[28.05.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 6 8 2 0 2 . 5 0 5 2 : r ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF-EVOLUTION Jiahao Qiu1, Xuan Qi2, Tongcheng Zhang3, Xinzhe Juan3,4, Jiacheng Guo1, Yifu Lu1, Yimin Wang3,4, Zixin Yao1, Qihan Ren3, Xun Jiang5, Xing Zhou5, Dongrui Liu3, Ling Yang1, Yue Wu1, Kaixuan Huang1, Shilong Liu1, Hongru Wang6, Mengdi Wang1 1AI Lab, Princeton University 2IIIS, Tsinghua University 4University of Michigan 5Tianqiao and Chrissy Chen Institute 3Shanghai Jiao Tong University 6The Chinese University of Hong Kong Figure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1] "
[28.05.2025 13:27] Response: ```python
[
    "AI Lab, Princeton University",
    "IIIS, Tsinghua University",
    "University of Michigan",
    "Tianqiao and Chrissy Chen Institute",
    "Shanghai Jiao Tong University",
    "The Chinese University of Hong Kong"
]
```
[28.05.2025 13:27] Deleting PDF ./assets/pdf/2505.20286.pdf.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20052.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20052.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20052.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.20036.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.20036.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.20036.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.19954.
[28.05.2025 13:27] Downloading paper 2505.19954 from http://arxiv.org/pdf/2505.19954v1...
[28.05.2025 13:27] Extracting affiliations from text.
[28.05.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 4 5 9 9 1 . 5 0 5 2 : r An Explainable Diagnostic Framework for Neurodegenerative Dementias via Reinforcement-Optimized LLM Reasoning Andrew Zamai1 Nathanaël Fijalkow1 Boris Mansencal1 Laurent Simon1 Eloi Navet1 Pierrick Coupé1 1Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France "
[28.05.2025 13:27] Response: ```python
["Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France"]
```
[28.05.2025 13:27] Deleting PDF ./assets/pdf/2505.19954.pdf.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.17855.
[28.05.2025 13:27] Downloading paper 2505.17855 from http://arxiv.org/pdf/2505.17855v1...
[28.05.2025 13:27] Extracting affiliations from text.
[28.05.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Explaining Sources of Uncertainty in Automated Fact-Checking Jingyi Sun* Greta Warren* University of Copenhagen {jisu, grwa, ias, augenstein}@di.ku.dk 5 2 0 2 3 2 ] . [ 1 5 5 8 7 1 . 5 0 5 2 : r a "
[28.05.2025 13:27] Response: ```python
["University of Copenhagen"]
```
[28.05.2025 13:27] Deleting PDF ./assets/pdf/2505.17855.pdf.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.17190.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.17190.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.17190.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Downloading and parsing paper https://huggingface.co/papers/2505.15561.
[28.05.2025 13:27] Extra JSON file exists (./assets/json/2505.15561.json), skip PDF parsing.
[28.05.2025 13:27] Paper image links file exists (./assets/img_data/2505.15561.json), skip HTML parsing.
[28.05.2025 13:27] Success.
[28.05.2025 13:27] Enriching papers with extra data.
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 0. MME-Reasoning evaluates the logical reasoning capabilities of multimodal large language models, revealing significant limitations and performance imbalances across inductive, deductive, and abductive reasoning types.  					AI-generated summary 				 Logical reasoning is a fundamental aspect of human ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 1. OmniConsistency, using large-scale Diffusion Transformers, enhances stylization consistency and generalization in image-to-image pipelines without style degradation.  					AI-generated summary 				 Diffusion models have advanced image stylization significantly, yet two core challenges persist: (1) m...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 2. Academic poster generation is a crucial yet challenging task in scientific communication, requiring the compression of long-context interleaved documents into a single, visually coherent page. To address this challenge, we introduce the first benchmark and metric suite for poster generation, which p...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 3. SynLogic, a data synthesis framework, enhances the logical reasoning capabilities of Large Language Models through RL, achieving state-of-the-art performance and improving generalization across various domains.  					AI-generated summary 				 Recent advances such as OpenAI-o1 and DeepSeek R1 have de...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 4. LLMs can generate long text segments in a single forward pass using learned embeddings, revealing a capability for multi-token generation without iterative decoding.  					AI-generated summary 				 A recent study showed that large language models (LLMs) can reconstruct surprisingly long texts - up t...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 5. A Verifier-guided Iterative Policy Optimization method enhances Video-LLMs' reasoning capabilities by integrating a Rollout-Aware Verifier between GRPO and DPO phases, leading to faster and more effective optimization.  					AI-generated summary 				 Applying Reinforcement Learning (RL) to Video Lar...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 6. Reasoning large language models (LLMs) heavily rely on scaling test-time compute to perform complex reasoning tasks by generating extensive "thinking" chains. While demonstrating impressive results, this approach incurs significant computational costs and inference time. In this work, we challenge t...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 7. In this paper, we introduce UI-Genie, a self-improving framework addressing two key challenges in GUI agents: verification of trajectory outcome is challenging and high-quality training data are not scalable. These challenges are addressed by a reward model and a self-improving pipeline, respectivel...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 8. Subject-to-Video (S2V) generation aims to create videos that faithfully incorporate reference content, providing enhanced flexibility in the production of videos. To establish the infrastructure for S2V generation, we propose OpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, a...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 9. SVG2 is a training-free framework that enhances video generation efficiency and quality by accurately identifying and processing critical tokens using semantic-aware permutation and dynamic budget control.  					AI-generated summary 				 Diffusion Transformers (DiTs) are essential for video generati...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 10. The MMMR benchmark evaluates multi-modal reasoning in MLLMs by assessing thinking quality through diverse reasoning types and a modular evaluation pipeline.  					AI-generated summary 				 Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled unified processing of language, visio...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 11. MLLMs achieve modest accuracy in video OCR due to motion blur, temporal variations, and visual effects; MME-VideoOCR benchmark reveals limitations in spatio-temporal reasoning and language bias.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have achieved considerable accur...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 12. Low-Rank Adaptation (LoRA) is a popular method for parameter-efficient fine-tuning (PEFT) of generative models, valued for its simplicity and effectiveness. Despite recent enhancements, LoRA still suffers from a fundamental limitation: overfitting when the bottleneck is widened. It performs best at ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 13. Video-Holmes benchmark evaluates complex video reasoning capabilities of MLLMs using suspense short films and reveals significant challenges in information integration compared to human experts.  					AI-generated summary 				 Recent advances in CoT reasoning and RL post-training have been reported ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 14. A large-scale dataset called rStar-Coder enhances code reasoning in LLMs by providing verified code problems and solutions, leading to improved performance on various benchmarks.  					AI-generated summary 				 Advancing code reasoning in large language models (LLMs) is fundamentally limited by the ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 15. MetaMind, a multi-agent framework inspired by metacognition, enhances LLMs' ability to perform Theory of Mind tasks by decomposing social understanding into hypothesis generation, refinement, and response generation, achieving human-like performance.  					AI-generated summary 				 Human social inte...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 16. HoliTom combines outer-LLM pruning through global temporal segmentation with inner-LLM token similarity-based merging to significantly reduce computational inefficiency in video LLMs without sacrificing performance.  					AI-generated summary 				 Video large language models (video LLMs) excel at vi...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 17. Recent advancements in generative models have enabled high-fidelity text-to-image generation. However, open-source image-editing models still lag behind their proprietary counterparts, primarily due to limited high-quality data and insufficient benchmarks. To overcome these limitations, we introduce...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 18. The research proposes a finer-grained neuron identification algorithm for detecting language-specific and language-agnostic neurons in LLMs, and investigates the impact on multilingual alignment and capabilities through analysis of multilingual understanding, shared semantic reasoning, multilingual ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 19. Improving performance on complex tasks and enabling interpretable decision making in large language models (LLMs), especially for clinical applications, requires effective reasoning. Yet this remains challenging without supervised fine-tuning (SFT) on costly chain-of-thought (CoT) data distilled fro...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 20. NOVA is a benchmark for evaluating vision-language models on rare, clinically relevant MRI pathologies, challenging their out-of-distribution and open-world recognition capabilities.  					AI-generated summary 				 In many real-world applications, deployed models encounter inputs that differ from th...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 21. Active vision, also known as active perception, refers to the process of actively selecting where and how to look in order to gather task-relevant information. It is a critical component of efficient perception and decision-making in humans and advanced embodied agents. Recently, the use of Multimod...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 22. Controllability, temporal coherence, and detail synthesis remain the most critical challenges in video generation. In this paper, we focus on a commonly used yet underexplored cinematic technique known as Frame In and Frame Out. Specifically, starting from image-to-video generation, users can contro...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 23. Vision-language models (VLMs) have demonstrated remarkable capabilities in understanding and reasoning about visual content, but significant challenges persist in tasks requiring cross-viewpoint understanding and spatial reasoning. We identify a critical limitation: current VLMs excel primarily at e...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 24. Precise control over language model generation is vital for ensuring both safety and reliability. Although prompt engineering and steering are commonly used to intervene in model behaviors, the vast number of parameters in models often results in highly intertwined internal representations. This int...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 25. Open-source Code Graph Models enhance repository-level code generation tasks by integrating code graph structures into LLMs' attention mechanisms, achieving high performance without agent-based approaches.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have shown pro...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 26. This paper presents DetailFlow, a coarse-to-fine 1D autoregressive (AR) image generation method that models images through a novel next-detail prediction strategy. By learning a resolution-aware token sequence supervised with progressively degraded images, DetailFlow enables the generation process t...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 27. SeePhys, a multimodal benchmark, highlights challenges in LLMs' visual reasoning and physics-grounded problem-solving capabilities, especially in interpreting diagrams and reducing reliance on textual cues.  					AI-generated summary 				 We present SeePhys, a large-scale multimodal benchmark for LL...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 28. Multimodal large language models (MLLMs) remain vulnerable to transferable adversarial examples. While existing methods typically achieve targeted attacks by aligning global features-such as CLIP's [CLS] token-between adversarial and target samples, they often overlook the rich local information enc...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 29. BARL, a Bayes-Adaptive RL framework, enhances LLM performance by integrating reflective reasoning and efficient exploration, leading to better token efficiency and effectiveness in test scenarios.  					AI-generated summary 				 Large Language Models (LLMs) trained via Reinforcement Learning (RL) ha...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 30. Frame inbetweening aims to synthesize intermediate video sequences conditioned on the given start and end frames. Current state-of-the-art methods mainly extend large-scale pre-trained Image-to-Video Diffusion models (I2V-DMs) by incorporating end-frame constraints via directly fine-tuning or omitti...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 31. As test-time scaling becomes a pivotal research frontier in Large Language Models (LLMs) development, contemporary and advanced post-training methodologies increasingly focus on extending the generation length of long Chain-of-Thought (CoT) responses to enhance reasoning capabilities toward DeepSeek...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 32. Diffusion Transformer (DiT)-based video diffusion models generate high-quality videos at scale but incur prohibitive processing latency and memory costs for long videos. To address this, we propose a novel distributed inference strategy, termed DualParal. The core idea is that, instead of generating...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 33. VisTA, a reinforcement learning framework, enhances visual reasoning by autonomously selecting and combining tools from a diverse library without extensive human supervision.  					AI-generated summary 				 We introduce VisTA, a new reinforcement learning framework that empowers visual agents to dyn...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 34. Post-training compression reduces the computational and memory costs of large language models (LLMs), enabling resource-efficient deployment. However, existing compression benchmarks only focus on language modeling (e.g., perplexity) and natural language understanding tasks (e.g., GLUE accuracy), ig...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 35. R1-Searcher++, a novel framework, enhances LLMs by adaptively integrating internal and external knowledge through two-stage training, improving retrieval-augmented reasoning efficiency and performance.  					AI-generated summary 				 Large Language Models (LLMs) are powerful but prone to hallucinati...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 36. DFIR-Metric evaluates Large Language Models for digital forensics using a comprehensive benchmark with knowledge assessments, realistic forensic challenges, and practical analysis cases, introducing a Task Understanding Score for near-zero accuracy scenarios.  					AI-generated summary 				 Digital ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 37. Target Speech Extraction (TSE) aims to isolate a target speaker's voice from a mixture of multiple speakers by leveraging speaker-specific cues, typically provided as auxiliary audio (a.k.a. cue audio). Although recent advancements in TSE have primarily employed discriminative models that offer high...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 38. MLLMs exhibit modality bias, favoring language over other modalities like visual inputs, which impedes balanced multimodal integration and necessitates research into balanced strategies and architectures.  					AI-generated summary 				 Recent advances in Multimodal Large Language Models (MLLMs) hav...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 39. ComfyMind, a collaborative AI system built on ComfyUI, enhances generative workflows with a Semantic Workflow Interface and Search Tree Planning mechanism, outperforming existing open-source systems across generation, editing, and reasoning tasks.  					AI-generated summary 				 With the rapid advan...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 40. Share-GRPO, a novel reinforcement learning approach, enhances Multimodal Large Language Models by expanding the question space, sharing diverse reasoning trajectories, and hierarchical advantage computation.  					AI-generated summary 				 In this work, we aim to incentivize the reasoning ability of...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 41. AutoRefine, a reinforcement learning framework for large language models, enhances retrieval-augmented reasoning by iteratively refining knowledge and optimizing searches, leading to improved performance in complex question-answering tasks.  					AI-generated summary 				 Large language models have ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 42. AdInject is a novel real-world black-box attack method leveraging internet advertising to inject malicious content into vision-language model-based web agents, demonstrating significant vulnerability in web agent security.  					AI-generated summary 				 Vision-Language Model (VLM) based Web Agents ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 43. UNITE addresses challenges in multimodal information retrieval through data curation and modality-aware training, achieving state-of-the-art results across benchmarks with Modal-Aware Masked Contrastive Learning.  					AI-generated summary 				 Multimodal information retrieval (MIR) faces inherent c...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 44. Absolute joint coordinates in global space improve motion fidelity, text alignment, and scalability for text-to-motion generation, supporting downstream tasks with a simple Transformer backbone.  					AI-generated summary 				 State-of-the-art text-to-motion generation models rely on the kinematic-a...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 45. BiomedSQL evaluates scientific reasoning in text-to-SQL tasks using a large biomedical knowledge base, highlighting performance gaps in existing models.  					AI-generated summary 				 Biomedical researchers increasingly rely on large-scale structured databases for complex analytical tasks. However,...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 46. Large language models (LLMs) are increasingly recognized as powerful tools for scientific discovery, particularly in molecular science. A fundamental requirement for these models is the ability to accurately understand molecular structures, commonly encoded in the SMILES representation. However, cur...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 47. The ExtAgents multi-agent framework enhances the scalability of inference-time knowledge integration in large language models, improving performance without increasing the context window.  					AI-generated summary 				 With the rapid advancement of post-training techniques for reasoning and informa...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 48. Alita, a simplicity-driven generalist agent, achieves high performance across multiple benchmarks through minimal predefinition and self-evolution using task-related model context protocols.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled agents to autono...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 49. A multi-task pre-training strategy for protein language models improves their performance on downstream protein prediction tasks by learning richer representations from sequence data alone.  					AI-generated summary 				 Protein language models (PLMs) have emerged as powerful tools to detect comple...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 50. The study introduces a curated PPB-Affinity dataset and evaluates four architectural designs for adapting protein language models to predict protein-protein interaction binding affinity, demonstrating that hierarchical pooling and pooled attention addition architectures perform better than concatena...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 51. A framework using modular pipelines and reinforcement learning enhances the diagnostic clarity of deep learning models for neurodegenerative dementias by generating causally grounded explanations.  					AI-generated summary 				 The differential diagnosis of neurodegenerative dementias is a challeng...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 52. CLUE generates natural language explanations for a language model's uncertainty by identifying and explaining conflicts and agreements in text spans, enhancing the clarity and helpfulness of explanations in tasks like fact-checking.  					AI-generated summary 				 Understanding sources of a model's ...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 53. Dynamic programming (DP) algorithms for combinatorial optimization problems work with taking maximization, minimization, and classical addition in their recursion algorithms. The associated value functions correspond to convex polyhedra in the max plus semiring. Existing Neural Algorithmic Reasoning...
[28.05.2025 13:27] ********************************************************************************
[28.05.2025 13:27] Abstract 54. Retrieval Augmented Generation enhances LLM accuracy by adding passages retrieved from an external corpus to the LLM prompt. This paper investigates how positional bias - the tendency of LLMs to weight information differently based on its position in the prompt - affects not only the LLM's capabilit...
[28.05.2025 13:27] Read previous papers.
[28.05.2025 13:27] Generating reviews via LLM API.
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark"], "emoji": "🧠", "ru": {"title": "Раскрывая пробелы в логике искусственного интеллекта", "desc": "MME-Reasoning - это новый комплексный бенчмарк для оценки способностей мультимодальных больших языковых моделей (MLLM) к логическому рассуждению.
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#diffusion", "#cv", "#training"], "emoji": "🎨", "ru": {"title": "Универсальная согласованность стиля в генерации изображений", "desc": "OmniConsistency - это универсальный плагин для улучшения согласованности стилизации в задачах преобразования изобра
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#open_source", "#agents", "#science"], "emoji": "🖼️", "ru": {"title": "Автоматическая генерация научных постеров: от статьи к визуализации", "desc": "Эта статья представляет первый эталонный тест и набор метрик для генерации академических постеров, сопос
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#training", "#rl", "#dataset", "#reasoning", "#open_source"], "emoji": "🧠", "ru": {"title": "SynLogic: прорыв в обучении ИИ логическому мышлению", "desc": "SynLogic - это фреймворк для синтеза данных, который улучшает способности больших языковых моделей (LLM) к логическому рассужде
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#data", "#long_context", "#architecture", "#multimodal"], "emoji": "🚀", "ru": {"title": "Мгновенная генерация длинных текстов с помощью LLM", "desc": "Исследование показывает, что большие языковые модели (LLM) способны генерировать длинные тексты в один проход, используя только два 
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#training", "#video", "#optimization", "#rl", "#rlhf"], "emoji": "🎥", "ru": {"title": "VerIPO: Улучшение рассуждений видео-LLM с помощью верификатора", "desc": "Статья представляет метод VerIPO для улучшения способностей видео-LLM к рассуждениям. Метод использует Verif
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#inference", "#reasoning", "#training"], "emoji": "⚡", "ru": {"title": "Короче мысль - быстрее вывод: оптимизация рассуждений в LLM", "desc": "Статья исследует эффективность коротких цепочек рассуждений в крупных языковых моделях (LLM) для задач рассуждения. Авторы предлагают метод 
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#synthetic", "#open_source", "#dataset", "#agents", "#training", "#data"], "emoji": "🧞", "ru": {"title": "UI-Genie: самообучающийся ИИ-помощник для графических интерфейсов", "desc": "UI-Genie - это самосовершенствующаяся система для агентов графическог
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#synthetic", "#video"], "emoji": "🎬", "ru": {"title": "OpenS2V-Nexus: Революция в генерации видео на основе заданного содержания", "desc": "Статья представляет OpenS2V-Nexus - инфраструктуру для генерации видео на основе заданного содержания
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#diffusion", "#training", "#video", "#optimization"], "emoji": "🎞️", "ru": {"title": "Семантическая оптимизация для быстрой и качественной генерации видео", "desc": "SVG2 - это фреймворк для улучшения эффективности и качества генерации видео без дополнительного обучения. Он использу
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark"], "emoji": "🧠", "ru": {"title": "MMMR: Новый стандарт оценки мультимодального мышления ИИ", "desc": "Статья представляет новый бенчмарк MMMR для оценки мультимодального рассуждения в крупных языковых моделях (MLLM). MMMR включает набор данных
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#games", "#benchmark", "#reasoning", "#video"], "emoji": "🎥", "ru": {"title": "Ограничения мультимодальных моделей в задаче OCR на видео", "desc": "Мультимодальные большие языковые модели (MLLM) показывают невысокую точность в задаче оптического распознавания символов
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#training", "#benchmark", "#optimization"], "emoji": "🧩", "ru": {"title": "GraLoRA: Гранулярная низкоранговая адаптация для эффективной настройки генеративных моделей", "desc": "Статья представляет новый метод адаптации моделей машинного обучения под названием Granular L
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark", "#video"], "emoji": "🕵️", "ru": {"title": "Шерлок Холмс для ИИ: новый вызов в понимании видео", "desc": "Video-Holmes - это новый бенчмарк для оценки способностей мультимодальных языковых моделей к сложным рассуждениям на основе видео. Он ис
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#synthetic", "#reasoning", "#data"], "emoji": "🧠", "ru": {"title": "rStar-Coder: прорыв в обучении языковых моделей рассуждениям о коде", "desc": "Исследователи представили rStar-Coder - крупномасштабный датасет для улучшения способностей языковых моделей (
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#agents", "#reasoning", "#alignment"], "emoji": "🧠", "ru": {"title": "MetaMind: Искусственный интеллект с человеческим социальным пониманием", "desc": "MetaMind - это многоагентная система, улучшающая способность больших языковых моделей выполнять задачи
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#inference", "#video", "#optimization"], "emoji": "🎬", "ru": {"title": "HoliTom: Революционное сжатие токенов для эффективных видео-LLM", "desc": "HoliTom - это новый фреймворк для эффективного сжатия токенов в видео-LLM моделях. Он сочетает внешнюю обрезку LLM через глобальную врем
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#optimization", "#cv", "#data"], "emoji": "🖼️", "ru": {"title": "ImgEdit: прорыв в редактировании изображений с помощью ИИ", "desc": "Исследователи представили ImgEdit - крупномасштабный набор данных для редактирования изображений, содержащи
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#low_resource", "#multilingual", "#alignment"], "emoji": "🌐", "ru": {"title": "Раскрытие тайн многоязычности в нейронах LLM", "desc": "Исследование предлагает алгоритм более точной идентификации нейронов для обнаружения языково-специфичных и языково-агностических нейронов в больших 
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#healthcare", "#reasoning", "#benchmark", "#rl", "#dataset", "#interpretability"], "emoji": "🧠", "ru": {"title": "Революция в обучении медицинских ИИ: рассуждение без явных инструкций", "desc": "Статья представляет AlphaMed - первую медицинскую модель большого языка (LLM), демонстри
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#healthcare", "#cv", "#reasoning", "#benchmark", "#interpretability"], "emoji": "🧠", "ru": {"title": "NOVA: Экстремальный тест на обобщение ИИ в медицинской визуализации", "desc": "NOVA - это новый бенчмарк для оценки мультимодальных моделей на редких патологиях МРТ головного мозга.
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#optimization", "#rl", "#agents", "#reasoning"], "emoji": "👁️", "ru": {"title": "ACTIVE-O3: Наделение MLLM активным восприятием для эффективного принятия решений", "desc": "Статья представляет ACTIVE-O3 - фреймворк обучения с подкреплением для наделения 
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#games", "#diffusion", "#architecture", "#video"], "emoji": "🎬", "ru": {"title": "Управляемая генерация видео: новый уровень контроля над объектами в кадре", "desc": "Статья посвящена улучшению контролируемости, временной согласованности и детализации в ген
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#reasoning", "#3d", "#games"], "emoji": "🧠", "ru": {"title": "Новый рубеж в пространственном интеллекте моделей компьютерного зрения", "desc": "Статья представляет новый бенчмарк ViewSpatial-Bench для оценки способностей моделей компьютерного зрения к пространст
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#security", "#training", "#alignment"], "emoji": "🎯", "ru": {"title": "Точное управление языковыми моделями через атомарные компоненты знаний", "desc": "Статья представляет новый метод под названием Steering Target Atoms (STA) для точного контроля над генерацией
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#dataset", "#games", "#architecture", "#open_source"], "emoji": "🧠", "ru": {"title": "Графовые модели кода: новый уровень генерации в открытых ИИ-системах", "desc": "Статья представляет Code Graph Models (CGM) - новый подход к генерации кода на уровне ре
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#training", "#architecture", "#diffusion"], "emoji": "🖼️", "ru": {"title": "Эффективная генерация изображений от общего к частному", "desc": "DetailFlow - это новый метод генерации изображений, использующий авторегрессионный подход с последовательным уточнением 
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#benchmark", "#cv", "#multimodal"], "emoji": "🔬", "ru": {"title": "SeePhys: выявление ограничений визуального мышления LLM в физике", "desc": "SeePhys - это новый мультимодальный бенчмарк для оценки способностей больших языковых моделей (LLM) в обл
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#security", "#training"], "emoji": "🎯", "ru": {"title": "Усовершенствованная атака на мультимодальные языковые модели через оптимальное выравнивание признаков", "desc": "Статья представляет новый метод атаки на мультимодальные языковые модели, называемый FOA-Attack. О
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#rl", "#training", "#rlhf", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "BARL: Умнее исследуем, эффективнее рассуждаем", "desc": "BARL - это новая система Байесовского адаптивного обучения с подкреплением для улучшения работы больших языковых моделей. Она интегриру
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#architecture", "#video", "#training"], "emoji": "🎞️", "ru": {"title": "Симметричное внедрение граничных кадров для улучшенного синтеза видео", "desc": "Статья представляет новый подход к синтезу промежуточных видеокадров между заданными начальным и ко
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#optimization", "#training", "#rlhf", "#rl", "#reasoning", "#benchmark"], "emoji": "🧠", "ru": {"title": "Краткость - сестра таланта: новый метод для улучшения рассуждений ИИ", "desc": "Исследователи предложили новый метод обучения языковых моделей для улучшения их способности к расс
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#video", "#inference"], "emoji": "🎞️", "ru": {"title": "Ускорение генерации длинных видео с помощью распределенного вывода", "desc": "Статья представляет новую стратегию распределенного вывода для видео-диффузионных моделей на основе Diffusion Transfor
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#benchmark", "#optimization", "#cv", "#rl"], "emoji": "🧠", "ru": {"title": "VisTA: Автономное улучшение визуального мышления с помощью обучения с подкреплением", "desc": "VisTA - это новая система обучения с подкреплением для улучшения визуального мышления. 
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#agents", "#optimization", "#inference", "#benchmark"], "emoji": "🔬", "ru": {"title": "ACBench: первый комплексный бенчмарк для оценки агентных способностей сжатых LLM", "desc": "Статья представляет новый бенчмарк ACBench для оценки влияния сжатия на агентные способности больших язы
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#hallucinations", "#optimization", "#rl", "#reasoning", "#rag"], "emoji": "🧠", "ru": {"title": "Адаптивное обучение LLM: объединяем внутренние и внешние знания", "desc": "R1-Searcher++ - это новая система, улучшающая работу больших языковых моделей (LLM) путем адаптивной интеграции 
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#science", "#hallucinations", "#benchmark", "#dataset", "#optimization", "#reasoning"], "emoji": "🔍", "ru": {"title": "Комплексная оценка языковых моделей для цифровой криминалистики", "desc": "DFIR-Metric - это комплексный инструмент для оценки больших языковых моделей (LLM) в обла
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#audio"], "emoji": "🎙️", "ru": {"title": "SoloSpeech: генеративное извлечение целевой речи нового поколения", "desc": "SoloSpeech - это новый генеративный подход к извлечению целевой речи из смеси голосов. Он использует каскадный пайплайн, включающий сжатие, извлечение, реконструкци
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#interpretability", "#training", "#agi", "#multimodal", "#architecture"], "emoji": "🔬", "ru": {"title": "Преодоление языкового доминирования в мультимодальных ИИ-системах", "desc": "Статья исследует проблему модальной предвзятости в мультимодальных больших языковых моделях (MLLM), к
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#multimodal", "#open_source", "#games", "#training", "#reasoning", "#benchmark"], "emoji": "🧠", "ru": {"title": "ComfyMind: Улучшение генеративных рабочих процессов с помощью семантического интерфейса и адаптивного планирования", "desc": "ComfyMind - это система искусственного интел
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#rl", "#training", "#multimodal", "#benchmark", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "Усиление рассуждений MLLM через разделяемое обучение с подкреплением", "desc": "Share-GRPO - это новый подход в области обучения с подкреплением, который улучшает мультимод
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#optimization", "#rag", "#rl", "#reasoning", "#benchmark"], "emoji": "🔍", "ru": {"title": "AutoRefine: Умное уточнение знаний для улучшения рассуждений ИИ", "desc": "AutoRefine - это система обучения с подкреплением для больших языковых моделей, которая улучшает рассуждения на основ
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#cv", "#agents", "#security"], "emoji": "🕵️", "ru": {"title": "Реклама как оружие: новая угроза для ИИ-агентов в сети", "desc": "AdInject - это новый метод атаки на веб-агентов, основанных на мультимодальных языковых моделях, с использованием интернет-рекламы для внедрения вредоносн
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#dataset", "#data", "#benchmark", "#training", "#multimodal"], "emoji": "🔍", "ru": {"title": "UNITE: Преодоление разрыва между модальностями в мультимодальном поиске", "desc": "Статья представляет UNITE - универсальную систему для мультимодального информационного поиска. Авторы реша
[28.05.2025 13:27] Using data from previous issue: {"categories": ["#training", "#multimodal", "#games", "#optimization", "#cv"], "emoji": "🤖", "ru": {"title": "Глобальные координаты для улучшения генерации движений из текста", "desc": "В статье предлагается новый подход к генерации движений на основе текста, использующий абсолютные координаты суста
[28.05.2025 13:27] Querying the API.
[28.05.2025 13:27] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

BiomedSQL evaluates scientific reasoning in text-to-SQL tasks using a large biomedical knowledge base, highlighting performance gaps in existing models.  					AI-generated summary 				 Biomedical researchers increasingly rely on large-scale structured databases for complex analytical tasks. However, current text-to-SQL systems often struggle to map qualitative scientific questions into executable SQL, particularly when implicit domain reasoning is required. We introduce BiomedSQL, the first benchmark explicitly designed to evaluate scientific reasoning in text-to-SQL generation over a real-world biomedical knowledge base. BiomedSQL comprises 68,000 question/SQL query/answer triples grounded in a harmonized BigQuery knowledge base that integrates gene-disease associations, causal inference from omics data, and drug approval records. Each question requires models to infer domain-specific criteria, such as genome-wide significance thresholds, effect directionality, or trial phase filtering, rather than rely on syntactic translation alone. We evaluate a range of open- and closed-source LLMs across prompting strategies and interaction paradigms. Our results reveal a substantial performance gap: GPT-o3-mini achieves 59.0% execution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%, both well below the expert baseline of 90.0%. BiomedSQL provides a new foundation for advancing text-to-SQL systems capable of supporting scientific discovery through robust reasoning over structured biomedical knowledge bases. Our dataset is publicly available at https://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source at https://github.com/NIH-CARD/biomedsql.
[28.05.2025 13:27] Response: {
  "desc": "BiomedSQL - это новый эталонный тест для оценки научного мышления в задачах преобразования текста в SQL, использующий большую биомедицинскую базу знаний. Он включает 68 000 триплетов вопрос/SQL-запрос/ответ, основанных на интегрированной базе знаний BigQuery. Каждый вопрос требует от моделей вывода специфичных для предметной области критериев, а не просто синтаксического перевода. Результаты показывают значительный разрыв в производительности между существующими моделями и экспертным уровнем.",

  "emoji": "🧬",

  "title": "Оценка научного мышления в тексто-SQL задачах для биомедицины"
}
[28.05.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"BiomedSQL evaluates scientific reasoning in text-to-SQL tasks using a large biomedical knowledge base, highlighting performance gaps in existing models.  					AI-generated summary 				 Biomedical researchers increasingly rely on large-scale structured databases for complex analytical tasks. However, current text-to-SQL systems often struggle to map qualitative scientific questions into executable SQL, particularly when implicit domain reasoning is required. We introduce BiomedSQL, the first benchmark explicitly designed to evaluate scientific reasoning in text-to-SQL generation over a real-world biomedical knowledge base. BiomedSQL comprises 68,000 question/SQL query/answer triples grounded in a harmonized BigQuery knowledge base that integrates gene-disease associations, causal inference from omics data, and drug approval records. Each question requires models to infer domain-specific criteria, such as genome-wide significance thresholds, effect directionality, or trial phase filtering, rather than rely on syntactic translation alone. We evaluate a range of open- and closed-source LLMs across prompting strategies and interaction paradigms. Our results reveal a substantial performance gap: GPT-o3-mini achieves 59.0% execution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%, both well below the expert baseline of 90.0%. BiomedSQL provides a new foundation for advancing text-to-SQL systems capable of supporting scientific discovery through robust reasoning over structured biomedical knowledge bases. Our dataset is publicly available at https://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source at https://github.com/NIH-CARD/biomedsql."

[28.05.2025 13:27] Response: ```python
['DATASET', 'BENCHMARK', 'MULTIMODAL']
```
[28.05.2025 13:27] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"BiomedSQL evaluates scientific reasoning in text-to-SQL tasks using a large biomedical knowledge base, highlighting performance gaps in existing models.  					AI-generated summary 				 Biomedical researchers increasingly rely on large-scale structured databases for complex analytical tasks. However, current text-to-SQL systems often struggle to map qualitative scientific questions into executable SQL, particularly when implicit domain reasoning is required. We introduce BiomedSQL, the first benchmark explicitly designed to evaluate scientific reasoning in text-to-SQL generation over a real-world biomedical knowledge base. BiomedSQL comprises 68,000 question/SQL query/answer triples grounded in a harmonized BigQuery knowledge base that integrates gene-disease associations, causal inference from omics data, and drug approval records. Each question requires models to infer domain-specific criteria, such as genome-wide significance thresholds, effect directionality, or trial phase filtering, rather than rely on syntactic translation alone. We evaluate a range of open- and closed-source LLMs across prompting strategies and interaction paradigms. Our results reveal a substantial performance gap: GPT-o3-mini achieves 59.0% execution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%, both well below the expert baseline of 90.0%. BiomedSQL provides a new foundation for advancing text-to-SQL systems capable of supporting scientific discovery through robust reasoning over structured biomedical knowledge bases. Our dataset is publicly available at https://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source at https://github.com/NIH-CARD/biomedsql."

[28.05.2025 13:27] Response: ```python
['REASONING', 'OPEN_SOURCE', 'SCIENCE']
```
[28.05.2025 13:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"BiomedSQL is a benchmark designed to assess scientific reasoning in text-to-SQL tasks specifically within the biomedical domain. It highlights the challenges faced by existing models in translating qualitative scientific questions into executable SQL queries, especially when implicit reasoning is required. The benchmark includes 68,000 question/SQL query/answer triples based on a comprehensive biomedical knowledge base, which necessitates understanding complex domain-specific criteria. Evaluation of various large language models (LLMs) shows significant performance gaps, indicating the need for improved systems that can effectively support scientific discovery through advanced reasoning capabilities.","title":"Bridging the Gap in Biomedical Text-to-SQL Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='BiomedSQL is a benchmark designed to assess scientific reasoning in text-to-SQL tasks specifically within the biomedical domain. It highlights the challenges faced by existing models in translating qualitative scientific questions into executable SQL queries, especially when implicit reasoning is required. The benchmark includes 68,000 question/SQL query/answer triples based on a comprehensive biomedical knowledge base, which necessitates understanding complex domain-specific criteria. Evaluation of various large language models (LLMs) shows significant performance gaps, indicating the need for improved systems that can effectively support scientific discovery through advanced reasoning capabilities.', title='Bridging the Gap in Biomedical Text-to-SQL Reasoning'))
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"BiomedSQL是一个新的基准，旨在评估文本到SQL生成中的科学推理能力，特别是在生物医学领域。它包含68,000个问题、SQL查询和答案的三元组，基于一个整合了基因-疾病关联、组学数据因果推断和药物批准记录的知识库。现有的文本到SQL系统在将科学问题转化为可执行的SQL时，尤其是在需要隐含领域推理时，表现不佳。通过对多种大型语言模型的评估，BiomedSQL揭示了显著的性能差距，为支持科学发现的文本到SQL系统的进步奠定了基础。","title":"BiomedSQL：推动生物医学领域的科学推理"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='BiomedSQL是一个新的基准，旨在评估文本到SQL生成中的科学推理能力，特别是在生物医学领域。它包含68,000个问题、SQL查询和答案的三元组，基于一个整合了基因-疾病关联、组学数据因果推断和药物批准记录的知识库。现有的文本到SQL系统在将科学问题转化为可执行的SQL时，尤其是在需要隐含领域推理时，表现不佳。通过对多种大型语言模型的评估，BiomedSQL揭示了显著的性能差距，为支持科学发现的文本到SQL系统的进步奠定了基础。', title='BiomedSQL：推动生物医学领域的科学推理'))
[28.05.2025 13:28] Using data from previous issue: {"categories": ["#benchmark", "#graphs", "#science", "#dataset", "#open_source", "#data", "#multimodal"], "emoji": "🧪", "ru": {"title": "CLEANMOL: Улучшение понимания молекул языковыми моделями", "desc": "Статья представляет CLEANMOL - новый фреймворк для улучшения понимания молекулярных структур бо
[28.05.2025 13:28] Querying the API.
[28.05.2025 13:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The ExtAgents multi-agent framework enhances the scalability of inference-time knowledge integration in large language models, improving performance without increasing the context window.  					AI-generated summary 				 With the rapid advancement of post-training techniques for reasoning and information seeking, large language models (LLMs) can incorporate a large quantity of retrieved knowledge to solve complex tasks. However, the limited context window of LLMs obstructs scaling the amount of external knowledge input, prohibiting further improvement, especially for tasks requiring significant amount of external knowledge. Existing context window extension methods inevitably cause information loss. LLM-based multi-agent methods emerge as a new paradigm to handle massive input in a distributional manner, where we identify two core bottlenecks in existing knowledge synchronization and reasoning processes. In this work, we develop a multi-agent framework, ExtAgents, to overcome the bottlenecks and enable better scalability in inference-time knowledge integration without longer-context training. Benchmarked with our enhanced multi-hop question answering test, $boldsymbol{inftyBench+}, and other public test sets including long survey generation, ExtAgents significantly enhances the performance over existing non-training methods with the same amount of external knowledge input, regardless of whether it falls within or exceeds the context window$. Moreover, the method maintains high efficiency due to high parallelism. Further study in the coordination of LLM agents on increasing external knowledge input could benefit real-world applications.
[28.05.2025 13:28] Response: {
  "desc": "Статья представляет новую систему ExtAgents, которая улучшает масштабируемость интеграции знаний во время вывода в больших языковых моделях (БЯМ). Эта мультиагентная система позволяет обрабатывать большие объемы внешних знаний, преодолевая ограничения контекстного окна БЯМ. ExtAgents показывает значительное улучшение производительности на различных задачах, включая многоэтапные вопросно-ответные системы и генерацию длинных обзоров. Система сохраняет высокую эффективность благодаря параллелизму и не требует дополнительного обучения модели.",

  "emoji": "🤖",

  "title": "ExtAgents: Расширение возможностей БЯМ без увеличения контекстного окна"
}
[28.05.2025 13:28] Renaming some terms.
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The ExtAgents multi-agent framework enhances the scalability of inference-time knowledge integration in large language models, improving performance without increasing the context window.  					AI-generated summary 				 With the rapid advancement of post-training techniques for reasoning and information seeking, large language models (LLMs) can incorporate a large quantity of retrieved knowledge to solve complex tasks. However, the limited context window of LLMs obstructs scaling the amount of external knowledge input, prohibiting further improvement, especially for tasks requiring significant amount of external knowledge. Existing context window extension methods inevitably cause information loss. LLM-based multi-agent methods emerge as a new paradigm to handle massive input in a distributional manner, where we identify two core bottlenecks in existing knowledge synchronization and reasoning processes. In this work, we develop a multi-agent framework, ExtAgents, to overcome the bottlenecks and enable better scalability in inference-time knowledge integration without longer-context training. Benchmarked with our enhanced multi-hop question answering test, $boldsymbol{inftyBench+}, and other public test sets including long survey generation, ExtAgents significantly enhances the performance over existing non-training methods with the same amount of external knowledge input, regardless of whether it falls within or exceeds the context window$. Moreover, the method maintains high efficiency due to high parallelism. Further study in the coordination of LLM agents on increasing external knowledge input could benefit real-world applications."

[28.05.2025 13:28] Response: ```python
['AGENTS', 'INFERENCE', 'BENCHMARK']
```
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The ExtAgents multi-agent framework enhances the scalability of inference-time knowledge integration in large language models, improving performance without increasing the context window.  					AI-generated summary 				 With the rapid advancement of post-training techniques for reasoning and information seeking, large language models (LLMs) can incorporate a large quantity of retrieved knowledge to solve complex tasks. However, the limited context window of LLMs obstructs scaling the amount of external knowledge input, prohibiting further improvement, especially for tasks requiring significant amount of external knowledge. Existing context window extension methods inevitably cause information loss. LLM-based multi-agent methods emerge as a new paradigm to handle massive input in a distributional manner, where we identify two core bottlenecks in existing knowledge synchronization and reasoning processes. In this work, we develop a multi-agent framework, ExtAgents, to overcome the bottlenecks and enable better scalability in inference-time knowledge integration without longer-context training. Benchmarked with our enhanced multi-hop question answering test, $boldsymbol{inftyBench+}, and other public test sets including long survey generation, ExtAgents significantly enhances the performance over existing non-training methods with the same amount of external knowledge input, regardless of whether it falls within or exceeds the context window$. Moreover, the method maintains high efficiency due to high parallelism. Further study in the coordination of LLM agents on increasing external knowledge input could benefit real-world applications."

[28.05.2025 13:28] Response: ```python
["LONG_CONTEXT", "REASONING"]
```
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The ExtAgents framework improves how large language models (LLMs) integrate external knowledge during inference without needing to extend their context window. It addresses key challenges in knowledge synchronization and reasoning that limit the effectiveness of existing methods. By using a multi-agent approach, ExtAgents allows for better scalability and performance in tasks that require significant external information. This method not only enhances results in multi-hop question answering but also maintains efficiency through parallel processing.","title":"Scalable Knowledge Integration with ExtAgents Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The ExtAgents framework improves how large language models (LLMs) integrate external knowledge during inference without needing to extend their context window. It addresses key challenges in knowledge synchronization and reasoning that limit the effectiveness of existing methods. By using a multi-agent approach, ExtAgents allows for better scalability and performance in tasks that require significant external information. This method not only enhances results in multi-hop question answering but also maintains efficiency through parallel processing.', title='Scalable Knowledge Integration with ExtAgents Framework'))
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ExtAgents是一个多智能体框架，旨在提高大语言模型在推理时整合外部知识的可扩展性。该框架解决了现有知识同步和推理过程中的两个核心瓶颈，从而在不增加上下文窗口的情况下，提升了性能。通过在多跳问答测试和其他公共测试集上的基准测试，ExtAgents显著提高了在相同外部知识输入下的表现。该方法还因其高并行性而保持了高效率，未来在协调LLM智能体以增加外部知识输入方面的研究将有助于实际应用。","title":"ExtAgents：提升大语言模型知识整合的可扩展性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ExtAgents是一个多智能体框架，旨在提高大语言模型在推理时整合外部知识的可扩展性。该框架解决了现有知识同步和推理过程中的两个核心瓶颈，从而在不增加上下文窗口的情况下，提升了性能。通过在多跳问答测试和其他公共测试集上的基准测试，ExtAgents显著提高了在相同外部知识输入下的表现。该方法还因其高并行性而保持了高效率，未来在协调LLM智能体以增加外部知识输入方面的研究将有助于实际应用。', title='ExtAgents：提升大语言模型知识整合的可扩展性'))
[28.05.2025 13:28] Querying the API.
[28.05.2025 13:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Alita, a simplicity-driven generalist agent, achieves high performance across multiple benchmarks through minimal predefinition and self-evolution using task-related model context protocols.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita--a generalist agent designed with the principle of "Simplicity is the ultimate sophistication," enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at https://github.com/CharlesQ9/Alita{https://github.com/CharlesQ9/Alita}.
[28.05.2025 13:28] Response: {
  "desc": "Алита - это агент широкого профиля, достигающий высокой производительности на различных тестах благодаря минимальному предопределению и саморазвитию. Он использует протоколы контекста модели, связанные с задачей, для масштабируемого агентного рассуждения. Алита оснащена только одним компонентом для прямого решения проблем, что делает ее намного проще предыдущих подходов. Агент достигает высоких результатов на эталонных наборах данных GAIA, Mathvista и PathVQA, превосходя многие более сложные системы.",
  "emoji": "🤖",
  "title": "Простота - ключ к универсальному ИИ-агенту"
}
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Alita, a simplicity-driven generalist agent, achieves high performance across multiple benchmarks through minimal predefinition and self-evolution using task-related model context protocols.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita--a generalist agent designed with the principle of "Simplicity is the ultimate sophistication," enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at https://github.com/CharlesQ9/Alita{https://github.com/CharlesQ9/Alita}."

[28.05.2025 13:28] Response: ```python
['AGENTS', 'BENCHMARK']
```
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Alita, a simplicity-driven generalist agent, achieves high performance across multiple benchmarks through minimal predefinition and self-evolution using task-related model context protocols.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita--a generalist agent designed with the principle of "Simplicity is the ultimate sophistication," enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at https://github.com/CharlesQ9/Alita{https://github.com/CharlesQ9/Alita}."

[28.05.2025 13:28] Response: ```python
["AGI", "REASONING", "OPEN_SOURCE"]
```
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Alita is a generalist agent that excels in various tasks by focusing on simplicity and self-evolution. It minimizes the need for predefined tools, allowing it to adapt and generalize better across different domains. By using task-related model context protocols, Alita can autonomously develop and refine its capabilities, enhancing its problem-solving skills. Its performance on benchmarks like GAIA demonstrates its effectiveness, achieving high accuracy rates compared to more complex systems.","title":"Simplicity Fuels Alita\'s Generalist Intelligence"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Alita is a generalist agent that excels in various tasks by focusing on simplicity and self-evolution. It minimizes the need for predefined tools, allowing it to adapt and generalize better across different domains. By using task-related model context protocols, Alita can autonomously develop and refine its capabilities, enhancing its problem-solving skills. Its performance on benchmarks like GAIA demonstrates its effectiveness, achieving high accuracy rates compared to more complex systems.', title="Simplicity Fuels Alita's Generalist Intelligence"))
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Alita是一种以简约为驱动的通用智能体，通过最小的预定义和自我进化在多个基准测试中实现了高性能。与依赖手动预定义工具的现有框架不同，Alita仅配备一个直接解决问题的组件，使其设计更加简洁。它通过生成任务相关的模型上下文协议（MCPs）来增强自我进化能力，从而实现可扩展的智能推理。Alita在GAIA基准验证数据集上达到了75.15%的pass@1和87.27%的pass@3准确率，表现优于许多复杂的智能体系统。","title":"简约设计，强大智能！"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Alita是一种以简约为驱动的通用智能体，通过最小的预定义和自我进化在多个基准测试中实现了高性能。与依赖手动预定义工具的现有框架不同，Alita仅配备一个直接解决问题的组件，使其设计更加简洁。它通过生成任务相关的模型上下文协议（MCPs）来增强自我进化能力，从而实现可扩展的智能推理。Alita在GAIA基准验证数据集上达到了75.15%的pass@1和87.27%的pass@3准确率，表现优于许多复杂的智能体系统。', title='简约设计，强大智能！'))
[28.05.2025 13:28] Using data from previous issue: {"categories": ["#training", "#optimization", "#healthcare", "#dataset", "#science"], "emoji": "🧬", "ru": {"title": "Многозадачное обучение раскрывает потенциал белковых языковых моделей", "desc": "Исследователи разработали новую стратегию предварительного обучения белковых языковых моделей (PLM) с 
[28.05.2025 13:28] Using data from previous issue: {"categories": ["#training", "#optimization", "#leakage", "#architecture", "#dataset", "#science"], "emoji": "🧬", "ru": {"title": "Улучшение предсказания аффинности белок-белковых взаимодействий с помощью продвинутых архитектур языковых моделей", "desc": "Исследование представляет курированный набор
[28.05.2025 13:28] Querying the API.
[28.05.2025 13:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A framework using modular pipelines and reinforcement learning enhances the diagnostic clarity of deep learning models for neurodegenerative dementias by generating causally grounded explanations.  					AI-generated summary 				 The differential diagnosis of neurodegenerative dementias is a challenging clinical task, mainly because of the overlap in symptom presentation and the similarity of patterns observed in structural neuroimaging. To improve diagnostic efficiency and accuracy, deep learning-based methods such as Convolutional Neural Networks and Vision Transformers have been proposed for the automatic classification of brain MRIs. However, despite their strong predictive performance, these models find limited clinical utility due to their opaque decision making. In this work, we propose a framework that integrates two core components to enhance diagnostic transparency. First, we introduce a modular pipeline for converting 3D T1-weighted brain MRIs into textual radiology reports. Second, we explore the potential of modern Large Language Models (LLMs) to assist clinicians in the differential diagnosis between Frontotemporal dementia subtypes, Alzheimer's disease, and normal aging based on the generated reports. To bridge the gap between predictive accuracy and explainability, we employ reinforcement learning to incentivize diagnostic reasoning in LLMs. Without requiring supervised reasoning traces or distillation from larger models, our approach enables the emergence of structured diagnostic rationales grounded in neuroimaging findings. Unlike post-hoc explainability methods that retrospectively justify model decisions, our framework generates diagnostic rationales as part of the inference process-producing causally grounded explanations that inform and guide the model's decision-making process. In doing so, our framework matches the diagnostic performance of existing deep learning methods while offering rationales that support its diagnostic conclusions.
[28.05.2025 13:28] Response: {
  "desc": "Статья представляет фреймворк для улучшения диагностической ясности моделей глубокого обучения при нейродегенеративных деменциях. Он использует модульные пайплайны для преобразования 3D МРТ мозга в текстовые радиологические отчеты. Затем применяются большие языковые модели (LLM) для дифференциальной диагностики на основе этих отчетов. Обучение с подкреплением используется для стимулирования диагностических рассуждений в LLM, что позволяет получать структурированные обоснования, основанные на нейровизуализации.",

  "emoji": "🧠",

  "title": "Прозрачная нейродиагностика: ИИ с обоснованием"
}
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A framework using modular pipelines and reinforcement learning enhances the diagnostic clarity of deep learning models for neurodegenerative dementias by generating causally grounded explanations.  					AI-generated summary 				 The differential diagnosis of neurodegenerative dementias is a challenging clinical task, mainly because of the overlap in symptom presentation and the similarity of patterns observed in structural neuroimaging. To improve diagnostic efficiency and accuracy, deep learning-based methods such as Convolutional Neural Networks and Vision Transformers have been proposed for the automatic classification of brain MRIs. However, despite their strong predictive performance, these models find limited clinical utility due to their opaque decision making. In this work, we propose a framework that integrates two core components to enhance diagnostic transparency. First, we introduce a modular pipeline for converting 3D T1-weighted brain MRIs into textual radiology reports. Second, we explore the potential of modern Large Language Models (LLMs) to assist clinicians in the differential diagnosis between Frontotemporal dementia subtypes, Alzheimer's disease, and normal aging based on the generated reports. To bridge the gap between predictive accuracy and explainability, we employ reinforcement learning to incentivize diagnostic reasoning in LLMs. Without requiring supervised reasoning traces or distillation from larger models, our approach enables the emergence of structured diagnostic rationales grounded in neuroimaging findings. Unlike post-hoc explainability methods that retrospectively justify model decisions, our framework generates diagnostic rationales as part of the inference process-producing causally grounded explanations that inform and guide the model's decision-making process. In doing so, our framework matches the diagnostic performance of existing deep learning methods while offering rationales that support its diagnostic conclusions."

[28.05.2025 13:28] Response: ```python
["RL", "CV", "3D", "MULTIMODAL", "HEALTHCARE"]
```
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A framework using modular pipelines and reinforcement learning enhances the diagnostic clarity of deep learning models for neurodegenerative dementias by generating causally grounded explanations.  					AI-generated summary 				 The differential diagnosis of neurodegenerative dementias is a challenging clinical task, mainly because of the overlap in symptom presentation and the similarity of patterns observed in structural neuroimaging. To improve diagnostic efficiency and accuracy, deep learning-based methods such as Convolutional Neural Networks and Vision Transformers have been proposed for the automatic classification of brain MRIs. However, despite their strong predictive performance, these models find limited clinical utility due to their opaque decision making. In this work, we propose a framework that integrates two core components to enhance diagnostic transparency. First, we introduce a modular pipeline for converting 3D T1-weighted brain MRIs into textual radiology reports. Second, we explore the potential of modern Large Language Models (LLMs) to assist clinicians in the differential diagnosis between Frontotemporal dementia subtypes, Alzheimer's disease, and normal aging based on the generated reports. To bridge the gap between predictive accuracy and explainability, we employ reinforcement learning to incentivize diagnostic reasoning in LLMs. Without requiring supervised reasoning traces or distillation from larger models, our approach enables the emergence of structured diagnostic rationales grounded in neuroimaging findings. Unlike post-hoc explainability methods that retrospectively justify model decisions, our framework generates diagnostic rationales as part of the inference process-producing causally grounded explanations that inform and guide the model's decision-making process. In doing so, our framework matches the diagnostic performance of existing deep learning methods while offering rationales that support its diagnostic conclusions."

[28.05.2025 13:28] Response: ```python
['INTERPRETABILITY', 'REASONING']
```
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new framework that improves the clarity of deep learning models used for diagnosing neurodegenerative dementias. It combines modular pipelines that convert brain MRIs into textual reports with reinforcement learning to enhance the reasoning capabilities of Large Language Models (LLMs). By generating explanations that are causally linked to neuroimaging data, the framework provides insights into the model\'s decision-making process. This approach not only maintains high diagnostic accuracy but also offers transparent rationales that assist clinicians in differentiating between various dementia types.","title":"Enhancing Diagnostic Clarity with Causally Grounded Explanations"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper presents a new framework that improves the clarity of deep learning models used for diagnosing neurodegenerative dementias. It combines modular pipelines that convert brain MRIs into textual reports with reinforcement learning to enhance the reasoning capabilities of Large Language Models (LLMs). By generating explanations that are causally linked to neuroimaging data, the framework provides insights into the model's decision-making process. This approach not only maintains high diagnostic accuracy but also offers transparent rationales that assist clinicians in differentiating between various dementia types.", title='Enhancing Diagnostic Clarity with Causally Grounded Explanations'))
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究提出了一种框架，结合模块化管道和强化学习，旨在提高深度学习模型在神经退行性痴呆诊断中的透明度。我们首先将3D T1加权脑MRI转换为文本放射学报告，然后利用大型语言模型帮助临床医生进行前额叶痴呆亚型、阿尔茨海默病和正常衰老的鉴别诊断。通过强化学习，我们鼓励语言模型进行诊断推理，从而生成基于神经影像学发现的结构化诊断理由。与传统的后验可解释性方法不同，我们的框架在推理过程中生成因果解释，既保持了深度学习模型的预测性能，又提供了支持诊断结论的合理性。","title":"提升神经退行性痴呆诊断透明度的智能框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究提出了一种框架，结合模块化管道和强化学习，旨在提高深度学习模型在神经退行性痴呆诊断中的透明度。我们首先将3D T1加权脑MRI转换为文本放射学报告，然后利用大型语言模型帮助临床医生进行前额叶痴呆亚型、阿尔茨海默病和正常衰老的鉴别诊断。通过强化学习，我们鼓励语言模型进行诊断推理，从而生成基于神经影像学发现的结构化诊断理由。与传统的后验可解释性方法不同，我们的框架在推理过程中生成因果解释，既保持了深度学习模型的预测性能，又提供了支持诊断结论的合理性。', title='提升神经退行性痴呆诊断透明度的智能框架'))
[28.05.2025 13:28] Querying the API.
[28.05.2025 13:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

CLUE generates natural language explanations for a language model's uncertainty by identifying and explaining conflicts and agreements in text spans, enhancing the clarity and helpfulness of explanations in tasks like fact-checking.  					AI-generated summary 				 Understanding sources of a model's uncertainty regarding its predictions is crucial for effective human-AI collaboration. Prior work proposes using numerical uncertainty or hedges ("I'm not sure, but ..."), which do not explain uncertainty that arises from conflicting evidence, leaving users unable to resolve disagreements or rely on the output. We introduce CLUE (Conflict-and-Agreement-aware Language-model Uncertainty Explanations), the first framework to generate natural language explanations of model uncertainty by (i) identifying relationships between spans of text that expose claim-evidence or inter-evidence conflicts and agreements that drive the model's predictive uncertainty in an unsupervised way, and (ii) generating explanations via prompting and attention steering that verbalize these critical interactions. Across three language models and two fact-checking datasets, we show that CLUE produces explanations that are more faithful to the model's uncertainty and more consistent with fact-checking decisions than prompting for uncertainty explanations without span-interaction guidance. Human evaluators judge our explanations to be more helpful, more informative, less redundant, and more logically consistent with the input than this baseline. CLUE requires no fine-tuning or architectural changes, making it plug-and-play for any white-box language model. By explicitly linking uncertainty to evidence conflicts, it offers practical support for fact-checking and generalises readily to other tasks that require reasoning over complex information.
[28.05.2025 13:28] Response: {
  "desc": "CLUE - это новый метод генерации объяснений неопределенности языковых моделей на естественном языке. Он выявляет конфликты и согласования между фрагментами текста, влияющие на неуверенность модели в предсказаниях. CLUE формирует объяснения с помощью промптов и управления вниманием, вербализуя критические взаимодействия между частями текста. Эксперименты показали, что объяснения CLUE более информативны и логически согласованы с входными данными по сравнению с базовыми методами.",
  "emoji": "🔍",
  "title": "CLUE: Прозрачные объяснения неопределенности языковых моделей"
}
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CLUE generates natural language explanations for a language model's uncertainty by identifying and explaining conflicts and agreements in text spans, enhancing the clarity and helpfulness of explanations in tasks like fact-checking.  					AI-generated summary 				 Understanding sources of a model's uncertainty regarding its predictions is crucial for effective human-AI collaboration. Prior work proposes using numerical uncertainty or hedges ("I'm not sure, but ..."), which do not explain uncertainty that arises from conflicting evidence, leaving users unable to resolve disagreements or rely on the output. We introduce CLUE (Conflict-and-Agreement-aware Language-model Uncertainty Explanations), the first framework to generate natural language explanations of model uncertainty by (i) identifying relationships between spans of text that expose claim-evidence or inter-evidence conflicts and agreements that drive the model's predictive uncertainty in an unsupervised way, and (ii) generating explanations via prompting and attention steering that verbalize these critical interactions. Across three language models and two fact-checking datasets, we show that CLUE produces explanations that are more faithful to the model's uncertainty and more consistent with fact-checking decisions than prompting for uncertainty explanations without span-interaction guidance. Human evaluators judge our explanations to be more helpful, more informative, less redundant, and more logically consistent with the input than this baseline. CLUE requires no fine-tuning or architectural changes, making it plug-and-play for any white-box language model. By explicitly linking uncertainty to evidence conflicts, it offers practical support for fact-checking and generalises readily to other tasks that require reasoning over complex information."

[28.05.2025 13:28] Response: ```python
['MULTIMODAL', 'DATA', 'TRAINING']
```
[28.05.2025 13:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CLUE generates natural language explanations for a language model's uncertainty by identifying and explaining conflicts and agreements in text spans, enhancing the clarity and helpfulness of explanations in tasks like fact-checking.  					AI-generated summary 				 Understanding sources of a model's uncertainty regarding its predictions is crucial for effective human-AI collaboration. Prior work proposes using numerical uncertainty or hedges ("I'm not sure, but ..."), which do not explain uncertainty that arises from conflicting evidence, leaving users unable to resolve disagreements or rely on the output. We introduce CLUE (Conflict-and-Agreement-aware Language-model Uncertainty Explanations), the first framework to generate natural language explanations of model uncertainty by (i) identifying relationships between spans of text that expose claim-evidence or inter-evidence conflicts and agreements that drive the model's predictive uncertainty in an unsupervised way, and (ii) generating explanations via prompting and attention steering that verbalize these critical interactions. Across three language models and two fact-checking datasets, we show that CLUE produces explanations that are more faithful to the model's uncertainty and more consistent with fact-checking decisions than prompting for uncertainty explanations without span-interaction guidance. Human evaluators judge our explanations to be more helpful, more informative, less redundant, and more logically consistent with the input than this baseline. CLUE requires no fine-tuning or architectural changes, making it plug-and-play for any white-box language model. By explicitly linking uncertainty to evidence conflicts, it offers practical support for fact-checking and generalises readily to other tasks that require reasoning over complex information."

[28.05.2025 13:28] Response: ```python
['INTERPRETABILITY', 'REASONING']
```
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CLUE is a framework that generates natural language explanations for a language model\'s uncertainty by analyzing conflicts and agreements in text spans. It identifies how different pieces of evidence relate to each other, revealing the reasons behind the model\'s uncertainty in its predictions. This approach enhances the clarity of explanations, making them more useful for tasks like fact-checking. CLUE operates without needing any modifications to the model, allowing it to be easily integrated into existing systems.","title":"CLUE: Clear Explanations for Model Uncertainty"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="CLUE is a framework that generates natural language explanations for a language model's uncertainty by analyzing conflicts and agreements in text spans. It identifies how different pieces of evidence relate to each other, revealing the reasons behind the model's uncertainty in its predictions. This approach enhances the clarity of explanations, making them more useful for tasks like fact-checking. CLUE operates without needing any modifications to the model, allowing it to be easily integrated into existing systems.", title='CLUE: Clear Explanations for Model Uncertainty'))
[28.05.2025 13:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CLUE是一个生成自然语言解释的框架，旨在揭示语言模型的不确定性。它通过识别文本片段之间的冲突和一致性，帮助用户理解模型的预测不确定性。与以往的数值不确定性方法不同，CLUE能够提供更清晰的解释，特别是在事实核查等任务中。该框架无需微调或架构更改，适用于任何白盒语言模型，能够有效支持复杂信息的推理。","title":"CLUE：揭示语言模型不确定性的智能解释工具"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CLUE是一个生成自然语言解释的框架，旨在揭示语言模型的不确定性。它通过识别文本片段之间的冲突和一致性，帮助用户理解模型的预测不确定性。与以往的数值不确定性方法不同，CLUE能够提供更清晰的解释，特别是在事实核查等任务中。该框架无需微调或架构更改，适用于任何白盒语言模型，能够有效支持复杂信息的推理。', title='CLUE：揭示语言模型不确定性的智能解释工具'))
[28.05.2025 13:28] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#architecture", "#security", "#math", "#reasoning"], "emoji": "🌴", "ru": {"title": "Тропическое внимание: острое масштабно-инвариантное рассуждение для нейроалгоритмических задач", "desc": "В статье представлен новый метод внимания под названием 'Тропи
[28.05.2025 13:28] Using data from previous issue: {"categories": ["#interpretability", "#rag", "#benchmark", "#hallucinations"], "emoji": "🔍", "ru": {"title": "Позиционное смещение в RAG: не так страшно, как кажется", "desc": "Данная статья исследует влияние позиционного смещения на точность языковых моделей в контексте Retrieval Augmented Generati
[28.05.2025 13:28] Loading Chinese text from previous data.
[28.05.2025 13:28] Renaming data file.
[28.05.2025 13:28] Renaming previous data. hf_papers.json to ./d/2025-05-28.json
[28.05.2025 13:28] Saving new data file.
[28.05.2025 13:28] Generating page.
[28.05.2025 13:28] Renaming previous page.
[28.05.2025 13:28] Renaming previous data. index.html to ./d/2025-05-28.html
[28.05.2025 13:28] [Experimental] Generating Chinese page for reading.
[28.05.2025 13:28] Chinese vocab [{'word': 'OmniConsistency', 'pinyin': '', 'trans': 'OmniConsistency'}, {'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '变压器', 'pinyin': 'biàn yā qì', 'trans': 'transformer'}, {'word': '增强', 'pinyin': 'zēng qiáng', 'trans': 'enhance'}, {'word': '风格', 'pinyin': 'fēng gé', 'trans': 'style'}, {'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'}, {'word': '泛化', 'pinyin': 'fàn huà', 'trans': 'generalization'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'}, {'word': '退化', 'pinyin': 'tuì huà', 'trans': 'degeneration'}, {'word': '上下文', 'pinyin': 'shàng xià wén', 'trans': 'context'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '两阶段', 'pinyin': 'liǎng jiē duàn', 'trans': 'two-stage'}, {'word': '渐进', 'pinyin': 'jiàn jìn', 'trans': 'progressive'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '插播', 'pinyin': 'chā bō', 'trans': 'interpolation'}, {'word': '设计', 'pinyin': 'shè jì', 'trans': 'design'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '接近', 'pinyin': 'jiē jìn', 'trans': 'approach'}, {'word': '商业', 'pinyin': 'shāng yè', 'trans': 'commercial'}, {'word': '顶尖', 'pinyin': 'dǐng jiān', 'trans': 'top-notch'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': 'GPT-4o', 'pinyin': '', 'trans': 'GPT-4o'}]
[28.05.2025 13:28] Renaming previous Chinese page.
[28.05.2025 13:28] Renaming previous data. zh.html to ./d/2025-05-27_zh_reading_task.html
[28.05.2025 13:28] Writing Chinese reading task.
[28.05.2025 13:28] Writing result.
[28.05.2025 13:28] Renaming log file.
[28.05.2025 13:28] Renaming previous data. log.txt to ./logs/2025-05-28_last_log.txt
