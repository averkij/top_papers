[27.05.2025 23:10] Read previous papers.
[27.05.2025 23:10] Generating top page (month).
[27.05.2025 23:10] Writing top page (month).
[28.05.2025 00:55] Read previous papers.
[28.05.2025 00:55] Get feed.
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17894
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19147
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19297
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19457
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19250
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16348
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20258
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19914
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19815
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18545
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20259
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19209
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18675
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19439
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18601
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19590
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18536
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19752
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20139
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19949
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20256
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13136
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19788
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18759
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20152
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18822
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20046
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19640
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19602
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13426
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19386
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16972
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19955
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19443
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19427
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19103
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20278
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19223
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.10887
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19731
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18773
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18384
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17652
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20254
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15804
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20294
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19630
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19084
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19056
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18926
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18323
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18116
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16984
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16886
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16312
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19706
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18283
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15957
[28.05.2025 00:55] Extract page data from URL. URL: https://huggingface.co/papers/2505.20297
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20290
[28.05.2025 00:55] Extract page data from URL. URL: https://huggingface.co/papers/2505.20236
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19800
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19440
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19415
[28.05.2025 00:55] Extract page data from URL. URL: https://huggingface.co/papers/2505.18497
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18454
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18291
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12737
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20225
[28.05.2025 00:55] Extract page data from URL. URL: https://huggingface.co/papers/2505.16968
[28.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14071
[28.05.2025 00:55] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.05.2025 00:55] No deleted papers detected.
[28.05.2025 00:55] Downloading and parsing papers (pdf, html). Total: 71.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.17894.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.17894.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.17894.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19147.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19147.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19147.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19297.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19297.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19297.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19457.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19457.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19457.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19250.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19250.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19250.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.16348.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.16348.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.16348.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20258.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20258.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20258.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19914.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19914.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19914.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19815.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19815.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19815.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18545.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18545.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18545.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20259.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20259.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20259.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19209.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19209.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19209.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18675.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18675.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18675.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19439.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19439.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19439.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18601.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18601.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18601.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19590.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19590.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19590.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18536.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18536.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18536.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19752.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19752.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19752.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20139.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20139.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20139.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19949.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19949.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19949.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20256.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20256.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20256.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13136.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13136.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13136.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19788.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19788.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19788.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18759.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18759.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18759.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20152.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20152.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20152.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18822.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18822.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18822.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20046.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20046.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20046.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19640.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19640.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19640.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19602.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19602.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19602.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13426.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13426.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13426.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19386.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19386.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19386.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.16972.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.16972.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.16972.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19955.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19955.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19955.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19443.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19443.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19443.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19427.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19427.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19427.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19103.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19103.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19103.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20278.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20278.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20278.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19223.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19223.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19223.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.10887.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.10887.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.10887.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19731.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19731.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19731.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18773.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18773.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18773.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18384.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18384.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18384.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.17652.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.17652.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.17652.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20254.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20254.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20254.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.15804.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.15804.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.15804.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20294.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20294.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20294.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19630.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19630.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19630.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19084.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19084.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19084.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19056.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19056.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19056.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18926.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18926.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18926.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18323.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18323.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18323.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18116.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18116.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18116.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.16984.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.16984.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.16984.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.16886.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.16886.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.16886.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.16312.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.16312.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.16312.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19706.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19706.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19706.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18283.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18283.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18283.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.15957.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.15957.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.15957.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20297.
[28.05.2025 00:55] Downloading paper 2505.20297 from http://arxiv.org/pdf/2505.20297v1...
[28.05.2025 00:55] Extracting affiliations from text.
[28.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 7 9 2 0 2 . 5 0 5 2 : r DiSA: Diffusion Step Annealing in Autoregressive Image Generation Qinyu Zhao1, Jaskirat Singh1, Ming Xu1, Akshay Asthana2, Stephen Gould1, Liang Zheng1 1 Australian National University 2 Seeing Machines Ltd {qinyu.zhao,jaskirat.singh,mingda.xu,stephen.gould,liang.zheng}@anu.edu.au {akshay.asthana}@seeingmachines.com "
[28.05.2025 00:55] Response: ```python
["Australian National University", "Seeing Machines Ltd"]
```
[28.05.2025 00:55] Deleting PDF ./assets/pdf/2505.20297.pdf.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20290.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20290.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20290.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20236.
[28.05.2025 00:55] Downloading paper 2505.20236 from http://arxiv.org/pdf/2505.20236v1...
[28.05.2025 00:55] Extracting affiliations from text.
[28.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 6 3 2 0 2 . 5 0 5 2 : r Seeing is Believing, but How Much? Comprehensive Analysis of Verbalized Calibration in Vision-Language Models Weihao Xuan1,2, Qingcheng Zeng3*, Heli Qi4, Junjue Wang1, Naoto Yokoya1,2 1The University of Tokyo, 2RIKEN AIP, 3Northwestern University, 4Waseda University "
[28.05.2025 00:55] Response: ```python
["The University of Tokyo", "RIKEN AIP", "Northwestern University", "Waseda University"]
```
[28.05.2025 00:55] Deleting PDF ./assets/pdf/2505.20236.pdf.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19800.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19800.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19800.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19440.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19440.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19440.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.19415.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.19415.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.19415.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18497.
[28.05.2025 00:55] Downloading paper 2505.18497 from http://arxiv.org/pdf/2505.18497v1...
[28.05.2025 00:55] Extracting affiliations from text.
[28.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic Competence in Large Language Models Kefan Yu*, Qingcheng Zeng*, Weihao Xuan, Wanxin Li, Jingyi Wu, Rob Voigt Northwestern University The University of Tokyo Zhejiang University qcz@u.northwestern.edu 5 2 0 2 4 2 ] . [ 1 7 9 4 8 1 . 5 0 5 2 : r a "
[28.05.2025 00:55] Response: ```python
["Northwestern University", "The University of Tokyo", "Zhejiang University"]
```
[28.05.2025 00:55] Deleting PDF ./assets/pdf/2505.18497.pdf.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18454.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18454.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18454.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.18291.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.18291.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.18291.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12737.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12737.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12737.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.20225.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.20225.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.20225.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.16968.
[28.05.2025 00:55] Downloading paper 2505.16968 from http://arxiv.org/pdf/2505.16968v2...
[28.05.2025 00:55] Extracting affiliations from text.
[28.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 2 ] . [ 2 8 6 9 6 1 . 5 0 5 2 : r CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark Ahmed Heakl1 Sarim Hashmi1 Gustavo Bertolo Stahl1 Seung Hun Eddie Han1 Salman Khan1,2 Abdulrahman Mahmoud1 1MBZUAI 2Australian National University https://github.com/GustavoStahl/CASS (cid:18) https://huggingface.co/datasets/MBZUAI/cass "
[28.05.2025 00:55] Response: ```python
["MBZUAI", "Australian National University"]
```
[28.05.2025 00:55] Deleting PDF ./assets/pdf/2505.16968.pdf.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.14071.
[28.05.2025 00:55] Extra JSON file exists (./assets/json/2505.14071.json), skip PDF parsing.
[28.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.14071.json), skip HTML parsing.
[28.05.2025 00:55] Success.
[28.05.2025 00:55] Enriching papers with extra data.
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 0. Mutarjim is a compact Arabic-English translation model that outperforms larger models on established benchmarks and achieves state-of-the-art performance on a new comprehensive Tarjama-25 benchmark.  					AI-generated summary 				 We introduce Mutarjim, a compact yet powerful language model for bidi...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 1. The rapid advancement of large language models (LLMs) and multi-modal LLMs (MLLMs) has historically relied on model-centric scaling through increasing parameter counts from millions to hundreds of billions to drive performance gains. However, as we approach hardware limits on model size, the dominan...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 2. A new method using a pre-trained generative model helps construct a high-impact SFT dataset, Alchemist, which improves the generative quality of text-to-image models while maintaining diversity.  					AI-generated summary 				 Pre-training equips text-to-image (T2I) models with broad world knowledge...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 3. BizFinBench is a benchmark for evaluating large language models in financial applications, revealing distinct performance patterns across various tasks.  					AI-generated summary 				 Large language models excel in general tasks, yet assessing their reliability in logic-heavy, precision-critical do...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 4. PATS enhances LLM efficiency by dynamically adjusting reasoning strategies based on task difficulty, leveraging PRMs and Beam Search.  					AI-generated summary 				 Current large-language models (LLMs) typically adopt a fixed reasoning strategy, either simple or complex, for all questions, regardle...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 5. MEMENTO evaluates personalized memory utilization in embodied agents, revealing limitations in understanding user semantics and routines.  					AI-generated summary 				 Embodied agents empowered by large language models (LLMs) have shown strong performance in household object rearrangement tasks. H...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 6. Adaptive Reasoning Model (ARM) uses Ada-GRPO to reduce token usage and improve efficiency across different reasoning modes.  					AI-generated summary 				 While large reasoning models demonstrate strong performance on complex tasks, they lack the ability to adjust reasoning token usage based on tas...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 7. Enigmata is a comprehensive suite for improving LLMs in puzzle reasoning through scalable multi-task RL training, leading to better performance on benchmarks and advanced math tasks.  					AI-generated summary 				 Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at advance...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 8. LLM reasoning is understood through a meta-learning framework, treating reasoning as pseudo-gradient descent and questions as individual tasks, which enhances generalization and provides practical insights for improvement.  					AI-generated summary 				 We propose a novel framework for comprehendin...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 9. Large language models (LLMs) often exhibit strong biases, e.g, against women or in favor of the number 7. We investigate whether LLMs would be able to output less biased answers when allowed to observe their prior answers to the same question in a multi-turn conversation. To understand which types o...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 10. A lifecycle safety alignment framework employs a Meta-Attacker and Defender to adapt LLMs to novel jailbreaking strategies, improving robustness in deployment.  					AI-generated summary 				 LLMs have made impressive progress, but their growing capabilities also expose them to highly flexible jailb...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 11. A method is proposed to generate detailed scientific hypotheses using LLMs by defining and optimizing a latent reward landscape, outperforming baselines in benchmark evaluations.  					AI-generated summary 				 Large language models (LLMs) have shown promise in automating scientific hypothesis gener...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 12. Multimodal large language models (MLLMs) have recently achieved significant progress in visual tasks, including semantic scene understanding and text-image alignment, with reasoning variants enhancing performance on complex tasks involving mathematics and logic. However, their capacity for reasoning...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 13. Large Language Models have achieved remarkable success in natural language processing tasks, with Reinforcement Learning playing a key role in adapting them to specific applications. However, obtaining ground truth answers for training LLMs in mathematical problem-solving is often challenging, costl...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 14. Flex-Judge uses minimal textual reasoning data to generalize across multiple modalities and evaluation formats, outperforming state-of-the-art models in multimodal evaluations.  					AI-generated summary 				 Human-generated reward signals are critical for aligning generative models with human prefe...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 15. Intuitor, a Reinforcement Learning from Internal Feedback method, uses self-certainty as a reward signal to enable unsupervised learning of large language models, achieving performance comparable to GRPO on benchmarks and superior generalization.  					AI-generated summary 				 Training large langua...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 16. Standing in 2025, at a critical juncture in the pursuit of Artificial General Intelligence (AGI), reinforcement fine-tuning (RFT) has demonstrated significant potential in enhancing the reasoning capability of large language models (LLMs) and has led to the development of cutting-edge AI models such...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 17. A novel framework, Discrete Markov Bridge, is introduced for discrete data modeling with Matrix Learning and Score Learning components, demonstrating superior performance compared to existing methods on Text8 and CIFAR-10 datasets.  					AI-generated summary 				 Discrete diffusion has recently emer...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 18. StructEval benchmarks Large Language Models for generating and converting structured outputs, highlighting performance gaps and challenges in producing visual content.  					AI-generated summary 				 As Large Language Models (LLMs) become integral to software development workflows, their ability to ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 19. Influence functions are used to attribute LLMs' reasoning in math and coding to individual training elements, revealing cross-domain effects and enabling a reweighting strategy that improves model accuracy.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable rea...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 20. An end-to-end reinforcement learning framework, Omni-R1, achieves superior performance in long-horizon video-audio reasoning and fine-grained pixel understanding tasks by combining global reasoning and detail understanding systems.  					AI-generated summary 				 Long-horizon video-audio reasoning a...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 21. ModernGBERT and LL\"aMmlein2Vec, new German encoder models, outperform existing models in terms of performance and parameter-efficiency across various NLP tasks.  					AI-generated summary 				 Despite the prominence of decoder-only language models, encoders remain crucial for resource-constrained a...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 22. Multi-Turn Decomposition improves efficiency in large reasoning models by breaking down chain-of-thought into manageable turns, reducing token usage and latency while maintaining performance.  					AI-generated summary 				 Large Reasoning Models (LRMs) are criticized for the excessively lengthy Cha...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 23. Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the ef...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 24. A novel hard negative contrastive learning framework improves geometric reasoning in Large Multimodal Models, significantly enhancing their performance compared to existing models.  					AI-generated summary 				 Benefiting from contrastively trained visual encoders on large-scale natural scene imag...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 25. AdaCtrl, a novel framework, dynamically adjusts reasoning length based on problem difficulty and user control, improving performance and reducing response length across various datasets compared to standard training methods.  					AI-generated summary 				 Modern large reasoning models demonstrate i...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 26. REARANK, a reinforcement learning-enhanced large language model for listwise reasoning,outperforms baseline models and even surpasses GPT-4 on reasoning-intensive benchmarks with minimal data.  					AI-generated summary 				 We present REARANK, a large language model (LLM)-based listwise reasoning r...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 27. A reinforcement learning-guided training paradigm enhances large language models' reasoning efficiency and performance for multi-hop questions by interleaving thinking and answering.  					AI-generated summary 				 Long chain-of-thought (CoT) significantly enhances large language models' (LLM) reaso...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 28. ScaleKV compresses the KV cache in Visual Autoregressive models by differentiating drafters and refiners across transformer layers, reducing memory consumption while maintaining high fidelity.  					AI-generated summary 				 Visual Autoregressive (VAR) modeling has garnered significant attention for...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 29. VLM-Gym addresses the "knowing-doing" gap in Vision-Language Models by training them in a diverse RL environment, leading to enhanced perception and reasoning abilities that surpass existing models in interactive games.  					AI-generated summary 				 Vision-Language Models (VLMs) excel in many dire...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 30. Force prompts enable video generation models to simulate realistic physical interactions using pretrained models and force conditioning from Blender-generated videos.  					AI-generated summary 				 Recent advances in video generation models have sparked interest in world models capable of simulatin...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 31. Recent advances in Automatic Speech Recognition (ASR) have been largely fueled by massive speech corpora. However, extending coverage to diverse languages with limited resources remains a formidable challenge. This paper introduces Speech Back-Translation, a scalable pipeline that improves multiling...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 32. MLR-Bench evaluates AI agents in scientific research through modular stages, revealing that while LLMs perform well in ideation and writing, coding agents often produce unreliable experimental results.  					AI-generated summary 				 Recent advancements in AI agents have demonstrated their growing p...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 33. A review contrasts vibe coding and agentic coding paradigms, highlighting their differences in interaction, autonomy, and application areas in AI-assisted software development.  					AI-generated summary 				 This review presents a comprehensive analysis of two emerging paradigms in AI-assisted soft...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 34. WINA, a training-free sparse activation framework for large language models, improves inference accuracy by considering hidden state magnitudes and weight matrix norms, outperforming existing methods.  					AI-generated summary 				 The growing computational demands of large language models (LLMs) m...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 35. WHISTRESS is an alignment-free method for sentence stress detection trained on synthetic data, outperforming existing methods and generalizing well to diverse benchmarks.  					AI-generated summary 				 Spoken language conveys meaning not only through words but also through intonation, emotion, and ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 36. Large language models excel at pattern matching, yet often fall short in systematic compositional generalization. We propose the coverage principle: a data-centric framework showing that models relying primarily on pattern matching for compositional tasks cannot reliably generalize beyond substituti...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 37. VRPO is a variance-reduced preference optimization framework for Masked Diffusion Models that significantly enhances their alignment with human preferences and performance across various benchmarks.  					AI-generated summary 				 While Masked Diffusion Models (MDMs), such as LLaDA, present a promis...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 38. InfantAgent-Next is a multimodal agent that integrates tool-based and vision models in a modular architecture to solve various benchmarks, including OSWorld, GAIA, and SWE-Bench.  					AI-generated summary 				 This paper introduces InfantAgent-Next, a generalist agent capable of interacting with co...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 39. Nash Mirror Prox is an online algorithm for Nash Learning from Human Feedback that achieves linear convergence to the Nash equilibrium and is applicable for fine-tuning language models.  					AI-generated summary 				 Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on rewa...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 40. State-of-the-art membership inference attacks (MIAs) typically require training many reference models, making it difficult to scale these attacks to large pre-trained language models (LLMs). As a result, prior research has either relied on weaker attacks that avoid training reference models (e.g., f...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 41. Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.  					AI-generated summary 				 Foundation models are increasingly becoming better autonomous programmers, ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 42. CDAS addresses low sample efficiency in reinforcement learning by aligning model competence with problem difficulty, improving both accuracy and efficiency in mathematical benchmarks.  					AI-generated summary 				 Reinforcement learning exhibits potential in enhancing the reasoning abilities of la...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 43. Prioritizing feature consistency in sparse autoencoders improves mechanistic interpretability of neural networks by ensuring reliable and interpretable features.  					AI-generated summary 				 Sparse Autoencoders (SAEs) are a prominent tool in mechanistic interpretability (MI) for decomposing neura...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 44. STAR-R1, a novel RL framework with a fine-grained reward mechanism, enhances spatial reasoning in multimodal large language models by addressing limitations in traditional SFT and sparse-reward RL.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have demonstrated remarkable ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 45. A new benchmark and policy, GLEAM-Bench and GLEAM, improve the scalability and reliability of active mapping in complex environments through semantic representations and efficient exploration strategies.  					AI-generated summary 				 Generalizable active mapping in complex unknown environments rem...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 46. Large language models (LLMs) have demonstrated excellent capabilities in the field of biomedical question answering, but their application in real-world clinical consultations still faces core challenges. Existing systems rely on a one-way information transmission mode where patients must fully desc...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 47. Jodi, a diffusion framework using a linear diffusion transformer and role switch mechanism, unifies visual generation and understanding, performing joint, controllable, and perceptual tasks effectively across multiple visual domains.  					AI-generated summary 				 Visual generation and understandin...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 48. Modifying models to generate justified refusals through fine-tuning on an extended-refusal dataset mitigates ablation attacks while maintaining high refusal rates and general performance.  					AI-generated summary 				 Large language models (LLMs) are typically aligned to comply with safety guideli...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 49. A hybrid neural physics system with diffusion-based control achieves real-time, interactive fluid simulations with low latency and high fidelity.  					AI-generated summary 				 We propose a neural physics system for real-time, interactive fluid simulations. Traditional physics-based methods, while ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 50. For nearly a decade the academic community has investigated backdoors in neural networks, primarily focusing on classification tasks where adversaries manipulate the model prediction. While demonstrably malicious, the immediate real-world impact of such prediction-altering attacks has remained uncle...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 51. Negative-aware Fine-Tuning (NFT) enhances LLMs' math abilities using supervised learning with negative feedback, achieving performance comparable to RL methods.  					AI-generated summary 				 Reinforcement Learning (RL) has played a central role in the recent surge of LLMs' math abilities by enabli...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 52. A new post-training method, Unified Fine-Tuning (UFT), improves upon supervised and reinforcement fine-tuning for large language models by combining their benefits, achieving better generalization and faster convergence.  					AI-generated summary 				 Post-training has demonstrated its importance i...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 53. With the growing success of reasoning models across complex natural language tasks, researchers in the Information Retrieval (IR) community have begun exploring how similar reasoning capabilities can be integrated into passage rerankers built on Large Language Models (LLMs). These methods typically ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 54. EquivPruner reduces token consumption and improves reasoning accuracy by pruning semantically equivalent actions in LLM searches, leveraging a new dataset for mathematical equivalence.  					AI-generated summary 				 Large Language Models (LLMs) excel at complex reasoning through search algorithms, ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 55. PathFinder-PRM, a hierarchical and error-aware Process Reward Model, improves mathematical problem-solving by fine-grained error classification and step correctness estimation, achieving state-of-the-art PRMScore with reduced data usage.  					AI-generated summary 				 Large Language Models (LLMs) a...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 56. TAGS, a test-time framework combining generalist and specialist models with hierarchical retrieval and reliability scoring, enhances medical LLM reasoning without fine-tuning.  					AI-generated summary 				 Recent advances such as Chain-of-Thought prompting have significantly improved large languag...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 57. A survey proposes a systematic taxonomy for evaluating large audio-language models across dimensions including auditory awareness, knowledge reasoning, dialogue ability, and fairness, to address fragmented benchmarks in the field.  					AI-generated summary 				 With advancements in large audio-lang...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 58. Diffusion step annealing enhances inference efficiency in autoregressive models by reducing the number of diffusion steps as more tokens are generated, preserving quality.  					AI-generated summary 				 An increasing number of autoregressive models, such as MAR, FlowAR, xAR, and Harmon adopt diffus...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 59. EgoZero learns robust manipulation policies for robots using in-the-wild human demonstrations and zero robot data, enabling zero-shot transfer across diverse tasks.  					AI-generated summary 				 Despite recent progress in general purpose robotics, robot policies still lag far behind basic human ca...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 60. Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 61. A framework leveraging Large Language Models (LLMs) is introduced for automatic metadata extraction from scientific papers, with a focus on datasets from languages other than Arabic.  					AI-generated summary 				 Metadata extraction is essential for cataloging and preserving datasets, enabling eff...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 62. This paper studies the emergence of interpretable categorical features within large language models (LLMs), analyzing their behavior across training checkpoints (time), transformer layers (space), and varying model sizes (scale). Using sparse autoencoders for mechanistic interpretability, we identif...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 63. A comprehensive benchmark, MMIG-Bench, evaluates multi-modal image generators using text prompts and reference images, providing detailed insights through low-level, mid-level, and high-level metrics.  					AI-generated summary 				 Recent multimodal image generators such as GPT-4o, Gemini 2.0 Flash...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 64. Current large language models (LLMs) have demonstrated emerging capabilities in social intelligence tasks, including implicature resolution (Sravanthi et al. (2024)) and theory-of-mind reasoning (Shapira et al. (2024)), both of which require substantial pragmatic understanding. However, how LLMs acq...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 65. Hybrid reasoning policy optimization (HRPO) leverages reinforcement learning to integrate latent reasoning with large language models, enhancing performance in knowledge- and reasoning-intensive tasks while maintaining interpretability.  					AI-generated summary 				 Recent advances in large langua...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 66. A new benchmark, InstructPart, and a task-oriented part segmentation dataset are introduced to evaluate and improve the performance of Vision-Language Models in real-world contexts.  					AI-generated summary 				 Large multimodal foundation models, particularly in the domains of language and vision...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 67. Option-aware Temporally Abstracted (OTA) value learning improves offline goal-conditioned reinforcement learning performance by refining the high-level policy through better advantage estimates in long-horizon settings.  					AI-generated summary 				 Offline goal-conditioned reinforcement learning ...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 68. FLAME-MoE is an open-source research suite for MoE architectures in LLMs, providing tools to investigate scaling, routing, and expert behavior with reproducible experiments.  					AI-generated summary 				 Recent large language models such as Gemini-1.5, DeepSeek-V3, and Llama-4 increasingly adopt M...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 69. We introduce CASS, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA leftrightarrow HIP) and assembly-level (Nvidia SASS leftrightarrow AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and d...
[28.05.2025 00:55] ********************************************************************************
[28.05.2025 00:55] Abstract 70. Steering methods have emerged as effective and targeted tools for guiding large language models' (LLMs) behavior without modifying their parameters. Multimodal large language models (MLLMs), however, do not currently enjoy the same suite of techniques, due in part to their recency and architectural ...
[28.05.2025 00:55] Read previous papers.
[28.05.2025 00:55] Generating reviews via LLM API.
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#dataset", "#benchmark", "#machine_translation", "#multilingual", "#small_models", "#open_source"], "emoji": "🌍", "ru": {"title": "Маленькая модель - большие результаты в арабско-английском переводе", "desc": "Mutarjim - это компактная модель машинного перевода для араб
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#data", "#math", "#optimization", "#long_context", "#survey"], "emoji": "🗜️", "ru": {"title": "Сжатие токенов: новый рубеж эффективности ИИ", "desc": "Статья рассматривает переход от масштабирования моделей к сжатию данных в контексте развития крупных языковых моделей (
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#open_source", "#training", "#data"], "emoji": "🧪", "ru": {"title": "Алхимия данных: новый подход к улучшению генеративных моделей", "desc": "В статье представлен новый метод создания наборов данных для дообучения генеративных моделей изображений по тексту.
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#benchmark", "#science", "#reasoning", "#dataset", "#open_source"], "emoji": "💹", "ru": {"title": "BizFinBench: Новый стандарт оценки LLM в финансах", "desc": "BizFinBench - это новый эталонный тест для оценки больших языковых моделей (LLM) в финансовых приложениях. Он состоит из 67
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#reasoning", "#math", "#inference", "#optimization"], "emoji": "🧠", "ru": {"title": "Адаптивные рассуждения LLM: эффективность через гибкость", "desc": "Статья представляет новый подход к рассуждениям в больших языковых моделях (LLM) под названием PATS. Эта методика поз
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#agents", "#interpretability", "#multimodal", "#agi", "#reasoning"], "emoji": "🤖", "ru": {"title": "Оценка памяти ИИ-ассистентов: путь к персонализации", "desc": "MEMENTO - это система оценки персонализированных воплощенных агентов, которая исследует их способность использовать памя
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#inference", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Адаптивные рассуждения для эффективного использования ресурсов ИИ", "desc": "Адаптивная модель рассуждений (ARM) использует Ada-GRPO для снижения использования токенов и повышения эффективности 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#math", "#training", "#rl", "#optimization", "#benchmark", "#dataset"], "emoji": "🧩", "ru": {"title": "Enigmata: прокачка логики языковых моделей через головоломки", "desc": "Enigmata - это комплексный набор инструментов для улучшения навыков решения головоломок у боль
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#math", "#training"], "emoji": "🧠", "ru": {"title": "Рассуждения LLM как мета-обучение: новый взгляд на искусственный интеллект", "desc": "Данная статья представляет новый подход к пониманию способностей рассуждения больших языковых моделей (LLM) через
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#data", "#ethics", "#hallucinations", "#benchmark", "#rlhf"], "emoji": "🤖", "ru": {"title": "Самокоррекция предвзятости в языковых моделях через многоэтапный диалог", "desc": "Исследование посвящено изучению предвзятости в больших языковых моделях (LLM) и возможности ее уменьшения в
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#inference", "#training", "#alignment", "#security"], "emoji": "🛡️", "ru": {"title": "Непрерывное обучение для защиты языковых моделей от новых атак", "desc": "Эта статья представляет систему непрерывного обучения для повышения безопасности языковых моделей (LLM) в условиях новых ат
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#science", "#rlhf", "#benchmark", "#multimodal", "#optimization"], "emoji": "🧪", "ru": {"title": "Искусственный интеллект на страже научного прогресса: от идеи к эксперименту", "desc": "Предложен метод генерации детальных научных гипотез с использованием больших языковых моделей (LL
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark", "#cv", "#open_source"], "emoji": "🗺️", "ru": {"title": "ReasonMap: новый взгляд на визуальное мышление языковых моделей", "desc": "ReasonMap - это новый бенчмарк для оценки способностей мультимодальных языковых моделей к пониманию визуальной
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#math", "#rl", "#optimization", "#training"], "emoji": "🧮", "ru": {"title": "Обучение ИИ математике без правильных ответов", "desc": "Исследование посвящено использованию формата и длины ответов в качестве вспомогательных сигналов для обучения больших языковых моделей 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#alignment", "#benchmark", "#multimodal", "#transfer_learning"], "emoji": "🧠", "ru": {"title": "Рассуждения на основе текста - ключ к универсальной мультимодальной оценке", "desc": "Flex-Judge - это модель оценки мультимодальных данных, использующая минимальны
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#rlhf", "#optimization"], "emoji": "🧠", "ru": {"title": "Самообучение ИИ: внутренняя уверенность как двигатель прогресса", "desc": "Статья представляет метод обучения с подкреплением на основе внутренней обратной связи под названием Intuitor. Этот м
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#multimodal", "#training", "#reasoning", "#benchmark", "#rlhf", "#agi", "#rl"], "emoji": "🧠", "ru": {"title": "RFT: ключ к усилению рассуждений в мультимодальных ИИ-моделях", "desc": "Эта статья посвящена применению метода тонкой настройки с подкреплением (RFT) для улучшения способн
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#data", "#benchmark", "#diffusion", "#dataset", "#optimization", "#architecture"], "emoji": "🌉", "ru": {"title": "Дискретный марковский мост: новый подход к моделированию дискретных данных", "desc": "Представлен новый фреймворк Discrete Markov Bridge для моделирования д
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#open_source", "#benchmark"], "emoji": "🏗️", "ru": {"title": "StructEval: Измеряем структурную точность языковых моделей", "desc": "StructEval - это новый комплексный бенчмарк для оценки способностей больших языковых моделей (LLM) генерировать структу
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#reasoning", "#data", "#dataset", "#optimization", "#interpretability"], "emoji": "🧠", "ru": {"title": "Функции влияния раскрывают секреты обучения LLM математике и программированию", "desc": "Исследователи использовали функции влияния для анализа вклада отдельных элеме
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#video", "#hallucinations", "#benchmark", "#multimodal", "#optimization"], "emoji": "🤖", "ru": {"title": "Умное разделение труда: глобальное рассуждение и детальный анализ в одной модели", "desc": "Omni-R1 - это комплексная система обучения с подкреплением для з
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#multilingual", "#benchmark", "#open_source", "#dataset", "#training", "#low_resource", "#architecture"], "emoji": "🇩🇪", "ru": {"title": "Новое слово в немецких языковых моделях: ModernGBERT и LL\"aMmlein2Vec", "desc": "Исследователи представили новые немецкие энкодерные модели Mode
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#benchmark", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное рассуждение по шагам: MinD оптимизирует работу LRM", "desc": "Статья представляет метод Multi-Turn Decomposition (MinD) для повышения эффективности больших моделей рассуждений
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#transfer_learning", "#dataset", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Оптимизация дистилляции языковых моделей через манипуляции с данными", "desc": "Эта статья представляет DC-CoT - первый дата-центричный бенчмарк для оценки мето
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#training", "#reasoning", "#dataset", "#open_source"], "emoji": "📐", "ru": {"title": "Прорыв в геометрическом мышлении ИИ через усовершенствованное контрастное обучение", "desc": "Статья представляет новый метод контрастного обучения с использованием сло
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#training", "#rl", "#dataset"], "emoji": "🧠", "ru": {"title": "Адаптивное управление глубиной рассуждений в больших языковых моделях", "desc": "AdaCtrl - это новая система, которая динамически регулирует длину рассуждений в зависимости от сложности задачи и пожеланий п
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#interpretability", "#optimization", "#reasoning", "#rlhf", "#rl"], "emoji": "🧠", "ru": {"title": "REARANK: Усиление рассуждений в ранжировании с помощью обучения с подкреплением", "desc": "REARANK - это модель для переранжирования, основанная на больших язы
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#math", "#rlhf", "#training", "#rl", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное рассуждение ИИ: мысль и ответ в одном потоке", "desc": "Статья представляет новый подход к обучению больших языковых моделей (LLM) для решения многоэтапных задач рассужден
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#inference", "#optimization", "#architecture"], "emoji": "🗜️", "ru": {"title": "ScaleKV: Эффективное сжатие кэша для визуальных ИИ-моделей", "desc": "ScaleKV - это новый метод сжатия KV-кэша для визуальных авторегрессионных моделей. Он разделяет слои трансформера на драфтеры и рефай
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#multimodal", "#training", "#reasoning", "#open_source", "#agents", "#games", "#optimization", "#rl"], "emoji": "🎮", "ru": {"title": "Преодоление разрыва между знанием и действием в Vision-Language Models с помощью RL", "desc": "Статья представляет VLM-Gym - среду обучения с подкреп
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#dataset", "#video", "#synthetic", "#games", "#data"], "emoji": "🎥", "ru": {"title": "Силовые подсказки для реалистичной физики в генеративных видеомоделях", "desc": "Статья представляет метод 'силовых подсказок' для генерации видео с реалистичным физическим взаимодействием. Авторы 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#data", "#multilingual", "#low_resource", "#dataset", "#audio", "#synthetic"], "emoji": "🗣️", "ru": {"title": "Синтетическая речь открывает новые горизонты для многоязычного ASR", "desc": "Эта статья представляет метод Speech Back-Translation для улучшения многоязычных систем автома
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#agents", "#science", "#benchmark", "#open_source"], "emoji": "🧠", "ru": {"title": "MLR-Bench: комплексная оценка ИИ в научных исследованиях", "desc": "MLR-Bench - это комплексный инструмент для оценки ИИ-агентов в области машинного обучения. Он включает 201 исследовательскую задачу
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#survey", "#agents", "#architecture", "#interpretability"], "emoji": "🤖", "ru": {"title": "Вайб vs Агент: Новые горизонты ИИ-ассистированной разработки", "desc": "Эта статья представляет сравнительный анализ двух парадигм в разработке программного обеспечения с помощью ИИ: вайб-коди
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#inference", "#training", "#open_source", "#optimization", "#architecture"], "emoji": "🚀", "ru": {"title": "WINA: Эффективная разреженная активация для ускорения языковых моделей", "desc": "WINA - это новый метод разреженной активации для больших языковых моделей, не требующий допол
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#audio", "#data", "#benchmark", "#alignment"], "emoji": "🗣️", "ru": {"title": "WHISTRESS: Точное определение ударения в предложениях без выравнивания", "desc": "WHISTRESS - это метод обнаружения ударения в предложениях, не требующий выравнивания и обученный
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#interpretability", "#training", "#reasoning", "#data", "#architecture"], "emoji": "🧠", "ru": {"title": "Принцип покрытия: новый взгляд на композиционное мышление в ИИ", "desc": "Статья исследует ограничения больших языковых моделей в области систематической композиционной генерализ
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#rl", "#benchmark", "#architecture", "#optimization", "#alignment", "#rlhf"], "emoji": "🎯", "ru": {"title": "Повышение эффективности маскированных диффузионных моделей через оптимизацию предпочтений", "desc": "VRPO - это фреймворк для оптимизации предпочтений с уменьшен
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#agi", "#open_source", "#benchmark", "#agents", "#multimodal", "#architecture"], "emoji": "🤖", "ru": {"title": "Универсальный мультимодальный агент для решения разнообразных задач", "desc": "InfantAgent-Next - это мультимодальный агент, интегрирующий инструментальные и визуальные мо
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#games", "#rlhf", "#training", "#alignment", "#optimization"], "emoji": "🤖", "ru": {"title": "Nash Mirror Prox: Эффективное обучение ИИ на основе человеческих предпочтений", "desc": "Статья представляет Nash Mirror Prox - онлайн-алгоритм для обучения с подкреплением на основе обратн
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#data", "#dataset", "#benchmark", "#security", "#leakage"], "emoji": "🕵️", "ru": {"title": "Масштабирование атак вывода членства на большие языковые модели: возможности и ограничения", "desc": "Исследователи масштабировали сильную атаку вывода членства (MIA) под названием LiRA для м
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#cybersecurity", "#agents", "#security"], "emoji": "🛡️", "ru": {"title": "Динамическая оценка угроз ИИ в кибербезопасности", "desc": "Исследование показывает, что злоумышленники могут значительно улучшить способности фундаментальных моделей в области наступательной кибербезопасности
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#math", "#optimization"], "emoji": "🎯", "ru": {"title": "Точное соответствие: CDAS повышает эффективность обучения с подкреплением", "desc": "CDAS (Competence-Difficulty Alignment Sampling) - это новый метод в области обучения с подкреплением, напра
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#interpretability", "#training", "#math", "#architecture"], "emoji": "🔍", "ru": {"title": "Стабильность признаков - ключ к надежной интерпретации нейросетей", "desc": "Статья рассматривает важность стабильности признаков в разреженных автоэнкодерах для улучшения механистической инте
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#rl", "#multimodal", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "Прорыв в пространственном мышлении ИИ с помощью умного обучения с подкреплением", "desc": "STAR-R1 - это новая система обучения с подкреплением для улучшения пространственного мышления мультимодальны
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#benchmark", "#transfer_learning", "#3d", "#robotics", "#synthetic"], "emoji": "🗺️", "ru": {"title": "Революция в активном картографировании: GLEAM открывает новые горизонты", "desc": "GLEAM-Bench и GLEAM - это новые инструменты для улучшения активного картографирования в сложных ср
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#reasoning", "#science", "#healthcare", "#dataset", "#games", "#optimization", "#rl"], "emoji": "🩺", "ru": {"title": "Умный виртуальный доктор: ИИ учится вести диалог с пациентом", "desc": "Статья представляет DoctorAgent-RL - систему на основе обучения с подкреплением 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#dataset", "#diffusion", "#cv", "#multimodal", "#open_source"], "emoji": "🎨", "ru": {"title": "Jodi: Единая модель для генерации и понимания изображений", "desc": "Jodi - это фреймворк диффузии, объединяющий генерацию и понимание визуальных данных. Он использует линейный диффузионны
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#security", "#dataset", "#alignment", "#ethics"], "emoji": "🛡️", "ru": {"title": "Укрепление этических барьеров в ИИ через обоснованные отказы", "desc": "Исследователи предложили метод защиты языковых моделей от атак, направленных на подавление механизмов отказа от вред
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#dataset", "#3d", "#agents", "#diffusion", "#open_source", "#optimization"], "emoji": "💧", "ru": {"title": "Интерактивное моделирование жидкостей в реальном времени с помощью ИИ", "desc": "Авторы предлагают гибридную нейронную систему для моделирования жидкостей в реальном времени. 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#leakage", "#inference", "#security", "#architecture"], "emoji": "🕵️", "ru": {"title": "Новые архитектурные бэкдоры: скрытая угроза пакетному выводу нейросетей", "desc": "Статья представляет новый класс бэкдоров в нейронных сетях, использующих архитектурные уязвимости для эксплуатац
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#rl", "#training", "#math", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "Учимся на ошибках: новый метод обучения языковых моделей", "desc": "Статья представляет новый метод обучения языковых моделей - Negative-aware Fine-Tuning (NFT). NFT позволяет моделям учиться 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "UFT: Объединение лучшего из SFT и RFT для улучшения языковых моделей", "desc": "Предложен новый метод пост-обучения языковых моделей - Unified Fine-Tuning (UFT). Он объединяет преимущества supervised fine-tun
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#reasoning", "#benchmark"], "emoji": "🤔", "ru": {"title": "Рассуждения в ранжировании: не всегда путь к точности", "desc": "Исследователи изучают влияние процесса рассуждения на точность переранжирования пассажей с использованием больших языковых моделей (
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#data", "#dataset", "#optimization", "#training"], "emoji": "✂️", "ru": {"title": "EquivPruner: умное сокращение для эффективных LLM", "desc": "EquivPruner - это новый подход к оптимизации работы больших языковых моделей (LLM) при решении задач, требующих рассуждений. 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#training", "#math", "#hallucinations", "#dataset", "#optimization"], "emoji": "🧮", "ru": {"title": "Точная навигация в математических рассуждениях с PathFinder-PRM", "desc": "PathFinder-PRM - это новая иерархическая модель вознаграждения процесса, учитывающая ошибки, 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#multimodal", "#healthcare", "#optimization", "#reasoning", "#training"], "emoji": "🩺", "ru": {"title": "TAGS: Синергия генералистов и специалистов для улучшения медицинских LLM", "desc": "TAGS - это фреймворк для улучшения медицинских рассуждений больших языковых моделей (LLM) без 
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#ethics", "#reasoning", "#audio", "#benchmark", "#multimodal", "#survey"], "emoji": "🎧", "ru": {"title": "Структурированный подход к оценке аудио-языковых ИИ-моделей", "desc": "Статья представляет систематическую таксономию для оценки больших аудио-языковых моделей (LALM). Авторы вы
[28.05.2025 00:55] Querying the API.
[28.05.2025 00:55] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Diffusion step annealing enhances inference efficiency in autoregressive models by reducing the number of diffusion steps as more tokens are generated, preserving quality.  					AI-generated summary 				 An increasing number of autoregressive models, such as MAR, FlowAR, xAR, and Harmon adopt diffusion sampling to improve the quality of image generation. However, this strategy leads to low inference efficiency, because it usually takes 50 to 100 steps for diffusion to sample a token. This paper explores how to effectively address this issue. Our key motivation is that as more tokens are generated during the autoregressive process, subsequent tokens follow more constrained distributions and are easier to sample. To intuitively explain, if a model has generated part of a dog, the remaining tokens must complete the dog and thus are more constrained. Empirical evidence supports our motivation: at later generation stages, the next tokens can be well predicted by a multilayer perceptron, exhibit low variance, and follow closer-to-straight-line denoising paths from noise to tokens. Based on our finding, we introduce diffusion step annealing (DiSA), a training-free method which gradually uses fewer diffusion steps as more tokens are generated, e.g., using 50 steps at the beginning and gradually decreasing to 5 steps at later stages. Because DiSA is derived from our finding specific to diffusion in autoregressive models, it is complementary to existing acceleration methods designed for diffusion alone. DiSA can be implemented in only a few lines of code on existing models, and albeit simple, achieves 5-10times faster inference for MAR and Harmon and 1.4-2.5times for FlowAR and xAR, while maintaining the generation quality.
[28.05.2025 00:55] Response: {
  "desc": "Статья представляет метод диффузионного отжига шагов (DiSA) для улучшения эффективности вывода в авторегрессионных моделях с диффузионным сэмплированием. DiSA постепенно уменьшает количество шагов диффузии по мере генерации токенов, основываясь на наблюдении, что последующие токены следуют более ограниченным распределениям. Этот подход позволяет ускорить вывод в 5-10 раз для моделей MAR и Harmon и в 1.4-2.5 раза для FlowAR и xAR, сохраняя качество генерации. DiSA легко реализуется и совместим с существующими методами ускорения диффузии.",

  "emoji": "🚀",

  "title": "Ускорение генерации без потери качества: диффузионный отжиг шагов в авторегрессионных моделях"
}
[28.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Diffusion step annealing enhances inference efficiency in autoregressive models by reducing the number of diffusion steps as more tokens are generated, preserving quality.  					AI-generated summary 				 An increasing number of autoregressive models, such as MAR, FlowAR, xAR, and Harmon adopt diffusion sampling to improve the quality of image generation. However, this strategy leads to low inference efficiency, because it usually takes 50 to 100 steps for diffusion to sample a token. This paper explores how to effectively address this issue. Our key motivation is that as more tokens are generated during the autoregressive process, subsequent tokens follow more constrained distributions and are easier to sample. To intuitively explain, if a model has generated part of a dog, the remaining tokens must complete the dog and thus are more constrained. Empirical evidence supports our motivation: at later generation stages, the next tokens can be well predicted by a multilayer perceptron, exhibit low variance, and follow closer-to-straight-line denoising paths from noise to tokens. Based on our finding, we introduce diffusion step annealing (DiSA), a training-free method which gradually uses fewer diffusion steps as more tokens are generated, e.g., using 50 steps at the beginning and gradually decreasing to 5 steps at later stages. Because DiSA is derived from our finding specific to diffusion in autoregressive models, it is complementary to existing acceleration methods designed for diffusion alone. DiSA can be implemented in only a few lines of code on existing models, and albeit simple, achieves 5-10times faster inference for MAR and Harmon and 1.4-2.5times for FlowAR and xAR, while maintaining the generation quality."

[28.05.2025 00:55] Response: ```python
["INFERENCE", "TRAINING"]
```
[28.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Diffusion step annealing enhances inference efficiency in autoregressive models by reducing the number of diffusion steps as more tokens are generated, preserving quality.  					AI-generated summary 				 An increasing number of autoregressive models, such as MAR, FlowAR, xAR, and Harmon adopt diffusion sampling to improve the quality of image generation. However, this strategy leads to low inference efficiency, because it usually takes 50 to 100 steps for diffusion to sample a token. This paper explores how to effectively address this issue. Our key motivation is that as more tokens are generated during the autoregressive process, subsequent tokens follow more constrained distributions and are easier to sample. To intuitively explain, if a model has generated part of a dog, the remaining tokens must complete the dog and thus are more constrained. Empirical evidence supports our motivation: at later generation stages, the next tokens can be well predicted by a multilayer perceptron, exhibit low variance, and follow closer-to-straight-line denoising paths from noise to tokens. Based on our finding, we introduce diffusion step annealing (DiSA), a training-free method which gradually uses fewer diffusion steps as more tokens are generated, e.g., using 50 steps at the beginning and gradually decreasing to 5 steps at later stages. Because DiSA is derived from our finding specific to diffusion in autoregressive models, it is complementary to existing acceleration methods designed for diffusion alone. DiSA can be implemented in only a few lines of code on existing models, and albeit simple, achieves 5-10times faster inference for MAR and Harmon and 1.4-2.5times for FlowAR and xAR, while maintaining the generation quality."

[28.05.2025 00:55] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[28.05.2025 00:55] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a method called diffusion step annealing (DiSA) to improve the efficiency of autoregressive models during inference. The key idea is that as more tokens are generated, the distribution of subsequent tokens becomes more constrained, allowing for fewer diffusion steps without sacrificing quality. Empirical results show that DiSA can significantly speed up the inference process, achieving up to 10 times faster performance in certain models. This method is easy to implement and complements existing techniques for accelerating diffusion processes in machine learning.","title":"Speed Up Inference with Diffusion Step Annealing!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a method called diffusion step annealing (DiSA) to improve the efficiency of autoregressive models during inference. The key idea is that as more tokens are generated, the distribution of subsequent tokens becomes more constrained, allowing for fewer diffusion steps without sacrificing quality. Empirical results show that DiSA can significantly speed up the inference process, achieving up to 10 times faster performance in certain models. This method is easy to implement and complements existing techniques for accelerating diffusion processes in machine learning.', title='Speed Up Inference with Diffusion Step Annealing!'))
[28.05.2025 00:55] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了一种名为扩散步骤退火（DiSA）的方法，旨在提高自回归模型的推理效率。随着生成的标记数量增加，后续标记的分布变得更加受限，从而更容易进行采样。通过实验证明，在生成的后期阶段，下一标记可以通过多层感知器进行良好预测，且具有低方差。DiSA方法在生成初期使用较多的扩散步骤，随着生成的进行逐渐减少步骤数量，从而实现了推理速度的显著提升。","title":"扩散步骤退火：提升自回归模型推理效率的创新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了一种名为扩散步骤退火（DiSA）的方法，旨在提高自回归模型的推理效率。随着生成的标记数量增加，后续标记的分布变得更加受限，从而更容易进行采样。通过实验证明，在生成的后期阶段，下一标记可以通过多层感知器进行良好预测，且具有低方差。DiSA方法在生成初期使用较多的扩散步骤，随着生成的进行逐渐减少步骤数量，从而实现了推理速度的显著提升。', title='扩散步骤退火：提升自回归模型推理效率的创新方法'))
[28.05.2025 00:55] Using data from previous issue: {"categories": ["#agents", "#optimization", "#robotics", "#transfer_learning"], "emoji": "🤖", "ru": {"title": "Обучение роботов манипуляциям без роботизированных данных", "desc": "EgoZero - это система, которая обучает робастные политики манипуляции для роботов, используя демонстрации людей в реальн
[28.05.2025 00:55] Querying the API.
[28.05.2025 00:55] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language models (LLMs). However, its effectiveness in vision-language models (VLMs) remains insufficiently studied. In this work, we conduct a comprehensive evaluation of verbalized confidence in VLMs, spanning three model categories, four task domains, and three evaluation scenarios. Our results show that current VLMs often display notable miscalibration across diverse tasks and settings. Notably, visual reasoning models (i.e., thinking with images) consistently exhibit better calibration, suggesting that modality-specific reasoning is critical for reliable uncertainty estimation. To further address calibration challenges, we introduce Visual Confidence-Aware Prompting, a two-stage prompting strategy that improves confidence alignment in multimodal settings. Overall, our study highlights the inherent miscalibration in VLMs across modalities. More broadly, our findings underscore the fundamental importance of modality alignment and model faithfulness in advancing reliable multimodal systems.
[28.05.2025 00:55] Response: {
  "desc": "Статья исследует эффективность вербализованной неопределенности в мультимодальных моделях компьютерного зрения и языка (VLM). Авторы проводят комплексную оценку калибровки уверенности VLM в различных задачах и сценариях. Результаты показывают, что текущие VLM часто демонстрируют заметную мискалибровку, при этом модели визуального рассуждения показывают лучшую калибровку. Для улучшения калибровки авторы предлагают двухэтапную стратегию промптинга Visual Confidence-Aware Prompting.",

  "emoji": "🧠",

  "title": "Калибровка уверенности в мультимодальных моделях: проблемы и решения"
}
[28.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language models (LLMs). However, its effectiveness in vision-language models (VLMs) remains insufficiently studied. In this work, we conduct a comprehensive evaluation of verbalized confidence in VLMs, spanning three model categories, four task domains, and three evaluation scenarios. Our results show that current VLMs often display notable miscalibration across diverse tasks and settings. Notably, visual reasoning models (i.e., thinking with images) consistently exhibit better calibration, suggesting that modality-specific reasoning is critical for reliable uncertainty estimation. To further address calibration challenges, we introduce Visual Confidence-Aware Prompting, a two-stage prompting strategy that improves confidence alignment in multimodal settings. Overall, our study highlights the inherent miscalibration in VLMs across modalities. More broadly, our findings underscore the fundamental importance of modality alignment and model faithfulness in advancing reliable multimodal systems."

[28.05.2025 00:56] Response: ```python
["MULTIMODAL", "CV", "TRAINING"]
```
[28.05.2025 00:56] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language models (LLMs). However, its effectiveness in vision-language models (VLMs) remains insufficiently studied. In this work, we conduct a comprehensive evaluation of verbalized confidence in VLMs, spanning three model categories, four task domains, and three evaluation scenarios. Our results show that current VLMs often display notable miscalibration across diverse tasks and settings. Notably, visual reasoning models (i.e., thinking with images) consistently exhibit better calibration, suggesting that modality-specific reasoning is critical for reliable uncertainty estimation. To further address calibration challenges, we introduce Visual Confidence-Aware Prompting, a two-stage prompting strategy that improves confidence alignment in multimodal settings. Overall, our study highlights the inherent miscalibration in VLMs across modalities. More broadly, our findings underscore the fundamental importance of modality alignment and model faithfulness in advancing reliable multimodal systems."

[28.05.2025 00:56] Response: ```python
["INTERPRETABILITY", "REASONING"]
```
[28.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper focuses on uncertainty quantification in vision-language models (VLMs), which is crucial for ensuring the reliability of AI systems. It evaluates how well these models express their confidence through verbalized uncertainty, a method that has been effective in large language models but not thoroughly explored in VLMs. The study finds that VLMs often miscalibrate their confidence levels across various tasks, although visual reasoning models perform better in this regard. To improve this calibration, the authors propose a new strategy called Visual Confidence-Aware Prompting, which enhances confidence alignment in multimodal contexts.","title":"Enhancing Trust in Vision-Language Models through Confidence Calibration"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper focuses on uncertainty quantification in vision-language models (VLMs), which is crucial for ensuring the reliability of AI systems. It evaluates how well these models express their confidence through verbalized uncertainty, a method that has been effective in large language models but not thoroughly explored in VLMs. The study finds that VLMs often miscalibrate their confidence levels across various tasks, although visual reasoning models perform better in this regard. To improve this calibration, the authors propose a new strategy called Visual Confidence-Aware Prompting, which enhances confidence alignment in multimodal contexts.', title='Enhancing Trust in Vision-Language Models through Confidence Calibration'))
[28.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"不确定性量化对于评估现代人工智能系统的可靠性和可信度至关重要。本文研究了在视觉-语言模型（VLMs）中，模型通过自然语言表达信心的方式，即口头不确定性。我们的评估显示，当前的VLMs在不同任务和设置中常常存在显著的校准失调，尤其是视觉推理模型表现出更好的校准效果。为了解决校准问题，我们提出了一种视觉信心感知提示的两阶段策略，以改善多模态环境中的信心对齐。","title":"提升视觉-语言模型的信心校准"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='不确定性量化对于评估现代人工智能系统的可靠性和可信度至关重要。本文研究了在视觉-语言模型（VLMs）中，模型通过自然语言表达信心的方式，即口头不确定性。我们的评估显示，当前的VLMs在不同任务和设置中常常存在显著的校准失调，尤其是视觉推理模型表现出更好的校准效果。为了解决校准问题，我们提出了一种视觉信心感知提示的两阶段策略，以改善多模态环境中的信心对齐。', title='提升视觉-语言模型的信心校准'))
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#data", "#multilingual", "#science", "#open_source", "#low_resource"], "emoji": "🔍", "ru": {"title": "MOLE: автоматическое извлечение метаданных с помощью больших языковых моделей", "desc": "Представлена система MOLE, использующая большие языковые модели дл
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#interpretability", "#training", "#architecture"], "emoji": "🧠", "ru": {"title": "Раскрывая тайны семантики в глубинах нейронных сетей", "desc": "Это исследование посвящено появлению интерпретируемых категориальных признаков в больших языковых моделях (LLM). Авторы анализируют повед
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#dataset", "#survey", "#open_source", "#benchmark"], "emoji": "🖼️", "ru": {"title": "MMIG-Bench: Революция в оценке мультимодальных генераторов изображений", "desc": "MMIG-Bench - это новый комплексный бенчмарк для оценки мультимодальных генераторов и
[28.05.2025 00:56] Querying the API.
[28.05.2025 00:56] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Current large language models (LLMs) have demonstrated emerging capabilities in social intelligence tasks, including implicature resolution (Sravanthi et al. (2024)) and theory-of-mind reasoning (Shapira et al. (2024)), both of which require substantial pragmatic understanding. However, how LLMs acquire this competence throughout the training process remains poorly understood. In this work, we introduce ALTPRAG, a dataset grounded in the pragmatic concept of alternatives, designed to evaluate whether LLMs at different training stages can accurately infer nuanced speaker intentions. Each instance pairs two contextually appropriate but pragmatically distinct continuations, enabling fine-grained assessment of both pragmatic interpretation and contrastive reasoning. We systematically evaluate 22 LLMs across key training stages: pre-training, supervised fine-tuning (SFT), and preference optimization, to examine the development of pragmatic competence. Our results show that even base models exhibit notable sensitivity to pragmatic cues, which improves consistently with increases in model and data scale. Additionally, SFT and RLHF contribute further gains, particularly in cognitive-pragmatic reasoning. These findings highlight pragmatic competence as an emergent and compositional property of LLM training and offer new insights for aligning models with human communicative norms.
[28.05.2025 00:56] Response: {
  "desc": "Исследователи представили ALTPRAG - набор данных для оценки прагматических способностей больших языковых моделей (LLM) на разных этапах обучения. Анализ 22 моделей показал, что даже базовые версии демонстрируют чувствительность к прагматическим сигналам, которая улучшается с увеличением масштаба модели и данных. Дополнительное обучение с учителем и оптимизация предпочтений дают дальнейший прирост, особенно в когнитивно-прагматических рассуждениях. Результаты показывают, что прагматическая компетентность является эмерджентным и композиционным свойством обучения LLM.",
  "emoji": "🗣️",
  "title": "Развитие прагматического интеллекта в больших языковых моделях"
}
[28.05.2025 00:56] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Current large language models (LLMs) have demonstrated emerging capabilities in social intelligence tasks, including implicature resolution (Sravanthi et al. (2024)) and theory-of-mind reasoning (Shapira et al. (2024)), both of which require substantial pragmatic understanding. However, how LLMs acquire this competence throughout the training process remains poorly understood. In this work, we introduce ALTPRAG, a dataset grounded in the pragmatic concept of alternatives, designed to evaluate whether LLMs at different training stages can accurately infer nuanced speaker intentions. Each instance pairs two contextually appropriate but pragmatically distinct continuations, enabling fine-grained assessment of both pragmatic interpretation and contrastive reasoning. We systematically evaluate 22 LLMs across key training stages: pre-training, supervised fine-tuning (SFT), and preference optimization, to examine the development of pragmatic competence. Our results show that even base models exhibit notable sensitivity to pragmatic cues, which improves consistently with increases in model and data scale. Additionally, SFT and RLHF contribute further gains, particularly in cognitive-pragmatic reasoning. These findings highlight pragmatic competence as an emergent and compositional property of LLM training and offer new insights for aligning models with human communicative norms."

[28.05.2025 00:56] Response: ```python
['DATASET', 'TRAINING', 'RLHF']
```
[28.05.2025 00:56] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Current large language models (LLMs) have demonstrated emerging capabilities in social intelligence tasks, including implicature resolution (Sravanthi et al. (2024)) and theory-of-mind reasoning (Shapira et al. (2024)), both of which require substantial pragmatic understanding. However, how LLMs acquire this competence throughout the training process remains poorly understood. In this work, we introduce ALTPRAG, a dataset grounded in the pragmatic concept of alternatives, designed to evaluate whether LLMs at different training stages can accurately infer nuanced speaker intentions. Each instance pairs two contextually appropriate but pragmatically distinct continuations, enabling fine-grained assessment of both pragmatic interpretation and contrastive reasoning. We systematically evaluate 22 LLMs across key training stages: pre-training, supervised fine-tuning (SFT), and preference optimization, to examine the development of pragmatic competence. Our results show that even base models exhibit notable sensitivity to pragmatic cues, which improves consistently with increases in model and data scale. Additionally, SFT and RLHF contribute further gains, particularly in cognitive-pragmatic reasoning. These findings highlight pragmatic competence as an emergent and compositional property of LLM training and offer new insights for aligning models with human communicative norms."

[28.05.2025 00:56] Response: ```python
['REASONING', 'ALIGNMENT']
```
[28.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces ALTPRAG, a dataset designed to assess how large language models (LLMs) understand speaker intentions through pragmatic reasoning. It evaluates LLMs at various training stages, including pre-training, supervised fine-tuning, and preference optimization, to see how their ability to interpret nuanced meanings develops. The study finds that even basic models show some understanding of pragmatic cues, which improves as the models and training data grow. Additionally, supervised fine-tuning and reinforcement learning from human feedback enhance cognitive-pragmatic reasoning, suggesting that pragmatic competence emerges as LLMs are trained.","title":"Unlocking Pragmatic Understanding in Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces ALTPRAG, a dataset designed to assess how large language models (LLMs) understand speaker intentions through pragmatic reasoning. It evaluates LLMs at various training stages, including pre-training, supervised fine-tuning, and preference optimization, to see how their ability to interpret nuanced meanings develops. The study finds that even basic models show some understanding of pragmatic cues, which improves as the models and training data grow. Additionally, supervised fine-tuning and reinforcement learning from human feedback enhance cognitive-pragmatic reasoning, suggesting that pragmatic competence emerges as LLMs are trained.', title='Unlocking Pragmatic Understanding in Language Models'))
[28.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"当前的大型语言模型（LLMs）在社会智能任务中展现出新兴能力，包括隐含意义解析和心智理论推理，这些都需要深厚的语用理解。然而，LLMs在训练过程中如何获得这种能力仍然不太清楚。我们引入了ALTPRAG数据集，旨在评估不同训练阶段的LLMs是否能够准确推断细微的说话者意图。研究结果表明，即使是基础模型对语用线索也表现出显著的敏感性，并且随着模型和数据规模的增加，这种能力不断提高。","title":"揭示大型语言模型的语用能力发展"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='当前的大型语言模型（LLMs）在社会智能任务中展现出新兴能力，包括隐含意义解析和心智理论推理，这些都需要深厚的语用理解。然而，LLMs在训练过程中如何获得这种能力仍然不太清楚。我们引入了ALTPRAG数据集，旨在评估不同训练阶段的LLMs是否能够准确推断细微的说话者意图。研究结果表明，即使是基础模型对语用线索也表现出显著的敏感性，并且随着模型和数据规模的增加，这种能力不断提高。', title='揭示大型语言模型的语用能力发展'))
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#rlhf", "#training", "#optimization", "#interpretability", "#reasoning", "#multilingual", "#rl"], "emoji": "🧠", "ru": {"title": "Гибридные рассуждения в языковых моделях: объединяем скрытое и явное", "desc": "Статья представляет гибридный подход к оптимизации политики рассуждений (H
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#robotics", "#benchmark", "#survey"], "emoji": "🧩", "ru": {"title": "Сегментация частей объектов: новый бенчмарк для мультимодальных моделей", "desc": "Статья представляет новый бенчмарк InstructPart и набор данных для сегментации частей объектов, ориентир
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#training", "#rl", "#rlhf", "#optimization", "#reasoning", "#benchmark"], "emoji": "🤖", "ru": {"title": "Временная абстракция для эффективного обучения с подкреплением", "desc": "Статья представляет метод Option-aware Temporally Abstracted (OTA) для обучения с подкреплением в офлайн
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#training", "#architecture", "#optimization"], "emoji": "🔥", "ru": {"title": "FLAME-MoE: Открытая платформа для исследования Mixture-of-Experts в LLM", "desc": "FLAME-MoE - это открытый исследовательский набор для архитектур Mixture-of-Experts (MoE) в бол
[28.05.2025 00:56] Querying the API.
[28.05.2025 00:56] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We introduce CASS, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA leftrightarrow HIP) and assembly-level (Nvidia SASS leftrightarrow AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and device, addressing a critical gap in low-level GPU code portability. Leveraging this resource, we train the CASS family of domain-specific language models, achieving 95% source translation accuracy and 37.5% assembly translation accuracy, substantially outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our generated code matches native performance in over 85% of test cases, preserving runtime and memory behavior. To support rigorous evaluation, we introduce CASS-Bench, a curated benchmark spanning 16 GPU domains with ground-truth execution. All data, models, and evaluation tools are released as open source to foster progress in GPU compiler tooling, binary compatibility, and LLM-guided hardware translation. Dataset and benchmark are on https://huggingface.co/datasets/MBZUAI/cass{blue{HuggingFace}}, with code at https://github.com/GustavoStahl/CASS{blue{GitHub}}.
[28.05.2025 00:56] Response: {
  "desc": "CASS - это новый масштабный набор данных и семейство моделей для кросс-архитектурной транспиляции GPU-кода, охватывающий как уровень исходного кода (CUDA ↔ HIP), так и уровень ассемблера (Nvidia SASS ↔ AMD RDNA3). Набор данных содержит 70 тысяч верифицированных пар кода для хоста и устройства, что решает критическую проблему переносимости низкоуровневого GPU-кода. Модели CASS, обученные на этих данных, достигают 95% точности для трансляции исходного кода и 37.5% для ассемблера, значительно превосходя коммерческие решения. Авторы также представили CASS-Bench - специализированный бенчмарк для строгой оценки в 16 GPU-доменах.",
  "emoji": "🔄",
  "title": "CASS: Революция в кросс-архитектурной транспиляции GPU-кода"
}
[28.05.2025 00:56] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce CASS, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA leftrightarrow HIP) and assembly-level (Nvidia SASS leftrightarrow AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and device, addressing a critical gap in low-level GPU code portability. Leveraging this resource, we train the CASS family of domain-specific language models, achieving 95% source translation accuracy and 37.5% assembly translation accuracy, substantially outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our generated code matches native performance in over 85% of test cases, preserving runtime and memory behavior. To support rigorous evaluation, we introduce CASS-Bench, a curated benchmark spanning 16 GPU domains with ground-truth execution. All data, models, and evaluation tools are released as open source to foster progress in GPU compiler tooling, binary compatibility, and LLM-guided hardware translation. Dataset and benchmark are on https://huggingface.co/datasets/MBZUAI/cass{blue{HuggingFace}}, with code at https://github.com/GustavoStahl/CASS{blue{GitHub}}."

[28.05.2025 00:56] Response: ```python
['DATASET', 'BENCHMARK']
```
[28.05.2025 00:56] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce CASS, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA leftrightarrow HIP) and assembly-level (Nvidia SASS leftrightarrow AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and device, addressing a critical gap in low-level GPU code portability. Leveraging this resource, we train the CASS family of domain-specific language models, achieving 95% source translation accuracy and 37.5% assembly translation accuracy, substantially outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our generated code matches native performance in over 85% of test cases, preserving runtime and memory behavior. To support rigorous evaluation, we introduce CASS-Bench, a curated benchmark spanning 16 GPU domains with ground-truth execution. All data, models, and evaluation tools are released as open source to foster progress in GPU compiler tooling, binary compatibility, and LLM-guided hardware translation. Dataset and benchmark are on https://huggingface.co/datasets/MBZUAI/cass{blue{HuggingFace}}, with code at https://github.com/GustavoStahl/CASS{blue{GitHub}}."

[28.05.2025 00:56] Response: ```python
['OPEN_SOURCE', 'LOW_RESOURCE']
```
[28.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CASS is a groundbreaking dataset and model suite designed for translating GPU code between different architectures, specifically CUDA and HIP at the source level, and Nvidia SASS and AMD RDNA3 at the assembly level. It includes 70,000 verified code pairs, which helps improve the portability of low-level GPU code. The CASS models achieve impressive translation accuracies of 95% for source code and 37.5% for assembly code, outperforming existing commercial solutions. Additionally, the generated code maintains native performance in over 85% of cases, and the CASS-Bench provides a comprehensive evaluation framework for testing across various GPU domains.","title":"CASS: Bridging GPU Code Across Architectures"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CASS is a groundbreaking dataset and model suite designed for translating GPU code between different architectures, specifically CUDA and HIP at the source level, and Nvidia SASS and AMD RDNA3 at the assembly level. It includes 70,000 verified code pairs, which helps improve the portability of low-level GPU code. The CASS models achieve impressive translation accuracies of 95% for source code and 37.5% for assembly code, outperforming existing commercial solutions. Additionally, the generated code maintains native performance in over 85% of cases, and the CASS-Bench provides a comprehensive evaluation framework for testing across various GPU domains.', title='CASS: Bridging GPU Code Across Architectures'))
[28.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"我们介绍了CASS，这是首个大规模的数据集和模型套件，专注于跨架构GPU代码转译，涵盖源代码级（CUDA与HIP之间）和汇编级（Nvidia SASS与AMD RDNA3之间）的转换。该数据集包含70,000对经过验证的代码对，解决了低级GPU代码可移植性的重要问题。利用这一资源，我们训练了CASS系列特定领域语言模型，实现了95%的源代码翻译准确率和37.5%的汇编翻译准确率，显著超越了商业基准如GPT-4o、Claude和Hipify。我们的生成代码在超过85%的测试案例中与原生性能相匹配，保持了运行时和内存行为的一致性。","title":"CASS：跨架构GPU代码转译的突破性进展"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='我们介绍了CASS，这是首个大规模的数据集和模型套件，专注于跨架构GPU代码转译，涵盖源代码级（CUDA与HIP之间）和汇编级（Nvidia SASS与AMD RDNA3之间）的转换。该数据集包含70,000对经过验证的代码对，解决了低级GPU代码可移植性的重要问题。利用这一资源，我们训练了CASS系列特定领域语言模型，实现了95%的源代码翻译准确率和37.5%的汇编翻译准确率，显著超越了商业基准如GPT-4o、Claude和Hipify。我们的生成代码在超过85%的测试案例中与原生性能相匹配，保持了运行时和内存行为的一致性。', title='CASS：跨架构GPU代码转译的突破性进展'))
[28.05.2025 00:56] Using data from previous issue: {"categories": ["#alignment", "#training", "#cv", "#optimization", "#multimodal"], "emoji": "🧭", "ru": {"title": "Текстовые векторы как компас для мультимодальных моделей", "desc": "Это исследование посвящено применению методов управления (steering) для мультимодальных больших языковых моделей (MLLM
[28.05.2025 00:56] Loading Chinese text from previous data.
[28.05.2025 00:56] Renaming data file.
[28.05.2025 00:56] Renaming previous data. hf_papers.json to ./d/2025-05-28.json
[28.05.2025 00:56] Saving new data file.
[28.05.2025 00:56] Generating page.
[28.05.2025 00:56] Renaming previous page.
[28.05.2025 00:56] Renaming previous data. index.html to ./d/2025-05-28.html
[28.05.2025 00:56] [Experimental] Generating Chinese page for reading.
[28.05.2025 00:56] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '大型', 'pinyin': 'dà xíng', 'trans': 'large-scale'}, {'word': '语言模型', 'pinyin': 'yǔ yán mó xíng', 'trans': 'language model'}, {'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '快速', 'pinyin': 'kuài sù', 'trans': 'rapid'}, {'word': '发展', 'pinyin': 'fā zhǎn', 'trans': 'development'}, {'word': '主要', 'pinyin': 'zhǔ yào', 'trans': 'main'}, {'word': '通过', 'pinyin': 'tōng guò', 'trans': 'through'}, {'word': '增加', 'pinyin': 'zēng jiā', 'trans': 'increase'}, {'word': '参数', 'pinyin': 'cān shǔ', 'trans': 'parameter'}, {'word': '数量', 'pinyin': 'shù liàng', 'trans': 'quantity'}, {'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '硬件', 'pinyin': 'yìng jiàn', 'trans': 'hardware'}, {'word': '限制', 'pinyin': 'xiàn zhì', 'trans': 'limit'}, {'word': '自注意力', 'pinyin': 'zì zhù yì lì', 'trans': 'self-attention'}, {'word': '成本', 'pinyin': 'chéng běn', 'trans': 'cost'}, {'word': '瓶颈', 'pinyin': 'píng lóng', 'trans': 'bottleneck'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '重点', 'pinyin': 'zhòng diǎn', 'trans': 'focus'}, {'word': '模型压缩', 'pinyin': 'mó xíng yā suō', 'trans': 'model compression'}, {'word': '转向', 'pinyin': 'zhuǎn xiàng', 'trans': 'turn to'}, {'word': '数据压缩', 'pinyin': 'shù jù yā suō', 'trans': 'data compression'}, {'word': '令牌', 'pinyin': 'lìng pái', 'trans': 'token'}, {'word': '压缩', 'pinyin': 'yā suō', 'trans': 'compression'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'training'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '作者', 'pinyin': 'zuò zhě', 'trans': 'author'}, {'word': '分析', 'pinyin': 'fēn xī', 'trans': 'analyze'}, {'word': '长上下文', 'pinyin': 'cháng shàng xià wén', 'trans': 'long context'}, {'word': '数学框架', 'pinyin': 'shù xué kuàng jià', 'trans': 'mathematical framework'}, {'word': '探讨', 'pinyin': 'tàn tǎo', 'trans': 'explore'}, {'word': '优势', 'pinyin': 'yōu shì', 'trans': 'advantage'}, {'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'}]
[28.05.2025 00:56] Renaming previous Chinese page.
[28.05.2025 00:56] Renaming previous data. zh.html to ./d/2025-05-27_zh_reading_task.html
[28.05.2025 00:56] Writing Chinese reading task.
[28.05.2025 00:56] Writing result.
[28.05.2025 00:56] Renaming log file.
[28.05.2025 00:56] Renaming previous data. log.txt to ./logs/2025-05-28_last_log.txt
