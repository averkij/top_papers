[26.05.2025 14:11] Read previous papers.
[26.05.2025 14:11] Generating top page (month).
[26.05.2025 14:11] Writing top page (month).
[26.05.2025 15:12] Read previous papers.
[26.05.2025 15:12] Get feed.
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18125
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17667
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17225
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14669
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18129
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17612
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15929
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18092
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17618
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17561
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17941
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17873
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16211
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17399
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17558
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15692
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16479
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17412
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16483
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13508
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17955
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17417
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16770
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14146
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17826
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16270
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15389
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17063
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17540
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17091
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17508
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15182
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17016
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18078
[26.05.2025 15:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.16134
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15805
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16293
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16056
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16022
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12891
[26.05.2025 15:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.16409
[26.05.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11881
[26.05.2025 15:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.05.2025 15:12] No deleted papers detected.
[26.05.2025 15:12] Downloading and parsing papers (pdf, html). Total: 42.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.18125.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.18125.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.18125.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17667.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17667.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17667.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17225.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17225.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17225.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14669.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14669.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14669.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.18129.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.18129.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.18129.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17612.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17612.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17612.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15929.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15929.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15929.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.18092.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.18092.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.18092.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17618.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17618.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17618.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17561.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17561.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17561.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17941.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17941.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17941.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17873.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17873.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17873.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16211.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16211.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16211.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17399.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17399.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17399.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17558.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17558.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17558.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15692.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15692.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15692.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16479.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16479.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16479.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17412.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17412.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17412.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16483.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16483.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16483.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.13508.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.13508.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.13508.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17955.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17955.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17955.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17417.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17417.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17417.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16770.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16770.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16770.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.14146.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.14146.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.14146.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17826.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17826.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17826.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16270.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16270.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16270.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15389.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15389.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15389.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17063.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17063.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17063.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17540.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17540.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17540.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17091.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17091.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17091.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17508.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17508.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17508.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15182.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15182.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15182.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.17016.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.17016.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.17016.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.18078.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.18078.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.18078.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16134.
[26.05.2025 15:12] Downloading paper 2505.16134 from http://arxiv.org/pdf/2505.16134v1...
[26.05.2025 15:12] Extracting affiliations from text.
[26.05.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Position of Uncertainty: Cross-Linguistic Study of position bias in Large Language Models Menschikov Mikhail,1,2, Alexander Kharitonov,3, Maiia Kotyga4, Vadim Porvatov2,3, Anna Zhukovskaya5, David Kagramanyan6, Egor Shvetsov2, and Evgeny Burnaev2,7 these authors contributed equally to this work 1ITMO, Saint-Petersburg, Russia, 2Skoltech, Moscow, Russia, 3Sber, Moscow, Russia, 4MIPT, Moscow, Russia, 5Lomonosov MSU, Moscow, Russia, 6HSE University, Moscow, Russia, 7AIRI, Moscow, Russia Corresponding author: m.menschikov@skoltech.ru Identifies project curator - 5 2 0 2 2 2 ] . [ 1 4 3 1 6 1 . 5 0 5 2 : r a "
[26.05.2025 15:12] Response: ```python
[
    "ITMO, Saint-Petersburg, Russia",
    "Skoltech, Moscow, Russia",
    "Sber, Moscow, Russia",
    "MIPT, Moscow, Russia",
    "Lomonosov MSU, Moscow, Russia",
    "HSE University, Moscow, Russia",
    "AIRI, Moscow, Russia"
]
```
[26.05.2025 15:12] Deleting PDF ./assets/pdf/2505.16134.pdf.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.15805.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.15805.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.15805.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16293.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16293.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16293.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16056.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16056.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16056.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16022.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.16022.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.16022.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.12891.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.12891.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.12891.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.16409.
[26.05.2025 15:12] Downloading paper 2505.16409 from http://arxiv.org/pdf/2505.16409v1...
[26.05.2025 15:12] Extracting affiliations from text.
[26.05.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 2 ] . [ 1 9 0 4 6 1 . 5 0 5 2 : r FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS Chaeeun Kim LBOX chaeeun@lbox.kr Seungone Kim Carnegie Mellon University seungone@cmu.edu "
[26.05.2025 15:12] Response: ```python
["LBOX", "Carnegie Mellon University"]
```
[26.05.2025 15:12] Deleting PDF ./assets/pdf/2505.16409.pdf.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2505.11881.
[26.05.2025 15:12] Extra JSON file exists (./assets/json/2505.11881.json), skip PDF parsing.
[26.05.2025 15:12] Paper image links file exists (./assets/img_data/2505.11881.json), skip HTML parsing.
[26.05.2025 15:12] Success.
[26.05.2025 15:12] Enriching papers with extra data.
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 0. TabSTAR, a tabular foundation model with semantically target-aware representations, achieves state-of-the-art performance in classification tasks with text features through transfer learning without dataset-specific parameters.  					AI-generated summary 				 While deep learning has achieved remarka...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 1. A framework called QwenLong-L1 enhances large reasoning models for long-context reasoning through reinforcement learning, achieving leading performance on document question-answering benchmarks.  					AI-generated summary 				 Recent large reasoning models (LRMs) have demonstrated strong reasoning c...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 2. A diagnostic set examines and categorizes reasoning rigidity in large language models, identifying patterns where models ignore instructions and default to familiar reasoning.  					AI-generated summary 				 Large language models have demonstrated remarkable proficiency in long and complex reasoning...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 3. Quartet, a hardware-supported FP4 training approach for large language models, demonstrates state-of-the-art accuracy while significantly reducing computational costs compared to standard or FP8 precision.  					AI-generated summary 				 The rapid advancement of large language models (LLMs) has been...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 4. A unified reinforcement learning system, V-Triune, combines visual reasoning and perception tasks in vision-language models through a single training pipeline, achieving significant improvements across various tasks.  					AI-generated summary 				 Reinforcement learning (RL) has significantly advan...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 5. Agent Distillation transfers reasoning and task-solving capabilities from large language models to smaller models using enhanced prompts and self-consistent actions, matching performance of larger models on various reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) excel a...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 6. A new benchmark, PhyX, evaluates models' physics-grounded reasoning in visual scenarios, revealing significant limitations in current models' physical understanding compared to human experts.  					AI-generated summary 				 Existing benchmarks fail to capture a crucial aspect of intelligence: physic...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 7. QwenLong-CPRS enhances large language models with multi-granularity context compression, dynamic optimization guided by natural language, and efficient bidirectional reasoning and parallel inference, achieving superior performance and context management.  					AI-generated summary 				 This technica...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 8. EvoSearch, an evolutionary search method, enhances test-time scaling for diffusion and flow-based generative models, improving image and video generation quality, diversity, and generalizability.  					AI-generated summary 				 As the marginal cost of scaling computation (data and parameters) during...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 9. ANSE enhances video diffusion models by selecting noise seeds based on model confidence, improving video quality and temporal coherence with minimal increase in inference time.  					AI-generated summary 				 The choice of initial noise significantly affects the quality and prompt alignment of video...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 10. VeriThinker reduces the length of complex reasoning chains in Large Reasoning Models (LRMs) by fine-tuning them on a verification task, thereby decreasing inference costs without significantly sacrificing accuracy.  					AI-generated summary 				 Large Reasoning Models (LRMs) excel at complex tasks ...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 11. A novel simulator and experiment-guided ranking method improve hypothesis prioritization in scientific discovery by incorporating simulated experimental outcomes.  					AI-generated summary 				 Hypothesis ranking is a crucial component of automated scientific discovery, particularly in natural scie...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 12. AudioTrust evaluates the trustworthiness of Audio Large Language Models across multifaceted dimensions, using a comprehensive dataset and specific metrics to assess their performance in real-world audio scenarios.  					AI-generated summary 				 The rapid advancement and expanding applications of Au...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 13. FullFront is a benchmark evaluating Multimodal Large Language Models across conceptualization, comprehension, and implementation phases in front-end engineering.  					AI-generated summary 				 Front-end engineering involves a complex workflow where engineers conceptualize designs, translate them in...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 14. The use of carefully crafted hallucinations in a curriculum learning approach within the DPO alignment procedure significantly enhances LLMs' hallucination detection abilities.  					AI-generated summary 				 Aligning large language models (LLMs) to accurately detect hallucinations remains a signifi...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 15. A novel RL framework, TAPO, integrates external guidance to enhance model performance and exploration compared to existing methods.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as an effective method for training reasoning models. However, existing RL approaches typically ...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 16. A unified framework for restoring nighttime images under diverse weather conditions using dual priors and adaptive collaboration.  					AI-generated summary 				 Restoring nighttime images affected by multiple adverse weather conditions is a practical yet under-explored research problem, as multiple...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 17. A scalable 3D shape generation framework using sparse volumes and spatial sparse attention, enabling high-resolution generation with reduced computational requirements.  					AI-generated summary 				 Generating high resolution 3D shapes using volumetric representations such as Signed Distance Funct...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 18. CANOE improves LLM faithfulness in generation tasks using synthetic QA data and Dual-GRPO reinforcement learning without human annotations.  					AI-generated summary 				 Teaching large language models (LLMs) to be faithful in the provided context is crucial for building reliable information-seekin...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 19. A novel framework, Time-R1, enhances moderate-sized LLMs with comprehensive temporal abilities through a reinforcement learning curriculum, outperforming larger models on future event prediction and creative scenario generation benchmarks.  					AI-generated summary 				 Large Language Models (LLMs)...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 20. A study of diffusion classifiers across multiple datasets and tasks reveals their compositional understanding, highlighting domain-specific performance effects and timestep weighting importance.  					AI-generated summary 				 Understanding visual scenes is fundamental to human intelligence. While d...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 21. The rapid growth of voice assistants powered by large language models (LLM) has highlighted a need for speech instruction data to train these systems. Despite the abundance of speech recognition data, there is a notable scarcity of speech instruction data, which is essential for fine-tuning models t...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 22. A benchmark called RBench-V evaluates multi-modal models' vision-indispensable reasoning through image manipulation and auxiliary line construction, demonstrating that current models struggle with multi-modal outputs.  					AI-generated summary 				 The rapid advancement of native multi-modal models...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 23. A lightweight, model-agnostic framework decouples the retrieval and generation processes in RAG systems, enhancing performance with minimal training data.  					AI-generated summary 				 Retrieval-augmented generation (RAG) systems empower large language models (LLMs) to access external knowledge du...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 24. Trinity-RFT is a flexible and scalable framework for reinforcement fine-tuning of large language models, supporting various interaction modes and data pipelines.  					AI-generated summary 				 Trinity-RFT is a general-purpose, flexible and scalable framework designed for reinforcement fine-tuning (...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 25. The Transformer Copilot framework enhances large language model performance through a Copilot model that refines the Pilot's logits based on a Mistake Log, leading to consistent performance improvements across various benchmarks.  					AI-generated summary 				 Large language models are typically ad...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 26. VLMs are more vulnerable to harmful meme-based prompts than to synthetic images, and while multi-turn interactions offer some protection, significant vulnerabilities remain.  					AI-generated summary 				 Rapid deployment of vision-language models (VLMs) magnifies safety risks, yet most evaluations...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 27. Synthetic Data RL enhances foundation models through reinforcement learning using only synthetic data, achieving performance comparable to models trained with full human-labeled data.  					AI-generated summary 				 Reinforcement learning (RL) is a powerful way to adapt foundation models to speciali...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 28. RePrompt, a reprompting framework using reinforcement learning, enhances text-to-image generation by optimizing for image-level outcomes, significantly improving spatial layout and compositional generalization.  					AI-generated summary 				 Despite recent progress in text-to-image (T2I) generation...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 29. Auto-regressive text LLMs trained on text can develop internal capabilities for understanding images and audio, enabling them to perform classification tasks across different modalities without fine-tuning.  					AI-generated summary 				 This paper presents a fascinating find: By training an auto-r...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 30. A regularized policy gradient framework is introduced to explore KL divergence formulations for enhancing the reasoning capabilities of LLMs in online reinforcement learning, demonstrating improved training stability and performance.  					AI-generated summary 				 Policy gradient algorithms have be...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 31. ReflAct, a new reasoning backbone for LLM agents, improves goal alignment and reduces hallucinations by continuously reflecting on the agent's state, surpassing ReAct and other enhanced variants.  					AI-generated summary 				 Recent advances in LLM agents have largely built on reasoning backbones ...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 32. We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based interactive post-training paradigm that fine-tunes pretrained Vision-Language-Action (VLA) models using only sparse binary success rewards. Existing VLA training pipelines rely heavily on offline expert demonstration data and ...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 33. DanceTogether, an end-to-end diffusion framework, generates long, photorealistic multi-actor interaction videos from single reference images and pose-mask streams, outperforming existing systems.  					AI-generated summary 				 Controllable video generation (CVG) has advanced rapidly, yet current sy...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 34. Large language models exhibit positional bias -- systematic neglect of information at specific context positions -- yet its interplay with linguistic diversity remains poorly understood. We present a cross-linguistic study across five typologically distinct languages (English, Russian, German, Hindi...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 35. LLMs frequently violate contextual security policies by leaking sensitive information, particularly under indirect attacks, indicating a critical gap in current safety mechanisms.  					AI-generated summary 				 As Large Language Models (LLMs) are increasingly deployed in sensitive domains such as e...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 36. Notes Writing enhances iterative RAG by generating concise notes at each step, improving reasoning and performance while minimizing output increase.  					AI-generated summary 				 Iterative RAG for multi-hop question answering faces challenges with lengthy contexts and the buildup of irrelevant inf...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 37. MoE models achieve efficient scaling in LLMs with expert offloading, emphasizing the importance of local routing consistency and cache effectiveness.  					AI-generated summary 				 Mixture-of-Experts (MoE) enables efficient scaling of large language models (LLMs) with sparsely activated experts dur...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 38. NOVER, a reinforcement learning framework that eliminates the need for external verifiers, enhances language model performance across text-to-text tasks.  					AI-generated summary 				 Recent advances such as DeepSeek R1-Zero highlight the effectiveness of incentive training, a reinforcement learni...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 39. A benchmark called TIME assesses temporal reasoning in LLMs across varied real-world challenges, including intensive temporal information, fast-changing event dynamics, and complex social interactions, and evaluates the impact of test-time scaling.  					AI-generated summary 				 Temporal reasoning ...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 40. FREESON, a novel framework that integrates retrieval and reasoning roles within LRMs using CT-MCTS, improves the performance of multistep reasoning models in QA tasks by reducing representation bottlenecks.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated remarkable ca...
[26.05.2025 15:12] ********************************************************************************
[26.05.2025 15:12] Abstract 41. Orthogonal Residual Updates enhance feature learning and training stability by decomposing module outputs to contribute primarily novel features.  					AI-generated summary 				 Residual connections are pivotal for deep neural networks, enabling greater depth by mitigating vanishing gradients. Howev...
[26.05.2025 15:12] Read previous papers.
[26.05.2025 15:12] Generating reviews via LLM API.
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#transfer_learning", "#architecture", "#benchmark", "#training"], "emoji": "📊", "ru": {"title": "TabSTAR: Умное представление текста для табличных данных", "desc": "TabSTAR - это новая модель машинного обучения для табличных данных с текстовыми признакам
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#training", "#long_context", "#optimization", "#benchmark", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "QwenLong-L1: Прорыв в обработке длинного контекста для моделей рассуждения", "desc": "QwenLong-L1 - это фреймворк, улучшающий модели крупномасштабного рассуждения (LRM) д
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#math", "#dataset", "#data", "#interpretability", "#reasoning"], "emoji": "🧠", "ru": {"title": "Преодоление жесткости мышления в ИИ: новый подход к диагностике языковых моделей", "desc": "Статья представляет диагностический набор для анализа и категоризации жесткости рассуждений в б
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#architecture", "#training", "#inference", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное обучение языковых моделей с помощью 4-битной точности", "desc": "Статья представляет Quartet - новый подход к обучению больших языковых моделей с использованием 4-битной точности 
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#rl", "#dataset", "#multimodal", "#optimization", "#training", "#open_source", "#reasoning"], "emoji": "🧠", "ru": {"title": "Единая система обучения с подкреплением для визуального ИИ", "desc": "V-Triune - это система обучения с подкреплением, объединяющая задачи визуального рассужд
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#math", "#small_models", "#agents", "#transfer_learning", "#training", "#hallucinations", "#reasoning"], "emoji": "🧠", "ru": {"title": "Передача навыков агента: от больших моделей к малым", "desc": "Метод Agent Distillation позволяет передавать навыки рассуждения и решения задач от 
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "PhyX: новый рубеж в оценке физического мышления ИИ", "desc": "Новый эталонный тест PhyX оценивает способность моделей к физически обоснованным рассуждениям в визуальных сценариях. Тест включает 3000 тщательно 
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#benchmark", "#training", "#long_context"], "emoji": "🧠", "ru": {"title": "Революционное улучшение обработки длинного контекста в нейросетях", "desc": "QwenLong-CPRS - это фреймворк для оптимизации контекста в больших языковых моделях. Он использует
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#video", "#optimization", "#cv", "#inference", "#diffusion", "#training"], "emoji": "🧬", "ru": {"title": "Эволюционный поиск для улучшения генеративных моделей", "desc": "EvoSearch - это новый метод тест-тайм скейлинга для генеративных моделей на основе диффузии и потоков. Он исполь
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#video", "#inference", "#diffusion", "#optimization"], "emoji": "🎬", "ru": {"title": "Умный выбор шума для лучшего видео-синтеза", "desc": "Статья представляет ANSE - метод улучшения видео-диффузионных моделей путем выбора начальных шумовых сидов на основе уверенности модели. В осно
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#math", "#optimization", "#inference", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эффективное сжатие цепочек рассуждений без потери точности", "desc": "VeriThinker - это новый подход к сжатию цепочек рассуждений в крупных моделях рассуждений (LRM). Метод использует д
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#science", "#optimization", "#data", "#dataset", "#benchmark"], "emoji": "🧪", "ru": {"title": "Симуляция экспериментов улучшает ранжирование научных гипотез", "desc": "Статья представляет новый метод ранжирования гипотез в научных исследованиях, основанный на результатах симулирован
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#hallucinations", "#benchmark", "#security", "#ethics", "#open_source", "#dataset", "#audio"], "emoji": "🎙️", "ru": {"title": "AudioTrust: Комплексная оценка надежности аудио ИИ", "desc": "AudioTrust - это первая многогранная система оценки надежности Аудио Больших Языковых Моделей 
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#games", "#multimodal", "#optimization", "#survey", "#benchmark"], "emoji": "🖥️", "ru": {"title": "FullFront: комплексная оценка MLLM в фронтенд-разработке", "desc": "FullFront - это комплексный бенчмарк для оценки мультимодальных языковых моделей (MLLM) в области фронтенд-разработк
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#alignment", "#benchmark", "#rlhf", "#training", "#hallucinations"], "emoji": "🔍", "ru": {"title": "Обучение LLM распознавать галлюцинации с помощью самих галлюцинаций", "desc": "Статья описывает новый метод улучшения способности больших языковых моделей (LLM) обнаруживать галлюцина
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#reasoning", "#training", "#interpretability", "#rl", "#rlhf"], "emoji": "🧠", "ru": {"title": "TAPO: Усиление обучения с подкреплением внешними мыслительными паттернами", "desc": "TAPO - это новая система обучения с подкреплением, которая включает внешние подсказки для улучшения про
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#dataset"], "emoji": "🌙", "ru": {"title": "Единый подход к восстановлению ночных изображений в сложных погодных условиях", "desc": "Статья представляет новый подход к восстановлению ночных изображений в различных погодных условиях. Авторы разработали датасет AllWeatherNight с
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#dataset", "#3d", "#training", "#optimization", "#diffusion"], "emoji": "🧊", "ru": {"title": "Революция в генерации 3D-объектов: эффективность и качество на новом уровне", "desc": "Статья представляет Direct3D S2 - масштабируемую систему для генерации 3D-объектов, использующую разре
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#rl", "#dataset", "#rlhf", "#optimization", "#training", "#synthetic"], "emoji": "🛶", "ru": {"title": "Достоверность без разметки: CANOE улучшает генерацию текста языковыми моделями", "desc": "CANOE - это новый подход к улучшению достоверности генерации текста языковыми моделями без
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#rl", "#optimization", "#dataset", "#training", "#benchmark", "#reasoning"], "emoji": "⏳", "ru": {"title": "Маленькая модель с большим чувством времени", "desc": "Статья представляет Time-R1 - новую систему для улучшения темпоральных способностей языковых моделей среднего размера. И
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#dataset", "#benchmark", "#diffusion"], "emoji": "🧠", "ru": {"title": "Классификаторы диффузии: композиционность с условиями", "desc": "Исследование классификаторов диффузии на различных наборах данных и задачах выявляет их композиционное понимание. Оно подчеркивает влияние с
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#multilingual", "#dataset", "#low_resource", "#data", "#synthetic", "#training", "#audio"], "emoji": "🗣️", "ru": {"title": "Голосовые ассистенты для редких языков: обучение без TTS", "desc": "Статья описывает новый подход к обучению голосовых ассистентов для языков с ограниченными р
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#games", "#multimodal", "#benchmark", "#open_source", "#reasoning"], "emoji": "🧠", "ru": {"title": "Новый вызов для ИИ: рассуждения с помощью зрения", "desc": "RBench-V - это новый бенчмарк для оценки способностей мультимодальных моделей к рассуждениям с использованием зрения. Он вк
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#healthcare", "#rag", "#rl", "#dataset", "#benchmark", "#reasoning", "#training", "#optimization"], "emoji": "🔍", "ru": {"title": "Эффективный поиск для RAG с минимальным обучением", "desc": "Предложена легковесная, модельно-агностичная система s3 для улучшения поиска информации в R
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#agi", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Trinity-RFT: универсальная платформа для дообучения языковых моделей", "desc": "Trinity-RFT - это гибкая и масштабируемая платформа для дообучения больших языковых моделей с помощью обучения с подкр
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#architecture", "#transfer_learning", "#training"], "emoji": "🚀", "ru": {"title": "Transformer Copilot: Учимся на ошибках для повышения эффективности ИИ", "desc": "Представлена новая архитектура Transformer Copilot, которая улучшает работу больших язык
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#security", "#ethics", "#benchmark", "#multimodal"], "emoji": "🛡️", "ru": {"title": "Мемы vs ИИ: неожиданная угроза безопасности визуально-языковых моделей", "desc": "Исследование показывает, что визуально-языковые модели (VLM) более уязвимы к вредоносным мемам, чем к синтетическим 
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#optimization", "#training", "#synthetic"], "emoji": "🤖", "ru": {"title": "Усиление языковых моделей без человеческих данных", "desc": "Статья представляет новый метод под названием Synthetic Data RL, который улучшает языковые модели с помощью обучения с подкрепление
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#rl", "#rag", "#optimization", "#reasoning", "#training"], "emoji": "🎨", "ru": {"title": "Умное улучшение промптов для более точной генерации изображений", "desc": "RePrompt - это новая система для улучшения генерации изображений по текстовому описанию, использующая обучение 
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#optimization", "#architecture", "#transfer_learning", "#audio"], "emoji": "🧠", "ru": {"title": "Языковые модели обретают зрение и слух через чтение", "desc": "Исследование показывает, что авторегрессионные языковые модели, обученные на текстовых данных, способ
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#optimization", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Регуляризация градиента политики для улучшения рассуждений языковых моделей", "desc": "Статья представляет новый фреймворк под названием RPG (regularized policy gradient) для улучшения способн
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#alignment", "#reasoning", "#rl", "#hallucinations", "#agents"], "emoji": "🧠", "ru": {"title": "ReflAct: Рефлексия для надежных ИИ-агентов", "desc": "ReflAct - это новый подход к построению рассуждений для агентов на основе больших языковых моделей (LLM). Он улучшает согласованность
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#games", "#training", "#optimization", "#rlhf", "#multimodal", "#rl", "#transfer_learning"], "emoji": "🤖", "ru": {"title": "Эффективное пост-обучение VLA моделей с минимальным надзором", "desc": "RIPT-VLA - это новая парадигма пост-обучения моделей зрения-языка-действия (VLA) с испо
[26.05.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#games", "#video", "#diffusion", "#robotics", "#dataset", "#benchmark"], "emoji": "💃", "ru": {"title": "Революция в генерации видео: от хореографии к многоактерному взаимодействию", "desc": "DanceTogether - это новая система генерации видео на основе диффузионной модели. Она 
[26.05.2025 15:12] Querying the API.
[26.05.2025 15:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models exhibit positional bias -- systematic neglect of information at specific context positions -- yet its interplay with linguistic diversity remains poorly understood. We present a cross-linguistic study across five typologically distinct languages (English, Russian, German, Hindi, Vietnamese), examining how positional bias interacts with model uncertainty, syntax, and prompting. Key findings: (1) Positional bias is model-driven, with language-specific variations -- Qwen2.5-7B favors late positions, challenging assumptions of early-token bias; (2) Explicit positional guidance (e.g., correct context is at position X) reduces accuracy across languages, undermining prompt-engineering practices; (3) Aligning context with positional bias increases entropy, yet minimal entropy does not predict accuracy. (4) We further uncover that LLMs differently impose dominant word order in free-word-order languages like Hindi.
[26.05.2025 15:13] Response: {
  "desc": "Статья исследует позиционное смещение в больших языковых моделях на примере пяти типологически различных языков. Авторы обнаружили, что позиционное смещение зависит от модели, а не от языка, причем модель Qwen2.5-7B отдает предпочтение поздним позициям. Исследование показало, что явные позиционные указания снижают точность модели, а выравнивание контекста с позиционным смещением увеличивает энтропию. Также было выявлено, что нейросети по-разному навязывают доминирующий порядок слов в языках со свободным порядком слов.",
  "emoji": "🧠",
  "title": "Позиционное смещение в нейросетях: влияние на разные языки"
}
[26.05.2025 15:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models exhibit positional bias -- systematic neglect of information at specific context positions -- yet its interplay with linguistic diversity remains poorly understood. We present a cross-linguistic study across five typologically distinct languages (English, Russian, German, Hindi, Vietnamese), examining how positional bias interacts with model uncertainty, syntax, and prompting. Key findings: (1) Positional bias is model-driven, with language-specific variations -- Qwen2.5-7B favors late positions, challenging assumptions of early-token bias; (2) Explicit positional guidance (e.g., correct context is at position X) reduces accuracy across languages, undermining prompt-engineering practices; (3) Aligning context with positional bias increases entropy, yet minimal entropy does not predict accuracy. (4) We further uncover that LLMs differently impose dominant word order in free-word-order languages like Hindi."

[26.05.2025 15:13] Response: ```python
['MULTILINGUAL']
```
[26.05.2025 15:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models exhibit positional bias -- systematic neglect of information at specific context positions -- yet its interplay with linguistic diversity remains poorly understood. We present a cross-linguistic study across five typologically distinct languages (English, Russian, German, Hindi, Vietnamese), examining how positional bias interacts with model uncertainty, syntax, and prompting. Key findings: (1) Positional bias is model-driven, with language-specific variations -- Qwen2.5-7B favors late positions, challenging assumptions of early-token bias; (2) Explicit positional guidance (e.g., correct context is at position X) reduces accuracy across languages, undermining prompt-engineering practices; (3) Aligning context with positional bias increases entropy, yet minimal entropy does not predict accuracy. (4) We further uncover that LLMs differently impose dominant word order in free-word-order languages like Hindi."

[26.05.2025 15:13] Response: ```python
['HALLUCINATIONS', 'ALIGNMENT']
```
[26.05.2025 15:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how large language models (LLMs) show positional bias, which means they often ignore information based on where it appears in a sentence. The study looks at five different languages to see how this bias interacts with factors like model uncertainty and syntax. It finds that the bias varies by language and that giving explicit positional hints can actually lower accuracy. Additionally, the research reveals that LLMs handle word order differently in languages that allow more flexibility, such as Hindi.","title":"Understanding Positional Bias in Multilingual Contexts"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates how large language models (LLMs) show positional bias, which means they often ignore information based on where it appears in a sentence. The study looks at five different languages to see how this bias interacts with factors like model uncertainty and syntax. It finds that the bias varies by language and that giving explicit positional hints can actually lower accuracy. Additionally, the research reveals that LLMs handle word order differently in languages that allow more flexibility, such as Hindi.', title='Understanding Positional Bias in Multilingual Contexts'))
[26.05.2025 15:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文研究了大型语言模型中的位置偏见，即在特定上下文位置上系统性忽视信息的现象。研究涵盖了五种不同类型的语言（英语、俄语、德语、印地语和越南语），探讨了位置偏见与模型不确定性、句法和提示之间的相互作用。主要发现包括：位置偏见是由模型驱动的，并且在不同语言中存在特定的变化；明确的位置信息指导会降低各语言的准确性，挑战了提示工程的假设。","title":"揭示大型语言模型中的位置偏见与语言多样性的关系"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文研究了大型语言模型中的位置偏见，即在特定上下文位置上系统性忽视信息的现象。研究涵盖了五种不同类型的语言（英语、俄语、德语、印地语和越南语），探讨了位置偏见与模型不确定性、句法和提示之间的相互作用。主要发现包括：位置偏见是由模型驱动的，并且在不同语言中存在特定的变化；明确的位置信息指导会降低各语言的准确性，挑战了提示工程的假设。', title='揭示大型语言模型中的位置偏见与语言多样性的关系'))
[26.05.2025 15:13] Using data from previous issue: {"categories": ["#leakage", "#multimodal", "#alignment", "#security", "#dataset", "#benchmark"], "emoji": "🔐", "ru": {"title": "LLM нарушают политики безопасности: urgent call для улучшения защиты данных", "desc": "Это исследование посвящено проблеме нарушения большими языковыми моделями (LLM) конте
[26.05.2025 15:13] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#multimodal", "#rag", "#long_context"], "emoji": "📝", "ru": {"title": "Усиление итеративного RAG через генерацию кратких заметок", "desc": "Статья предлагает метод Notes Writing для улучшения итеративного RAG в задачах ответов на многоэтапные вопросы. 
[26.05.2025 15:13] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization", "#architecture"], "emoji": "🧠", "ru": {"title": "Оптимизация MoE моделей: ключ к эффективному масштабированию LLM", "desc": "Статья исследует эффективность масштабирования больших языковых моделей (LLM) с использованием архитектуры Mixture-
[26.05.2025 15:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#rlhf", "#reasoning"], "emoji": "🧠", "ru": {"title": "NOVER: обучение с подкреплением без верификаторов для улучшения языковых моделей", "desc": "NOVER - это новая система обучения с подкреплением для языковых моделей, которая не требует внешних 
[26.05.2025 15:13] Using data from previous issue: {"categories": ["#dataset", "#survey", "#reasoning", "#benchmark", "#open_source"], "emoji": "⏳", "ru": {"title": "TIME: Комплексная оценка темпорального рассуждения в LLM", "desc": "Статья представляет новый бенчмарк TIME для оценки темпорального рассуждения в больших языковых моделях (LLM). Бенчма
[26.05.2025 15:13] Querying the API.
[26.05.2025 15:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FREESON, a novel framework that integrates retrieval and reasoning roles within LRMs using CT-MCTS, improves the performance of multistep reasoning models in QA tasks by reducing representation bottlenecks.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in multi-step reasoning and calling search engines at appropriate steps. However, existing retrieval-augmented reasoning approaches rely on separate retrieval models, limiting the LRM's role in retrieval to deciding when to retrieve and how to query. This separation not only increases hardware and operational costs but also leads to errors in the retrieval process due to the representation bottleneck, a phenomenon where the retriever's embedding space is not expressive enough to meet the generator's requirements. To address this, we shift our perspective from sequence-to-sequence matching to locating the answer-containing paths within the corpus, and propose a novel framework called FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables LRMs to retrieve relevant knowledge on their own by acting as both a generator and retriever. To achieve this, we introduce a variant of the MCTS algorithm specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus toward answer-containing regions. Our results on five open-domain QA benchmarks, including single-hop and multi-hop questions, show that FREESON achieves an average improvement of 14.4% in EM and F1 over four multi-step reasoning models with a separate retriever, and it also performs comparably to the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.
[26.05.2025 15:13] Response: {
  "desc": "FREESON - это новая система, которая объединяет функции поиска и рассуждения в крупных моделях рассуждений (LRM) с использованием алгоритма CT-MCTS. Она улучшает производительность моделей многоступенчатого рассуждения в задачах вопросно-ответных систем, уменьшая проблему узкого места представления. FREESON позволяет LRM самостоятельно извлекать релевантные знания, выступая одновременно в роли генератора и поисковика. Система показала значительное улучшение точности на нескольких эталонных наборах данных для открытых вопросно-ответных систем.",
  "emoji": "🧠",
  "title": "FREESON: Объединение поиска и рассуждений в единой модели для улучшения вопросно-ответных систем"
}
[26.05.2025 15:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FREESON, a novel framework that integrates retrieval and reasoning roles within LRMs using CT-MCTS, improves the performance of multistep reasoning models in QA tasks by reducing representation bottlenecks.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in multi-step reasoning and calling search engines at appropriate steps. However, existing retrieval-augmented reasoning approaches rely on separate retrieval models, limiting the LRM's role in retrieval to deciding when to retrieve and how to query. This separation not only increases hardware and operational costs but also leads to errors in the retrieval process due to the representation bottleneck, a phenomenon where the retriever's embedding space is not expressive enough to meet the generator's requirements. To address this, we shift our perspective from sequence-to-sequence matching to locating the answer-containing paths within the corpus, and propose a novel framework called FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables LRMs to retrieve relevant knowledge on their own by acting as both a generator and retriever. To achieve this, we introduce a variant of the MCTS algorithm specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus toward answer-containing regions. Our results on five open-domain QA benchmarks, including single-hop and multi-hop questions, show that FREESON achieves an average improvement of 14.4% in EM and F1 over four multi-step reasoning models with a separate retriever, and it also performs comparably to the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA."

[26.05.2025 15:13] Response: ```python
["RAG", "MULTIMODAL"]
```
[26.05.2025 15:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FREESON, a novel framework that integrates retrieval and reasoning roles within LRMs using CT-MCTS, improves the performance of multistep reasoning models in QA tasks by reducing representation bottlenecks.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in multi-step reasoning and calling search engines at appropriate steps. However, existing retrieval-augmented reasoning approaches rely on separate retrieval models, limiting the LRM's role in retrieval to deciding when to retrieve and how to query. This separation not only increases hardware and operational costs but also leads to errors in the retrieval process due to the representation bottleneck, a phenomenon where the retriever's embedding space is not expressive enough to meet the generator's requirements. To address this, we shift our perspective from sequence-to-sequence matching to locating the answer-containing paths within the corpus, and propose a novel framework called FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables LRMs to retrieve relevant knowledge on their own by acting as both a generator and retriever. To achieve this, we introduce a variant of the MCTS algorithm specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus toward answer-containing regions. Our results on five open-domain QA benchmarks, including single-hop and multi-hop questions, show that FREESON achieves an average improvement of 14.4% in EM and F1 over four multi-step reasoning models with a separate retriever, and it also performs comparably to the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA."

[26.05.2025 15:13] Response: ```python
["REASONING"]
```
[26.05.2025 15:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FREESON is a new framework that enhances Large Reasoning Models (LRMs) by integrating retrieval and reasoning tasks using a specialized algorithm called CT-MCTS. This approach allows LRMs to independently retrieve relevant information while generating answers, eliminating the need for separate retrieval models. By addressing the representation bottleneck, FREESON improves the efficiency and accuracy of multi-step reasoning in question-answering tasks. The framework has shown significant performance gains on various QA benchmarks, outperforming traditional models that rely on separate retrieval systems.","title":"FREESON: Unifying Retrieval and Reasoning for Enhanced QA Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FREESON is a new framework that enhances Large Reasoning Models (LRMs) by integrating retrieval and reasoning tasks using a specialized algorithm called CT-MCTS. This approach allows LRMs to independently retrieve relevant information while generating answers, eliminating the need for separate retrieval models. By addressing the representation bottleneck, FREESON improves the efficiency and accuracy of multi-step reasoning in question-answering tasks. The framework has shown significant performance gains on various QA benchmarks, outperforming traditional models that rely on separate retrieval systems.', title='FREESON: Unifying Retrieval and Reasoning for Enhanced QA Performance'))
[26.05.2025 15:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FREESON是一个新颖的框架，它将检索和推理的角色整合在大型推理模型（LRMs）中，使用CT-MCTS算法来提升多步推理模型在问答任务中的表现。传统的检索增强推理方法依赖于独立的检索模型，这限制了LRM在检索中的作用，并导致表示瓶颈的问题。FREESON通过让LRM同时作为生成器和检索器，能够自主检索相关知识，从而减少了硬件和操作成本。实验结果表明，FREESON在多个开放域问答基准上平均提高了14.4%的表现，显示出其在多步推理任务中的有效性。","title":"FREESON：整合检索与推理的创新框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FREESON是一个新颖的框架，它将检索和推理的角色整合在大型推理模型（LRMs）中，使用CT-MCTS算法来提升多步推理模型在问答任务中的表现。传统的检索增强推理方法依赖于独立的检索模型，这限制了LRM在检索中的作用，并导致表示瓶颈的问题。FREESON通过让LRM同时作为生成器和检索器，能够自主检索相关知识，从而减少了硬件和操作成本。实验结果表明，FREESON在多个开放域问答基准上平均提高了14.4%的表现，显示出其在多步推理任务中的有效性。', title='FREESON：整合检索与推理的创新框架'))
[26.05.2025 15:13] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Ортогональность для инноваций: новый подход к остаточным связям", "desc": "Статья представляет новый метод под названием 'Ортогональное Остаточное Обновление' для улучшения обучения глубоких нейронных сете
[26.05.2025 15:13] Loading Chinese text from previous data.
[26.05.2025 15:13] Renaming data file.
[26.05.2025 15:13] Renaming previous data. hf_papers.json to ./d/2025-05-26.json
[26.05.2025 15:13] Saving new data file.
[26.05.2025 15:13] Generating page.
[26.05.2025 15:13] Renaming previous page.
[26.05.2025 15:13] Renaming previous data. index.html to ./d/2025-05-26.html
[26.05.2025 15:13] [Experimental] Generating Chinese page for reading.
[26.05.2025 15:13] Chinese vocab [{'word': '迁移学习', 'pinyin': 'qiān yí xué xí', 'trans': 'transfer learning'}, {'word': '分类任务', 'pinyin': 'fēn lèi rèn wù', 'trans': 'classification task'}, {'word': '参数', 'pinyin': 'cān shǔ', 'trans': 'parameter'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-training'}, {'word': '文本编码器', 'pinyin': 'wén běn biān mǎ qì', 'trans': 'text encoder'}, {'word': '目标令牌', 'pinyin': 'mù biāo lìng pái', 'trans': 'target token'}, {'word': '嵌入', 'pinyin': 'qiàn rù', 'trans': 'embedding'}, {'word': '表现出色', 'pinyin': 'biǎo xiàn chū sè', 'trans': 'perform excellently'}, {'word': '扩展规律', 'pinyin': 'kuò zhǎn guī lǜ', 'trans': 'expansion pattern'}]
[26.05.2025 15:13] Renaming previous Chinese page.
[26.05.2025 15:13] Renaming previous data. zh.html to ./d/2025-05-25_zh_reading_task.html
[26.05.2025 15:13] Writing Chinese reading task.
[26.05.2025 15:13] Writing result.
[26.05.2025 15:13] Renaming log file.
[26.05.2025 15:13] Renaming previous data. log.txt to ./logs/2025-05-26_last_log.txt
