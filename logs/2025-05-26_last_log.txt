[26.05.2025 09:47] Read previous papers.
[26.05.2025 09:47] Generating top page (month).
[26.05.2025 09:47] Writing top page (month).
[26.05.2025 10:16] Read previous papers.
[26.05.2025 10:16] Get feed.
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18125
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17667
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17612
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15929
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18129
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18092
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17225
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17941
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17561
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17873
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16211
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17618
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15692
[26.05.2025 10:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.14669
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17399
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17558
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16479
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16483
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13508
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17417
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16770
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15389
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17826
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17508
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17412
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17091
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16270
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17063
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17540
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17016
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16293
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16022
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15805
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12891
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16056
[26.05.2025 10:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11881
[26.05.2025 10:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.05.2025 10:16] No deleted papers detected.
[26.05.2025 10:16] Downloading and parsing papers (pdf, html). Total: 36.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.18125.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.18125.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.18125.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17667.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17667.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17667.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17612.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17612.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17612.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.15929.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.15929.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.15929.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.18129.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.18129.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.18129.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.18092.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.18092.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.18092.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17225.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17225.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17225.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17941.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17941.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17941.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17561.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17561.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17561.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17873.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17873.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17873.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16211.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16211.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16211.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17618.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17618.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17618.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.15692.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.15692.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.15692.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.14669.
[26.05.2025 10:16] Downloading paper 2505.14669 from http://arxiv.org/pdf/2505.14669v1...
[26.05.2025 10:16] Extracting affiliations from text.
[26.05.2025 10:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 2 ] . [ 1 9 6 6 4 1 . 5 0 5 2 : r Quartet: Native FP4 Training Can Be Optimal for Large Language Models Roberto L. Castro ISTA Andrei Panferov ISTA Oliver Sieberling ETH Zürich Saleh Ashkboos ETH Zürich Dan Alistarh ISTA & Red Hat AI "
[26.05.2025 10:16] Response: ```python
["ISTA", "ETH Zürich", "ISTA & Red Hat AI"]
```
[26.05.2025 10:16] Deleting PDF ./assets/pdf/2505.14669.pdf.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17399.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17399.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17399.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17558.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17558.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17558.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16479.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16479.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16479.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16483.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16483.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16483.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.13508.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.13508.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.13508.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17417.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17417.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17417.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16770.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16770.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16770.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.15389.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.15389.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.15389.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17826.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17826.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17826.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17508.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17508.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17508.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17412.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17412.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17412.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17091.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17091.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17091.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16270.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16270.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16270.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17063.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17063.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17063.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17540.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17540.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17540.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.17016.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.17016.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.17016.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16293.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16293.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16293.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16022.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16022.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16022.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.15805.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.15805.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.15805.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.12891.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.12891.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.12891.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.16056.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.16056.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.16056.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Downloading and parsing paper https://huggingface.co/papers/2505.11881.
[26.05.2025 10:16] Extra JSON file exists (./assets/json/2505.11881.json), skip PDF parsing.
[26.05.2025 10:16] Paper image links file exists (./assets/img_data/2505.11881.json), skip HTML parsing.
[26.05.2025 10:16] Success.
[26.05.2025 10:16] Enriching papers with extra data.
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 0. TabSTAR, a tabular foundation model with semantically target-aware representations, achieves state-of-the-art performance in classification tasks with text features through transfer learning without dataset-specific parameters.  					AI-generated summary 				 While deep learning has achieved remarka...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 1. A framework called QwenLong-L1 enhances large reasoning models for long-context reasoning through reinforcement learning, achieving leading performance on document question-answering benchmarks.  					AI-generated summary 				 Recent large reasoning models (LRMs) have demonstrated strong reasoning c...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 2. Agent Distillation transfers reasoning and task-solving capabilities from large language models to smaller models using enhanced prompts and self-consistent actions, matching performance of larger models on various reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) excel a...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 3. A new benchmark, PhyX, evaluates models' physics-grounded reasoning in visual scenarios, revealing significant limitations in current models' physical understanding compared to human experts.  					AI-generated summary 				 Existing benchmarks fail to capture a crucial aspect of intelligence: physic...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 4. A unified reinforcement learning system, V-Triune, combines visual reasoning and perception tasks in vision-language models through a single training pipeline, achieving significant improvements across various tasks.  					AI-generated summary 				 Reinforcement learning (RL) has significantly advan...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 5. QwenLong-CPRS enhances large language models with multi-granularity context compression, dynamic optimization guided by natural language, and efficient bidirectional reasoning and parallel inference, achieving superior performance and context management.  					AI-generated summary 				 This technica...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 6. A diagnostic set examines and categorizes reasoning rigidity in large language models, identifying patterns where models ignore instructions and default to familiar reasoning.  					AI-generated summary 				 Large language models have demonstrated remarkable proficiency in long and complex reasoning...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 7. VeriThinker reduces the length of complex reasoning chains in Large Reasoning Models (LRMs) by fine-tuning them on a verification task, thereby decreasing inference costs without significantly sacrificing accuracy.  					AI-generated summary 				 Large Reasoning Models (LRMs) excel at complex tasks ...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 8. ANSE enhances video diffusion models by selecting noise seeds based on model confidence, improving video quality and temporal coherence with minimal increase in inference time.  					AI-generated summary 				 The choice of initial noise significantly affects the quality and prompt alignment of video...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 9. A novel simulator and experiment-guided ranking method improve hypothesis prioritization in scientific discovery by incorporating simulated experimental outcomes.  					AI-generated summary 				 Hypothesis ranking is a crucial component of automated scientific discovery, particularly in natural scie...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 10. AudioTrust evaluates the trustworthiness of Audio Large Language Models across multifaceted dimensions, using a comprehensive dataset and specific metrics to assess their performance in real-world audio scenarios.  					AI-generated summary 				 The rapid advancement and expanding applications of Au...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 11. EvoSearch, an evolutionary search method, enhances test-time scaling for diffusion and flow-based generative models, improving image and video generation quality, diversity, and generalizability.  					AI-generated summary 				 As the marginal cost of scaling computation (data and parameters) during...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 12. A novel RL framework, TAPO, integrates external guidance to enhance model performance and exploration compared to existing methods.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as an effective method for training reasoning models. However, existing RL approaches typically ...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 13. Quartet, a hardware-supported FP4 training approach for large language models, demonstrates state-of-the-art accuracy while significantly reducing computational costs compared to standard or FP8 precision.  					AI-generated summary 				 The rapid advancement of large language models (LLMs) has been...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 14. FullFront is a benchmark evaluating Multimodal Large Language Models across conceptualization, comprehension, and implementation phases in front-end engineering.  					AI-generated summary 				 Front-end engineering involves a complex workflow where engineers conceptualize designs, translate them in...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 15. The use of carefully crafted hallucinations in a curriculum learning approach within the DPO alignment procedure significantly enhances LLMs' hallucination detection abilities.  					AI-generated summary 				 Aligning large language models (LLMs) to accurately detect hallucinations remains a signifi...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 16. A unified framework for restoring nighttime images under diverse weather conditions using dual priors and adaptive collaboration.  					AI-generated summary 				 Restoring nighttime images affected by multiple adverse weather conditions is a practical yet under-explored research problem, as multiple...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 17. CANOE improves LLM faithfulness in generation tasks using synthetic QA data and Dual-GRPO reinforcement learning without human annotations.  					AI-generated summary 				 Teaching large language models (LLMs) to be faithful in the provided context is crucial for building reliable information-seekin...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 18. A novel framework, Time-R1, enhances moderate-sized LLMs with comprehensive temporal abilities through a reinforcement learning curriculum, outperforming larger models on future event prediction and creative scenario generation benchmarks.  					AI-generated summary 				 Large Language Models (LLMs)...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 19. The rapid growth of voice assistants powered by large language models (LLM) has highlighted a need for speech instruction data to train these systems. Despite the abundance of speech recognition data, there is a notable scarcity of speech instruction data, which is essential for fine-tuning models t...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 20. A benchmark called RBench-V evaluates multi-modal models' vision-indispensable reasoning through image manipulation and auxiliary line construction, demonstrating that current models struggle with multi-modal outputs.  					AI-generated summary 				 The rapid advancement of native multi-modal models...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 21. VLMs are more vulnerable to harmful meme-based prompts than to synthetic images, and while multi-turn interactions offer some protection, significant vulnerabilities remain.  					AI-generated summary 				 Rapid deployment of vision-language models (VLMs) magnifies safety risks, yet most evaluations...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 22. Trinity-RFT is a flexible and scalable framework for reinforcement fine-tuning of large language models, supporting various interaction modes and data pipelines.  					AI-generated summary 				 Trinity-RFT is a general-purpose, flexible and scalable framework designed for reinforcement fine-tuning (...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 23. A regularized policy gradient framework is introduced to explore KL divergence formulations for enhancing the reasoning capabilities of LLMs in online reinforcement learning, demonstrating improved training stability and performance.  					AI-generated summary 				 Policy gradient algorithms have be...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 24. A scalable 3D shape generation framework using sparse volumes and spatial sparse attention, enabling high-resolution generation with reduced computational requirements.  					AI-generated summary 				 Generating high resolution 3D shapes using volumetric representations such as Signed Distance Funct...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 25. Auto-regressive text LLMs trained on text can develop internal capabilities for understanding images and audio, enabling them to perform classification tasks across different modalities without fine-tuning.  					AI-generated summary 				 This paper presents a fascinating find: By training an auto-r...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 26. The Transformer Copilot framework enhances large language model performance through a Copilot model that refines the Pilot's logits based on a Mistake Log, leading to consistent performance improvements across various benchmarks.  					AI-generated summary 				 Large language models are typically ad...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 27. Synthetic Data RL enhances foundation models through reinforcement learning using only synthetic data, achieving performance comparable to models trained with full human-labeled data.  					AI-generated summary 				 Reinforcement learning (RL) is a powerful way to adapt foundation models to speciali...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 28. RePrompt, a reprompting framework using reinforcement learning, enhances text-to-image generation by optimizing for image-level outcomes, significantly improving spatial layout and compositional generalization.  					AI-generated summary 				 Despite recent progress in text-to-image (T2I) generation...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 29. We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based interactive post-training paradigm that fine-tunes pretrained Vision-Language-Action (VLA) models using only sparse binary success rewards. Existing VLA training pipelines rely heavily on offline expert demonstration data and ...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 30. Notes Writing enhances iterative RAG by generating concise notes at each step, improving reasoning and performance while minimizing output increase.  					AI-generated summary 				 Iterative RAG for multi-hop question answering faces challenges with lengthy contexts and the buildup of irrelevant inf...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 31. NOVER, a reinforcement learning framework that eliminates the need for external verifiers, enhances language model performance across text-to-text tasks.  					AI-generated summary 				 Recent advances such as DeepSeek R1-Zero highlight the effectiveness of incentive training, a reinforcement learni...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 32. LLMs frequently violate contextual security policies by leaking sensitive information, particularly under indirect attacks, indicating a critical gap in current safety mechanisms.  					AI-generated summary 				 As Large Language Models (LLMs) are increasingly deployed in sensitive domains such as e...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 33. A benchmark called TIME assesses temporal reasoning in LLMs across varied real-world challenges, including intensive temporal information, fast-changing event dynamics, and complex social interactions, and evaluates the impact of test-time scaling.  					AI-generated summary 				 Temporal reasoning ...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 34. MoE models achieve efficient scaling in LLMs with expert offloading, emphasizing the importance of local routing consistency and cache effectiveness.  					AI-generated summary 				 Mixture-of-Experts (MoE) enables efficient scaling of large language models (LLMs) with sparsely activated experts dur...
[26.05.2025 10:16] ********************************************************************************
[26.05.2025 10:16] Abstract 35. Orthogonal Residual Updates enhance feature learning and training stability by decomposing module outputs to contribute primarily novel features.  					AI-generated summary 				 Residual connections are pivotal for deep neural networks, enabling greater depth by mitigating vanishing gradients. Howev...
[26.05.2025 10:16] Read previous papers.
[26.05.2025 10:16] Generating reviews via LLM API.
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#transfer_learning", "#architecture", "#benchmark", "#training"], "emoji": "📊", "ru": {"title": "TabSTAR: Умное представление текста для табличных данных", "desc": "TabSTAR - это новая модель машинного обучения для табличных данных с текстовыми признакам
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#training", "#long_context", "#optimization", "#benchmark", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "QwenLong-L1: Прорыв в обработке длинного контекста для моделей рассуждения", "desc": "QwenLong-L1 - это фреймворк, улучшающий модели крупномасштабного рассуждения (LRM) д
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#math", "#small_models", "#agents", "#transfer_learning", "#training", "#hallucinations", "#reasoning"], "emoji": "🧠", "ru": {"title": "Передача навыков агента: от больших моделей к малым", "desc": "Метод Agent Distillation позволяет передавать навыки рассуждения и решения задач от 
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "PhyX: новый рубеж в оценке физического мышления ИИ", "desc": "Новый эталонный тест PhyX оценивает способность моделей к физически обоснованным рассуждениям в визуальных сценариях. Тест включает 3000 тщательно 
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#rl", "#dataset", "#multimodal", "#optimization", "#training", "#open_source", "#reasoning"], "emoji": "🧠", "ru": {"title": "Единая система обучения с подкреплением для визуального ИИ", "desc": "V-Triune - это система обучения с подкреплением, объединяющая задачи визуального рассужд
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#benchmark", "#training", "#long_context"], "emoji": "🧠", "ru": {"title": "Революционное улучшение обработки длинного контекста в нейросетях", "desc": "QwenLong-CPRS - это фреймворк для оптимизации контекста в больших языковых моделях. Он использует
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#math", "#dataset", "#data", "#interpretability", "#reasoning"], "emoji": "🧠", "ru": {"title": "Преодоление жесткости мышления в ИИ: новый подход к диагностике языковых моделей", "desc": "Статья представляет диагностический набор для анализа и категоризации жесткости рассуждений в б
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#math", "#optimization", "#inference", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эффективное сжатие цепочек рассуждений без потери точности", "desc": "VeriThinker - это новый подход к сжатию цепочек рассуждений в крупных моделях рассуждений (LRM). Метод использует д
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#video", "#inference", "#diffusion", "#optimization"], "emoji": "🎬", "ru": {"title": "Умный выбор шума для лучшего видео-синтеза", "desc": "Статья представляет ANSE - метод улучшения видео-диффузионных моделей путем выбора начальных шумовых сидов на основе уверенности модели. В осно
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#science", "#optimization", "#data", "#dataset", "#benchmark"], "emoji": "🧪", "ru": {"title": "Симуляция экспериментов улучшает ранжирование научных гипотез", "desc": "Статья представляет новый метод ранжирования гипотез в научных исследованиях, основанный на результатах симулирован
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#hallucinations", "#benchmark", "#security", "#ethics", "#open_source", "#dataset", "#audio"], "emoji": "🎙️", "ru": {"title": "AudioTrust: Комплексная оценка надежности аудио ИИ", "desc": "AudioTrust - это первая многогранная система оценки надежности Аудио Больших Языковых Моделей 
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#video", "#optimization", "#cv", "#inference", "#diffusion", "#training"], "emoji": "🧬", "ru": {"title": "Эволюционный поиск для улучшения генеративных моделей", "desc": "EvoSearch - это новый метод тест-тайм скейлинга для генеративных моделей на основе диффузии и потоков. Он исполь
[26.05.2025 10:16] Using data from previous issue: {"categories": ["#reasoning", "#training", "#interpretability", "#rl", "#rlhf"], "emoji": "🧠", "ru": {"title": "TAPO: Усиление обучения с подкреплением внешними мыслительными паттернами", "desc": "TAPO - это новая система обучения с подкреплением, которая включает внешние подсказки для улучшения про
[26.05.2025 10:16] Querying the API.
[26.05.2025 10:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Quartet, a hardware-supported FP4 training approach for large language models, demonstrates state-of-the-art accuracy while significantly reducing computational costs compared to standard or FP8 precision.  					AI-generated summary 				 The rapid advancement of large language models (LLMs) has been paralleled by unprecedented increases in computational demands, with training costs for state-of-the-art models doubling every few months. Training models directly in low-precision arithmetic offers a solution, by improving both computational throughput and energy efficiency. Specifically, NVIDIA's recent Blackwell architecture facilitates extremely low-precision operations, specifically FP4 variants, promising substantial efficiency gains. Yet, current algorithms for training LLMs in FP4 precision face significant accuracy degradation and often rely on mixed-precision fallbacks. In this paper, we systematically investigate hardware-supported FP4 training and introduce Quartet, a new approach enabling accurate, end-to-end FP4 training with all the major computations (in e.g. linear layers) being performed in low precision. Through extensive evaluations on Llama-type models, we reveal a new low-precision scaling law that quantifies performance trade-offs across varying bit-widths and allows us to identify a "near-optimal" low-precision training technique in terms of accuracy-vs-computation, called Quartet. We implement Quartet using optimized CUDA kernels tailored for NVIDIA Blackwell GPUs, and show that it can achieve state-of-the-art accuracy for FP4 precision, successfully training billion-scale models. Our method demonstrates that fully FP4-based training is a competitive alternative to standard-precision and FP8 training. Our code is available at https://github.com/IST-DASLab/Quartet.
[26.05.2025 10:17] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#games", "#multimodal", "#optimization", "#survey", "#benchmark"], "emoji": "🖥️", "ru": {"title": "FullFront: комплексная оценка MLLM в фронтенд-разработке", "desc": "FullFront - это комплексный бенчмарк для оценки мультимодальных языковых моделей (MLLM) в области фронтенд-разработк
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#alignment", "#benchmark", "#rlhf", "#training", "#hallucinations"], "emoji": "🔍", "ru": {"title": "Обучение LLM распознавать галлюцинации с помощью самих галлюцинаций", "desc": "Статья описывает новый метод улучшения способности больших языковых моделей (LLM) обнаруживать галлюцина
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#cv", "#dataset"], "emoji": "🌙", "ru": {"title": "Единый подход к восстановлению ночных изображений в сложных погодных условиях", "desc": "Статья представляет новый подход к восстановлению ночных изображений в различных погодных условиях. Авторы разработали датасет AllWeatherNight с
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#rl", "#dataset", "#rlhf", "#optimization", "#training", "#synthetic"], "emoji": "🛶", "ru": {"title": "Достоверность без разметки: CANOE улучшает генерацию текста языковыми моделями", "desc": "CANOE - это новый подход к улучшению достоверности генерации текста языковыми моделями без
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#rl", "#optimization", "#dataset", "#training", "#benchmark", "#reasoning"], "emoji": "⏳", "ru": {"title": "Маленькая модель с большим чувством времени", "desc": "Статья представляет Time-R1 - новую систему для улучшения темпоральных способностей языковых моделей среднего размера. И
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#multilingual", "#dataset", "#low_resource", "#data", "#synthetic", "#training", "#audio"], "emoji": "🗣️", "ru": {"title": "Голосовые ассистенты для редких языков: обучение без TTS", "desc": "Статья описывает новый подход к обучению голосовых ассистентов для языков с ограниченными р
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#games", "#multimodal", "#benchmark", "#open_source", "#reasoning"], "emoji": "🧠", "ru": {"title": "Новый вызов для ИИ: рассуждения с помощью зрения", "desc": "RBench-V - это новый бенчмарк для оценки способностей мультимодальных моделей к рассуждениям с использованием зрения. Он вк
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#security", "#ethics", "#benchmark", "#multimodal"], "emoji": "🛡️", "ru": {"title": "Мемы vs ИИ: неожиданная угроза безопасности визуально-языковых моделей", "desc": "Исследование показывает, что визуально-языковые модели (VLM) более уязвимы к вредоносным мемам, чем к синтетическим 
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#agi", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Trinity-RFT: универсальная платформа для дообучения языковых моделей", "desc": "Trinity-RFT - это гибкая и масштабируемая платформа для дообучения больших языковых моделей с помощью обучения с подкр
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#optimization", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Регуляризация градиента политики для улучшения рассуждений языковых моделей", "desc": "Статья представляет новый фреймворк под названием RPG (regularized policy gradient) для улучшения способн
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#dataset", "#3d", "#training", "#optimization", "#diffusion"], "emoji": "🧊", "ru": {"title": "Революция в генерации 3D-объектов: эффективность и качество на новом уровне", "desc": "Статья представляет Direct3D S2 - масштабируемую систему для генерации 3D-объектов, использующую разре
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#optimization", "#architecture", "#transfer_learning", "#audio"], "emoji": "🧠", "ru": {"title": "Языковые модели обретают зрение и слух через чтение", "desc": "Исследование показывает, что авторегрессионные языковые модели, обученные на текстовых данных, способ
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#architecture", "#transfer_learning", "#training"], "emoji": "🚀", "ru": {"title": "Transformer Copilot: Учимся на ошибках для повышения эффективности ИИ", "desc": "Представлена новая архитектура Transformer Copilot, которая улучшает работу больших язык
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#optimization", "#training", "#synthetic"], "emoji": "🤖", "ru": {"title": "Усиление языковых моделей без человеческих данных", "desc": "Статья представляет новый метод под названием Synthetic Data RL, который улучшает языковые модели с помощью обучения с подкрепление
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#cv", "#rl", "#rag", "#optimization", "#reasoning", "#training"], "emoji": "🎨", "ru": {"title": "Умное улучшение промптов для более точной генерации изображений", "desc": "RePrompt - это новая система для улучшения генерации изображений по текстовому описанию, использующая обучение 
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#games", "#training", "#optimization", "#rlhf", "#multimodal", "#rl", "#transfer_learning"], "emoji": "🤖", "ru": {"title": "Эффективное пост-обучение VLA моделей с минимальным надзором", "desc": "RIPT-VLA - это новая парадигма пост-обучения моделей зрения-языка-действия (VLA) с испо
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#multimodal", "#rag", "#long_context"], "emoji": "📝", "ru": {"title": "Усиление итеративного RAG через генерацию кратких заметок", "desc": "Статья предлагает метод Notes Writing для улучшения итеративного RAG в задачах ответов на многоэтапные вопросы. 
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#rlhf", "#reasoning"], "emoji": "🧠", "ru": {"title": "NOVER: обучение с подкреплением без верификаторов для улучшения языковых моделей", "desc": "NOVER - это новая система обучения с подкреплением для языковых моделей, которая не требует внешних 
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#leakage", "#multimodal", "#alignment", "#security", "#dataset", "#benchmark"], "emoji": "🔐", "ru": {"title": "LLM нарушают политики безопасности: urgent call для улучшения защиты данных", "desc": "Это исследование посвящено проблеме нарушения большими языковыми моделями (LLM) конте
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#dataset", "#survey", "#reasoning", "#benchmark", "#open_source"], "emoji": "⏳", "ru": {"title": "TIME: Комплексная оценка темпорального рассуждения в LLM", "desc": "Статья представляет новый бенчмарк TIME для оценки темпорального рассуждения в больших языковых моделях (LLM). Бенчма
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization", "#architecture"], "emoji": "🧠", "ru": {"title": "Оптимизация MoE моделей: ключ к эффективному масштабированию LLM", "desc": "Статья исследует эффективность масштабирования больших языковых моделей (LLM) с использованием архитектуры Mixture-
[26.05.2025 10:17] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Ортогональность для инноваций: новый подход к остаточным связям", "desc": "Статья представляет новый метод под названием 'Ортогональное Остаточное Обновление' для улучшения обучения глубоких нейронных сете
[26.05.2025 10:17] Loading Chinese text from previous data.
[26.05.2025 10:17] Renaming data file.
[26.05.2025 10:17] Renaming previous data. hf_papers.json to ./d/2025-05-26.json
[26.05.2025 10:17] Saving new data file.
[26.05.2025 10:17] Generating page.
[26.05.2025 10:17] Renaming previous page.
[26.05.2025 10:17] Renaming previous data. index.html to ./d/2025-05-26.html
[26.05.2025 10:17] [Experimental] Generating Chinese page for reading.
[26.05.2025 10:17] Chinese vocab [{'word': '迁移学习', 'pinyin': 'qiān yí xué xí', 'trans': 'transfer learning'}, {'word': '分类任务', 'pinyin': 'fēn lèi rèn wù', 'trans': 'classification task'}, {'word': '参数', 'pinyin': 'cān shǔ', 'trans': 'parameter'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-training'}, {'word': '文本编码器', 'pinyin': 'wén běn biān mǎ qì', 'trans': 'text encoder'}, {'word': '目标令牌', 'pinyin': 'mù biāo lìng pái', 'trans': 'target token'}, {'word': '嵌入', 'pinyin': 'qiàn rù', 'trans': 'embedding'}, {'word': '表现出色', 'pinyin': 'biǎo xiàn chū sè', 'trans': 'perform excellently'}, {'word': '扩展规律', 'pinyin': 'kuò zhǎn guī lǜ', 'trans': 'expansion pattern'}]
[26.05.2025 10:17] Renaming previous Chinese page.
[26.05.2025 10:17] Renaming previous data. zh.html to ./d/2025-05-25_zh_reading_task.html
[26.05.2025 10:17] Writing Chinese reading task.
[26.05.2025 10:17] Writing result.
[26.05.2025 10:17] Renaming log file.
[26.05.2025 10:17] Renaming previous data. log.txt to ./logs/2025-05-26_last_log.txt
