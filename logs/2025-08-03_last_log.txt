[02.08.2025 18:36] Read previous papers.
[02.08.2025 18:36] Generating top page (month).
[02.08.2025 18:36] Writing top page (month).
[03.08.2025 02:28] Read previous papers.
[03.08.2025 02:28] Get feed.
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23726
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23779
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22968
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22879
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23682
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23277
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.21509
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23698
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23374
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.21584
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.20519
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23436
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23632
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.14793
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23404
[03.08.2025 02:28] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23257
[03.08.2025 02:28] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.08.2025 02:28] No deleted papers detected.
[03.08.2025 02:28] Downloading and parsing papers (pdf, html). Total: 16.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23726.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23726.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23726.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23779.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23779.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23779.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.22968.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.22968.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.22968.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.22879.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.22879.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.22879.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23682.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23682.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23682.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23277.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23277.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23277.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.21509.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.21509.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.21509.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23698.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23698.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23698.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23374.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23374.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23374.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.21584.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.21584.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.21584.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.20519.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.20519.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.20519.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23436.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23436.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23436.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23632.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23632.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23632.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.14793.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.14793.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.14793.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23404.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23404.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23404.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Downloading and parsing paper https://huggingface.co/papers/2507.23257.
[03.08.2025 02:28] Extra JSON file exists (./assets/json/2507.23257.json), skip PDF parsing.
[03.08.2025 02:28] Paper image links file exists (./assets/img_data/2507.23257.json), skip HTML parsing.
[03.08.2025 02:28] Success.
[03.08.2025 02:28] Enriching papers with extra data.
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 0. Seed-Prover, a lemma-style reasoning model using Lean, achieves high performance in formal theorem proving and automated mathematical reasoning through iterative refinement and specialized geometry support.  					AI-generated summary 				 LLMs have demonstrated strong mathematical reasoning abilitie...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 1. The Phi-Ground model family achieves state-of-the-art performance in GUI grounding for multimodal reasoning models, improving accuracy across various benchmarks.  					AI-generated summary 				 With the development of multimodal reasoning models, Computer Use Agents (CUAs), akin to Jarvis from "Iron...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 2. A benchmark dataset for Spoken Dialogue Models (SDMs) in English and Chinese is presented to evaluate their performance in understanding and emulating human spoken conversations, addressing challenges like ambiguity and context-dependency.  					AI-generated summary 				 Spoken Dialogue Models (SDMs...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 3. RecGPT integrates large language models into recommender systems to focus on user intent, improving content diversity and satisfaction while enhancing merchant and platform performance.  					AI-generated summary 				 Recommender systems are among the most impactful applications of artificial intell...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 4. The ViLLA framework enhances VLA models by incorporating latent actions, improving performance in both simulated and real-world robot manipulation tasks.  					AI-generated summary 				 Visual-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies th...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 5. iLRM, an iterative Large 3D Reconstruction Model, improves scalability and efficiency in 3D reconstruction by decoupling scene representation, using a two-stage attention scheme, and injecting high-resolution information.  					AI-generated summary 				 Feed-forward 3D modeling has emerged as a prom...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 6. Persona vectors in large language models can monitor and control personality changes during training and deployment, enabling the identification and mitigation of undesirable traits.  					AI-generated summary 				 Large language models interact with users through a simulated 'Assistant' persona. Wh...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 7. Reinforcement Learning enhances generalizable spatial reasoning and interaction in 3D environments through cross-view goal specification and automated task synthesis, achieving zero-shot generalization and improved interaction success rates.  					AI-generated summary 				 While Reinforcement Learni...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 8. NeRF-GS combines Neural Radiance Fields and 3D Gaussian Splatting to enhance 3D scene representation and performance through joint optimization and shared spatial information.  					AI-generated summary 				 We introduce NeRF-GS, a novel framework that jointly optimizes Neural Radiance Fields (NeRF)...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 9. TARS, a token-adaptive preference strategy, improves multimodal large language models by reducing hallucinations through min-max optimization under semantic constraints.  					AI-generated summary 				 Multimodal large language models (MLLMs) enable vision-language reasoning, yet often generate plau...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 10. AgroBench evaluates vision-language models across agricultural tasks, revealing areas for improvement in fine-grained identification, particularly weed identification, with expert-annotated categories.  					AI-generated summary 				 Precise automated understanding of agricultural tasks such as dise...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 11. Enhancing dual-teacher self-supervised frameworks with Kolmogorov-Arnold Networks improves art style classification by better modeling nonlinear feature correlations and disentangling complex style manifolds.  					AI-generated summary 				 Art style classification remains a formidable challenge in ...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 12. Softmax attention is more expressive than linear attention due to its recurrent form, which can be analyzed using RNN components.  					AI-generated summary 				 Since its introduction, softmax attention has become the backbone of modern transformer architectures due to its expressiveness and scalab...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 13. Equivariant neural network architectures are extended to handle time-parameterized transformations, improving performance in sequence models like RNNs.  					AI-generated summary 				 Data arrives at our senses as a continuous stream, smoothly transforming from one instant to the next. These smooth ...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 14. An enhanced Dense Passage Retrieval framework for Arabic uses a novel Attentive Relevance Scoring mechanism to improve retrieval performance and ranking accuracy.  					AI-generated summary 				 Arabic poses a particular challenge for natural language processing (NLP) and information retrieval (IR) ...
[03.08.2025 02:28] ********************************************************************************
[03.08.2025 02:28] Abstract 15. The paper introduces the Influence Approximation Unlearning (IAU) algorithm, which leverages incremental learning principles to efficiently address the computational challenges of influence-based unlearning in machine learning models.  					AI-generated summary 				 Due to growing privacy concerns, ...
[03.08.2025 02:28] Read previous papers.
[03.08.2025 02:28] Generating reviews via LLM API.
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#optimization", "#training", "#math", "#reasoning", "#rl"], "emoji": "üß†", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ–º —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "Seed-Prover - —ç—Ç–æ –º–æ–¥–µ–ª—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Ç–µ–æ—Ä–µ–º, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è —è–∑—ã–∫ Lean. –û–Ω–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É—Ç–æ—á
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#agents", "#dataset", "#optimization", "#reasoning", "#training", "#multimodal"], "emoji": "üñ•Ô∏è", "ru": {"title": "Phi-Ground: –ø—Ä–æ—Ä—ã–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏–≤—è–∑–∫–∏ GUI –¥–ª—è –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–°–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π Phi-Ground –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø–µ—Ä–µ–¥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∑–∞–¥–∞—á–µ –ø—Ä–∏–≤—è–∑–∫–∏ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#survey", "#long_context", "#benchmark", "#dataset", "#multimodal"], "emoji": "üó£Ô∏è", "ru": {"title": "–ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª–µ–π –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏ –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–∞—Ö
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#optimization", "#training", "#reasoning", "#alignment", "#multimodal"], "emoji": "üéØ", "ru": {"title": "RecGPT: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", "desc": "RecGPT - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—â–∞—è –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –¥–ª—è —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#optimization", "#agents", "#agi", "#games", "#robotics", "#architecture"], "emoji": "ü§ñ", "ru": {"title": "ViLLA: –£–ª—É—á—à–µ–Ω–∏–µ —Ä–æ–±–æ—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π —Å –ø–æ–º–æ—â—å—é –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π", "desc": "–§—Ä–µ–π–º–≤–æ—Ä–∫ ViLLA —É–ª—É—á—à–∞–µ—Ç –º–æ–¥–µ–ª–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è (VLA) –ø—É—Ç–µ–º –≤–∫–ª—é—á–µ–Ω–∏—è –ª–∞—Ç–µ–Ω—Ç–Ω
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#optimization", "#3d"], "emoji": "üèõÔ∏è", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è 3D-—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –≥–∞—É—Å—Å–æ–≤—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º", "desc": "iLRM - —ç—Ç–æ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π 3D-—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–µ—Ö–º–µ—Ä–Ω–æ–µ –≥–∞—É—Å—Å–æ–≤–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ü–µ–Ω—ã, –¥–≤—É
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#rlhf", "#hallucinations", "#data", "#ethics", "#training", "#alignment"], "emoji": "üé≠", "ru": {"title": "–í–µ–∫—Ç–æ—Ä—ã –ø–µ—Ä—Å–æ–Ω—ã: –∫–ª—é—á –∫ –∫–æ–Ω—Ç—Ä–æ–ª—é –ª–∏—á–Ω–æ—Å—Ç–∏ –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –≤–µ–∫—Ç–æ—Ä–æ–≤ –ø–µ—Ä—Å–æ–Ω—ã –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. –≠—Ç–∏ –≤–µ–∫—Ç–æ—Ä—ã –ø–æ–∑–≤–æ–ª—è—é—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å 
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#games", "#3d", "#rl"], "emoji": "üß†", "ru": {"title": "RL –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –¥–ª—è –ò–ò", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –≤ 3D-—Å—Ä–µ–¥–∞—Ö —Å –ø
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#3d", "#benchmark"], "emoji": "üåü", "ru": {"title": "NeRF-GS: –°–∏–Ω–µ—Ä–≥–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π –∏ –≥–∞—É—Å—Å–æ–≤–∞ —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥–∞ –¥–ª—è —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–≥–æ 3D-–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "NeRF-GS - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Ä–∞–¥–∏–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–ª—è (NeRF) –∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω–æ–µ –≥–∞—É—Å—Å–æ–≤–æ —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥ (3DGS) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#hallucinations", "#optimization", "#multimodal", "#benchmark", "#rlhf"], "emoji": "üß†", "ru": {"title": "TARS: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ—Ä—å–±—ã —Å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò", "desc": "TARS - —ç—Ç–æ –Ω–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö 
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#cv", "#open_source", "#science", "#dataset", "#benchmark"], "emoji": "üåæ", "ru": {"title": "AgroBench: —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ò–ò –≤ —Å–µ–ª—å—Å–∫–æ–º —Ö–æ–∑—è–π—Å—Ç–≤–µ", "desc": "AgroBench - —ç—Ç–æ –Ω–æ–≤—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –≤ —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#cv", "#math", "#training", "#optimization"], "emoji": "üé®", "ru": {"title": "–°–µ—Ç–∏ –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–ê—Ä–Ω–æ–ª—å–¥–∞ —É–ª—É—á—à–∞—é—Ç —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ç–∏–ª–µ–π –∏—Å–∫—É—Å—Å—Ç–≤–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è —Å –¥–≤—É–º—è —É—á–∏—Ç–µ–ª—è–º–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ç–∏–ª–µ–π –∏—Å–∫—É—Å—Å—Ç–≤–∞. –ê
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#interpretability"], "emoji": "üîç", "ru": {"title": "–†–∞—Å–∫—Ä—ã–≤–∞—è —Å–∏–ª—É —Å–æ—Ñ—Ç–º–∞–∫—Å-–≤–Ω–∏–º–∞–Ω–∏—è —á–µ—Ä–µ–∑ –ø—Ä–∏–∑–º—É RNN", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É —Å–æ—Ñ—Ç–º–∞–∫—Å-–≤–Ω–∏–º–∞–Ω–∏–µ–º –∏ –ª–∏–Ω–µ–π–Ω—ã–º –≤–Ω–∏–º–∞–Ω–∏–µ–º –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö. –ê–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Å–æ—Ñ—Ç–º–∞–∫—Å-–≤–Ω–∏–º–∞–Ω–∏–µ –º–æ–∂–Ω
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization"], "emoji": "‚è≥", "ru": {"title": "–≠–∫–≤–∏–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –≤–æ –≤—Ä–µ–º–µ–Ω–∏: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π", "desc": "–°—Ç–∞—Ç—å—è —Ä–∞—Å—à–∏—Ä—è–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é —ç–∫–≤–∏–≤–∞—Ä–∏–∞–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π, –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ –≤—Ä–µ–º–µ–Ω–∏. –≠—Ç
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#low_resource", "#multilingual", "#dataset"], "emoji": "üïå", "ru": {"title": "–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∞—Ä–∞–±—Å–∫–∏–º —Ç–µ–∫—Å—Ç–∞–º —Å –ø–æ–º–æ—â—å—é –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–ª–æ—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–∞—Å—Å–∞–∂–µ–π (Dense Passage Retrieva
[03.08.2025 02:28] Using data from previous issue: {"categories": ["#optimization", "#security", "#training", "#data"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä–∏–∑–º—É –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º Influence Approximation Unlearning (IAU) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º–∞—à–∏–Ω–Ω–æ–≥–æ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏—è. IAU –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–∏–Ω
[03.08.2025 02:28] Renaming data file.
[03.08.2025 02:28] Renaming previous data. hf_papers.json to ./d/2025-08-01.json
[03.08.2025 02:28] Saving new data file.
[03.08.2025 02:28] Generating page.
[03.08.2025 02:28] Renaming previous page.
[03.08.2025 02:28] Renaming previous data. index.html to ./d/2025-08-01.html
[03.08.2025 02:28] Writing result.
[03.08.2025 02:28] Renaming log file.
[03.08.2025 02:28] Renaming previous data. log.txt to ./logs/2025-08-03_last_log.txt
