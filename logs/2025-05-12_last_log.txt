[12.05.2025 06:17] Read previous papers.
[12.05.2025 06:17] Generating top page (month).
[12.05.2025 06:17] Writing top page (month).
[12.05.2025 07:12] Read previous papers.
[12.05.2025 07:12] Get feed.
[12.05.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.05026
[12.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.06111
[12.05.2025 07:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[12.05.2025 07:12] No deleted papers detected.
[12.05.2025 07:12] Downloading and parsing papers (pdf, html). Total: 2.
[12.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.05026.
[12.05.2025 07:12] Downloading paper 2505.05026 from http://arxiv.org/pdf/2505.05026v2...
[12.05.2025 07:13] Extracting affiliations from text.
[12.05.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 ] . [ 2 6 2 0 5 0 . 5 0 5 2 : r Preprint. Under review. G-FOCUS: Towards Robust Method for Assessing UI Design Persuasiveness Jang Han Yoon Min Soo Kim Sumin Shim Yejin Choi Jaehyun Jeon Hanbin Kim Youngjae Yu Yonsei University jaehyun.jeon@yonsei.ac.kr "
[12.05.2025 07:13] Response: ```python
["Yonsei University"]
```
[12.05.2025 07:13] Deleting PDF ./assets/pdf/2505.05026.pdf.
[12.05.2025 07:13] Success.
[12.05.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2505.06111.
[12.05.2025 07:13] Extra JSON file exists (./assets/json/2505.06111.json), skip PDF parsing.
[12.05.2025 07:13] Paper image links file exists (./assets/img_data/2505.06111.json), skip HTML parsing.
[12.05.2025 07:13] Success.
[12.05.2025 07:13] Enriching papers with extra data.
[12.05.2025 07:13] ********************************************************************************
[12.05.2025 07:13] Abstract 0. Evaluating user interface (UI) design effectiveness extends beyond aesthetics to influencing user behavior, a principle central to Design Persuasiveness. A/B testing is the predominant method for determining which UI variations drive higher user engagement, but it is costly and time-consuming. While...
[12.05.2025 07:13] ********************************************************************************
[12.05.2025 07:13] Abstract 1. A generalist robot should perform effectively across various environments. However, most existing approaches heavily rely on scaling action-annotated data to enhance their capabilities. Consequently, they are often limited to single physical specification and struggle to learn transferable knowledge...
[12.05.2025 07:13] Read previous papers.
[12.05.2025 07:13] Generating reviews via LLM API.
[12.05.2025 07:13] Querying the API.
[12.05.2025 07:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Evaluating user interface (UI) design effectiveness extends beyond aesthetics to influencing user behavior, a principle central to Design Persuasiveness. A/B testing is the predominant method for determining which UI variations drive higher user engagement, but it is costly and time-consuming. While recent Vision-Language Models (VLMs) can process automated UI analysis, current approaches focus on isolated design attributes rather than comparative persuasiveness-the key factor in optimizing user interactions. To address this, we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled with A/B test results and expert rationales. Additionally, we propose G-FOCUS, a novel inference-time reasoning strategy that enhances VLM-based persuasiveness assessment by reducing position bias and improving evaluation accuracy. Experimental results show that G-FOCUS surpasses existing inference strategies in consistency and accuracy for pairwise UI evaluation. Through promoting VLM-driven evaluation of UI persuasiveness, our work offers an approach to complement A/B testing, propelling progress in scalable UI preference modeling and design optimization. Code and data will be released publicly.
[12.05.2025 07:13] Response: {
  "desc": "ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ² Ñ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸Ñ… ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ĞĞ½Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº WiserUI-Bench Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ², ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¹ 300 Ğ¿Ğ°Ñ€ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… UI-Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ A/B-Ñ‚ĞµÑÑ‚Ğ¾Ğ². Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ G-FOCUS Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ² Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ G-FOCUS Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¿Ğ¾ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ².",
  "emoji": "ğŸ–¥ï¸",
  "title": "ĞÑ†ĞµĞ½ĞºĞ° ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ UI Ğ±ĞµĞ· A/B-Ñ‚ĞµÑÑ‚Ğ¾Ğ²"
}
[12.05.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Evaluating user interface (UI) design effectiveness extends beyond aesthetics to influencing user behavior, a principle central to Design Persuasiveness. A/B testing is the predominant method for determining which UI variations drive higher user engagement, but it is costly and time-consuming. While recent Vision-Language Models (VLMs) can process automated UI analysis, current approaches focus on isolated design attributes rather than comparative persuasiveness-the key factor in optimizing user interactions. To address this, we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled with A/B test results and expert rationales. Additionally, we propose G-FOCUS, a novel inference-time reasoning strategy that enhances VLM-based persuasiveness assessment by reducing position bias and improving evaluation accuracy. Experimental results show that G-FOCUS surpasses existing inference strategies in consistency and accuracy for pairwise UI evaluation. Through promoting VLM-driven evaluation of UI persuasiveness, our work offers an approach to complement A/B testing, propelling progress in scalable UI preference modeling and design optimization. Code and data will be released publicly."

[12.05.2025 07:13] Response: ```python
['BENCHMARK', 'INFERENCE', 'CV']
```
[12.05.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Evaluating user interface (UI) design effectiveness extends beyond aesthetics to influencing user behavior, a principle central to Design Persuasiveness. A/B testing is the predominant method for determining which UI variations drive higher user engagement, but it is costly and time-consuming. While recent Vision-Language Models (VLMs) can process automated UI analysis, current approaches focus on isolated design attributes rather than comparative persuasiveness-the key factor in optimizing user interactions. To address this, we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled with A/B test results and expert rationales. Additionally, we propose G-FOCUS, a novel inference-time reasoning strategy that enhances VLM-based persuasiveness assessment by reducing position bias and improving evaluation accuracy. Experimental results show that G-FOCUS surpasses existing inference strategies in consistency and accuracy for pairwise UI evaluation. Through promoting VLM-driven evaluation of UI persuasiveness, our work offers an approach to complement A/B testing, propelling progress in scalable UI preference modeling and design optimization. Code and data will be released publicly."

[12.05.2025 07:13] Response: ```python
["OPTIMIZATION", "REASONING"]
```
[12.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the importance of evaluating user interface (UI) design not just for its visual appeal but for its ability to influence user behavior, a concept known as Design Persuasiveness. The authors highlight the limitations of traditional A/B testing, which is often expensive and slow, and propose a new benchmark called WiserUI-Bench for assessing UI design effectiveness through pairwise comparisons. They introduce G-FOCUS, an innovative reasoning strategy that improves the accuracy of Vision-Language Models (VLMs) in evaluating UI persuasiveness by minimizing biases. The results demonstrate that G-FOCUS outperforms existing methods, paving the way for more efficient and scalable UI design optimization.","title":"Revolutionizing UI Evaluation with G-FOCUS and WiserUI-Bench"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the importance of evaluating user interface (UI) design not just for its visual appeal but for its ability to influence user behavior, a concept known as Design Persuasiveness. The authors highlight the limitations of traditional A/B testing, which is often expensive and slow, and propose a new benchmark called WiserUI-Bench for assessing UI design effectiveness through pairwise comparisons. They introduce G-FOCUS, an innovative reasoning strategy that improves the accuracy of Vision-Language Models (VLMs) in evaluating UI persuasiveness by minimizing biases. The results demonstrate that G-FOCUS outperforms existing methods, paving the way for more efficient and scalable UI design optimization.', title='Revolutionizing UI Evaluation with G-FOCUS and WiserUI-Bench'))
[12.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬è®ºæ–‡æ¢è®¨äº†ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰è®¾è®¡çš„æœ‰æ•ˆæ€§è¯„ä¼°ï¼Œå¼ºè°ƒè®¾è®¡çš„è¯´æœåŠ›å¯¹ç”¨æˆ·è¡Œä¸ºçš„å½±å“ã€‚ä¼ ç»Ÿçš„A/Bæµ‹è¯•æ–¹æ³•è™½ç„¶å¸¸ç”¨ï¼Œä½†æˆæœ¬é«˜ä¸”è€—æ—¶ã€‚æˆ‘ä»¬æå‡ºäº†WiserUI-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæˆå¯¹UIè®¾è®¡è¯´æœåŠ›è¯„ä¼°çš„åŸºå‡†ï¼ŒåŒ…å«300å¯¹çœŸå®çš„UIå›¾åƒåŠå…¶A/Bæµ‹è¯•ç»“æœå’Œä¸“å®¶ç†ç”±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†G-FOCUSï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¨ç†ç­–ç•¥ï¼Œèƒ½å¤Ÿæé«˜åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„è¯´æœåŠ›è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚","title":"æå‡ç”¨æˆ·ç•Œé¢è®¾è®¡çš„è¯´æœåŠ›è¯„ä¼°"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬è®ºæ–‡æ¢è®¨äº†ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰è®¾è®¡çš„æœ‰æ•ˆæ€§è¯„ä¼°ï¼Œå¼ºè°ƒè®¾è®¡çš„è¯´æœåŠ›å¯¹ç”¨æˆ·è¡Œä¸ºçš„å½±å“ã€‚ä¼ ç»Ÿçš„A/Bæµ‹è¯•æ–¹æ³•è™½ç„¶å¸¸ç”¨ï¼Œä½†æˆæœ¬é«˜ä¸”è€—æ—¶ã€‚æˆ‘ä»¬æå‡ºäº†WiserUI-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæˆå¯¹UIè®¾è®¡è¯´æœåŠ›è¯„ä¼°çš„åŸºå‡†ï¼ŒåŒ…å«300å¯¹çœŸå®çš„UIå›¾åƒåŠå…¶A/Bæµ‹è¯•ç»“æœå’Œä¸“å®¶ç†ç”±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†G-FOCUSï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¨ç†ç­–ç•¥ï¼Œèƒ½å¤Ÿæé«˜åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„è¯´æœåŠ›è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚', title='æå‡ç”¨æˆ·ç•Œé¢è®¾è®¡çš„è¯´æœåŠ›è¯„ä¼°'))
[12.05.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#robotics", "#training", "#benchmark", "#agents", "#transfer_learning"], "emoji": "ğŸ¤–", "ru": {"title": "Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ ÑĞ·Ñ‹Ğº", "desc": "UniVLA - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ¾ĞºÑ€ÑƒĞ¶Ğ°ÑÑ‰ĞµĞ¹ ÑÑ€
[12.05.2025 07:13] Loading Chinese text from previous data.
[12.05.2025 07:13] Renaming data file.
[12.05.2025 07:13] Renaming previous data. hf_papers.json to ./d/2025-05-12.json
[12.05.2025 07:13] Saving new data file.
[12.05.2025 07:13] Generating page.
[12.05.2025 07:13] Renaming previous page.
[12.05.2025 07:13] Renaming previous data. index.html to ./d/2025-05-12.html
[12.05.2025 07:13] [Experimental] Generating Chinese page for reading.
[12.05.2025 07:13] Chinese vocab [{'word': 'æ¨ç†', 'pinyin': 'tuÄ« lÇ', 'trans': 'reasoning'}, {'word': 'äººå·¥æ™ºèƒ½', 'pinyin': 'rÃ©n gÅng zhÃ¬ nÃ©ng', 'trans': 'artificial intelligence'}, {'word': 'ä¸ç¡®å®š', 'pinyin': 'bÃ¹ quÃ¨ dÃ¬ng', 'trans': 'uncertain'}, {'word': 'å¤šæ¨¡æ€', 'pinyin': 'duÅ mÃ³ tÃ i', 'trans': 'multimodal'}, {'word': 'æ¨¡æ€', 'pinyin': 'mÃ³ tÃ i', 'trans': 'modality'}, {'word': 'ç»“åˆ', 'pinyin': 'jiÃ© hÃ©', 'trans': 'combine'}, {'word': 'æ”¯æŒ', 'pinyin': 'zhÄ« chÃ­', 'trans': 'support'}, {'word': 'å¤æ‚', 'pinyin': 'fÃ¹ zÃ¡', 'trans': 'complex'}, {'word': 'æ¨¡å—åŒ–', 'pinyin': 'mÃ³ kuÃ i huÃ ', 'trans': 'modularization'}, {'word': 'æ„ŸçŸ¥', 'pinyin': 'gÇn zhÄ«', 'trans': 'perception'}, {'word': 'é©±åŠ¨', 'pinyin': 'qÅ« dÃ²ng', 'trans': 'drive'}, {'word': 'æµæ°´çº¿', 'pinyin': 'liÃº shuÇ xiÃ n', 'trans': 'pipeline'}, {'word': 'ç»Ÿä¸€', 'pinyin': 'tÇ’ng yÄ«', 'trans': 'unified'}, {'word': 'æ¡†æ¶', 'pinyin': 'kuÃ ng jiÃ ', 'trans': 'framework'}, {'word': 'å›é¡¾', 'pinyin': 'huÃ­ gÃ¹', 'trans': 'review'}, {'word': 'ä»»åŠ¡', 'pinyin': 'rÃ¨n wÃ¹', 'trans': 'task'}, {'word': 'ç‰¹å®š', 'pinyin': 'tÃ¨ dÃ¬ng', 'trans': 'specific'}, {'word': 'æ£€æŸ¥', 'pinyin': 'jiÇn chÃ¡', 'trans': 'examine'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'}, {'word': 'æ–¹å‘', 'pinyin': 'fÄng xiÃ ng', 'trans': 'direction'}]
[12.05.2025 07:13] Renaming previous Chinese page.
[12.05.2025 07:13] Renaming previous data. zh.html to ./d/2025-05-11_zh_reading_task.html
[12.05.2025 07:13] Writing Chinese reading task.
[12.05.2025 07:13] Writing result.
[12.05.2025 07:13] Renaming log file.
[12.05.2025 07:13] Renaming previous data. log.txt to ./logs/2025-05-12_last_log.txt
