[27.06.2025 08:16] Read previous papers.
[27.06.2025 08:16] Generating top page (month).
[27.06.2025 08:16] Writing top page (month).
[27.06.2025 09:13] Read previous papers.
[27.06.2025 09:13] Get feed.
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20670
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21539
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21551
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21506
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21547
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21552
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16655
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20911
[27.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20430
[27.06.2025 09:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.15196
[27.06.2025 09:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.06.2025 09:13] No deleted papers detected.
[27.06.2025 09:13] Downloading and parsing papers (pdf, html). Total: 10.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.20670.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.20670.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.20670.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.21539.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.21539.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.21539.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.21551.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.21551.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.21551.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.21506.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.21506.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.21506.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.21547.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.21547.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.21547.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.21552.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.21552.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.21552.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.16655.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.16655.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.16655.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.20911.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.20911.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.20911.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.20430.
[27.06.2025 09:13] Extra JSON file exists (./assets/json/2506.20430.json), skip PDF parsing.
[27.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.20430.json), skip HTML parsing.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.15196.
[27.06.2025 09:13] Downloading paper 2506.15196 from http://arxiv.org/pdf/2506.15196v2...
[27.06.2025 09:13] Extracting affiliations from text.
[27.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 2 ] . [ 2 6 9 1 5 1 . 6 0 5 2 : r HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges Xianliang Yang1 Ling Zhang1 Haolong Qian1,2 Lei Song1 Jiang Bian1 1Microsoft Research Asia, Beijing, China 2Tsinghua University, Beijing, China {Xianliang.Yang, Ling.Zhang, v-haolqian, Lei.Song, Jiang.Bian} @microsoft.com "
[27.06.2025 09:13] Response: ```python
["Microsoft Research Asia, Beijing, China", "Tsinghua University, Beijing, China"]
```
[27.06.2025 09:13] Deleting PDF ./assets/pdf/2506.15196.pdf.
[27.06.2025 09:13] Success.
[27.06.2025 09:13] Enriching papers with extra data.
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 0. MMSearch-R1, a reinforcement learning framework, enables large multimodal models to perform efficient, on-demand, multi-turn search in real-world environments, outperforming existing approaches.  					AI-generated summary 				 Robust deployment of large multimodal models (LMMs) in real-world scenari...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 1. WorldVLA, an autoregressive action world model integrating vision-language-action (VLA) and world models, enhances performance through mutual understanding and generation, improving action prediction and sequence generation with an attention mask strategy.  					AI-generated summary 				 We present ...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 2. Grokking, or continued test performance improvement after training loss convergence, is observed during pretraining of a large language model, showcasing a memorization-to-generalization process.  					AI-generated summary 				 Grokking, i.e., test performance keeps improving long after training los...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 3. Mind2Web 2 benchmark evaluates agentic search systems with a suite of realistic, long-horizon tasks, introducing an Agent-as-a-Judge framework to assess accuracy and source attribution.  					AI-generated summary 				 Agentic search such as Deep Research systems, where large language models autonomo...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 4. SAM4D is a multi-modal and temporal foundation model for segmentation in autonomous driving using Unified Multi-modal Positional Encoding and Motion-aware Cross-modal Memory Attention, with a multi-modal automated data engine generating pseudo-labels.  					AI-generated summary 				 We present SAM4D...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 5. A model trained on real-world egocentric video and body pose predicts video from human actions using an auto-regressive conditional diffusion transformer, evaluated with a hierarchical protocol of tasks.  					AI-generated summary 				 We train models to Predict Ego-centric Video from human Actions ...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 6. A preference-aligned routing framework using a compact 1.5B model effectively matches queries to user-defined domains and action types, outperforming proprietary models in subjective evaluation criteria.  					AI-generated summary 				 With the rapid proliferation of large language models (LLMs) -- ...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 7. A neurosymbolic agent combines language models for fast subtask planning with A$^*$ search for detailed toolpaths, creating a cost-efficient multi-turn image editing solution.  					AI-generated summary 				 We develop a cost-efficient neurosymbolic agent to address challenging multi-turn image edit...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 8. DeepRare, a large language model-based system, provides accurate rare disease diagnoses using heterogeneous clinical inputs and outperforms other diagnostic methods across various datasets.  					AI-generated summary 				 Rare diseases collectively affect over 300 million individuals worldwide, yet ...
[27.06.2025 09:13] ********************************************************************************
[27.06.2025 09:13] Abstract 9. HeurAgenix, a two-stage hyper-heuristic framework using large language models, evolves and selects heuristics dynamically for combinatorial optimization problems, achieving performance on par with specialized solvers.  					AI-generated summary 				 Heuristic algorithms play a vital role in solving ...
[27.06.2025 09:13] Read previous papers.
[27.06.2025 09:13] Generating reviews via LLM API.
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#reasoning", "#games", "#rl", "#rag", "#multimodal"], "emoji": "🔍", "ru": {"title": "Эффективный мультимодальный поиск с помощью обучения с подкреплением", "desc": "MMSearch-R1 - это фреймворк обучения с подкреплением, который позволяет большим мультимод
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#rl", "#multimodal", "#games", "#cv"], "emoji": "🌐", "ru": {"title": "Единая модель мира и действий для улучшенного понимания и генерации", "desc": "WorldVLA - это авторегрессионная модель мира действий, объединяющая понимание и генерацию изображений и действий. Она
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#math", "#data", "#optimization", "#reasoning", "#benchmark", "#training"], "emoji": "🧠", "ru": {"title": "От запоминания к обобщению: раскрывая тайны грокинга в больших языковых моделях", "desc": "Исследование демонстрирует явление грокинга (grokking) при предобучении большой языко
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#agents", "#agi", "#benchmark"], "emoji": "🕵️", "ru": {"title": "Mind2Web 2: Новый стандарт оценки агентного поиска", "desc": "Mind2Web 2 - это новый бенчмарк для оценки систем агентного поиска, включающий 130 реалистичных задач с длительным гор
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#games", "#multimodal", "#cv"], "emoji": "🚗", "ru": {"title": "SAM4D: Революция в сегментации для беспилотных автомобилей", "desc": "SAM4D - это многомодальная и темпоральная фундаментальная модель для сегментации в автономном вождении. Она использует ун
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#diffusion", "#agents", "#games", "#dataset", "#video"], "emoji": "🎥", "ru": {"title": "Предсказание эгоцентрического видео по действиям человека", "desc": "Статья представляет модель PEVA, обученную предсказывать эгоцентрическое видео на основе действий человека. Модель использует 
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#training", "#alignment", "#small_models", "#multimodal"], "emoji": "🔀", "ru": {"title": "Умная маршрутизация запросов к ИИ с учетом предпочтений пользователя", "desc": "В статье представлен фреймворк для маршрутизации запросов к языковым моделям на основе предпочтений пользователей
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#cv", "#agents", "#optimization", "#reasoning"], "emoji": "🎨", "ru": {"title": "Эффективное редактирование изображений с помощью нейросимволического ИИ", "desc": "Статья представляет нейросимволический агент для эффективного многоэтапного редактирования изображений. Он сочетает быст
[27.06.2025 09:13] Using data from previous issue: {"categories": ["#agents", "#reasoning", "#benchmark", "#science", "#dataset", "#healthcare"], "emoji": "🔬", "ru": {"title": "DeepRare: Революция в диагностике редких заболеваний с помощью ИИ", "desc": "DeepRare - это система на основе большой языковой модели для диагностики редких заболеваний, испо
[27.06.2025 09:13] Querying the API.
[27.06.2025 09:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

HeurAgenix, a two-stage hyper-heuristic framework using large language models, evolves and selects heuristics dynamically for combinatorial optimization problems, achieving performance on par with specialized solvers.  					AI-generated summary 				 Heuristic algorithms play a vital role in solving combinatorial optimization (CO) problems, yet traditional designs depend heavily on manual expertise and struggle to generalize across diverse instances. We introduce HeurAgenix, a two-stage hyper-heuristic framework powered by large language models (LLMs) that first evolves heuristics and then selects among them automatically. In the heuristic evolution phase, HeurAgenix leverages an LLM to compare seed heuristic solutions with higher-quality solutions and extract reusable evolution strategies. During problem solving, it dynamically picks the most promising heuristic for each problem state, guided by the LLM's perception ability. For flexibility, this selector can be either a state-of-the-art LLM or a fine-tuned lightweight model with lower inference cost. To mitigate the scarcity of reliable supervision caused by CO complexity, we fine-tune the lightweight heuristic selector with a dual-reward mechanism that jointly exploits singals from selection preferences and state perception, enabling robust selection under noisy annotations. Extensive experiments on canonical benchmarks show that HeurAgenix not only outperforms existing LLM-based hyper-heuristics but also matches or exceeds specialized solvers. Code is available at https://github.com/microsoft/HeurAgenix.
[27.06.2025 09:13] Response: {
  "desc": "HeurAgenix - это двухэтапная гипер-эвристическая система, использующая большие языковые модели (LLM) для решения задач комбинаторной оптимизации. На первом этапе система эволюционирует эвристики, а на втором выбирает наиболее подходящую для конкретной задачи. HeurAgenix использует LLM для сравнения эвристических решений и извлечения стратегий эволюции. Система применяет механизм двойного вознаграждения при обучении легковесного селектора эвристик, что позволяет осуществлять надежный выбор даже при зашумленных аннотациях.",
  "emoji": "🧠",
  "title": "Автоматическая эволюция и выбор эвристик с помощью искусственного интеллекта"
}
[27.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"HeurAgenix, a two-stage hyper-heuristic framework using large language models, evolves and selects heuristics dynamically for combinatorial optimization problems, achieving performance on par with specialized solvers.  					AI-generated summary 				 Heuristic algorithms play a vital role in solving combinatorial optimization (CO) problems, yet traditional designs depend heavily on manual expertise and struggle to generalize across diverse instances. We introduce HeurAgenix, a two-stage hyper-heuristic framework powered by large language models (LLMs) that first evolves heuristics and then selects among them automatically. In the heuristic evolution phase, HeurAgenix leverages an LLM to compare seed heuristic solutions with higher-quality solutions and extract reusable evolution strategies. During problem solving, it dynamically picks the most promising heuristic for each problem state, guided by the LLM's perception ability. For flexibility, this selector can be either a state-of-the-art LLM or a fine-tuned lightweight model with lower inference cost. To mitigate the scarcity of reliable supervision caused by CO complexity, we fine-tune the lightweight heuristic selector with a dual-reward mechanism that jointly exploits singals from selection preferences and state perception, enabling robust selection under noisy annotations. Extensive experiments on canonical benchmarks show that HeurAgenix not only outperforms existing LLM-based hyper-heuristics but also matches or exceeds specialized solvers. Code is available at https://github.com/microsoft/HeurAgenix."

[27.06.2025 09:13] Response: ```python
['AGENTS', 'TRAINING', 'ARCHITECTURE', 'BENCHMARK']
```
[27.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"HeurAgenix, a two-stage hyper-heuristic framework using large language models, evolves and selects heuristics dynamically for combinatorial optimization problems, achieving performance on par with specialized solvers.  					AI-generated summary 				 Heuristic algorithms play a vital role in solving combinatorial optimization (CO) problems, yet traditional designs depend heavily on manual expertise and struggle to generalize across diverse instances. We introduce HeurAgenix, a two-stage hyper-heuristic framework powered by large language models (LLMs) that first evolves heuristics and then selects among them automatically. In the heuristic evolution phase, HeurAgenix leverages an LLM to compare seed heuristic solutions with higher-quality solutions and extract reusable evolution strategies. During problem solving, it dynamically picks the most promising heuristic for each problem state, guided by the LLM's perception ability. For flexibility, this selector can be either a state-of-the-art LLM or a fine-tuned lightweight model with lower inference cost. To mitigate the scarcity of reliable supervision caused by CO complexity, we fine-tune the lightweight heuristic selector with a dual-reward mechanism that jointly exploits singals from selection preferences and state perception, enabling robust selection under noisy annotations. Extensive experiments on canonical benchmarks show that HeurAgenix not only outperforms existing LLM-based hyper-heuristics but also matches or exceeds specialized solvers. Code is available at https://github.com/microsoft/HeurAgenix."

[27.06.2025 09:13] Response: ```python
["OPTIMIZATION"]
```
[27.06.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"HeurAgenix is a novel two-stage hyper-heuristic framework that utilizes large language models (LLMs) to enhance the solving of combinatorial optimization (CO) problems. The framework first evolves heuristics by comparing initial solutions with better ones, extracting effective strategies for improvement. In the second stage, it dynamically selects the most suitable heuristic for each problem state, leveraging the LLM\'s ability to perceive and adapt. This approach not only improves performance compared to traditional methods but also rivals specialized solvers, demonstrating the potential of LLMs in optimization tasks.","title":"Dynamic Heuristic Evolution and Selection with LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="HeurAgenix is a novel two-stage hyper-heuristic framework that utilizes large language models (LLMs) to enhance the solving of combinatorial optimization (CO) problems. The framework first evolves heuristics by comparing initial solutions with better ones, extracting effective strategies for improvement. In the second stage, it dynamically selects the most suitable heuristic for each problem state, leveraging the LLM's ability to perceive and adapt. This approach not only improves performance compared to traditional methods but also rivals specialized solvers, demonstrating the potential of LLMs in optimization tasks.", title='Dynamic Heuristic Evolution and Selection with LLMs'))
[27.06.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"HeurAgenix 是一个基于大型语言模型的两阶段超启发式框架，旨在动态演化和选择启发式算法以解决组合优化问题。该框架首先通过比较种子启发式解与高质量解，提取可重用的演化策略。然后，在解决问题时，HeurAgenix 根据当前状态动态选择最有前景的启发式算法。实验结果表明，HeurAgenix 的性能与专门的求解器相当，甚至在某些情况下超过了现有的基于 LLM 的超启发式算法。","title":"动态演化与选择启发式算法的创新框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='HeurAgenix 是一个基于大型语言模型的两阶段超启发式框架，旨在动态演化和选择启发式算法以解决组合优化问题。该框架首先通过比较种子启发式解与高质量解，提取可重用的演化策略。然后，在解决问题时，HeurAgenix 根据当前状态动态选择最有前景的启发式算法。实验结果表明，HeurAgenix 的性能与专门的求解器相当，甚至在某些情况下超过了现有的基于 LLM 的超启发式算法。', title='动态演化与选择启发式算法的创新框架'))
[27.06.2025 09:13] Renaming data file.
[27.06.2025 09:13] Renaming previous data. hf_papers.json to ./d/2025-06-27.json
[27.06.2025 09:13] Saving new data file.
[27.06.2025 09:13] Generating page.
[27.06.2025 09:13] Renaming previous page.
[27.06.2025 09:13] Renaming previous data. index.html to ./d/2025-06-27.html
[27.06.2025 09:13] Writing result.
[27.06.2025 09:13] Renaming log file.
[27.06.2025 09:13] Renaming previous data. log.txt to ./logs/2025-06-27_last_log.txt
