[27.06.2025 05:14] Read previous papers.
[27.06.2025 05:14] Generating top page (month).
[27.06.2025 05:14] Writing top page (month).
[27.06.2025 06:17] Read previous papers.
[27.06.2025 06:17] Get feed.
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20670
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21551
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21539
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21506
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21547
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21552
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16655
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20911
[27.06.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20430
[27.06.2025 06:17] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.06.2025 06:17] No deleted papers detected.
[27.06.2025 06:17] Downloading and parsing papers (pdf, html). Total: 9.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.20670.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.20670.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.20670.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.21551.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.21551.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.21551.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.21539.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.21539.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.21539.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.21506.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.21506.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.21506.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.21547.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.21547.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.21547.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.21552.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.21552.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.21552.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.16655.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.16655.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.16655.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.20911.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.20911.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.20911.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2506.20430.
[27.06.2025 06:17] Extra JSON file exists (./assets/json/2506.20430.json), skip PDF parsing.
[27.06.2025 06:17] Paper image links file exists (./assets/img_data/2506.20430.json), skip HTML parsing.
[27.06.2025 06:17] Success.
[27.06.2025 06:17] Enriching papers with extra data.
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 0. MMSearch-R1, a reinforcement learning framework, enables large multimodal models to perform efficient, on-demand, multi-turn search in real-world environments, outperforming existing approaches.  					AI-generated summary 				 Robust deployment of large multimodal models (LMMs) in real-world scenari...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 1. Grokking, or continued test performance improvement after training loss convergence, is observed during pretraining of a large language model, showcasing a memorization-to-generalization process.  					AI-generated summary 				 Grokking, i.e., test performance keeps improving long after training los...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 2. WorldVLA, an autoregressive action world model integrating vision-language-action (VLA) and world models, enhances performance through mutual understanding and generation, improving action prediction and sequence generation with an attention mask strategy.  					AI-generated summary 				 We present ...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 3. Mind2Web 2 benchmark evaluates agentic search systems with a suite of realistic, long-horizon tasks, introducing an Agent-as-a-Judge framework to assess accuracy and source attribution.  					AI-generated summary 				 Agentic search such as Deep Research systems, where large language models autonomo...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 4. SAM4D is a multi-modal and temporal foundation model for segmentation in autonomous driving using Unified Multi-modal Positional Encoding and Motion-aware Cross-modal Memory Attention, with a multi-modal automated data engine generating pseudo-labels.  					AI-generated summary 				 We present SAM4D...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 5. A model trained on real-world egocentric video and body pose predicts video from human actions using an auto-regressive conditional diffusion transformer, evaluated with a hierarchical protocol of tasks.  					AI-generated summary 				 We train models to Predict Ego-centric Video from human Actions ...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 6. A preference-aligned routing framework using a compact 1.5B model effectively matches queries to user-defined domains and action types, outperforming proprietary models in subjective evaluation criteria.  					AI-generated summary 				 With the rapid proliferation of large language models (LLMs) -- ...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 7. A neurosymbolic agent combines language models for fast subtask planning with A$^*$ search for detailed toolpaths, creating a cost-efficient multi-turn image editing solution.  					AI-generated summary 				 We develop a cost-efficient neurosymbolic agent to address challenging multi-turn image edit...
[27.06.2025 06:17] ********************************************************************************
[27.06.2025 06:17] Abstract 8. DeepRare, a large language model-based system, provides accurate rare disease diagnoses using heterogeneous clinical inputs and outperforms other diagnostic methods across various datasets.  					AI-generated summary 				 Rare diseases collectively affect over 300 million individuals worldwide, yet ...
[27.06.2025 06:17] Read previous papers.
[27.06.2025 06:17] Generating reviews via LLM API.
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#reasoning", "#games", "#rl", "#rag", "#multimodal"], "emoji": "üîç", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "MMSearch-R1 - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª—å—à–∏–º –º—É–ª—å—Ç–∏–º–æ–¥
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#math", "#data", "#optimization", "#reasoning", "#benchmark", "#training"], "emoji": "üß†", "ru": {"title": "–û—Ç –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫ –æ–±–æ–±—â–µ–Ω–∏—é: —Ä–∞—Å–∫—Ä—ã–≤–∞—è —Ç–∞–π–Ω—ã –≥—Ä–æ–∫–∏–Ω–≥–∞ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —è–≤–ª–µ–Ω–∏–µ –≥—Ä–æ–∫–∏–Ω–≥–∞ (grokking) –ø—Ä–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#rl", "#multimodal", "#games", "#cv"], "emoji": "üåê", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –∏ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "WorldVLA - —ç—Ç–æ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –¥–µ–π—Å—Ç–≤–∏–π. –û–Ω–∞
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#agents", "#agi", "#benchmark"], "emoji": "üïµÔ∏è", "ru": {"title": "Mind2Web 2: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞", "desc": "Mind2Web 2 - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞, –≤–∫–ª—é—á–∞—é—â–∏–π 130 —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á —Å –¥–ª–∏—Ç–µ–ª—å–Ω—ã–º –≥–æ—Ä
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#games", "#multimodal", "#cv"], "emoji": "üöó", "ru": {"title": "SAM4D: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π", "desc": "SAM4D - —ç—Ç–æ –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω–∞—è –∏ —Ç–µ–º–ø–æ—Ä–∞–ª—å–Ω–∞—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º –≤–æ–∂–¥–µ–Ω–∏–∏. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–Ω
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#diffusion", "#agents", "#games", "#dataset", "#video"], "emoji": "üé•", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º —á–µ–ª–æ–≤–µ–∫–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å PEVA, –æ–±—É—á–µ–Ω–Ω—É—é –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–µ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–π—Å—Ç–≤–∏–π —á–µ–ª–æ–≤–µ–∫–∞. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#training", "#alignment", "#small_models", "#multimodal"], "emoji": "üîÄ", "ru": {"title": "–£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ò–ò —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#cv", "#agents", "#optimization", "#reasoning"], "emoji": "üé®", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–≥–æ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ–π—Ä–æ—Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–π –∞–≥–µ–Ω—Ç –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω —Å–æ—á–µ—Ç–∞–µ—Ç –±—ã—Å—Ç
[27.06.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#reasoning", "#benchmark", "#science", "#dataset", "#healthcare"], "emoji": "üî¨", "ru": {"title": "DeepRare: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "DeepRare - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π, –∏—Å–ø–æ
[27.06.2025 06:17] Renaming data file.
[27.06.2025 06:17] Renaming previous data. hf_papers.json to ./d/2025-06-27.json
[27.06.2025 06:17] Saving new data file.
[27.06.2025 06:17] Generating page.
[27.06.2025 06:17] Renaming previous page.
[27.06.2025 06:17] Renaming previous data. index.html to ./d/2025-06-27.html
[27.06.2025 06:17] Writing result.
[27.06.2025 06:17] Renaming log file.
[27.06.2025 06:17] Renaming previous data. log.txt to ./logs/2025-06-27_last_log.txt
