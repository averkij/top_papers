[27.06.2025 16:15] Read previous papers.
[27.06.2025 16:15] Generating top page (month).
[27.06.2025 16:15] Writing top page (month).
[27.06.2025 17:10] Read previous papers.
[27.06.2025 17:10] Get feed.
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20670
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21520
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21539
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20911
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21551
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21506
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21547
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21552
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16655
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20430
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21272
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21263
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21103
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20936
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.18729
[27.06.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15196
[27.06.2025 17:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.06.2025 17:10] No deleted papers detected.
[27.06.2025 17:10] Downloading and parsing papers (pdf, html). Total: 16.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.20670.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.20670.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.20670.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21520.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21520.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21520.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21539.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21539.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21539.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.20911.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.20911.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.20911.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21551.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21551.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21551.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21506.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21506.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21506.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21547.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21547.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21547.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21552.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21552.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21552.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.16655.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.16655.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.16655.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.20430.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.20430.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.20430.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21272.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21272.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21272.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21263.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21263.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21263.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.21103.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.21103.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.21103.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.20936.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.20936.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.20936.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.18729.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.18729.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.18729.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2506.15196.
[27.06.2025 17:10] Extra JSON file exists (./assets/json/2506.15196.json), skip PDF parsing.
[27.06.2025 17:10] Paper image links file exists (./assets/img_data/2506.15196.json), skip HTML parsing.
[27.06.2025 17:10] Success.
[27.06.2025 17:10] Enriching papers with extra data.
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 0. MMSearch-R1, a reinforcement learning framework, enables large multimodal models to perform efficient, on-demand, multi-turn search in real-world environments, outperforming existing approaches.  					AI-generated summary 				 Robust deployment of large multimodal models (LMMs) in real-world scenari...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 1. MADrive enhances scene reconstruction for autonomous driving by integrating visually similar 3D car assets from an external memory bank to achieve photorealistic synthesis of altered scenarios.  					AI-generated summary 				 Recent advances in scene reconstruction have pushed toward highly realisti...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 2. WorldVLA, an autoregressive action world model integrating vision-language-action (VLA) and world models, enhances performance through mutual understanding and generation, improving action prediction and sequence generation with an attention mask strategy.  					AI-generated summary 				 We present ...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 3. A neurosymbolic agent combines language models for fast subtask planning with A$^*$ search for detailed toolpaths, creating a cost-efficient multi-turn image editing solution.  					AI-generated summary 				 We develop a cost-efficient neurosymbolic agent to address challenging multi-turn image edit...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 4. Grokking, or continued test performance improvement after training loss convergence, is observed during pretraining of a large language model, showcasing a memorization-to-generalization process.  					AI-generated summary 				 Grokking, i.e., test performance keeps improving long after training los...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 5. Mind2Web 2 benchmark evaluates agentic search systems with a suite of realistic, long-horizon tasks, introducing an Agent-as-a-Judge framework to assess accuracy and source attribution.  					AI-generated summary 				 Agentic search such as Deep Research systems, where large language models autonomo...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 6. SAM4D is a multi-modal and temporal foundation model for segmentation in autonomous driving using Unified Multi-modal Positional Encoding and Motion-aware Cross-modal Memory Attention, with a multi-modal automated data engine generating pseudo-labels.  					AI-generated summary 				 We present SAM4D...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 7. A model trained on real-world egocentric video and body pose predicts video from human actions using an auto-regressive conditional diffusion transformer, evaluated with a hierarchical protocol of tasks.  					AI-generated summary 				 We train models to Predict Ego-centric Video from human Actions ...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 8. A preference-aligned routing framework using a compact 1.5B model effectively matches queries to user-defined domains and action types, outperforming proprietary models in subjective evaluation criteria.  					AI-generated summary 				 With the rapid proliferation of large language models (LLMs) -- ...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 9. DeepRare, a large language model-based system, provides accurate rare disease diagnoses using heterogeneous clinical inputs and outperforms other diagnostic methods across various datasets.  					AI-generated summary 				 Rare diseases collectively affect over 300 million individuals worldwide, yet ...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 10. FairyGen generates story-driven cartoon videos from a single drawing by disentangling character modeling and background styling, employing MLLM for storyboards, style propagation for consistency, and MMDiT-based diffusion models for motion.  					AI-generated summary 				 We propose FairyGen, an aut...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 11. DiLoCoX, a decentralized cluster training framework, enhances the training of large-scale models over slow networks by utilizing pipeline parallelism, dual optimizer policy, and gradient compression, achieving significant speed improvements and effective scalability.  					AI-generated summary 				 ...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 12. A novel conditional computation architecture for Transformers dynamically skips middle layers based on input and a gating mechanism, but does not outperform dense baselines in reducing computational cost or improving validation performance.  					AI-generated summary 				 Conditional computation is ...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 13. A physics-based skinning and rigging framework called PhysRig uses volumetric representation and continuum mechanics for more realistic and physically plausible animations.  					AI-generated summary 				 Skinning and rigging are fundamental components in animation, articulated object reconstruction...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 14. Rotary positional embeddings enhance time-varying control in text-to-music generation models with fewer parameters.  					AI-generated summary 				 We propose MuseControlLite, a lightweight mechanism designed to fine-tune text-to-music generation models for precise conditioning using various time-va...
[27.06.2025 17:10] ********************************************************************************
[27.06.2025 17:10] Abstract 15. HeurAgenix, a two-stage hyper-heuristic framework using large language models, evolves and selects heuristics dynamically for combinatorial optimization problems, achieving performance on par with specialized solvers.  					AI-generated summary 				 Heuristic algorithms play a vital role in solving ...
[27.06.2025 17:10] Read previous papers.
[27.06.2025 17:10] Generating reviews via LLM API.
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#reasoning", "#games", "#rl", "#rag", "#multimodal"], "emoji": "üîç", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "MMSearch-R1 - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª—å—à–∏–º –º—É–ª—å—Ç–∏–º–æ–¥
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#3d", "#multimodal", "#games", "#synthetic", "#dataset"], "emoji": "üöó", "ru": {"title": "–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ü–µ–Ω –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –≤–æ–∂–¥–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –≤–Ω–µ—à–Ω–µ–π –ø–∞–º—è—Ç–∏", "desc": "MADrive - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å—Ü–µ–Ω –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º –≤–æ–∂–¥–µ–Ω–∏–∏. –û–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –≤–∏–∑—É–∞
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#rl", "#multimodal", "#games", "#cv"], "emoji": "üåê", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –∏ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "WorldVLA - —ç—Ç–æ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –¥–µ–π—Å—Ç–≤–∏–π. –û–Ω–∞
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#cv", "#agents", "#optimization", "#reasoning"], "emoji": "üé®", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–≥–æ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ–π—Ä–æ—Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–π –∞–≥–µ–Ω—Ç –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω —Å–æ—á–µ—Ç–∞–µ—Ç –±—ã—Å—Ç
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#math", "#data", "#optimization", "#reasoning", "#benchmark", "#training"], "emoji": "üß†", "ru": {"title": "–û—Ç –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫ –æ–±–æ–±—â–µ–Ω–∏—é: —Ä–∞—Å–∫—Ä—ã–≤–∞—è —Ç–∞–π–Ω—ã –≥—Ä–æ–∫–∏–Ω–≥–∞ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —è–≤–ª–µ–Ω–∏–µ –≥—Ä–æ–∫–∏–Ω–≥–∞ (grokking) –ø—Ä–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#agents", "#agi", "#benchmark"], "emoji": "üïµÔ∏è", "ru": {"title": "Mind2Web 2: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞", "desc": "Mind2Web 2 - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞, –≤–∫–ª—é—á–∞—é—â–∏–π 130 —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á —Å –¥–ª–∏—Ç–µ–ª—å–Ω—ã–º –≥–æ—Ä
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#games", "#multimodal", "#cv"], "emoji": "üöó", "ru": {"title": "SAM4D: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π", "desc": "SAM4D - —ç—Ç–æ –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω–∞—è –∏ —Ç–µ–º–ø–æ—Ä–∞–ª—å–Ω–∞—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º –≤–æ–∂–¥–µ–Ω–∏–∏. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–Ω
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#diffusion", "#agents", "#games", "#dataset", "#video"], "emoji": "üé•", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º —á–µ–ª–æ–≤–µ–∫–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å PEVA, –æ–±—É—á–µ–Ω–Ω—É—é –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–µ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–π—Å—Ç–≤–∏–π —á–µ–ª–æ–≤–µ–∫–∞. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#training", "#alignment", "#small_models", "#multimodal"], "emoji": "üîÄ", "ru": {"title": "–£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ò–ò —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#agents", "#reasoning", "#benchmark", "#science", "#dataset", "#healthcare"], "emoji": "üî¨", "ru": {"title": "DeepRare: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "DeepRare - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π, –∏—Å–ø–æ
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#multimodal", "#3d", "#video", "#diffusion", "#story_generation"], "emoji": "üé®", "ru": {"title": "–û—Ç –¥–µ—Ç—Å–∫–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ –∫ –º—É–ª—å—Ç—Ñ–∏–ª—å–º—É: FairyGen –æ–∂–∏–≤–ª—è–µ—Ç –≤–æ–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "desc": "FairyGen - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º—É–ª—å—Ç—Ñ–∏–ª—å–º–æ–≤ –ø–æ –æ–¥–Ω–æ–º—É –¥–µ—Ç—Å–∫–æ–º—É —Ä–∏—Å—É–Ω–∫—É, —Å–æ—Ö—Ä–∞–Ω—è—é—â–∞—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ö—É–¥–æ–∂–µ—Å—Ç–≤
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#training"], "emoji": "üöÄ", "ru": {"title": "DiLoCoX: –ü—Ä–æ—Ä—ã–≤ –≤ –¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "DiLoCoX - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#interpretability", "#architecture", "#optimization", "#training"], "emoji": "‚è≠Ô∏è", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–ø—É—Å–∫ —Å—Ä–µ–¥–Ω–∏—Ö —Å–ª–æ–µ–≤: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —É—Å–ª–æ–≤–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#synthetic", "#dataset", "#games", "#cv", "#3d"], "emoji": "ü¶æ", "ru": {"title": "PhysRig: —Ñ–∏–∑–∏—á–µ—Å–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "PhysRig - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∏–º–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –æ–±—ä–µ–º–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏ –º–µ—Ö–∞–Ω–∏–∫—É —Å–ø–ª–æ—à–Ω—ã—Ö —Å—Ä–µ–¥ –¥–ª—è –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#audio", "#diffusion", "#training", "#games", "#data"], "emoji": "üéµ", "ru": {"title": "–õ–µ–≥–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –º—É–∑—ã–∫–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö –≤–ª–æ–∂–µ–Ω–∏–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ MuseControlLite - –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π –º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä
[27.06.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#training", "#optimization", "#agents", "#architecture"], "emoji": "üß†", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —ç–≤–æ–ª—é—Ü–∏—è –∏ –≤—ã–±–æ—Ä —ç–≤—Ä–∏—Å—Ç–∏–∫ —Å –ø–æ–º–æ—â—å—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞", "desc": "HeurAgenix - —ç—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –≥–∏–ø–µ—Ä-—ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ
[27.06.2025 17:10] Renaming data file.
[27.06.2025 17:10] Renaming previous data. hf_papers.json to ./d/2025-06-27.json
[27.06.2025 17:10] Saving new data file.
[27.06.2025 17:10] Generating page.
[27.06.2025 17:10] Renaming previous page.
[27.06.2025 17:10] Renaming previous data. index.html to ./d/2025-06-27.html
[27.06.2025 17:10] Writing result.
[27.06.2025 17:10] Renaming log file.
[27.06.2025 17:10] Renaming previous data. log.txt to ./logs/2025-06-27_last_log.txt
