[31.01.2025 08:13] Read previous papers.
[31.01.2025 08:13] Generating top page (month).
[31.01.2025 08:13] Writing top page (month).
[31.01.2025 09:10] Read previous papers.
[31.01.2025 09:10] Get feed.
[31.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18492
[31.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18585
[31.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.16411
[31.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18438
[31.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18009
[31.01.2025 09:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.01.2025 09:10] No deleted papers detected.
[31.01.2025 09:10] Downloading and parsing papers (pdf, html). Total: 5.
[31.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.18492.
[31.01.2025 09:10] Extra JSON file exists (./assets/json/2501.18492.json), skip PDF parsing.
[31.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.18492.json), skip HTML parsing.
[31.01.2025 09:10] Success.
[31.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.18585.
[31.01.2025 09:10] Extra JSON file exists (./assets/json/2501.18585.json), skip PDF parsing.
[31.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.18585.json), skip HTML parsing.
[31.01.2025 09:10] Success.
[31.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.16411.
[31.01.2025 09:10] Extra JSON file exists (./assets/json/2501.16411.json), skip PDF parsing.
[31.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.16411.json), skip HTML parsing.
[31.01.2025 09:10] Success.
[31.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.18438.
[31.01.2025 09:10] Extra JSON file exists (./assets/json/2501.18438.json), skip PDF parsing.
[31.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.18438.json), skip HTML parsing.
[31.01.2025 09:10] Success.
[31.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.18009.
[31.01.2025 09:10] Extra JSON file exists (./assets/json/2501.18009.json), skip PDF parsing.
[31.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.18009.json), skip HTML parsing.
[31.01.2025 09:10] Success.
[31.01.2025 09:10] Enriching papers with extra data.
[31.01.2025 09:10] ********************************************************************************
[31.01.2025 09:10] Abstract 0. As LLMs increasingly impact safety-critical applications, ensuring their safety using guardrails remains a key challenge. This paper proposes GuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to reason. Concretely, we first create the GuardReasonerTrain dataset, which cons...
[31.01.2025 09:10] ********************************************************************************
[31.01.2025 09:10] Abstract 1. Large language models (LLMs) such as OpenAI's o1 have demonstrated remarkable abilities in complex reasoning tasks by scaling test-time compute and exhibiting human-like deep thinking. However, we identify a phenomenon we term underthinking, where o1-like LLMs frequently switch between different rea...
[31.01.2025 09:10] ********************************************************************************
[31.01.2025 09:10] Abstract 2. Understanding the physical world is a fundamental challenge in embodied AI, critical for enabling agents to perform complex tasks and operate safely in real-world environments. While Vision-Language Models (VLMs) have shown great promise in reasoning and task planning for embodied agents, their abil...
[31.01.2025 09:10] ********************************************************************************
[31.01.2025 09:10] Abstract 3. The irruption of DeepSeek-R1 constitutes a turning point for the AI industry in general and the LLMs in particular. Its capabilities have demonstrated outstanding performance in several tasks, including creative thinking, code generation, maths and automated program repair, at apparently lower execu...
[31.01.2025 09:10] ********************************************************************************
[31.01.2025 09:10] Abstract 4. Large Language Models have emerged many intellectual capacities. While numerous benchmarks assess their intelligence, limited attention has been given to their ability to explore, an essential capacity for discovering new information and adapting to novel environments in both natural and artificial ...
[31.01.2025 09:10] Read previous papers.
[31.01.2025 09:10] Generating reviews via LLM API.
[31.01.2025 09:10] Using data from previous issue: {"categories": ["#small_models", "#training", "#open_source", "#dataset", "#reasoning", "#benchmark", "#alignment"], "emoji": "ğŸ›¡ï¸", "ru": {"title": "Ğ Ğ°Ğ·ÑƒĞ¼Ğ½Ğ°Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ°: Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğ¼Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ GuardReasoner - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… 
[31.01.2025 09:10] Using data from previous issue: {"categories": ["#math", "#reasoning", "#training", "#optimization"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ“Ğ»ÑƒĞ±Ğ¶Ğµ Ğ¼Ñ‹ÑĞ»Ğ¸, Ñ‚Ğ¾Ñ‡Ğ½ĞµĞµ Ğ¾Ñ‚Ğ²ĞµÑ‚: Ğ±Ğ¾Ñ€ÑŒĞ±Ğ° Ñ 'Ğ½ĞµĞ´Ğ¾Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼' Ğ² Ğ˜Ğ˜", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ Ñ„ĞµĞ½Ğ¾Ğ¼ĞµĞ½ 'Ğ½ĞµĞ´Ğ¾Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ' Ğ² ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ñ‚Ğ¸Ğ¿Ğ° GPT-3, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°ÑÑ‚ÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°
[31.01.2025 09:10] Using data from previous issue: {"categories": ["#games", "#agents", "#multimodal", "#reasoning", "#benchmark"], "emoji": "ğŸ§ª", "ru": {"title": "ĞĞ°ÑƒÑ‡Ğ¸Ğ¼ Ğ˜Ğ˜ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ·Ğ¸ĞºÑƒ", "desc": "PhysBench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (VLM) Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¼Ğ¸Ñ€. ĞĞ½ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ĞµĞµ 10 
[31.01.2025 09:10] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#ethics", "#alignment", "#security", "#training"], "emoji": "ğŸ›¡ï¸", "ru": {"title": "Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞµ Ğ²ÑĞµĞ³Ğ¾: ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ²ÑƒÑ… ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: DeepSeek-R1 Ğ¸ Op
[31.01.2025 09:10] Using data from previous issue: {"categories": ["#agents", "#agi", "#rl", "#reasoning", "#benchmark"], "emoji": "ğŸ§ ", "ru": {"title": "ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğº Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¸Ğ³Ñ€Ñƒ Little Alch
[31.01.2025 09:10] Trying to get texts in Chinese.
[31.01.2025 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

As LLMs increasingly impact safety-critical applications, ensuring their safety using guardrails remains a key challenge. This paper proposes GuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to reason. Concretely, we first create the GuardReasonerTrain dataset, which consists of 127K samples with 460K detailed reasoning steps. Then, we introduce reasoning SFT to unlock the reasoning capability of guard models. In addition, we present hard sample DPO to further strengthen their reasoning ability. In this manner, GuardReasoner achieves better performance, explainability, and generalizability. Extensive experiments and analyses on 13 benchmarks of 3 guardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B surpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on average. We release the training data, code, and models with different scales (1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.
[31.01.2025 09:10] Mistral response. {"id": "8e1204a7aacf43e3ae06e7621fe95a5d", "object": "chat.completion", "created": 1738314648, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5982\u4f55\u786e\u4fdd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u3002\u4f5c\u8005\u63d0\u51fa\u4e86GuardReasoner\uff0c\u901a\u8fc7\u5f15\u5bfc\u5b88\u62a4\u6a21\u578b\u5b66\u4e60\u63a8\u7406\u6765\u4fdd\u969cLLMs\u7684\u5b89\u5168\u3002\u7814\u7a76\u56e2\u961f\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b127K\u6837\u672c\u548c460K\u8be6\u7ec6\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86\u63a8\u7406SFT\u548c\u96be\u6837\u672cDPO\u6765\u63d0\u5347\u5b88\u62a4\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGuardReasoner\u5728\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 289, "total_tokens": 451, "completion_tokens": 162}}
[31.01.2025 09:10] Response: è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œé€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMsçš„å®‰å…¨ã€‚ç ”ç©¶å›¢é˜Ÿåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥æå‡å®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚
[31.01.2025 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œé€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMsçš„å®‰å…¨ã€‚ç ”ç©¶å›¢é˜Ÿåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥æå‡å®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚
[31.01.2025 09:11] Mistral response. {"id": "63672b4c415346609ee20a36f2db6c54", "object": "chat.completion", "created": 1738314651, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5982\u4f55\u786e\u4fdd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u3002\nZh\u00e8 pi\u0101n w\u00e9nzh\u0101ng t\u01ceol\u00f9n le r\u00fah\u00e9 qu\u00e8b\u01ceo d\u00e0 y\u01d4y\u00e1n m\u00f3x\u00edng (LLMs) z\u00e0i \u0101nqu\u00e1n gu\u01cenji\u00e0n y\u00ecngy\u00f2ng zh\u014dng de \u0101nqu\u00e1nx\u00ecng.\n\n\u4f5c\u8005\u63d0\u51fa\u4e86GuardReasoner\uff0c\u901a\u8fc7\u5f15\u5bfc\u5b88\u62a4\u6a21\u578b\u5b66\u4e60\u63a8\u7406\u6765\u4fdd\u969cLLMs\u7684\u5b89\u5168\u3002\nZu\u00f2zh\u011b t\u00edch\u016b le GuardReasoner, t\u014dnggu\u00f2 y\u01d0nd\u01ceo sh\u01d2uh\u00f9 m\u00f3x\u00edng xu\u00e9x\u00ed tu\u012bl\u01d0 l\u00e1i b\u01ceozh\u00e0ng LLMs de \u0101nqu\u00e1n.\n\n\u7814\u7a76\u56e2\u961f\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b127K\u6837\u672c\u548c460K\u8be6\u7ec6\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86\u63a8\u7406SFT\u548c\u96be\u6837\u672cDPO\u6765\u63d0\u5347\u5b88\u62a4\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\nY\u00e1nji\u016b tu\u00e1ndu\u00ec chu\u00e0ngji\u00e0n le y\u012bg\u00e8 b\u0101oh\u00e1n 127K y\u00e0ngb\u011bn h\u00e9 460K xi\u00e1ngx\u00ec tu\u012bl\u01d0 b\u00f9zh\u00f2u de sh\u00f9j\u00f9j\u00ed, b\u00ecng y\u01d0nr\u00f9 le tu\u012bl\u01d0 SFT h\u00e9 n\u00e1n y\u00e0ngb\u011bn DPO l\u00e1i t\u00edsh\u0113ng sh\u01d2uh\u00f9 m\u00f3x\u00edng de tu\u012bl\u01d0 n\u00e9ngl\u00ec.\n\n\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGuardReasoner\u5728\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002\nSh\u00edy\u00e0n ji\u00e9gu\u01d2 xi\u01censh\u00ec, GuardReasoner z\u00e0i x\u00ecngn\u00e9ng, k\u011b ji\u011bsh\u00ecx\u00ecng h\u00e9 f\u00e0nhu\u00e0 n\u00e9ngl\u00ec f\u0101ngmi\u00e0n bi\u01ceoxi\u00e0n g\u00e8ng h\u01ceo."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 177, "total_tokens": 669, "completion_tokens": 492}}
[31.01.2025 09:11] Response: è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚
ZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le rÃºhÃ© quÃ¨bÇo dÃ  yÇ”yÃ¡n mÃ³xÃ­ng (LLMs) zÃ i ÄnquÃ¡n guÇnjiÃ n yÃ¬ngyÃ²ng zhÅng de ÄnquÃ¡nxÃ¬ng.

ä½œè€…æå‡ºäº†GuardReasonerï¼Œé€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMsçš„å®‰å…¨ã€‚
ZuÃ²zhÄ› tÃ­chÅ« le GuardReasoner, tÅngguÃ² yÇndÇo shÇ’uhÃ¹ mÃ³xÃ­ng xuÃ©xÃ­ tuÄ«lÇ lÃ¡i bÇozhÃ ng LLMs de ÄnquÃ¡n.

ç ”ç©¶å›¢é˜Ÿåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥æå‡å®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
YÃ¡njiÅ« tuÃ¡nduÃ¬ chuÃ ngjiÃ n le yÄ«gÃ¨ bÄohÃ¡n 127K yÃ ngbÄ›n hÃ© 460K xiÃ¡ngxÃ¬ tuÄ«lÇ bÃ¹zhÃ²u de shÃ¹jÃ¹jÃ­, bÃ¬ng yÇnrÃ¹ le tuÄ«lÇ SFT hÃ© nÃ¡n yÃ ngbÄ›n DPO lÃ¡i tÃ­shÄ“ng shÇ’uhÃ¹ mÃ³xÃ­ng de tuÄ«lÇ nÃ©nglÃ¬.

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚
ShÃ­yÃ n jiÃ©guÇ’ xiÇnshÃ¬, GuardReasoner zÃ i xÃ¬ngnÃ©ng, kÄ› jiÄ›shÃ¬xÃ¬ng hÃ© fÃ nhuÃ  nÃ©nglÃ¬ fÄngmiÃ n biÇoxiÃ n gÃ¨ng hÇo.
[31.01.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œé€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMsçš„å®‰å…¨ã€‚ç ”ç©¶å›¢é˜Ÿåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥æå‡å®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚
[31.01.2025 09:11] Mistral response. {"id": "72e47985de614a8da737ab5325dc6842", "object": "chat.completion", "created": 1738314662, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\n    {\"word\": \"\u8ba8\u8bba\", \"pinyin\": \"t\u01ceo l\u00f9n\", \"trans\": \"discuss\"},\n    {\"word\": \"\u786e\u4fdd\", \"pinyin\": \"qu\u00e8 b\u01ceo\", \"trans\": \"ensure\"},\n    {\"word\": \"\u5b89\u5168\", \"pinyin\": \"\u0101n qu\u00e1n\", \"trans\": \"safety\"},\n    {\"word\": \"\u5173\u952e\", \"pinyin\": \"gu\u0101n ji\u00e0n\", \"trans\": \"key\"},\n    {\"word\": \"\u5e94\u7528\", \"pinyin\": \"y\u00ecng y\u00f2ng\", \"trans\": \"application\"},\n    {\"word\": \"\u63d0\u51fa\", \"pinyin\": \"t\u00ed ch\u016b\", \"trans\": \"propose\"},\n    {\"word\": \"\u5f15\u5bfc\", \"pinyin\": \"y\u01d0n d\u01ceo\", \"trans\": \"guide\"},\n    {\"word\": \"\u5b88\u62a4\", \"pinyin\": \"sh\u01d2u h\u00f9\", \"trans\": \"guard\"},\n    {\"word\": \"\u63a8\u7406\", \"pinyin\": \"tu\u012b l\u01d0\", \"trans\": \"reasoning\"},\n    {\"word\": \"\u4fdd\u969c\", \"pinyin\": \"b\u01ceo zh\u00e0ng\", \"trans\": \"safeguard\"},\n    {\"word\": \"\u521b\u5efa\", \"pinyin\": \"chu\u00e0ng ji\u00e0n\", \"trans\": \"create\"},\n    {\"word\": \"\u6837\u672c\", \"pinyin\": \"y\u00e0ng b\u011bn\", \"trans\": \"sample\"},\n    {\"word\": \"\u8be6\u7ec6\", \"pinyin\": \"xi\u00e1ng x\u00ec\", \"trans\": \"detailed\"},\n    {\"word\": \"\u6b65\u9aa4\", \"pinyin\": \"b\u00f9 zh\u00f2u\", \"trans\": \"step\"},\n    {\"word\": \"\u5f15\u5165\", \"pinyin\": \"y\u01d0n r\u00f9\", \"trans\": \"introduce\"},\n    {\"word\": \"\u63d0\u5347\", \"pinyin\": \"t\u00ed sh\u0113ng\", \"trans\": \"enhance\"},\n    {\"word\": \"\u80fd\u529b\", \"pinyin\": \"n\u00e9ng l\u00ec\", \"trans\": \"ability\"},\n    {\"word\": \"\u8868\u73b0\", \"pinyin\": \"bi\u01ceo xi\u00e0n\", \"trans\": \"performance\"},\n    {\"word\": \"\u53ef\u89e3\u91ca\u6027\", \"pinyin\": \"k\u011b ji\u011b sh\u00ec x\u00ecng\", \"trans\": \"interpretability\"},\n    {\"word\": \"\u6cdb\u5316\", \"pinyin\": \"f\u00e0n hu\u00e0\", \"trans\": \"generalization\"}\n]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 209, "total_tokens": 791, "completion_tokens": 582}}
[31.01.2025 09:11] Response: [
    {"word": "è®¨è®º", "pinyin": "tÇo lÃ¹n", "trans": "discuss"},
    {"word": "ç¡®ä¿", "pinyin": "quÃ¨ bÇo", "trans": "ensure"},
    {"word": "å®‰å…¨", "pinyin": "Än quÃ¡n", "trans": "safety"},
    {"word": "å…³é”®", "pinyin": "guÄn jiÃ n", "trans": "key"},
    {"word": "åº”ç”¨", "pinyin": "yÃ¬ng yÃ²ng", "trans": "application"},
    {"word": "æå‡º", "pinyin": "tÃ­ chÅ«", "trans": "propose"},
    {"word": "å¼•å¯¼", "pinyin": "yÇn dÇo", "trans": "guide"},
    {"word": "å®ˆæŠ¤", "pinyin": "shÇ’u hÃ¹", "trans": "guard"},
    {"word": "æ¨ç†", "pinyin": "tuÄ« lÇ", "trans": "reasoning"},
    {"word": "ä¿éšœ", "pinyin": "bÇo zhÃ ng", "trans": "safeguard"},
    {"word": "åˆ›å»º", "pinyin": "chuÃ ng jiÃ n", "trans": "create"},
    {"word": "æ ·æœ¬", "pinyin": "yÃ ng bÄ›n", "trans": "sample"},
    {"word": "è¯¦ç»†", "pinyin": "xiÃ¡ng xÃ¬", "trans": "detailed"},
    {"word": "æ­¥éª¤", "pinyin": "bÃ¹ zhÃ²u", "trans": "step"},
    {"word": "å¼•å…¥", "pinyin": "yÇn rÃ¹", "trans": "introduce"},
    {"word": "æå‡", "pinyin": "tÃ­ shÄ“ng", "trans": "enhance"},
    {"word": "èƒ½åŠ›", "pinyin": "nÃ©ng lÃ¬", "trans": "ability"},
    {"word": "è¡¨ç°", "pinyin": "biÇo xiÃ n", "trans": "performance"},
    {"word": "å¯è§£é‡Šæ€§", "pinyin": "kÄ› jiÄ› shÃ¬ xÃ¬ng", "trans": "interpretability"},
    {"word": "æ³›åŒ–", "pinyin": "fÃ n huÃ ", "trans": "generalization"}
]
[31.01.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¦‚ä½•ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚ä½œè€…æå‡ºäº†GuardReasonerï¼Œé€šè¿‡å¼•å¯¼å®ˆæŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥ä¿éšœLLMsçš„å®‰å…¨ã€‚ç ”ç©¶å›¢é˜Ÿåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†æ¨ç†SFTå’Œéš¾æ ·æœ¬DPOæ¥æå‡å®ˆæŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuardReasoneråœ¨æ€§èƒ½ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚
[31.01.2025 09:11] Mistral response. {"id": "689a71b39a164d4c83dee393bce80cf4", "object": "chat.completion", "created": 1738314674, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "This article discusses how to ensure the safety of Large Language Models (LLMs) in security-critical applications. The authors propose GuardReasoner, which guides the guard model to learn reasoning to safeguard LLMs. The research team created a dataset containing 127K samples and 460K detailed reasoning steps and introduced reasoning SFT and hard sample DPO to enhance the guard model's reasoning capabilities. Experimental results show that GuardReasoner performs better in terms of performance, interpretability, and generalization."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 175, "total_tokens": 286, "completion_tokens": 111}}
[31.01.2025 09:11] Response: This article discusses how to ensure the safety of Large Language Models (LLMs) in security-critical applications. The authors propose GuardReasoner, which guides the guard model to learn reasoning to safeguard LLMs. The research team created a dataset containing 127K samples and 460K detailed reasoning steps and introduced reasoning SFT and hard sample DPO to enhance the guard model's reasoning capabilities. Experimental results show that GuardReasoner performs better in terms of performance, interpretability, and generalization.
[31.01.2025 09:11] Renaming data file.
[31.01.2025 09:11] Renaming previous data. hf_papers.json to ./d/2025-01-31.json
[31.01.2025 09:11] Saving new data file.
[31.01.2025 09:11] Generating page.
[31.01.2025 09:11] Renaming previous page.
[31.01.2025 09:11] Renaming previous data. index.html to ./d/2025-01-31.html
[31.01.2025 09:11] [Experimental] Generating Chinese page for reading.
[31.01.2025 09:11] Chinese vocab [{'word': 'è®¨è®º', 'pinyin': 'tÇo lÃ¹n', 'trans': 'discuss'}, {'word': 'ç¡®ä¿', 'pinyin': 'quÃ¨ bÇo', 'trans': 'ensure'}, {'word': 'å®‰å…¨', 'pinyin': 'Än quÃ¡n', 'trans': 'safety'}, {'word': 'å…³é”®', 'pinyin': 'guÄn jiÃ n', 'trans': 'key'}, {'word': 'åº”ç”¨', 'pinyin': 'yÃ¬ng yÃ²ng', 'trans': 'application'}, {'word': 'æå‡º', 'pinyin': 'tÃ­ chÅ«', 'trans': 'propose'}, {'word': 'å¼•å¯¼', 'pinyin': 'yÇn dÇo', 'trans': 'guide'}, {'word': 'å®ˆæŠ¤', 'pinyin': 'shÇ’u hÃ¹', 'trans': 'guard'}, {'word': 'æ¨ç†', 'pinyin': 'tuÄ« lÇ', 'trans': 'reasoning'}, {'word': 'ä¿éšœ', 'pinyin': 'bÇo zhÃ ng', 'trans': 'safeguard'}, {'word': 'åˆ›å»º', 'pinyin': 'chuÃ ng jiÃ n', 'trans': 'create'}, {'word': 'æ ·æœ¬', 'pinyin': 'yÃ ng bÄ›n', 'trans': 'sample'}, {'word': 'è¯¦ç»†', 'pinyin': 'xiÃ¡ng xÃ¬', 'trans': 'detailed'}, {'word': 'æ­¥éª¤', 'pinyin': 'bÃ¹ zhÃ²u', 'trans': 'step'}, {'word': 'å¼•å…¥', 'pinyin': 'yÇn rÃ¹', 'trans': 'introduce'}, {'word': 'æå‡', 'pinyin': 'tÃ­ shÄ“ng', 'trans': 'enhance'}, {'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©ng lÃ¬', 'trans': 'ability'}, {'word': 'è¡¨ç°', 'pinyin': 'biÇo xiÃ n', 'trans': 'performance'}, {'word': 'å¯è§£é‡Šæ€§', 'pinyin': 'kÄ› jiÄ› shÃ¬ xÃ¬ng', 'trans': 'interpretability'}, {'word': 'æ³›åŒ–', 'pinyin': 'fÃ n huÃ ', 'trans': 'generalization'}]
[31.01.2025 09:11] Renaming previous Chinese page.
[31.01.2025 09:11] Renaming previous data. zh.html to ./d/2025-01-30_zh_reading_task.html
[31.01.2025 09:11] Writing Chinese reading task.
[31.01.2025 09:11] Writing result.
[31.01.2025 09:11] Renaming log file.
[31.01.2025 09:11] Renaming previous data. log.txt to ./logs/2025-01-31_last_log.txt
