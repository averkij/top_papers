[16.01.2025 12:18] Read previous papers.
[16.01.2025 12:18] Generating top page (month).
[16.01.2025 12:18] Writing top page (month).
[16.01.2025 13:16] Read previous papers.
[16.01.2025 13:16] Get feed.
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08828
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08983
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08994
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08365
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08809
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08970
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.07783
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.09012
[16.01.2025 13:16] Get page data from previous paper. URL: https://huggingface.co/papers/2501.09019
[16.01.2025 13:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[16.01.2025 13:16] No deleted papers detected.
[16.01.2025 13:16] Downloading and parsing papers (pdf, html). Total: 9.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.08828.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.08828.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.08828.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.08983.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.08983.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.08983.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.08994.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.08994.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.08994.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.08365.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.08365.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.08365.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.08809.
[16.01.2025 13:16] Downloading paper 2501.08809 from http://arxiv.org/pdf/2501.08809v1...
[16.01.2025 13:16] Failed to download and parse paper https://huggingface.co/papers/2501.08809: 'LTChar' object is not iterable
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.08970.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.08970.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.08970.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.07783.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.07783.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.07783.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.09012.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.09012.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.09012.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Downloading and parsing paper https://huggingface.co/papers/2501.09019.
[16.01.2025 13:16] Extra JSON file exists (./assets/json/2501.09019.json), skip PDF parsing.
[16.01.2025 13:16] Paper image links file exists (./assets/img_data/2501.09019.json), skip HTML parsing.
[16.01.2025 13:16] Success.
[16.01.2025 13:16] Enriching papers with extra data.
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 0. Multi-modal document retrieval is designed to identify and retrieve various forms of multi-modal content, such as figures, tables, charts, and layout information from extensive documents. Despite its significance, there is a notable lack of a robust benchmark to effectively evaluate the performance ...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 1. 3D scene generation has garnered growing attention in recent years and has made significant progress. Generating 4D cities is more challenging than 3D scenes due to the presence of structurally complex, visually diverse objects like buildings and vehicles, and heightened human sensitivity to distort...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 2. Video generation has achieved remarkable progress with the introduction of diffusion models, which have significantly improved the quality of generated videos. However, recent research has primarily focused on scaling up model training, while offering limited insights into the direct impact of repre...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 3. Many AI companies are training their large language models (LLMs) on data without the permission of the copyright owners. The permissibility of doing so varies by jurisdiction: in countries like the EU and Japan, this is allowed under certain restrictions, while in the United States, the legal lands...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 4. In recent years, remarkable advancements in artificial intelligence-generated content (AIGC) have been achieved in the fields of image synthesis and text generation, generating content comparable to that produced by humans. However, the quality of AI-generated music has not yet reached this standard...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 5. We often interact with untrusted parties. Prioritization of privacy can limit the effectiveness of these interactions, as achieving certain goals necessitates sharing private data. Traditionally, addressing this challenge has involved either seeking trusted intermediaries or constructing cryptograph...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 6. Image pyramids are widely adopted in top-performing methods to obtain multi-scale features for precise visual perception and understanding. However, current image pyramids use the same large-scale model to process multiple resolutions of images, leading to significant computational cost. To address ...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 7. We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability shall be elicited to evaluate the aesthetics of artworks. To facilitate this investigation, we construct MM-StyleBench, a novel high-quality dataset for benchmarking artistic stylization. We then develop a principled method...
[16.01.2025 13:16] ********************************************************************************
[16.01.2025 13:16] Abstract 8. The first-in-first-out (FIFO) video diffusion, built on a pre-trained text-to-video model, has recently emerged as an effective approach for tuning-free long video generation. This technique maintains a queue of video frames with progressively increasing noise, continuously producing clean frames at...
[16.01.2025 13:16] Read previous papers.
[16.01.2025 13:16] Generating reviews via LLM API.
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#dataset"], "emoji": "üîç", "ru": {"title": "MMDocIR: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ MMDocIR –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ë–µ–Ω—á–º–∞—Ä–∫ –≤–∫–ª—é—á–∞–µ—Ç –¥–≤–µ –∑–∞–¥–∞—á–∏: –ø–æ–∏—Å–∫ –Ω–∞ —É
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#3d", "#dataset"], "emoji": "üèôÔ∏è", "ru": {"title": "–ö–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 4D-–≥–æ—Ä–æ–¥–æ–≤ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–∏–Ω–∞–º–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏–∫–∏", "desc": "CityDreamer4D - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö 4D-–≥–æ—Ä–æ–¥–æ–≤. –û–Ω–∞ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞) –∏ —Å
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#video", "#diffusion", "#architecture"], "emoji": "üé¨", "ru": {"title": "RepVideo: —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç RepVideo - —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞. –ê–≤—Ç–æ—Ä—ã –æ–±
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#open_source", "#ethics", "#data", "#dataset"], "emoji": "üìö", "ru": {"title": "–û—Ç–∫—Ä—ã—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ò–ò: –≤—ã–∑–æ–≤—ã –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã", "desc": "–°—Ç–∞—Ç—å—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π. –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —é—Ä–∏–¥–∏—á
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#audio", "#story_generation", "#multimodal", "#dataset"], "emoji": "üéµ", "ru": {"title": "XMusic: –ò–ò-–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è —Å —É–ø—Ä–∞–≤–ª—è–µ–º—ã–º–∏ —ç–º–æ—Ü–∏—è–º–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç XMusic - –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–π –º—É–∑—ã–∫–∏, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#data", "#ethics", "#architecture", "#security", "#inference"], "emoji": "üîê", "ru": {"title": "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∫–∞–∫ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –ø–æ—Å—Ä–µ–¥–Ω–∏–∫ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è - Trusted Capa
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#architecture", "#multimodal", "#cv"], "emoji": "üîç", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –º–Ω–æ–≥–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Parameter-Inverted Image Pyramid Networks (PIIP). PIIP –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#artificial intelligence", "#reasoning", "#hallucinations", "#multimodal", "#benchmark", "#dataset"], "emoji": "üé®", "ru": {"title": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —É—á–∏—Ç—Å—è –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–æ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ 
[16.01.2025 13:16] Using data from previous issue: {"categories": ["#benchmark", "#video", "#long_context", "#diffusion"], "emoji": "üêç", "ru": {"title": "–ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ–µ –≤–∏–¥–µ–æ: Ouroboros-Diffusion –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Ouroboros-Di
[16.01.2025 13:16] Loading Chinese text from previous data.
[16.01.2025 13:16] Renaming data file.
[16.01.2025 13:16] Renaming previous data. hf_papers.json to ./d/2025-01-16.json
[16.01.2025 13:16] Saving new data file.
[16.01.2025 13:16] Generating page.
[16.01.2025 13:16] Renaming previous page.
[16.01.2025 13:16] Renaming previous data. index.html to ./d/2025-01-16.html
[16.01.2025 13:16] [Experimental] Generating Chinese page for reading.
[16.01.2025 13:16] Chinese vocab [{'word': 'Â§öÊ®°ÊÄÅ', 'pinyin': 'du≈ç m√≥ t√†i', 'trans': 'multimodal'}, {'word': 'Ê£ÄÁ¥¢', 'pinyin': 'ji«én su«í', 'trans': 'retrieval'}, {'word': 'Êó®Âú®', 'pinyin': 'zh«ê z√†i', 'trans': 'aim to'}, {'word': 'ËØÜÂà´', 'pinyin': 'sh√≠ bi√©', 'trans': 'recognize'}, {'word': 'Â∏ÉÂ±Ä', 'pinyin': 'b√π ji√∫', 'trans': 'layout'}, {'word': 'Â∞ΩÁÆ°', 'pinyin': 'j√¨n gu«én', 'trans': 'although'}, {'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´ zh«în', 'trans': 'benchmark'}, {'word': 'ËØÑ‰º∞', 'pinyin': 'p√≠ng g≈´', 'trans': 'evaluate'}, {'word': 'Á≥ªÁªü', 'pinyin': 'x√¨ t«íng', 'trans': 'system'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}, {'word': 'ÊèêÂá∫', 'pinyin': 't√≠ ch≈´', 'trans': 'propose'}, {'word': 'È°µÈù¢Á∫ß', 'pinyin': 'y√® mi√†n j√≠', 'trans': 'page-level'}, {'word': 'Ê†áÊ≥®', 'pinyin': 'biƒÅo zh√π', 'trans': 'annotation'}, {'word': 'ËµÑÊ∫ê', 'pinyin': 'zƒ´ yu√°n', 'trans': 'resource'}, {'word': 'ËßÜËßâ', 'pinyin': 'sh√¨ ju√©', 'trans': 'visual'}, {'word': 'ÊñáÊú¨', 'pinyin': 'w√©n bƒõn', 'trans': 'text'}, {'word': 'Ë°®Áé∞', 'pinyin': 'bi«éo xi√†n', 'trans': 'perform'}, {'word': '‰ºò‰∫é', 'pinyin': 'y≈çu y√∫', 'trans': 'superior to'}, {'word': '‰ΩøÁî®', 'pinyin': 'sh«ê y√≤ng', 'trans': 'use'}, {'word': 'OCR', 'pinyin': '', 'trans': 'Optical Character Recognition'}]
[16.01.2025 13:16] Renaming previous Chinese page.
[16.01.2025 13:16] Renaming previous data. zh.html to ./d/2025-01-15_zh_reading_task.html
[16.01.2025 13:16] Writing Chinese reading task.
[16.01.2025 13:16] Writing result.
[16.01.2025 13:16] Renaming log file.
[16.01.2025 13:16] Renaming previous data. log.txt to ./logs/2025-01-16_last_log.txt
