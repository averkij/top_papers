[16.01.2025 07:10] Read previous papers.
[16.01.2025 07:10] Generating top page (month).
[16.01.2025 07:10] Writing top page (month).
[16.01.2025 08:12] Read previous papers.
[16.01.2025 08:12] Get feed.
[16.01.2025 08:12] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08828
[16.01.2025 08:12] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08994
[16.01.2025 08:12] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08983
[16.01.2025 08:12] Get page data from previous paper. URL: https://huggingface.co/papers/2501.08809
[16.01.2025 08:12] Get page data from previous paper. URL: https://huggingface.co/papers/2501.09012
[16.01.2025 08:12] Get page data from previous paper. URL: https://huggingface.co/papers/2501.09019
[16.01.2025 08:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[16.01.2025 08:12] No deleted papers detected.
[16.01.2025 08:12] Downloading and parsing papers (pdf, html). Total: 6.
[16.01.2025 08:12] Downloading and parsing paper https://huggingface.co/papers/2501.08828.
[16.01.2025 08:12] Extra JSON file exists (./assets/json/2501.08828.json), skip PDF parsing.
[16.01.2025 08:12] Paper image links file exists (./assets/img_data/2501.08828.json), skip HTML parsing.
[16.01.2025 08:12] Success.
[16.01.2025 08:12] Downloading and parsing paper https://huggingface.co/papers/2501.08994.
[16.01.2025 08:12] Extra JSON file exists (./assets/json/2501.08994.json), skip PDF parsing.
[16.01.2025 08:12] Paper image links file exists (./assets/img_data/2501.08994.json), skip HTML parsing.
[16.01.2025 08:12] Success.
[16.01.2025 08:12] Downloading and parsing paper https://huggingface.co/papers/2501.08983.
[16.01.2025 08:12] Extra JSON file exists (./assets/json/2501.08983.json), skip PDF parsing.
[16.01.2025 08:12] Paper image links file exists (./assets/img_data/2501.08983.json), skip HTML parsing.
[16.01.2025 08:12] Success.
[16.01.2025 08:12] Downloading and parsing paper https://huggingface.co/papers/2501.08809.
[16.01.2025 08:12] Downloading paper 2501.08809 from http://arxiv.org/pdf/2501.08809v1...
[16.01.2025 08:12] Failed to download and parse paper https://huggingface.co/papers/2501.08809: 'LTChar' object is not iterable
[16.01.2025 08:12] Downloading and parsing paper https://huggingface.co/papers/2501.09012.
[16.01.2025 08:12] Extra JSON file exists (./assets/json/2501.09012.json), skip PDF parsing.
[16.01.2025 08:12] Paper image links file exists (./assets/img_data/2501.09012.json), skip HTML parsing.
[16.01.2025 08:12] Success.
[16.01.2025 08:12] Downloading and parsing paper https://huggingface.co/papers/2501.09019.
[16.01.2025 08:12] Extra JSON file exists (./assets/json/2501.09019.json), skip PDF parsing.
[16.01.2025 08:12] Paper image links file exists (./assets/img_data/2501.09019.json), skip HTML parsing.
[16.01.2025 08:12] Success.
[16.01.2025 08:12] Enriching papers with extra data.
[16.01.2025 08:12] ********************************************************************************
[16.01.2025 08:12] Abstract 0. Multi-modal document retrieval is designed to identify and retrieve various forms of multi-modal content, such as figures, tables, charts, and layout information from extensive documents. Despite its significance, there is a notable lack of a robust benchmark to effectively evaluate the performance ...
[16.01.2025 08:12] ********************************************************************************
[16.01.2025 08:12] Abstract 1. Video generation has achieved remarkable progress with the introduction of diffusion models, which have significantly improved the quality of generated videos. However, recent research has primarily focused on scaling up model training, while offering limited insights into the direct impact of repre...
[16.01.2025 08:12] ********************************************************************************
[16.01.2025 08:12] Abstract 2. 3D scene generation has garnered growing attention in recent years and has made significant progress. Generating 4D cities is more challenging than 3D scenes due to the presence of structurally complex, visually diverse objects like buildings and vehicles, and heightened human sensitivity to distort...
[16.01.2025 08:12] ********************************************************************************
[16.01.2025 08:12] Abstract 3. In recent years, remarkable advancements in artificial intelligence-generated content (AIGC) have been achieved in the fields of image synthesis and text generation, generating content comparable to that produced by humans. However, the quality of AI-generated music has not yet reached this standard...
[16.01.2025 08:12] ********************************************************************************
[16.01.2025 08:12] Abstract 4. We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability shall be elicited to evaluate the aesthetics of artworks. To facilitate this investigation, we construct MM-StyleBench, a novel high-quality dataset for benchmarking artistic stylization. We then develop a principled method...
[16.01.2025 08:12] ********************************************************************************
[16.01.2025 08:12] Abstract 5. The first-in-first-out (FIFO) video diffusion, built on a pre-trained text-to-video model, has recently emerged as an effective approach for tuning-free long video generation. This technique maintains a queue of video frames with progressively increasing noise, continuously producing clean frames at...
[16.01.2025 08:12] Read previous papers.
[16.01.2025 08:12] Generating reviews via LLM API.
[16.01.2025 08:12] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#dataset"], "emoji": "üîç", "ru": {"title": "MMDocIR: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ MMDocIR –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ë–µ–Ω—á–º–∞—Ä–∫ –≤–∫–ª—é—á–∞–µ—Ç –¥–≤–µ –∑–∞–¥–∞—á–∏: –ø–æ–∏—Å–∫ –Ω–∞ —É
[16.01.2025 08:12] Using data from previous issue: {"categories": ["#video", "#diffusion", "#architecture"], "emoji": "üé¨", "ru": {"title": "RepVideo: —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç RepVideo - —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞. –ê–≤—Ç–æ—Ä—ã –æ–±
[16.01.2025 08:12] Using data from previous issue: {"categories": ["#3d", "#dataset"], "emoji": "üèôÔ∏è", "ru": {"title": "–ö–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 4D-–≥–æ—Ä–æ–¥–æ–≤ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–∏–Ω–∞–º–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏–∫–∏", "desc": "CityDreamer4D - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö 4D-–≥–æ—Ä–æ–¥–æ–≤. –û–Ω–∞ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞) –∏ —Å
[16.01.2025 08:12] Using data from previous issue: {"categories": ["#audio", "#story_generation", "#multimodal", "#dataset"], "emoji": "üéµ", "ru": {"title": "XMusic: –ò–ò-–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è —Å —É–ø—Ä–∞–≤–ª—è–µ–º—ã–º–∏ —ç–º–æ—Ü–∏—è–º–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç XMusic - –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–π –º—É–∑—ã–∫–∏, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø
[16.01.2025 08:12] Using data from previous issue: {"categories": ["#artificial intelligence", "#reasoning", "#hallucinations", "#multimodal", "#benchmark", "#dataset"], "emoji": "üé®", "ru": {"title": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —É—á–∏—Ç—Å—è –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–æ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ 
[16.01.2025 08:12] Using data from previous issue: {"categories": ["#benchmark", "#video", "#long_context", "#diffusion"], "emoji": "üêç", "ru": {"title": "–ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ–µ –≤–∏–¥–µ–æ: Ouroboros-Diffusion –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Ouroboros-Di
[16.01.2025 08:12] Loading Chinese text from previous data.
[16.01.2025 08:12] Renaming data file.
[16.01.2025 08:12] Renaming previous data. hf_papers.json to ./d/2025-01-16.json
[16.01.2025 08:12] Saving new data file.
[16.01.2025 08:12] Generating page.
[16.01.2025 08:12] Renaming previous page.
[16.01.2025 08:12] Renaming previous data. index.html to ./d/2025-01-16.html
[16.01.2025 08:12] [Experimental] Generating Chinese page for reading.
[16.01.2025 08:12] Chinese vocab [{'word': '‰ªãÁªç', 'pinyin': 'ji√® sh√†o', 'trans': 'introduce'}, {'word': 'Á≥ªÂàó', 'pinyin': 'x√¨ li√®', 'trans': 'series'}, {'word': 'Ê®°Âûã', 'pinyin': 'm√≥ x√≠ng', 'trans': 'model'}, {'word': 'Â§ÑÁêÜ', 'pinyin': 'ch«î l«ê', 'trans': 'process'}, {'word': '‰∏ä‰∏ãÊñá', 'pinyin': 'sh√†ng xi√† w√©n', 'trans': 'context'}, {'word': 'ÂçìË∂ä', 'pinyin': 'zhu√≥ yu√®', 'trans': 'outstanding'}, {'word': 'ËÉΩÂäõ', 'pinyin': 'n√©ng l√¨', 'trans': 'ability'}, {'word': 'Ê†∏ÂøÉ', 'pinyin': 'h√© xƒ´n', 'trans': 'core'}, {'word': 'Èó™Áîµ', 'pinyin': 'sh«én di√†n', 'trans': 'lightning'}, {'word': 'Ê≥®ÊÑèÂäõ', 'pinyin': 'zh√π y√¨ l√¨', 'trans': 'attention'}, {'word': 'È´òÊïà', 'pinyin': 'gƒÅo xi√†o', 'trans': 'efficient'}, {'word': 'Êâ©Â±ï', 'pinyin': 'ku√≤ zh«én', 'trans': 'expand'}, {'word': 'Ê∑∑Âêà', 'pinyin': 'h√πn h√©', 'trans': 'hybrid'}, {'word': '‰∏ìÂÆ∂', 'pinyin': 'zhuƒÅn jiƒÅ', 'trans': 'expert'}, {'word': 'ÈõÜÊàê', 'pinyin': 'j√≠ ch√©ng', 'trans': 'integrate'}, {'word': 'Âπ∂Ë°å', 'pinyin': 'b√¨ng x√≠ng', 'trans': 'parallel'}, {'word': 'Á≠ñÁï•', 'pinyin': 'c√® l√º√®', 'trans': 'strategy'}, {'word': 'ÈÄö‰ø°', 'pinyin': 't≈çng x√¨n', 'trans': 'communication'}, {'word': 'ÈáçÂè†', 'pinyin': 'ch√≥ng di√©', 'trans': 'overlap'}, {'word': 'ÊäÄÊúØ', 'pinyin': 'j√¨ sh√π', 'trans': 'technology'}, {'word': 'ËÆ≠ÁªÉ', 'pinyin': 'x√πn li√†n', 'trans': 'train'}, {'word': 'Êé®ÁêÜ', 'pinyin': 'tuƒ´ l«ê', 'trans': 'inference'}, {'word': 'Á™óÂè£', 'pinyin': 'chuƒÅng k«íu', 'trans': 'window'}, {'word': 'Ê†áËÆ∞', 'pinyin': 'biƒÅo j√¨', 'trans': 'token'}, {'word': 'ËßÜËßâ', 'pinyin': 'sh√¨ ju√©', 'trans': 'visual'}, {'word': 'ËØ≠Ë®Ä', 'pinyin': 'y«î y√°n', 'trans': 'language'}, {'word': 'ÊåÅÁª≠', 'pinyin': 'ch√≠ x√π', 'trans': 'continuous'}, {'word': 'ÂÆûÈ™å', 'pinyin': 'sh√≠ y√†n', 'trans': 'experiment'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}, {'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´ zh«în', 'trans': 'benchmark'}, {'word': 'ÂÖ¨ÂºÄ', 'pinyin': 'g≈çng kƒÅi', 'trans': 'public'}, {'word': 'ÂèëÂ∏É', 'pinyin': 'fƒÅ b√π', 'trans': 'release'}]
[16.01.2025 08:12] Renaming previous Chinese page.
[16.01.2025 08:12] Renaming previous data. zh.html to ./d/2025-01-15_zh_reading_task.html
[16.01.2025 08:12] Writing Chinese reading task.
[16.01.2025 08:12] Writing result.
[16.01.2025 08:12] Renaming log file.
[16.01.2025 08:12] Renaming previous data. log.txt to ./logs/2025-01-16_last_log.txt
