[13.06.2025 07:12] Read previous papers.
[13.06.2025 07:12] Generating top page (month).
[13.06.2025 07:12] Writing top page (month).
[13.06.2025 08:16] Read previous papers.
[13.06.2025 08:16] Get feed.
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09513
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10954
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09993
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10857
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10540
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10974
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10960
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10821
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10890
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10741
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10952
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09967
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09344
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08060
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10910
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10357
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09942
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10953
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06694
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10036
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08373
[13.06.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2506.07795
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06950
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06561
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.05982
[13.06.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10378
[13.06.2025 08:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[13.06.2025 08:16] No deleted papers detected.
[13.06.2025 08:16] Downloading and parsing papers (pdf, html). Total: 26.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.09513.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.09513.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.09513.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10954.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10954.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10954.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.09993.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.09993.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.09993.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10857.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10857.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10857.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10540.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10540.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10540.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10974.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10974.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10974.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10960.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10960.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10960.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10821.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10821.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10821.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10890.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10890.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10890.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10741.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10741.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10741.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10952.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10952.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10952.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.09967.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.09967.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.09967.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.09344.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.09344.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.09344.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.08060.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.08060.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.08060.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10910.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10910.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10910.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10357.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10357.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10357.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.09942.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.09942.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.09942.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10953.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10953.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10953.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.06694.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.06694.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.06694.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10036.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10036.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10036.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.08373.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.08373.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.08373.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.07795.
[13.06.2025 08:16] Downloading paper 2506.07795 from http://arxiv.org/pdf/2506.07795v1...
[13.06.2025 08:16] Extracting affiliations from text.
[13.06.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 ] . [ 1 5 9 7 7 0 . 6 0 5 2 : r LLM Unlearning Should Be Form-Independent Xiaotian Ye1, Mengqi Zhang2, Shu Wu3 1School of Computer Science, Beijing University of Posts and Telecommunications 2Shandong University 3New Laboratory of Pattern Recognition (NLPR), State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation, Chinese Academy of Sciences yexiaotian@bupt.edu.cn, mengqi.zhang@sdu.edu.cn, shu.wu@nlpr.ia.ac.cn AbstractLarge Language Model (LLM) unlearning aims to erase or suppress undesirable knowledge within the model, offering promise for controlling harmful or private information to prevent misuse. However, recent studies highlight its limited efficacy in real-world scenarios, hindering practical adoption. In this study, we identify pervasive issue underlying many downstream failures: the effectiveness of existing unlearning methods heavily depends on the form of training samples and frequently fails to generalize to alternate expressions of the same knowledge. We formally characterize this problem as Form-Dependent Bias and systematically investigate its specific manifestation patterns across various downstream tasks. To quantify its prevalence and support future research, we introduce ORT, novel benchmark designed to evaluate the robustness of unlearning methods against variations in knowledge expression. Results reveal that Form-Dependent Bias is both widespread and severe among current techniques. We argue that LLM unlearning should be formindependent to address the endless forms of downstream tasks encountered in real-world security-critical scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR), novel training-free method, as promising solution path. ROCR performs unlearning by targeting the invariants in downstream tasks, specifically the activated dangerous concepts. It is capable of modifying model parameters within seconds to redirect the models perception of specific unlearnin"
[13.06.2025 08:16] Response: ```python
[
    "School of Computer Science, Beijing University of Posts and Telecommunications",
    "Shandong University",
    "New Laboratory of Pattern Recognition (NLPR), State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation, Chinese Academy of Sciences"
]
```
[13.06.2025 08:16] Deleting PDF ./assets/pdf/2506.07795.pdf.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.06950.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.06950.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.06950.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.06561.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.06561.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.06561.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.05982.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.05982.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.05982.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2506.10378.
[13.06.2025 08:16] Extra JSON file exists (./assets/json/2506.10378.json), skip PDF parsing.
[13.06.2025 08:16] Paper image links file exists (./assets/img_data/2506.10378.json), skip HTML parsing.
[13.06.2025 08:16] Success.
[13.06.2025 08:16] Enriching papers with extra data.
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 0. ReasonMed, a large medical reasoning dataset, enhances the accuracy of medical question answering models by combining detailed reasoning paths with concise summaries, setting new benchmarks for model performance.  					AI-generated summary 				 Though reasoning-based large language models (LLMs) hav...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 1. An automated pipeline, SWE-Factory, is introduced to facilitate the creation of large-scale datasets for evaluating and training Large Language Models in GitHub issue resolution tasks, offering efficient environment building, standardized grading, and automated validation.  					AI-generated summary...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 2. The proposed Text-Aware Image Restoration (TAIR) system integrates a multi-task diffusion framework with a text-spotting module to enhance both image recovery and textual fidelity, outperforming existing diffusion-based methods.  					AI-generated summary 				 Image restoration aims to recover degra...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 3. VRBench evaluates long video understanding by assessing multi-step reasoning capabilities across temporal and procedural validity using human-labeled question-answering pairs and reasoning chains.  					AI-generated summary 				 We present VRBench, the first long narrative video benchmark crafted fo...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 4. AniMaker, a multi-agent framework using MCTS-Gen and AniEval, generates coherent storytelling videos from text input, outperforming existing models with better quality and efficiency.  					AI-generated summary 				 Despite rapid advancements in video generation models, generating coherent storytell...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 5. AutoMind, a flexible and knowledgeable LLM-agent framework, improves automated data science through expert knowledge integration, strategic solution exploration, and adaptive coding, outperforming existing systems.  					AI-generated summary 				 Large Language Model (LLM) agents have shown great po...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 6. A benchmark for Chinese harmful content detection, coupled with a knowledge-augmented baseline, improves the performance of smaller models without extensive resources.  					AI-generated summary 				 Large language models (LLMs) have been increasingly applied to automated harmful content detection t...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 7. VideoDeepResearch, a text-only reasoning model with modular tools, surpasses existing baselines in long video understanding tasks without extending context windows or enhancing visual perception capabilities.  					AI-generated summary 				 Long video understanding (LVU) presents a significant chall...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 8. CreatiPoster generates high-quality, editable, and customizable graphic compositions from text or assets, outperforming existing tools and templates.  					AI-generated summary 				 Graphic design plays a crucial role in both commercial and personal contexts, yet creating high-quality, editable, and...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 9. PosterCraft improves aesthetic poster generation through a unified, modular pipeline with enhanced text rendering, region-aware fine-tuning, aesthetic reinforcement learning, and joint vision-language refinement.  					AI-generated summary 				 Generating aesthetic posters is more challenging than s...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 10. Domain2Vec decomposes datasets into meta-domains to optimize language model pretraining and downstream performance with reduced computational cost.  					AI-generated summary 				 We introduce~Domain2Vec, a novel approach that decomposes any dataset into a linear combination of several meta-domains,...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 11. SAE-Tuning efficiently elicits strong reasoning in language models by leveraging sparse autoencoders, enabling cost-effective performance gains without extensive retraining.  					AI-generated summary 				 How cost-effectively can we elicit strong reasoning in language models by leveraging their und...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 12. Ming-Omni is a unified multimodal model with dedicated encoders and modality-specific routers that can process images, text, audio, and video, and performs tasks like speech and image generation, context-aware chatting, and versatile image editing.  					AI-generated summary 				 We propose Ming-Omn...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 13. Transformers can approximate supervised fine-tuning capabilities through in-context learning without altering model parameters, supported by theoretical bounds and practical techniques.  					AI-generated summary 				 Large language models have transformed natural language processing, yet supervised...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 14. A scalable reinforcement learning pipeline for training reasoning models demonstrates improvements in multimodal understanding, instruction following, and function calling without relying on existing implementations.  					AI-generated summary 				 We introduce Magistral, Mistral's first reasoning m...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 15. Optimus-3, an agent using knowledge-enhanced data generation, Mixture-of-Experts routing, and multimodal reasoning-augmented reinforcement learning, achieves superior performance across various tasks in Minecraft.  					AI-generated summary 				 Recently, agents based on multimodal large language mo...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 16. VerIF, a hybrid verification method combining rule-based and LLM-based approaches, enhances instruction-following RL with significant performance improvements and generalization.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has become a key technique for enha...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 17. A paradigm shift in web agent research is proposed, advocating for the development of Agentic Web Interfaces (AWIs) to optimize interaction for AI agents within web environments.  					AI-generated summary 				 Recent advancements in Large Language Models (LLMs) and multimodal counterparts have spur...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 18. MoveGCL is a privacy-preserving framework using generative continual learning and a Mixture-of-Experts Transformer for training mobility foundation models without sharing raw data.  					AI-generated summary 				 Foundation models have revolutionized fields such as natural language processing and co...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 19. Token Perturbation Guidance (TPG) enhances diffusion model generation quality without training, by perturbing intermediate token representations, achieving CFG-like performance and improving unconditional generation.  					AI-generated summary 				 Classifier-free guidance (CFG) has become an essent...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 20. A new framework using draft models enhances approximate inference for long-context LLMs by better predicting token and key-value pair importance, improving accuracy while maintaining memory and compute efficiency.  					AI-generated summary 				 Optimizing inference for long-context Large Language M...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 21. Form-Dependent Bias limits the effectiveness of LLM unlearning across different knowledge expressions, and Rank-one Concept Redirection (ROCR) is proposed as a form-independent solution that enhances unlearning efficacy.  					AI-generated summary 				 Large Language Model (LLM) unlearning aims to e...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 22. A framework for evaluating and optimizing natural language prompts in large language models is proposed, revealing correlations between prompt properties and their impact on reasoning tasks.  					AI-generated summary 				 As large language models (LLMs) have progressed towards more human-like and h...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 23. LaMP-Cap introduces a dataset for personalized figure caption generation using multimodal profiles to improve the quality of AI-generated captions.  					AI-generated summary 				 Figure captions are crucial for helping readers understand and remember a figure's key message. Many models have been de...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 24. MCA-Bench is a multimodal benchmark suite for CAPTCHA security evaluation which fine-tunes specialized cracking agents using a shared vision-language model.  					AI-generated summary 				 As automated attack techniques rapidly advance, CAPTCHAs remain a critical defense mechanism against malicious ...
[13.06.2025 08:16] ********************************************************************************
[13.06.2025 08:16] Abstract 25. The study proposes a causal representation learning framework to evaluate language model capabilities through latent factors, emphasizing the importance of controlling for base model variations to uncover underlying causal relationships.  					AI-generated summary 				 Faithful evaluation of languag...
[13.06.2025 08:16] Read previous papers.
[13.06.2025 08:16] Generating reviews via LLM API.
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#benchmark", "#healthcare", "#reasoning", "#training"], "emoji": "🩺", "ru": {"title": "ReasonMed: Прорыв в медицинских вопросно-ответных системах на основе ИИ", "desc": "ReasonMed - это крупнейший набор данных для медицинских рассуждений, состоящий из 37
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#data", "#science", "#dataset", "#agents", "#benchmark", "#open_source"], "emoji": "🏭", "ru": {"title": "SWE-Factory: автоматизация создания датасетов для LLM в разработке ПО", "desc": "SWE-Factory - это автоматизированный конвейер для создания масштабных датасетов для оценки и обуч
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#dataset", "#cv", "#benchmark", "#diffusion", "#hallucinations"], "emoji": "📝", "ru": {"title": "Восстановление изображений с сохранением текстовой информации", "desc": "Предложенная система восстановления изображений с учетом текста (TAIR) объединяет многозадачную диффузионную моде
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#reasoning", "#video", "#multimodal"], "emoji": "🎬", "ru": {"title": "VRBench: Оценка глубокого понимания видео через многоступенчатые рассуждения", "desc": "VRBench - это новый бенчмарк для оценки способностей моделей машинного обучения к многоступенч
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#video", "#multimodal", "#story_generation", "#agents"], "emoji": "🎬", "ru": {"title": "AniMaker: умная система для создания анимационных историй из текста", "desc": "AniMaker - это многоагентная система для создания анимационных видеороликов по текстовому описанию.
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#science", "#training", "#dataset", "#benchmark", "#agents"], "emoji": "🤖", "ru": {"title": "AutoMind: ИИ-ассистент нового поколения для автоматизации науки о данных", "desc": "AutoMind - это новая гибкая система на основе больших языковых моделей для автоматизации задач в области н
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#multilingual", "#small_models", "#low_resource", "#ethics", "#dataset", "#benchmark"], "emoji": "🇨🇳", "ru": {"title": "Улучшение обнаружения вредоносного контента на китайском языке с помощью знаний", "desc": "Представлен новый бенчмарк для обнаружения вредоносного контента на кита
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#long_context", "#video", "#multimodal", "#agents"], "emoji": "🎥", "ru": {"title": "Агентный подход превосходит мультимодальные модели в понимании длинных видео", "desc": "VideoDeepResearch - это новая агентная система для понимания длинных видео, основан
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#dataset", "#cv", "#benchmark", "#open_source", "#multimodal"], "emoji": "🎨", "ru": {"title": "CreatiPoster: ИИ-революция в графическом дизайне", "desc": "CreatiPoster - это новая система искусственного интеллекта для генерации высококачественных графических композиций на основе тек
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#architecture", "#open_source", "#dataset", "#data", "#multimodal"], "emoji": "🎨", "ru": {"title": "Искусственный интеллект создает эстетичные постеры нового уровня", "desc": "PosterCraft - это унифицированная система для создания эстетичных пост
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#transfer_learning", "#dataset", "#training", "#optimization", "#data"], "emoji": "🧩", "ru": {"title": "Умное разложение данных для эффективного обучения языковых моделей", "desc": "Domain2Vec - это новый подход к декомпозиции датасетов на мета-домены для оптимизации предобучения яз
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#rl", "#training", "#open_source", "#optimization", "#small_models", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эффективное обучение рассуждению с помощью разреженных автоэнкодеров", "desc": "Эта статья представляет метод SAE-Tuning для эффективного улучшения способностей языковы
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#audio", "#open_source", "#video", "#cv", "#multimodal"], "emoji": "🤖", "ru": {"title": "Единая модель для всех модальностей: восприятие и генерация в одном", "desc": "Статья представляет Ming-Omni - унифицированную мультимодальную модель, способную обрабатывать изображения, текст, 
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#transfer_learning", "#rag", "#inference", "#training"], "emoji": "🧠", "ru": {"title": "Трансформеры: обучение в контексте как альтернатива тонкой настройке", "desc": "Статья исследует способность трансформеров аппроксимировать возможности обучения с учителем без из
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#reasoning", "#open_source", "#multimodal"], "emoji": "🧠", "ru": {"title": "Обучение с подкреплением открывает новые горизонты для моделей рассуждений", "desc": "Исследователи представили Magistral - модель рассуждений, обученную с помощью масшта
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#agents", "#rag", "#rl", "#reasoning", "#multimodal", "#games"], "emoji": "🤖", "ru": {"title": "Optimus-3: Универсальный ИИ-агент покоряет Minecraft", "desc": "Статья представляет Optimus-3 - интеллектуального агента для игры Minecraft, использующег
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#rl", "#benchmark", "#open_source", "#reasoning", "#training", "#rlhf"], "emoji": "🤖", "ru": {"title": "VerIF: Гибридная верификация для улучшения RL в следовании инструкциям", "desc": "Статья представляет VerIF - гибридный метод верификации, сочетающий 
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#agents", "#agi", "#optimization", "#multimodal"], "emoji": "🌐", "ru": {"title": "Агентные Веб-Интерфейсы: революция во взаимодействии ИИ с веб-средой", "desc": "Статья предлагает новую парадигму для веб-агентов, вводя концепцию Агентных Веб-Интерфейсов (AWI). AWI оптимизированы для
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#data", "#training", "#open_source", "#architecture"], "emoji": "🚶", "ru": {"title": "Защита приватности при обучении моделей мобильности", "desc": "MoveGCL - это фреймворк для обучения фундаментальных моделей мобильности с сохранением конфиденциальности да
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#training", "#diffusion", "#cv"], "emoji": "🔀", "ru": {"title": "Улучшение генерации диффузионных моделей без переобучения", "desc": "Статья представляет новый метод под названием Token Perturbation Guidance (TPG) для улучшения качества генерации диффузионных моделе
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#benchmark", "#architecture", "#training", "#inference"], "emoji": "🚀", "ru": {"title": "Ускорение вывода ИИ с помощью умных черновиков", "desc": "Предложена новая система для приближенного вывода в больших языковых моделях с длинным контекстом, исп
[13.06.2025 08:16] Querying the API.
[13.06.2025 08:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Form-Dependent Bias limits the effectiveness of LLM unlearning across different knowledge expressions, and Rank-one Concept Redirection (ROCR) is proposed as a form-independent solution that enhances unlearning efficacy.  					AI-generated summary 				 Large Language Model (LLM) unlearning aims to erase or suppress undesirable knowledge within the model, offering promise for controlling harmful or private information to prevent misuse. However, recent studies highlight its limited efficacy in real-world scenarios, hindering practical adoption. In this study, we identify a pervasive issue underlying many downstream failures: the effectiveness of existing unlearning methods heavily depends on the form of training samples and frequently fails to generalize to alternate expressions of the same knowledge. We formally characterize this problem as Form-Dependent Bias and systematically investigate its specific manifestation patterns across various downstream tasks. To quantify its prevalence and support future research, we introduce ORT, a novel benchmark designed to evaluate the robustness of unlearning methods against variations in knowledge expression. Results reveal that Form-Dependent Bias is both widespread and severe among current techniques.   We argue that LLM unlearning should be form-independent to address the endless forms of downstream tasks encountered in real-world security-critical scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR), a novel training-free method, as a promising solution path. ROCR performs unlearning by targeting the invariants in downstream tasks, specifically the activated dangerous concepts. It is capable of modifying model parameters within seconds to redirect the model's perception of a specific unlearning target concept to another harmless concept. Extensive experiments demonstrate that ROCR significantly improves unlearning effectiveness compared to traditional methods while generating highly natural outputs.
[13.06.2025 08:16] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#survey", "#reasoning", "#training"], "emoji": "🧠", "ru": {"title": "Оптимизация промптов для улучшения рассуждений языковых моделей", "desc": "Предложена система оценки и оптимизации естественно-языковых промптов для больших языковых моделей. Авторы п
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#multimodal", "#interpretability", "#games"], "emoji": "🖼️", "ru": {"title": "Персонализированные подписи к изображениям: мультимодальный подход", "desc": "LaMP-Cap представляет датасет для персонализированной генерации подписей к изображениям с использо
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#security", "#open_source", "#multimodal"], "emoji": "🔐", "ru": {"title": "Единый мультимодальный бенчмарк для оценки безопасности CAPTCHA", "desc": "MCA-Bench - это комплексный набор инструментов для оценки безопасности CAPTCHA, использующий мультимодальный
[13.06.2025 08:16] Using data from previous issue: {"categories": ["#science", "#dataset", "#interpretability", "#benchmark", "#reasoning", "#math"], "emoji": "🧠", "ru": {"title": "Раскрытие причинно-следственных связей в способностях языковых моделей", "desc": "Исследование предлагает каузальную модель представления для оценки возможностей языковых
[13.06.2025 08:16] Loading Chinese text from previous data.
[13.06.2025 08:16] Renaming data file.
[13.06.2025 08:16] Renaming previous data. hf_papers.json to ./d/2025-06-13.json
[13.06.2025 08:16] Saving new data file.
[13.06.2025 08:16] Generating page.
[13.06.2025 08:16] Renaming previous page.
[13.06.2025 08:16] Renaming previous data. index.html to ./d/2025-06-13.html
[13.06.2025 08:16] [Experimental] Generating Chinese page for reading.
[13.06.2025 08:16] Chinese vocab [{'word': 'Seedance', 'pinyin': 'Sīdànsì', 'trans': 'Seedance'}, {'word': '高性能', 'pinyin': 'gāo xìngnéng', 'trans': 'high performance'}, {'word': '视频生成模型', 'pinyin': 'shìpín shēngchéng móxíng', 'trans': 'video generation model'}, {'word': '结合', 'pinyin': 'jiéhé', 'trans': 'combine'}, {'word': '先进', 'pinyin': 'xiānjìn', 'trans': 'advanced'}, {'word': '数据整理', 'pinyin': 'shùjù zhěnglǐ', 'trans': 'data processing'}, {'word': '高效', 'pinyin': 'gāoxiào', 'trans': 'efficient'}, {'word': '架构设计', 'pinyin': 'jiàgòu shèjì', 'trans': 'architecture design'}, {'word': '训练后优化', 'pinyin': 'xùnliàn hòu yōuhuà', 'trans': 'post-training optimization'}, {'word': '模型加速', 'pinyin': 'móxíng jiāsù', 'trans': 'model acceleration'}, {'word': '1080p分辨率', 'pinyin': '1080p fēnbiānlǜ', 'trans': '1080p resolution'}, {'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generate'}, {'word': '只需', 'pinyin': 'zhǐ xū', 'trans': 'only need'}, {'word': '顶尖', 'pinyin': 'dǐngjiān', 'trans': 'top-notch'}, {'word': '质量', 'pinyin': 'zhìliàng', 'trans': 'quality'}, {'word': '速度', 'pinyin': 'sùdù', 'trans': 'speed'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '出色', 'pinyin': 'chūsè', 'trans': 'outstanding'}, {'word': '优越', 'pinyin': 'yōuyuè', 'trans': 'superior'}, {'word': '时空流畅性', 'pinyin': 'shíkōng liúchàngxìng', 'trans': 'spatiotemporal smoothness'}, {'word': '结构稳定性', 'pinyin': 'jiégòu wěndìngxìng', 'trans': 'structural stability'}]
[13.06.2025 08:16] Renaming previous Chinese page.
[13.06.2025 08:16] Renaming previous data. zh.html to ./d/2025-06-12_zh_reading_task.html
[13.06.2025 08:16] Writing Chinese reading task.
[13.06.2025 08:16] Writing result.
[13.06.2025 08:16] Renaming log file.
[13.06.2025 08:16] Renaming previous data. log.txt to ./logs/2025-06-13_last_log.txt
