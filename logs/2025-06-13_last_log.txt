[13.06.2025 08:16] Read previous papers.
[13.06.2025 08:16] Generating top page (month).
[13.06.2025 08:16] Writing top page (month).
[13.06.2025 09:13] Read previous papers.
[13.06.2025 09:13] Get feed.
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09513
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10954
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09993
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10857
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10540
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10952
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10357
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10974
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10960
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10821
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10741
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10890
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09967
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10910
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09344
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08060
[13.06.2025 09:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.09952
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09942
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10953
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06694
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10036
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08373
[13.06.2025 09:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.08234
[13.06.2025 09:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.07795
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06950
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06561
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.05982
[13.06.2025 09:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10378
[13.06.2025 09:13] Extract page data from URL. URL: https://huggingface.co/papers/2506.08862
[13.06.2025 09:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[13.06.2025 09:13] No deleted papers detected.
[13.06.2025 09:13] Downloading and parsing papers (pdf, html). Total: 29.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.09513.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.09513.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.09513.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10954.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10954.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10954.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.09993.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.09993.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.09993.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10857.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10857.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10857.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10540.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10540.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10540.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10952.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10952.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10952.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10357.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10357.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10357.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10974.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10974.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10974.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10960.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10960.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10960.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10821.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10821.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10821.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10741.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10741.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10741.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10890.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10890.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10890.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.09967.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.09967.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.09967.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10910.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10910.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10910.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.09344.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.09344.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.09344.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.08060.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.08060.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.08060.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.09952.
[13.06.2025 09:13] Downloading paper 2506.09952 from http://arxiv.org/pdf/2506.09952v1...
[13.06.2025 09:13] Extracting affiliations from text.
[13.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting Ziyi Wang* Yanran Zhang Jiwen Lu Department of Automation, Tsinghua University, China {wziyi22, zhangyr21}@mails.tsinghua.edu.cn; {jzhou, lujiwen}@tsinghua.edu.cn 5 2 0 2 1 1 ] . [ 1 2 5 9 9 0 . 6 0 5 2 : r a "
[13.06.2025 09:13] Response: ```python
["Department of Automation, Tsinghua University, China"]
```
[13.06.2025 09:13] Deleting PDF ./assets/pdf/2506.09952.pdf.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.09942.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.09942.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.09942.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10953.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10953.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10953.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.06694.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.06694.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.06694.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10036.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10036.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10036.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.08373.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.08373.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.08373.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.08234.
[13.06.2025 09:13] Downloading paper 2506.08234 from http://arxiv.org/pdf/2506.08234v1...
[13.06.2025 09:13] Extracting affiliations from text.
[13.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Compound AI Systems Optimization: Survey of Methods, Challenges, and Future Directions Yu-Ang Lee* Guan-Ting Yi* Mei-Yi Liu Jui-Chao Lu Guan-Bo Yang Yun-Nung Chen National Taiwan University, Taipei, Taiwan {r12946015,r13922053,r10228031,b09901142,r13922083}@ntu.edu.tw y.v.chen@ieee.org 5 2 0 2 9 ] . [ 1 4 3 2 8 0 . 6 0 5 2 : r a "
[13.06.2025 09:13] Response: ```python
["National Taiwan University, Taipei, Taiwan"]
```
[13.06.2025 09:13] Deleting PDF ./assets/pdf/2506.08234.pdf.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.07795.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.07795.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.07795.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.06950.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.06950.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.06950.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.06561.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.06561.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.06561.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.05982.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.05982.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.05982.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.10378.
[13.06.2025 09:13] Extra JSON file exists (./assets/json/2506.10378.json), skip PDF parsing.
[13.06.2025 09:13] Paper image links file exists (./assets/img_data/2506.10378.json), skip HTML parsing.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2506.08862.
[13.06.2025 09:13] Downloading paper 2506.08862 from http://arxiv.org/pdf/2506.08862v1...
[13.06.2025 09:13] Extracting affiliations from text.
[13.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams Zike Wu1,2 Qi Yan1,2 Xuanyu Yi4 Lele Wang1 Renjie Liao1,2,3 1University of British Columbia 2Vector Institute for AI 3Canada CIFAR AI Chair 4Nanyang Technological University 5 2 0 2 0 1 ] . [ 1 2 6 8 8 0 . 6 0 5 2 : r {zikewu, qi.yan, lelewang, rjliao}@ece.ubc.ca, xuanyu001@e.ntu.edu.sg Figure 1: Given an uncalibrated video stream, our StreamSplat performs instant reconstruction of dynamic 3D Gaussian scene in an online manner, enabling video reconstruction and interpolation, depth estimation, and novel view synthesis. "
[13.06.2025 09:13] Response: ```python
["University of British Columbia", "Vector Institute for AI", "Canada CIFAR AI Chair", "Nanyang Technological University"]
```
[13.06.2025 09:13] Deleting PDF ./assets/pdf/2506.08862.pdf.
[13.06.2025 09:13] Success.
[13.06.2025 09:13] Enriching papers with extra data.
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 0. ReasonMed, a large medical reasoning dataset, enhances the accuracy of medical question answering models by combining detailed reasoning paths with concise summaries, setting new benchmarks for model performance.  					AI-generated summary 				 Though reasoning-based large language models (LLMs) hav...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 1. An automated pipeline, SWE-Factory, is introduced to facilitate the creation of large-scale datasets for evaluating and training Large Language Models in GitHub issue resolution tasks, offering efficient environment building, standardized grading, and automated validation.  					AI-generated summary...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 2. The proposed Text-Aware Image Restoration (TAIR) system integrates a multi-task diffusion framework with a text-spotting module to enhance both image recovery and textual fidelity, outperforming existing diffusion-based methods.  					AI-generated summary 				 Image restoration aims to recover degra...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 3. VRBench evaluates long video understanding by assessing multi-step reasoning capabilities across temporal and procedural validity using human-labeled question-answering pairs and reasoning chains.  					AI-generated summary 				 We present VRBench, the first long narrative video benchmark crafted fo...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 4. AniMaker, a multi-agent framework using MCTS-Gen and AniEval, generates coherent storytelling videos from text input, outperforming existing models with better quality and efficiency.  					AI-generated summary 				 Despite rapid advancements in video generation models, generating coherent storytell...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 5. Domain2Vec decomposes datasets into meta-domains to optimize language model pretraining and downstream performance with reduced computational cost.  					AI-generated summary 				 We introduce~Domain2Vec, a novel approach that decomposes any dataset into a linear combination of several meta-domains,...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 6. Optimus-3, an agent using knowledge-enhanced data generation, Mixture-of-Experts routing, and multimodal reasoning-augmented reinforcement learning, achieves superior performance across various tasks in Minecraft.  					AI-generated summary 				 Recently, agents based on multimodal large language mo...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 7. AutoMind, a flexible and knowledgeable LLM-agent framework, improves automated data science through expert knowledge integration, strategic solution exploration, and adaptive coding, outperforming existing systems.  					AI-generated summary 				 Large Language Model (LLM) agents have shown great po...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 8. A benchmark for Chinese harmful content detection, coupled with a knowledge-augmented baseline, improves the performance of smaller models without extensive resources.  					AI-generated summary 				 Large language models (LLMs) have been increasingly applied to automated harmful content detection t...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 9. VideoDeepResearch, a text-only reasoning model with modular tools, surpasses existing baselines in long video understanding tasks without extending context windows or enhancing visual perception capabilities.  					AI-generated summary 				 Long video understanding (LVU) presents a significant chall...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 10. PosterCraft improves aesthetic poster generation through a unified, modular pipeline with enhanced text rendering, region-aware fine-tuning, aesthetic reinforcement learning, and joint vision-language refinement.  					AI-generated summary 				 Generating aesthetic posters is more challenging than s...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 11. CreatiPoster generates high-quality, editable, and customizable graphic compositions from text or assets, outperforming existing tools and templates.  					AI-generated summary 				 Graphic design plays a crucial role in both commercial and personal contexts, yet creating high-quality, editable, and...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 12. SAE-Tuning efficiently elicits strong reasoning in language models by leveraging sparse autoencoders, enabling cost-effective performance gains without extensive retraining.  					AI-generated summary 				 How cost-effectively can we elicit strong reasoning in language models by leveraging their und...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 13. A scalable reinforcement learning pipeline for training reasoning models demonstrates improvements in multimodal understanding, instruction following, and function calling without relying on existing implementations.  					AI-generated summary 				 We introduce Magistral, Mistral's first reasoning m...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 14. Ming-Omni is a unified multimodal model with dedicated encoders and modality-specific routers that can process images, text, audio, and video, and performs tasks like speech and image generation, context-aware chatting, and versatile image editing.  					AI-generated summary 				 We propose Ming-Omn...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 15. Transformers can approximate supervised fine-tuning capabilities through in-context learning without altering model parameters, supported by theoretical bounds and practical techniques.  					AI-generated summary 				 Large language models have transformed natural language processing, yet supervised...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 16. UniPre3D is a unified pre-training method for 3D point clouds and models of any scale, using Gaussian primitives and 2D feature integration for effective performance across object and scene tasks.  					AI-generated summary 				 The scale diversity of point cloud data presents significant challenges...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 17. VerIF, a hybrid verification method combining rule-based and LLM-based approaches, enhances instruction-following RL with significant performance improvements and generalization.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has become a key technique for enha...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 18. A paradigm shift in web agent research is proposed, advocating for the development of Agentic Web Interfaces (AWIs) to optimize interaction for AI agents within web environments.  					AI-generated summary 				 Recent advancements in Large Language Models (LLMs) and multimodal counterparts have spur...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 19. MoveGCL is a privacy-preserving framework using generative continual learning and a Mixture-of-Experts Transformer for training mobility foundation models without sharing raw data.  					AI-generated summary 				 Foundation models have revolutionized fields such as natural language processing and co...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 20. Token Perturbation Guidance (TPG) enhances diffusion model generation quality without training, by perturbing intermediate token representations, achieving CFG-like performance and improving unconditional generation.  					AI-generated summary 				 Classifier-free guidance (CFG) has become an essent...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 21. A new framework using draft models enhances approximate inference for long-context LLMs by better predicting token and key-value pair importance, improving accuracy while maintaining memory and compute efficiency.  					AI-generated summary 				 Optimizing inference for long-context Large Language M...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 22. Recent advancements in optimizing compound AI systems highlight challenges in integrating various components, with an emphasis on natural language feedback methods for non-differentiable systems.  					AI-generated summary 				 Recent advancements in large language models (LLMs) and AI systems have ...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 23. Form-Dependent Bias limits the effectiveness of LLM unlearning across different knowledge expressions, and Rank-one Concept Redirection (ROCR) is proposed as a form-independent solution that enhances unlearning efficacy.  					AI-generated summary 				 Large Language Model (LLM) unlearning aims to e...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 24. A framework for evaluating and optimizing natural language prompts in large language models is proposed, revealing correlations between prompt properties and their impact on reasoning tasks.  					AI-generated summary 				 As large language models (LLMs) have progressed towards more human-like and h...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 25. LaMP-Cap introduces a dataset for personalized figure caption generation using multimodal profiles to improve the quality of AI-generated captions.  					AI-generated summary 				 Figure captions are crucial for helping readers understand and remember a figure's key message. Many models have been de...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 26. MCA-Bench is a multimodal benchmark suite for CAPTCHA security evaluation which fine-tunes specialized cracking agents using a shared vision-language model.  					AI-generated summary 				 As automated attack techniques rapidly advance, CAPTCHAs remain a critical defense mechanism against malicious ...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 27. The study proposes a causal representation learning framework to evaluate language model capabilities through latent factors, emphasizing the importance of controlling for base model variations to uncover underlying causal relationships.  					AI-generated summary 				 Faithful evaluation of languag...
[13.06.2025 09:13] ********************************************************************************
[13.06.2025 09:13] Abstract 28. StreamSplat, a fully feed-forward framework, addresses real-time 3D scene reconstruction from uncalibrated video with accurate dynamics and long-term stability.  					AI-generated summary 				 Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams is crucial for numerous real-...
[13.06.2025 09:13] Read previous papers.
[13.06.2025 09:13] Generating reviews via LLM API.
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#benchmark", "#healthcare", "#reasoning", "#training"], "emoji": "🩺", "ru": {"title": "ReasonMed: Прорыв в медицинских вопросно-ответных системах на основе ИИ", "desc": "ReasonMed - это крупнейший набор данных для медицинских рассуждений, состоящий из 37
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#data", "#science", "#dataset", "#agents", "#benchmark", "#open_source"], "emoji": "🏭", "ru": {"title": "SWE-Factory: автоматизация создания датасетов для LLM в разработке ПО", "desc": "SWE-Factory - это автоматизированный конвейер для создания масштабных датасетов для оценки и обуч
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#cv", "#benchmark", "#diffusion", "#hallucinations"], "emoji": "📝", "ru": {"title": "Восстановление изображений с сохранением текстовой информации", "desc": "Предложенная система восстановления изображений с учетом текста (TAIR) объединяет многозадачную диффузионную моде
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#reasoning", "#video", "#multimodal"], "emoji": "🎬", "ru": {"title": "VRBench: Оценка глубокого понимания видео через многоступенчатые рассуждения", "desc": "VRBench - это новый бенчмарк для оценки способностей моделей машинного обучения к многоступенч
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#video", "#multimodal", "#story_generation", "#agents"], "emoji": "🎬", "ru": {"title": "AniMaker: умная система для создания анимационных историй из текста", "desc": "AniMaker - это многоагентная система для создания анимационных видеороликов по текстовому описанию.
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#transfer_learning", "#dataset", "#training", "#optimization", "#data"], "emoji": "🧩", "ru": {"title": "Умное разложение данных для эффективного обучения языковых моделей", "desc": "Domain2Vec - это новый подход к декомпозиции датасетов на мета-домены для оптимизации предобучения яз
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#agents", "#rag", "#rl", "#reasoning", "#multimodal", "#games"], "emoji": "🤖", "ru": {"title": "Optimus-3: Универсальный ИИ-агент покоряет Minecraft", "desc": "Статья представляет Optimus-3 - интеллектуального агента для игры Minecraft, использующег
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#science", "#training", "#dataset", "#benchmark", "#agents"], "emoji": "🤖", "ru": {"title": "AutoMind: ИИ-ассистент нового поколения для автоматизации науки о данных", "desc": "AutoMind - это новая гибкая система на основе больших языковых моделей для автоматизации задач в области н
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#multilingual", "#small_models", "#low_resource", "#ethics", "#dataset", "#benchmark"], "emoji": "🇨🇳", "ru": {"title": "Улучшение обнаружения вредоносного контента на китайском языке с помощью знаний", "desc": "Представлен новый бенчмарк для обнаружения вредоносного контента на кита
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#long_context", "#video", "#multimodal", "#agents"], "emoji": "🎥", "ru": {"title": "Агентный подход превосходит мультимодальные модели в понимании длинных видео", "desc": "VideoDeepResearch - это новая агентная система для понимания длинных видео, основан
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#architecture", "#open_source", "#dataset", "#data", "#multimodal"], "emoji": "🎨", "ru": {"title": "Искусственный интеллект создает эстетичные постеры нового уровня", "desc": "PosterCraft - это унифицированная система для создания эстетичных пост
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#cv", "#benchmark", "#open_source", "#multimodal"], "emoji": "🎨", "ru": {"title": "CreatiPoster: ИИ-революция в графическом дизайне", "desc": "CreatiPoster - это новая система искусственного интеллекта для генерации высококачественных графических композиций на основе тек
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#rl", "#training", "#open_source", "#optimization", "#small_models", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эффективное обучение рассуждению с помощью разреженных автоэнкодеров", "desc": "Эта статья представляет метод SAE-Tuning для эффективного улучшения способностей языковы
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#reasoning", "#open_source", "#multimodal"], "emoji": "🧠", "ru": {"title": "Обучение с подкреплением открывает новые горизонты для моделей рассуждений", "desc": "Исследователи представили Magistral - модель рассуждений, обученную с помощью масшта
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#audio", "#open_source", "#video", "#cv", "#multimodal"], "emoji": "🤖", "ru": {"title": "Единая модель для всех модальностей: восприятие и генерация в одном", "desc": "Статья представляет Ming-Omni - унифицированную мультимодальную модель, способную обрабатывать изображения, текст, 
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#transfer_learning", "#rag", "#inference", "#training"], "emoji": "🧠", "ru": {"title": "Трансформеры: обучение в контексте как альтернатива тонкой настройке", "desc": "Статья исследует способность трансформеров аппроксимировать возможности обучения с учителем без из
[13.06.2025 09:13] Querying the API.
[13.06.2025 09:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

UniPre3D is a unified pre-training method for 3D point clouds and models of any scale, using Gaussian primitives and 2D feature integration for effective performance across object and scene tasks.  					AI-generated summary 				 The scale diversity of point cloud data presents significant challenges in developing unified representation learning techniques for 3D vision. Currently, there are few unified 3D models, and no existing pre-training method is equally effective for both object- and scene-level point clouds. In this paper, we introduce UniPre3D, the first unified pre-training method that can be seamlessly applied to point clouds of any scale and 3D models of any architecture. Our approach predicts Gaussian primitives as the pre-training task and employs differentiable Gaussian splatting to render images, enabling precise pixel-level supervision and end-to-end optimization. To further regulate the complexity of the pre-training task and direct the model's focus toward geometric structures, we integrate 2D features from pre-trained image models to incorporate well-established texture knowledge. We validate the universal effectiveness of our proposed method through extensive experiments across a variety of object- and scene-level tasks, using diverse point cloud models as backbones. Code is available at https://github.com/wangzy22/UniPre3D.
[13.06.2025 09:13] Response: {
  "desc": "UniPre3D - это унифицированный метод предварительного обучения для облаков точек и 3D-моделей любого масштаба. Он использует гауссовы примитивы и интеграцию 2D-признаков для эффективной работы как с объектами, так и со сценами. Метод применяет дифференцируемое гауссово сплаттинг для рендеринга изображений, что позволяет осуществлять точный попиксельный контроль и сквозную оптимизацию. UniPre3D показал универсальную эффективность в различных задачах на уровне объектов и сцен с использованием разнообразных моделей облаков точек в качестве основы.",
  "emoji": "🌐",
  "title": "Единый метод предобучения для 3D-данных любого масштаба"
}
[13.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"UniPre3D is a unified pre-training method for 3D point clouds and models of any scale, using Gaussian primitives and 2D feature integration for effective performance across object and scene tasks.  					AI-generated summary 				 The scale diversity of point cloud data presents significant challenges in developing unified representation learning techniques for 3D vision. Currently, there are few unified 3D models, and no existing pre-training method is equally effective for both object- and scene-level point clouds. In this paper, we introduce UniPre3D, the first unified pre-training method that can be seamlessly applied to point clouds of any scale and 3D models of any architecture. Our approach predicts Gaussian primitives as the pre-training task and employs differentiable Gaussian splatting to render images, enabling precise pixel-level supervision and end-to-end optimization. To further regulate the complexity of the pre-training task and direct the model's focus toward geometric structures, we integrate 2D features from pre-trained image models to incorporate well-established texture knowledge. We validate the universal effectiveness of our proposed method through extensive experiments across a variety of object- and scene-level tasks, using diverse point cloud models as backbones. Code is available at https://github.com/wangzy22/UniPre3D."

[13.06.2025 09:13] Response: ```python
['3D', 'DATASET', 'TRAINING']
```
[13.06.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"UniPre3D is a unified pre-training method for 3D point clouds and models of any scale, using Gaussian primitives and 2D feature integration for effective performance across object and scene tasks.  					AI-generated summary 				 The scale diversity of point cloud data presents significant challenges in developing unified representation learning techniques for 3D vision. Currently, there are few unified 3D models, and no existing pre-training method is equally effective for both object- and scene-level point clouds. In this paper, we introduce UniPre3D, the first unified pre-training method that can be seamlessly applied to point clouds of any scale and 3D models of any architecture. Our approach predicts Gaussian primitives as the pre-training task and employs differentiable Gaussian splatting to render images, enabling precise pixel-level supervision and end-to-end optimization. To further regulate the complexity of the pre-training task and direct the model's focus toward geometric structures, we integrate 2D features from pre-trained image models to incorporate well-established texture knowledge. We validate the universal effectiveness of our proposed method through extensive experiments across a variety of object- and scene-level tasks, using diverse point cloud models as backbones. Code is available at https://github.com/wangzy22/UniPre3D."

[13.06.2025 09:13] Response: ```python
["OPTIMIZATION"]
```
[13.06.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"UniPre3D is a novel pre-training method designed for 3D point clouds and models, addressing the challenges posed by varying scales in 3D vision. It uniquely predicts Gaussian primitives as part of its pre-training task and utilizes differentiable Gaussian splatting for accurate image rendering. By integrating 2D features from pre-trained image models, it enhances the model\'s understanding of geometric structures and textures. Extensive experiments demonstrate its effectiveness across both object and scene-level tasks, making it a versatile solution for 3D representation learning.","title":"UniPre3D: Unified Pre-Training for All 3D Scales"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="UniPre3D is a novel pre-training method designed for 3D point clouds and models, addressing the challenges posed by varying scales in 3D vision. It uniquely predicts Gaussian primitives as part of its pre-training task and utilizes differentiable Gaussian splatting for accurate image rendering. By integrating 2D features from pre-trained image models, it enhances the model's understanding of geometric structures and textures. Extensive experiments demonstrate its effectiveness across both object and scene-level tasks, making it a versatile solution for 3D representation learning.", title='UniPre3D: Unified Pre-Training for All 3D Scales'))
[13.06.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"UniPre3D是一种统一的预训练方法，旨在处理各种规模的3D点云和模型。该方法通过预测高斯原语作为预训练任务，并使用可微分的高斯点云渲染技术，实现了精确的像素级监督。为了增强模型对几何结构的关注，UniPre3D还整合了来自预训练图像模型的2D特征，利用已有的纹理知识。通过广泛的实验验证，我们的方法在对象和场景任务中表现出普遍的有效性。","title":"统一预训练，提升3D视觉表现"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='UniPre3D是一种统一的预训练方法，旨在处理各种规模的3D点云和模型。该方法通过预测高斯原语作为预训练任务，并使用可微分的高斯点云渲染技术，实现了精确的像素级监督。为了增强模型对几何结构的关注，UniPre3D还整合了来自预训练图像模型的2D特征，利用已有的纹理知识。通过广泛的实验验证，我们的方法在对象和场景任务中表现出普遍的有效性。', title='统一预训练，提升3D视觉表现'))
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#rl", "#benchmark", "#open_source", "#reasoning", "#training", "#rlhf"], "emoji": "🤖", "ru": {"title": "VerIF: Гибридная верификация для улучшения RL в следовании инструкциям", "desc": "Статья представляет VerIF - гибридный метод верификации, сочетающий 
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#agents", "#agi", "#optimization", "#multimodal"], "emoji": "🌐", "ru": {"title": "Агентные Веб-Интерфейсы: революция во взаимодействии ИИ с веб-средой", "desc": "Статья предлагает новую парадигму для веб-агентов, вводя концепцию Агентных Веб-Интерфейсов (AWI). AWI оптимизированы для
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#data", "#training", "#open_source", "#architecture"], "emoji": "🚶", "ru": {"title": "Защита приватности при обучении моделей мобильности", "desc": "MoveGCL - это фреймворк для обучения фундаментальных моделей мобильности с сохранением конфиденциальности да
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#diffusion", "#cv"], "emoji": "🔀", "ru": {"title": "Улучшение генерации диффузионных моделей без переобучения", "desc": "Статья представляет новый метод под названием Token Perturbation Guidance (TPG) для улучшения качества генерации диффузионных моделе
[13.06.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#benchmark", "#architecture", "#training", "#inference"], "emoji": "🚀", "ru": {"title": "Ускорение вывода ИИ с помощью умных черновиков", "desc": "Предложена новая система для приближенного вывода в больших языковых моделях с длинным контекстом, исп
[13.06.2025 09:13] Querying the API.
[13.06.2025 09:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recent advancements in optimizing compound AI systems highlight challenges in integrating various components, with an emphasis on natural language feedback methods for non-differentiable systems.  					AI-generated summary 				 Recent advancements in large language models (LLMs) and AI systems have led to a paradigm shift in the design and optimization of complex AI workflows. By integrating multiple components, compound AI systems have become increasingly adept at performing sophisticated tasks. However, as these systems grow in complexity, new challenges arise in optimizing not only individual components but also their interactions. While traditional optimization methods such as supervised fine-tuning (SFT) and reinforcement learning (RL) remain foundational, the rise of natural language feedback introduces promising new approaches, especially for optimizing non-differentiable systems. This paper provides a systematic review of recent progress in optimizing compound AI systems, encompassing both numerical and language-based techniques. We formalize the notion of compound AI system optimization, classify existing methods along several key dimensions, and highlight open research challenges and future directions in this rapidly evolving field. A list of surveyed papers is publicly available at https://github.com/MiuLab/AISysOpt-Survey.
[13.06.2025 09:14] Response: {
  "desc": "Статья рассматривает последние достижения в оптимизации сложных систем искусственного интеллекта. Авторы анализируют проблемы интеграции различных компонентов, уделяя особое внимание методам обратной связи на естественном языке для недифференцируемых систем. В работе представлен систематический обзор современных подходов к оптимизации составных систем ИИ, включая как численные, так и языковые методы. Исследователи формализуют понятие оптимизации составных систем ИИ, классифицируют существующие методы и выделяют открытые проблемы в этой быстро развивающейся области.",
  "emoji": "🧠",
  "title": "Новые горизонты оптимизации сложных систем ИИ"
}
[13.06.2025 09:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent advancements in optimizing compound AI systems highlight challenges in integrating various components, with an emphasis on natural language feedback methods for non-differentiable systems.  					AI-generated summary 				 Recent advancements in large language models (LLMs) and AI systems have led to a paradigm shift in the design and optimization of complex AI workflows. By integrating multiple components, compound AI systems have become increasingly adept at performing sophisticated tasks. However, as these systems grow in complexity, new challenges arise in optimizing not only individual components but also their interactions. While traditional optimization methods such as supervised fine-tuning (SFT) and reinforcement learning (RL) remain foundational, the rise of natural language feedback introduces promising new approaches, especially for optimizing non-differentiable systems. This paper provides a systematic review of recent progress in optimizing compound AI systems, encompassing both numerical and language-based techniques. We formalize the notion of compound AI system optimization, classify existing methods along several key dimensions, and highlight open research challenges and future directions in this rapidly evolving field. A list of surveyed papers is publicly available at https://github.com/MiuLab/AISysOpt-Survey."

[13.06.2025 09:14] Response: ```python
['RLHF', 'TRAINING']
```
[13.06.2025 09:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent advancements in optimizing compound AI systems highlight challenges in integrating various components, with an emphasis on natural language feedback methods for non-differentiable systems.  					AI-generated summary 				 Recent advancements in large language models (LLMs) and AI systems have led to a paradigm shift in the design and optimization of complex AI workflows. By integrating multiple components, compound AI systems have become increasingly adept at performing sophisticated tasks. However, as these systems grow in complexity, new challenges arise in optimizing not only individual components but also their interactions. While traditional optimization methods such as supervised fine-tuning (SFT) and reinforcement learning (RL) remain foundational, the rise of natural language feedback introduces promising new approaches, especially for optimizing non-differentiable systems. This paper provides a systematic review of recent progress in optimizing compound AI systems, encompassing both numerical and language-based techniques. We formalize the notion of compound AI system optimization, classify existing methods along several key dimensions, and highlight open research challenges and future directions in this rapidly evolving field. A list of surveyed papers is publicly available at https://github.com/MiuLab/AISysOpt-Survey."

[13.06.2025 09:14] Response: ```python
["OPTIMIZATION", "SURVEY"]
```
[13.06.2025 09:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the recent progress in optimizing compound AI systems, which are complex systems made up of multiple interacting components. It highlights the challenges faced in integrating these components, particularly when using natural language feedback methods for systems that are not easily differentiable. The authors review traditional optimization techniques like supervised fine-tuning and reinforcement learning, while also exploring new approaches that leverage natural language. They aim to formalize the concept of compound AI system optimization and identify future research directions in this evolving field.","title":"Optimizing Complex AI Systems with Natural Language Feedback"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the recent progress in optimizing compound AI systems, which are complex systems made up of multiple interacting components. It highlights the challenges faced in integrating these components, particularly when using natural language feedback methods for systems that are not easily differentiable. The authors review traditional optimization techniques like supervised fine-tuning and reinforcement learning, while also exploring new approaches that leverage natural language. They aim to formalize the concept of compound AI system optimization and identify future research directions in this evolving field.', title='Optimizing Complex AI Systems with Natural Language Feedback'))
[13.06.2025 09:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"最近在复合人工智能系统优化方面的进展突显了整合各种组件的挑战，特别是在非可微系统中使用自然语言反馈方法。随着大型语言模型和人工智能系统的发展，复合人工智能系统在执行复杂任务方面变得更加高效。尽管传统的优化方法如监督微调和强化学习仍然是基础，但自然语言反馈的兴起为优化非可微系统提供了新的可能性。本文系统回顾了复合人工智能系统优化的最新进展，分类现有方法，并强调了该领域的开放研究挑战和未来方向。","title":"优化复合AI系统的新方法探索"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='最近在复合人工智能系统优化方面的进展突显了整合各种组件的挑战，特别是在非可微系统中使用自然语言反馈方法。随着大型语言模型和人工智能系统的发展，复合人工智能系统在执行复杂任务方面变得更加高效。尽管传统的优化方法如监督微调和强化学习仍然是基础，但自然语言反馈的兴起为优化非可微系统提供了新的可能性。本文系统回顾了复合人工智能系统优化的最新进展，分类现有方法，并强调了该领域的开放研究挑战和未来方向。', title='优化复合AI系统的新方法探索'))
[13.06.2025 09:14] Querying the API.
[13.06.2025 09:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Form-Dependent Bias limits the effectiveness of LLM unlearning across different knowledge expressions, and Rank-one Concept Redirection (ROCR) is proposed as a form-independent solution that enhances unlearning efficacy.  					AI-generated summary 				 Large Language Model (LLM) unlearning aims to erase or suppress undesirable knowledge within the model, offering promise for controlling harmful or private information to prevent misuse. However, recent studies highlight its limited efficacy in real-world scenarios, hindering practical adoption. In this study, we identify a pervasive issue underlying many downstream failures: the effectiveness of existing unlearning methods heavily depends on the form of training samples and frequently fails to generalize to alternate expressions of the same knowledge. We formally characterize this problem as Form-Dependent Bias and systematically investigate its specific manifestation patterns across various downstream tasks. To quantify its prevalence and support future research, we introduce ORT, a novel benchmark designed to evaluate the robustness of unlearning methods against variations in knowledge expression. Results reveal that Form-Dependent Bias is both widespread and severe among current techniques.   We argue that LLM unlearning should be form-independent to address the endless forms of downstream tasks encountered in real-world security-critical scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR), a novel training-free method, as a promising solution path. ROCR performs unlearning by targeting the invariants in downstream tasks, specifically the activated dangerous concepts. It is capable of modifying model parameters within seconds to redirect the model's perception of a specific unlearning target concept to another harmless concept. Extensive experiments demonstrate that ROCR significantly improves unlearning effectiveness compared to traditional methods while generating highly natural outputs.
[13.06.2025 09:14] Response: {
  "desc": "Исследование выявило проблему зависимости эффективности методов разобучения больших языковых моделей от формы обучающих примеров. Это явление, названное Form-Dependent Bias, ограничивает возможности подавления нежелательных знаний в моделях. Для решения этой проблемы авторы предлагают новый метод Rank-one Concept Redirection (ROCR), который не зависит от формы представления знаний. ROCR перенаправляет восприятие модели от опасных концепций к безвредным, значительно улучшая эффективность разобучения по сравнению с традиционными методами.",

  "emoji": "🧠",

  "title": "Преодоление зависимости от формы в разобучении языковых моделей"
}
[13.06.2025 09:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Form-Dependent Bias limits the effectiveness of LLM unlearning across different knowledge expressions, and Rank-one Concept Redirection (ROCR) is proposed as a form-independent solution that enhances unlearning efficacy.  					AI-generated summary 				 Large Language Model (LLM) unlearning aims to erase or suppress undesirable knowledge within the model, offering promise for controlling harmful or private information to prevent misuse. However, recent studies highlight its limited efficacy in real-world scenarios, hindering practical adoption. In this study, we identify a pervasive issue underlying many downstream failures: the effectiveness of existing unlearning methods heavily depends on the form of training samples and frequently fails to generalize to alternate expressions of the same knowledge. We formally characterize this problem as Form-Dependent Bias and systematically investigate its specific manifestation patterns across various downstream tasks. To quantify its prevalence and support future research, we introduce ORT, a novel benchmark designed to evaluate the robustness of unlearning methods against variations in knowledge expression. Results reveal that Form-Dependent Bias is both widespread and severe among current techniques.   We argue that LLM unlearning should be form-independent to address the endless forms of downstream tasks encountered in real-world security-critical scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR), a novel training-free method, as a promising solution path. ROCR performs unlearning by targeting the invariants in downstream tasks, specifically the activated dangerous concepts. It is capable of modifying model parameters within seconds to redirect the model's perception of a specific unlearning target concept to another harmless concept. Extensive experiments demonstrate that ROCR significantly improves unlearning effectiveness compared to traditional methods while generating highly natural outputs."

[13.06.2025 09:14] Response: ```python
['RLHF', 'BENCHMARK', 'TRAINING']
```
[13.06.2025 09:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Form-Dependent Bias limits the effectiveness of LLM unlearning across different knowledge expressions, and Rank-one Concept Redirection (ROCR) is proposed as a form-independent solution that enhances unlearning efficacy.  					AI-generated summary 				 Large Language Model (LLM) unlearning aims to erase or suppress undesirable knowledge within the model, offering promise for controlling harmful or private information to prevent misuse. However, recent studies highlight its limited efficacy in real-world scenarios, hindering practical adoption. In this study, we identify a pervasive issue underlying many downstream failures: the effectiveness of existing unlearning methods heavily depends on the form of training samples and frequently fails to generalize to alternate expressions of the same knowledge. We formally characterize this problem as Form-Dependent Bias and systematically investigate its specific manifestation patterns across various downstream tasks. To quantify its prevalence and support future research, we introduce ORT, a novel benchmark designed to evaluate the robustness of unlearning methods against variations in knowledge expression. Results reveal that Form-Dependent Bias is both widespread and severe among current techniques.   We argue that LLM unlearning should be form-independent to address the endless forms of downstream tasks encountered in real-world security-critical scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR), a novel training-free method, as a promising solution path. ROCR performs unlearning by targeting the invariants in downstream tasks, specifically the activated dangerous concepts. It is capable of modifying model parameters within seconds to redirect the model's perception of a specific unlearning target concept to another harmless concept. Extensive experiments demonstrate that ROCR significantly improves unlearning effectiveness compared to traditional methods while generating highly natural outputs."

[13.06.2025 09:14] Response: ```python
["ETHICS", "SECURITY", "HALLUCINATIONS"]
```
[13.06.2025 09:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of unlearning in Large Language Models (LLMs), specifically focusing on the limitations caused by Form-Dependent Bias, which affects the effectiveness of unlearning methods across different knowledge expressions. The authors propose a new method called Rank-one Concept Redirection (ROCR) that aims to enhance unlearning efficacy by being form-independent, allowing it to generalize better across various tasks. They introduce a benchmark called ORT to evaluate the robustness of unlearning techniques against different expressions of knowledge. Experimental results show that ROCR outperforms traditional unlearning methods, providing a more effective and efficient way to manage harmful or private information in LLMs.","title":"Unlearning Without Limits: ROCR for Form-Independent Knowledge Management"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenge of unlearning in Large Language Models (LLMs), specifically focusing on the limitations caused by Form-Dependent Bias, which affects the effectiveness of unlearning methods across different knowledge expressions. The authors propose a new method called Rank-one Concept Redirection (ROCR) that aims to enhance unlearning efficacy by being form-independent, allowing it to generalize better across various tasks. They introduce a benchmark called ORT to evaluate the robustness of unlearning techniques against different expressions of knowledge. Experimental results show that ROCR outperforms traditional unlearning methods, providing a more effective and efficient way to manage harmful or private information in LLMs.', title='Unlearning Without Limits: ROCR for Form-Independent Knowledge Management'))
[13.06.2025 09:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了大型语言模型（LLM）在去除不良知识时面临的挑战，特别是形式依赖偏差的问题。研究表明，现有的去学习方法在不同知识表达形式下的有效性有限，导致其在实际应用中的效果不佳。为了解决这一问题，提出了一种新的方法——Rank-one Concept Redirection（ROCR），旨在实现形式无关的去学习。实验结果显示，ROCR在去学习的有效性上显著优于传统方法，同时生成的输出也更加自然。","title":"形式无关的去学习新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了大型语言模型（LLM）在去除不良知识时面临的挑战，特别是形式依赖偏差的问题。研究表明，现有的去学习方法在不同知识表达形式下的有效性有限，导致其在实际应用中的效果不佳。为了解决这一问题，提出了一种新的方法——Rank-one Concept Redirection（ROCR），旨在实现形式无关的去学习。实验结果显示，ROCR在去学习的有效性上显著优于传统方法，同时生成的输出也更加自然。', title='形式无关的去学习新方法'))
[13.06.2025 09:14] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#survey", "#reasoning", "#training"], "emoji": "🧠", "ru": {"title": "Оптимизация промптов для улучшения рассуждений языковых моделей", "desc": "Предложена система оценки и оптимизации естественно-языковых промптов для больших языковых моделей. Авторы п
[13.06.2025 09:14] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#multimodal", "#interpretability", "#games"], "emoji": "🖼️", "ru": {"title": "Персонализированные подписи к изображениям: мультимодальный подход", "desc": "LaMP-Cap представляет датасет для персонализированной генерации подписей к изображениям с использо
[13.06.2025 09:14] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#security", "#open_source", "#multimodal"], "emoji": "🔐", "ru": {"title": "Единый мультимодальный бенчмарк для оценки безопасности CAPTCHA", "desc": "MCA-Bench - это комплексный набор инструментов для оценки безопасности CAPTCHA, использующий мультимодальный
[13.06.2025 09:14] Using data from previous issue: {"categories": ["#science", "#dataset", "#interpretability", "#benchmark", "#reasoning", "#math"], "emoji": "🧠", "ru": {"title": "Раскрытие причинно-следственных связей в способностях языковых моделей", "desc": "Исследование предлагает каузальную модель представления для оценки возможностей языковых
[13.06.2025 09:14] Querying the API.
[13.06.2025 09:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

StreamSplat, a fully feed-forward framework, addresses real-time 3D scene reconstruction from uncalibrated video with accurate dynamics and long-term stability.  					AI-generated summary 				 Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams is crucial for numerous real-world applications. However, existing methods struggle to jointly address three key challenges: 1) processing uncalibrated inputs in real time, 2) accurately modeling dynamic scene evolution, and 3) maintaining long-term stability and computational efficiency. To this end, we introduce StreamSplat, the first fully feed-forward framework that transforms uncalibrated video streams of arbitrary length into dynamic 3D Gaussian Splatting (3DGS) representations in an online manner, capable of recovering scene dynamics from temporally local observations. We propose two key technical innovations: a probabilistic sampling mechanism in the static encoder for 3DGS position prediction, and a bidirectional deformation field in the dynamic decoder that enables robust and efficient dynamic modeling. Extensive experiments on static and dynamic benchmarks demonstrate that StreamSplat consistently outperforms prior works in both reconstruction quality and dynamic scene modeling, while uniquely supporting online reconstruction of arbitrarily long video streams. Code and models are available at https://github.com/nickwzk/StreamSplat.
[13.06.2025 09:14] Response: {
  "desc": "StreamSplat - это новая система для реконструкции динамических 3D-сцен из неоткалиброванного видео в режиме реального времени. Она использует полностью прямую архитектуру нейронной сети для преобразования видеопотока в динамическое представление на основе 3D Gaussian Splatting. Ключевые инновации включают вероятностный механизм выборки для предсказания позиций 3DGS и двунаправленное поле деформации для моделирования динамики. StreamSplat превосходит существующие методы по качеству реконструкции и эффективности, поддерживая обработку видеопотоков произвольной длины.",
  "emoji": "🎥",
  "title": "Революция в 3D-реконструкции: от видео к динамическим сценам в реальном времени"
}
[13.06.2025 09:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"StreamSplat, a fully feed-forward framework, addresses real-time 3D scene reconstruction from uncalibrated video with accurate dynamics and long-term stability.  					AI-generated summary 				 Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams is crucial for numerous real-world applications. However, existing methods struggle to jointly address three key challenges: 1) processing uncalibrated inputs in real time, 2) accurately modeling dynamic scene evolution, and 3) maintaining long-term stability and computational efficiency. To this end, we introduce StreamSplat, the first fully feed-forward framework that transforms uncalibrated video streams of arbitrary length into dynamic 3D Gaussian Splatting (3DGS) representations in an online manner, capable of recovering scene dynamics from temporally local observations. We propose two key technical innovations: a probabilistic sampling mechanism in the static encoder for 3DGS position prediction, and a bidirectional deformation field in the dynamic decoder that enables robust and efficient dynamic modeling. Extensive experiments on static and dynamic benchmarks demonstrate that StreamSplat consistently outperforms prior works in both reconstruction quality and dynamic scene modeling, while uniquely supporting online reconstruction of arbitrarily long video streams. Code and models are available at https://github.com/nickwzk/StreamSplat."

[13.06.2025 09:14] Response: ```python
['3D', 'VIDEO', 'BENCHMARK', 'ARCHITECTURE']
```
[13.06.2025 09:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"StreamSplat, a fully feed-forward framework, addresses real-time 3D scene reconstruction from uncalibrated video with accurate dynamics and long-term stability.  					AI-generated summary 				 Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams is crucial for numerous real-world applications. However, existing methods struggle to jointly address three key challenges: 1) processing uncalibrated inputs in real time, 2) accurately modeling dynamic scene evolution, and 3) maintaining long-term stability and computational efficiency. To this end, we introduce StreamSplat, the first fully feed-forward framework that transforms uncalibrated video streams of arbitrary length into dynamic 3D Gaussian Splatting (3DGS) representations in an online manner, capable of recovering scene dynamics from temporally local observations. We propose two key technical innovations: a probabilistic sampling mechanism in the static encoder for 3DGS position prediction, and a bidirectional deformation field in the dynamic decoder that enables robust and efficient dynamic modeling. Extensive experiments on static and dynamic benchmarks demonstrate that StreamSplat consistently outperforms prior works in both reconstruction quality and dynamic scene modeling, while uniquely supporting online reconstruction of arbitrarily long video streams. Code and models are available at https://github.com/nickwzk/StreamSplat."

[13.06.2025 09:14] Response: []
[13.06.2025 09:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"StreamSplat is a novel framework designed for real-time 3D scene reconstruction from uncalibrated video inputs. It effectively addresses the challenges of processing uncalibrated data, accurately modeling dynamic changes in scenes, and ensuring long-term stability. The framework utilizes a feed-forward approach, incorporating a probabilistic sampling mechanism for predicting 3D positions and a bidirectional deformation field for dynamic modeling. Experimental results show that StreamSplat outperforms existing methods in both reconstruction quality and the ability to handle long video streams.","title":"StreamSplat: Real-Time 3D Scene Reconstruction Made Easy!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='StreamSplat is a novel framework designed for real-time 3D scene reconstruction from uncalibrated video inputs. It effectively addresses the challenges of processing uncalibrated data, accurately modeling dynamic changes in scenes, and ensuring long-term stability. The framework utilizes a feed-forward approach, incorporating a probabilistic sampling mechanism for predicting 3D positions and a bidirectional deformation field for dynamic modeling. Experimental results show that StreamSplat outperforms existing methods in both reconstruction quality and the ability to handle long video streams.', title='StreamSplat: Real-Time 3D Scene Reconstruction Made Easy!'))
[13.06.2025 09:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"StreamSplat 是一个完全前馈的框架，旨在从未校准的视频中实时重建动态三维场景。该方法解决了处理未校准输入、准确建模动态场景演变以及保持长期稳定性等三个关键挑战。通过引入静态编码器中的概率采样机制和动态解码器中的双向变形场，StreamSplat 实现了高效的动态建模。实验结果表明，StreamSplat 在重建质量和动态场景建模方面均优于现有方法，并支持任意长度视频流的在线重建。","title":"StreamSplat：实时动态三维场景重建的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='StreamSplat 是一个完全前馈的框架，旨在从未校准的视频中实时重建动态三维场景。该方法解决了处理未校准输入、准确建模动态场景演变以及保持长期稳定性等三个关键挑战。通过引入静态编码器中的概率采样机制和动态解码器中的双向变形场，StreamSplat 实现了高效的动态建模。实验结果表明，StreamSplat 在重建质量和动态场景建模方面均优于现有方法，并支持任意长度视频流的在线重建。', title='StreamSplat：实时动态三维场景重建的新突破'))
[13.06.2025 09:14] Trying to get texts in Chinese.
[13.06.2025 09:14] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

ReasonMed, a large medical reasoning dataset, enhances the accuracy of medical question answering models by combining detailed reasoning paths with concise summaries, setting new benchmarks for model performance.  					AI-generated summary 				 Though reasoning-based large language models (LLMs) have excelled in mathematics and programming, their capabilities in knowledge-intensive medical question answering remain underexplored. To address this, we introduce ReasonMed, the largest medical reasoning dataset, comprising 370k high-quality examples distilled from 1.7 million initial reasoning paths generated by various LLMs. ReasonMed is constructed through a multi-agent verification and refinement process, where we design an Error Refiner to enhance the reasoning paths by identifying and correcting error-prone steps flagged by a verifier. Leveraging ReasonMed, we systematically investigate best practices for training medical reasoning models and find that combining detailed Chain-of-Thought (CoT) reasoning with concise answer summaries yields the most effective fine-tuning strategy. Based on this strategy, we train ReasonMed-7B, which sets a new benchmark for sub-10B models, outperforming the prior best by 4.17\% and even exceeding LLaMA3.1-70B on PubMedQA by 4.60\%.
[13.06.2025 09:14] Mistral response. {"object": "error", "message": "Service tier capacity exceeded for this model.", "type": "invalid_request_error", "param": null, "code": null}
[13.06.2025 09:14] Failed to get Chinese text: 'choices'
[13.06.2025 09:14] Renaming data file.
[13.06.2025 09:14] Renaming previous data. hf_papers.json to ./d/2025-06-13.json
[13.06.2025 09:14] Saving new data file.
[13.06.2025 09:14] Generating page.
[13.06.2025 09:14] Renaming previous page.
[13.06.2025 09:14] Renaming previous data. index.html to ./d/2025-06-13.html
[13.06.2025 09:14] [Experimental] Generating Chinese page for reading.
[13.06.2025 09:14] Writing result.
[13.06.2025 09:14] Renaming log file.
[13.06.2025 09:14] Renaming previous data. log.txt to ./logs/2025-06-13_last_log.txt
