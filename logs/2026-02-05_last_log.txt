[05.02.2026 01:18] Read previous papers.
[05.02.2026 01:18] Generating top page (month).
[05.02.2026 01:18] Writing top page (month).
[05.02.2026 04:08] Read previous papers.
[05.02.2026 04:08] Get feed.
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.02402
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.02958
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.04515
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.03442
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2601.18207
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.04879
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.04575
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2601.22954
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.01640
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.03143
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.04145
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.02554
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.02350
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.04486
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.04605
[05.02.2026 04:08] Extract page data from URL. URL: https://huggingface.co/papers/2602.04284
[05.02.2026 04:08] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.02.2026 04:08] Downloading and parsing papers (pdf, html). Total: 16.
[05.02.2026 04:08] Downloading and parsing paper https://huggingface.co/papers/2602.02402.
[05.02.2026 04:08] Downloading paper 2602.02402 from https://arxiv.org/pdf/2602.02402v1...
[05.02.2026 04:08] Extracting affiliations from text.
[05.02.2026 04:08] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SoMA: Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation Mu Huang 1 2 Hui Wang 3 2 Kerui Ren 3 2 Linning Xu 4 2 Yunsong Zhou 2 Mulin Yu 2 Bo Dai 5 Jiangmiao Pang 2 6 2 0 2 2 ] . [ 1 2 0 4 2 0 . 2 0 6 2 : r Figure 1. SoMA is GS neural simulator that reconstructs and simulates deformable object dynamics from real-world robot manipulation. Learning from multi-view RGB observations, it performs action-conditioned simulation directly on Gaussian splats, enabling interactionconsistent, stable long-horizon resimulation with higher-fidelity rendering under both seen and unseen manipulations. "
[05.02.2026 04:08] Response: ```python
[]
```
[05.02.2026 04:08] Extracting affiliations from text.
[05.02.2026 04:08] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SoMA: Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation Mu Huang 1 2 Hui Wang 3 2 Kerui Ren 3 2 Linning Xu 4 2 Yunsong Zhou 2 Mulin Yu 2 Bo Dai 5 Jiangmiao Pang 2 6 2 0 2 2 ] . [ 1 2 0 4 2 0 . 2 0 6 2 : r Figure 1. SoMA is GS neural simulator that reconstructs and simulates deformable object dynamics from real-world robot manipulation. Learning from multi-view RGB observations, it performs action-conditioned simulation directly on Gaussian splats, enabling interactionconsistent, stable long-horizon resimulation with higher-fidelity rendering under both seen and unseen manipulations.Simulating deformable objects under rich interactions remains fundamental challenge for realto-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable longhorizon manipulation and generalization beyond 1Fudan University, China 2Shanghai Artificial Intelligence Laboratory, China 3Shanghai Jiao Tong University, China 4The Chinese University of Hong Kong, China 5The University of Hong Kong, China. Correspondence to: Bo Dai <bdai@hku.hk>. Preprint. February 3, 2026. 1 observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding. Project Page: city-super.github.io/SoMA 1. Introduction Embodied learning is inherently data-driven, as it requires large-scale interaction data for robots to understand and act in the physical world. Yet, collecting real-world robot manipulation data is costly and risky (Zheng et al., 2025), as in tasks involving deformable objects like cloth folding and flexible object handling (Ganapathi et al., 2021; Mo et al., 2022). Thus, real-to-sim (R2S) simulation offers alternative by scalable reproducing real-world object behaviors in virtual environments, serving as foundation for data synthesis, augmentation, and policy learning. practical simulator must strike balance between physical fidelity and long-horizon interaction consistency. It should Submission and Formatting Instructions for ICML 2026 faithfully capture deformable object geometry and dynamics without introducing R2S bias, while remaining stable and coherent under sustained robotobject interaction. While geometry can often be recovered from visual observations, learning physically meaningful dynamics and interactions remains challenging. This challenge is exacerbated by partial occlusion and complex contact patterns. Existing approaches address these challenges along two largely separate directions. Physics-based simulators (Belytschko et al., 2014; Jiang et al., 2016) ensure consistent interaction over long horizons, but rely on predefined physical models and parameters that are difficult to infer from visual data. Differentiable simulators (Jiang et al., 2025a; Zhang et al., 2024b; Zhong et al., 2024) alleviate this limitation by optimizing small set of parameters, yet remain constrained by simplified physical assumptions. In contrast, neural dynamics modeling (Shao et al., 2024; Zhang et al., 2024a) and 4D reconstruction methods (Bahmani et al., 2024a;b; Ling et al., 2024; Ren et al., 2023) learn motion directly from data and recover dynamic geometry, but primarily focus on reproducing observed trajectories, offering limited support for robot-conditioned interaction and generalization beyond the training distribution. As result, neither direction alone suffices for R2S simulation in complex robot manipulation. We bridge the two worlds by rethinking the representation and learning of deformable object simulation. This paper proposes SoMA, real-to-sim neural Simulator of Manipulation for soft-body interaction, operating directly on learned Gaussian splat representations. SoMA models deformable objects, robot actions, and environmental effects in unified learned particle representation, enabling causal action-driven dynamics and stable long-horizon interaction without predefined physical rules. Explicit designs are proposed to achieve the functionality through the neural simulator. To ensure kinematically consistent interaction between the robot and deformable objects, it establishes robot-conditioned R2S mapping that anchors learned object dynamics to the robots joint-space actions, ensuring causal and kinematically consistent interaction. For physically consistent interaction, dynamics are modeled through force-driven updates defined directly on Gaussian splats, allowing local contact effects to propagate through the deformable object even when visual observations are partial or occluded. To support long-horizon interaction without drift or collapse, SoMA adopts multi-resolution training strategy that balances temporal coverage and computational efficiency, together with blended supervision scheme that combines occlusion-aware reconstruction signals with physics-inspired consistency constraints. Together, these components enable SoMA to serve as stable, actionconditioned neural simulator for R2S soft-body manipulation. We summarize our contributions as follows: (1) R2S neural simulation paradigm for soft-body manipulation, supporting long-horizon, interaction-consistent simulation. (2) Mechanisms that make such simulation feasible, including robot-conditioned alignment to anchor scenes to real kinematics, force-driven Gaussian-splat dynamics model for contact and occlusion, and multi-resolution training with blended supervision for stable long-horizon performance. (3) Extensive evaluation on public benchmarks and new real-world dataset, demonstrating state-of-the-art RGB and depth performance (20% improvement) and clear advantages for sustained interactive manipulation. 2. Related Works 3D reconstruction and scene representation. Camera pose estimation and 3D reconstruction form the geometric basis of vision-based simulation and real-to-sim pipelines. Classical multi-view geometry methods, such as SLAM and COLMAP (Cadena et al., 2017; Cam"
[05.02.2026 04:08] Mistral response. {"id": "c2830e8666844ee3a34f18275c36f7d7", "created": 1770264536, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1379, "total_tokens": 1434, "completion_tokens": 55, "num_cached_tokens": 1378}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Fudan University, China\",\n    \"Shanghai Artificial Intelligence Laboratory, China\",\n    \"Shanghai Jiao Tong University, China\",\n    \"The Chinese University of Hong Kong, China\",\n    \"The University of Hong Kong, China\"\n]\n```"}}]}
[05.02.2026 04:08] Response: ```python
[
    "Fudan University, China",
    "Shanghai Artificial Intelligence Laboratory, China",
    "Shanghai Jiao Tong University, China",
    "The Chinese University of Hong Kong, China",
    "The University of Hong Kong, China"
]
```
[05.02.2026 04:08] Deleting PDF ./assets/pdf/2602.02402.pdf.
[05.02.2026 04:08] Success.
[05.02.2026 04:08] Downloading and parsing paper https://huggingface.co/papers/2602.02958.
[05.02.2026 04:08] Downloading paper 2602.02958 from https://arxiv.org/pdf/2602.02958v1...
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization Haocheng Xi * 1 Shuo Yang * 1 Yilong Zhao 1 Muyang Li 2 Han Cai 3 Xingyang Li 2 Yujun Lin 3 Zhuoyang Zhang 2 Jintao Zhang 1 Xiuyu Li 1 Zhiying Xu 4 Jun Wu 4 Chenfeng Xu 5 Ion Stoica 1 Song Han 3 2 Kurt Keutzer 1 6 2 0 2 3 ] . [ 1 8 5 9 2 0 . 2 0 6 2 : r a "
[05.02.2026 04:09] Response: ```python
[
    "UC Berkeley",
    "MIT-IBM Watson AI Lab",
    "MIT",
    "Tsinghua University",
    "Stanford University"
]
```
[05.02.2026 04:09] Deleting PDF ./assets/pdf/2602.02958.pdf.
[05.02.2026 04:09] Success.
[05.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.04515.
[05.02.2026 04:09] Downloading paper 2602.04515 from https://arxiv.org/pdf/2602.04515v1...
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models Yu Bai, MingMing Yu, Chaojie Li, Ziyi Bai, Xinlong Wang, Borje F. Karlsson Beijing Academy of Artificial Intelligence 6 2 0 2 4 ] . [ 1 5 1 5 4 0 . 2 0 6 2 : r Fig. 1: Overview of EgoActor, which can control humanoid robot by jointly predicting movement, active perception, manipulation, and human interaction actions to achieve coordinated and precise execution, enabling humanoid robots to conduct long-horizon multi-step task instructions described in natural language. AbstractDeploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose novel task EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and humanrobot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGBonly data from real-world demonstrations, spatial reasoning questionanswering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments1. I. INTRODUCTION Deploying humanoid robots in rea"
[05.02.2026 04:09] Response: ```python
["Beijing Academy of Artificial Intelligence"]
```
[05.02.2026 04:09] Deleting PDF ./assets/pdf/2602.04515.pdf.
[05.02.2026 04:09] Success.
[05.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.03442.
[05.02.2026 04:09] Downloading paper 2602.03442 from https://arxiv.org/pdf/2602.03442v1...
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 3 ] . [ 1 2 4 4 3 0 . 2 0 6 2 : r A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces February 4, Mingxuan Du1, Benfeng Xu2, Chiwei Zhu1, Shaohan Wang1, Pengyu Wang1 Xiaorui Wang2, Zhendong Mao1 1University of Science and Technology of China, Hefei, China 2Metastone Technology, Beijing, China dumingxuan@mail.ustc.edu.cn Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in single shot and concatenates them into the models input, or (2) predefining workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword_search, semantic_search, and chunk_read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag. The development of LLMs has entered new phase, where the primary scaling direction is shifting from single-turn text understanding and generation toward complex reasoning and multi-step, toolaugmented interaction (OpenAI, 2025c; Anthropic, 2025b; Google, 2025; DeepSeek-AI et al., 2025;"
[05.02.2026 04:09] Response: ```python
[
    "University of Science and Technology of China, Hefei, China",
    "Metastone Technology, Beijing, China"
]
```
[05.02.2026 04:09] Deleting PDF ./assets/pdf/2602.03442.pdf.
[05.02.2026 04:09] Success.
[05.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2601.18207.
[05.02.2026 04:09] Downloading paper 2601.18207 from https://arxiv.org/pdf/2601.18207v1...
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR James Burgess1* Jan N. Hansen1 Duo Peng2 Yuhui Zhang1 Alejandro Lozano1 Min Woo Sun1 Emma Lundberg1,2,3 Serena Yeung-Levy1,2 1Stanford University, 2Chan Zuckerberg Biohub Network , 3KTH Royal Institute of Technology (cid:128) Project Page ı Datasets Code "
[05.02.2026 04:09] Response: ```python
[
    "Stanford University",
    "Chan Zuckerberg Biohub Network",
    "KTH Royal Institute of Technology"
]
```
[05.02.2026 04:09] Deleting PDF ./assets/pdf/2601.18207.pdf.
[05.02.2026 04:09] Success.
[05.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.04879.
[05.02.2026 04:09] Downloading paper 2602.04879 from https://arxiv.org/pdf/2602.04879v1...
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Penghui Qi * 1 2 Xiangxin Zhou * 1 Zichen Liu 2 Tianyu Pang 1 Chao Du 1 Min Lin 1 Wee Sun Lee 2 (cid:135) https://github.com/sail-sg/Stable-RL 6 2 0 2 4 ] . [ 1 9 7 8 4 0 . 2 0 6 2 : r Figure 1. Comparison of PPO and the proposed DPPO (the Binary-TV variant in Section 4.4). (Left) The surrogate objective and corresponding masks for PPO and DPPO. PPO (and variants like GRPO) employs heuristic mask based on the probability ratio, which over-penalizes low-probability tokens and under-penalizes high-probability ones (Section 4.2). In contrast, DPPO utilizes more principled mask based on direct approximation of policy divergence (e.g., Total Variation), ensuring updates stay within theoretically grounded trust region (Section 3). (Right) Experimental results on the AIME24 using Qwen3-30B-A3B-Base. DPPO significantly outperforms GRPO baselines, achieving superior training efficiency and stability even without rollout routing replay (R3) (Section 7). "
[05.02.2026 04:09] Response: ```python
[]
```
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Penghui Qi * 1 2 Xiangxin Zhou * 1 Zichen Liu 2 Tianyu Pang 1 Chao Du 1 Min Lin 1 Wee Sun Lee 2 (cid:135) https://github.com/sail-sg/Stable-RL 6 2 0 2 4 ] . [ 1 9 7 8 4 0 . 2 0 6 2 : r Figure 1. Comparison of PPO and the proposed DPPO (the Binary-TV variant in Section 4.4). (Left) The surrogate objective and corresponding masks for PPO and DPPO. PPO (and variants like GRPO) employs heuristic mask based on the probability ratio, which over-penalizes low-probability tokens and under-penalizes high-probability ones (Section 4.2). In contrast, DPPO utilizes more principled mask based on direct approximation of policy divergence (e.g., Total Variation), ensuring updates stay within theoretically grounded trust region (Section 3). (Right) Experimental results on the AIME24 using Qwen3-30B-A3B-Base. DPPO significantly outperforms GRPO baselines, achieving superior training efficiency and stability even without rollout routing replay (R3) (Section 7).Reinforcement learning (RL) has become cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally illsuited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as noisy single-sample Monte Carlo estimate of the true policy divergence. This creates sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping *Equal contribution 1Sea AI Lab, Singapore 2School of Computing, National University of Singapore. Correspondence to: Wee Sun Lee <leews@comp.nus.edu.sg>, Penghui Qi <penghuiq@comp.nus.edu.sg>. Preprint. February 5, 2026. 1 with more principled constraint based on direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering more robust foundation for RL-based LLM fine-tuning. 1. Introduction Reinforcement learning (RL) is foundational paradigm for fine-tuning Large Language Models (LLMs), enabling alignment with human preferences (Ouyang et al., 2022; Rafailov et al., 2023) and complex reasoning tasks (Guo et al., 2025; Qi et al., 2025a). Proximal Policy Optimization (PPO1) (Schulman et al., 2017) has established itself as the de facto standard in this domain, favored for its simplicity and empirical scalability. Central to PPO is heuristic clipping mechanism designed to prevent destructive policy updates. By constraining the probability ratio between new 1We denote PPO by its ratio-clipping loss, regardless of advantage estimation. Under this definition, GRPO is PPO variant. Rethinking the Trust Region in LLM Reinforcement Learning gence Proximal Policy Optimization (DPPO), framework that substitutes PPOs heuristic clipping with more principled constraint grounded in trust region theory. Rather than relying on noisy single-sample ratios, DPPO directly estimates policy divergence (e.g., TV or KL divergence). To ensure memory feasibility for LLMs, we introduce two efficient approximations, Binary and Top-K divergence, which capture essential distributional shifts with negligible overhead. This allows DPPO to rigorously distinguish between safe and unsafe updates, effectively resolving the problems of overand under-constraining inherent in standard PPO. In this work, we provide comprehensive rethinking of the trust region in the context of LLM fine-tuning. Our contributions are threefold. Theoretical Formulation: We derive policy improvement bounds specifically tailored to the finite-horizon, undiscounted setting of LLM generation, establishing rigorous theoretical foundation for trust-region methods in this domain. Stability and Efficiency Analysis: We isolate the primary sources of training instability to provide practical stabilization guidelines, while further highlighting the significant role that low-probability tokens play in driving exploration. Algorithmic Performance: We demonstrate that DPPO achieves superior stability and final performance compared to existing methods like GRPO, providing robust new framework for RL-based fine-tuning. 2. Background 2.1. Policy Performance Difference We begin with the standard formulation of Markov Decision Process (MDP), defined by the tuple = (S, A, P, r, ρ0, γ), which includes the state space S, action space A, transition dynamics (ss, a), reward function r(s, a), initial state distribution ρ0(s), and discount factor γ [0, 1]. stochastic policy π(as) generates trajectories τ = (s0, a0, r0, s1, a1, r1, . . .) by sampling actions at π(st) and transitioning to states st+1 (st, at). The central goal of RL is to find policy that maximizes the expected discounted return: η(π) = Eτ π (cid:34) (cid:88) (cid:35) γtrt . t=0 (cid:104) (cid:80) To facilitate policy optimization, we define the standard value functions under policy π: the state-value function (cid:105) (cid:12) π(s) = Eτ π t=0 γtrt (cid:12)s0 = , the action-value func- (cid:105) (cid:104) (cid:80) tion Qπ(s, a) = Eτ π t=0 γtrt , and the advantage function Aπ(s, a) = Qπ(s, a) π(s). key theoretical tool for relating the performance of two distinct policies is the policy performance difference theorem (Kakade & Langford, 2002). It states that for any two policies, target policy (to be optimized) π and behavior (cid:12) (cid:12)s0 = s, a0 = Figure 2. The plots show numerical differences between training and an inference engine for Qwen3-30B-A3B-Base with identical parameters. (Left) The probability ratio (used in PPO) is highly volatile for low-probability tokens. (Right) In contrast, the TV divergence (used in DPPO) is more stable. This highlights key flaw of PPOs clipping mechanism: it over-penalizes low-probability tokens, which can slow down learning; and under-penalizes highprobability tokens, which can permit large, destabilizing updates. and old policies, the algorithm aims to confine learning to t"
[05.02.2026 04:09] Mistral response. {"id": "e908b7e0b00b4c459c54f6c220b09fe9", "created": 1770264569, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1631, "total_tokens": 1653, "completion_tokens": 22, "num_cached_tokens": 1630}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Sea AI Lab, Singapore\", \"School of Computing, National University of Singapore\"]\n```"}}]}
[05.02.2026 04:09] Response: ```python
["Sea AI Lab, Singapore", "School of Computing, National University of Singapore"]
```
[05.02.2026 04:09] Deleting PDF ./assets/pdf/2602.04879.pdf.
[05.02.2026 04:09] Success.
[05.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.04575.
[05.02.2026 04:09] Downloading paper 2602.04575 from https://arxiv.org/pdf/2602.04575v1...
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2026-02-05 Vibe AIGC: New Paradigm for Content Generation via Agentic Orchestration Jiaheng Liu1, Yuanxing Zhang2, Shihao Li1, Xinping Lei1 1 NJU-LINK Team, Nanjing University 2 Kling Team, Kuaishou Technology liujiaheng@nju.edu.cn Abstract For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered usability ceiling manifested as the Intent-Execution Gap (i.e., the fundamental disparity between creators high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the Vibe AIGC, new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows. Under this paradigm, the users role transcends traditional prompt engineering, evolving into Commander who provides Vibe, high-level representation encompassing aesthetic preferences, functional logic, and etc. centralized MetaPlanner then functions as system architect, deconstructing this Vibe into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from fragile inference engine into robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets. 6 2 0 2 4 ] . [ 1 5 7 5 4 0 . 2 0 6 2 : r Figure 1: Content generation advancing toward the Vibe AIGC era: systemic leap driven by structural combination. The trajectory of generative artificial intelligence (AI) has reached critical juncture. For the past decade, the community has operated under Model-Centric paradigm (Blattmann et al., 2023; Achiam et al., 2023; Rombach et al., 2"
[05.02.2026 04:09] Response: ```python
[
    "NJU-LINK Team, Nanjing University",
    "Kling Team, Kuaishou Technology"
]
```
[05.02.2026 04:09] Deleting PDF ./assets/pdf/2602.04575.pdf.
[05.02.2026 04:09] Success.
[05.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2601.22954.
[05.02.2026 04:09] Downloading paper 2601.22954 from https://arxiv.org/pdf/2601.22954v1...
[05.02.2026 04:09] Extracting affiliations from text.
[05.02.2026 04:09] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Yuezhou Hu * 1 Harman Singh * 1 Monishwaran Maheswaran * 1 Haocheng Xi 1 Coleman Hooper 1 Jintao Zhang 1 Aditya Tomar 1 Michael W. Mahoney 1 Sewon Min 1 Mehrdad Farajtabar 2 Kurt Keutzer 1 Amir Gholami 1 Chenfeng Xu 1 Links: Code Models Project Page 6 2 0 2 0 3 ] . [ 1 4 5 9 2 2 . 1 0 6 2 : r Abstract Diffusion Large Language Models (dLLMs) have emerged as promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, stateof-the-art block-wise dLLMs rely on remasking mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation. We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that standard dLLM can be efficiently converted to the RCD paradigm with merely 1 billion tokens. RCD consistently improves frontier dLLMs by 510 points in accuracy with minimal extra computation overhead across wide range of benchmarks. Notably, on the most challenging AIME tasks, RCD nearly doubles baseline accuracy and attains up to 45x fewer denoising steps at equivalent accuracy levels. 1. Introduction Diffusion Large Language Models (dLLMs) have recently emerged as promising alternative to purely autoregres- *Equal contribution Equal Advising 1University of California, Berkeley 2Apple. Correspondence to: Chenfeng Xu <xuchenfeng@berkeley.edu>, Amir Gholami <amirgh@berkeley.edu>. Preprint. February 2, 2026. 1 Figure 1. Overview of th"
[05.02.2026 04:09] Response: ```python
[
    "University of California, Berkeley",
    "Apple"
]
```
[05.02.2026 04:09] Deleting PDF ./assets/pdf/2601.22954.pdf.
[05.02.2026 04:09] Success.
[05.02.2026 04:09] Downloading and parsing paper https://huggingface.co/papers/2602.01640.
[05.02.2026 04:09] Downloading paper 2602.01640 from https://arxiv.org/pdf/2602.01640v1...
[05.02.2026 04:10] Extracting affiliations from text.
[05.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 0 4 6 1 0 . 2 0 6 2 : r A2Eval: Agentic and Automated Evaluation for Embodied Brain Shuai Zhang 1 2 3 Jiayu Hu 3 Zijie Chen 2 Zeyuan Ding 3 Yi Zhang 3 Yingji Zhang 4 Ziyi Zhou 3 5 Junwei Liao 3 Shengjie Zhou 6 Yong Dai 3 Zhenzhong Lan 2 Xiaozhu Ju Abstract Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor-intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers 4.6 speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearmans ρ = 0.85, and maintains high ranking fidelity (Kendalls τ = 0.81), establishing new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon. (a) Capacity coverage in embodied VLM benchmarks. 1. Introduction Evaluating modern embodied vision-language models (VLM) has become the compass for navigating the rapid advancements in Embodied AI (Liu et al., 2025; Cong & Mo, 2025). comprehensive and precise evaluation mechanism is not only benchmark for academic breakthroughs but also cornerstone for industrial decision-making (Yifan et al., 2025; Zhang et al., 2025a). However, the cost of 1Zhejiang University, China 2Westlake University, China 3Beijing Innovatio"
[05.02.2026 04:10] Response: ```python
[
    "Zhejiang University, China",
    "Westlake University, China",
    "Beijing Innovatio"
]
```
[05.02.2026 04:10] Deleting PDF ./assets/pdf/2602.01640.pdf.
[05.02.2026 04:10] Success.
[05.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.03143.
[05.02.2026 04:10] Downloading paper 2602.03143 from https://arxiv.org/pdf/2602.03143v1...
[05.02.2026 04:10] Extracting affiliations from text.
[05.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Self-Hinting Language Models Enhance Reinforcement Learning Baohao Liao * 1 2 Hanze Dong * 1 Xinxing Xu 1 Christof Monz 2 Jiang Bian 1 Abstract Group Relative Policy Optimization (GRPO) has recently emerged as practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards, GRPO often stalls because rollouts within group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt x, the model samples compact hint (e.g., plan or decomposition) and then generates solution τ conditioned on (x, h). Crucially, the task reward R(x, τ ) is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards. At test time, we set = and deploy the no-hint policy without any privileged information. Moreover, sampling diverse selfhints serves as an adaptive curriculum that tracks the learners bottlenecks more effectively than fixed hints from an initial policy or stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3BInstruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE. 6 2 0 2 3 ] . [ 1 3 4 1 3 0 . 2 0 6 2 : r 1. Introduction Reinforcement learning (RL) has become core tool for training and aligning large language models (LLMs), particularly when supervision is most naturally expressed via *Equal contribution This work was done during an internship at Microsoft. 1Microsoft Research 2Language Technology Lab, University of Amsterdam. Correspondence to: Hanze Dong <hanzedong@microsoft.com>. Pre"
[05.02.2026 04:10] Response: ```python
['Microsoft Research', 'Language Technology Lab, University of Amsterdam', 'Microsoft']
```
[05.02.2026 04:10] Deleting PDF ./assets/pdf/2602.03143.pdf.
[05.02.2026 04:10] Success.
[05.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.04145.
[05.02.2026 04:10] Downloading paper 2602.04145 from https://arxiv.org/pdf/2602.04145v1...
[05.02.2026 04:10] Extracting affiliations from text.
[05.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Jinyuan Li 1 Chengsong Huang 1 Langlin Huang 1 Shaoyang Xu 2 Haolin Liu 3 Wenxuan Zhang 2 Jiaxin Huang 1 Abstract Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)- annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training. Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora. To explain this, we formalize theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by relative 4.1%. Our code is released Balanced-Info-MPRM. 6 2 0 2 4 ] . [ 1 5 4 1 4 0 . 2 0 6 2 : r 1. Introduction Process Reward Models (PRMs) (Ma et al., 2023; Zhu et al., 2025; Tan et al., 2025) provide step-level supervision for reasoning by scoring intermediate steps instead of only the final answer. In multimodal reasoning, Multimodal PRMs (MPRMs) are increasingly used for Multimodal Large 1Washington University in St. Louis 2Singapore University of Technology and Design 3University of Virginia. Correspondence to: Jinyuan Li <ljinyuan@wustl.edu>, Jiaxin Huang (Corresponding Author) <jiaxinh@wustl.edu>. Preprint. February 5, 2026. Figure 1. Overall m"
[05.02.2026 04:10] Response: ```python
[
    "Washington University in St. Louis",
    "Singapore University of Technology and Design",
    "University of Virginia"
]
```
[05.02.2026 04:10] Deleting PDF ./assets/pdf/2602.04145.pdf.
[05.02.2026 04:10] Success.
[05.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.02554.
[05.02.2026 04:10] Downloading paper 2602.02554 from https://arxiv.org/pdf/2602.02554v1...
[05.02.2026 04:10] Extracting affiliations from text.
[05.02.2026 04:10] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation Jingwen Xu * 1 Yiyang Lu * 1 Zisu Huang 1 Changze Lv 1 Xiaohua Wang 1 Shizheng Li 1 Zhibo Xu 1 Zhengkang Guo 1 Zhengyuan Wang 1 Muzhao Tian 1 Xuanjing Huang 1 Xiaoqing Zheng 1 6 2 0 2 0 3 ] . [ 1 4 5 5 2 0 . 2 0 6 2 : r a "
[05.02.2026 04:10] Response: ```python
[]
```
[05.02.2026 04:10] Extracting affiliations from text.
[05.02.2026 04:10] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation Jingwen Xu * 1 Yiyang Lu * 1 Zisu Huang 1 Changze Lv 1 Xiaohua Wang 1 Shizheng Li 1 Zhibo Xu 1 Zhengkang Guo 1 Zhengyuan Wang 1 Muzhao Tian 1 Xuanjing Huang 1 Xiaoqing Zheng 1 6 2 0 2 0 3 ] . [ 1 4 5 5 2 0 . 2 0 6 2 : r aTraining LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs back-translation strategy: documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the models performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity. 1. Introduction The interaction of natural language and programming languages has been core focus in software engineering research. Key directions include generating executable code from natural language specifications (Haiduc & Marcus, 2008; Gulwani, 2011; Chen et al., 2021) and producing natural language documentation from source code (McBurney, 2015; Jiang et al., 2017; Iyer et al., 2016). These bidirectional transformations bridge human intent and machine1College of Computer Science and Artificial gence, Fudan University, Shanghai, China. dence Yiyang Huang <xqzheng@fudan.edu.cn>. IntelliCorresponJingwen Xu <xujw24@m.fudan.edu.cn>, Xuanjing Zheng Lu <xjhuang@fudan.edu.cn>, <yylu24@m.fudan.edu.cn>, Xiaoqing to: Preprint. February 4, 2026. 1 executable logic, enabling rapid prototyping and code synthesis (Austin et al., 2021; Hendrycks et al., 2021; Zhuo et al., 2024), while facilitating automated commenting and legacy code maintenance (Stolee et al., 2014; Wan et al., 2018). Overall, they enhance developer productivity and software maintainability across the development lifecycle. Code-related tasks have been studied for over decade. Early approaches relied on information retrieval techniques (Ye et al., 2016) as well as statistical models (Iyer et al., 2016; Wan et al., 2018). Recent advances in LLMs have substantially improved bidirectional generation between natural language and programming code. Foundation models such as GPT-5 (OpenAI, 2025), Qwen3 (Team, 2025), Gemini 2.5 (DeepMind, 2025), and Claude 3.7 (Anthropic, 2025) demonstrate strong code understanding and generation capabilities. In parallel, code-specialized models, including CodeLLaMA (Roziere et al., 2023), DeepSeek-Coder V2 (Zhu et al., 2024), and Qwen3-Coder (Team, 2025), have emerged and achieved strong performance across wide range of code-related benchmarks (Elnaggar et al., 2021; Chen et al., 2021; Austin et al., 2021; Zhuo et al., 2024). However, training LLMs for code-documentation alignment and transformation tasks, such as code description and documentation generation, typically relies on large collections of high-quality code-documentation pairs. Despite the abundance of raw source code in public repositories such as GitHub, such paired supervision remains limited and uneven in quality, which in turn constrains the scalability and generalization of models on these tasks. To address this bottleneck, prior work has explored various data augmentation strategies. For example, WizardCoder (Luo et al., 2023) iteratively evolves instructions to construct diverse training pairs, while Magicoder (Wei et al., 2024b) synthesizes coding problems from unlabeled code snippets. Gao et al. (2024) employs self-supervised pseudo-labeling on unlabeled code. Although effective, these approaches typically require stronger external models to synthesize documentation or pseudo-labels, preventing the target model from leveraging the same mechanism for self-improvement. Moreover, once such code-documentation pairs are constructed, model optimization is usually carried out using conventional suBatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation pervised fine-tuning (SFT) or reinforcement learning (RL) paradigms, where the generated documentation is treated as fixed supervision rather than being explicitly evaluated or optimized with respect to the training objective. To overcome these constraints, we revisit the problem from self-supervised perspective and explore whether meaningful training signals can be derived directly from unlabeled code via model generation and feedback. key observation is that well-formed documentation should preserve sufficient information to enable faithful reconstruction of the code, and effective code generation should adhere to the requirements outlined in the documentation. Consequently, the reconstructed code is expected to be similar with the original code. This relationship provides natural foundation for learning code-documentation transformations without relying on explicit paired data. This observation naturally motivates back-translation learning paradigm, in which documentation is generated from code and then used to regenerate code, with the similarity between the original and reconstructed code serving as an implicit supervisory signal. Building on this back-translation strategy, we propose BatCoder, self-contained framework that learns code description and code generation jointly from unlabeled code snippets. Given code snippet, the model first generates natural language document, which is then used to reconstruct the original code. The similarity between the original and reconstructed code provides unified training signal that serves two complementary purposes: assessing the quality of the generated documentation and guiding the code generation process. Recent advances in code similarity metrics, such as CSSG (Xu et al., 2026), make this design practically feasible. These similarity-based signals are incorporated as rewards within reinforcement learning algorithm, enabling the joint o"
[05.02.2026 04:10] Mistral response. {"id": "dd5930c81a0f46449e1d8ce87563279c", "created": 1770264635, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1519, "total_tokens": 1529, "completion_tokens": 10, "num_cached_tokens": 1518}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Fudan University\"]\n```"}}]}
[05.02.2026 04:10] Response: ```python
["Fudan University"]
```
[05.02.2026 04:10] Deleting PDF ./assets/pdf/2602.02554.pdf.
[05.02.2026 04:10] Success.
[05.02.2026 04:10] Downloading and parsing paper https://huggingface.co/papers/2602.02350.
[05.02.2026 04:10] Downloading paper 2602.02350 from https://arxiv.org/pdf/2602.02350v1...
[05.02.2026 04:11] Extracting affiliations from text.
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 0 5 3 2 0 . 2 0 6 2 : r Under review as conference paper at ICLR CONTEXT LEARNING FOR MULTI-AGENT DISCUSSION Xingyuan Hua1, Sheng Yue2, Xinyi Li3, Yizhe Zhao1, Jinrui Zhang1, Ju Ren1,4 1Department of Computer Science and Technology, Tsinghua University, 2School of Cyber Science and Technology, Sun Yat-sen University, 3College of Computer Science, Northwest University, 4Zhongguancun Laboratory "
[05.02.2026 04:11] Response: ```python
[
    "Department of Computer Science and Technology, Tsinghua University",
    "School of Cyber Science and Technology, Sun Yat-sen University",
    "College of Computer Science, Northwest University",
    "Zhongguancun Laboratory"
]
```
[05.02.2026 04:11] Deleting PDF ./assets/pdf/2602.02350.pdf.
[05.02.2026 04:11] Success.
[05.02.2026 04:11] Downloading and parsing paper https://huggingface.co/papers/2602.04486.
[05.02.2026 04:11] Downloading paper 2602.04486 from https://arxiv.org/pdf/2602.04486v1...
[05.02.2026 04:11] Extracting affiliations from text.
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition Jinlong Ma1, Yu Zhang1, Xuefeng Bai1, Kehai Chen1, Yuwei Wang2, Zeming Liu3, Jun Yu1, Min Zhang 1 1Harbin Institute of Technology, Shenzhen, China, 2Institute of Computing Technology Chinese Academy of Sciences, 3Beijing University of Aeronautics and Astronautics Correspondence: chenkehai@hit.edu.cn 6 2 0 2 4 ] . [ 1 6 8 4 4 0 . 2 0 6 2 : r a "
[05.02.2026 04:11] Response: ```python
[
    "Harbin Institute of Technology, Shenzhen, China",
    "Institute of Computing Technology Chinese Academy of Sciences",
    "Beijing University of Aeronautics and Astronautics"
]
```
[05.02.2026 04:11] Deleting PDF ./assets/pdf/2602.04486.pdf.
[05.02.2026 04:11] Success.
[05.02.2026 04:11] Downloading and parsing paper https://huggingface.co/papers/2602.04605.
[05.02.2026 04:11] Downloading paper 2602.04605 from https://arxiv.org/pdf/2602.04605v1...
[05.02.2026 04:11] Extracting affiliations from text.
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 4 ] . [ 1 5 0 6 4 0 . 2 0 6 2 : r RexBERT: Context Specialized Bidirectional Encoders E-commerce for Rahul Bajaj thebajajra@gmail.com Anuj Garg anujgarg2004@gmail.com "
[05.02.2026 04:11] Response: ```python
[]
```
[05.02.2026 04:11] Extracting affiliations from text.
[05.02.2026 04:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 4 ] . [ 1 5 0 6 4 0 . 2 0 6 2 : r RexBERT: Context Specialized Bidirectional Encoders E-commerce for Rahul Bajaj thebajajra@gmail.com Anuj Garg anujgarg2004@gmail.comEncoder-only transformers remain indispensable in retrieval, classification and ranking systems where latency, stability and cost are paramount. Most general-purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, family of BERT-style encoders designed specifically for e-commerce semantics. We make three contributions. First, we release Ecom-niverse, 350 billion token corpus curated from diverse retail and shopping sources. We describe modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present reproducible pre-training recipe building on ModernBERTs architectural advances. The recipe consists of three phases: general pre-training, context extension, and annealed domain specialization. Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification, semantic similarity, and general natural language understanding tasks using e-commerce dataset. Despite having 2-3 fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long context models on domain-specific benchmarks. Our results demonstrate that high-quality in-domain data combined with principled training approach provides stronger foundation for e-commerce applications than indiscriminate scaling alone.Encoder-only language models have long been the workhorses of natural language processing. BERT Devlin et al. (2019) and its successors power classification, retrieval, and reranking systems in production because they offer favorable trade-off between inference cost and quality. However, the community has increasingly focused on decoder-only models for generation, leaving encoder research comparatively underdeveloped. Recent efforts such as ModernBERT Warner et al. (2024) demonstrate that revisiting the encoder architecture and training recipe yields substantial Pareto improvements: models trained on 2 trillion tokens with long contexts deliver state-of-the-art performance across classification and retrieval tasks while being highly efficient for inference. In parallel, domain-specific encoders such as BioClinical ModernBERT for clinical NLP Sounack et al. (2025), show that continued pre-training on large, targeted corpus further boosts domain performance without sacrificing general abilities. These advances motivate revisiting domain adaptation for the e-commerce sector. Importantly, the principles underlying our approach careful data curation, multi-phase curriculum and modern encoder architecture are not tied to commerce. The same pipeline can be extended to any specialized domain by collecting an appropriate corpus and running it through our modular cleaning and training stages. In this sense, RexBERT serves as case study in building domain-specific encoders from open data, and the techniques we describe are readily applicable to healthcare, legal, scientific or other verticals. E-commerce is high-impact domain where representation quality directly affects search, recommendations, attribute extraction and compliance routing. Generic models trained on broad web corpora often fail to capture subtle distinctions between complementary, substitute, and irrelevant products or recognize fine-grained attributes. To address this gap, we develop RexBERT, family of open-data encoders specialized for retail. Our approach draws inspiration from ModernBERT but differs in two key respects: we operate exclusively on open datasets and curate large corpus 1 focused on commerce; and we employ three-stage curriculum that gradually shifts from general to domain-specific distributions. Contributions Our work makes the following contributions: 1. We curate Ecom-niverse, 350 billion token collection of retail-relevant text distilled from the FineFineWeb corpus. The dataset covers diverse categories such as fashion, beauty, automotive and entertainment. Figure 1 visualises the domain distribution of the curated corpus. 2. We describe pre-training recipe based on modernised encoder architecture. The training progresses through (1) pre-training on diverse mixture of open web, books, code and technical documents; (2) context extension to support sequences up to 8,192 tokens; and (3) annealing, which gradually shifts the sampling distribution toward Ecom-niverse and incorporates Guided MLM masking strategy. 3. We train RexBERT models at four scales (17 M, 68 M, 150 and 400 parameters) and evaluate them on GLUE tasks and e-commerce benchmarks derived from the Amazon ESCI dataset. RexBERT encoders consistently outperform general-purpose models of similar or larger size on token classification and semantic similarity tasks. Despite 2-3x fewer parameters, our models achieve higher token classification accuracy and Spearman correlation than contemporary models in similar parameter size range. Figure 1: Domain distribution of Ecom-niverse. Sizes represent the amount of filtered data contributed by each FineFineWeb domain and additional corpora. Hobby and News supply the largest portions.Encoder-only transformers BERT (Devlin et al., 2019) launched the era of encoder-only transformers. Subsequent variants such as RoBERTa (Liu et al., 2019), DeBERTa (He et al., 2021) and GTE incorporated training improvements, but many still rely on the original recipe and tokenizer. MosaicBERT (Portes et al., 2023) and CrammingBERT (Geiping & Goldstein, 2023) focus on efficiency rather than scaling. ModernBERT (Warner et al., 2024) modernises encoder architectures using rotary positional embeddings (RoPE), GeGLU activations, alternating global and local attention, unpadding and flash attention to achieve state-of-the-art performance on classification, retrieval and code tasks. Their training on 2 trillion tokens of diverse data and context extension to 8,192 tokens allows long-context inference with high throughput. Our work builds upon these architectural 2 advances but demonstrates that much smaller models can excel on specialised domains when paired with targeted pre-training. Domain-specific encoders Domain adaptation via continued pre-training has been successful in biomedical and clinical NLP, where BioBERT (Lee et al., 20"
[05.02.2026 04:11] Mistral response. {"id": "0323aed6a6f147a3ac00d12e7202d214", "created": 1770264678, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1390, "total_tokens": 1396, "completion_tokens": 6, "num_cached_tokens": 1389}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[]\n```"}}]}
[05.02.2026 04:11] Response: ```python
[]
```
[05.02.2026 04:11] Deleting PDF ./assets/pdf/2602.04605.pdf.
[05.02.2026 04:11] Success.
[05.02.2026 04:11] Downloading and parsing paper https://huggingface.co/papers/2602.04284.
[05.02.2026 04:11] Downloading paper 2602.04284 from https://arxiv.org/pdf/2602.04284v1...
[05.02.2026 04:11] Extracting affiliations from text.
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning Yansong Ning 1 Jun Fang 2 Naiqiang Tan 2 Hao Liu "
[05.02.2026 04:11] Response: ```python
[]
```
[05.02.2026 04:11] Extracting affiliations from text.
[05.02.2026 04:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning Yansong Ning 1 Jun Fang 2 Naiqiang Tan 2 Hao LiuManaging agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize small amount of cold-start data, including both singleturn and multi-turn omission scenarios, to finetune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating dual sampling mechanism and tailored omission reward to incentivize the agents adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usailhkust/Agent-Omit. 6 2 0 2 4 ] . [ 1 4 8 2 4 0 . 2 0 6 2 : r 1. Introduction Large language model (LLM) agents solve complex realworld tasks through autonomously interacting with external tool/resources with interleave thought, action, and environ1AI Thrust, The Hong Kong University of Science and Technology (Guangzhou) 2Didichuxing Co. Ltd 3CSE, The Hong Kong University of Science and Technology. Correspondence to: <yning092@connect.hkust-gz.edu.cn>. Preprint. February 5, 2026. 1 Figure 1. Illustrative examples of how thought necessity and observation utility varies across turns. (a) Initial planning (e.g., search for Trivor and Muztagh Ata) already determines the subsequent tool call action, making follow-up thought redundant; (b) Observations from early turns are unuseful in the last turn, because only tool response in turn 4 is used for the answer summarization. ment observation (Su et al., 2025). Recently, the paradigm of agentic reinforcement learning (RL) has further pushed the boundaries of this field (Shang et al., 2025). By interacting with environments and iteratively refining agent policy based on task-specific feedback, agentic LLMs like Kimi-K2 (Team et al., 2025a) and DeepSeek-V3.2 (Liu et al., 2025a) have demonstrated remarkable capabilities in wide of domain applications, such as deep search, web navigation, digital game, embodied decision-making, and scientific discovery (Xi et al., 2025). Despite these advances, these agents often suffer in generating redundant thought even for simple tool-call actions and accumulating excessive observation context over multiple turns (Wang et al., 2025), limiting their efficiency and practical applicability. Recent efforts have explored various strategies to mitigate these overheads. Overall, they can be categorized into three paradigms: Thought Management (TM), Observation Management (OM), and Thought&Observation Management (TOM). TM and OM are the most direct strategies, focusing on compressing thought or pruning historical observations. For example, ToolLight (Chen et al., 2025b) and Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission DEPO (Chen et al., 2025a) employ fine-tuning to compress the thought token length, while Observation-Mask (Lindenbauer et al., 2025) and DeepMiner (Tang et al., 2025) use the heuristic strategy to selectively omit historical observations. To address both simultaneously, TOM-based approaches like MEM-Agent (Yu et al., 2025) and ReSum (Wu et al., 2025) employ LLM-based summarization tools to jointly compress thought and observation into concise context. However, these studies tend to equally compress or modify the entire interaction trajectory, overlooking that the influence of thoughts and observations can vary across different turns. Our motivation stems from key assumption: the necessity of thoughts and observations utility varies across turns. As illustrated in Figure 1(a), an agents initial high-level planning often makes follow-up reasoning thoughts redundant once the execution is clear. Similarly, early-turn observations, while necessary for initial reasoning, usually become irrelevant noise during the final answer summarization phase. These limitations hinders the development of more flexible and efficient agents. To address this, we first conduct quantitative investigation into how thought and observation affect agent effectiveness and efficiency. Using Monte Carlo rollouts (Snell et al., 2024), we observe that not all turns contribute equally to task success, and selectively omitting redundant thought/observation can significantly reduce token cost without sacrificing accuracy. Building upon these insights, we propose AgentOmit, unified framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Our approach consists of two stages: (1) Agent Omission Behavior Synthesis, which constructs both of single-turn and multi-turn omission cold-start data to provide initial supervision for efficient agentic reasoning patterns; and (2) Omit-Aware Agentic Reinforcement Learning, which incorporates dual sampling mechanism and tailored omission reward to progressively improve the agents capability for adaptive thought/observation omission. Finally, we theoretically prove that the deviation of our omission policy is upper-bounded by the KL-divergence. We evaluate Agent-Omit on five benchmarks, including DeepSearch, WebShop, TextCraft, BabyAI, and SciWorld. Experimental results show that Agent-Omit-8B achieves accuracy comparable to seven frontier LLMs (e.g., DeepSeekR1-0528 and o3), while substantially reducing token cost. Moreover, when applied to Qwen3-8B, Agent-Omit consistently outperforms seven efficient LLM agent construction methods, achieving the best effectivenessefficiency trade-off. Further analysis reveals that the trained agent can adaptively omit 34 rounds of thought/observation, where omissions predominantl"
[05.02.2026 04:11] Mistral response. {"id": "08b73d5069be41d7803bc18aa3bfb949", "created": 1770264684, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1421, "total_tokens": 1471, "completion_tokens": 50, "num_cached_tokens": 1420}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"AI Thrust, The Hong Kong University of Science and Technology (Guangzhou)\",\n    \"Didichuxing Co. Ltd\",\n    \"CSE, The Hong Kong University of Science and Technology\"\n]\n```"}}]}
[05.02.2026 04:11] Response: ```python
[
    "AI Thrust, The Hong Kong University of Science and Technology (Guangzhou)",
    "Didichuxing Co. Ltd",
    "CSE, The Hong Kong University of Science and Technology"
]
```
[05.02.2026 04:11] Deleting PDF ./assets/pdf/2602.04284.pdf.
[05.02.2026 04:11] Success.
[05.02.2026 04:11] Enriching papers with extra data.
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 0. SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space.  					AI-generated summary 				 Simulating deformable objects under rich interactions remains...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 1. Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact.  					AI-generated summary 				 Despite rapid progress in autoregr...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 2. EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments.  					AI-generated summary 				 Deploying humanoid robots in real-world settings is fundam...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 3. Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements.  					AI-generated summary 				 Frontier language models have demonstrated strong reasoning and long-ho...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 4. Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.  					AI-generated summary 				 Search agents are language models ...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 5. DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency.  					AI-generated summary 				 Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs),...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 6. Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution.  					AI-generated summary 				 For the past decade, the traj...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 7. Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have emerged as a promising...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 8. Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy.  					AI-generated summary 				 Current embodied VLM evaluation relies on static, expert-defined, manually annotated benc...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 9. SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models.  					AI-generated summary 				 Group Relative Policy Optimization (GRPO) has recently em...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 10. Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data.  					AI-generated summary 				 Multimodal Process Reward Models (MPRMs) are central to step...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 11. BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks.  					AI-generated summary 				 Training LLMs for code-related tasks typically depends on high-...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 12. Multi-Agent Discussion methods suffer from inconsistency due to individual context misalignment, which is addressed through a context learning approach that dynamically generates context instructions for each agent to improve consensus reaching and performance.  					AI-generated summary 				 Multi-...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 13. MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization.  					AI-generated summary 				 Grounded Multimodal Named Entity Recognition (GMN...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 14. RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data.  					AI-generated summary 				 Encoder-only transformers remain indispensable in retrieval, classificat...
[05.02.2026 04:11] ********************************************************************************
[05.02.2026 04:11] Abstract 15. Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods.  					AI-generated summary 				 Managing agent thought and observatio...
[05.02.2026 04:11] Read previous papers.
[05.02.2026 04:11] Generating reviews via LLM API.
[05.02.2026 04:11] Querying the API.
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space.  					AI-generated summary 				 Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding.
[05.02.2026 04:11] Response: ```json
{
  "desc": "SoMA — это нейросетевой симулятор на основе трёхмерного Gaussian Splat, который объединяет моделирование деформируемых объектов, физических воздействий окружающей среды и действий робота в единое латентное пространство. Система позволяет стабильно симулировать длительные горизонты манипуляции мягкими телами без использования предопределённых физических законов, полагаясь на обучаемые нейронные представления. Подход улучшает точность перенесения симуляции с реальных данных в виртуальный мир на 20% и обеспечивает лучшую обобщаемость на новые траектории за пределы обучающих примеров. SoMA демонстрирует стабильность при выполнении сложных манипуляционных задач, таких как складывание ткани на длительных горизонтах.",
  "emoji": "🤖",
  "title": "Нейросетевой симулятор для управления мягкими телами без физических моделей"
}
```
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space.  					AI-generated summary 				 Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding."

[05.02.2026 04:11] Response: ```python
["3D", "ROBOTICS", "TRAINING"]
```

**Justification:**

- **3D**: The paper explicitly focuses on "3D Gaussian Splat simulator" and 3D content representation/processing
- **ROBOTICS**: The paper addresses robot manipulation, real-to-sim simulation for robotic systems, and robot-conditioned control
- **TRAINING**: The paper involves learning deformable dynamics and training neural models in a latent space for improved simulation and generalization
[05.02.2026 04:11] Error. Failed to parse JSON from LLM. ["3D", "ROBOTICS", "TRAINING"]


**Justification:**

- **3D**: The paper explicitly focuses on "3D Gaussian Splat simulator" and 3D content representation/processing
- **ROBOTICS**: The paper addresses robot manipulation, real-to-sim simulation for robotic systems, and robot-conditioned control
- **TRAINING**: The paper involves learning deformable dynamics and training neural models in a latent space for improved simulation and generalization
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space.  					AI-generated summary 				 Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding."

[05.02.2026 04:11] Response: ```python
['OPTIMIZATION']
```

The paper focuses on improving simulation and control methods for robot manipulation tasks, which relates to optimization of training and inference methods for neural simulators. However, the primary contribution is in developing a neural simulation framework rather than addressing the core topics in the provided list comprehensively. The paper doesn't directly address AGI, games, interpretability, reasoning, transfer learning, graphs, ethics, security, diffusion models, alignment, hallucinations, long context, synthetic data generation, translation, leakage, open-source contributions, scientific applications, or low-resource languages in a way that would warrant those classifications.
[05.02.2026 04:11] Error. Failed to parse JSON from LLM. ["OPTIMIZATION"]


The paper focuses on improving simulation and control methods for robot manipulation tasks, which relates to optimization of training and inference methods for neural simulators. However, the primary contribution is in developing a neural simulation framework rather than addressing the core topics in the provided list comprehensively. The paper doesn"t directly address AGI, games, interpretability, reasoning, transfer learning, graphs, ethics, security, diffusion models, alignment, hallucinations, long context, synthetic data generation, translation, leakage, open-source contributions, scientific applications, or low-resource languages in a way that would warrant those classifications.
[05.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SoMA is a novel simulator designed for manipulating soft bodies in three dimensions. It integrates deformable dynamics, environmental forces, and robot actions into a single neural framework, allowing for more accurate and stable simulations. By using learned Gaussian splats, SoMA can model complex interactions without relying on predefined physics, enhancing its ability to generalize beyond previously observed scenarios. This results in improved performance in real-world tasks, such as cloth folding, with a significant increase in accuracy and stability during long-horizon manipulations.","title":"SoMA: Revolutionizing Soft Body Manipulation with Neural Simulation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SoMA is a novel simulator designed for manipulating soft bodies in three dimensions. It integrates deformable dynamics, environmental forces, and robot actions into a single neural framework, allowing for more accurate and stable simulations. By using learned Gaussian splats, SoMA can model complex interactions without relying on predefined physics, enhancing its ability to generalize beyond previously observed scenarios. This results in improved performance in real-world tasks, such as cloth folding, with a significant increase in accuracy and stability during long-horizon manipulations.', title='SoMA: Revolutionizing Soft Body Manipulation with Neural Simulation'))
[05.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SoMA是一种3D高斯点模拟器，旨在实现软体物体的稳定和长时间操控。它将可变形动力学、环境力和机器人动作结合在一个统一的潜在神经空间中。与传统模拟器不同，SoMA不依赖于预定义的物理模型，而是通过学习的高斯点来建模交互，从而提高了重模拟的准确性和泛化能力。该方法在真实世界的机器人操控中提高了20%的准确性，使得复杂任务如长时间的布料折叠变得可行。","title":"SoMA：稳定的软体操控新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SoMA是一种3D高斯点模拟器，旨在实现软体物体的稳定和长时间操控。它将可变形动力学、环境力和机器人动作结合在一个统一的潜在神经空间中。与传统模拟器不同，SoMA不依赖于预定义的物理模型，而是通过学习的高斯点来建模交互，从而提高了重模拟的准确性和泛化能力。该方法在真实世界的机器人操控中提高了20%的准确性，使得复杂任务如长时间的布料折叠变得可行。', title='SoMA：稳定的软体操控新方法'))
[05.02.2026 04:11] Querying the API.
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact.  					AI-generated summary 				 Despite rapid progress in autoregressive video diffusion, an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained KV cache budgets restrict the effective working memory, directly degrading long horizon consistency in identity, layout, and motion. To address this challenge, we present Quant VideoGen (QVG), a training free KV cache quantization framework for autoregressive video diffusion models. QVG leverages video spatiotemporal redundancy through Semantic Aware Smoothing, producing low magnitude, quantization friendly residuals. It further introduces Progressive Residual Quantization, a coarse to fine multi stage scheme that reduces quantization error while enabling a smooth quality memory trade off. Across LongCat Video, HY WorldPlay, and Self Forcing benchmarks, QVG establishes a new Pareto frontier between quality and memory efficiency, reducing KV cache memory by up to 7.0 times with less than 4% end to end latency overhead while consistently outperforming existing baselines in generation quality.
[05.02.2026 04:11] Response: ```json
{
  "desc": "В работе предложен метод Quant VideoGen для сокращения использования памяти KV кеша в авторегрессивных моделях видео-диффузии. Авторы применяют семантически-осознанное сглаживание и прогрессивную остаточную квантизацию, которые эффективно используют пространственно-временную избыточность видеоданных. Метод позволяет сократить объем KV кеша в 7 раз при минимальных накладных расходах на скорость (менее 4%), что значительно улучшает развертывание моделей на доступном оборудовании. Подход показывает устойчивое преобладание над существующими решениями по качеству генерации видео при сохранении долгосрочной согласованности в идентичности, композиции и движении.",
  "emoji": "🎬",
  "title": "Эффективная квантизация памяти для авторегрессивной генерации видео"
}
```
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact.  					AI-generated summary 				 Despite rapid progress in autoregressive video diffusion, an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained KV cache budgets restrict the effective working memory, directly degrading long horizon consistency in identity, layout, and motion. To address this challenge, we present Quant VideoGen (QVG), a training free KV cache quantization framework for autoregressive video diffusion models. QVG leverages video spatiotemporal redundancy through Semantic Aware Smoothing, producing low magnitude, quantization friendly residuals. It further introduces Progressive Residual Quantization, a coarse to fine multi stage scheme that reduces quantization error while enabling a smooth quality memory trade off. Across LongCat Video, HY WorldPlay, and Self Forcing benchmarks, QVG establishes a new Pareto frontier between quality and memory efficiency, reducing KV cache memory by up to 7.0 times with less than 4% end to end latency overhead while consistently outperforming existing baselines in generation quality."

[05.02.2026 04:11] Response: ```python
['VIDEO', 'INFERENCE']
```
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact.  					AI-generated summary 				 Despite rapid progress in autoregressive video diffusion, an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained KV cache budgets restrict the effective working memory, directly degrading long horizon consistency in identity, layout, and motion. To address this challenge, we present Quant VideoGen (QVG), a training free KV cache quantization framework for autoregressive video diffusion models. QVG leverages video spatiotemporal redundancy through Semantic Aware Smoothing, producing low magnitude, quantization friendly residuals. It further introduces Progressive Residual Quantization, a coarse to fine multi stage scheme that reduces quantization error while enabling a smooth quality memory trade off. Across LongCat Video, HY WorldPlay, and Self Forcing benchmarks, QVG establishes a new Pareto frontier between quality and memory efficiency, reducing KV cache memory by up to 7.0 times with less than 4% end to end latency overhead while consistently outperforming existing baselines in generation quality."

[05.02.2026 04:11] Response: ```python
['OPTIMIZATION', 'LONG_CONTEXT']
```
[05.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Quant VideoGen (QVG) is a novel framework designed to overcome the limitations of KV cache memory in autoregressive video diffusion models. It introduces Semantic Aware Smoothing to effectively manage video spatiotemporal redundancy, resulting in lower magnitude residuals that are easier to quantize. Additionally, QVG employs Progressive Residual Quantization, which systematically reduces quantization errors while balancing memory usage and video quality. This approach significantly decreases KV cache memory requirements by up to 7 times with minimal impact on latency, while enhancing the overall quality of video generation compared to existing methods.","title":"Revolutionizing Video Generation with Efficient Memory Management"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Quant VideoGen (QVG) is a novel framework designed to overcome the limitations of KV cache memory in autoregressive video diffusion models. It introduces Semantic Aware Smoothing to effectively manage video spatiotemporal redundancy, resulting in lower magnitude residuals that are easier to quantize. Additionally, QVG employs Progressive Residual Quantization, which systematically reduces quantization errors while balancing memory usage and video quality. This approach significantly decreases KV cache memory requirements by up to 7 times with minimal impact on latency, while enhancing the overall quality of video generation compared to existing methods.', title='Revolutionizing Video Generation with Efficient Memory Management'))
[05.02.2026 04:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Quant VideoGen（QVG）是一种针对自回归视频扩散模型的KV缓存量化框架，旨在解决KV缓存内存限制的问题。通过语义感知平滑技术，QVG能够有效利用视频的时空冗余，生成低幅度、适合量化的残差。它还引入了渐进式残差量化方案，减少量化误差，同时实现质量与内存的平衡。实验结果表明，QVG在多个基准测试中显著降低了KV缓存内存，且生成质量优于现有方法。","title":"量化视频生成：内存与质量的完美平衡"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Quant VideoGen（QVG）是一种针对自回归视频扩散模型的KV缓存量化框架，旨在解决KV缓存内存限制的问题。通过语义感知平滑技术，QVG能够有效利用视频的时空冗余，生成低幅度、适合量化的残差。它还引入了渐进式残差量化方案，减少量化误差，同时实现质量与内存的平衡。实验结果表明，QVG在多个基准测试中显著降低了KV缓存内存，且生成质量优于现有方法。', title='量化视频生成：内存与质量的完美平衡'))
[05.02.2026 04:11] Querying the API.
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments.  					AI-generated summary 				 Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments.
[05.02.2026 04:11] Response: ```json
{
  "desc": "EgoActor — это унифицированная модель видения и языка, которая преобразует высокоуровневые инструкции в точные действия гуманоидного робота. Модель интегрирует восприятие и исполнение, работая как в симулированных, так и в реальных окружениях, используя только RGB-видео с эгоцентрической точки зрения. Система предсказывает различные примитивы действий: локомоцию, движения головы, манипуляции и взаимодействие с человеком, принимая решения в контексте частичной информации и динамически меняющейся среды. Модель демонстрирует высокую способность к обобщению на новые задачи и неизвестные окружения, работая эффективно с 4B и 8B параметрами.",
  "emoji": "🤖",
  "title": "От инструкций к действиям: язык робота прямо из видения"
}
```
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments.  					AI-generated summary 				 Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments."

[05.02.2026 04:11] Response: ```python
['ROBOTICS', 'MULTIMODAL', 'CV', 'TRAINING']
```
[05.02.2026 04:11] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments.  					AI-generated summary 				 Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments."

[05.02.2026 04:11] Response: ```python
['TRANSFER_LEARNING']
```

The paper demonstrates transfer learning by leveraging supervision from multiple sources (real-world demonstrations, spatial reasoning QA, and simulated environment demonstrations) to train a unified vision-language model that generalizes across diverse tasks and unseen environments. This represents knowledge transfer across different data modalities and domains (simulation to real-world).
[05.02.2026 04:11] Error. Failed to parse JSON from LLM. ["TRANSFER_LEARNING"]


The paper demonstrates transfer learning by leveraging supervision from multiple sources (real-world demonstrations, spatial reasoning QA, and simulated environment demonstrations) to train a unified vision-language model that generalizes across diverse tasks and unseen environments. This represents knowledge transfer across different data modalities and domains (simulation to real-world).
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"EgoActor is a vision-language model designed to convert high-level instructions into specific actions for humanoid robots. It addresses the challenges of integrating perception, movement, and manipulation in dynamic environments with limited information. The model can predict various actions, such as walking and turning, while coordinating real-time perception and execution. Extensive testing shows that EgoActor can effectively link abstract planning with practical execution across different tasks and environments.","title":"EgoActor: Bridging Instructions to Humanoid Actions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='EgoActor is a vision-language model designed to convert high-level instructions into specific actions for humanoid robots. It addresses the challenges of integrating perception, movement, and manipulation in dynamic environments with limited information. The model can predict various actions, such as walking and turning, while coordinating real-time perception and execution. Extensive testing shows that EgoActor can effectively link abstract planning with practical execution across different tasks and environments.', title='EgoActor: Bridging Instructions to Humanoid Actions'))
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"EgoActor 是一个统一的视觉-语言模型，能够将高层指令转化为精确的人形机器人动作。它通过集成感知和执行，解决了在动态环境中进行运动和操作的挑战。该模型能够预测各种运动原语和人机交互，实时协调感知与执行。通过对真实世界数据的广泛监督，EgoActor 能够在不同任务和未知环境中进行有效的决策和流畅的动作推理。","title":"EgoActor：将高层指令转化为人形机器人动作的统一模型"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='EgoActor 是一个统一的视觉-语言模型，能够将高层指令转化为精确的人形机器人动作。它通过集成感知和执行，解决了在动态环境中进行运动和操作的挑战。该模型能够预测各种运动原语和人机交互，实时协调感知与执行。通过对真实世界数据的广泛监督，EgoActor 能够在不同任务和未知环境中进行有效的决策和流畅的动作推理。', title='EgoActor：将高层指令转化为人形机器人动作的统一模型'))
[05.02.2026 04:12] Querying the API.
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements.  					AI-generated summary 				 Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search, semantic search, and chunk read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag.
[05.02.2026 04:12] Response: ```json
{
  "desc": "В статье представлена A-RAG — фреймворк для извлечения и генерации с дополнением, который позволяет языковым моделям самостоятельно принимать решения о поиске информации на разных уровнях детализации. В отличие от традиционных подходов, которые либо извлекают документы одноразово, либо используют предопределённый алгоритм, A-RAG предоставляет модели три инструмента: поиск по ключевым словам, семантический поиск и чтение отдельных фрагментов. Эта архитектура позволяет агенту адаптивно искать информацию в зависимости от задачи и эффективнее масштабироваться с улучшением возможностей модели. Экспериментальные результаты на множестве бенчмарков показывают, что A-RAG превосходит существующие методы при сравнимом или даже меньшем количестве обработанных токенов.",
  "emoji": "🔍",
  "title": "Умный агент управляет поиском информации для больших языковых моделей"
}
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements.  					AI-generated summary 				 Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search, semantic search, and chunk read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag."

[05.02.2026 04:12] Response: ```python
['AGENTS', 'RAG', 'BENCHMARK']
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements.  					AI-generated summary 				 Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search, semantic search, and chunk read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag."

[05.02.2026 04:12] Response: ```python
['REASONING', 'OPEN_SOURCE']
```
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces the Agentic RAG (A-RAG) framework, which allows language models to make dynamic retrieval decisions at different levels of detail. Unlike traditional retrieval-augmented generation (RAG) systems that use fixed algorithms or predefined workflows, A-RAG empowers models to adaptively utilize retrieval tools such as keyword search, semantic search, and chunk reading. This flexibility enables the model to efficiently scale its performance as it improves, leading to better results in open-domain question answering tasks. Experiments show that A-RAG outperforms existing methods while using fewer tokens, highlighting its effectiveness in leveraging advanced model capabilities.","title":"Empowering Models with Dynamic Retrieval Decisions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces the Agentic RAG (A-RAG) framework, which allows language models to make dynamic retrieval decisions at different levels of detail. Unlike traditional retrieval-augmented generation (RAG) systems that use fixed algorithms or predefined workflows, A-RAG empowers models to adaptively utilize retrieval tools such as keyword search, semantic search, and chunk reading. This flexibility enables the model to efficiently scale its performance as it improves, leading to better results in open-domain question answering tasks. Experiments show that A-RAG outperforms existing methods while using fewer tokens, highlighting its effectiveness in leveraging advanced model capabilities.', title='Empowering Models with Dynamic Retrieval Decisions'))
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种名为A-RAG的代理检索增强生成框架，旨在使模型能够动态适应多层次的检索决策。传统的RAG系统无法充分利用前沿语言模型的推理和工具使用能力，通常依赖于单一检索或预定义工作流。A-RAG通过提供关键字搜索、语义搜索和块读取等三种检索工具，使模型能够在多个粒度上自适应地搜索和检索信息。实验结果表明，A-RAG在多个开放领域问答基准上表现优于现有方法，同时检索的令牌数量相当或更少，证明了其有效利用模型能力的潜力。","title":"动态适应的检索增强生成框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种名为A-RAG的代理检索增强生成框架，旨在使模型能够动态适应多层次的检索决策。传统的RAG系统无法充分利用前沿语言模型的推理和工具使用能力，通常依赖于单一检索或预定义工作流。A-RAG通过提供关键字搜索、语义搜索和块读取等三种检索工具，使模型能够在多个粒度上自适应地搜索和检索信息。实验结果表明，A-RAG在多个开放领域问答基准上表现优于现有方法，同时检索的令牌数量相当或更少，证明了其有效利用模型能力的潜力。', title='动态适应的检索增强生成框架'))
[05.02.2026 04:12] Querying the API.
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.  					AI-generated summary 				 Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.
[05.02.2026 04:12] Response: ```json
{
  "desc": "В работе предложена методика обучения поисковых агентов на основе LLM для ответов на технические вопросы путём поиска по научным статьям. Авторы использовали обучение с подкреплением с проверяемыми наградами (RLVR) для оптимизации стратегии поиска и рассуждений агента. Они создали корпус из 16 миллионов аннотаций биомедицинских статей и набор данных PaperSearchQA с 60 тысячами вопросов для оценки качества. Обученные агенты превзошли базовые методы поиска и продемонстрировали такие продвинутые способности, как планирование, логические рассуждения и самопроверка.",
  "emoji": "🔬",
  "title": "Агенты, которые учатся искать истину в научных статьях через обучение с подкреплением"
}
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.  					AI-generated summary 				 Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains."

[05.02.2026 04:12] Response: ```python
["AGENTS", "RL", "DATASET", "BENCHMARK", "RAG"]
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.  					AI-generated summary 				 Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains."

[05.02.2026 04:12] Response: ```python
["REASONING", "SCIENCE", "OPEN_SOURCE"]
```
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a novel approach to training search agents that utilize reinforcement learning with verifiable rewards (RLVR) to improve technical question-answering in scientific domains. By focusing on a corpus of 16 million biomedical paper abstracts, the authors create a dataset called PaperSearchQA, which includes 60,000 factoid questions relevant to the scientific literature. The trained agents demonstrate advanced reasoning capabilities, outperforming traditional retrieval methods and showcasing behaviors such as planning and self-verification. This work not only enhances the relevance of AI in scientific research but also provides scalable methods for future applications in various scientific fields.","title":"Empowering AI with Advanced Reasoning for Scientific Question-Answering"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a novel approach to training search agents that utilize reinforcement learning with verifiable rewards (RLVR) to improve technical question-answering in scientific domains. By focusing on a corpus of 16 million biomedical paper abstracts, the authors create a dataset called PaperSearchQA, which includes 60,000 factoid questions relevant to the scientific literature. The trained agents demonstrate advanced reasoning capabilities, outperforming traditional retrieval methods and showcasing behaviors such as planning and self-verification. This work not only enhances the relevance of AI in scientific research but also provides scalable methods for future applications in various scientific fields.', title='Empowering AI with Advanced Reasoning for Scientific Question-Answering'))
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种新的搜索代理，专门用于科学论文的技术问答任务。通过强化学习与可验证奖励的方法，这些代理在回答技术性问题时表现优于传统的检索方法。我们构建了一个包含1600万篇生物医学论文摘要的搜索语料库，并创建了一个名为PaperSearchQA的问答数据集，包含6万个可回答的问题。我们的研究表明，这些搜索代理能够进行规划、推理和自我验证，具有重要的应用潜力。","title":"科学论文问答的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种新的搜索代理，专门用于科学论文的技术问答任务。通过强化学习与可验证奖励的方法，这些代理在回答技术性问题时表现优于传统的检索方法。我们构建了一个包含1600万篇生物医学论文摘要的搜索语料库，并创建了一个名为PaperSearchQA的问答数据集，包含6万个可回答的问题。我们的研究表明，这些搜索代理能够进行规划、推理和自我验证，具有重要的应用潜力。', title='科学论文问答的新突破'))
[05.02.2026 04:12] Querying the API.
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency.  					AI-generated summary 				 Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.
[05.02.2026 04:12] Response: ```json
{
  "desc": "DPPO — это новый алгоритм обучения с подкреплением, который решает проблемы стандартного PPO при настройке больших языковых моделей. Вместо механизма обрезания коэффициента вероятности, авторы предлагают использовать прямое ограничение на основе расхождения между политиками, такое как дивергенция Кульбака-Лейблера. Основная идея заключается в том, что обрезание коэффициентов неправильно обрабатывает маловероятные и высоковероятные токены, приводя к нестабильности обучения. Для эффективной реализации авторы вводят приближения Binary и Top-K, которые позволяют избежать больших затрат памяти при сохранении качества оптимизации.",
  "emoji": "🎯",
  "title": "От обрезания коэффициентов к принципиальным ограничениям: стабильная настройка LLM через DPPO"
}
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency.  					AI-generated summary 				 Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning."

[05.02.2026 04:12] Response: ```python
['RLHF', 'RL', 'TRAINING']
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency.  					AI-generated summary 				 Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning."

[05.02.2026 04:12] Response: ```python
['OPTIMIZATION', 'ALIGNMENT']
```

**Justification:**

- **OPTIMIZATION**: The paper proposes DPPO, an improved training optimization method for fine-tuning LLMs. It directly addresses limitations in PPO's optimization mechanism and demonstrates improvements in "training stability and efficiency," which are core optimization concerns.

- **ALIGNMENT**: The paper discusses reinforcement learning for fine-tuning LLMs, which is a key technique used in aligning language models with human preferences and intended behavior (as evidenced by the RL-based approach to guide model behavior).
[05.02.2026 04:12] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "ALIGNMENT"]


**Justification:**

- **OPTIMIZATION**: The paper proposes DPPO, an improved training optimization method for fine-tuning LLMs. It directly addresses limitations in PPO"s optimization mechanism and demonstrates improvements in "training stability and efficiency," which are core optimization concerns.

- **ALIGNMENT**: The paper discusses reinforcement learning for fine-tuning LLMs, which is a key technique used in aligning language models with human preferences and intended behavior (as evidenced by the RL-based approach to guide model behavior).
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Divergence Proximal Policy Optimization (DPPO), a new method for fine-tuning Large Language Models (LLMs) that improves upon the traditional Proximal Policy Optimization (PPO) algorithm. The authors argue that the ratio clipping mechanism in PPO is not effective for LLMs due to their large vocabularies, leading to inefficient and unstable training. DPPO replaces this clipping with direct policy divergence constraints, which provide a more accurate measure of policy changes. The paper also presents efficient approximations to manage memory usage, demonstrating that DPPO significantly enhances training stability and efficiency in reinforcement learning applications for LLMs.","title":"DPPO: A Smarter Way to Fine-Tune Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Divergence Proximal Policy Optimization (DPPO), a new method for fine-tuning Large Language Models (LLMs) that improves upon the traditional Proximal Policy Optimization (PPO) algorithm. The authors argue that the ratio clipping mechanism in PPO is not effective for LLMs due to their large vocabularies, leading to inefficient and unstable training. DPPO replaces this clipping with direct policy divergence constraints, which provide a more accurate measure of policy changes. The paper also presents efficient approximations to manage memory usage, demonstrating that DPPO significantly enhances training stability and efficiency in reinforcement learning applications for LLMs.', title='DPPO: A Smarter Way to Fine-Tune Language Models'))
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DPPO（Divergence Proximal Policy Optimization）通过用直接的策略发散约束替代PPO中的比率裁剪，解决了PPO在大语言模型（LLM）微调中的局限性。这种方法提高了训练的稳定性和效率，特别是在处理大词汇量时。传统的PPO方法在更新低概率token时过度惩罚，而对高概率token的变化则约束不足，导致训练不稳定。DPPO通过引入高效的二进制和Top-K近似方法，能够在保持低内存占用的同时，准确捕捉策略发散。","title":"DPPO：提升大语言模型微调的稳定性与效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DPPO（Divergence Proximal Policy Optimization）通过用直接的策略发散约束替代PPO中的比率裁剪，解决了PPO在大语言模型（LLM）微调中的局限性。这种方法提高了训练的稳定性和效率，特别是在处理大词汇量时。传统的PPO方法在更新低概率token时过度惩罚，而对高概率token的变化则约束不足，导致训练不稳定。DPPO通过引入高效的二进制和Top-K近似方法，能够在保持低内存占用的同时，准确捕捉策略发散。', title='DPPO：提升大语言模型微调的稳定性与效率'))
[05.02.2026 04:12] Querying the API.
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution.  					AI-generated summary 				 For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the Vibe AIGC, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.   Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.
[05.02.2026 04:12] Response: ```json
{
  "desc": "Vibe AIGC представляет новую парадигму генеративного AI, где пользователь предоставляет высокоуровневые эстетические и функциональные предпочтения вместо детальных промптов. Система использует многоагентные рабочие процессы, управляемые центральным Meta-Planner, для преобразованияIntent-Execution Gap — разрыва между человеческим замыслом и стохастическим выходом традиционных моделей. Вместо случайного вывода из одной модели система организует логическую оркестрацию независимых агентов, создавая проверяемые и адаптивные конвейеры обработки. Этот подход превращает AI из хрупкого механизма вывода в надежного инженерного партнера для создания сложных цифровых активов.",
  "emoji": "🎭",
  "title": "От случайного вывода к логической оркестрации: многоагентная парадигма для согласования замысла и исполнения"
}
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution.  					AI-generated summary 				 For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the Vibe AIGC, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.   Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets."

[05.02.2026 04:12] Response: ```python
["AGENTS", "MULTIMODAL"]
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution.  					AI-generated summary 				 For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the Vibe AIGC, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.   Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets."

[05.02.2026 04:12] Response: ```python
["ALIGNMENT"]
```

**Reasoning:** The paper discusses bridging the "Intent-Execution Gap" between human intent and machine execution through multi-agent workflows. This directly relates to aligning AI systems with human preferences and intended behavior - a core concept in the ALIGNMENT topic. The paper emphasizes how users provide high-level aesthetic and functional preferences that are then orchestrated to match human imagination and intent, which is fundamentally about alignment between human values/preferences and AI system behavior.
[05.02.2026 04:12] Error. Failed to parse JSON from LLM. ["ALIGNMENT"]


**Reasoning:** The paper discusses bridging the "Intent-Execution Gap" between human intent and machine execution through multi-agent workflows. This directly relates to aligning AI systems with human preferences and intended behavior - a core concept in the ALIGNMENT topic. The paper emphasizes how users provide high-level aesthetic and functional preferences that are then orchestrated to match human imagination and intent, which is fundamentally about alignment between human values/preferences and AI system behavior.
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Vibe AIGC presents a new approach to generative AI that allows users to express their aesthetic and functional preferences more effectively. Instead of relying solely on traditional models, it utilizes multi-agent workflows to better align human intent with machine output. Users act as Commanders, providing a high-level \'Vibe\' that guides the content generation process. This method aims to overcome the Intent-Execution Gap by transforming AI into a reliable partner in creating complex digital assets.","title":"Bridging Human Intent and Machine Execution with Vibe AIGC"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="Vibe AIGC presents a new approach to generative AI that allows users to express their aesthetic and functional preferences more effectively. Instead of relying solely on traditional models, it utilizes multi-agent workflows to better align human intent with machine output. Users act as Commanders, providing a high-level 'Vibe' that guides the content generation process. This method aims to overcome the Intent-Execution Gap by transforming AI into a reliable partner in creating complex digital assets.", title='Bridging Human Intent and Machine Execution with Vibe AIGC'))
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Vibe AIGC提出了一种新的生成性人工智能范式，用户可以提供高层次的美学和功能偏好。这些偏好通过多代理工作流进行协调，旨在缩小人类意图与机器执行之间的差距。用户的角色从传统的提示工程师转变为指挥官，提供一个包含美学和功能逻辑的高层次表示。通过逻辑编排的转变，Vibe AIGC将人类想象与机器执行连接起来，重新定义人机协作经济。","title":"Vibe AIGC：重塑人机协作的生成性AI新范式"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Vibe AIGC提出了一种新的生成性人工智能范式，用户可以提供高层次的美学和功能偏好。这些偏好通过多代理工作流进行协调，旨在缩小人类意图与机器执行之间的差距。用户的角色从传统的提示工程师转变为指挥官，提供一个包含美学和功能逻辑的高层次表示。通过逻辑编排的转变，Vibe AIGC将人类想象与机器执行连接起来，重新定义人机协作经济。', title='Vibe AIGC：重塑人机协作的生成性AI新范式'))
[05.02.2026 04:12] Querying the API.
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, state-of-the-art block-wise dLLMs rely on a "remasking" mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), a module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses a decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation. We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that a standard dLLM can be efficiently converted to the RCD paradigm with merely ~1 billion tokens. RCD consistently improves frontier dLLMs by 5-10 points in accuracy with minimal extra computation overhead across a wide range of benchmarks. Notably, on the most challenging AIME tasks, RCD nearly doubles baseline accuracy and attains up to 4-5x fewer denoising steps at equivalent accuracy levels.
[05.02.2026 04:12] Response: ```json
{
  "desc": "В статье предложен метод Residual Context Diffusion (RCD), который улучшает диффузионные большие языковые модели путём переиспользования информации из отклоненных токенов. Авторы показали, что стандартный механизм переmasking в блочных дLLM-моделях неэффективно выбрасывает вычисления, хотя отклоненные токены содержат полезный контекст для последующих итераций декодирования. Предложенный модуль преобразует представления отклоненных токенов в контекстные остатки и вводит их обратно на этапе шумоподавления, используя двухэтапный конвейер обучения для избежания узких мест памяти. Метод достигает улучшения на 5-10 пунктов по точности с минимальными накладными расходами и особенно эффективен на сложных задачах рассуждения, удваивая базовую точность.",
  "emoji": "♻️",
  "title": "Возрождение отброшенной информации в диффузионных языковых моделях"
}
```
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, state-of-the-art block-wise dLLMs rely on a "remasking" mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), a module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses a decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation. We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that a standard dLLM can be efficiently converted to the RCD paradigm with merely ~1 billion tokens. RCD consistently improves frontier dLLMs by 5-10 points in accuracy with minimal extra computation overhead across a wide range of benchmarks. Notably, on the most challenging AIME tasks, RCD nearly doubles baseline accuracy and attains up to 4-5x fewer denoising steps at equivalent accuracy levels."

[05.02.2026 04:12] Response: ```python
["ARCHITECTURE", "TRAINING", "INFERENCE"]
```

**Justification:**

- **ARCHITECTURE**: The paper proposes Residual Context Diffusion (RCD), a novel module/architectural component that modifies how diffusion language models process tokens by injecting contextual residuals back into the denoising process.

- **TRAINING**: The paper describes a "decoupled two-stage training pipeline" specifically designed to address memory bottlenecks during backpropagation, which is a training methodology contribution.

- **INFERENCE**: The paper focuses on improving computational efficiency during decoding/inference, demonstrating fewer denoising steps needed at equivalent accuracy levels, which is an inference optimization concern.
[05.02.2026 04:12] Error. Failed to parse JSON from LLM. ["ARCHITECTURE", "TRAINING", "INFERENCE"]


**Justification:**

- **ARCHITECTURE**: The paper proposes Residual Context Diffusion (RCD), a novel module/architectural component that modifies how diffusion language models process tokens by injecting contextual residuals back into the denoising process.

- **TRAINING**: The paper describes a "decoupled two-stage training pipeline" specifically designed to address memory bottlenecks during backpropagation, which is a training methodology contribution.

- **INFERENCE**: The paper focuses on improving computational efficiency during decoding/inference, demonstrating fewer denoising steps needed at equivalent accuracy levels, which is an inference optimization concern.
[05.02.2026 04:12] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, state-of-the-art block-wise dLLMs rely on a "remasking" mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), a module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses a decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation. We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that a standard dLLM can be efficiently converted to the RCD paradigm with merely ~1 billion tokens. RCD consistently improves frontier dLLMs by 5-10 points in accuracy with minimal extra computation overhead across a wide range of benchmarks. Notably, on the most challenging AIME tasks, RCD nearly doubles baseline accuracy and attains up to 4-5x fewer denoising steps at equivalent accuracy levels."

[05.02.2026 04:12] Response: ```python
["DIFFUSION", "OPTIMIZATION", "REASONING"]
```
[05.02.2026 04:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Residual Context Diffusion (RCD) is a novel approach that enhances diffusion large language models (dLLMs) by reusing information from discarded tokens during the decoding process. Traditional dLLMs often discard less confident tokens, which leads to wasted computational resources. RCD addresses this by converting these discarded tokens into contextual residuals, which are then reintegrated into the decoding steps, improving overall model accuracy. This method not only boosts performance significantly but also maintains low computational costs, making it an efficient upgrade for existing dLLMs.","title":"Recycling Discarded Tokens for Enhanced Language Model Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Residual Context Diffusion (RCD) is a novel approach that enhances diffusion large language models (dLLMs) by reusing information from discarded tokens during the decoding process. Traditional dLLMs often discard less confident tokens, which leads to wasted computational resources. RCD addresses this by converting these discarded tokens into contextual residuals, which are then reintegrated into the decoding steps, improving overall model accuracy. This method not only boosts performance significantly but also maintains low computational costs, making it an efficient upgrade for existing dLLMs.', title='Recycling Discarded Tokens for Enhanced Language Model Performance'))
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"残差上下文扩散（RCD）通过回收被丢弃的标记信息，增强了扩散大型语言模型的性能。该方法利用上下文残差，将丢弃的标记表示转化为有用的信息，注入到后续的去噪步骤中，从而提高解码的准确性。RCD采用解耦的两阶段训练流程，避免了反向传播带来的内存瓶颈。实验表明，RCD在多个基准测试中，能够在计算开销极小的情况下，提升前沿扩散大型语言模型的准确性。","title":"提升扩散模型的残差上下文利用"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='残差上下文扩散（RCD）通过回收被丢弃的标记信息，增强了扩散大型语言模型的性能。该方法利用上下文残差，将丢弃的标记表示转化为有用的信息，注入到后续的去噪步骤中，从而提高解码的准确性。RCD采用解耦的两阶段训练流程，避免了反向传播带来的内存瓶颈。实验表明，RCD在多个基准测试中，能够在计算开销极小的情况下，提升前沿扩散大型语言模型的准确性。', title='提升扩散模型的残差上下文利用'))
[05.02.2026 04:13] Querying the API.
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy.  					AI-generated summary 				 Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.
[05.02.2026 04:13] Response: ```json
{
  "desc": "В статье предлагается Agentic Automatic Evaluation (A2Eval) — первая автоматизированная система для оценки встраиваемых видео-языковых моделей, использующая двух сотрудничающих агентов. Data Agent самостоятельно определяет ключевые способности модели и создает сбалансированный набор тестов, а Eval Agent синтезирует и валидирует их реализацию. Метод сокращает объем тестовых наборов на 85%, уменьшает вычислительные затраты на 77% и ускоряет оценку в 4.6 раза, одновременно улучшая соответствие оценок суждениям экспертов. Система исправляет систематические смещения в рангировании моделей и устанавливает новый стандарт для эффективной и высокоточной оценки встраиваемых моделей компьютерного зрения и языка.",
  "emoji": "🤖",
  "title": "Автоматическая оценка видение-языковых моделей через сотрудничающих агентов"
}
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy.  					AI-generated summary 				 Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon."

[05.02.2026 04:13] Response: ```python
["AGENTS", "BENCHMARK", "MULTIMODAL", "CV"]
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy.  					AI-generated summary 				 Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon."

[05.02.2026 04:13] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **OPTIMIZATION**: The paper focuses on reducing evaluation costs (77% computational cost reduction), compressing evaluation suites (85% compression), and achieving speedup (4.6x) while maintaining quality. These are core optimization objectives.

- **OPEN_SOURCE**: The paper explicitly states "Our code and data will be public soon," indicating a commitment to releasing resources publicly.
[05.02.2026 04:13] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **OPTIMIZATION**: The paper focuses on reducing evaluation costs (77% computational cost reduction), compressing evaluation suites (85% compression), and achieving speedup (4.6x) while maintaining quality. These are core optimization objectives.

- **OPEN_SOURCE**: The paper explicitly states "Our code and data will be public soon," indicating a commitment to releasing resources publicly.
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces the Agentic Automatic Evaluation (A2Eval) framework, which automates the assessment of embodied vision-language models (VLMs) using collaborative agents. It addresses the limitations of traditional evaluation methods that rely on static benchmarks, which are often redundant and imbalanced, leading to high costs and skewed model rankings. A2Eval features a Data Agent that creates a balanced evaluation suite and an Eval Agent that validates evaluation processes, significantly reducing evaluation suite size and computational costs. The framework demonstrates improved ranking accuracy and efficiency, setting a new standard for evaluating embodied VLMs.","title":"Revolutionizing VLM Assessment with Automated Evaluation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces the Agentic Automatic Evaluation (A2Eval) framework, which automates the assessment of embodied vision-language models (VLMs) using collaborative agents. It addresses the limitations of traditional evaluation methods that rely on static benchmarks, which are often redundant and imbalanced, leading to high costs and skewed model rankings. A2Eval features a Data Agent that creates a balanced evaluation suite and an Eval Agent that validates evaluation processes, significantly reducing evaluation suite size and computational costs. The framework demonstrates improved ranking accuracy and efficiency, setting a new standard for evaluating embodied VLMs.', title='Revolutionizing VLM Assessment with Automated Evaluation'))
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为Agentic Automatic Evaluation (A2Eval) 的自动评估框架，旨在改善现有的具身视觉-语言模型评估方法。传统评估依赖于静态的、专家定义的手动标注基准，存在冗余和覆盖不均的问题，导致高昂的成本和模型排名失真。A2Eval通过两个协作代理自动化基准创建和评估，显著降低了评估套件的规模和计算成本，同时提高了评估的准确性。经过10个基准和13个模型的评估，A2Eval实现了85%的评估套件压缩和77%的计算成本降低，确立了高保真、低成本的评估新标准。","title":"自动化评估，提升模型评估效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为Agentic Automatic Evaluation (A2Eval) 的自动评估框架，旨在改善现有的具身视觉-语言模型评估方法。传统评估依赖于静态的、专家定义的手动标注基准，存在冗余和覆盖不均的问题，导致高昂的成本和模型排名失真。A2Eval通过两个协作代理自动化基准创建和评估，显著降低了评估套件的规模和计算成本，同时提高了评估的准确性。经过10个基准和13个模型的评估，A2Eval实现了85%的评估套件压缩和77%的计算成本降低，确立了高保真、低成本的评估新标准。', title='自动化评估，提升模型评估效率'))
[05.02.2026 04:13] Querying the API.
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models.  					AI-generated summary 				 Group Relative Policy Optimization (GRPO) has recently emerged as a practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards, GRPO often stalls because rollouts within a group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt x, the model samples a compact hint h (e.g., a plan or decomposition) and then generates a solution τ conditioned on (x,h). Crucially, the task reward R(x,τ) is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards. At test time, we set h=varnothing and deploy the no-hint policy without any privileged information. Moreover, sampling diverse self-hints serves as an adaptive curriculum that tracks the learner's bottlenecks more effectively than fixed hints from an initial policy or a stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3B-Instruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE.
[05.02.2026 04:13] Response: ```json
{
  "desc": "SAGE — это фреймворк обучения с подкреплением, который расширяет алгоритм GRPO путём добавления самогенерируемых подсказок во время тренировки. Метод решает проблему разреженных наград, когда откаты внутри группы получают одинаковые награды, что приводит к нулевым градиентам обновлений. Модель генерирует компактные подсказки (например, планы или разложения решения), которые увеличивают разнообразие результатов в группе, но не влияют на исходную функцию вознаграждения. На этапе инференции подсказки отбрасываются, а адаптивный учебный процесс автоматически фокусируется на узких местах обучения модели.",
  "emoji": "🎯",
  "title": "Усиление GRPO самогенерируемыми подсказками для выравнивания больших языковых моделей"
}
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models.  					AI-generated summary 				 Group Relative Policy Optimization (GRPO) has recently emerged as a practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards, GRPO often stalls because rollouts within a group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt x, the model samples a compact hint h (e.g., a plan or decomposition) and then generates a solution τ conditioned on (x,h). Crucially, the task reward R(x,τ) is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards. At test time, we set h=varnothing and deploy the no-hint policy without any privileged information. Moreover, sampling diverse self-hints serves as an adaptive curriculum that tracks the learner's bottlenecks more effectively than fixed hints from an initial policy or a stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3B-Instruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE."

[05.02.2026 04:13] Response: ```python
["RL", "RLHF", "TRAINING"]
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models.  					AI-generated summary 				 Group Relative Policy Optimization (GRPO) has recently emerged as a practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards, GRPO often stalls because rollouts within a group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt x, the model samples a compact hint h (e.g., a plan or decomposition) and then generates a solution τ conditioned on (x,h). Crucially, the task reward R(x,τ) is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards. At test time, we set h=varnothing and deploy the no-hint policy without any privileged information. Moreover, sampling diverse self-hints serves as an adaptive curriculum that tracks the learner's bottlenecks more effectively than fixed hints from an initial policy or a stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3B-Instruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE."

[05.02.2026 04:13] Response: ```python
["ALIGNMENT", "OPTIMIZATION", "OPEN_SOURCE"]
```
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SAGE is a new reinforcement learning framework that builds on Group Relative Policy Optimization (GRPO) by introducing self-hints during training. These self-hints help to diversify the outcomes when rewards are sparse, which prevents the model from getting stuck due to identical rewards in a group. By sampling hints that guide the model\'s learning process, SAGE reshapes the rollout distribution while keeping the task reward unchanged. Experiments show that SAGE outperforms GRPO across multiple benchmarks, demonstrating its effectiveness in improving the alignment of large language models.","title":"SAGE: Enhancing Learning Diversity with Self-Hints"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="SAGE is a new reinforcement learning framework that builds on Group Relative Policy Optimization (GRPO) by introducing self-hints during training. These self-hints help to diversify the outcomes when rewards are sparse, which prevents the model from getting stuck due to identical rewards in a group. By sampling hints that guide the model's learning process, SAGE reshapes the rollout distribution while keeping the task reward unchanged. Experiments show that SAGE outperforms GRPO across multiple benchmarks, demonstrating its effectiveness in improving the alignment of large language models.", title='SAGE: Enhancing Learning Diversity with Self-Hints'))
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SAGE是一种基于策略的强化学习框架，旨在通过在训练过程中注入自我提示来增强GRPO的效果，从而提高在稀疏奖励下的结果多样性。该方法通过为每个提示生成紧凑的提示，帮助模型在相同的终端验证奖励下重塑回滚分布。SAGE的关键在于，它在测试时不使用任何提示，确保模型在没有特权信息的情况下仍能表现良好。此外，实验结果表明，SAGE在多个基准测试中均优于GRPO，显示出其在大语言模型对齐方面的有效性。","title":"自我提示提升强化学习效果"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SAGE是一种基于策略的强化学习框架，旨在通过在训练过程中注入自我提示来增强GRPO的效果，从而提高在稀疏奖励下的结果多样性。该方法通过为每个提示生成紧凑的提示，帮助模型在相同的终端验证奖励下重塑回滚分布。SAGE的关键在于，它在测试时不使用任何提示，确保模型在没有特权信息的情况下仍能表现良好。此外，实验结果表明，SAGE在多个基准测试中均优于GRPO，显示出其在大语言模型对齐方面的有效性。', title='自我提示提升强化学习效果'))
[05.02.2026 04:13] Querying the API.
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data.  					AI-generated summary 				 Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.
[05.02.2026 04:13] Response: ```json
{
  "desc": "В статье исследуется проблема эффективности обучения мультимодальных моделей вознаграждения процесса (MPRM), которые используются для пошагового контроля визуального рассуждения в больших языковых моделях. Авторы обнаружили, что данные для обучения содержат значительную избыточность и предложили теоретический фреймворк, объясняющий, что информативные градиентные обновления зависят от смеси меток и надежности аннотаций. На основе этих выводов разработан метод Balanced-Information Score (BIS), который приоритизирует примеры обучения по двум критериям без дополнительных вычислительных затрат. Экспериментальные результаты показывают, что подмножество данных, отобранное методом BIS, достигает производительности полного набора данных, используя только 10% от исходного объема обучающих данных.",
  "emoji": "⚖️",
  "title": "Умный отбор данных для эффективного обучения моделей вознаграждения"
}
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data.  					AI-generated summary 				 Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%."

[05.02.2026 04:13] Response: ```python
["MULTIMODAL", "TRAINING", "DATA", "BENCHMARK"]
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data.  					AI-generated summary 				 Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%."

[05.02.2026 04:13] Response: ```python
['OPTIMIZATION', 'SYNTHETIC']
```

**Justification:**

- **OPTIMIZATION**: The paper focuses on improving training efficiency of multimodal process reward models through data selection strategies (Balanced-Information Score), which is a training optimization method that achieves full performance with only 10% of data.

- **SYNTHETIC**: The paper deals with Monte Carlo (MC)-annotated corpora and discusses how to efficiently use this annotated training data, which relates to leveraging artificial/generated annotations for training purposes.
[05.02.2026 04:13] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "SYNTHETIC"]


**Justification:**

- **OPTIMIZATION**: The paper focuses on improving training efficiency of multimodal process reward models through data selection strategies (Balanced-Information Score), which is a training optimization method that achieves full performance with only 10% of data.

- **SYNTHETIC**: The paper deals with Monte Carlo (MC)-annotated corpora and discusses how to efficiently use this annotated training data, which relates to leveraging artificial/generated annotations for training purposes.
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a method for training Multimodal Process Reward Models (MPRMs) more efficiently by using a Balanced-Information Score (BIS). The BIS focuses on optimizing the mixture of positive and negative labels and their reliability, which helps in reducing the amount of training data needed. The authors demonstrate that their approach can achieve the same performance as using the full dataset by only utilizing 10% of the training data. This method not only saves resources but also enhances the training process by addressing redundancy in existing Monte Carlo-annotated corpora.","title":"Efficient MPRM Training: 10% Data, Full Performance!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a method for training Multimodal Process Reward Models (MPRMs) more efficiently by using a Balanced-Information Score (BIS). The BIS focuses on optimizing the mixture of positive and negative labels and their reliability, which helps in reducing the amount of training data needed. The authors demonstrate that their approach can achieve the same performance as using the full dataset by only utilizing 10% of the training data. This method not only saves resources but also enhances the training process by addressing redundancy in existing Monte Carlo-annotated corpora.', title='Efficient MPRM Training: 10% Data, Full Performance!'))
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文研究了多模态过程奖励模型（MPRM）的高效训练方法，重点在于如何通过平衡信息评分来提高数据利用率。我们发现，MPRM的训练在随机抽样时会迅速饱和，表明现有的蒙特卡洛标注数据存在冗余。为了解释这一现象，我们提出了一个理论框架，强调标签混合和标签可靠性对信息梯度更新的重要性。通过引入平衡信息评分（BIS），我们能够在不增加额外成本的情况下，优先考虑标签的混合性和可靠性，从而在仅使用10%的训练数据时实现与全数据相当的性能。","title":"高效训练多模态奖励模型的平衡信息评分"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文研究了多模态过程奖励模型（MPRM）的高效训练方法，重点在于如何通过平衡信息评分来提高数据利用率。我们发现，MPRM的训练在随机抽样时会迅速饱和，表明现有的蒙特卡洛标注数据存在冗余。为了解释这一现象，我们提出了一个理论框架，强调标签混合和标签可靠性对信息梯度更新的重要性。通过引入平衡信息评分（BIS），我们能够在不增加额外成本的情况下，优先考虑标签的混合性和可靠性，从而在仅使用10%的训练数据时实现与全数据相当的性能。', title='高效训练多模态奖励模型的平衡信息评分'))
[05.02.2026 04:13] Querying the API.
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks.  					AI-generated summary 				 Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity.
[05.02.2026 04:13] Response: ```json
{
  "desc": "BatCoder представляет собой фреймворк самообучения с применением reinforcement learning, который одновременно оптимизирует генерацию кода и документации через back-translation. Подход использует семантическое сходство между исходным и восстановленным кодом в качестве неявной награды для обучения модели. Фреймворк позволяет обучать LLM только на коде, что значительно расширяет доступные примеры для тренировки. На бенчмарках HumanEval и MBPP модель с 7B параметрами достигла 83.5% и 81.0% точности pass@1, превосходя существующие baseline решения.",
  "emoji": "🔄",
  "title": "Двусторонний перевод кода и документации для самообучения без разметки"
}
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks.  					AI-generated summary 				 Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity."

[05.02.2026 04:13] Response: ```python
['RL', 'PLP', 'TRAINING']
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks.  					AI-generated summary 				 Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity."

[05.02.2026 04:13] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE', 'LOW_RESOURCE']
```
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"BatCoder is a novel self-supervised reinforcement learning framework that enhances the generation of code and its corresponding documentation. It utilizes a back-translation method where documentation is created from code, and then this documentation is used to regenerate the original code, allowing the model to learn from the semantic similarities. This process provides an implicit reward signal for reinforcement learning, improving the model\'s ability to generate accurate code and documentation. By leveraging only code for training, BatCoder significantly increases the amount of available training data, leading to impressive performance on code-related benchmarks.","title":"Revolutionizing Code and Documentation Generation with BatCoder"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="BatCoder is a novel self-supervised reinforcement learning framework that enhances the generation of code and its corresponding documentation. It utilizes a back-translation method where documentation is created from code, and then this documentation is used to regenerate the original code, allowing the model to learn from the semantic similarities. This process provides an implicit reward signal for reinforcement learning, improving the model's ability to generate accurate code and documentation. By leveraging only code for training, BatCoder significantly increases the amount of available training data, leading to impressive performance on code-related benchmarks.", title='Revolutionizing Code and Documentation Generation with BatCoder'))
[05.02.2026 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"BatCoder是一种自监督强化学习框架，旨在通过反向翻译共同优化代码生成和文档生成。该方法首先从代码生成文档，然后利用生成的文档重构原始代码，二者之间的语义相似性作为隐式奖励，促进模型性能的提升。通过仅使用代码进行训练，BatCoder显著增加了可用的训练样本，解决了高质量代码-文档对稀缺的问题。在HumanEval和MBPP基准测试中，BatCoder的表现优于许多强大的开源基线。","title":"BatCoder：优化代码与文档生成的自监督学习框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='BatCoder是一种自监督强化学习框架，旨在通过反向翻译共同优化代码生成和文档生成。该方法首先从代码生成文档，然后利用生成的文档重构原始代码，二者之间的语义相似性作为隐式奖励，促进模型性能的提升。通过仅使用代码进行训练，BatCoder显著增加了可用的训练样本，解决了高质量代码-文档对稀缺的问题。在HumanEval和MBPP基准测试中，BatCoder的表现优于许多强大的开源基线。', title='BatCoder：优化代码与文档生成的自监督学习框架'))
[05.02.2026 04:13] Querying the API.
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Multi-Agent Discussion methods suffer from inconsistency due to individual context misalignment, which is addressed through a context learning approach that dynamically generates context instructions for each agent to improve consensus reaching and performance.  					AI-generated summary 				 Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.
[05.02.2026 04:13] Response: ```json
{
  "desc": "В статье рассматривается проблема непоследовательности в методах многоагентного обсуждения, где несколько экземпляров больших языковых моделей совместно решают задачи. Авторы предлагают метод M2CL, который обучает генератор контекста для каждого агента, способный динамически создавать инструкции контекста на каждом раунде обсуждения через автоматическую организацию и уточнение информации. Механизм самоадаптации позволяет моделям избежать преждевременной сходимости к шуму большинства и постепенно достичь правильного консенсуса. Экспериментальные результаты показывают превосходство M2CL над существующими методами на 20-50% на задачах академического рассуждения, воплощённых и управляющих задачах.",
  "emoji": "🤝",
  "title": "Синхронизация контекстов агентов для достижения консенсуса в многоагентном обсуждении"
}
```
[05.02.2026 04:13] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multi-Agent Discussion methods suffer from inconsistency due to individual context misalignment, which is addressed through a context learning approach that dynamically generates context instructions for each agent to improve consensus reaching and performance.  					AI-generated summary 				 Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency."

[05.02.2026 04:14] Response: ```python
["AGENTS", "TRAINING"]
```

**Justification:**

- **AGENTS**: The paper explicitly focuses on "Multi-Agent Discussion" methods where multiple LLM instances collaboratively solve problems. It introduces M2CL (multi-LLM context learning method) to improve agent coordination and consensus reaching.

- **TRAINING**: The paper describes training context generators with "a carefully crafted self-adaptive mechanism" to improve agent performance, which falls under training/fine-tuning methods for improving model behavior.
[05.02.2026 04:14] Error. Failed to parse JSON from LLM. ["AGENTS", "TRAINING"]


**Justification:**

- **AGENTS**: The paper explicitly focuses on "Multi-Agent Discussion" methods where multiple LLM instances collaboratively solve problems. It introduces M2CL (multi-LLM context learning method) to improve agent coordination and consensus reaching.

- **TRAINING**: The paper describes training context generators with "a carefully crafted self-adaptive mechanism" to improve agent performance, which falls under training/fine-tuning methods for improving model behavior.
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multi-Agent Discussion methods suffer from inconsistency due to individual context misalignment, which is addressed through a context learning approach that dynamically generates context instructions for each agent to improve consensus reaching and performance.  					AI-generated summary 				 Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency."

[05.02.2026 04:14] Response: ```python
['REASONING', 'ALIGNMENT']
```

**Justification:**

- **REASONING**: The paper explicitly addresses enhancing logical reasoning capabilities through multi-agent discussion methods. It mentions evaluation on "academic reasoning" tasks and focuses on improving collaborative problem-solving through structured discussion.

- **ALIGNMENT**: The paper addresses aligning multiple LLM agents toward a common goal (reaching consensus and coherent solutions). The core problem is "misalignment between their individual contexts," and the solution involves generating context instructions to align agent behavior toward correct consensus, which relates to aligning models with intended behavior.
[05.02.2026 04:14] Error. Failed to parse JSON from LLM. ["REASONING", "ALIGNMENT"]


**Justification:**

- **REASONING**: The paper explicitly addresses enhancing logical reasoning capabilities through multi-agent discussion methods. It mentions evaluation on "academic reasoning" tasks and focuses on improving collaborative problem-solving through structured discussion.

- **ALIGNMENT**: The paper addresses aligning multiple LLM agents toward a common goal (reaching consensus and coherent solutions). The core problem is "misalignment between their individual contexts," and the solution involves generating context instructions to align agent behavior toward correct consensus, which relates to aligning models with intended behavior.
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the problem of inconsistency in Multi-Agent Discussion (MAD) methods caused by misaligned individual contexts among agents. It introduces a novel approach called Multi-LLM Context Learning (M2CL), which dynamically generates context instructions for each agent during discussions. By employing a self-adaptive mechanism, M2CL enhances context coherence and reduces discrepancies, allowing agents to reach a more accurate consensus. The results demonstrate that M2CL outperforms existing methods by a significant margin, improving performance on various complex tasks.","title":"Enhancing Consensus in Multi-Agent Discussions with Dynamic Context Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the problem of inconsistency in Multi-Agent Discussion (MAD) methods caused by misaligned individual contexts among agents. It introduces a novel approach called Multi-LLM Context Learning (M2CL), which dynamically generates context instructions for each agent during discussions. By employing a self-adaptive mechanism, M2CL enhances context coherence and reduces discrepancies, allowing agents to reach a more accurate consensus. The results demonstrate that M2CL outperforms existing methods by a significant margin, improving performance on various complex tasks.', title='Enhancing Consensus in Multi-Agent Discussions with Dynamic Context Learning'))
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"多智能体讨论方法（MAD）在个体上下文不一致的情况下容易出现讨论不一致的问题。为了解决这个问题，本文提出了一种多LLM上下文学习方法（M2CL），该方法为每个智能体学习一个上下文生成器，能够在每轮讨论中动态生成上下文指令。M2CL通过自动信息组织和精炼，控制上下文的一致性和输出差异，从而帮助智能体逐步达成正确的共识。实验结果表明，M2CL在学术推理、具身任务和移动控制等挑战性任务上，性能显著优于现有方法，提升幅度达到20%至50%。","title":"动态生成上下文，提升多智能体讨论一致性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='多智能体讨论方法（MAD）在个体上下文不一致的情况下容易出现讨论不一致的问题。为了解决这个问题，本文提出了一种多LLM上下文学习方法（M2CL），该方法为每个智能体学习一个上下文生成器，能够在每轮讨论中动态生成上下文指令。M2CL通过自动信息组织和精炼，控制上下文的一致性和输出差异，从而帮助智能体逐步达成正确的共识。实验结果表明，M2CL在学术推理、具身任务和移动控制等挑战性任务上，性能显著优于现有方法，提升幅度达到20%至50%。', title='动态生成上下文，提升多智能体讨论一致性'))
[05.02.2026 04:14] Querying the API.
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization.  					AI-generated summary 				 Grounded Multimodal Named Entity Recognition (GMNER) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit modality bias, including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning (MCR), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines.
[05.02.2026 04:14] Response: ```json
{
  "desc": "В работе исследуется применение многомодальных большых языковых моделей для задачи распознавания именованных сущностей с визуальной привязкой. Авторы обнаружили, что эти модели страдают от модальностной предвзятости, то есть полагаются на одну модальность вместо проведения тщательной кросс-модальной верификации. Для решения этой проблемы предложен метод MCR, который использует инъекцию многостилевых схем рассуждений и оптимизацию, управляемую ограничениями, для принуждения модели к согласованному кросс-модальному анализу. Экспериментальные результаты показывают, что предложенный подход эффективно снижает влияние модальностной предвзятости и превосходит существующие базовые методы.",
  "emoji": "🔍",
  "title": "Преодоление модальностной предвзятости в мультимодальных МLLM через структурированные кросс-модальные рассуждения"
}
```
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization.  					AI-generated summary 				 Grounded Multimodal Named Entity Recognition (GMNER) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit modality bias, including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning (MCR), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines."

[05.02.2026 04:14] Response: ```python
["MULTIMODAL", "TRAINING", "RLHF"]
```
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization.  					AI-generated summary 				 Grounded Multimodal Named Entity Recognition (GMNER) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit modality bias, including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning (MCR), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines."

[05.02.2026 04:14] Response: ```python
['REASONING', 'INTERPRETABILITY']
```

**Justification:**

- **REASONING**: The paper explicitly focuses on enhancing cross-modal reasoning capabilities through "Modality-aware Consistency Reasoning (MCR)" and "Multi-style Reasoning Schema Injection (MRSI)" to enforce structured reasoning chains and address modality bias.

- **INTERPRETABILITY**: The paper addresses understanding and analyzing model behavior by investigating why MLLMs exhibit modality bias (visual and textual bias) and proposing methods to make the reasoning process more verifiable and transparent through "Constraint-guided Verifiable Optimization (CVO)".
[05.02.2026 04:14] Error. Failed to parse JSON from LLM. ["REASONING", "INTERPRETABILITY"]


**Justification:**

- **REASONING**: The paper explicitly focuses on enhancing cross-modal reasoning capabilities through "Modality-aware Consistency Reasoning (MCR)" and "Multi-style Reasoning Schema Injection (MRSI)" to enforce structured reasoning chains and address modality bias.

- **INTERPRETABILITY**: The paper addresses understanding and analyzing model behavior by investigating why MLLMs exhibit modality bias (visual and textual bias) and proposing methods to make the reasoning process more verifiable and transparent through "Constraint-guided Verifiable Optimization (CVO)".
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the issue of modality bias in Grounded Multimodal Named Entity Recognition (GMNER) tasks when using Multimodal Large Language Models (MLLMs). The authors propose a novel approach called Modality-aware Consistency Reasoning (MCR), which enhances cross-modal reasoning through techniques like Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI helps convert abstract constraints into actionable reasoning processes, while CVO allows the model to adjust its reasoning paths effectively. Experimental results show that MCR significantly reduces modality bias and outperforms existing methods in GMNER and visual grounding tasks.","title":"Enhancing Cross-Modal Reasoning to Combat Modality Bias in GMNER"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the issue of modality bias in Grounded Multimodal Named Entity Recognition (GMNER) tasks when using Multimodal Large Language Models (MLLMs). The authors propose a novel approach called Modality-aware Consistency Reasoning (MCR), which enhances cross-modal reasoning through techniques like Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI helps convert abstract constraints into actionable reasoning processes, while CVO allows the model to adjust its reasoning paths effectively. Experimental results show that MCR significantly reduces modality bias and outperforms existing methods in GMNER and visual grounding tasks.', title='Enhancing Cross-Modal Reasoning to Combat Modality Bias in GMNER'))
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文探讨了多模态大型语言模型（MLLMs）在基于文本的实体识别任务中的应用，特别是针对模态偏差的问题。我们提出了一种新的方法，称为模态感知一致性推理（MCR），通过多样式推理模式注入（MRSI）和约束引导的可验证优化（CVO）来增强跨模态推理能力。MRSI将抽象约束转化为可执行的推理链，而CVO则使模型能够动态调整推理路径。实验结果表明，MCR有效减轻了模态偏差，并在性能上超越了现有的基准。","title":"消除模态偏差，提升多模态实体识别性能"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文探讨了多模态大型语言模型（MLLMs）在基于文本的实体识别任务中的应用，特别是针对模态偏差的问题。我们提出了一种新的方法，称为模态感知一致性推理（MCR），通过多样式推理模式注入（MRSI）和约束引导的可验证优化（CVO）来增强跨模态推理能力。MRSI将抽象约束转化为可执行的推理链，而CVO则使模型能够动态调整推理路径。实验结果表明，MCR有效减轻了模态偏差，并在性能上超越了现有的基准。', title='消除模态偏差，提升多模态实体识别性能'))
[05.02.2026 04:14] Querying the API.
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data.  					AI-generated summary 				 Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics. We make three contributions. First, we release Ecom-niverse, a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT's architectural advances. The recipe consists of three phases: general pre-training, context extension, and annealed domain specialization. Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification, semantic similarity, and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone.
[05.02.2026 04:14] Response: ```json
{
  "desc": "RexBERT — это семейство BERT-подобных энкодеров, специально разработанных для понимания семантики электронной коммерции. Авторы создали Ecom-niverse, корпус из 350 миллиардов токенов, собранный из качественных источников розничной торговли, и разработали модульный конвейер для извлечения релевантного контента. Предобучение проводится в три этапа: общее предобучение, расширение контекста и специализированная адаптация к домену электронной коммерции. Модели RexBERT с 17M до 400M параметров превосходят крупные универсальные энкодеры на специализированных задачах, демонстрируя, что качество in-domain данных важнее, чем просто увеличение масштаба модели.",
  "emoji": "🛍️",
  "title": "Специализированные энкодеры лучше универсальных — качество данных важнее масштаба"
}
```
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data.  					AI-generated summary 				 Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics. We make three contributions. First, we release Ecom-niverse, a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT's architectural advances. The recipe consists of three phases: general pre-training, context extension, and annealed domain specialization. Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification, semantic similarity, and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone."

[05.02.2026 04:14] Response: ```python
['DATASET', 'ARCHITECTURE', 'TRAINING', 'BENCHMARK']
```

**Justification:**

- **DATASET**: The paper introduces "Ecom-niverse," a 350 billion token corpus curated from retail and shopping sources, which is a significant new dataset contribution.

- **ARCHITECTURE**: The paper builds on "ModernBERT's architectural advances" and presents BERT-style encoder architectures (RexBERT family), contributing to neural architecture design.

- **TRAINING**: The paper presents a "reproducible pretraining recipe" with three phases (general pre-training, context extension, and annealed domain specialization), directly addressing training methodologies.

- **BENCHMARK**: The paper evaluates models on domain-specific benchmarks and e-commerce datasets for token classification, semantic similarity, and natural language understanding tasks.
[05.02.2026 04:14] Error. Failed to parse JSON from LLM. ["DATASET", "ARCHITECTURE", "TRAINING", "BENCHMARK"]


**Justification:**

- **DATASET**: The paper introduces "Ecom-niverse," a 350 billion token corpus curated from retail and shopping sources, which is a significant new dataset contribution.

- **ARCHITECTURE**: The paper builds on "ModernBERT"s architectural advances" and presents BERT-style encoder architectures (RexBERT family), contributing to neural architecture design.

- **TRAINING**: The paper presents a "reproducible pretraining recipe" with three phases (general pre-training, context extension, and annealed domain specialization), directly addressing training methodologies.

- **BENCHMARK**: The paper evaluates models on domain-specific benchmarks and e-commerce datasets for token classification, semantic similarity, and natural language understanding tasks.
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data.  					AI-generated summary 				 Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics. We make three contributions. First, we release Ecom-niverse, a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT's architectural advances. The recipe consists of three phases: general pre-training, context extension, and annealed domain specialization. Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification, semantic similarity, and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone."

[05.02.2026 04:14] Response: ```python
['OPEN_SOURCE', 'TRANSFER_LEARNING', 'LONG_CONTEXT', 'OPTIMIZATION']
```

**Justification:**

- **OPEN_SOURCE**: The paper releases Ecom-niverse, a 350 billion token corpus, and RexBERT models to the public, contributing to open-source resources.

- **TRANSFER_LEARNING**: The paper demonstrates knowledge transfer through domain-specific pretraining on e-commerce data, showing how specialized training improves performance on domain-specific tasks compared to general-purpose models.

- **LONG_CONTEXT**: The paper explicitly mentions "context extension" as one of the three training phases and compares performance against "modern long-context models."

- **OPTIMIZATION**: The paper presents a "reproducible pretraining recipe" with three phases (general pre-training, context extension, and annealed domain specialization), which represents advances in training optimization methods.
[05.02.2026 04:14] Error. Failed to parse JSON from LLM. ["OPEN_SOURCE", "TRANSFER_LEARNING", "LONG_CONTEXT", "OPTIMIZATION"]


**Justification:**

- **OPEN_SOURCE**: The paper releases Ecom-niverse, a 350 billion token corpus, and RexBERT models to the public, contributing to open-source resources.

- **TRANSFER_LEARNING**: The paper demonstrates knowledge transfer through domain-specific pretraining on e-commerce data, showing how specialized training improves performance on domain-specific tasks compared to general-purpose models.

- **LONG_CONTEXT**: The paper explicitly mentions "context extension" as one of the three training phases and compares performance against "modern long-context models."

- **OPTIMIZATION**: The paper presents a "reproducible pretraining recipe" with three phases (general pre-training, context extension, and annealed domain specialization), which represents advances in training optimization methods.
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RexBERT is a new family of BERT-style encoders tailored for e-commerce tasks, achieving better results through specialized pretraining and high-quality data. It utilizes a massive dataset called Ecom-niverse, which consists of 350 billion tokens from various retail sources, ensuring comprehensive coverage of e-commerce semantics. The training process involves a three-phase approach that enhances the model\'s ability to understand context and specialize in domain-specific tasks. Remarkably, RexBERT models, despite having fewer parameters than traditional encoders, outperform them in tasks like token classification and semantic similarity, proving that targeted training is more effective than simply increasing model size.","title":"RexBERT: Tailored Transformers for E-Commerce Excellence"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="RexBERT is a new family of BERT-style encoders tailored for e-commerce tasks, achieving better results through specialized pretraining and high-quality data. It utilizes a massive dataset called Ecom-niverse, which consists of 350 billion tokens from various retail sources, ensuring comprehensive coverage of e-commerce semantics. The training process involves a three-phase approach that enhances the model's ability to understand context and specialize in domain-specific tasks. Remarkably, RexBERT models, despite having fewer parameters than traditional encoders, outperform them in tasks like token classification and semantic similarity, proving that targeted training is more effective than simply increasing model size.", title='RexBERT: Tailored Transformers for E-Commerce Excellence'))
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RexBERT是一种专为电子商务语义设计的BERT风格编码器家族，通过专门的预训练和高质量的领域内数据，在特定任务上表现优异。我们发布了Ecom-niverse，这是一个包含3500亿个标记的语料库，专门从各种零售和购物来源中整理而成。RexBERT的预训练过程包括一般预训练、上下文扩展和逐步领域专业化三个阶段。尽管参数数量比一般编码器少2-3倍，RexBERT在电子商务数据集上的表现超越了更大的通用编码器，证明了高质量领域数据与合理训练方法的结合在电子商务应用中更具优势。","title":"RexBERT：电子商务语义的强大编码器"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RexBERT是一种专为电子商务语义设计的BERT风格编码器家族，通过专门的预训练和高质量的领域内数据，在特定任务上表现优异。我们发布了Ecom-niverse，这是一个包含3500亿个标记的语料库，专门从各种零售和购物来源中整理而成。RexBERT的预训练过程包括一般预训练、上下文扩展和逐步领域专业化三个阶段。尽管参数数量比一般编码器少2-3倍，RexBERT在电子商务数据集上的表现超越了更大的通用编码器，证明了高质量领域数据与合理训练方法的结合在电子商务应用中更具优势。', title='RexBERT：电子商务语义的强大编码器'))
[05.02.2026 04:14] Querying the API.
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods.  					AI-generated summary 				 Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.
[05.02.2026 04:14] Response: ```json
{
  "desc": "Статья представляет Agent-Omit, фреймворк обучения для агентов на основе LLM, который позволяет им адаптивно пропускать лишние размышления и наблюдения во время многоходовых взаимодействий. Авторы проводят количественный анализ влияния мыслей и наблюдений на эффективность и производительность агента, выявляя, что их значимость варьируется в зависимости от этапа взаимодействия. Предложенный подход использует синтез холодного старта с данными омиссии и обучение с подкреплением с двойным механизмом выборки для развития способности агента к адаптивному пропуску избыточной информации. Экспериментальные результаты демонстрируют, что Agent-Omit-8B достигает сопоставимой производительности с передовыми LLM-агентами при лучшем соотношении эффективности и вычислительной экономичности.",
  "emoji": "✂️",
  "title": "Умное пропускание: обучение агентов опускать лишние мысли для эффективности"
}
```
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods.  					AI-generated summary 				 Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit."

[05.02.2026 04:14] Response: ```python
["AGENTS", "TRAINING", "RL", "BENCHMARK", "DATASET"]
```
[05.02.2026 04:14] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods.  					AI-generated summary 				 Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit."

[05.02.2026 04:14] Response: ```python
['OPTIMIZATION', 'SYNTHETIC', 'OPEN_SOURCE']
```

**Justification:**

1. **OPTIMIZATION**: The paper focuses on improving agent efficiency and effectiveness trade-offs through adaptive omission of redundant thoughts and observations during training and inference.

2. **SYNTHETIC**: The paper explicitly mentions synthesizing "a small amount of cold-start data, including both single-turn and multi-turn omission scenarios" for fine-tuning the agent.

3. **OPEN_SOURCE**: The paper states "Our code and data are available at https://github.com/usail-hkust/Agent-Omit," indicating the authors are releasing their framework, code, and datasets publicly.
[05.02.2026 04:14] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "SYNTHETIC", "OPEN_SOURCE"]


**Justification:**

1. **OPTIMIZATION**: The paper focuses on improving agent efficiency and effectiveness trade-offs through adaptive omission of redundant thoughts and observations during training and inference.

2. **SYNTHETIC**: The paper explicitly mentions synthesizing "a small amount of cold-start data, including both single-turn and multi-turn omission scenarios" for fine-tuning the agent.

3. **OPEN_SOURCE**: The paper states "Our code and data are available at https://github.com/usail-hkust/Agent-Omit," indicating the authors are releasing their framework, code, and datasets publicly.
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Agent-Omit is a novel training framework designed for large language model (LLM) agents to improve their efficiency during multi-turn interactions by selectively omitting unnecessary thoughts and observations. The framework addresses the issue that previous methods treated all interaction data equally, failing to recognize that the importance of thoughts and observations can vary from one turn to another. By conducting quantitative analyses, the authors demonstrate how these factors influence both the effectiveness and efficiency of agents. The proposed method includes a unique reinforcement learning approach that encourages agents to adaptively omit redundant information, leading to better performance compared to existing LLM agent strategies.","title":"Optimize Agent Interactions with Adaptive Omission"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Agent-Omit is a novel training framework designed for large language model (LLM) agents to improve their efficiency during multi-turn interactions by selectively omitting unnecessary thoughts and observations. The framework addresses the issue that previous methods treated all interaction data equally, failing to recognize that the importance of thoughts and observations can vary from one turn to another. By conducting quantitative analyses, the authors demonstrate how these factors influence both the effectiveness and efficiency of agents. The proposed method includes a unique reinforcement learning approach that encourages agents to adaptively omit redundant information, leading to better performance compared to existing LLM agent strategies.', title='Optimize Agent Interactions with Adaptive Omission'))
[05.02.2026 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Agent-Omit是一种训练框架，旨在使大型语言模型（LLM）代理在多轮交互中自适应地省略冗余的思维和观察，从而在效果和效率之间实现更好的平衡。现有研究未能考虑不同轮次中思维的必要性和观察的实用性，因此Agent-Omit通过定量研究这些因素对代理效果和效率的影响，提出了一种统一的训练框架。该框架通过合成少量冷启动数据来微调代理的省略行为，并引入了一种省略感知的强化学习方法，以激励代理的自适应省略能力。实验结果表明，Agent-Omit在多个基准测试中表现出色，达到了与前沿LLM代理相当的性能，并在效率方面优于其他方法。","title":"Agent-Omit：提升多轮交互效率的智能省略框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Agent-Omit是一种训练框架，旨在使大型语言模型（LLM）代理在多轮交互中自适应地省略冗余的思维和观察，从而在效果和效率之间实现更好的平衡。现有研究未能考虑不同轮次中思维的必要性和观察的实用性，因此Agent-Omit通过定量研究这些因素对代理效果和效率的影响，提出了一种统一的训练框架。该框架通过合成少量冷启动数据来微调代理的省略行为，并引入了一种省略感知的强化学习方法，以激励代理的自适应省略能力。实验结果表明，Agent-Omit在多个基准测试中表现出色，达到了与前沿LLM代理相当的性能，并在效率方面优于其他方法。', title='Agent-Omit：提升多轮交互效率的智能省略框架'))
[05.02.2026 04:14] Renaming data file.
[05.02.2026 04:14] Renaming previous data. hf_papers.json to ./d/2026-02-05.json
[05.02.2026 04:14] Saving new data file.
[05.02.2026 04:14] Generating page.
[05.02.2026 04:14] Renaming previous page.
[05.02.2026 04:14] Renaming previous data. index.html to ./d/2026-02-05.html
[05.02.2026 04:14] Writing result.
[05.02.2026 04:14] Renaming log file.
[05.02.2026 04:14] Renaming previous data. log.txt to ./logs/2026-02-05_last_log.txt
