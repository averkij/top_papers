[30.10.2025 16:16] Read previous papers.
[30.10.2025 16:16] Generating top page (month).
[30.10.2025 16:16] Writing top page (month).
[30.10.2025 17:11] Read previous papers.
[30.10.2025 17:11] Get feed.
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23538
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23473
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25741
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24592
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25065
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25772
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25726
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25590
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24821
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21890
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22304
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18455
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25760
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25682
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24824
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19195
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25771
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24654
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25092
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24803
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22543
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18672
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25409
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24718
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24211
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.25758
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24035
[30.10.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24801
[30.10.2025 17:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[30.10.2025 17:11] No deleted papers detected.
[30.10.2025 17:11] Downloading and parsing papers (pdf, html). Total: 28.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.23538.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.23538.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.23538.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.23473.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.23473.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.23473.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25741.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25741.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25741.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24592.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24592.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24592.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25065.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25065.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25065.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25772.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25772.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25772.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25726.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25726.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25726.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25590.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25590.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25590.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24821.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24821.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24821.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.21890.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.21890.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.21890.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.22304.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.22304.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.22304.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.18455.
[30.10.2025 17:11] Downloading paper 2510.18455 from http://arxiv.org/pdf/2510.18455v1...
[30.10.2025 17:11] Failed to download and parse paper https://huggingface.co/papers/2510.18455: 'LTChar' object is not iterable
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25760.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25760.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25760.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25682.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25682.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25682.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24824.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24824.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24824.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.19195.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.19195.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.19195.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25771.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25771.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25771.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24654.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24654.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24654.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25092.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25092.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25092.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24803.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24803.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24803.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.22543.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.22543.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.22543.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.18672.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.18672.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.18672.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25409.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25409.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25409.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24718.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24718.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24718.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24211.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24211.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24211.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.25758.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.25758.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.25758.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24035.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24035.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24035.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2510.24801.
[30.10.2025 17:11] Extra JSON file exists (./assets/json/2510.24801.json), skip PDF parsing.
[30.10.2025 17:11] Paper image links file exists (./assets/img_data/2510.24801.json), skip HTML parsing.
[30.10.2025 17:11] Success.
[30.10.2025 17:11] Enriching papers with extra data.
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 0. A unified multimodal code corpus and model, JanusCoder, generate code from text and visual inputs, outperforming commercial models in various coding tasks.  					AI-generated summary 				 The scope of neural code intelligence is rapidly expanding beyond text-based source code to encompass the rich v...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 1. Video-Thinker, a multimodal large language model, autonomously reasons with videos using intrinsic grounding and captioning capabilities, achieving state-of-the-art performance on various video reasoning benchmarks.  					AI-generated summary 				 Recent advances in image reasoning methods, particul...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 2. Modern LLMs are trained to "think" primarily via explicit text generation, such as chain-of-thought (CoT), which defers reasoning to post-training and under-leverages pre-training data. We present and open-source Ouro, named after the recursive Ouroboros, a family of pre-trained Looped Language Mode...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 3. ReForm, a reflective autoformalization method, improves the semantic accuracy of formal statements generated from natural language mathematics through iterative refinement and semantic consistency evaluation.  					AI-generated summary 				 Autoformalization, which translates natural language mathem...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 4. Reinforcement learning (RL)-based post-training has been crucial for enabling multi-step reasoning in large reasoning models (LRMs), yet current reward schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware Group Relative Policy Optimization (GRPO) that augments standard answer...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 5. Visual effects (VFX) are crucial to the expressive power of digital media, yet their creation remains a major challenge for generative AI. Prevailing methods often rely on the one-LoRA-per-effect paradigm, which is resource-intensive and fundamentally incapable of generalizing to unseen effects, thu...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 6. Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existi...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 7. Recently, instruction-based image editing (IIE) has received widespread attention. In practice, IIE often modifies only specific regions of an image, while the remaining areas largely remain unchanged. Although these two types of regions differ significantly in generation difficulty and computationa...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 8. We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a sparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion total parameters, of which only 6.1 billion are active per token. This architecture enables highly efficient scaling (dramatically improving computat...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 9. Diffusion models are explored through variational, score-based, and flow-based perspectives, focusing on their mathematical foundations and applications in controllable generation and efficient sampling.  					AI-generated summary 				 This monograph presents the core principles that have guided the...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 10. Biomolecular interactions underpin almost all biological processes, and their rational design is central to programming new biological functions. Generative AI models have emerged as powerful tools for molecular design, yet most remain specialized for individual molecular types and lack fine-grained...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 11. ChronoPlay is a framework for generating dynamic RAG benchmarks in gaming, addressing the challenges of game content updates and player focus shifts with a dual-dynamic update mechanism and dual-source synthesis engine.  					AI-generated summary 				 Retrieval Augmented Generation (RAG) systems are...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 12. Humans possess spatial reasoning abilities that enable them to understand spaces through multimodal observations, such as vision and sound. Large multimodal reasoning models extend these abilities by learning to perceive and reason, showing promising performance across diverse spatial tasks. However...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 13. Unified vision-language models (UVLMs) must perform both understanding and generation within a single architecture, but these tasks rely on heterogeneous data and supervision, making it difficult to balance them during reinforcement learning (RL). We propose PairUni, a unified framework that reorgan...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 14. Large Language Models (LLMs) are powerful but often too slow and costly for real-world use during inference. Looped transformers save on parameters by reusing the same weights for multiple computational steps, or "loops." However, this approach has a major flaw: the loops run one after another, caus...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 15. Dream4Drive is a synthetic data generation framework that enhances downstream perception tasks in autonomous driving by decomposing videos into 3D-aware guidance maps and rendering 3D assets, leading to improved performance across various training epochs.  					AI-generated summary 				 Recent advan...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 16. We release Gaperon, a fully open suite of French-English-coding language models designed to advance transparency and reproducibility in large-scale model training. The Gaperon family includes 1.5B, 8B, and 24B parameter models trained on 2-4 trillion tokens, released with all elements of the trainin...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 17. In this paper, we present a framework for training large language models (LLMs) as diagnostic agents with reinforcement learning, enabling them to manage multi-turn diagnostic processes, adaptively select examinations, and commit to final diagnoses. Unlike instruction-tuned models trained on static ...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 18. Recent advances in text-only large language models (LLMs), such as DeepSeek-R1, demonstrate remarkable reasoning ability. However, these models remain fragile or entirely incapable when extended to multi-modal tasks. Existing approaches largely rely on single-form captions, which lack diversity and ...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 19. Practical deployment of Multi-Agent Systems (MAS) demands strong test-time performance, motivating methods that guide inference-time search and selectively spend compute to improve quality. We present the Multi-Agent System Process Reward Model (MASPRM). It assigns per-action, per-agent values to pa...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 20. Flawed-Aware Policy Optimization (FAPO) improves reinforcement learning with verifiable rewards by penalizing flawed-positive rollouts, enhancing reasoning capability and training stability without increasing computational cost.  					AI-generated summary 				 Reinforcement learning with verifiable ...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 21. The reasoning large language model (RLLM) has been proven competitive in solving complex reasoning tasks such as mathematics, coding, compared to general LLM. However, the serving performance and behavior of RLLM remains unexplored, which may undermine the deployment and utilization of RLLM in real-...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 22. The rapid advancement of large language models(LLMs) has intensified the need for domain and culture specific evaluation. Existing benchmarks are largely Anglocentric and domain-agnostic, limiting their applicability to India-centric contexts. To address this gap, we introduce BhashaBench V1, the fi...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 23. Generative View Stitching (GVS) enables stable, collision-free, and temporally consistent camera-guided video generation by sampling sequences in parallel and conditioning on both past and future frames.  					AI-generated summary 				 Autoregressive video diffusion models are capable of long rollou...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 24. A new parallel decoding framework, MC-SJD, accelerates autoregressive visual generation by improving token stability and acceptance rate, achieving significant speedups without quality loss.  					AI-generated summary 				 While autoregressive (AR) modeling has recently emerged as a new paradigm in ...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 25. Large language models (LLMs) in psychological counseling have attracted increasing attention. However, existing approaches often lack emotional understanding, adaptive strategies, and the use of therapeutic methods across multiple sessions with long-term memory, leaving them far from real clinical p...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 26. We introduce GraphNet, a dataset of 2.7K real-world deep learning computational graphs with rich metadata, spanning six major task categories across multiple deep learning frameworks. To evaluate tensor compiler performance on these samples, we propose the benchmark metric Speedup Score S(t), which ...
[30.10.2025 17:11] ********************************************************************************
[30.10.2025 17:11] Abstract 27. As centralized AI hits compute ceilings and diminishing returns from ever-larger training runs, meeting demand requires an inference layer that scales horizontally in both capacity and capability. We present Fortytwo, a novel protocol that leverages swarm intelligence principles and distributed pair...
[30.10.2025 17:11] Read previous papers.
[30.10.2025 17:11] Generating reviews via LLM API.
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization", "#dataset", "#multimodal", "#data", "#games", "#open_source"], "emoji": "🎨", "ru": {"title": "JanusCoder: единая модель для генерации кода из текста и изображений", "desc": "Исследователи представили JanusCoder — унифицированную мультимо
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#multimodal", "#training", "#games", "#dataset", "#reasoning", "#video"], "emoji": "🎬", "ru": {"title": "Научить LLM думать над видео через автономное рассуждение", "desc": "Video-Thinker — это multimodal LLM, который умеет рассуждать над видео, используя встроенные возможности grou
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#architecture", "#training", "#open_source", "#benchmark", "#dataset", "#reasoning"], "emoji": "🔁", "ru": {"title": "Рассуждения внутри модели: обучение LLM думать в латентном пространстве", "desc": "В статье представлена архитектура Ouro - семейство Looped Language Models (LoopLM),
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#training", "#benchmark", "#math", "#dataset", "#reasoning", "#optimization", "#data"], "emoji": "🔄", "ru": {"title": "Рефлексивная автоформализация математики с самопроверкой", "desc": "Статья представляет ReForm — метод автоформализации, который переводит математические задачи на 
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#rlhf", "#optimization", "#rl", "#benchmark", "#reasoning"], "emoji": "🔍", "ru": {"title": "Награда за процесс мышления: обучение LLM рассуждать правильно, а не только давать правильные ответы", "desc": "Статья представляет PM4GRPO - улучшенный метод обучения с подкреплением для бол
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#training", "#open_source", "#games", "#dataset", "#video"], "emoji": "✨", "ru": {"title": "Единая модель для копирования визуальных эффектов из примера", "desc": "Исследователи представили VFXMaster — первую универсальную систему для генерации видео с визуальными эффектами на основ
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#agents", "#optimization", "#benchmark", "#agi"], "emoji": "🏅", "ru": {"title": "Десятиборье для AI-агентов: новый стандарт проверки на реальных задачах", "desc": "Исследователи представили Toolathlon — новый бенчмарк для оценки языковых агентов, способных выполнять сложные многошаг
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#optimization"], "emoji": "🎯", "ru": {"title": "Умное разделение регионов для быстрого редактирования изображений", "desc": "Статья предлагает RegionE — фреймворк для ускорения редактирования изображений по текстовым инструкциям без дополнительного обучения. Кл
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#architecture", "#audio", "#agi"], "emoji": "🎭", "ru": {"title": "Единая мультимодальная модель с разреженной MoE-архитектурой для речи, текста и изображений", "desc": "В статье представлена Ming-Flash-Omni — улучшенная мультимодальная модель на базе архитектур
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#math", "#cv", "#diffusion"], "emoji": "🌊", "ru": {"title": "Три лица диффузии: единая математическая основа генеративных моделей", "desc": "Монография исследует диффузионные модели через три взаимодополняющих подхода: вариационный (пошаговое удаление шума), score-based (обучение гр
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#multimodal", "#healthcare", "#dataset"], "emoji": "🧬", "ru": {"title": "Универсальный генеративный AI для дизайна межмолекулярных взаимодействий", "desc": "ODesign — это генеративная модель на основе AI, которая проектирует взаимодействия между всеми типами биомолекул на атомном ур
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#rag", "#benchmark", "#optimization", "#games"], "emoji": "🎮", "ru": {"title": "Динамический бенчмарк для RAG-систем в мире игр", "desc": "ChronoPlay — это фреймворк для автоматической генерации динамических бенчмарков RAG-систем в игровой индустрии. Ключевая проблема заключается в 
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#survey", "#agents", "#benchmark", "#reasoning", "#multimodal", "#audio", "#3d"], "emoji": "🧭", "ru": {"title": "Пространственное мышление для AI: обзор мультимодальных моделей", "desc": "Статья представляет систематический обзор способностей больших мультимодальных моделей к простр
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#training", "#rl", "#dataset", "#rlhf", "#optimization", "#multimodal"], "emoji": "🔗", "ru": {"title": "Парное обучение для баланса понимания и генерации в vision-language моделях", "desc": "Статья представляет PairUni — фреймворк для обучения унифицированных vision-language моделей
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#inference"], "emoji": "🔄", "ru": {"title": "Параллельные петли для быстрых LLM без потери качества", "desc": "Large Language Models часто слишком медленные и дорогие для практического применения. Looped трансформеры экономят параметры, переиспользу
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#multimodal", "#training", "#3d", "#dataset", "#agents", "#synthetic"], "emoji": "🚗", "ru": {"title": "Генерация синтетических данных для обучения систем автопилота через 3D-рендеринг", "desc": "Dream4Drive - это фреймворк для генерации синтетических данных, который улучшает задачи 
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#security", "#dataset", "#data", "#benchmark", "#open_source", "#leakage", "#multilingual", "#training"], "emoji": "🔓", "ru": {"title": "Полностью открытая модель для изучения фильтрации данных и контаминации", "desc": "Исследователи представили Gaperon — семейство полностью открыты
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#rl", "#science", "#healthcare", "#benchmark"], "emoji": "🩺", "ru": {"title": "Обучение AI-диагноста через взаимодействие с виртуальной клиникой", "desc": "Исследователи разработали DiagAgent — LLM, обученную ставить диагнозы через reinforcement learning в в
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#agents", "#reasoning", "#small_models", "#multimodal", "#games", "#inference"], "emoji": "👁️", "ru": {"title": "Разделяй восприятие и рассуждение: агентный подход к мультимодальному пониманию", "desc": "Статья представляет Seeing Eye - модульный фреймворк, который позволяет текстов
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#math", "#agents", "#transfer_learning", "#reasoning", "#optimization", "#inference"], "emoji": "🤝", "ru": {"title": "Умное управление мультиагентными системами через оценку прогресса каждого агента", "desc": "Статья представляет MASPRM — модель наград для мультиагентных систем, кот
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#rlhf", "#training"], "emoji": "🎯", "ru": {"title": "Умное наказание за правильные ответы с неправильной логикой", "desc": "Статья представляет метод FAPO для улучшения обучения с подкреплением в больших языковых моделях. Проблема в том, что LLM
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#training", "#reasoning", "#inference", "#optimization"], "emoji": "🤔", "ru": {"title": "Особенности серверного обслуживания reasoning LLM моделей", "desc": "Исследователи провели комплексное изучение производительности reasoning LLM (RLLM) - моделей, специализирующихся на решении с
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#multilingual", "#low_resource", "#open_source", "#benchmark", "#dataset", "#science"], "emoji": "🇮🇳", "ru": {"title": "BhashaBench V1: Оценка LLM в индийском контексте", "desc": "В статье обсуждается создание BhashaBench V1, первого доменно-специфического, многоцелевого, двуязычног
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#video"], "emoji": "🎥", "ru": {"title": "Стабильная генерация видео без столкновений", "desc": "В статье представлена новая методика Generative View Stitching (GVS) для генерации видео с использованием камеры, которая обеспечивает стабильность и отсутств
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#inference", "#video", "#optimization", "#training", "#cv"], "emoji": "⚡", "ru": {"title": "Ускорение авторегрессивной генерации в 13 раз одной строкой кода", "desc": "Исследователи представили MC-SJD — новый метод ускорения авторегрессивной генерации изображений и видео без потери 
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#long_context", "#alignment", "#agents", "#healthcare"], "emoji": "🧠", "ru": {"title": "TheraMind: новый подход в психологическом консультировании с использованием LLM", "desc": "В статье рассматривается использование LLM в психологическом консультир
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#graphs", "#cv", "#benchmark"], "emoji": "📊", "ru": {"title": "GraphNet: бенчмарк для оценки tensor compilers на реальных вычислительных графах", "desc": "Исследователи представили GraphNet — датасет из 2700 реальных вычислительных графов для deep learni
[30.10.2025 17:11] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#inference", "#optimization", "#security"], "emoji": "🐝", "ru": {"title": "Коллективный разум AI-моделей через распределённый консенсус", "desc": "Статья представляет Fortytwo — протокол для децентрализованного AI-инференса, основанный на принципах роевого и
[30.10.2025 17:11] Renaming data file.
[30.10.2025 17:11] Renaming previous data. hf_papers.json to ./d/2025-10-30.json
[30.10.2025 17:11] Saving new data file.
[30.10.2025 17:11] Generating page.
[30.10.2025 17:11] Renaming previous page.
[30.10.2025 17:11] Renaming previous data. index.html to ./d/2025-10-30.html
[30.10.2025 17:11] Writing result.
[30.10.2025 17:11] Renaming log file.
[30.10.2025 17:11] Renaming previous data. log.txt to ./logs/2025-10-30_last_log.txt
