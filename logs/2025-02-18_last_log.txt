[18.02.2025 03:14] Read previous papers.
[18.02.2025 03:14] Generating top page (month).
[18.02.2025 03:14] Writing top page (month).
[18.02.2025 04:12] Read previous papers.
[18.02.2025 04:12] Get feed.
[18.02.2025 04:12] Extract page data from URL. URL: https://huggingface.co/papers/2502.11438
[18.02.2025 04:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.11275
[18.02.2025 04:12] Extract page data from URL. URL: https://huggingface.co/papers/2502.09061
[18.02.2025 04:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.11901
[18.02.2025 04:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.02.2025 04:12] No deleted papers detected.
[18.02.2025 04:12] Downloading and parsing papers (pdf, html). Total: 4.
[18.02.2025 04:12] Downloading and parsing paper https://huggingface.co/papers/2502.11438.
[18.02.2025 04:12] Downloading paper 2502.11438 from http://arxiv.org/pdf/2502.11438v1...
[18.02.2025 04:13] Extracting affiliations from text.
[18.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL Jimin Lee, Ingeol Baek, Byeongjeong Kim, Hwanhee Lee* Department of Artificial Intelligence, Chung-Ang University, Seoul, Korea {ljm1690, ingeolbaek, michael97k, hwanheelee}@cau.ac.kr 5 2 0 2 7 1 ] . [ 1 8 3 4 1 1 . 2 0 5 2 : r a "
[18.02.2025 04:13] Response: ```python
["Department of Artificial Intelligence, Chung-Ang University, Seoul, Korea"]
```
[18.02.2025 04:13] Deleting PDF ./assets/pdf/2502.11438.pdf.
[18.02.2025 04:13] Success.
[18.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.11275.
[18.02.2025 04:13] Extra JSON file exists (./assets/json/2502.11275.json), skip PDF parsing.
[18.02.2025 04:13] Paper image links file exists (./assets/img_data/2502.11275.json), skip HTML parsing.
[18.02.2025 04:13] Success.
[18.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.09061.
[18.02.2025 04:13] Downloading paper 2502.09061 from http://arxiv.org/pdf/2502.09061v1...
[18.02.2025 04:13] Extracting affiliations from text.
[18.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"CRANE: Reasoning with constrained LLM generation Debangshu Banerjee 1 * Tarun Suresh 1 * Shubham Ugare 1 Sasa Misailovic 1 Gagandeep Singh "
[18.02.2025 04:13] Response: ```python
[]
```
[18.02.2025 04:13] Extracting affiliations from text.
[18.02.2025 04:13] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"CRANE: Reasoning with constrained LLM generation Debangshu Banerjee 1 * Tarun Suresh 1 * Shubham Ugare 1 Sasa Misailovic 1 Gagandeep SinghCode generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcement of formal constraints often diminishes the reasoning capabilities of LLMs. In this work, we first provide theoretical explanation for why constraining LLM outputs to very restrictive grammars that only allow syntactically valid final answers reduces the reasoning capabilities of the model. Second, we demonstrate that by augmenting the output grammar with carefully designed additional rules, it is always possible to preserve the reasoning capabilities of the LLM while ensuring syntactic and semantic correctness in its outputs. Building on these theoretical insights, we propose reasoning-augmented constrained decoding algorithm, CRANE, which effectively balances the correctness of constrained generation with the flexibility of unconstrained generation. Experiments on multiple open-source LLMs and benchmarks show that CRANE significantly outperforms both state-of-the-art constrained decoding strategies and standard unconstrained decoding, showing up to 10% points accuracy improvement over baselines on challenging symbolic reasoning benchmarks GSM-symbolic and FOLIO. 5 2 0 2 3 1 ] . [ 1 1 6 0 9 0 . 2 0 5 2 : r 1. Introduction Transformer-based large language models (LLMs) are widely used in AI systems that interact with traditional software tools like Python interpreters (OpenAI, 2024; Chen et al., 2023) for code generation (Suresh et al., 2024a;b; *Equal contribution 1Department of Computer Science, University of Illinois Urbana-Champaign, USA. Correspondence to: Debangshu Banerjee <db21@illinois.edu>. Proceedings of the 42 nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025 by the author(s). 1 Jiang et al., 2024), logical solvers (Pan et al., 2023; Olausson et al., 2023), and theorem provers (Wu et al., 2022; Yang et al., 2023). These tools impose specific syntactic and semantic constraints on their inputs, requiring LLMs to produce outputs in the correct format. For instance, if an LLM provides output to specific logical solver (Han et al., 2024), the output must be parsable by that solver. Similarly, Wolfram Alpha (wolfram, 2024) translates user queries about mathematical problems into domain-specific language (DSL) to utilize symbolic solvers. However, as highlighted in recent studies (Ugare et al., 2024b; Lundberg et al., 2023; Poesia et al., 2022), pre-trained LLM outputs do not always comply with downstream tools input requirements. Constrained decoding algorithms (Ugare et al., 2024b; Poesia et al., 2022) address this issue by projecting the LLM output onto user-specified formal constraints (e.g., syntactic rules defined by context-free grammar G), thereby ensuring that the input requirements of downstream tasks are satisfied. As illustrated in Fig. 1, constrained decoding improves the syntactic correctness of LLM outputs (e.g., generating well-formed mathematical expression). However, it does not guarantee functional correctness (e.g., ensuring the expression correctly answers the users query). Recent works such as Tam et al. (2024) have empirically observed that imposing constraints on LLM outputs can, in some cases, reduce functional correctness for specific tasks. Tam et al. (2024) attributes this reduction in functional accuracy to decline in the LLMs reasoning capabilities under constrained decoding. This observation raises the following open questions: RQ1: Do LLMs truly lose reasoning capabilities under constrained decoding? RQ2: How can we leverage the benefits of constrained decoding in reducing syntax errors while preserving the unconstrained reasoning capabilities of LLMs? Key Challenges: First, we need to formally identify the root cause of the reduction in functional accuracy of endto-end systems when pre-trained LLM operates under constrained generation. Unlike the empirical observations in (Tam et al., 2024), we seek formal justification for this reduction that is not limited to specific LLMs used in experiments but extends to any LLM, including more CRANE: Reasoning with constrained LLM generation Figure 1. An example from the GSM-symbolic dataset (variables in blue) where unconstrained generation produces syntactically incorrect output, while constrained generation provides syntactically valid but incorrect answer. CRANE, however, generates correct answer. powerful ones developed in the future. Second, we must design cost-efficient decoding strategies that address the shortcomings of existing constrained decoding methods while improving functional accuracy. In this work, we do not consider task-specific fine-tuning of LLMs, as fine-tuning for each task is compute-intensive. Unlike constrained decoding, fine-tuning does not guarantee that the LLM output adheres to formal constraints. Contributions: We make the following contributions to improve the functional accuracy of the end-to-end system: We theoretically show that LLMs with constant number of layers, which are known to be capable of simulating steps of any given Turing machine with O(n) reasoning steps (Merrill & Sabharwal, 2024), can only solve problems within relatively restrictive circuit complexity class when constrained to generate outputs that always conform to restrictive grammar defining only the valid output strings. This demonstrates that, for restrictive grammar, constrained decoding reduces the problem-solving capabilities of LLMs. We theoretically show that the loss of expressivity of LLMs under constrained decoding arises because the output grammar is too restrictive to accommodate the intermediate reasoning steps required to compute the answer. We further demonstrate that augmenting the grammar with specific additional production rules enables the LLM to generate the intermediate reasoning steps while ensuring that the final output always adheres to the intended output structure. With the augmented grammar Ga, the LLM retains its expressivity under constrained decoding. We propose simple and cost-efficient decoding strategy, CRANE (Constrained Reasoning Augmented Generation). CRANE effectively alternates betwe"
[18.02.2025 04:13] Mistral response. {"id": "61512725f31f40f9b6ca52307eab6cbd", "object": "chat.completion", "created": 1739851992, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Department of Computer Science, University of Illinois Urbana-Champaign, USA\"]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1608, "total_tokens": 1634, "completion_tokens": 26}}
[18.02.2025 04:13] Response: ```python
["Department of Computer Science, University of Illinois Urbana-Champaign, USA"]
```
[18.02.2025 04:13] Deleting PDF ./assets/pdf/2502.09061.pdf.
[18.02.2025 04:13] Success.
[18.02.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2502.11901.
[18.02.2025 04:13] Extra JSON file exists (./assets/json/2502.11901.json), skip PDF parsing.
[18.02.2025 04:13] Paper image links file exists (./assets/img_data/2502.11901.json), skip HTML parsing.
[18.02.2025 04:13] Success.
[18.02.2025 04:13] Enriching papers with extra data.
[18.02.2025 04:13] ********************************************************************************
[18.02.2025 04:13] Abstract 0. Text-to-SQL aims to convert natural language questions into executable SQL queries. While previous approaches, such as skeleton-masked selection, have demonstrated strong performance by retrieving similar training examples to guide large language models (LLMs), they struggle in real-world scenarios ...
[18.02.2025 04:13] ********************************************************************************
[18.02.2025 04:13] Abstract 1. Massive high-quality data, both pre-training raw texts and post-training annotations, have been carefully prepared to incubate advanced large language models (LLMs). In contrast, for information extraction (IE), pre-training data, such as BIO-tagged sequences, are hard to scale up. We show that IE m...
[18.02.2025 04:13] ********************************************************************************
[18.02.2025 04:13] Abstract 2. Code generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is a promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcemen...
[18.02.2025 04:13] ********************************************************************************
[18.02.2025 04:13] Abstract 3. Existing LMs struggle with proof-oriented programming due to data scarcity, which manifest in two key ways: (1) a lack of sufficient corpora for proof-oriented programming languages such as F*, and (2) the absence of large-scale, project-level proof-oriented implementations that can teach the model ...
[18.02.2025 04:13] Read previous papers.
[18.02.2025 04:13] Generating reviews via LLM API.
[18.02.2025 04:13] Querying the API.
[18.02.2025 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Text-to-SQL aims to convert natural language questions into executable SQL queries. While previous approaches, such as skeleton-masked selection, have demonstrated strong performance by retrieving similar training examples to guide large language models (LLMs), they struggle in real-world scenarios where such examples are unavailable. To overcome this limitation, we propose Self-Augmentation in-context learning with Fine-grained Example selection for Text-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by generating and filtering self-augmented examples. SAFE-SQL first prompts an LLM to generate multiple Text-to-SQL examples relevant to the test input. Then SAFE-SQL filters these examples through three relevance assessments, constructing high-quality in-context learning examples. Using self-generated examples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL frameworks, achieving higher execution accuracy. Notably, our approach provides additional performance gains in extra hard and unseen scenarios, where conventional methods often fail.
[18.02.2025 04:13] Response: {
  "desc": "SAFE-SQL - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° Ğ² SQL-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ², ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ. SAFE-SQL Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… zero-shot Ğ¸ few-shot, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ². ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²ĞµĞ½ Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¸ Ñ€Ğ°Ğ½ĞµĞµ Ğ½Ğµ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°Ğ²ÑˆĞ¸Ñ…ÑÑ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…, Ğ³Ğ´Ğµ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ½Ğµ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ.",
  "emoji": "ğŸ”",
  "title": "Ğ¡Ğ°Ğ¼Ğ¾ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜ Ğ² Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² SQL"
}
[18.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Text-to-SQL aims to convert natural language questions into executable SQL queries. While previous approaches, such as skeleton-masked selection, have demonstrated strong performance by retrieving similar training examples to guide large language models (LLMs), they struggle in real-world scenarios where such examples are unavailable. To overcome this limitation, we propose Self-Augmentation in-context learning with Fine-grained Example selection for Text-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by generating and filtering self-augmented examples. SAFE-SQL first prompts an LLM to generate multiple Text-to-SQL examples relevant to the test input. Then SAFE-SQL filters these examples through three relevance assessments, constructing high-quality in-context learning examples. Using self-generated examples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL frameworks, achieving higher execution accuracy. Notably, our approach provides additional performance gains in extra hard and unseen scenarios, where conventional methods often fail."

[18.02.2025 04:13] Response: ```python
['DATASET', 'DATA', 'TRAINING']
```
[18.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Text-to-SQL aims to convert natural language questions into executable SQL queries. While previous approaches, such as skeleton-masked selection, have demonstrated strong performance by retrieving similar training examples to guide large language models (LLMs), they struggle in real-world scenarios where such examples are unavailable. To overcome this limitation, we propose Self-Augmentation in-context learning with Fine-grained Example selection for Text-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by generating and filtering self-augmented examples. SAFE-SQL first prompts an LLM to generate multiple Text-to-SQL examples relevant to the test input. Then SAFE-SQL filters these examples through three relevance assessments, constructing high-quality in-context learning examples. Using self-generated examples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL frameworks, achieving higher execution accuracy. Notably, our approach provides additional performance gains in extra hard and unseen scenarios, where conventional methods often fail."

[18.02.2025 04:13] Response: ```python
['TRANSFER_LEARNING', 'OPTIMIZATION']
```
[18.02.2025 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces SAFE-SQL, a new framework for converting natural language questions into SQL queries. It addresses the limitations of previous methods that rely on existing training examples, which may not be available in real-world situations. SAFE-SQL enhances SQL generation by creating and filtering self-generated examples using a large language model (LLM). The framework demonstrates improved execution accuracy, especially in challenging and unseen scenarios, outperforming traditional zero-shot and few-shot approaches.","title":"Transforming Language to SQL with Self-Augmented Learning"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces SAFE-SQL, a new framework for converting natural language questions into SQL queries. It addresses the limitations of previous methods that rely on existing training examples, which may not be available in real-world situations. SAFE-SQL enhances SQL generation by creating and filtering self-generated examples using a large language model (LLM). The framework demonstrates improved execution accuracy, especially in challenging and unseen scenarios, outperforming traditional zero-shot and few-shot approaches.', title='Transforming Language to SQL with Self-Augmented Learning'))
[18.02.2025 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶SAFE-SQLï¼Œç”¨äºå°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„SQLæŸ¥è¯¢ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªæˆ‘å¢å¼ºçš„ä¸Šä¸‹æ–‡å­¦ä¹ å’Œç»†ç²’åº¦ç¤ºä¾‹é€‰æ‹©æ¥æé«˜SQLç”Ÿæˆçš„è´¨é‡ã€‚SAFE-SQLé¦–å…ˆç”Ÿæˆå¤šä¸ªä¸æµ‹è¯•è¾“å…¥ç›¸å…³çš„Text-to-SQLç¤ºä¾‹ï¼Œç„¶åé€šè¿‡ä¸‰ç§ç›¸å…³æ€§è¯„ä¼°å¯¹è¿™äº›ç¤ºä¾‹è¿›è¡Œè¿‡æ»¤ï¼Œä»è€Œæ„å»ºé«˜è´¨é‡çš„å­¦ä¹ ç¤ºä¾‹ã€‚ä¸ä¼ ç»Ÿçš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ–¹æ³•ç›¸æ¯”ï¼ŒSAFE-SQLåœ¨æ‰§è¡Œå‡†ç¡®æ€§ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨å›°éš¾å’Œæœªè§è¿‡çš„åœºæ™¯ä¸­è¡¨ç°æ›´ä½³ã€‚","title":"è‡ªæˆ‘å¢å¼ºï¼Œæå‡Text-to-SQLçš„å‡†ç¡®æ€§"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶SAFE-SQLï¼Œç”¨äºå°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„SQLæŸ¥è¯¢ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªæˆ‘å¢å¼ºçš„ä¸Šä¸‹æ–‡å­¦ä¹ å’Œç»†ç²’åº¦ç¤ºä¾‹é€‰æ‹©æ¥æé«˜SQLç”Ÿæˆçš„è´¨é‡ã€‚SAFE-SQLé¦–å…ˆç”Ÿæˆå¤šä¸ªä¸æµ‹è¯•è¾“å…¥ç›¸å…³çš„Text-to-SQLç¤ºä¾‹ï¼Œç„¶åé€šè¿‡ä¸‰ç§ç›¸å…³æ€§è¯„ä¼°å¯¹è¿™äº›ç¤ºä¾‹è¿›è¡Œè¿‡æ»¤ï¼Œä»è€Œæ„å»ºé«˜è´¨é‡çš„å­¦ä¹ ç¤ºä¾‹ã€‚ä¸ä¼ ç»Ÿçš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ–¹æ³•ç›¸æ¯”ï¼ŒSAFE-SQLåœ¨æ‰§è¡Œå‡†ç¡®æ€§ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨å›°éš¾å’Œæœªè§è¿‡çš„åœºæ™¯ä¸­è¡¨ç°æ›´ä½³ã€‚', title='è‡ªæˆ‘å¢å¼ºï¼Œæå‡Text-to-SQLçš„å‡†ç¡®æ€§'))
[18.02.2025 04:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#dataset", "#data", "#transfer_learning"], "emoji": "ğŸ£", "ru": {"title": "Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¿Ğ»ĞµÑ‡Ğ°Ñ… Ğ³Ğ¸Ğ³Ğ°Ğ½Ñ‚Ğ¾Ğ²: ĞºĞ°Ğº IE Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµÑÑƒÑ€ÑÑ‹ LLM", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ (IE) Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½
[18.02.2025 04:13] Querying the API.
[18.02.2025 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Code generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is a promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcement of formal constraints often diminishes the reasoning capabilities of LLMs. In this work, we first provide a theoretical explanation for why constraining LLM outputs to very restrictive grammars that only allow syntactically valid final answers reduces the reasoning capabilities of the model. Second, we demonstrate that by augmenting the output grammar with carefully designed additional rules, it is always possible to preserve the reasoning capabilities of the LLM while ensuring syntactic and semantic correctness in its outputs. Building on these theoretical insights, we propose a reasoning-augmented constrained decoding algorithm, CRANE, which effectively balances the correctness of constrained generation with the flexibility of unconstrained generation. Experiments on multiple open-source LLMs and benchmarks show that CRANE significantly outperforms both state-of-the-art constrained decoding strategies and standard unconstrained decoding, showing up to 10% points accuracy improvement over baselines on challenging symbolic reasoning benchmarks GSM-symbolic and FOLIO.
[18.02.2025 04:13] Response: {
  "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ñ… Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ (LLM) Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ, Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… LLM Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑĞ½Ğ¸Ğ¶Ğ°Ñ‚ÑŒ Ğ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ½Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ CRANE, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€ÑƒĞµÑ‚ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚ÑŒÑ Ğ½ĞµĞ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ CRANE Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ Ğ½ĞµĞ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ.",
  "emoji": "ğŸ§ ",
  "title": "Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…"
}
[18.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Code generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is a promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcement of formal constraints often diminishes the reasoning capabilities of LLMs. In this work, we first provide a theoretical explanation for why constraining LLM outputs to very restrictive grammars that only allow syntactically valid final answers reduces the reasoning capabilities of the model. Second, we demonstrate that by augmenting the output grammar with carefully designed additional rules, it is always possible to preserve the reasoning capabilities of the LLM while ensuring syntactic and semantic correctness in its outputs. Building on these theoretical insights, we propose a reasoning-augmented constrained decoding algorithm, CRANE, which effectively balances the correctness of constrained generation with the flexibility of unconstrained generation. Experiments on multiple open-source LLMs and benchmarks show that CRANE significantly outperforms both state-of-the-art constrained decoding strategies and standard unconstrained decoding, showing up to 10% points accuracy improvement over baselines on challenging symbolic reasoning benchmarks GSM-symbolic and FOLIO."

[18.02.2025 04:13] Response: ```python
['DATASET', 'BENCHMARK', 'ARCHITECTURE', 'TRAINING']
```
[18.02.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Code generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is a promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcement of formal constraints often diminishes the reasoning capabilities of LLMs. In this work, we first provide a theoretical explanation for why constraining LLM outputs to very restrictive grammars that only allow syntactically valid final answers reduces the reasoning capabilities of the model. Second, we demonstrate that by augmenting the output grammar with carefully designed additional rules, it is always possible to preserve the reasoning capabilities of the LLM while ensuring syntactic and semantic correctness in its outputs. Building on these theoretical insights, we propose a reasoning-augmented constrained decoding algorithm, CRANE, which effectively balances the correctness of constrained generation with the flexibility of unconstrained generation. Experiments on multiple open-source LLMs and benchmarks show that CRANE significantly outperforms both state-of-the-art constrained decoding strategies and standard unconstrained decoding, showing up to 10% points accuracy improvement over baselines on challenging symbolic reasoning benchmarks GSM-symbolic and FOLIO."

[18.02.2025 04:13] Response: ```python
['REASONING', 'OPTIMIZATION']
```
[18.02.2025 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the challenges of generating outputs from large language models (LLMs) that are both correct in form and meaning, especially in tasks like code generation and symbolic reasoning. It explains that overly strict constraints on the grammar can hinder the model\'s reasoning abilities. The authors propose a new approach called CRANE, which enhances the output grammar with additional rules to maintain reasoning capabilities while ensuring syntactic and semantic correctness. Their experiments show that CRANE outperforms existing methods, achieving significant accuracy improvements on difficult reasoning tasks.","title":"Balancing Correctness and Reasoning in LLM Outputs with CRANE"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper discusses the challenges of generating outputs from large language models (LLMs) that are both correct in form and meaning, especially in tasks like code generation and symbolic reasoning. It explains that overly strict constraints on the grammar can hinder the model's reasoning abilities. The authors propose a new approach called CRANE, which enhances the output grammar with additional rules to maintain reasoning capabilities while ensuring syntactic and semantic correctness. Their experiments show that CRANE outperforms existing methods, achieving significant accuracy improvements on difficult reasoning tasks.", title='Balancing Correctness and Reasoning in LLM Outputs with CRANE'))
[18.02.2025 04:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åœ¨ç”Ÿæˆä»£ç å’Œç¬¦å·æ•°å­¦æ¨ç†ç­‰ä»»åŠ¡ä¸­ï¼Œç¡®ä¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºçš„è¯­æ³•å’Œè¯­ä¹‰æ­£ç¡®æ€§ã€‚æˆ‘ä»¬å‘ç°ï¼Œè¿‡äºä¸¥æ ¼çš„è¯­æ³•çº¦æŸä¼šé™ä½æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è§£ç ç®—æ³•CRANEï¼Œé€šè¿‡å¢åŠ ç²¾å¿ƒè®¾è®¡çš„é¢å¤–è§„åˆ™ï¼Œæ—¢èƒ½ä¿æŒè¾“å‡ºçš„æ­£ç¡®æ€§ï¼Œåˆèƒ½å¢å¼ºæ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCRANEåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„è§£ç ç­–ç•¥ï¼Œæå‡äº†ç¬¦å·æ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚","title":"å¹³è¡¡æ¨ç†èƒ½åŠ›ä¸ç”Ÿæˆæ­£ç¡®æ€§çš„åˆ›æ–°è§£ç ç®—æ³•"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åœ¨ç”Ÿæˆä»£ç å’Œç¬¦å·æ•°å­¦æ¨ç†ç­‰ä»»åŠ¡ä¸­ï¼Œç¡®ä¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºçš„è¯­æ³•å’Œè¯­ä¹‰æ­£ç¡®æ€§ã€‚æˆ‘ä»¬å‘ç°ï¼Œè¿‡äºä¸¥æ ¼çš„è¯­æ³•çº¦æŸä¼šé™ä½æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è§£ç ç®—æ³•CRANEï¼Œé€šè¿‡å¢åŠ ç²¾å¿ƒè®¾è®¡çš„é¢å¤–è§„åˆ™ï¼Œæ—¢èƒ½ä¿æŒè¾“å‡ºçš„æ­£ç¡®æ€§ï¼Œåˆèƒ½å¢å¼ºæ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCRANEåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„è§£ç ç­–ç•¥ï¼Œæå‡äº†ç¬¦å·æ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚', title='å¹³è¡¡æ¨ç†èƒ½åŠ›ä¸ç”Ÿæˆæ­£ç¡®æ€§çš„åˆ›æ–°è§£ç ç®—æ³•'))
[18.02.2025 04:13] Using data from previous issue: {"categories": ["#reasoning", "#training", "#dataset", "#data", "#plp", "#transfer_learning", "#synthetic"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹ Ğ² Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ,
[18.02.2025 04:13] Loading Chinese text from previous data.
[18.02.2025 04:13] Renaming data file.
[18.02.2025 04:13] Renaming previous data. hf_papers.json to ./d/2025-02-18.json
[18.02.2025 04:13] Saving new data file.
[18.02.2025 04:13] Generating page.
[18.02.2025 04:13] Renaming previous page.
[18.02.2025 04:13] Renaming previous data. index.html to ./d/2025-02-18.html
[18.02.2025 04:13] [Experimental] Generating Chinese page for reading.
[18.02.2025 04:13] Chinese vocab [{'word': 'æ‰©æ•£æ¨¡å‹', 'pinyin': 'kuÃ² sÃ n mÃ³ xÃ­ng', 'trans': 'diffusion model'}, {'word': 'é¦–é€‰', 'pinyin': 'shÇ’u xuÇn', 'trans': 'preferred choice'}, {'word': 'ä¾èµ–', 'pinyin': 'yÄ« lÃ i', 'trans': 'depend on'}, {'word': 'é¡ºåº', 'pinyin': 'shÃ¹n xÃ¹', 'trans': 'sequential'}, {'word': 'å‰å‘ä¼ é€’', 'pinyin': 'qiÃ¡n xiÃ ng chuÃ¡n dÃ¬', 'trans': 'forward pass'}, {'word': 'æ˜¾è‘—', 'pinyin': 'xiÇn zhÃ¹', 'trans': 'significant'}, {'word': 'é™åˆ¶', 'pinyin': 'xiÃ n zhÃ¬', 'trans': 'limit'}, {'word': 'å®æ—¶æ€§èƒ½', 'pinyin': 'shÃ­ shÃ­ xÃ¬ng nÃ©ng', 'trans': 'real-time performance'}, {'word': 'åŠ é€Ÿ', 'pinyin': 'jiÄ sÃ¹', 'trans': 'accelerate'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'}, {'word': 'é›†ä¸­', 'pinyin': 'jÃ­ zhÅng', 'trans': 'focus on'}, {'word': 'å‡å°‘', 'pinyin': 'jiÇn shÇo', 'trans': 'reduce'}, {'word': 'é‡‡æ ·æ­¥éª¤', 'pinyin': 'cÇi yÃ ng bÃ¹ zhÃ²u', 'trans': 'sampling steps'}, {'word': 'é‡ç”¨', 'pinyin': 'chÃ³ng yÃ²ng', 'trans': 'reuse'}, {'word': 'ä¸­é—´ç»“æœ', 'pinyin': 'zhÅng jiÄn jiÃ© guÇ’', 'trans': 'intermediate results'}, {'word': 'åˆ©ç”¨', 'pinyin': 'lÃ¬ yÃ²ng', 'trans': 'utilize'}, {'word': 'å›¾åƒ', 'pinyin': 'tÃº xiÃ ng', 'trans': 'image'}, {'word': 'å†…éƒ¨ç©ºé—´åŒºåŸŸ', 'pinyin': 'nÃ¨i bÃ¹ kÅng jiÄn qÅ« yÃ¹', 'trans': 'internal spatial regions'}, {'word': 'å˜åŒ–', 'pinyin': 'biÃ n huÃ ', 'trans': 'change'}, {'word': 'æ‰©æ•£å˜å‹å™¨', 'pinyin': 'kuÃ² sÃ n biÃ n yÄ qÃ¬', 'trans': 'diffusion transformer'}, {'word': 'çµæ´»æ€§', 'pinyin': 'lÃ­ng huÃ³ xÃ¬ng', 'trans': 'flexibility'}, {'word': 'å¼•å…¥', 'pinyin': 'yÇn rÃ¹', 'trans': 'introduce'}, {'word': 'RAS', 'pinyin': 'RAS', 'trans': 'RAS'}, {'word': 'é‡‡æ ·ç­–ç•¥', 'pinyin': 'cÇi yÃ ng cÃ¨ lÃ¼Ã¨', 'trans': 'sampling strategy'}, {'word': 'åŠ¨æ€åˆ†é…', 'pinyin': 'dÃ²ng tÃ i fÄ“n pÃ¨i', 'trans': 'dynamic allocation'}, {'word': 'å…³æ³¨ç‚¹', 'pinyin': 'guÄn zhÃ¹ diÇn', 'trans': 'focus points'}, {'word': 'å…³é”®è§‚å¯Ÿ', 'pinyin': 'guÇn jiÃ n guÄn chÃ¡', 'trans': 'key observation'}, {'word': 'è¯­ä¹‰', 'pinyin': 'yÇ” yÃ¬', 'trans': 'semantic'}, {'word': 'æœ‰æ„ä¹‰', 'pinyin': 'yÇ’u yÃ¬ yÃ¬', 'trans': 'meaningful'}, {'word': 'è¿ç»­æ­¥éª¤', 'pinyin': 'liÃ¡n xÃ¹ bÃ¹ zhÃ²u', 'trans': 'continuous steps'}, {'word': 'è¡¨ç°', 'pinyin': 'biÇo xiÃ n', 'trans': 'performance'}, {'word': 'è¿ç»­æ€§', 'pinyin': 'liÃ¡n xÃ¹ xÃ¬ng', 'trans': 'continuity'}, {'word': 'æ´å¯Ÿ', 'pinyin': 'dÃ²ng chÃ¡', 'trans': 'insight'}, {'word': 'æ›´æ–°', 'pinyin': 'gÄ“ng xÄ«n', 'trans': 'update'}, {'word': 'ç¼“å­˜å™ªå£°', 'pinyin': 'huÇn cÃºn zÃ o shÄ“ng', 'trans': 'cached noise'}, {'word': 'ç¡®å®š', 'pinyin': 'quÃ¨ dÃ¬ng', 'trans': 'determine'}, {'word': 'æ—¶é—´ä¸€è‡´æ€§', 'pinyin': 'shÃ­ jiÄn yÄ« zhÃ¬ xÃ¬ng', 'trans': 'temporal consistency'}, {'word': 'è¯„ä¼°', 'pinyin': 'pÃ­ng gÅ«', 'trans': 'evaluate'}, {'word': 'Stable Diffusion 3', 'pinyin': 'Stable Diffusion 3', 'trans': 'Stable Diffusion 3'}, {'word': 'Lumina-Next-T2I', 'pinyin': 'Lumina-Next-T2I', 'trans': 'Lumina-Next-T2I'}, {'word': 'å®ç°', 'pinyin': 'shÃ­ xiÃ n', 'trans': 'achieve'}, {'word': 'åŠ é€Ÿ', 'pinyin': 'jiÄ sÃ¹', 'trans': 'acceleration'}, {'word': 'ç”Ÿæˆè´¨é‡', 'pinyin': 'shÄ“ng chÃ©ng zhÃ¬ liÃ ng', 'trans': 'generation quality'}, {'word': 'è½»å¾®ä¸‹é™', 'pinyin': 'qÄ«ng wÄ“i xiÃ  jiÃ ng', 'trans': 'slight decrease'}, {'word': 'ç”¨æˆ·ç ”ç©¶', 'pinyin': 'yÃ²ng hÃ¹ yÃ¡n jiÅ«', 'trans': 'user study'}, {'word': 'äººç±»è¯„ä¼°', 'pinyin': 'rÃ©n lÃ¨i pÃ­ng gÅ«', 'trans': 'human evaluation'}, {'word': 'ç›¸ä¼¼', 'pinyin': 'xiÄng sÃ¬', 'trans': 'similar'}, {'word': 'æ½œåŠ›', 'pinyin': 'qiÃ¡n lÃ¬', 'trans': 'potential'}, {'word': 'é‡è¦è¿›å±•', 'pinyin': 'zhÃ²ng yÃ o jÃ¬n zhÇn', 'trans': 'significant progress'}]
[18.02.2025 04:13] Renaming previous Chinese page.
[18.02.2025 04:13] Renaming previous data. zh.html to ./d/2025-02-17_zh_reading_task.html
[18.02.2025 04:13] Writing Chinese reading task.
[18.02.2025 04:13] Writing result.
[18.02.2025 04:13] Renaming log file.
[18.02.2025 04:13] Renaming previous data. log.txt to ./logs/2025-02-18_last_log.txt
