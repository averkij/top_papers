[21.10.2025 20:13] Read previous papers.
[21.10.2025 20:13] Generating top page (month).
[21.10.2025 20:13] Writing top page (month).
[21.10.2025 21:11] Read previous papers.
[21.10.2025 21:11] Get feed.
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17681
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16872
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17800
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17354
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17269
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15346
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17715
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16751
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16333
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17509
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16888
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17803
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17795
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17498
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15821
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16720
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15021
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17797
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17790
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17431
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16259
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16258
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14605
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17793
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16641
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16276
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15527
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16727
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16499
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16156
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15768
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16136
[21.10.2025 21:11] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06471
[21.10.2025 21:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[21.10.2025 21:11] No deleted papers detected.
[21.10.2025 21:11] Downloading and parsing papers (pdf, html). Total: 33.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17681.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17681.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17681.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16872.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16872.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16872.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17800.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17800.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17800.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17354.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17354.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17354.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17269.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17269.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17269.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.15346.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.15346.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.15346.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17715.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17715.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17715.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16751.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16751.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16751.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16333.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16333.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16333.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17509.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17509.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17509.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16888.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16888.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16888.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17803.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17803.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17803.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17795.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17795.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17795.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17498.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17498.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17498.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.15821.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.15821.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.15821.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16720.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16720.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16720.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.15021.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.15021.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.15021.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17797.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17797.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17797.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17790.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17790.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17790.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17431.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17431.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17431.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16259.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16259.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16259.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16258.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16258.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16258.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.14605.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.14605.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.14605.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.17793.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.17793.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.17793.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16641.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16641.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16641.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16276.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16276.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16276.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.15527.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.15527.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.15527.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16727.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16727.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16727.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16499.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16499.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16499.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16156.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16156.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16156.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.15768.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.15768.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.15768.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.16136.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.16136.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.16136.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Downloading and parsing paper https://huggingface.co/papers/2510.06471.
[21.10.2025 21:11] Extra JSON file exists (./assets/json/2510.06471.json), skip PDF parsing.
[21.10.2025 21:11] Paper image links file exists (./assets/img_data/2510.06471.json), skip HTML parsing.
[21.10.2025 21:11] Success.
[21.10.2025 21:11] Enriching papers with extra data.
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 0. PICABench and PICAEval evaluate physical realism in image editing by assessing eight sub-dimensions and using VLM-as-a-judge with human annotations, highlighting the need for physics-based solutions.  					AI-generated summary 				 Image editing has achieved remarkable progress recently. Modern edit...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 1. DeepAnalyze-8B, an agentic LLM, autonomously completes the data science pipeline from raw data to research reports using curriculum-based training and data-grounded trajectory synthesis.  					AI-generated summary 				 Autonomous data science, from raw data sources to analyst-grade deep research rep...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 2. Glyph compresses long textual inputs into images using vision-language models, achieving significant token compression and improved performance in long-context tasks.  					AI-generated summary 				 Large language models (LLMs) increasingly rely on long-context modeling for tasks such as document un...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 3. Nyx, a unified mixed-modal retriever, enhances vision-language generation by retrieving and reasoning over mixed-modal data, outperforming existing RAG systems in real-world scenarios.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhanci...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 4. FineVision, a large-scale and curated dataset, enhances vision-language models through rigorous data collection, de-duplication, and human oversight, leading to improved performance.  					AI-generated summary 				 The advancement of vision-language models (VLMs) is hampered by a fragmented landscap...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 5. SAFE, a selective ensembling framework for large language models, improves long-form generation by considering tokenization mismatch and consensus in probability distributions, leading to better accuracy and efficiency.  					AI-generated summary 				 Ensembling Large Language Models (LLMs) has gain...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 6. QueST, a framework combining difficulty-aware graph sampling and fine-tuning, generates large-scale synthetic coding problems to enhance the performance of large language models in competitive coding and reasoning tasks.  					AI-generated summary 				 Large Language Models have achieved strong perf...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 7. Beam search in discrete visual autoregressive models enhances text-to-image generation more effectively than search in continuous diffusion models, highlighting architecture's importance over scale.  					AI-generated summary 				 While inference-time scaling through search has revolutionized Large ...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 8. Reinforcement Learning enhances vision encoders in Multimodal Language Models, leading to better visual representations and performance compared to Supervised Fine-tuning.  					AI-generated summary 				 A dominant assumption in Multimodal Language Model (MLLM) research is that its performance is la...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 9. EliCal, a two-stage framework combining self-consistency supervision and minimal correctness annotations, achieves near-optimal honesty alignment in large language models with limited annotation effort.  					AI-generated summary 				 Honesty alignment-the ability of large language models (LLMs) to ...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 10. Edit-R1, a post-training framework using Diffusion Negative-aware Finetuning and a Multimodal Large Language Model, achieves state-of-the-art results in instruction-based image editing by addressing overfitting and lack of a universal reward model.  					AI-generated summary 				 Instruction-based i...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 11. ConsistEdit, a novel attention control method for MM-DiT, enhances image and video editing by ensuring consistency and fine-grained control across all inference steps and attention layers.  					AI-generated summary 				 Recent advances in training-free attention control methods have enabled flexibl...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 12. Executable Knowledge Graphs (xKG) enhance AI research replication by integrating technical insights and code snippets from scientific literature, improving performance in automated replication tasks.  					AI-generated summary 				 Replicating AI research is a crucial yet challenging task for large ...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 13. Deep Self-Evolving Reasoning (DSER) extends the reasoning capabilities of smaller models by iteratively improving solutions through a probabilistic Markov chain, enabling them to solve previously unsolvable problems and surpass larger models in accuracy.  					AI-generated summary 				 Long-form cha...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 14. Chronos-2, a pretrained model with a group attention mechanism, achieves state-of-the-art performance in zero-shot univariate, multivariate, and covariate-informed forecasting tasks.  					AI-generated summary 				 Pretrained time series models have enabled inference-only forecasting systems that pr...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 15. The survey outlines the shift from pipeline-based to model-native agentic AI, emphasizing the role of reinforcement learning in integrating planning, tool use, and memory within large language models across various domains.  					AI-generated summary 				 The rapid evolution of agentic AI marks a ne...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 16. ECHO is a framework that constructs benchmarks for image generation models using real-world social media data, uncovering complex tasks and improving model evaluation.  					AI-generated summary 				 Recent advances in image generation, often driven by proprietary systems like GPT-4o Image Gen, regu...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 17. Enterprise Deep Research (EDR) is a multi-agent system that automates report generation and real-time data analysis by integrating specialized agents and tools, outperforming existing agentic systems on open benchmarks.  					AI-generated summary 				 As information grows exponentially, enterprises ...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 18. UltraCUA integrates GUI actions with programmatic tools to improve computer-use agent performance and efficiency.  					AI-generated summary 				 Multimodal agents for computer use rely exclusively on primitive actions (click, type, scroll) that require accurate visual grounding and lengthy executio...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 19. Agentic reinforcement learning models trained for search tasks inherit safety mechanisms but are vulnerable to attacks that reduce their refusal and safety rates.  					AI-generated summary 				 Agentic reinforcement learning (RL) trains large language models to autonomously call tools during reason...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 20. Large reasoning models are vulnerable to reasoning distraction, where irrelevant tasks embedded in prompts reduce accuracy, and a combined SFT and RL defense improves robustness.  					AI-generated summary 				 Recent advances in large reasoning models (LRMs) have enabled remarkable performance on c...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 21. Embody 3D is a multimodal dataset featuring extensive 3D motion data with hand tracking, body shape, text annotations, and audio tracks from multiple participants in various scenarios.  					AI-generated summary 				 The Codec Avatars Lab at Meta introduces Embody 3D, a multimodal dataset of 500 ind...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 22. A novel three-stage method, Wiki-PRF, enhances knowledge-based visual question answering by improving multimodal query quality and relevance through visual language models and reinforcement learning.  					AI-generated summary 				 Knowledge-based visual question answering (KB-VQA) requires visual l...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 23. FARE, a family of large-scale parameter evaluators, surpasses specialized RL-trained evaluators in both static benchmarks and real-world tasks through data-driven development and iterative rejection-sampling supervised finetuning.  					AI-generated summary 				 Finetuning specialized generative eva...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 24. MultiVerse, a new multi-turn conversation benchmark, evaluates VLMs across diverse tasks and interaction goals, revealing challenges and the importance of in-context learning.  					AI-generated summary 				 Vision-and-Language Models (VLMs) have shown impressive capabilities on single-turn benchmar...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 25. A caching framework with speculative execution reduces web environment latency in web-interactive agentic systems without degrading performance.  					AI-generated summary 				 Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have demonstrated strong reasoning capabilities. To furthe...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 26. A novel balanced multi-task attention mechanism in custom convolutional neural networks improves satellite land use classification accuracy to 97.23% on the EuroSAT dataset without pre-trained models.  					AI-generated summary 				 This work presents a systematic investigation of custom convolution...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 27. Beacon, a benchmark, measures sycophancy in large language models, revealing it as a combination of linguistic and affective biases that can be mitigated through interventions.  					AI-generated summary 				 Large language models internalize a structural trade-off between truthfulness and obsequiou...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 28. A structured, automated framework inspired by the knapsack problem optimizes agentic system composition by considering performance, budget, and compatibility, achieving higher success rates at lower costs.  					AI-generated summary 				 Designing effective agentic systems requires the seamless comp...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 29. AsyncVoice Agent, with its asynchronous architecture, enhances human-AI collaboration by enabling real-time interaction and interruption of the model's reasoning process, significantly reducing latency while maintaining accuracy.  					AI-generated summary 				 Effective human-AI collaboration on co...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 30. Theoretical and experimental evidence suggests that evaluating AI translators for complex languages can be done solely through their outputs, using a segment-by-segment translation and shuffle test to identify hallucinations and assess quality without reference translations.  					AI-generated summa...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 31. A method using pretrained rectified flow models with periodic guidance successfully transfers appearance and geometric details to 3D assets, outperforming baselines and evaluated using a GPT-based system.  					AI-generated summary 				 Transferring appearance to 3D assets using different representa...
[21.10.2025 21:11] ********************************************************************************
[21.10.2025 21:11] Abstract 32. Test-time scaling improves translation quality in domain-specific models and post-editing but offers limited benefits for general-purpose models in direct translation.  					AI-generated summary 				 Test-time scaling (TTS) has enhanced the performance of Reasoning Models (RMs) on various tasks such...
[21.10.2025 21:11] Read previous papers.
[21.10.2025 21:11] Generating reviews via LLM API.
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#cv", "#optimization", "#dataset", "#survey", "#benchmark"], "emoji": "🔮", "ru": {"title": "Физическая реалистичность в редактировании изображений: новый бенчмарк", "desc": "Исследователи представили PICABench — новый бенчмарк для оценки физической реалистичности при редактировании 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#science", "#agi", "#training", "#agents", "#data", "#open_source"], "emoji": "🔬", "ru": {"title": "Автономный data scientist с 8 миллиардами параметров", "desc": "DeepAnalyze-8B — это первая agentic LLM, разработанная специально для автономной data science, способная самостоятельно
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#long_context", "#data", "#dataset", "#training", "#benchmark", "#optimization"], "emoji": "🖼️", "ru": {"title": "Текст как картинка: сжатие миллиона токенов через визуализацию", "desc": "Статья представляет Glyph - framework, который преобразует длинные тексто
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#rag", "#training", "#optimization", "#dataset", "#multimodal", "#reasoning", "#games", "#open_source"], "emoji": "🔍", "ru": {"title": "Универсальный поиск для мультимодальной генерации", "desc": "Статья представляет Nyx — универсальную систему для retrieval-augmented generation (RA
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#dataset", "#data", "#open_source"], "emoji": "🖼️", "ru": {"title": "FineVision: новый стандарт для моделей зрение-язык", "desc": "FineVision — это новый крупный и тщательно отобранный набор данных для улучшения моделей, объединяющих зрение и язык. Он включает 24 миллиона образцов, 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#benchmark", "#long_context", "#training"], "emoji": "🎯", "ru": {"title": "Умный ансамбль: когда много моделей лучше одной", "desc": "Исследователи представили метод SAFE для улучшения длинных текстов, генерируемых большими языковыми моделями через 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#data", "#synthetic", "#rl", "#dataset", "#training", "#reasoning"], "emoji": "🎯", "ru": {"title": "QueST: генерация сложных задач для прокачки coding-способностей LLM", "desc": "QueST - это новый фреймворк для создания синтетических задач по программированию, который использует гра
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#cv", "#optimization", "#inference", "#architecture", "#benchmark", "#games"], "emoji": "🔍", "ru": {"title": "Дискретность важнее масштаба: beam search в авторегрессионных моделях для генерации изображений", "desc": "Исследователи показали, что beam search значительно эффективнее ра
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#games", "#training", "#rl", "#optimization"], "emoji": "👁️", "ru": {"title": "Reinforcement Learning делает зрение мультимодальных моделей острее", "desc": "Исследование показывает, что стратегия обучения мультимодальных языковых моделей существенно влияет на 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#benchmark", "#training", "#alignment", "#dataset", "#open_source"], "emoji": "🎯", "ru": {"title": "Честность AI с минимальной разметкой: калибровка уверенности через самосогласованность", "desc": "Статья представляет EliCal — двухэтапный фреймворк для обучения больших языковых моде
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#training", "#multimodal", "#diffusion", "#open_source"], "emoji": "🎨", "ru": {"title": "Обучение с подкреплением для редактирования изображений по инструкциям", "desc": "Исследователи представили Edit-R1 — фреймворк для дополнительного обучения моделе
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#cv", "#training", "#optimization", "#multimodal", "#architecture"], "emoji": "🎯", "ru": {"title": "ConsistEdit: точный контроль внимания в MM-DiT для надёжного редактирования", "desc": "Исследователи представили ConsistEdit — новый метод управления механизмом внимания в архитектуре
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#multimodal", "#rag", "#science", "#open_source", "#dataset", "#graphs", "#agents"], "emoji": "🔬", "ru": {"title": "Граф знаний с исполняемым кодом для репликации AI-исследований", "desc": "Статья представляет Executable Knowledge Graphs (xKG) — модульную базу знаний для автоматизац
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#small_models", "#training", "#benchmark"], "emoji": "🔄", "ru": {"title": "Малые модели учатся решать сложные задачи через самоулучшение", "desc": "Метод Deep Self-Evolving Reasoning (DSER) позволяет небольшим языковым моделям итеративно улучшать свои 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#synthetic", "#dataset", "#training", "#optimization", "#benchmark"], "emoji": "⏰", "ru": {"title": "Универсальный прогнозировщик временных рядов с группированным вниманием", "desc": "Chronos-2 - это предобученная модель для прогнозирования временных рядов, которая работает в zero-s
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#survey", "#reasoning", "#rl", "#agents"], "emoji": "🧠", "ru": {"title": "От конвейера к интеллекту: как RL превращает LLM в самообучающихся агентов", "desc": "Статья описывает переход от конвейерных AI-систем к model-native подходу, где планирование, использование инструментов и па
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#optimization", "#survey", "#cv", "#benchmark", "#dataset"], "emoji": "📸", "ru": {"title": "Оценка AI-генерации через призму реального использования", "desc": "ECHO — это фреймворк для создания бенчмарков моделей генерации изображений на основе реальных данных из социальных сетей. И
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#dataset", "#agi", "#benchmark", "#agents", "#optimization"], "emoji": "🔍", "ru": {"title": "Мультиагентная система для автоматизации корпоративной аналитики", "desc": "Enterprise Deep Research (EDR) — это мультиагентная система для автоматической генер
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#optimization", "#synthetic", "#training", "#multimodal", "#agents", "#open_source"], "emoji": "🖱️", "ru": {"title": "Гибридные действия для AI-агентов: клики плюс программные инструменты", "desc": "Статья представляет UltraCUA — модель для управления компьютером, которая объединяет
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#alignment", "#agents", "#rl", "#security", "#rlhf"], "emoji": "🔍⚠️", "ru": {"title": "Безопасность поисковых AI-агентов под угрозой простых атак", "desc": "Исследователи изучили безопасность языковых моделей, обученных методом reinforcement learning для автономного использования ин
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#synthetic", "#reasoning", "#alignment", "#security", "#training", "#rl"], "emoji": "🎯", "ru": {"title": "Не дай себя отвлечь: защита reasoning-моделей от манипуляций в промптах", "desc": "Исследование выявляет новую уязвимость больших reasoning-моделей под названием \"reasoning dis
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#dataset", "#3d", "#multimodal"], "emoji": "🕺", "ru": {"title": "Embody 3D: огромный датасет для оживления аватаров", "desc": "Исследователи из Meta представили Embody 3D — масштабный мультимодальный датасет с 3D-данными движений человека. Набор данных содержит 500 часов записей от 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#multimodal", "#rag", "#reasoning", "#benchmark", "#rl", "#optimization"], "emoji": "🔍", "ru": {"title": "Трёхэтапный метод для визуального ответа на вопросы с использованием внешних знаний", "desc": "Статья представляет метод Wiki-PRF для knowledge-based visual question answering, 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#rl", "#dataset", "#training", "#reasoning", "#benchmark", "#data", "#open_source"], "emoji": "⚖️", "ru": {"title": "FARE: мощные оценщики через данные, а не через RL", "desc": "Исследователи представили FARE — семейство больших языковых моделей для оценки качества ответов AI-систем
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#multimodal", "#long_context", "#reasoning"], "emoji": "🗣️", "ru": {"title": "MultiVerse: когда AI-модели проваливают обычный разговор", "desc": "Исследователи представили MultiVerse — новый бенчмарк для оценки способности vision-language моделей (VLM) вест
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#reasoning", "#data", "#agents", "#optimization", "#benchmark"], "emoji": "⚡", "ru": {"title": "Ускорение веб-агентов через умное кэширование", "desc": "Исследование выявляет проблемы эффективности в агентных системах на основе LLM, которые взаимодействуют с веб-средой. Авторы обнар
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#cv", "#optimization", "#dataset", "#architecture", "#open_source"], "emoji": "🛰️", "ru": {"title": "Сбалансированное внимание к спутниковым снимкам без предобучения", "desc": "Исследователи разработали специализированную свёрточную нейронную сеть для классификации использования зем
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#ethics", "#rlhf", "#hallucinations", "#alignment", "#benchmark"], "emoji": "🎭", "ru": {"title": "Лесть vs правда: как LLM выбирают между истиной и угодливостью", "desc": "Исследователи представили Beacon — бенчмарк для измерения сикофантии (льстивости) в больших языковых моделях. О
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#optimization"], "emoji": "🎒", "ru": {"title": "Задача о рюкзаке для оптимальной сборки AI-агентов", "desc": "Исследователи предложили новый фреймворк для автоматической композиции агентных систем, вдохновленный классической задачей о рюкзаке. Вместо статиче
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#alignment", "#training", "#agents"], "emoji": "🎙️", "ru": {"title": "Прерывай и управляй: голосовой AI-агент с асинхронной архитектурой", "desc": "Статья представляет AsyncVoice Agent — систему для взаимодействия человека с AI через голос в реальном вре
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#low_resource", "#benchmark", "#hallucinations", "#data", "#machine_translation", "#multilingual"], "emoji": "🐋", "ru": {"title": "Оценка AI-переводчиков без эталонов: метод перемешивания для экзотических языков", "desc": "Статья предлагает метод оценки качества AI-переводчиков для 
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#3d", "#cv", "#diffusion", "#transfer_learning", "#games", "#benchmark"], "emoji": "🎨", "ru": {"title": "Умный перенос внешнего вида на 3D через периодическое guidance", "desc": "Статья предлагает метод переноса внешнего вида на 3D-объекты с использованием предобученных моделей rect
[21.10.2025 21:11] Using data from previous issue: {"categories": ["#multilingual", "#benchmark", "#machine_translation", "#training", "#reasoning", "#inference"], "emoji": "🔄", "ru": {"title": "Test-time scaling эффективен для машинного перевода только в узкоспециализированных задачах", "desc": "Исследование показывает, что увеличение вычислений во
[21.10.2025 21:11] Renaming data file.
[21.10.2025 21:11] Renaming previous data. hf_papers.json to ./d/2025-10-21.json
[21.10.2025 21:11] Saving new data file.
[21.10.2025 21:11] Generating page.
[21.10.2025 21:11] Renaming previous page.
[21.10.2025 21:11] Renaming previous data. index.html to ./d/2025-10-21.html
[21.10.2025 21:11] Writing result.
[21.10.2025 21:11] Renaming log file.
[21.10.2025 21:11] Renaming previous data. log.txt to ./logs/2025-10-21_last_log.txt
