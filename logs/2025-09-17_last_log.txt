[17.09.2025 03:22] Read previous papers.
[17.09.2025 03:22] Generating top page (month).
[17.09.2025 03:22] Writing top page (month).
[17.09.2025 04:13] Read previous papers.
[17.09.2025 04:13] Get feed.
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13232
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12815
[17.09.2025 04:13] Extract page data from URL. URL: https://huggingface.co/papers/2509.12603
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06079
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13317
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12341
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13312
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13311
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13309
[17.09.2025 04:13] Get page data from previous paper. URL: https://huggingface.co/papers/2509.11526
[17.09.2025 04:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.09.2025 04:13] No deleted papers detected.
[17.09.2025 04:13] Downloading and parsing papers (pdf, html). Total: 10.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.13232.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.13232.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.13232.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.12815.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.12815.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.12815.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.12603.
[17.09.2025 04:13] Downloading paper 2509.12603 from http://arxiv.org/pdf/2509.12603v1...
[17.09.2025 04:13] Extracting affiliations from text.
[17.09.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 3 0 6 2 1 . 9 0 5 2 : r ECONPROVER: Towards More Economical Test-Time Scaling for Automated Theorem Proving Mukai Li,,1,2, Linfeng Song ,1, Zhenwen Liang1, Jiahao Xu1, Shansan Gong2, Qi Liu,2, Haitao Mi1, Dong Yu 1Tencent 2The University of Hong Kong Figure 1: Performance-cost curve of open-source ATP models. The horizontal axis shows the total token-level sampling cost (in log scale), and the vertical axis shows the accuracy on miniF2F. Our ECONPROVER-GD achieves comparable performance while requiring only 12% of the sampling cost compared to the base model. "
[17.09.2025 04:13] Response: ```python
["Tencent", "The University of Hong Kong"]
```
[17.09.2025 04:13] Deleting PDF ./assets/pdf/2509.12603.pdf.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.06079.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.06079.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.06079.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.13317.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.13317.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.13317.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.12341.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.12341.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.12341.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.13312.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.13312.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.13312.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.13311.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.13311.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.13311.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.13309.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.13309.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.13309.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Downloading and parsing paper https://huggingface.co/papers/2509.11526.
[17.09.2025 04:13] Extra JSON file exists (./assets/json/2509.11526.json), skip PDF parsing.
[17.09.2025 04:13] Paper image links file exists (./assets/img_data/2509.11526.json), skip HTML parsing.
[17.09.2025 04:13] Success.
[17.09.2025 04:13] Enriching papers with extra data.
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 0. Single-stream Policy Optimization (SPO) improves policy-gradient training for Large Language Models by eliminating group-based issues and providing a stable, low-variance learning signal, leading to better performance and efficiency.  					AI-generated summary 				 We revisit policy-gradient optimiz...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 1. Hunyuan3D Studio automates 3D asset creation using AI, integrating neural modules to transform concept images or text into high-quality, game-ready 3D models with optimized geometry and PBR textures.  					AI-generated summary 				 The creation of high-quality 3D assets, a cornerstone of modern game...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 2. Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  					AI-generated summary 				 Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performanc...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 3. A caption-assisted reasoning framework bridges visual and textual modalities, achieving top performance in multimodal reasoning tasks like SeePhys and MathVerse.  					AI-generated summary 				 Multimodal reasoning remains a fundamental challenge in artificial intelligence. Despite substantial advan...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 4. A Spatial Region 3D (SR-3D) vision-language model unifies 2D and 3D representations by enriching 2D features with 3D positional embeddings, enabling flexible region prompting and accurate spatial reasoning across frames.  					AI-generated summary 				 We present Spatial Region 3D (SR-3D) aware visi...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 5. A replacement for the domain-extension step in a quantum lattice algorithm uses a pair-shift difference construction to correct periodicity issues and enforce modular linear relations efficiently.  					AI-generated summary 				 We give a simple, fully correct, and assumption-light replacement for t...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 6. WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.  					AI-generated summary 				 This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents m...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 7. A scalable framework and two-phase fine-tuning strategy enhance function-calling capabilities of agents in diverse environments, improving performance on agentic benchmarks.  					AI-generated summary 				 Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practic...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 8. WebResearcher, a deep-research framework, enhances AI agents' knowledge synthesis by reformulating research as a Markov Decision Process and using a scalable data synthesis engine, achieving superior performance across benchmarks.  					AI-generated summary 				 Recent advances in deep-research syst...
[17.09.2025 04:13] ********************************************************************************
[17.09.2025 04:13] Abstract 9. A novel MIL framework, MHIM-MIL, uses masked hard instance mining with a Siamese structure and momentum teacher to improve cancer diagnosis and subtyping accuracy.  					AI-generated summary 				 Digitizing pathological images into gigapixel Whole Slide Images (WSIs) has opened new avenues for Compu...
[17.09.2025 04:13] Read previous papers.
[17.09.2025 04:13] Generating reviews via LLM API.
[17.09.2025 04:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "🚀", "ru": {"title": "SPO: Революция в обучении языковых моделей", "desc": "Статья представляет новый метод оптимизации политики для больших языковых моделей (LLM) под названием Single-stream Policy Optimization (SPO). SPO 
[17.09.2025 04:13] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "🎮", "ru": {"title": "ИИ революционизирует создание 3D-ассетов для игр", "desc": "Hunyuan3D Studio - это платформа для автоматизированного создания 3D-ассетов с использованием искусственного интеллекта. Система интегрирует нейронные модули 
[17.09.2025 04:13] Querying the API.
[17.09.2025 04:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  					AI-generated summary 				 Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performance gains through widely adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT) reasoning and increased sampling passes. However, they both introduce significant computational overhead for inference. Moreover, existing cost analyses typically regulate only the number of sampling passes, while neglecting the substantial disparities in sampling costs introduced by different scaling strategies. In this paper, we systematically compare the efficiency of different test-time scaling strategies for ATP models and demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source approaches. We then investigate approaches to significantly reduce token usage and sample passes while maintaining the original performance. Specifically, we propose two complementary methods that can be integrated into a unified EconRL pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching mechanism designed to mitigate unnecessary token consumption, and (2) Diverse parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance pass rates under constrained sampling passes. Experiments on miniF2F and ProofNet demonstrate that our EconProver achieves comparable performance to baseline methods with only 12% of the computational cost. This work provides actionable insights for deploying lightweight ATP models without sacrificing performance.
[17.09.2025 04:13] Response: {
  "desc": "Статья представляет два метода для снижения вычислительных затрат в моделях автоматического доказательства теорем (ATP) при сохранении производительности. Первый метод - динамическое переключение цепочки рассуждений (CoT), снижающее избыточное потребление токенов. Второй метод - разнообразное параллельно-масштабируемое обучение с подкреплением (RL) с обучаемыми префиксами для повышения эффективности при ограниченном числе проходов. Эксперименты показывают, что предложенный подход EconProver достигает сравнимой производительности с базовыми методами при использовании лишь 12% вычислительных ресурсов.",
  "emoji": "🧠",
  "title": "Эффективное автоматическое доказательство теорем: меньше затрат, та же мощность"
}
[17.09.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  					AI-generated summary 				 Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performance gains through widely adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT) reasoning and increased sampling passes. However, they both introduce significant computational overhead for inference. Moreover, existing cost analyses typically regulate only the number of sampling passes, while neglecting the substantial disparities in sampling costs introduced by different scaling strategies. In this paper, we systematically compare the efficiency of different test-time scaling strategies for ATP models and demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source approaches. We then investigate approaches to significantly reduce token usage and sample passes while maintaining the original performance. Specifically, we propose two complementary methods that can be integrated into a unified EconRL pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching mechanism designed to mitigate unnecessary token consumption, and (2) Diverse parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance pass rates under constrained sampling passes. Experiments on miniF2F and ProofNet demonstrate that our EconProver achieves comparable performance to baseline methods with only 12% of the computational cost. This work provides actionable insights for deploying lightweight ATP models without sacrificing performance."

[17.09.2025 04:13] Response: ```python
['RL', 'INFERENCE', 'TRAINING']
```
[17.09.2025 04:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  					AI-generated summary 				 Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performance gains through widely adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT) reasoning and increased sampling passes. However, they both introduce significant computational overhead for inference. Moreover, existing cost analyses typically regulate only the number of sampling passes, while neglecting the substantial disparities in sampling costs introduced by different scaling strategies. In this paper, we systematically compare the efficiency of different test-time scaling strategies for ATP models and demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source approaches. We then investigate approaches to significantly reduce token usage and sample passes while maintaining the original performance. Specifically, we propose two complementary methods that can be integrated into a unified EconRL pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching mechanism designed to mitigate unnecessary token consumption, and (2) Diverse parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance pass rates under constrained sampling passes. Experiments on miniF2F and ProofNet demonstrate that our EconProver achieves comparable performance to baseline methods with only 12% of the computational cost. This work provides actionable insights for deploying lightweight ATP models without sacrificing performance."

[17.09.2025 04:13] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[17.09.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents two innovative methods aimed at reducing the computational costs associated with Automated Theorem Proving (ATP) models while preserving their performance. The first method, dynamic Chain-of-Thought (CoT) switching, optimizes token usage by selectively activating CoT reasoning only when necessary. The second method, Diverse parallel-scaled reinforcement learning (RL), employs trainable prefixes to improve sampling efficiency under limited passes. Through experiments, the proposed EconProver demonstrates that it can achieve similar performance to existing models while using only 12% of the computational resources, offering a more efficient approach to ATP.","title":"Efficient ATP: Cutting Costs Without Cutting Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents two innovative methods aimed at reducing the computational costs associated with Automated Theorem Proving (ATP) models while preserving their performance. The first method, dynamic Chain-of-Thought (CoT) switching, optimizes token usage by selectively activating CoT reasoning only when necessary. The second method, Diverse parallel-scaled reinforcement learning (RL), employs trainable prefixes to improve sampling efficiency under limited passes. Through experiments, the proposed EconProver demonstrates that it can achieve similar performance to existing models while using only 12% of the computational resources, offering a more efficient approach to ATP.', title='Efficient ATP: Cutting Costs Without Cutting Performance'))
[17.09.2025 04:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了两种方法，动态链式思维切换和多样化并行缩放强化学习，以降低自动定理证明（ATP）模型的计算成本，同时保持性能。研究表明，现有的测试时间缩放策略在推理时引入了显著的计算开销，而传统的成本分析往往只关注采样次数。通过系统比较不同的缩放策略，本文展示了当前开源方法的低效性，并提出了减少令牌使用和采样次数的有效方案。实验结果表明，所提出的EconProver在仅使用12%计算成本的情况下，性能与基线方法相当。","title":"降低计算成本，提升自动定理证明效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了两种方法，动态链式思维切换和多样化并行缩放强化学习，以降低自动定理证明（ATP）模型的计算成本，同时保持性能。研究表明，现有的测试时间缩放策略在推理时引入了显著的计算开销，而传统的成本分析往往只关注采样次数。通过系统比较不同的缩放策略，本文展示了当前开源方法的低效性，并提出了减少令牌使用和采样次数的有效方案。实验结果表明，所提出的EconProver在仅使用12%计算成本的情况下，性能与基线方法相当。', title='降低计算成本，提升自动定理证明效率'))
[17.09.2025 04:14] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "Мост между зрением и языком: новый подход к мультимодальному ИИ", "desc": "Авторы представляют фреймворк для мультимодального рассуждения, который объединяет визуальные и текстовые модальности.
[17.09.2025 04:14] Using data from previous issue: {"categories": ["#benchmark", "#games", "#3d", "#cv", "#multimodal", "#reasoning"], "emoji": "🔍", "ru": {"title": "Объединение 2D и 3D для лучшего понимания пространства", "desc": "SR-3D - это модель машинного обучения, объединяющая 2D и 3D представления визуальных данных. Она обогащает 2D признаки 
[17.09.2025 04:14] Using data from previous issue: {"categories": [], "emoji": "🔬", "ru": {"title": "Усовершенствование квантового алгоритма решетки: эффективное расширение домена", "desc": "Статья представляет улучшение для алгоритма квантовой решетки. Авторы предлагают замену для шага расширения домена, используя конструкцию разности парных сдвиго
[17.09.2025 04:14] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#hallucinations", "#long_context", "#multimodal", "#agents"], "emoji": "🕸️", "ru": {"title": "Адаптивное планирование и целенаправленный синтез для качественных исследовательских отчетов", "desc": "Статья представляет WebWeaver - двухагентную систему д
[17.09.2025 04:14] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#agi", "#training", "#agents"], "emoji": "🤖", "ru": {"title": "Масштабируемое обучение агентов для улучшения вызова функций в разнообразных средах", "desc": "Статья представляет масштабируемую систему и двухфазную стратегию дообучения для улучшения спо
[17.09.2025 04:14] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#science", "#dataset", "#training", "#agents", "#transfer_learning"], "emoji": "🕸️", "ru": {"title": "WebResearcher: новый уровень глубокого исследования для ИИ", "desc": "WebResearcher - это новая система глубокого исследования, которая улучшает спосо
[17.09.2025 04:14] Using data from previous issue: {"categories": ["#benchmark", "#science", "#optimization", "#training", "#healthcare"], "emoji": "🔬", "ru": {"title": "Новый метод машинного обучения повышает точность диагностики рака", "desc": "Статья представляет новый подход к множественному обучению с экземплярами (MIL) для улучшения диагностик
[17.09.2025 04:14] Renaming data file.
[17.09.2025 04:14] Renaming previous data. hf_papers.json to ./d/2025-09-17.json
[17.09.2025 04:14] Saving new data file.
[17.09.2025 04:14] Generating page.
[17.09.2025 04:14] Renaming previous page.
[17.09.2025 04:14] Renaming previous data. index.html to ./d/2025-09-17.html
[17.09.2025 04:14] Writing result.
[17.09.2025 04:14] Renaming log file.
[17.09.2025 04:14] Renaming previous data. log.txt to ./logs/2025-09-17_last_log.txt
