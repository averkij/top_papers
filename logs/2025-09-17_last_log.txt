[17.09.2025 04:14] Read previous papers.
[17.09.2025 04:14] Generating top page (month).
[17.09.2025 04:14] Writing top page (month).
[17.09.2025 05:11] Read previous papers.
[17.09.2025 05:11] Get feed.
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13232
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13312
[17.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.13305
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13311
[17.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.13310
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13309
[17.09.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.13313
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12815
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12603
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06079
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13317
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12341
[17.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.11526
[17.09.2025 05:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.09.2025 05:11] No deleted papers detected.
[17.09.2025 05:11] Downloading and parsing papers (pdf, html). Total: 13.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13232.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.13232.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.13232.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13312.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.13312.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.13312.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13305.
[17.09.2025 05:11] Downloading paper 2509.13305 from http://arxiv.org/pdf/2509.13305v1...
[17.09.2025 05:11] Extracting affiliations from text.
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2025-09-17 WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning Kuan Li((cid:0)), Zhongwang Zhang, Huifeng Yin((cid:0)), Rui Ye, Yida Zhao, Liwen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, Xinyu Wang, Zile Qiao, Zhen Zhang, Yong Jiang((cid:0)), Pengjun Xie, Fei Huang, Jingren Zhou Tongyi Lab , Alibaba Group https://tongyi-agent.github.io/blog https://github.com/Alibaba-NLP/DeepResearch "
[17.09.2025 05:11] Response: ```python
["Tongyi Lab, Alibaba Group"]
```
[17.09.2025 05:11] Deleting PDF ./assets/pdf/2509.13305.pdf.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13311.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.13311.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.13311.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13310.
[17.09.2025 05:11] Downloading paper 2509.13310 from http://arxiv.org/pdf/2509.13310v1...
[17.09.2025 05:11] Extracting affiliations from text.
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2025-09-17 Scaling Agents via Continual Pre-training Liangcai Su, Zhen Zhang, Guangyu Li, Zhuo Chen, Chenxi Wang, Maojia Song, Xinyu Wang((cid:0)), Kuan Li, Jialong Wu, Xuanzhong Chen, Zile Qiao, Zhongwang Zhang, Huifeng Yin, Shihao Cai, Runnan Fang, Zhengwei Tao, Wenbiao Yin, Chenxiong Qian, Yong Jiang((cid:0)), Pengjun Xie, Fei Huang, Jingren Zhou Tongyi Lab , Alibaba Group https://tongyi-agent.github.io/blog https://github.com/Alibaba-NLP/DeepResearch "
[17.09.2025 05:11] Response: ```python
["Tongyi Lab, Alibaba Group"]
```
[17.09.2025 05:11] Deleting PDF ./assets/pdf/2509.13310.pdf.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13309.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.13309.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.13309.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13313.
[17.09.2025 05:11] Downloading paper 2509.13313 from http://arxiv.org/pdf/2509.13313v1...
[17.09.2025 05:11] Extracting affiliations from text.
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2025-09-17 ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization Xixi Wu, Kuan Li, Yida Zhao, Liwen Zhang((cid:0)), Litu Ou, Huifeng Yin, Zhongwang Zhang, Yong Jiang((cid:0)), Pengjun Xie, Fei Huang, Minhao Cheng, Shuai Wang, Hong Cheng, Jingren Zhou Tongyi Lab , Alibaba Group https://tongyi-agent.github.io/blog https://github.com/Alibaba-NLP/DeepResearch "
[17.09.2025 05:11] Response: ```python
["Tongyi Lab, Alibaba Group"]
```
[17.09.2025 05:11] Deleting PDF ./assets/pdf/2509.13313.pdf.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.12815.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.12815.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.12815.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.12603.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.12603.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.12603.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.06079.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.06079.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.06079.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.13317.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.13317.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.13317.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.12341.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.12341.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.12341.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.11526.
[17.09.2025 05:11] Extra JSON file exists (./assets/json/2509.11526.json), skip PDF parsing.
[17.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.11526.json), skip HTML parsing.
[17.09.2025 05:11] Success.
[17.09.2025 05:11] Enriching papers with extra data.
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 0. Single-stream Policy Optimization (SPO) improves policy-gradient training for Large Language Models by eliminating group-based issues and providing a stable, low-variance learning signal, leading to better performance and efficiency.  					AI-generated summary 				 We revisit policy-gradient optimiz...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 1. WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.  					AI-generated summary 				 This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents m...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 2. WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.  					AI-generated summary 				 Transcending human cognitive limitations represents a critical frontier in LLM tra...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 3. A scalable framework and two-phase fine-tuning strategy enhance function-calling capabilities of agents in diverse environments, improving performance on agentic benchmarks.  					AI-generated summary 				 Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practic...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 4. AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.  					AI-generated summary 				 Large language models (LLMs) have evolved into agentic systems capable of autonomo...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 5. WebResearcher, a deep-research framework, enhances AI agents' knowledge synthesis by reformulating research as a Markov Decision Process and using a scalable data synthesis engine, achieving superior performance across benchmarks.  					AI-generated summary 				 Recent advances in deep-research syst...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 6. ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.  					AI-generated summary 				 Large Language Model (LLM)-based web agents demonstrate ...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 7. Hunyuan3D Studio automates 3D asset creation using AI, integrating neural modules to transform concept images or text into high-quality, game-ready 3D models with optimized geometry and PBR textures.  					AI-generated summary 				 The creation of high-quality 3D assets, a cornerstone of modern game...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 8. Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  					AI-generated summary 				 Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performanc...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 9. A caption-assisted reasoning framework bridges visual and textual modalities, achieving top performance in multimodal reasoning tasks like SeePhys and MathVerse.  					AI-generated summary 				 Multimodal reasoning remains a fundamental challenge in artificial intelligence. Despite substantial advan...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 10. A Spatial Region 3D (SR-3D) vision-language model unifies 2D and 3D representations by enriching 2D features with 3D positional embeddings, enabling flexible region prompting and accurate spatial reasoning across frames.  					AI-generated summary 				 We present Spatial Region 3D (SR-3D) aware visi...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 11. A replacement for the domain-extension step in a quantum lattice algorithm uses a pair-shift difference construction to correct periodicity issues and enforce modular linear relations efficiently.  					AI-generated summary 				 We give a simple, fully correct, and assumption-light replacement for t...
[17.09.2025 05:11] ********************************************************************************
[17.09.2025 05:11] Abstract 12. A novel MIL framework, MHIM-MIL, uses masked hard instance mining with a Siamese structure and momentum teacher to improve cancer diagnosis and subtyping accuracy.  					AI-generated summary 				 Digitizing pathological images into gigapixel Whole Slide Images (WSIs) has opened new avenues for Compu...
[17.09.2025 05:11] Read previous papers.
[17.09.2025 05:11] Generating reviews via LLM API.
[17.09.2025 05:11] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "🚀", "ru": {"title": "SPO: Революция в обучении языковых моделей", "desc": "Статья представляет новый метод оптимизации политики для больших языковых моделей (LLM) под названием Single-stream Policy Optimization (SPO). SPO 
[17.09.2025 05:11] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#hallucinations", "#long_context", "#multimodal", "#agents"], "emoji": "🕸️", "ru": {"title": "Адаптивное планирование и целенаправленный синтез для качественных исследовательских отчетов", "desc": "Статья представляет WebWeaver - двухагентную систему д
[17.09.2025 05:11] Querying the API.
[17.09.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.  					AI-generated summary 				 Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.
[17.09.2025 05:11] Response: {
  "desc": "WebSailor - это методология пост-обучения, которая улучшает работу моделей с открытым исходным кодом в сложных задачах поиска информации. Она основана на систематическом снижении неопределенности, что ранее было доступно только проприетарным агентным системам. Методология включает генерацию новых задач с высокой неопределенностью и эффективный алгоритм обучения с подкреплением DUPO. В результате WebSailor значительно превосходит все открытые агенты и сравнивается по производительности с проприетарными системами.",
  "emoji": "🧭",
  "title": "WebSailor: открытый путь к сверхчеловеческому поиску информации"
}
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.  					AI-generated summary 				 Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap."

[17.09.2025 05:11] Response: ```python
['RL', 'TRAINING', 'AGENTS']
```
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.  					AI-generated summary 				 Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap."

[17.09.2025 05:11] Response: ```python
['AGI', 'REASONING', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[17.09.2025 05:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"WebSailor is a new method that improves open-source machine learning models by reducing uncertainty in their decision-making processes. This technique allows these models to perform as well as proprietary systems in challenging tasks that require searching for information. The methodology includes creating difficult tasks that test the models\' abilities and using a special training algorithm called Duplicating Sampling Policy Optimization (DUPO). By implementing these strategies, WebSailor helps open-source models achieve better performance in complex scenarios, bridging the gap with advanced proprietary agents.","title":"Closing the Gap: Empowering Open-Source Models with WebSailor"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="WebSailor is a new method that improves open-source machine learning models by reducing uncertainty in their decision-making processes. This technique allows these models to perform as well as proprietary systems in challenging tasks that require searching for information. The methodology includes creating difficult tasks that test the models' abilities and using a special training algorithm called Duplicating Sampling Policy Optimization (DUPO). By implementing these strategies, WebSailor helps open-source models achieve better performance in complex scenarios, bridging the gap with advanced proprietary agents.", title='Closing the Gap: Empowering Open-Source Models with WebSailor'))
[17.09.2025 05:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"WebSailor是一种后训练方法，旨在通过系统性减少不确定性来增强开源模型的性能，使其在复杂的信息检索任务中与专有代理的表现相匹配。该方法的成功依赖于一种复杂的推理模式，这种模式在开源模型中缺失，即在广阔的信息环境中系统性地减少极端不确定性的能力。WebSailor通过结构化采样和信息模糊化生成新颖的高不确定性任务，并结合高效的代理强化学习训练算法，显著提升了开源代理在复杂信息检索任务中的表现。最终，WebSailor成功缩小了开源模型与专有系统之间的能力差距。","title":"WebSailor：缩小开源与专有模型的能力差距"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='WebSailor是一种后训练方法，旨在通过系统性减少不确定性来增强开源模型的性能，使其在复杂的信息检索任务中与专有代理的表现相匹配。该方法的成功依赖于一种复杂的推理模式，这种模式在开源模型中缺失，即在广阔的信息环境中系统性地减少极端不确定性的能力。WebSailor通过结构化采样和信息模糊化生成新颖的高不确定性任务，并结合高效的代理强化学习训练算法，显著提升了开源代理在复杂信息检索任务中的表现。最终，WebSailor成功缩小了开源模型与专有系统之间的能力差距。', title='WebSailor：缩小开源与专有模型的能力差距'))
[17.09.2025 05:11] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#agi", "#training", "#agents"], "emoji": "🤖", "ru": {"title": "Масштабируемое обучение агентов для улучшения вызова функций в разнообразных средах", "desc": "Статья представляет масштабируемую систему и двухфазную стратегию дообучения для улучшения спо
[17.09.2025 05:11] Querying the API.
[17.09.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.  					AI-generated summary 				 Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.
[17.09.2025 05:11] Response: {
  "desc": "Исследователи представили AgentFounder - модель глубокого исследовательского агента, использующую Агентное Континуальное Предобучение (Agentic CPT). Эта модель достигает наилучших результатов в агентных задачах, сохраняя при этом способность эффективно использовать инструменты. AgentFounder решает проблему недостаточной производительности пост-обученных моделей в агентных задачах. Модель показала высокие результаты на 10 бенчмарках, включая BrowseComp и HLE.",
  "emoji": "🤖",
  "title": "AgentFounder: новый шаг в создании эффективных агентных систем искусственного интеллекта"
}
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.  					AI-generated summary 				 Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE."

[17.09.2025 05:11] Response: ```python
['AGENTS', 'TRAINING']
```
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.  					AI-generated summary 				 Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE."

[17.09.2025 05:11] Response: ```python
["AGI", "OPTIMIZATION"]
```
[17.09.2025 05:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces AgentFounder, a deep research agent model that utilizes Agentic Continual Pre-training (Agentic CPT) to enhance performance in agentic tasks. Traditional post-training methods struggle with agentic tasks due to the lack of specialized foundational models, leading to optimization challenges. By implementing Agentic CPT, AgentFounder effectively learns diverse agentic behaviors while aligning with expert demonstrations. The model demonstrates superior performance on multiple benchmarks, showcasing its advanced tool-use capabilities and problem-solving skills.","title":"Empowering Agents with Continual Learning for Superior Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces AgentFounder, a deep research agent model that utilizes Agentic Continual Pre-training (Agentic CPT) to enhance performance in agentic tasks. Traditional post-training methods struggle with agentic tasks due to the lack of specialized foundational models, leading to optimization challenges. By implementing Agentic CPT, AgentFounder effectively learns diverse agentic behaviors while aligning with expert demonstrations. The model demonstrates superior performance on multiple benchmarks, showcasing its advanced tool-use capabilities and problem-solving skills.', title='Empowering Agents with Continual Learning for Superior Performance'))
[17.09.2025 05:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种名为AgentFounder的深度研究代理模型，该模型结合了代理持续预训练（Agentic Continual Pre-training），在代理任务中实现了最先进的性能，同时保持了强大的工具使用能力。大型语言模型（LLMs）已经发展成为能够自主使用工具和进行多步骤推理的代理系统，但在代理任务中，基于通用基础模型的后训练方法表现不佳。我们发现问题的根源在于缺乏强大的代理基础模型，导致模型在后训练过程中需要同时学习多样的代理行为并与专家示范对齐，从而产生基本的优化矛盾。为了解决这个问题，我们首次提出将代理持续预训练纳入深度研究代理的训练流程，以构建强大的代理基础模型。","title":"AgentFounder：代理任务的最优解"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种名为AgentFounder的深度研究代理模型，该模型结合了代理持续预训练（Agentic Continual Pre-training），在代理任务中实现了最先进的性能，同时保持了强大的工具使用能力。大型语言模型（LLMs）已经发展成为能够自主使用工具和进行多步骤推理的代理系统，但在代理任务中，基于通用基础模型的后训练方法表现不佳。我们发现问题的根源在于缺乏强大的代理基础模型，导致模型在后训练过程中需要同时学习多样的代理行为并与专家示范对齐，从而产生基本的优化矛盾。为了解决这个问题，我们首次提出将代理持续预训练纳入深度研究代理的训练流程，以构建强大的代理基础模型。', title='AgentFounder：代理任务的最优解'))
[17.09.2025 05:11] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#science", "#dataset", "#training", "#agents", "#transfer_learning"], "emoji": "🕸️", "ru": {"title": "WebResearcher: новый уровень глубокого исследования для ИИ", "desc": "WebResearcher - это новая система глубокого исследования, которая улучшает спосо
[17.09.2025 05:11] Querying the API.
[17.09.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.  					AI-generated summary 				 Large Language Model (LLM)-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in paradigms like ReAct. Complex queries involving multiple entities, intertwined relationships, and high uncertainty demand extensive search cycles that rapidly exhaust context budgets before reaching complete solutions. To overcome this challenge, we introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints. For paradigm adaptation, we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned reasoning. Extensive experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web agents.
[17.09.2025 05:11] Response: {
  "desc": "В статье представлена новая парадигма ReSum, которая улучшает производительность веб-агентов на основе больших языковых моделей (БЯМ) в задачах, требующих обширных знаний. ReSum преодолевает ограничения контекстного окна путем периодического суммирования контекста, что позволяет агентам проводить неограниченное исследование. Авторы также предлагают ReSum-GRPO - метод адаптации парадигмы, интегрирующий GRPO с сегментированным обучением траекторий. Эксперименты показывают, что ReSum превосходит существующую парадигму ReAct на 4.5% в среднем, а после обучения с ReSum-GRPO улучшение достигает 8.2%.",
  "emoji": "🧠",
  "title": "ReSum: раздвигая границы контекста для веб-агентов на основе БЯМ"
}
[17.09.2025 05:11] Renaming some terms.
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.  					AI-generated summary 				 Large Language Model (LLM)-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in paradigms like ReAct. Complex queries involving multiple entities, intertwined relationships, and high uncertainty demand extensive search cycles that rapidly exhaust context budgets before reaching complete solutions. To overcome this challenge, we introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints. For paradigm adaptation, we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned reasoning. Extensive experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web agents."

[17.09.2025 05:11] Response: ```python
['AGENTS', 'BENCHMARK', 'TRAINING']
```
[17.09.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.  					AI-generated summary 				 Large Language Model (LLM)-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in paradigms like ReAct. Complex queries involving multiple entities, intertwined relationships, and high uncertainty demand extensive search cycles that rapidly exhaust context budgets before reaching complete solutions. To overcome this challenge, we introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints. For paradigm adaptation, we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned reasoning. Extensive experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web agents."

[17.09.2025 05:11] Response: ```python
["LONG_CONTEXT", "OPTIMIZATION"]
```
[17.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ReSum is a new approach that improves the performance of web agents on complex knowledge tasks by addressing the limitations of context windows found in previous methods like ReAct. It allows agents to summarize their interactions periodically, which helps them keep track of important information without being constrained by limited context. This method enables agents to explore more effectively, even when dealing with complicated queries that involve many entities and relationships. The results show that ReSum significantly enhances performance, achieving better accuracy with fewer training samples compared to existing models.","title":"ReSum: Breaking Context Barriers for Smarter Web Agents"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ReSum is a new approach that improves the performance of web agents on complex knowledge tasks by addressing the limitations of context windows found in previous methods like ReAct. It allows agents to summarize their interactions periodically, which helps them keep track of important information without being constrained by limited context. This method enables agents to explore more effectively, even when dealing with complicated queries that involve many entities and relationships. The results show that ReSum significantly enhances performance, achieving better accuracy with fewer training samples compared to existing models.', title='ReSum: Breaking Context Barriers for Smarter Web Agents'))
[17.09.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ReSum是一种新颖的周期性上下文摘要方法，旨在提升网络智能体在知识密集型任务中的表现。传统的ReAct方法受到上下文窗口限制的影响，难以处理复杂查询。ReSum通过将不断增长的交互历史转换为紧凑的推理状态，克服了这些限制，使智能体能够在不受上下文约束的情况下进行无限探索。实验结果表明，ReSum在多个基准测试中相较于ReAct平均提高了4.5%的性能，经过ReSum-GRPO训练后，性能提升可达8.2%。","title":"ReSum：突破上下文限制的智能体新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ReSum是一种新颖的周期性上下文摘要方法，旨在提升网络智能体在知识密集型任务中的表现。传统的ReAct方法受到上下文窗口限制的影响，难以处理复杂查询。ReSum通过将不断增长的交互历史转换为紧凑的推理状态，克服了这些限制，使智能体能够在不受上下文约束的情况下进行无限探索。实验结果表明，ReSum在多个基准测试中相较于ReAct平均提高了4.5%的性能，经过ReSum-GRPO训练后，性能提升可达8.2%。', title='ReSum：突破上下文限制的智能体新方法'))
[17.09.2025 05:12] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "🎮", "ru": {"title": "ИИ революционизирует создание 3D-ассетов для игр", "desc": "Hunyuan3D Studio - это платформа для автоматизированного создания 3D-ассетов с использованием искусственного интеллекта. Система интегрирует нейронные модули 
[17.09.2025 05:12] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#training", "#inference", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное автоматическое доказательство теорем: меньше затрат, та же мощность", "desc": "Статья представляет два метода для снижения вычислительных затрат в моделях автоматического дока
[17.09.2025 05:12] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "Мост между зрением и языком: новый подход к мультимодальному ИИ", "desc": "Авторы представляют фреймворк для мультимодального рассуждения, который объединяет визуальные и текстовые модальности.
[17.09.2025 05:12] Using data from previous issue: {"categories": ["#benchmark", "#games", "#3d", "#cv", "#multimodal", "#reasoning"], "emoji": "🔍", "ru": {"title": "Объединение 2D и 3D для лучшего понимания пространства", "desc": "SR-3D - это модель машинного обучения, объединяющая 2D и 3D представления визуальных данных. Она обогащает 2D признаки 
[17.09.2025 05:12] Using data from previous issue: {"categories": [], "emoji": "🔬", "ru": {"title": "Усовершенствование квантового алгоритма решетки: эффективное расширение домена", "desc": "Статья представляет улучшение для алгоритма квантовой решетки. Авторы предлагают замену для шага расширения домена, используя конструкцию разности парных сдвиго
[17.09.2025 05:12] Using data from previous issue: {"categories": ["#benchmark", "#science", "#optimization", "#training", "#healthcare"], "emoji": "🔬", "ru": {"title": "Новый метод машинного обучения повышает точность диагностики рака", "desc": "Статья представляет новый подход к множественному обучению с экземплярами (MIL) для улучшения диагностик
[17.09.2025 05:12] Renaming data file.
[17.09.2025 05:12] Renaming previous data. hf_papers.json to ./d/2025-09-17.json
[17.09.2025 05:12] Saving new data file.
[17.09.2025 05:12] Generating page.
[17.09.2025 05:12] Renaming previous page.
[17.09.2025 05:12] Renaming previous data. index.html to ./d/2025-09-17.html
[17.09.2025 05:12] Writing result.
[17.09.2025 05:12] Renaming log file.
[17.09.2025 05:12] Renaming previous data. log.txt to ./logs/2025-09-17_last_log.txt
