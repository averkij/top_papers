[11.03.2025 08:14] Read previous papers.
[11.03.2025 08:14] Generating top page (month).
[11.03.2025 08:14] Writing top page (month).
[11.03.2025 09:12] Read previous papers.
[11.03.2025 09:12] Get feed.
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.03601
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07365
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07605
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07002
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07314
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07216
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07067
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06680
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07027
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06580
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04629
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04812
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07608
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07602
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07459
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06749
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07507
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07197
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06520
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06121
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.03499
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07603
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.06885
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02199
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.07595
[11.03.2025 09:12] Extract page data from URL. URL: https://huggingface.co/papers/2503.05244
[11.03.2025 09:12] Extract page data from URL. URL: https://huggingface.co/papers/2503.07465
[11.03.2025 09:12] Extract page data from URL. URL: https://huggingface.co/papers/2503.07426
[11.03.2025 09:12] Extract page data from URL. URL: https://huggingface.co/papers/2503.05283
[11.03.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.03511
[11.03.2025 09:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.03.2025 09:12] No deleted papers detected.
[11.03.2025 09:12] Downloading and parsing papers (pdf, html). Total: 30.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.03601.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.03601.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.03601.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07365.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07365.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07365.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07605.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07605.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07605.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07002.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07002.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07002.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07314.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07314.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07314.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07216.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07216.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07216.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07067.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07067.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07067.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.06680.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.06680.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.06680.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07027.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07027.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07027.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.06580.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.06580.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.06580.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.04629.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.04629.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.04629.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.04812.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.04812.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.04812.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07608.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07608.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07608.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07602.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07602.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07602.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07459.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07459.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07459.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.06749.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.06749.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.06749.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07507.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07507.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07507.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07197.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07197.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07197.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.06520.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.06520.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.06520.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.06121.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.06121.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.06121.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.03499.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.03499.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.03499.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07603.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07603.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07603.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.06885.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.06885.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.06885.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.02199.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.02199.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.02199.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07595.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.07595.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.07595.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.05244.
[11.03.2025 09:12] Downloading paper 2503.05244 from http://arxiv.org/pdf/2503.05244v1...
[11.03.2025 09:12] Extracting affiliations from text.
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"WritingBench: Comprehensive Benchmark for Generative Writing Yuning Wu1, Jiahao Mei1,3, Ming Yan1*, Chenliang Li1, Shaopeng Lai1, Yuran Ren2, Zijia Wang2, Ji Zhang1, Mengyue Wu3, Qin Jin2*, Fei Huang1 1Alibaba Group, 2Renmin University of China, 3Shanghai Jiao Tong University {yuningwu, ym119608}@alibaba-inc.com, qjin@ruc.edu.cn 5 2 0 2 ] . [ 1 4 4 2 5 0 . 3 0 5 2 : r a "
[11.03.2025 09:12] Response: ```python
["Alibaba Group", "Renmin University of China", "Shanghai Jiao Tong University"]
```
[11.03.2025 09:12] Deleting PDF ./assets/pdf/2503.05244.pdf.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07465.
[11.03.2025 09:12] Downloading paper 2503.07465 from http://arxiv.org/pdf/2503.07465v1...
[11.03.2025 09:12] Extracting affiliations from text.
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"YOLOE: Real-Time Seeing Anything Ao Wang1* Lihao Liu1* Hui Chen1 Zijia Lin1 Jungong Han1 Guiguang Ding1 1Tsinghua University 5 2 0 M 0 1 ] . [ 1 5 6 4 7 0 . 3 0 5 2 : r a "
[11.03.2025 09:12] Response: ```python
["Tsinghua University"]
```
[11.03.2025 09:12] Deleting PDF ./assets/pdf/2503.07465.pdf.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.07426.
[11.03.2025 09:12] Downloading paper 2503.07426 from http://arxiv.org/pdf/2503.07426v1...
[11.03.2025 09:12] Extracting affiliations from text.
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RePO: ReLU-based Preference Optimization Junkang Wu 1 Kexin Huang 1 Xue Wang 2 Jinyang Gao 2 Bolin Ding 2 Jiancan Wu 1 Xiangnan He 1 Xiang Wang 1 5 2 0 2 0 1 ] . [ 1 6 2 4 7 0 . 3 0 5 2 : r a "
[11.03.2025 09:12] Response: ```python
[]
```
[11.03.2025 09:12] Extracting affiliations from text.
[11.03.2025 09:12] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RePO: ReLU-based Preference Optimization Junkang Wu 1 Kexin Huang 1 Xue Wang 2 Jinyang Gao 2 Bolin Ding 2 Jiancan Wu 1 Xiangnan He 1 Xiang Wang 1 5 2 0 2 0 1 ] . [ 1 6 2 4 7 0 . 3 0 5 2 : r aAligning large language models (LLMs) with human preferences is critical for real-world deployment, yet existing methods like RLHF face computational and stability challenges. While DPO establishes an offline paradigm with single hyperparameter β, subsequent methods like SimPO reintroduce complexity through dual parameters (β, γ). We propose ReLU-based Preference Optimization (RePO), streamlined algorithm that eliminates β via two advances: (1) retaining SimPOs reference-free margins but removing β through gradient analysis, and (2) adopting ReLU-based max-margin loss that naturally filters trivial pairs. Theoretically, RePO is characterized as SimPOs limiting case (β ), where the logistic weighting collapses to binary thresholding, forming convex envelope of the 0-1 loss. Empirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO and SimPO across multiple base models, requiring only one hyperparameter to tune. 1. Introduction Aligning large language models (LLMs) with human preferences is essential for their effective deployment in realworld applications (Anil et al., 2023; Touvron et al., 2023; OpenAI, 2023; Bubeck et al., 2023), ensuring that their outputs are beneficial, accurate, and adhere to human values (Ouyang et al., 2022) while minimizing potential safety risks. primary approach for achieving this alignment is Reinforcement Learning from Human Feedback (RLHF). It typically entails multi-stage process: initially, reward model is trained using ranked preference data; subsequently, the LLM is optimized with the guidance of reward model, using reinforcement learning algorithms such as Proximal Work done during internship at Alibaba 1University of Science and Technology of China, Hefei, China 2Alibaba Group, Hangzhou, China. Correspondence to: Xiang Wang <xiangwang1223@gmail.com>. Preprint. Policy Optimization (PPO) (Schulman et al., 2017). Despite its effectiveness, RLHF faces significant challenges, such as high computational costs and training instability (Rafailov et al., 2023; Zhao et al., 2023). Recent research has been exploring simpler offline alternatives. Direct Preference Optimization (DPO) (Rafailov et al., 2023) is one such approach. It reparameterizes the reward function in RLHF, bypassing the explicit learning of the reward model, and thus enabling direct training of LLMs with human preference data. Formally, the DPO objective is logistic-log loss, which applies log-sigmoid activation to the reward margin between the preferred and less-preferred responses to the same input. Here, the reward is derived from comparing the policy model of the LLM with reference model. Building on this, follow-up studies, especially SLiC-HF (Zhao et al., 2023) and SimPO (Meng et al., 2024), focus on further simplifications on the loss function and reward margins separately. Specifically, SLiC-HF replaces the logistic-log loss in DPO with hinge loss, achieving faster-decaying tail. SimPO, on the other hand, introduces reference-free reward margins with logistic-log loss, offering more streamlined and efficient approach. While advancing the field and achieving leading performance, they introduce additional complexity on hyperparameter tuning. SimPO inherits DPOs reward margin strength controller β and adds target reward margin γ. Similarly, SLiC-HF utilizes γ, but also introduces regularization weight λ. The necessity of dual-tuning these hyperparameters poses significant challenges in model training and deployment. This leads to natural question: Can we develop simpler offline preference optimization algorithm? In this paper, we propose simple idea: simultaneously simplifying the log-sigmoid activation and reward margins, to achieve comparable or even better performance. For reward margins, we adopt the reference-free approach of SimPO but eliminate the hyperparameter β. For the logsigmoid activation, we employ ReLU to the reference-free reward margins, following max-margin (support vector machine) paradigm (Boser et al., 1992; Cortes & Vapnik, 1995), similar to SLiC-HF. Consequently, our method can be interpreted as SimPO without β and SLiC-HF without RePO: ReLU-based Preference Optimization Figure 1. RePO, SimPO, and DPO primarily differ in their loss functions, as highlighted in the shaded box. RePO either outperforms or achieves comparable performance to DPO and SimPO across various settings on AlpacaEval 2, with only single hyperparameter γ. IT denotes pre-trained instruction-tuned models. e.g., Gemma2-IT 9B refers to Gemma2-9B (instruct setup). λ. Interestingly, it bridges these methods by omitting core component from each while maintaining competitive performance, demonstrating the effectiveness of this streamlined approach. We term this ReLU-based Preference Optimization RePO. Theoretically, we demonstrate that RePO emerges as the natural endpoint of SimPOs architectural evolution: when β , SimPOs logistic weighting collapses to RePOs binary thresholding (Lemma 3.1). This asymptotic behavior motivates our key theoretical insight the ReLU loss in RePO is precisely the convex envelope of the 0-1 loss (Theorem 4.2), inheriting its global optimality while enabling tractable gradient-based optimization. Practically, this formulation provides the following advantages: Simplified Hyperparameter Tuning: RePO removes the hyperparameter β, requiring only the tuning of γ within the range [0, 1]. Empirical results show that RePO can achieve performance comparable to SimPO on three models (Llama, Mistral, and Gemma) even with fixed γ = 0.5, significantly reducing the complexity of hyperparameter tuning. Effective Data Filtering: By using ReLU instead of continuous sigmoid function, RePO interprets the target reward margin γ as strict cutoff point. This mechanism zeroes out gradients for preference pairs whose reward margin exceeds γ (well-separated pairs), while assigning unit weight to less-separated pairs. This selective approach minimizes overfitting by focusing optimization on challenging data points. Controllable Over-Optimization: The cutoff point γ controls the mean of reward margin within batch, representing new metric for evaluating over-optimization. Experimental results suggest that this metric correlates with model behavior and can replace KL divergence as simpler"
[11.03.2025 09:12] Mistral response. {"id": "bd5ff315b3564060a7bc1783f9457a03", "object": "chat.completion", "created": 1741684345, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n['University of Science and Technology of China, Hefei, China', 'Alibaba Group, Hangzhou, China']\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1711, "total_tokens": 1746, "completion_tokens": 35}}
[11.03.2025 09:12] Response: ```python
['University of Science and Technology of China, Hefei, China', 'Alibaba Group, Hangzhou, China']
```
[11.03.2025 09:12] Deleting PDF ./assets/pdf/2503.07426.pdf.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.05283.
[11.03.2025 09:12] Downloading paper 2503.05283 from http://arxiv.org/pdf/2503.05283v1...
[11.03.2025 09:12] Extracting affiliations from text.
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 ] . [ 1 3 8 2 5 0 . 3 0 5 2 : r Escaping Platos Cave: Towards the Alignment of 3D and Text Latent Spaces Souhail Hadgi1 Diego Gomez1 Luca Moschella2,* Qixing Huang4 Andrea Santilli2 Emanuele Rodol`a2 Simone Melzi3 Maks Ovsjanikov 1Ecole polytechnique 2Sapienza University of Rome 3University of Milano-Bicocca 4The University of Texas at Austin "
[11.03.2025 09:12] Response: ```python
[
    "Ecole polytechnique",
    "Sapienza University of Rome",
    "University of Milano-Bicocca",
    "The University of Texas at Austin"
]
```
[11.03.2025 09:12] Deleting PDF ./assets/pdf/2503.05283.pdf.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.03511.
[11.03.2025 09:12] Extra JSON file exists (./assets/json/2503.03511.json), skip PDF parsing.
[11.03.2025 09:12] Paper image links file exists (./assets/img_data/2503.03511.json), skip HTML parsing.
[11.03.2025 09:12] Success.
[11.03.2025 09:12] Enriching papers with extra data.
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 0. Artificial Text Detection (ATD) is becoming increasingly important with the rise of advanced Large Language Models (LLMs). Despite numerous efforts, no single algorithm performs consistently well across different types of unseen text or guarantees effective generalization to new LLMs. Interpretabili...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 1. We present MM-Eureka, a multimodal reasoning model that successfully extends large-scale rule-based reinforcement learning (RL) to multimodal reasoning. While rule-based RL has shown remarkable success in improving LLMs' reasoning abilities in text domains, its application to multimodal settings has...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 2. Large Language Models have achieved remarkable success across various natural language processing tasks, yet their high computational cost during inference remains a major bottleneck. This paper introduces Sparse Expert Activation Pruning (SEAP), a training-free pruning method that selectively retai...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 3. Multimodal large language models (MLLMs), built on large-scale pre-trained vision towers and language models, have shown great capabilities in multimodal understanding. However, most existing MLLMs are trained on single-turn vision question-answering tasks, which do not accurately reflect real-world...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 4. Existing long-form video generation frameworks lack automated planning, requiring manual input for storylines, scenes, cinematography, and character interactions, resulting in high costs and inefficiencies. To address these challenges, we present MovieAgent, an automated movie generation via multi-a...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 5. Federated Learning (FL) is a widely used framework for training models in a decentralized manner, ensuring that the central server does not have direct access to data from local clients. However, this approach may still fail to fully preserve data privacy, as models from local clients are exposed to...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 6. Despite the success of distillation in large language models (LLMs), most prior work applies identical loss functions to both teacher- and student-generated data. These strategies overlook the synergy between loss formulations and data types, leading to a suboptimal performance boost in student mode...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 7. Implementing new features in repository-level codebases is a crucial application of code generation models. However, current benchmarks lack a dedicated evaluation framework for this capability. To fill this gap, we introduce FEA-Bench, a benchmark designed to assess the ability of large language mo...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 8. Recent advancements in Unet-based diffusion models, such as ControlNet and IP-Adapter, have introduced effective spatial and subject control mechanisms. However, the DiT (Diffusion Transformer) architecture still struggles with efficient and flexible control. To tackle this issue, we propose EasyCon...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 9. Traditional agentic workflows rely on external prompts to manage interactions with tools and the environment, which limits the autonomy of reasoning models. We position Large Agent Models (LAMs) that internalize the generation of Chain-of-Action (CoA), enabling the model to autonomously decide when ...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 10. Survey paper plays a crucial role in scientific research, especially given the rapid growth of research publications. Recently, researchers have begun using LLMs to automate survey generation for better efficiency. However, the quality gap between LLM-generated surveys and those written by human rem...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 11. Universal multimodal embedding models play a critical role in tasks such as interleaved image-text retrieval, multimodal RAG, and multimodal clustering. However, our empirical results indicate that existing LMM-based embedding models trained with the standard InfoNCE loss exhibit a high degree of ov...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 12. OpenAI o1 and DeepSeek R1 achieve or even surpass human expert-level performance in complex domains like mathematics and science, with reinforcement learning (RL) and reasoning playing a crucial role. In autonomous driving, recent end-to-end models have greatly improved planning performance but stil...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 13. Relational video customization refers to the creation of personalized videos that depict user-specified relations between two subjects, a crucial task for comprehending real-world visual content. While existing methods can personalize subject appearances and motions, they still struggle with complex...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 14. Large Language Models (LLMs) have shown impressive performance on existing medical question-answering benchmarks. This high performance makes it increasingly difficult to meaningfully evaluate and differentiate advanced methods. We present <PRE_TAG>MedAgentsBench</POST_TAG>, a benchmark that focuses...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 15. DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning capabilities in LLMs purely through Reinforcement Learning (RL). Inspired by this breakthrough, we explore how RL can be utilized to enhance the reasoning capability of MLLMs. However, direct training with RL struggles to acti...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 16. Recent advancements in 2D-to-3D perception have significantly improved the understanding of 3D scenes from 2D images. However, existing methods face critical challenges, including limited generalization across scenes, suboptimal perception accuracy, and slow reconstruction speeds. To address these l...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 17. Although masked image generation models and masked diffusion models are designed with different motivations and objectives, we observe that they can be unified within a single framework. Building upon this insight, we carefully explore the design space of training and sampling, identifying key facto...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 18. Traditional methods for reasoning segmentation rely on supervised fine-tuning with categorical labels and simple descriptions, limiting its out-of-domain generalization and lacking explicit reasoning processes. To address these limitations, we propose Seg-Zero, a novel framework that demonstrates re...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 19. Time series models face significant challenges in scaling to handle large and complex datasets, akin to the scaling achieved by large language models (LLMs). The unique characteristics of time series data and the computational demands of model scaling necessitate innovative approaches. While researc...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 20. State Space Models (SSMs) have emerged as efficient alternatives to Transformers, mitigating their quadratic computational cost. However, the application of Parameter-Efficient Fine-Tuning (PEFT) methods to SSMs remains largely unexplored. In particular, prompt-based methods like Prompt Tuning and P...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 21. Pre-trained LLMs that are further trained with image data perform well on vision-language tasks. While adding images during a second training phase effectively unlocks this capability, it is unclear how much of a gain or loss this two-step pipeline gives over VLMs which integrate images earlier into...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 22. Solving expert-level multimodal tasks is a key milestone towards general intelligence. As the capabilities of multimodal large language models (MLLMs) continue to improve, evaluation of such advanced multimodal intelligence becomes necessary yet challenging. In this work, we introduce ProBench, a be...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 23. Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual data and varied textual inputs in vision-centered se...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 24. The increasing popularity of large language models has not only led to widespread use but has also brought various risks, including the potential for systematically spreading fake news. Consequently, the development of classification systems such as DetectGPT has become vital. These detectors are vu...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 25. Recent advancements in large language models (LLMs) have significantly enhanced text generation capabilities, yet evaluating their performance in generative writing remains a challenge. Existing benchmarks primarily focus on generic text generation or limited in writing tasks, failing to capture the...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 26. Object detection and segmentation are widely employed in computer vision applications, yet conventional models like YOLO series, while efficient and accurate, are limited by predefined categories, hindering adaptability in open scenarios. Recent open-set methods leverage text prompts, visual cues, o...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 27. Aligning large language models (LLMs) with human preferences is critical for real-world deployment, yet existing methods like RLHF face computational and stability challenges. While DPO establishes an offline paradigm with single hyperparameter beta, subsequent methods like SimPO reintroduce complex...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 28. Recent works have shown that, when trained at scale, uni-modal 2D vision and text encoders converge to learned features that share remarkable structural properties, despite arising from different representations. However, the role of 3D encoders with respect to other modalities remains unexplored. F...
[11.03.2025 09:12] ********************************************************************************
[11.03.2025 09:12] Abstract 29. Robotic grasping in scenes with transparent and specular objects presents great challenges for methods relying on accurate depth information. In this paper, we introduce NeuGrasp, a neural surface reconstruction method that leverages background priors for material-agnostic grasp detection. NeuGrasp ...
[11.03.2025 09:12] Read previous papers.
[11.03.2025 09:12] Generating reviews via LLM API.
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#interpretability", "#data"], "emoji": "🔍", "ru": {"title": "Раскрывая секреты искусственных текстов: новый подход к интерпретируемому обнаружению", "desc": "Исследование посвящено улучшению интерпретируемости методов обнаружения искусственного текста (ATD) с и
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#rl", "#multimodal", "#reasoning", "#rag", "#open_source"], "emoji": "🤖", "ru": {"title": "Мультимодальное рассуждение через обучение с подкреплением", "desc": "MM-Eureka – это мультимодальная модель рассуждений, которая успешно расширяет масштабное обучение с подкреплением на основ
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#inference", "#optimization", "#training"], "emoji": "✂️", "ru": {"title": "Эффективное обрезание нейросетей без потери качества", "desc": "Статья представляет метод Sparse Expert Activation Pruning (SEAP) для оптимизации больших языковых моделей. SEAP выборочно сохраняет параметры,
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#games", "#multimodal", "#dataset", "#architecture"], "emoji": "🗣️", "ru": {"title": "Новый подход к мультимодальным диалогам: от реалистичных данных к продвинутым моделям", "desc": "Статья представляет MMDiag - новый набор данных для многоходовых мультим
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#multimodal", "#story_generation", "#video", "#agents"], "emoji": "🎬", "ru": {"title": "Автоматизированное создание фильмов с помощью ИИ-агентов", "desc": "MovieAgent - это новая система автоматизированной генерации длинных видео с использованием мульти
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#security", "#benchmark", "#data", "#ethics", "#multimodal", "#rl"], "emoji": "🔐", "ru": {"title": "FedRand: Защита конфиденциальности в федеративном обучении визуально-языковых моделей", "desc": "Статья представляет новый подход к федеративному обучению (FL) для визуально-языковых 
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#multimodal", "#alignment", "#training", "#optimization"], "emoji": "🔬", "ru": {"title": "Контрастивная дистилляция: новый подход к обучению языковых моделей", "desc": "DistiLLM-2 - это новый подход к дистилляции больших языковых моделей (LLM), использующий контрастивное обучение. О
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#plp", "#dataset", "#optimization", "#benchmark"], "emoji": "🧪", "ru": {"title": "FEA-Bench: новый вызов для языковых моделей в разработке ПО", "desc": "FEA-Bench - это новый бенчмарк для оценки способности больших языковых моделей (LLM) выполнять инкрементальную разработку в репози
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#cv", "#architecture", "#training", "#optimization", "#diffusion"], "emoji": "🎨", "ru": {"title": "EasyControl: гибкое и эффективное управление диффузионными трансформерами", "desc": "Статья представляет EasyControl - новую систему для улучшения контроля в диффузионных трансформерах
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#agents", "#rl", "#training"], "emoji": "🤖", "ru": {"title": "Автономные агентные модели: новый шаг к самостоятельному ИИ", "desc": "Эта статья представляет новый подход к созданию агентных моделей искусственного интеллекта, называемых Large Agent Mode
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#survey", "#multimodal", "#agents", "#dataset", "#benchmark"], "emoji": "📊", "ru": {"title": "SurveyForge: Автоматизация создания высококачественных обзорных статей с помощью ИИ", "desc": "SurveyForge - это новый подход к автоматическому созданию обзорных статей с использованием бол
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#transfer_learning", "#benchmark", "#rag", "#multimodal", "#training"], "emoji": "🔀", "ru": {"title": "Динамическое обучение для различения сложных негативных пар в мультимодальных эмбеддингах", "desc": "Статья представляет новый фреймворк для улучшения обучения мультимодальных эмбе
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#rl", "#training", "#optimization", "#multimodal", "#reasoning", "#agents"], "emoji": "🚗", "ru": {"title": "AlphaDrive: ИИ за рулем с обучением и рассуждением", "desc": "AlphaDrive - это новая система для автономного вождения, использующая визуально-языковые модели с обучением с под
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#architecture", "#open_source", "#video", "#interpretability", "#games"], "emoji": "🎬", "ru": {"title": "DreamRelation: Персонализация отношений в видео через машинное обучение", "desc": "DreamRelation - это новый подход к персонализации отношений в в
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#survey", "#healthcare"], "emoji": "🩺", "ru": {"title": "Новый бенчмарк для оценки языковых моделей в сложных медицинских задачах", "desc": "Статья представляет новый бенчмарк <PRE_TAG>MedAgentsBench</POST_TAG> для оценки языковых моделей в области медици
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#rl", "#training", "#optimization", "#multimodal", "#open_source", "#benchmark", "#reasoning", "#dataset", "#rag"], "emoji": "🧠", "ru": {"title": "Vision-R1: Новый уровень мультимодальных рассуждений в ИИ", "desc": "Исследователи разработали Vision-R1, мультимодальную языковую модел
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#3d", "#architecture", "#benchmark"], "emoji": "🔍", "ru": {"title": "Быстрая и точная 3D-реконструкция из 2D-изображений", "desc": "PE3R - это новая система для улучшения 3D-реконструкции из 2D-изображений. Она использует прямую архитектуру для быстрого восстановления 3D семантическ
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#training", "#cv"], "emoji": "🖼️", "ru": {"title": "Объединение маскированных моделей для эффективной генерации изображений", "desc": "Исследователи объединили модели генерации маскированных изображений и маскированные диффузионные модели в единую стру
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#architecture", "#reasoning", "#rlhf", "#optimization"], "emoji": "🧠", "ru": {"title": "Сегментация с рассуждением: ИИ учится объяснять свои решения", "desc": "Seg-Zero - это новая модель для сегментации изображений, использующая когнитивное подкрепление для улу
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training", "#open_source"], "emoji": "⏳", "ru": {"title": "Революция в масштабировании моделей временных рядов с RWKV-7", "desc": "Статья представляет новый подход к масштабированию моделей временных рядов с использованием архитектуры RWKV-7. Автор
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективная тонкая настройка моделей пространства состояний без промптов", "desc": "Эта статья представляет новый подход к тонкой настройке моделей пространства состояний (SSM) в машинном обучении. Авторы 
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#multimodal", "#training", "#benchmark", "#transfer_learning", "#optimization"], "emoji": "🔬", "ru": {"title": "Оптимальное время для интеграции визуальных данных в языковые модели", "desc": "Исследование посвящено сравнению эффективности двухэтапного обучения языковых моделей (снач
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#agi", "#benchmark", "#reasoning"], "emoji": "🧠", "ru": {"title": "ProBench: испытание интеллекта мультимодальных ИИ-моделей", "desc": "ProBench - это новый бенчмарк для оценки продвинутых мультимодальных языковых моделей (MLLM). Он состоит из 4000 выс
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#interpretability", "#alignment", "#training", "#multimodal"], "emoji": "🔍", "ru": {"title": "Опасность слепой веры в текст: проблема и решения для VLM моделей", "desc": "Исследование показывает, что модели компьютерного зрения и обработки естественного языка (VLM) склонны чрезмерно
[11.03.2025 09:12] Using data from previous issue: {"categories": ["#security", "#benchmark", "#rlhf", "#data", "#ethics", "#rl", "#hallucinations"], "emoji": "🕵️", "ru": {"title": "Обман детекторов: как LLM обходят системы обнаружения ИИ-текстов", "desc": "Статья рассматривает проблему уязвимости систем обнаружения текстов, сгенерированных большими
[11.03.2025 09:12] Querying the API.
[11.03.2025 09:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recent advancements in large language models (LLMs) have significantly enhanced text generation capabilities, yet evaluating their performance in generative writing remains a challenge. Existing benchmarks primarily focus on generic text generation or limited in writing tasks, failing to capture the diverse requirements of high-quality written contents across various domains. To bridge this gap, we present WritingBench, a comprehensive benchmark designed to evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing creative, persuasive, informative, and technical writing. We further propose a query-dependent evaluation framework that empowers LLMs to dynamically generate instance-specific assessment criteria. This framework is complemented by a fine-tuned critic model for criteria-aware scoring, enabling evaluations in style, format and length. The framework's validity is further demonstrated by its data curation capability, which enables 7B-parameter models to approach state-of-the-art (SOTA) performance. We open-source the benchmark, along with evaluation tools and modular framework components, to advance the development of LLMs in writing.
[11.03.2025 09:12] Response: {
  "desc": "Статья представляет WritingBench - комплексный бенчмарк для оценки языковых моделей в различных областях письма. Авторы предлагают фреймворк для динамической генерации критериев оценки и обученную модель-критик для подсчета баллов. Бенчмарк охватывает 6 основных областей и 100 подобластей письма, включая креативное, убеждающее, информативное и техническое письмо. Исследование показывает, что предложенный подход позволяет небольшим моделям приблизиться к производительности современных больших языковых моделей.",
  "emoji": "✍️",
  "title": "WritingBench: новый стандарт оценки языковых моделей в письме"
}
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent advancements in large language models (LLMs) have significantly enhanced text generation capabilities, yet evaluating their performance in generative writing remains a challenge. Existing benchmarks primarily focus on generic text generation or limited in writing tasks, failing to capture the diverse requirements of high-quality written contents across various domains. To bridge this gap, we present WritingBench, a comprehensive benchmark designed to evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing creative, persuasive, informative, and technical writing. We further propose a query-dependent evaluation framework that empowers LLMs to dynamically generate instance-specific assessment criteria. This framework is complemented by a fine-tuned critic model for criteria-aware scoring, enabling evaluations in style, format and length. The framework's validity is further demonstrated by its data curation capability, which enables 7B-parameter models to approach state-of-the-art (SOTA) performance. We open-source the benchmark, along with evaluation tools and modular framework components, to advance the development of LLMs in writing."

[11.03.2025 09:12] Response: ```python
["BENCHMARK", "DATASET", "DATA"]
```
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent advancements in large language models (LLMs) have significantly enhanced text generation capabilities, yet evaluating their performance in generative writing remains a challenge. Existing benchmarks primarily focus on generic text generation or limited in writing tasks, failing to capture the diverse requirements of high-quality written contents across various domains. To bridge this gap, we present WritingBench, a comprehensive benchmark designed to evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing creative, persuasive, informative, and technical writing. We further propose a query-dependent evaluation framework that empowers LLMs to dynamically generate instance-specific assessment criteria. This framework is complemented by a fine-tuned critic model for criteria-aware scoring, enabling evaluations in style, format and length. The framework's validity is further demonstrated by its data curation capability, which enables 7B-parameter models to approach state-of-the-art (SOTA) performance. We open-source the benchmark, along with evaluation tools and modular framework components, to advance the development of LLMs in writing."

[11.03.2025 09:12] Response: ```python
['OPEN_SOURCE', 'STORY_GENERATION']
```
[11.03.2025 09:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces WritingBench, a new benchmark for evaluating large language models (LLMs) in generative writing across six key domains and 100 subdomains. It addresses the limitations of existing benchmarks that do not adequately assess the quality of writing in various contexts. The authors propose a query-dependent evaluation framework that allows LLMs to create specific assessment criteria based on the writing task at hand. Additionally, a fine-tuned critic model is introduced to provide criteria-aware scoring, enhancing the evaluation of style, format, and length in generated texts.","title":"WritingBench: A New Standard for Evaluating Language Models in Writing"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces WritingBench, a new benchmark for evaluating large language models (LLMs) in generative writing across six key domains and 100 subdomains. It addresses the limitations of existing benchmarks that do not adequately assess the quality of writing in various contexts. The authors propose a query-dependent evaluation framework that allows LLMs to create specific assessment criteria based on the writing task at hand. Additionally, a fine-tuned critic model is introduced to provide criteria-aware scoring, enhancing the evaluation of style, format, and length in generated texts.', title='WritingBench: A New Standard for Evaluating Language Models in Writing'))
[11.03.2025 09:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"近年来，大型语言模型（LLMs）的进步显著提升了文本生成能力，但评估其在生成写作中的表现仍然是一个挑战。现有的基准主要集中在通用文本生成或有限的写作任务上，无法捕捉到高质量书面内容在不同领域的多样化需求。为了解决这个问题，我们提出了WritingBench，这是一个全面的基准，旨在评估LLMs在6个核心写作领域和100个子领域的表现，包括创意、说服性、信息性和技术写作。我们还提出了一种依赖查询的评估框架，使LLMs能够动态生成特定实例的评估标准，并通过一个经过微调的评估模型进行风格、格式和长度的评分。","title":"WritingBench：全面评估大型语言模型的写作能力"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='近年来，大型语言模型（LLMs）的进步显著提升了文本生成能力，但评估其在生成写作中的表现仍然是一个挑战。现有的基准主要集中在通用文本生成或有限的写作任务上，无法捕捉到高质量书面内容在不同领域的多样化需求。为了解决这个问题，我们提出了WritingBench，这是一个全面的基准，旨在评估LLMs在6个核心写作领域和100个子领域的表现，包括创意、说服性、信息性和技术写作。我们还提出了一种依赖查询的评估框架，使LLMs能够动态生成特定实例的评估标准，并通过一个经过微调的评估模型进行风格、格式和长度的评分。', title='WritingBench：全面评估大型语言模型的写作能力'))
[11.03.2025 09:12] Querying the API.
[11.03.2025 09:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Object detection and segmentation are widely employed in computer vision applications, yet conventional models like YOLO series, while efficient and accurate, are limited by predefined categories, hindering adaptability in open scenarios. Recent open-set methods leverage text prompts, visual cues, or prompt-free paradigm to overcome this, but often compromise between performance and efficiency due to high computational demands or deployment complexity. In this work, we introduce YOLOE, which integrates detection and segmentation across diverse open prompt mechanisms within a single highly efficient model, achieving real-time seeing anything. For text prompts, we propose Re-parameterizable Region-Text Alignment (RepRTA) strategy. It refines pretrained textual embeddings via a re-parameterizable lightweight auxiliary network and enhances visual-textual alignment with zero inference and transferring overhead. For visual prompts, we present Semantic-Activated Visual Prompt Encoder (SAVPE). It employs decoupled semantic and activation branches to bring improved visual embedding and accuracy with minimal complexity. For prompt-free scenario, we introduce Lazy Region-Prompt Contrast (LRPC) strategy. It utilizes a built-in large vocabulary and specialized embedding to identify all objects, avoiding costly language model dependency. Extensive experiments show YOLOE's exceptional zero-shot performance and transferability with high inference efficiency and low training cost. Notably, on LVIS, with 3times less training cost and 1.4times inference speedup, YOLOE-v8-S surpasses YOLO-Worldv2-S by 3.5 AP. When transferring to COCO, YOLOE-v8-L achieves 0.6 AP^b and 0.4 AP^m gains over closed-set YOLOv8-L with nearly 4times less training time. Code and models are available at https://github.com/THU-MIG/yoloe.
[11.03.2025 09:12] Response: {
  "desc": "YOLOE - это новая модель для обнаружения и сегментации объектов, которая объединяет различные механизмы открытых подсказок в одной эффективной архитектуре. Она использует стратегию RepRTA для текстовых подсказок, энкодер SAVPE для визуальных подсказок и метод LRPC для сценариев без подсказок. YOLOE демонстрирует исключительную производительность в задачах zero-shot и переносимость, превосходя существующие модели по эффективности и точности при меньших затратах на обучение.",
  "emoji": "🔍",
  "title": "YOLOE: Эффективное обнаружение и сегментация чего угодно в реальном времени"
}
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Object detection and segmentation are widely employed in computer vision applications, yet conventional models like YOLO series, while efficient and accurate, are limited by predefined categories, hindering adaptability in open scenarios. Recent open-set methods leverage text prompts, visual cues, or prompt-free paradigm to overcome this, but often compromise between performance and efficiency due to high computational demands or deployment complexity. In this work, we introduce YOLOE, which integrates detection and segmentation across diverse open prompt mechanisms within a single highly efficient model, achieving real-time seeing anything. For text prompts, we propose Re-parameterizable Region-Text Alignment (RepRTA) strategy. It refines pretrained textual embeddings via a re-parameterizable lightweight auxiliary network and enhances visual-textual alignment with zero inference and transferring overhead. For visual prompts, we present Semantic-Activated Visual Prompt Encoder (SAVPE). It employs decoupled semantic and activation branches to bring improved visual embedding and accuracy with minimal complexity. For prompt-free scenario, we introduce Lazy Region-Prompt Contrast (LRPC) strategy. It utilizes a built-in large vocabulary and specialized embedding to identify all objects, avoiding costly language model dependency. Extensive experiments show YOLOE's exceptional zero-shot performance and transferability with high inference efficiency and low training cost. Notably, on LVIS, with 3times less training cost and 1.4times inference speedup, YOLOE-v8-S surpasses YOLO-Worldv2-S by 3.5 AP. When transferring to COCO, YOLOE-v8-L achieves 0.6 AP^b and 0.4 AP^m gains over closed-set YOLOv8-L with nearly 4times less training time. Code and models are available at https://github.com/THU-MIG/yoloe."

[11.03.2025 09:12] Response: ```python
["CV", "BENCHMARK", "TRAINING"]
```
[11.03.2025 09:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Object detection and segmentation are widely employed in computer vision applications, yet conventional models like YOLO series, while efficient and accurate, are limited by predefined categories, hindering adaptability in open scenarios. Recent open-set methods leverage text prompts, visual cues, or prompt-free paradigm to overcome this, but often compromise between performance and efficiency due to high computational demands or deployment complexity. In this work, we introduce YOLOE, which integrates detection and segmentation across diverse open prompt mechanisms within a single highly efficient model, achieving real-time seeing anything. For text prompts, we propose Re-parameterizable Region-Text Alignment (RepRTA) strategy. It refines pretrained textual embeddings via a re-parameterizable lightweight auxiliary network and enhances visual-textual alignment with zero inference and transferring overhead. For visual prompts, we present Semantic-Activated Visual Prompt Encoder (SAVPE). It employs decoupled semantic and activation branches to bring improved visual embedding and accuracy with minimal complexity. For prompt-free scenario, we introduce Lazy Region-Prompt Contrast (LRPC) strategy. It utilizes a built-in large vocabulary and specialized embedding to identify all objects, avoiding costly language model dependency. Extensive experiments show YOLOE's exceptional zero-shot performance and transferability with high inference efficiency and low training cost. Notably, on LVIS, with 3times less training cost and 1.4times inference speedup, YOLOE-v8-S surpasses YOLO-Worldv2-S by 3.5 AP. When transferring to COCO, YOLOE-v8-L achieves 0.6 AP^b and 0.4 AP^m gains over closed-set YOLOv8-L with nearly 4times less training time. Code and models are available at https://github.com/THU-MIG/yoloe."

[11.03.2025 09:12] Response: ```python
["OPTIMIZATION", "TRANSFER_LEARNING"]
```
[11.03.2025 09:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents YOLOE, a novel model that enhances object detection and segmentation in open-set scenarios by integrating various prompt mechanisms. It introduces a Re-parameterizable Region-Text Alignment (RepRTA) strategy for text prompts, which refines textual embeddings efficiently without additional inference costs. For visual prompts, the Semantic-Activated Visual Prompt Encoder (SAVPE) improves visual accuracy while maintaining low complexity. Additionally, the Lazy Region-Prompt Contrast (LRPC) strategy allows for prompt-free object identification, significantly reducing training costs and improving inference speed compared to traditional models.","title":"YOLOE: Real-Time Object Detection and Segmentation for Open-Set Scenarios"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents YOLOE, a novel model that enhances object detection and segmentation in open-set scenarios by integrating various prompt mechanisms. It introduces a Re-parameterizable Region-Text Alignment (RepRTA) strategy for text prompts, which refines textual embeddings efficiently without additional inference costs. For visual prompts, the Semantic-Activated Visual Prompt Encoder (SAVPE) improves visual accuracy while maintaining low complexity. Additionally, the Lazy Region-Prompt Contrast (LRPC) strategy allows for prompt-free object identification, significantly reducing training costs and improving inference speed compared to traditional models.', title='YOLOE: Real-Time Object Detection and Segmentation for Open-Set Scenarios'))
[11.03.2025 09:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种新的目标检测和分割模型YOLOE，旨在克服传统模型在开放场景中的局限性。YOLOE通过集成多种开放提示机制，实现了高效的实时检测和分割。我们提出了可重参数化区域-文本对齐策略（RepRTA）和语义激活视觉提示编码器（SAVPE），以提高视觉和文本的对齐效果。实验结果表明，YOLOE在零样本性能和迁移能力上表现优异，同时训练成本低，推理效率高。","title":"YOLOE：高效的开放场景目标检测与分割"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种新的目标检测和分割模型YOLOE，旨在克服传统模型在开放场景中的局限性。YOLOE通过集成多种开放提示机制，实现了高效的实时检测和分割。我们提出了可重参数化区域-文本对齐策略（RepRTA）和语义激活视觉提示编码器（SAVPE），以提高视觉和文本的对齐效果。实验结果表明，YOLOE在零样本性能和迁移能力上表现优异，同时训练成本低，推理效率高。', title='YOLOE：高效的开放场景目标检测与分割'))
[11.03.2025 09:12] Querying the API.
[11.03.2025 09:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Aligning large language models (LLMs) with human preferences is critical for real-world deployment, yet existing methods like RLHF face computational and stability challenges. While DPO establishes an offline paradigm with single hyperparameter beta, subsequent methods like SimPO reintroduce complexity through dual parameters (beta, gamma). We propose {ReLU-based Preference Optimization (RePO)}, a streamlined algorithm that eliminates beta via two advances: (1) retaining SimPO's reference-free margins but removing beta through gradient analysis, and (2) adopting a ReLU-based max-margin loss that naturally filters trivial pairs. Theoretically, RePO is characterized as SimPO's limiting case (beta to infty), where the logistic weighting collapses to binary thresholding, forming a convex envelope of the 0-1 loss. Empirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO and SimPO across multiple base models, requiring only one hyperparameter to tune.
[11.03.2025 09:13] Response: {
  "desc": "Статья представляет новый алгоритм обучения с подкреплением для больших языковых моделей под названием RePO. Этот метод упрощает существующие подходы, такие как DPO и SimPO, устраняя необходимость в гиперпараметре beta. RePO использует ReLU-основанную функцию потерь для фильтрации тривиальных пар и оптимизации предпочтений. Эмпирические результаты показывают, что RePO превосходит DPO и SimPO на нескольких базовых моделях при использовании только одного гиперпараметра.",

  "emoji": "🚀",

  "title": "RePO: Упрощенная оптимизация предпочтений для больших языковых моделей"
}
[11.03.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Aligning large language models (LLMs) with human preferences is critical for real-world deployment, yet existing methods like RLHF face computational and stability challenges. While DPO establishes an offline paradigm with single hyperparameter beta, subsequent methods like SimPO reintroduce complexity through dual parameters (beta, gamma). We propose {ReLU-based Preference Optimization (RePO)}, a streamlined algorithm that eliminates beta via two advances: (1) retaining SimPO's reference-free margins but removing beta through gradient analysis, and (2) adopting a ReLU-based max-margin loss that naturally filters trivial pairs. Theoretically, RePO is characterized as SimPO's limiting case (beta to infty), where the logistic weighting collapses to binary thresholding, forming a convex envelope of the 0-1 loss. Empirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO and SimPO across multiple base models, requiring only one hyperparameter to tune."

[11.03.2025 09:13] Response: ```python
['RLHF', 'TRAINING']
```
[11.03.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Aligning large language models (LLMs) with human preferences is critical for real-world deployment, yet existing methods like RLHF face computational and stability challenges. While DPO establishes an offline paradigm with single hyperparameter beta, subsequent methods like SimPO reintroduce complexity through dual parameters (beta, gamma). We propose {ReLU-based Preference Optimization (RePO)}, a streamlined algorithm that eliminates beta via two advances: (1) retaining SimPO's reference-free margins but removing beta through gradient analysis, and (2) adopting a ReLU-based max-margin loss that naturally filters trivial pairs. Theoretically, RePO is characterized as SimPO's limiting case (beta to infty), where the logistic weighting collapses to binary thresholding, forming a convex envelope of the 0-1 loss. Empirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO and SimPO across multiple base models, requiring only one hyperparameter to tune."

[11.03.2025 09:13] Response: ```python
["ALIGNMENT"]
```
[11.03.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of aligning large language models (LLMs) with human preferences using a new method called ReLU-based Preference Optimization (RePO). RePO simplifies the optimization process by eliminating the need for a complex hyperparameter, beta, while still maintaining effective performance through gradient analysis and a ReLU-based max-margin loss. The authors demonstrate that RePO can be seen as a special case of an existing method, SimPO, when certain conditions are met, leading to a more efficient training process. Empirical results indicate that RePO consistently outperforms previous methods like DPO and SimPO, while only requiring the tuning of a single hyperparameter.","title":"Streamlining Preference Optimization for LLMs with RePO"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenge of aligning large language models (LLMs) with human preferences using a new method called ReLU-based Preference Optimization (RePO). RePO simplifies the optimization process by eliminating the need for a complex hyperparameter, beta, while still maintaining effective performance through gradient analysis and a ReLU-based max-margin loss. The authors demonstrate that RePO can be seen as a special case of an existing method, SimPO, when certain conditions are met, leading to a more efficient training process. Empirical results indicate that RePO consistently outperforms previous methods like DPO and SimPO, while only requiring the tuning of a single hyperparameter.', title='Streamlining Preference Optimization for LLMs with RePO'))
[11.03.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的算法，称为基于ReLU的偏好优化（RePO），旨在简化大型语言模型（LLMs）与人类偏好的对齐过程。RePO通过两个创新点消除了超参数beta，首先保留了SimPO的无参考边际，但通过梯度分析去除了beta，其次采用基于ReLU的最大边际损失，自然过滤掉无关的配对。理论上，RePO被描述为SimPO的极限情况，当beta趋向于无穷大时，逻辑加权收敛为二元阈值，形成0-1损失的凸包。实验证明，RePO在多个基础模型上优于DPO和SimPO，仅需调整一个超参数。","title":"简化偏好优化，提升语言模型对齐"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的算法，称为基于ReLU的偏好优化（RePO），旨在简化大型语言模型（LLMs）与人类偏好的对齐过程。RePO通过两个创新点消除了超参数beta，首先保留了SimPO的无参考边际，但通过梯度分析去除了beta，其次采用基于ReLU的最大边际损失，自然过滤掉无关的配对。理论上，RePO被描述为SimPO的极限情况，当beta趋向于无穷大时，逻辑加权收敛为二元阈值，形成0-1损失的凸包。实验证明，RePO在多个基础模型上优于DPO和SimPO，仅需调整一个超参数。', title='简化偏好优化，提升语言模型对齐'))
[11.03.2025 09:13] Querying the API.
[11.03.2025 09:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recent works have shown that, when trained at scale, uni-modal 2D vision and text encoders converge to learned features that share remarkable structural properties, despite arising from different representations. However, the role of 3D encoders with respect to other modalities remains unexplored. Furthermore, existing 3D foundation models that leverage large datasets are typically trained with explicit alignment objectives with respect to frozen encoders from other representations. In this work, we investigate the possibility of a posteriori alignment of representations obtained from uni-modal 3D encoders compared to text-based feature spaces. We show that naive post-training feature alignment of uni-modal text and 3D encoders results in limited performance. We then focus on extracting subspaces of the corresponding feature spaces and discover that by projecting learned representations onto well-chosen lower-dimensional <PRE_TAG>subspaces</POST_TAG> the quality of alignment becomes significantly higher, leading to improved accuracy on matching and retrieval tasks. Our analysis further sheds light on the nature of these shared subspaces, which roughly separate between semantic and geometric data representations. Overall, ours is the first work that helps to establish a baseline for post-training alignment of 3D uni-modal and text feature spaces, and helps to highlight both the shared and unique properties of 3D data compared to other representations.
[11.03.2025 09:13] Response: {
  "desc": "Исследование посвящено изучению возможности апостериорного выравнивания представлений, полученных из одномодальных 3D-энкодеров, с текстовыми пространствами признаков. Авторы обнаружили, что простое выравнивание признаков после обучения дает ограниченные результаты. Однако, проецирование выученных представлений на тщательно выбранные подпространства меньшей размерности значительно улучшает качество выравнивания. Анализ также показал, что эти общие подпространства примерно разделяют семантические и геометрические представления данных.",
  "emoji": "🧩",
  "title": "Улучшение выравнивания 3D и текстовых признаков через проекцию на подпространства"
}
[11.03.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent works have shown that, when trained at scale, uni-modal 2D vision and text encoders converge to learned features that share remarkable structural properties, despite arising from different representations. However, the role of 3D encoders with respect to other modalities remains unexplored. Furthermore, existing 3D foundation models that leverage large datasets are typically trained with explicit alignment objectives with respect to frozen encoders from other representations. In this work, we investigate the possibility of a posteriori alignment of representations obtained from uni-modal 3D encoders compared to text-based feature spaces. We show that naive post-training feature alignment of uni-modal text and 3D encoders results in limited performance. We then focus on extracting subspaces of the corresponding feature spaces and discover that by projecting learned representations onto well-chosen lower-dimensional <PRE_TAG>subspaces</POST_TAG> the quality of alignment becomes significantly higher, leading to improved accuracy on matching and retrieval tasks. Our analysis further sheds light on the nature of these shared subspaces, which roughly separate between semantic and geometric data representations. Overall, ours is the first work that helps to establish a baseline for post-training alignment of 3D uni-modal and text feature spaces, and helps to highlight both the shared and unique properties of 3D data compared to other representations."

[11.03.2025 09:13] Response: ```python
["3D", "MULTIMODAL"]
```
[11.03.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent works have shown that, when trained at scale, uni-modal 2D vision and text encoders converge to learned features that share remarkable structural properties, despite arising from different representations. However, the role of 3D encoders with respect to other modalities remains unexplored. Furthermore, existing 3D foundation models that leverage large datasets are typically trained with explicit alignment objectives with respect to frozen encoders from other representations. In this work, we investigate the possibility of a posteriori alignment of representations obtained from uni-modal 3D encoders compared to text-based feature spaces. We show that naive post-training feature alignment of uni-modal text and 3D encoders results in limited performance. We then focus on extracting subspaces of the corresponding feature spaces and discover that by projecting learned representations onto well-chosen lower-dimensional <PRE_TAG>subspaces</POST_TAG> the quality of alignment becomes significantly higher, leading to improved accuracy on matching and retrieval tasks. Our analysis further sheds light on the nature of these shared subspaces, which roughly separate between semantic and geometric data representations. Overall, ours is the first work that helps to establish a baseline for post-training alignment of 3D uni-modal and text feature spaces, and helps to highlight both the shared and unique properties of 3D data compared to other representations."

[11.03.2025 09:13] Response: ```python
["ALIGNMENT", "TRANSFER_LEARNING"]
```
[11.03.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the alignment of features from uni-modal 3D encoders with text-based representations. It reveals that simply aligning these features after training does not yield good results. Instead, the authors find that projecting these features into carefully selected lower-dimensional subspaces significantly improves alignment quality. This work establishes a baseline for understanding how 3D data relates to text features, highlighting both their similarities and differences.","title":"Enhancing 3D and Text Feature Alignment through Subspace Projection"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores the alignment of features from uni-modal 3D encoders with text-based representations. It reveals that simply aligning these features after training does not yield good results. Instead, the authors find that projecting these features into carefully selected lower-dimensional subspaces significantly improves alignment quality. This work establishes a baseline for understanding how 3D data relates to text features, highlighting both their similarities and differences.', title='Enhancing 3D and Text Feature Alignment through Subspace Projection'))
[11.03.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究探讨了3D编码器在与其他模态的关系中的作用，尤其是与文本特征空间的对比。我们发现，简单的后期训练特征对齐方法在单模态文本和3D编码器之间的性能有限。通过提取特征空间的子空间，并将学习到的表示投影到精心选择的低维子空间中，我们显著提高了对齐质量，从而在匹配和检索任务中提升了准确性。我们的工作首次为3D单模态和文本特征空间的后期训练对齐建立了基线，并突出了3D数据与其他表示之间的共享和独特特性。","title":"探索3D编码器与文本特征的对齐之路"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究探讨了3D编码器在与其他模态的关系中的作用，尤其是与文本特征空间的对比。我们发现，简单的后期训练特征对齐方法在单模态文本和3D编码器之间的性能有限。通过提取特征空间的子空间，并将学习到的表示投影到精心选择的低维子空间中，我们显著提高了对齐质量，从而在匹配和检索任务中提升了准确性。我们的工作首次为3D单模态和文本特征空间的后期训练对齐建立了基线，并突出了3D数据与其他表示之间的共享和独特特性。', title='探索3D编码器与文本特征的对齐之路'))
[11.03.2025 09:13] Using data from previous issue: {"categories": ["#robotics", "#agents", "#architecture", "#cv"], "emoji": "🤖", "ru": {"title": "NeuGrasp: нейронный захват для сложных поверхностей", "desc": "NeuGrasp - это нейронный метод реконструкции поверхности для захвата объектов с прозрачными и зеркальными поверхностями. Он использует трансф
[11.03.2025 09:13] Trying to get texts in Chinese.
[11.03.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Artificial Text Detection (ATD) is becoming increasingly important with the rise of advanced Large Language Models (LLMs). Despite numerous efforts, no single algorithm performs consistently well across different types of unseen text or guarantees effective generalization to new LLMs. Interpretability plays a crucial role in achieving this goal. In this study, we enhance ATD interpretability by using Sparse Autoencoders (SAE) to extract features from Gemma-2-2b residual stream. We identify both interpretable and efficient features, analyzing their semantics and relevance through domain- and model-specific statistics, a steering approach, and manual or LLM-based interpretation. Our methods offer valuable insights into how texts from various models differ from human-written content. We show that modern LLMs have a distinct writing style, especially in information-dense domains, even though they can produce human-like outputs with personalized prompts.
[11.03.2025 09:13] Mistral response. {"id": "e4d5f3dae8294df993d391bae78fc769", "object": "chat.completion", "created": 1741684402, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fdb\u6b65\uff0c\u4eba\u5de5\u6587\u672c\u68c0\u6d4b\uff08ATD\uff09\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u5c3d\u7ba1\u6709\u8bb8\u591a\u52aa\u529b\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2a\u7b97\u6cd5\u80fd\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u672a\u77e5\u6587\u672c\u4e2d\u8868\u73b0\u4e00\u81f4\uff0c\u6216\u4fdd\u8bc1\u6709\u6548\u5730\u6cdb\u5316\u5230\u65b0\u7684LLMs\u3002\u53ef\u89e3\u91ca\u6027\u5728\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002\u5728\u8fd9\u9879\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u4eceGemma-2-2b\u6b8b\u5dee\u6d41\u4e2d\u63d0\u53d6\u7279\u5f81\u6765\u589e\u5f3aATD\u7684\u53ef\u89e3\u91ca\u6027\u3002\u6211\u4eec\u786e\u5b9a\u4e86\u53ef\u89e3\u91ca\u548c\u9ad8\u6548\u7684\u7279\u5f81\uff0c\u901a\u8fc7\u9886\u57df\u548c\u6a21\u578b\u7279\u5b9a\u7684\u7edf\u8ba1\u6570\u636e\u3001\u5f15\u5bfc\u65b9\u6cd5\u4ee5\u53ca\u624b\u52a8\u6216\u57fa\u4e8eLLM\u7684\u89e3\u91ca\u6765\u5206\u6790\u5176\u8bed\u4e49\u548c\u76f8\u5173\u6027\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5173\u4e8e\u4e0d\u540c\u6a21\u578b\u751f\u6210\u7684\u6587\u672c\u4e0e\u4eba\u7c7b\u5199\u4f5c\u5185\u5bb9\u4e4b\u95f4\u5dee\u5f02\u7684\u5b9d\u8d35\u89c1\u89e3\u3002\u6211\u4eec\u5c55\u793a\u4e86\u73b0\u4ee3LLMs\u5728\u4fe1\u606f\u5bc6\u96c6\u9886\u57df\u5177\u6709\u72ec\u7279\u7684\u5199\u4f5c\u98ce\u683c\uff0c\u5373\u4f7f\u5b83\u4eec\u53ef\u4ee5\u901a\u8fc7\u4e2a\u6027\u5316\u63d0\u793a\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8f93\u51fa\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 225, "total_tokens": 524, "completion_tokens": 299}}
[11.03.2025 09:13] Response: 随着大型语言模型（LLMs）的进步，人工文本检测（ATD）变得越来越重要。尽管有许多努力，但没有一个算法能在不同类型的未知文本中表现一致，或保证有效地泛化到新的LLMs。可解释性在实现这一目标中起着关键作用。在这项研究中，我们通过使用稀疏自编码器（SAE）从Gemma-2-2b残差流中提取特征来增强ATD的可解释性。我们确定了可解释和高效的特征，通过领域和模型特定的统计数据、引导方法以及手动或基于LLM的解释来分析其语义和相关性。我们的方法提供了关于不同模型生成的文本与人类写作内容之间差异的宝贵见解。我们展示了现代LLMs在信息密集领域具有独特的写作风格，即使它们可以通过个性化提示生成类似人类的输出。
[11.03.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

随着大型语言模型（LLMs）的进步，人工文本检测（ATD）变得越来越重要。尽管有许多努力，但没有一个算法能在不同类型的未知文本中表现一致，或保证有效地泛化到新的LLMs。可解释性在实现这一目标中起着关键作用。在这项研究中，我们通过使用稀疏自编码器（SAE）从Gemma-2-2b残差流中提取特征来增强ATD的可解释性。我们确定了可解释和高效的特征，通过领域和模型特定的统计数据、引导方法以及手动或基于LLM的解释来分析其语义和相关性。我们的方法提供了关于不同模型生成的文本与人类写作内容之间差异的宝贵见解。我们展示了现代LLMs在信息密集领域具有独特的写作风格，即使它们可以通过个性化提示生成类似人类的输出。
[11.03.2025 09:13] Mistral response. {"id": "9d0a4167dd2f4708a3b725c09f4a2753", "object": "chat.completion", "created": 1741684409, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fdb\u6b65\uff0c\u4eba\u5de5\u6587\u672c\u68c0\u6d4b\uff08ATD\uff09\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u5c3d\u7ba1\u6709\u8bb8\u591a\u52aa\u529b\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2a\u7b97\u6cd5\u80fd\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u672a\u77e5\u6587\u672c\u4e2d\u8868\u73b0\u4e00\u81f4\uff0c\u6216\u4fdd\u8bc1\u6709\u6548\u5730\u6cdb\u5316\u5230\u65b0\u7684LLMs\u3002\u53ef\u89e3\u91ca\u6027\u5728\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002\u5728\u8fd9\u9879\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u4eceGemma-2-2b\u6b8b\u5dee\u6d41\u4e2d\u63d0\u53d6\u7279\u5f81\u6765\u589e\u5f3aATD\u7684\u53ef\u89e3\u91ca\u6027\u3002\u6211\u4eec\u786e\u5b9a\u4e86\u53ef\u89e3\u91ca\u548c\u9ad8\u6548\u7684\u7279\u5f81\uff0c\u901a\u8fc7\u9886\u57df\u548c\u6a21\u578b\u7279\u5b9a\u7684\u7edf\u8ba1\u6570\u636e\u3001\u5f15\u5bfc\u65b9\u6cd5\u4ee5\u53ca\u624b\u52a8\u6216\u57fa\u4e8eLLM\u7684\u89e3\u91ca\u6765\u5206\u6790\u5176\u8bed\u4e49\u548c\u76f8\u5173\u6027\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5173\u4e8e\u4e0d\u540c\u6a21\u578b\u751f\u6210\u7684\u6587\u672c\u4e0e\u4eba\u7c7b\u5199\u4f5c\u5185\u5bb9\u4e4b\u95f4\u5dee\u5f02\u7684\u5b9d\u8d35\u89c1\u89e3\u3002\u6211\u4eec\u5c55\u793a\u4e86\u73b0\u4ee3LLMs\u5728\u4fe1\u606f\u5bc6\u96c6\u9886\u57df\u5177\u6709\u72ec\u7279\u7684\u5199\u4f5c\u98ce\u683c\uff0c\u5373\u4f7f\u5b83\u4eec\u53ef\u4ee5\u901a\u8fc7\u4e2a\u6027\u5316\u63d0\u793a\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8f93\u51fa\u3002\n\nSu\u00edzhe d\u00e0x\u00edng y\u01d4y\u00e1n m\u00f3x\u00edng (LLMs) de j\u00ecnb\u00f9, r\u00e9ng\u014dng w\u00e9nb\u011bn ji\u01cenc\u00e8 (ATD) bi\u00e0n d\u00e9 yu\u00e8l\u00e1iyu\u00e8 zh\u00f2ngy\u00e0o. J\u01d0ngu\u01cen y\u01d2u x\u01d4du\u014d n\u01d4l\u00ec, d\u00e0n m\u00e9iy\u01d2u y\u012bg\u00e8 su\u00e0nf\u01ce n\u00e9ng z\u00e0i b\u00f9t\u00f3ng l\u00e8ix\u00edng de w\u00e8izh\u012b w\u00e9nb\u011bn zh\u014dng bi\u01ceoxi\u00e0n y\u012bzh\u00ec, hu\u00f2 b\u01ceozh\u00e8ng y\u01d2uxi\u00e0o de f\u00e0nhu\u00e0 d\u00e0o x\u012bn de LLMs. K\u011b ji\u011bsh\u00ecx\u00ecng z\u00e0i sh\u00edxi\u00e0n zh\u00e8 y\u012b m\u00f9bi\u0101o zh\u014dng q\u01d0zhe gu\u01cenji\u00e0n zu\u00f2y\u00f2ng. Z\u00e0i zh\u00e8 xi\u00e0ng y\u00e1nji\u016b zh\u014dng, w\u01d2men t\u014dnggu\u00f2 sh\u01d0y\u00f2ng x\u012bsh\u016b z\u00ecbi\u0101nm\u01ceq\u00ec (SAE) c\u00f3ng Gemma-2-2b c\u00e1nch\u00e1 li\u00fa zh\u014dng t\u012bqu t\u00e9di\u01cen l\u00e1i z\u0113ngqi\u00e1ng ATD de k\u011b ji\u011bsh\u00ecx\u00ecng. W\u01d2men qu\u00e8d\u00ecngle k\u011b ji\u011bsh\u00ec h\u00e9 g\u0101oxi\u00e0o de t\u00e9di\u01cen, t\u014dnggu\u00f2 l\u01d0ngy\u00f9 h\u00e9 m\u00f3x\u00edng t\u00e8d\u00ecng de t\u01d2ngj\u00ec sh\u00f9j\u00f9, y\u01d0nd\u01ceo f\u0101ngf\u01ce y\u01d0ji\u01ce sh\u01d2ud\u00f2ng hu\u00f2 j\u012by\u00fa LLM de ji\u011bsh\u00ec l\u00e1i f\u0113nxi q\u00ed y\u00f9y\u00e1n h\u00e9 xi\u0101nggu\u0101nx\u00ecng. W\u01d2men de f\u0101ngf\u01ce t\u00edg\u014dngle gu\u0101ny\u00fa b\u00f9t\u00f3ng m\u00f3x\u00edng sh\u0113ngch\u00e9ng de w\u00e9nb\u011bn y\u01d4 r\u00e9nl\u00e8i xi\u011bzu\u00f2 n\u00e8ir\u00f3ng zh\u012bji\u0101n ch\u0101y\u00ec de b\u01ceogu\u00ec ji\u00e0nsh\u00ec. W\u01d2men zh\u01censh\u00ecle xi\u00e0nd\u00e0i LLMs z\u00e0i x\u00ecnx\u012b m\u00ecji\u00e9 l\u01d0ngy\u00f9 y\u01d2u d\u00fat\u00e8 de xi\u011bzu\u00f2 f\u0113ngg\u00e9, j\u00edsh\u01d0 t\u0101men k\u011by\u01d0 t\u014dnggu\u00f2 g\u00e8x\u00ecnghu\u00e0 t\u01d0sh\u00ec sh\u0113ngch\u00e9ng l\u00e8ix\u00ed r\u00e9nl\u00e8i de sh\u00f9ch\u016b."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 314, "total_tokens": 1228, "completion_tokens": 914}}
[11.03.2025 09:13] Response: 随着大型语言模型（LLMs）的进步，人工文本检测（ATD）变得越来越重要。尽管有许多努力，但没有一个算法能在不同类型的未知文本中表现一致，或保证有效地泛化到新的LLMs。可解释性在实现这一目标中起着关键作用。在这项研究中，我们通过使用稀疏自编码器（SAE）从Gemma-2-2b残差流中提取特征来增强ATD的可解释性。我们确定了可解释和高效的特征，通过领域和模型特定的统计数据、引导方法以及手动或基于LLM的解释来分析其语义和相关性。我们的方法提供了关于不同模型生成的文本与人类写作内容之间差异的宝贵见解。我们展示了现代LLMs在信息密集领域具有独特的写作风格，即使它们可以通过个性化提示生成类似人类的输出。

Suízhe dàxíng yǔyán móxíng (LLMs) de jìnbù, réngōng wénběn jiǎncè (ATD) biàn dé yuèláiyuè zhòngyào. Jǐnguǎn yǒu xǔduō nǔlì, dàn méiyǒu yīgè suànfǎ néng zài bùtóng lèixíng de wèizhī wénběn zhōng biǎoxiàn yīzhì, huò bǎozhèng yǒuxiào de fànhuà dào xīn de LLMs. Kě jiěshìxìng zài shíxiàn zhè yī mùbiāo zhōng qǐzhe guǎnjiàn zuòyòng. Zài zhè xiàng yánjiū zhōng, wǒmen tōngguò shǐyòng xīshū zìbiānmǎqì (SAE) cóng Gemma-2-2b cánchá liú zhōng tīqu tédiǎn lái zēngqiáng ATD de kě jiěshìxìng. Wǒmen quèdìngle kě jiěshì hé gāoxiào de tédiǎn, tōngguò lǐngyù hé móxíng tèdìng de tǒngjì shùjù, yǐndǎo fāngfǎ yǐjiǎ shǒudòng huò jīyú LLM de jiěshì lái fēnxi qí yùyán hé xiāngguānxìng. Wǒmen de fāngfǎ tígōngle guānyú bùtóng móxíng shēngchéng de wénběn yǔ rénlèi xiězuò nèiróng zhījiān chāyì de bǎoguì jiànshì. Wǒmen zhǎnshìle xiàndài LLMs zài xìnxī mìjié lǐngyù yǒu dútè de xiězuò fēnggé, jíshǐ tāmen kěyǐ tōngguò gèxìnghuà tǐshì shēngchéng lèixí rénlèi de shùchū.
[11.03.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

随着大型语言模型（LLMs）的进步，人工文本检测（ATD）变得越来越重要。尽管有许多努力，但没有一个算法能在不同类型的未知文本中表现一致，或保证有效地泛化到新的LLMs。可解释性在实现这一目标中起着关键作用。在这项研究中，我们通过使用稀疏自编码器（SAE）从Gemma-2-2b残差流中提取特征来增强ATD的可解释性。我们确定了可解释和高效的特征，通过领域和模型特定的统计数据、引导方法以及手动或基于LLM的解释来分析其语义和相关性。我们的方法提供了关于不同模型生成的文本与人类写作内容之间差异的宝贵见解。我们展示了现代LLMs在信息密集领域具有独特的写作风格，即使它们可以通过个性化提示生成类似人类的输出。
[11.03.2025 09:14] Mistral response. {"id": "c3cbf568418f4c4489996e822fc1d147", "object": "chat.completion", "created": 1741684428, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[{'word': '\u968f\u7740', 'pinyin': 'su\u00edzhe', 'trans': 'with'},\n{'word': '\u5927\u578b', 'pinyin': 'd\u00e0x\u00edng', 'trans': 'large-scale'},\n{'word': '\u8bed\u8a00\u6a21\u578b', 'pinyin': 'y\u01d4y\u00e1n m\u00f3x\u00edng', 'trans': 'language model'},\n{'word': '\u8fdb\u6b65', 'pinyin': 'j\u00ecnb\u00f9', 'trans': 'progress'},\n{'word': '\u4eba\u5de5\u6587\u672c\u68c0\u6d4b', 'pinyin': 'r\u00e9ng\u014dng w\u00e9nb\u011bn ji\u01cenc\u00e8', 'trans': 'artificial text detection'},\n{'word': '\u53d8\u5f97', 'pinyin': 'bi\u00e0nd\u00e9', 'trans': 'become'},\n{'word': '\u8d8a\u6765\u8d8a', 'pinyin': 'yu\u00e8l\u00e1iyu\u00e8', 'trans': 'increasingly'},\n{'word': '\u91cd\u8981', 'pinyin': 'zh\u00f2ngy\u00e0o', 'trans': 'important'},\n{'word': '\u5c3d\u7ba1', 'pinyin': 'j\u01d0ngu\u01cen', 'trans': 'although'},\n{'word': '\u52aa\u529b', 'pinyin': 'n\u01d4l\u00ec', 'trans': 'effort'},\n{'word': '\u7b97\u6cd5', 'pinyin': 'su\u00e0nf\u01ce', 'trans': 'algorithm'},\n{'word': '\u4e00\u81f4', 'pinyin': 'y\u012bzh\u00ec', 'trans': 'consistent'},\n{'word': '\u8868\u73b0', 'pinyin': 'bi\u01ceoxi\u00e0n', 'trans': 'performance'},\n{'word': '\u672a\u77e5', 'pinyin': 'w\u00e8izh\u012b', 'trans': 'unknown'},\n{'word': '\u4fdd\u8bc1', 'pinyin': 'b\u01ceozh\u00e8ng', 'trans': 'guarantee'},\n{'word': '\u6709\u6548', 'pinyin': 'y\u01d2uxi\u00e0o', 'trans': 'effective'},\n{'word': '\u6cdb\u5316', 'pinyin': 'f\u00e0nhu\u00e0', 'trans': 'generalize'},\n{'word': '\u53ef\u89e3\u91ca\u6027', 'pinyin': 'k\u011b ji\u011bsh\u00ec x\u00ecng', 'trans': 'interpretability'},\n{'word': '\u8d77\u7740', 'pinyin': 'q\u01d0zhe', 'trans': 'playing'},\n{'word': '\u5173\u952e', 'pinyin': 'gu\u01cenji\u00e0n', 'trans': 'key'},\n{'word': '\u4f5c\u7528', 'pinyin': 'zu\u00f2y\u00f2ng', 'trans': 'role'},\n{'word': '\u7a00\u758f', 'pinyin': 'x\u012bsh\u016b', 'trans': 'sparse'},\n{'word': '\u81ea\u7f16\u7801\u5668', 'pinyin': 'z\u00ecbi\u0101nm\u01ceq\u00ec', 'trans': 'autoencoder'},\n{'word': '\u6b8b\u5dee\u6d41', 'pinyin': 'c\u00e1nch\u0101 li\u00fa', 'trans': 'residual flow'},\n{'word': '\u63d0\u53d6', 'pinyin': 't\u00edq\u01d4', 'trans': 'extract'},\n{'word': '\u7279\u5f81', 'pinyin': 't\u00e8zh\u0113ng', 'trans': 'feature'},\n{'word': '\u589e\u5f3a', 'pinyin': 'z\u0113ngqi\u00e1ng', 'trans': 'enhance'},\n{'word': '\u9886\u57df', 'pinyin': 'l\u01d0ngy\u00f9', 'trans': 'domain'},\n{'word': '\u7edf\u8ba1\u6570\u636e', 'pinyin': 't\u01d2ngj\u00ec sh\u00f9j\u00f9', 'trans': 'statistical data'},\n{'word': '\u5f15\u5bfc\u65b9\u6cd5', 'pinyin': 'y\u01d0nd\u01ceo f\u0101ngf\u01ce', 'trans': 'guidance method'},\n{'word': '\u624b\u52a8', 'pinyin': 'sh\u01d2ud\u00f2ng', 'trans': 'manual'},\n{'word': '\u57fa\u4e8e', 'pinyin': 'j\u012by\u00fa', 'trans': 'based on'},\n{'word': '\u89e3\u91ca', 'pinyin': 'ji\u011bsh\u00ec', 'trans': 'explanation'},\n{'word': '\u8bed\u4e49', 'pinyin': 'y\u01d4y\u00ec', 'trans': 'semantics'},\n{'word': '\u76f8\u5173\u6027', 'pinyin': 'xi\u0101nggu\u0101nx\u00ecng', 'trans': 'relevance'},\n{'word': '\u89c1\u89e3', 'pinyin': 'ji\u00e0nji\u011b', 'trans': 'insight'},\n{'word': '\u5dee\u5f02', 'pinyin': 'ch\u0101y\u00ec', 'trans': 'difference'},\n{'word': '\u5185\u5bb9', 'pinyin': 'n\u00e8ir\u00f3ng', 'trans': 'content'},\n{'word': '\u5c55\u793a', 'pinyin': 'zh\u01censh\u00ec', 'trans': 'demonstrate'},\n{'word': '\u4fe1\u606f\u5bc6\u96c6', 'pinyin': 'x\u00ecnx\u012b m\u00ecj\u00ed', 'trans': 'information-intensive'},\n{'word': '\u72ec\u7279', 'pinyin': 'd\u00fat\u00e8', 'trans': 'unique'},\n{'word': '\u5199\u4f5c\u98ce\u683c', 'pinyin': 'xi\u011bzu\u00f2 f\u0113ngg\u00e9', 'trans': 'writing style'},\n{'word': '\u4e2a\u6027\u5316', 'pinyin': 'g\u00e8x\u00ecnghu\u00e0', 'trans': 'personalized'},\n{'word': '\u63d0\u793a', 'pinyin': 't\u00edsh\u00ec', 'trans': 'prompt'},\n{'word': '\u8f93\u51fa', 'pinyin': 'sh\u016bch\u016b', 'trans': 'output'}]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 346, "total_tokens": 1630, "completion_tokens": 1284}}
[11.03.2025 09:14] Response: [{'word': '随着', 'pinyin': 'suízhe', 'trans': 'with'},
{'word': '大型', 'pinyin': 'dàxíng', 'trans': 'large-scale'},
{'word': '语言模型', 'pinyin': 'yǔyán móxíng', 'trans': 'language model'},
{'word': '进步', 'pinyin': 'jìnbù', 'trans': 'progress'},
{'word': '人工文本检测', 'pinyin': 'réngōng wénběn jiǎncè', 'trans': 'artificial text detection'},
{'word': '变得', 'pinyin': 'biàndé', 'trans': 'become'},
{'word': '越来越', 'pinyin': 'yuèláiyuè', 'trans': 'increasingly'},
{'word': '重要', 'pinyin': 'zhòngyào', 'trans': 'important'},
{'word': '尽管', 'pinyin': 'jǐnguǎn', 'trans': 'although'},
{'word': '努力', 'pinyin': 'nǔlì', 'trans': 'effort'},
{'word': '算法', 'pinyin': 'suànfǎ', 'trans': 'algorithm'},
{'word': '一致', 'pinyin': 'yīzhì', 'trans': 'consistent'},
{'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'},
{'word': '未知', 'pinyin': 'wèizhī', 'trans': 'unknown'},
{'word': '保证', 'pinyin': 'bǎozhèng', 'trans': 'guarantee'},
{'word': '有效', 'pinyin': 'yǒuxiào', 'trans': 'effective'},
{'word': '泛化', 'pinyin': 'fànhuà', 'trans': 'generalize'},
{'word': '可解释性', 'pinyin': 'kě jiěshì xìng', 'trans': 'interpretability'},
{'word': '起着', 'pinyin': 'qǐzhe', 'trans': 'playing'},
{'word': '关键', 'pinyin': 'guǎnjiàn', 'trans': 'key'},
{'word': '作用', 'pinyin': 'zuòyòng', 'trans': 'role'},
{'word': '稀疏', 'pinyin': 'xīshū', 'trans': 'sparse'},
{'word': '自编码器', 'pinyin': 'zìbiānmǎqì', 'trans': 'autoencoder'},
{'word': '残差流', 'pinyin': 'cánchā liú', 'trans': 'residual flow'},
{'word': '提取', 'pinyin': 'tíqǔ', 'trans': 'extract'},
{'word': '特征', 'pinyin': 'tèzhēng', 'trans': 'feature'},
{'word': '增强', 'pinyin': 'zēngqiáng', 'trans': 'enhance'},
{'word': '领域', 'pinyin': 'lǐngyù', 'trans': 'domain'},
{'word': '统计数据', 'pinyin': 'tǒngjì shùjù', 'trans': 'statistical data'},
{'word': '引导方法', 'pinyin': 'yǐndǎo fāngfǎ', 'trans': 'guidance method'},
{'word': '手动', 'pinyin': 'shǒudòng', 'trans': 'manual'},
{'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'},
{'word': '解释', 'pinyin': 'jiěshì', 'trans': 'explanation'},
{'word': '语义', 'pinyin': 'yǔyì', 'trans': 'semantics'},
{'word': '相关性', 'pinyin': 'xiāngguānxìng', 'trans': 'relevance'},
{'word': '见解', 'pinyin': 'jiànjiě', 'trans': 'insight'},
{'word': '差异', 'pinyin': 'chāyì', 'trans': 'difference'},
{'word': '内容', 'pinyin': 'nèiróng', 'trans': 'content'},
{'word': '展示', 'pinyin': 'zhǎnshì', 'trans': 'demonstrate'},
{'word': '信息密集', 'pinyin': 'xìnxī mìjí', 'trans': 'information-intensive'},
{'word': '独特', 'pinyin': 'dútè', 'trans': 'unique'},
{'word': '写作风格', 'pinyin': 'xiězuò fēnggé', 'trans': 'writing style'},
{'word': '个性化', 'pinyin': 'gèxìnghuà', 'trans': 'personalized'},
{'word': '提示', 'pinyin': 'tíshì', 'trans': 'prompt'},
{'word': '输出', 'pinyin': 'shūchū', 'trans': 'output'}]
[11.03.2025 09:14] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

随着大型语言模型（LLMs）的进步，人工文本检测（ATD）变得越来越重要。尽管有许多努力，但没有一个算法能在不同类型的未知文本中表现一致，或保证有效地泛化到新的LLMs。可解释性在实现这一目标中起着关键作用。在这项研究中，我们通过使用稀疏自编码器（SAE）从Gemma-2-2b残差流中提取特征来增强ATD的可解释性。我们确定了可解释和高效的特征，通过领域和模型特定的统计数据、引导方法以及手动或基于LLM的解释来分析其语义和相关性。我们的方法提供了关于不同模型生成的文本与人类写作内容之间差异的宝贵见解。我们展示了现代LLMs在信息密集领域具有独特的写作风格，即使它们可以通过个性化提示生成类似人类的输出。
[11.03.2025 09:14] Mistral response. {"id": "060eb634d35c41ce9d517b83d5753e25", "object": "chat.completion", "created": 1741684451, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "With the advancement of large language models (LLMs), artificial text detection (ATD) has become increasingly important. Despite numerous efforts, no single algorithm has been able to perform consistently across different types of unknown texts or guarantee effective generalization to new LLMs. Explainability plays a crucial role in achieving this goal. In this research, we enhance the explainability of ATD by extracting features from the residual stream of Gemma-2-2b using sparse autoencoders (SAE). We identify interpretable and efficient features and analyze their semantics and relevance through domain- and model-specific statistics, guided methods, and manual or LLM-based explanations. Our approach provides valuable insights into the differences between texts generated by different models and human-written content. We demonstrate that modern LLMs have a unique writing style in information-intensive domains, even though they can generate human-like outputs through personalized prompts."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 312, "total_tokens": 508, "completion_tokens": 196}}
[11.03.2025 09:14] Response: With the advancement of large language models (LLMs), artificial text detection (ATD) has become increasingly important. Despite numerous efforts, no single algorithm has been able to perform consistently across different types of unknown texts or guarantee effective generalization to new LLMs. Explainability plays a crucial role in achieving this goal. In this research, we enhance the explainability of ATD by extracting features from the residual stream of Gemma-2-2b using sparse autoencoders (SAE). We identify interpretable and efficient features and analyze their semantics and relevance through domain- and model-specific statistics, guided methods, and manual or LLM-based explanations. Our approach provides valuable insights into the differences between texts generated by different models and human-written content. We demonstrate that modern LLMs have a unique writing style in information-intensive domains, even though they can generate human-like outputs through personalized prompts.
[11.03.2025 09:14] Renaming data file.
[11.03.2025 09:14] Renaming previous data. hf_papers.json to ./d/2025-03-11.json
[11.03.2025 09:14] Saving new data file.
[11.03.2025 09:14] Generating page.
[11.03.2025 09:14] Renaming previous page.
[11.03.2025 09:14] Renaming previous data. index.html to ./d/2025-03-11.html
[11.03.2025 09:14] [Experimental] Generating Chinese page for reading.
[11.03.2025 09:14] Chinese vocab [{'word': '随着', 'pinyin': 'suízhe', 'trans': 'with'}, {'word': '大型', 'pinyin': 'dàxíng', 'trans': 'large-scale'}, {'word': '语言模型', 'pinyin': 'yǔyán móxíng', 'trans': 'language model'}, {'word': '进步', 'pinyin': 'jìnbù', 'trans': 'progress'}, {'word': '人工文本检测', 'pinyin': 'réngōng wénběn jiǎncè', 'trans': 'artificial text detection'}, {'word': '变得', 'pinyin': 'biàndé', 'trans': 'become'}, {'word': '越来越', 'pinyin': 'yuèláiyuè', 'trans': 'increasingly'}, {'word': '重要', 'pinyin': 'zhòngyào', 'trans': 'important'}, {'word': '尽管', 'pinyin': 'jǐnguǎn', 'trans': 'although'}, {'word': '努力', 'pinyin': 'nǔlì', 'trans': 'effort'}, {'word': '算法', 'pinyin': 'suànfǎ', 'trans': 'algorithm'}, {'word': '一致', 'pinyin': 'yīzhì', 'trans': 'consistent'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '未知', 'pinyin': 'wèizhī', 'trans': 'unknown'}, {'word': '保证', 'pinyin': 'bǎozhèng', 'trans': 'guarantee'}, {'word': '有效', 'pinyin': 'yǒuxiào', 'trans': 'effective'}, {'word': '泛化', 'pinyin': 'fànhuà', 'trans': 'generalize'}, {'word': '可解释性', 'pinyin': 'kě jiěshì xìng', 'trans': 'interpretability'}, {'word': '起着', 'pinyin': 'qǐzhe', 'trans': 'playing'}, {'word': '关键', 'pinyin': 'guǎnjiàn', 'trans': 'key'}, {'word': '作用', 'pinyin': 'zuòyòng', 'trans': 'role'}, {'word': '稀疏', 'pinyin': 'xīshū', 'trans': 'sparse'}, {'word': '自编码器', 'pinyin': 'zìbiānmǎqì', 'trans': 'autoencoder'}, {'word': '残差流', 'pinyin': 'cánchā liú', 'trans': 'residual flow'}, {'word': '提取', 'pinyin': 'tíqǔ', 'trans': 'extract'}, {'word': '特征', 'pinyin': 'tèzhēng', 'trans': 'feature'}, {'word': '增强', 'pinyin': 'zēngqiáng', 'trans': 'enhance'}, {'word': '领域', 'pinyin': 'lǐngyù', 'trans': 'domain'}, {'word': '统计数据', 'pinyin': 'tǒngjì shùjù', 'trans': 'statistical data'}, {'word': '引导方法', 'pinyin': 'yǐndǎo fāngfǎ', 'trans': 'guidance method'}, {'word': '手动', 'pinyin': 'shǒudòng', 'trans': 'manual'}, {'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'}, {'word': '解释', 'pinyin': 'jiěshì', 'trans': 'explanation'}, {'word': '语义', 'pinyin': 'yǔyì', 'trans': 'semantics'}, {'word': '相关性', 'pinyin': 'xiāngguānxìng', 'trans': 'relevance'}, {'word': '见解', 'pinyin': 'jiànjiě', 'trans': 'insight'}, {'word': '差异', 'pinyin': 'chāyì', 'trans': 'difference'}, {'word': '内容', 'pinyin': 'nèiróng', 'trans': 'content'}, {'word': '展示', 'pinyin': 'zhǎnshì', 'trans': 'demonstrate'}, {'word': '信息密集', 'pinyin': 'xìnxī mìjí', 'trans': 'information-intensive'}, {'word': '独特', 'pinyin': 'dútè', 'trans': 'unique'}, {'word': '写作风格', 'pinyin': 'xiězuò fēnggé', 'trans': 'writing style'}, {'word': '个性化', 'pinyin': 'gèxìnghuà', 'trans': 'personalized'}, {'word': '提示', 'pinyin': 'tíshì', 'trans': 'prompt'}, {'word': '输出', 'pinyin': 'shūchū', 'trans': 'output'}]
[11.03.2025 09:14] Renaming previous Chinese page.
[11.03.2025 09:14] Renaming previous data. zh.html to ./d/2025-03-10_zh_reading_task.html
[11.03.2025 09:14] Writing Chinese reading task.
[11.03.2025 09:14] Writing result.
[11.03.2025 09:14] Renaming log file.
[11.03.2025 09:14] Renaming previous data. log.txt to ./logs/2025-03-11_last_log.txt
