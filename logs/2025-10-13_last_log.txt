[13.10.2025 12:22] Read previous papers.
[13.10.2025 12:22] Generating top page (month).
[13.10.2025 12:22] Writing top page (month).
[13.10.2025 13:25] Read previous papers.
[13.10.2025 13:25] Get feed.
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08673
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05684
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04533
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09201
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09558
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08189
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06499
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09606
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08457
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09608
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09426
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08696
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06274
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07959
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04759
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09517
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09510
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08697
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09577
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08867
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08525
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08047
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07745
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09592
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09507
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05608
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09535
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09462
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08872
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07861
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02898
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09561
[13.10.2025 13:25] Extract page data from URL. URL: https://huggingface.co/papers/2510.09320
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08994
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07896
[13.10.2025 13:25] Extract page data from URL. URL: https://huggingface.co/papers/2510.08649
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07319
[13.10.2025 13:25] Extract page data from URL. URL: https://huggingface.co/papers/2510.07151
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01119
[13.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08492
[13.10.2025 13:25] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[13.10.2025 13:25] No deleted papers detected.
[13.10.2025 13:25] Downloading and parsing papers (pdf, html). Total: 40.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08673.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08673.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08673.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.05684.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.05684.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.05684.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.04533.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.04533.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.04533.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09201.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09201.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09201.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09558.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09558.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09558.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08189.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08189.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08189.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06499.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06499.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06499.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09606.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09606.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09606.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08457.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08457.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08457.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09608.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09608.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09608.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09426.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09426.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09426.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08696.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08696.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08696.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06274.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06274.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06274.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07959.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07959.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07959.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.04759.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.04759.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.04759.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09517.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09517.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09517.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09510.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09510.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09510.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08697.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08697.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08697.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09577.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09577.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09577.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08867.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08867.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08867.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08525.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08525.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08525.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08047.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08047.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08047.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07745.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07745.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07745.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09592.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09592.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09592.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09507.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09507.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09507.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.05608.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.05608.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.05608.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09535.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09535.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09535.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09462.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09462.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09462.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08872.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08872.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08872.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07861.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07861.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07861.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.02898.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.02898.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.02898.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09561.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.09561.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.09561.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.09320.
[13.10.2025 13:25] Downloading paper 2510.09320 from http://arxiv.org/pdf/2510.09320v1...
[13.10.2025 13:25] Extracting affiliations from text.
[13.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 1 ] . [ 1 0 2 3 9 0 . 0 1 5 2 : r Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation Wenyao Zhang123* Hongsi Liu234 Bohan Li123 Yunnan Wang123 Shengyang Zhao23 Xinqiang Yu Jiawei He5 Wenjun Zeng23 Zekun Qi6 Xin Jin23 1MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University 2Ningbo Institute of Digital Twin, Eastern Institute of Technology, Ningbo, China 3Ningbo Key Laboratory of Spatial Intelligence and Digital Derivative, Ningbo, China 6Tsinghua University 4University of Science and Technology of China 5CASIA "
[13.10.2025 13:25] Response: ```python
[
    "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University",
    "Ningbo Institute of Digital Twin, Eastern Institute of Technology, Ningbo, China",
    "Ningbo Key Laboratory of Spatial Intelligence and Digital Derivative, Ningbo, China",
    "Tsinghua University",
    "University of Science and Technology of China",
    "CASIA"
]
```
[13.10.2025 13:25] Deleting PDF ./assets/pdf/2510.09320.pdf.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08994.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08994.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08994.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07896.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07896.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07896.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08649.
[13.10.2025 13:25] Downloading paper 2510.08649 from http://arxiv.org/pdf/2510.08649v1...
[13.10.2025 13:25] Extracting affiliations from text.
[13.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Gustave Cortal1,2, Alain Finkel1, 1Université Paris-Saclay, CNRS, ENS Paris-Saclay, LMF, 91190, Gif-sur-Yvette, France 2Université Paris-Saclay, CNRS, LISN, 91400, Orsay, France {gustave.cortal, alain.finkel}@ens-paris-saclay.fr 5 2 0 2 9 ] . [ 1 9 4 6 8 0 . 0 1 5 2 : r a "
[13.10.2025 13:25] Response: ```python
["Université Paris-Saclay, CNRS, ENS Paris-Saclay, LMF, 91190, Gif-sur-Yvette, France", "Université Paris-Saclay, CNRS, LISN, 91400, Orsay, France"]
```
[13.10.2025 13:25] Deleting PDF ./assets/pdf/2510.08649.pdf.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07319.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07319.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07319.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07151.
[13.10.2025 13:25] Downloading paper 2510.07151 from http://arxiv.org/pdf/2510.07151v1...
[13.10.2025 13:25] Extracting affiliations from text.
[13.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 ] . [ 1 1 5 1 7 0 . 0 1 5 2 : r ELMUR: EXTERNAL LAYER MEMORY WITH UPDATE/REWRITE FOR LONG-HORIZON RL Egor Cherepanov1,2 Alexey K. Kovalev1,2 Aleksandr I. Panov1,2 1 Cognitive AI Lab, Moscow, Russia 2 IAI MIPT, Moscow, Russia {cherepanov, kovalev, panov}@iaipht.ru elmur-paper.github.io ABSTRACT Real-world robotic agents must act under partial observability and long horizons, where key cues may appear long before they affect decision making. However, most modern approaches rely solely on instantaneous information, without incorporating insights from the past. Standard recurrent or transformer models struggle with retaining and leveraging long-term dependencies: context windows truncate history, while naive memory extensions fail under scale and sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), transformer architecture with structured external memory. Each layer maintains memory embeddings, interacts with them via bidirectional cross-attention, and updates them through an Least Recently Used (LRU) memory module using replacement or convex blending. ELMUR extends effective horizons up to 100,000 times beyond the attention window and achieves 100% success rate on synthetic T-Maze task with corridors up to one million steps. In POPGym, it outperforms baselines on more than half of the tasks. On MIKASA-Robo sparse-reward manipulation tasks with visual observations, it nearly doubles the performance of strong baselines. These results demonstrate that structured, layer-local external memory offers simple and scalable approach to decision making under partial observability. Imagine robot cooking pasta: it stirs once, adds salt, and later adds salt again, repeating until the dish is inedible. The issue is simple: the robot cannot remember if salt was already added, since it dissolves invisibly, nor how much is still in the container. This is case of partial observability the world rarely reveals all necessary information. Humans recall past acti"
[13.10.2025 13:25] Response: ```python
["Cognitive AI Lab, Moscow, Russia", "IAI MIPT, Moscow, Russia"]
```
[13.10.2025 13:25] Deleting PDF ./assets/pdf/2510.07151.pdf.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.01119.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.01119.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.01119.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.08492.
[13.10.2025 13:25] Extra JSON file exists (./assets/json/2510.08492.json), skip PDF parsing.
[13.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.08492.json), skip HTML parsing.
[13.10.2025 13:25] Success.
[13.10.2025 13:25] Enriching papers with extra data.
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 0. Puffin, a unified multimodal model, integrates language regression and diffusion-based generation to enhance camera-centric spatial understanding and generation by treating camera parameters as language.  					AI-generated summary 				 Camera-centric understanding and generation are two cornerstones...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 1. D2E framework uses desktop interactions to pretrain embodied AI, achieving high success rates in physical manipulation and navigation tasks.  					AI-generated summary 				 Large language models leverage internet-scale text data, yet embodied AI remains constrained by the prohibitive costs of physic...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 2. Tangential Amplifying Guidance (TAG) improves diffusion model sample quality by directly amplifying tangential components of estimated scores without modifying the model architecture.  					AI-generated summary 				 Recent diffusion models achieve the state-of-the-art performance in image generation...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 3. Multimodal Prompt Optimizer (MPO) extends prompt optimization to handle multiple data types, improving performance over text-only methods in various applications.  					AI-generated summary 				 Large Language Models (LLMs) have shown remarkable success, and their multimodal expansions (MLLMs) furth...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 4. AutoPR, a multi-agent framework, automates the promotion of research papers by transforming them into engaging public content, significantly improving engagement metrics compared to direct LLM pipelines.  					AI-generated summary 				 As the volume of peer-reviewed research surges, scholars increas...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 5. R-HORIZON, a method using query composition, improves long-horizon reasoning in Large Reasoning Models through a benchmark of complex multi-step tasks, enhancing performance and accuracy.  					AI-generated summary 				 Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1, DeepSe...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 6. A scalable data engine converts large-scale pre-training documents into diverse question-answer pairs for reinforcement learning, significantly improving model performance and efficiency.  					AI-generated summary 				 Large Language Models (LLMs) have achieved remarkable success through imitation ...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 7. A spatial reasoning model using scale-aware experts and progressive rewards demonstrates competitive performance across diverse tasks and scales using a large, curated dataset.  					AI-generated summary 				 With the current surge in spatial reasoning explorations, researchers have made significant...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 8. ARES, a unified framework for adaptive reasoning, dynamically adjusts exploration effort based on task difficulty using high window-entropy tokens and hierarchical entropy rewards, improving performance and efficiency across various benchmarks.  					AI-generated summary 				 Recent advances in mult...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 9. StreamingVLM is a real-time vision-language model that efficiently processes infinite video streams using a compact KV cache and supervised fine-tuning, achieving high performance on long videos and diverse benchmarks.  					AI-generated summary 				 Vision-language models (VLMs) could power real-ti...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 10. A large-scale investigation into constructing a fully open bilingual LLM for Korean using synthetic data demonstrates that such data can sustain pretraining and achieve performance comparable to multilingual baselines.  					AI-generated summary 				 This work presents the first large-scale investig...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 11. LENS modifies GRPO by assigning confidence-dependent rewards to incorrect responses, improving efficiency and performance in reinforcement learning with verifiable rewards.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has become a standard recipe for improvin...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 12. A framework called Complexity Out of Distribution (Complexity OoD) is proposed to define and measure reasoning ability in AI models by evaluating their performance on test instances requiring higher solution complexity than training examples.  					AI-generated summary 				 Recent progress has pushe...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 13. A method called DISCO selects samples with the greatest model disagreements to predict performance, achieving state-of-the-art results across various benchmarks with reduced computational cost.  					AI-generated summary 				 Evaluating modern machine learning models has become prohibitively expensi...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 14. PG-Occ, a Progressive Gaussian Transformer Framework, enhances 3D occupancy prediction with progressive densification and anisotropy-aware sampling, achieving state-of-the-art performance.  					AI-generated summary 				 The 3D occupancy prediction task has witnessed remarkable progress in recent ye...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 15. StatEval is a comprehensive benchmark for statistical reasoning, covering foundational and research-level problems, and highlights the limitations of current LLMs in this domain.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable advances in mathematical and lo...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 16. MRMR is a benchmark for expert-level multidisciplinary multimodal retrieval that includes reasoning-intensive tasks, contradiction retrieval, and image-text interleaved sequences, highlighting the need for improved multimodal models.  					AI-generated summary 				 We introduce MRMR, the first exper...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 17. BigCodeArena is an open human evaluation platform for code generation that enables real-time execution and interaction, revealing preferences and capabilities of LLMs in coding tasks.  					AI-generated summary 				 Crowdsourced model evaluation platforms, such as Chatbot Arena, enable real-time eva...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 18. Introducing Dyna-Mind, a two-stage training framework that enhances AI agents' reasoning and planning abilities through simulation, leading to improved performance in complex interactive environments.  					AI-generated summary 				 Reasoning models have recently shown remarkable progress in domains...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 19. ReviewerToo, a modular AI-assisted peer review framework, complements human judgment with systematic assessments, achieving high accuracy and quality in specific domains while highlighting areas where human expertise remains essential.  					AI-generated summary 				 Peer review is the cornerstone o...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 20. A reinforcement learning framework identifies and prioritizes critical attention heads for efficient KV cache compression in large language models, maintaining reasoning quality with reduced overhead.  					AI-generated summary 				 Reasoning large language models exhibit complex reasoning behaviors...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 21. A parameter-space correction method reduces Word Error Rate in ASR systems by addressing pseudo-label biases without target ground truth.  					AI-generated summary 				 Robust ASR under domain shift is crucial because real-world systems encounter unseen accents and domains with limited labeled data...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 22. Parallel test-time scaling is enabled for latent reasoning models using uncertainty-inspired sampling strategies and a Latent Reward Model for effective trajectory selection.  					AI-generated summary 				 Parallel test-time scaling (TTS) is a pivotal approach for enhancing large language models (L...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 23. Mind-Paced Speaking (MPS) is a brain-inspired framework that enables real-time reasoning and fluent speech generation by dividing the process into a "Formulation Brain" for reasoning and an "Articulation Brain" for speech, achieving high accuracy with low latency.  					AI-generated summary 				 Rea...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 24. PhysToolBench evaluates MLLMs' comprehension of physical tools through a VQA dataset, revealing significant deficiencies in tool understanding.  					AI-generated summary 				 The ability to use, understand, and create tools is a hallmark of human intelligence, enabling sophisticated interaction wit...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 25. A plan-and-execute framework with EAGLET enhances LLM-based agents' planning abilities, achieving state-of-the-art performance in long-horizon tasks with reduced training costs.  					AI-generated summary 				 Agents based on large language models (LLMs) struggle with brainless trial-and-error and g...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 26. Group Relative Segment Penalization (GRSP) improves token efficiency in large reasoning models without significantly reducing accuracy, especially for complex problems, by regularizing reasoning at the step level.  					AI-generated summary 				 Large reasoning models (LRMs) boosted by Reinforcement...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 27. Adaptive attacks on AI control protocols using prompt injections can evade monitors and complete malicious tasks, highlighting a significant vulnerability in current security mechanisms.  					AI-generated summary 				 AI control protocols serve as a defense mechanism to stop untrusted LLM agents fr...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 28. Game-Theoretic Alignment (GTAlign) improves Large Language Model (LLM) performance by integrating game-theoretic decision making into reasoning and training, enhancing efficiency, answer quality, and mutual welfare.  					AI-generated summary 				 Large Language Models (LLMs) have achieved remarkabl...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 29. A framework evaluates DeepResearch systems by assessing the quality, redundancy, and factuality of their research reports using an LLM-as-a-Judge methodology.  					AI-generated summary 				 DeepResearch agents represent a transformative AI paradigm, conducting expert-level research through sophisti...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 30. A patch-centric framework for zero-shot captioning achieves state-of-the-art performance by using dense visual features from models like DINO to caption arbitrary image regions.  					AI-generated summary 				 Zero-shot captioners are recently proposed models that utilize common-space vision-languag...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 31. TC-LoRA enhances generative fidelity and adherence to spatial conditions by dynamically conditioning model weights through a hypernetwork, improving upon static activation-based methods in diffusion models.  					AI-generated summary 				 Current controllable diffusion models typically rely on fixed...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 32. Hybrid-depth framework integrates CLIP and DINO with language guidance to enhance self-supervised monocular depth estimation by addressing semantic and spatial feature mismatches.  					AI-generated summary 				 Current self-supervised monocular depth estimation (MDE) approaches encounter performanc...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 33. Speculative Jacobi-Denoising Decoding accelerates autoregressive text-to-image generation by enabling parallel token prediction and reducing model forward passes.  					AI-generated summary 				 As a new paradigm of visual content generation, autoregressive text-to-image models suffer from slow infe...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 34. ACE, a framework using neuron-level attribution, enhances multi-hop factual recall in LLMs by editing critical query-value pathways, outperforming existing methods.  					AI-generated summary 				 Large Language Models (LLMs) require efficient knowledge editing (KE) to update factual information, ye...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 35. A novel framework integrates functional linguistics, computer science, and psychology to analyze stylistic choices in personal narratives, revealing patterns linked to psychological states.  					AI-generated summary 				 Personal narratives are stories authors construct to make meaning of their exp...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 36. The Tenet framework decomposes the RVOS task into referring, video, and segmentation factors, using temporal prompts and prompt preference learning to adapt image-based foundation segmentation models for efficient RVOS.  					AI-generated summary 				 Referring Video Object Segmentation (RVOS) aims ...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 37. ELMUR, a transformer with structured external memory, enhances decision-making under partial observability by extending effective horizons and improving performance on various tasks.  					AI-generated summary 				 Real-world robotic agents must act under partial observability and long horizons, whe...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 38. Instant4D uses deep visual SLAM and a 4D Gaussian representation to efficiently reconstruct scenes from uncalibrated video sequences in minutes.  					AI-generated summary 				 Dynamic view synthesis has seen significant advances, yet reconstructing scenes from uncalibrated, casual video remains cha...
[13.10.2025 13:25] ********************************************************************************
[13.10.2025 13:25] Abstract 39. UML, an unpaired multimodal learner, enhances representation learning in a target modality by leveraging auxiliary unpaired data from different modalities.  					AI-generated summary 				 Traditional multimodal learners find unified representations for tasks like visual question answering, but rely ...
[13.10.2025 13:25] Read previous papers.
[13.10.2025 13:25] Generating reviews via LLM API.
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#dataset", "#multimodal", "#benchmark", "#alignment", "#open_source"], "emoji": "📸", "ru": {"title": "Камера как язык: единая модель для понимания и генерации сцен", "desc": "Puffin — это мультимодальная модель, которая объединяет понимание и генерацию изображен
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#agents", "#transfer_learning", "#robotics", "#games"], "emoji": "🎮", "ru": {"title": "От игр на компьютере к роботам: новый подход к обучению ИИ", "desc": "Исследователи разработали фреймворк D2E, который использует данные взаимодействия че
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#inference", "#optimization", "#hallucinations"], "emoji": "📐", "ru": {"title": "Улучшение генерации через усиление касательных компонент", "desc": "Статья предлагает метод Tangential Amplifying Guidance (TAG) для улучшения качества генерации диффузионных моделе
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#optimization", "#training", "#multimodal"], "emoji": "🎨", "ru": {"title": "Оптимизация промптов для всех модальностей одновременно", "desc": "Статья представляет Multimodal Prompt Optimizer (MPO) — новый подход к оптимизации промптов для мультимодальных языковых моделей (MLLM). В о
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#optimization", "#multimodal", "#alignment"], "emoji": "📢", "ru": {"title": "Автоматическое продвижение научных статей с помощью мультиагентной системы", "desc": "Исследователи представили AutoPR — новую задачу автоматического превращения научных статей в пр
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#long_context", "#training", "#reasoning", "#benchmark", "#rl"], "emoji": "🔭", "ru": {"title": "R-HORIZON: Обучение AI мыслить на дальние дистанции", "desc": "Статья представляет R-HORIZON - метод для оценки и улучшения способности больших языковых моделей к долгосрочному многоэтапн
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#rl", "#data", "#reasoning", "#optimization"], "emoji": "🔄", "ru": {"title": "От текстов к вопросам: масштабирование RL для языковых моделей", "desc": "Исследователи разработали Webscale-RL pipeline — масштабируемый движок данных, который преобразует больши
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#data", "#cv", "#training", "#dataset", "#reasoning", "#survey", "#benchmark", "#optimization"], "emoji": "🔭", "ru": {"title": "Пространственное мышление на всех масштабах: от объектов до городских сцен", "desc": "Исследователи представили SpaceVista-7B — модель для пространственног
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#reasoning", "#benchmark", "#optimization", "#open_source", "#multimodal", "#dataset"], "emoji": "🎯", "ru": {"title": "ARES: Адаптивное мышление AI в зависимости от сложности задачи", "desc": "Статья представляет фреймворк ARES, который решает проблему неэффективного ра
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#cv", "#video", "#long_context", "#training", "#multimodal", "#benchmark", "#optimization", "#agents"], "emoji": "🎬", "ru": {"title": "Бесконечные видеопотоки без перегрузки памяти", "desc": "StreamingVLM - это модель для обработки бесконечных видеопотоков в реальном времени, котора
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#low_resource", "#open_source", "#synthetic", "#data", "#training", "#dataset", "#multilingual"], "emoji": "🇰🇷", "ru": {"title": "Синтетические данные для обучения билингвальных LLM работают не хуже реальных", "desc": "Исследователи создали KORMo-10B — первую полностью открытую били
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#reasoning", "#benchmark", "#rl", "#optimization", "#rlhf"], "emoji": "🔍", "ru": {"title": "Превращая ошибки в уроки: как извлечь пользу из неправильных ответов LLM", "desc": "Статья представляет метод LENS, который улучшает алгоритм GRPO для обучения языковых моделей н
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#reasoning", "#training", "#math", "#benchmark", "#architecture"], "emoji": "🧩", "ru": {"title": "Когда AI учится думать сложнее, чем его учили", "desc": "Авторы предлагают фреймворк Complexity Out of Distribution для определения и измерения способности AI-моделей к рассуждению. Клю
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#data", "#optimization", "#benchmark", "#training"], "emoji": "🎯", "ru": {"title": "Умная выборка через разногласия моделей вместо дорогого полного тестирования", "desc": "Статья представляет метод DISCO для эффективной оценки современных ML-моделей, который значительно снижает вычи
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#3d", "#cv", "#open_source", "#optimization"], "emoji": "🎯", "ru": {"title": "Прогрессивное уплотнение гауссиан для понимания 3D-сцен", "desc": "Статья представляет PG-Occ — фреймворк на основе Gaussian Transformer для предсказания 3D occupancy с поддержкой open-vocabulary запросов.
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#survey", "#reasoning"], "emoji": "📊", "ru": {"title": "StatEval: бенчмарк, который показал слабость LLM в статистике", "desc": "Статья представляет StatEval — первый комплексный бенчмарк для оценки статистического мышления LLM, включающий 13,817 базовых за
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#benchmark", "#games", "#reasoning", "#multimodal"], "emoji": "🔬", "ru": {"title": "Мультимодальный поиск экспертного уровня с глубоким reasoning", "desc": "MRMR — это первый бенчмарк для мультимодального retrieval экспертного уровня, требующий интенсивного reasoning. Он содержит 15
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#games", "#dataset", "#multilingual", "#benchmark", "#open_source"], "emoji": "⚔️", "ru": {"title": "Арена для кода: краудсорсинговая оценка способностей LLM в программировании", "desc": "BigCodeArena — это открытая платформа для оценки генерации кода с помощью людей, которая позвол
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#synthetic", "#training", "#reasoning", "#rl", "#optimization", "#agents"], "emoji": "🎮", "ru": {"title": "Учим AI-агентов думать перед действием через симуляцию", "desc": "Dyna-Mind — это двухэтапный фреймворк для обучения AI-агентов, который улучшает их способность к рассуждению и
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#data", "#dataset", "#multimodal", "#ethics", "#benchmark", "#science"], "emoji": "🔍", "ru": {"title": "AI-рецензент: систематичность машины плюс экспертиза человека", "desc": "В статье представлен ReviewerToo — модульный фреймворк для AI-ассистированного научного рецензирования, ко
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#training", "#inference"], "emoji": "🎯", "ru": {"title": "Умное сжатие памяти: находим важные головы внимания через обучение с подкреплением", "desc": "Reasoning-модели с цепочками рассуждений создают огромный KV-кэш при генерации, а существующи
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#data", "#training", "#low_resource", "#optimization", "#audio"], "emoji": "🗣️", "ru": {"title": "Коррекция параметров для улучшения распознавания речи", "desc": "В статье рассматривается метод коррекции параметров для снижения уровня ошибок в системах распознавания речи (ASR) без и
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#inference", "#architecture", "#reasoning", "#optimization", "#training"], "emoji": "🔍", "ru": {"title": "Новые горизонты масштабирования в латентных моделях рассуждения", "desc": "В статье рассматривается метод параллельного масштабирования во время тестирования для моделей латентн
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#audio", "#reasoning", "#training", "#multimodal"], "emoji": "🧠", "ru": {"title": "Думай и говори одновременно: архитектура двух мозгов для разговорного AI", "desc": "Исследователи представили Mind-Paced Speaking (MPS) — фреймворк, вдохновлённый работой человеческого мозга, который 
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#agi", "#multimodal", "#interpretability", "#open_source"], "emoji": "🔧", "ru": {"title": "Проверка понимания физических инструментов у мультимодальных LLM", "desc": "PhysToolBench — это первый бенчмарк для оценки того, насколько хорошо мультимодальные LLM 
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#rl", "#agents", "#hallucinations", "#reasoning", "#optimization", "#training", "#long_context"], "emoji": "🦅", "ru": {"title": "EAGLET: умный планировщик для LLM-агентов без лишних затрат", "desc": "Исследователи предложили фреймворк plan-and-execute с методом EAGLET для улучшения 
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#training", "#optimization"], "emoji": "✂️", "ru": {"title": "Эффективное мышление: как научить AI рассуждать короче, но не глупее", "desc": "Большие модели рассуждений (LRM) часто страдают от «overthinking» — избыточных рассуждений, которые увеличивают вычислит
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#agents", "#security", "#benchmark"], "emoji": "🎭", "ru": {"title": "Prompt injection как универсальное оружие против AI-мониторов", "desc": "Исследование выявило критическую уязвимость в протоколах контроля AI, которые используют LLM-мониторы для предотвращения вредоносных действий
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#rlhf", "#alignment", "#training", "#reasoning"], "emoji": "🎮", "ru": {"title": "Когда LLM играет в игры с пользователем: теоретико-игровой alignment", "desc": "Статья представляет GTAlign — новый подход к alignment LLM, основанный на теории игр. Авторы решают проблему, когда модель
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#reasoning", "#optimization", "#survey"], "emoji": "🔬", "ru": {"title": "Оценка AI-исследователей: как измерить качество глубокого анализа", "desc": "Статья представляет DeepResearch-ReportEval — фреймворк для оценки AI-систем, способных проводить глубокие и
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#games", "#multimodal", "#cv"], "emoji": "🧩", "ru": {"title": "От целого изображения к патчам: новая эра zero-shot описаний", "desc": "Исследователи предложили новый подход к генерации описаний изображений без обучения на парах картинка-текст, сместив фокус с целого изображения на о
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#cv", "#training", "#diffusion", "#optimization", "#architecture"], "emoji": "🎛️", "ru": {"title": "Динамическая настройка весов для адаптивного контроля диффузионных моделей", "desc": "TC-LoRA представляет новый подход к управлению диффузионными моделями через динамическое изменени
[13.10.2025 13:25] Querying the API.
[13.10.2025 13:25] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Hybrid-depth framework integrates CLIP and DINO with language guidance to enhance self-supervised monocular depth estimation by addressing semantic and spatial feature mismatches.  					AI-generated summary 				 Current self-supervised monocular depth estimation (MDE) approaches encounter performance limitations due to insufficient semantic-spatial knowledge extraction. To address this challenge, we propose Hybrid-depth, a novel framework that systematically integrates foundation models (e.g., CLIP and DINO) to extract visual priors and acquire sufficient contextual information for MDE. Our approach introduces a coarse-to-fine progressive learning framework: 1) Firstly, we aggregate multi-grained features from CLIP (global semantics) and DINO (local spatial details) under contrastive language guidance. A proxy task comparing close-distant image patches is designed to enforce depth-aware feature alignment using text prompts; 2) Next, building on the coarse features, we integrate camera pose information and pixel-wise language alignment to refine depth predictions. This module seamlessly integrates with existing self-supervised MDE pipelines (e.g., Monodepth2, ManyDepth) as a plug-and-play depth encoder, enhancing continuous depth estimation. By aggregating CLIP's semantic context and DINO's spatial details through language guidance, our method effectively addresses feature granularity mismatches. Extensive experiments on the KITTI benchmark demonstrate that our method significantly outperforms SOTA methods across all metrics, which also indeed benefits downstream tasks like BEV perception. Code is available at https://github.com/Zhangwenyao1/Hybrid-depth.
[13.10.2025 13:25] Response: ```json
{
  "title": "Гибридная глубина: объединение семантики и деталей для оценки расстояний",
  "desc": "Статья представляет Hybrid-depth — новый подход к самообучаемой оценке глубины по одному изображению, который объединяет foundation models CLIP и DINO. Метод использует языковые подсказки для согласования глобальных семантических признаков от CLIP с локальными пространственными деталями от DINO в процессе обучения от грубого к точному. Интеграция информации о позе камеры и пиксельное выравнивание с языковыми признаками позволяет уточнить предсказания глубины. Эксперименты на датасете KITTI показывают превосходство над существующими методами и улучшение в задачах вроде BEV-восприятия.",
  "emoji": "🔍",
  "desc": "Статья представляет Hybrid-depth — новый подход к самообучаемой оценке глубины по одному изображению, который объединяет foundation models CLIP и DINO. Метод использует языковые подсказки для согласования глобальных семантических признаков от CLIP с локальными пространственными деталями от DINO в процессе обучения от грубого к точному. Интеграция информации о позе камеры и пиксельное выравнивание с языковыми признаками позволяет уточнить предсказания глубины. Эксперименты на датасете KITTI показывают превосходство над существующими методами и улучшение в задачах вроде BEV-восприятия."
}
```
[13.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hybrid-depth framework integrates CLIP and DINO with language guidance to enhance self-supervised monocular depth estimation by addressing semantic and spatial feature mismatches.  					AI-generated summary 				 Current self-supervised monocular depth estimation (MDE) approaches encounter performance limitations due to insufficient semantic-spatial knowledge extraction. To address this challenge, we propose Hybrid-depth, a novel framework that systematically integrates foundation models (e.g., CLIP and DINO) to extract visual priors and acquire sufficient contextual information for MDE. Our approach introduces a coarse-to-fine progressive learning framework: 1) Firstly, we aggregate multi-grained features from CLIP (global semantics) and DINO (local spatial details) under contrastive language guidance. A proxy task comparing close-distant image patches is designed to enforce depth-aware feature alignment using text prompts; 2) Next, building on the coarse features, we integrate camera pose information and pixel-wise language alignment to refine depth predictions. This module seamlessly integrates with existing self-supervised MDE pipelines (e.g., Monodepth2, ManyDepth) as a plug-and-play depth encoder, enhancing continuous depth estimation. By aggregating CLIP's semantic context and DINO's spatial details through language guidance, our method effectively addresses feature granularity mismatches. Extensive experiments on the KITTI benchmark demonstrate that our method significantly outperforms SOTA methods across all metrics, which also indeed benefits downstream tasks like BEV perception. Code is available at https://github.com/Zhangwenyao1/Hybrid-depth."

[13.10.2025 13:25] Response: ```python
['CV', 'MULTIMODAL', 'BENCHMARK']
```
[13.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hybrid-depth framework integrates CLIP and DINO with language guidance to enhance self-supervised monocular depth estimation by addressing semantic and spatial feature mismatches.  					AI-generated summary 				 Current self-supervised monocular depth estimation (MDE) approaches encounter performance limitations due to insufficient semantic-spatial knowledge extraction. To address this challenge, we propose Hybrid-depth, a novel framework that systematically integrates foundation models (e.g., CLIP and DINO) to extract visual priors and acquire sufficient contextual information for MDE. Our approach introduces a coarse-to-fine progressive learning framework: 1) Firstly, we aggregate multi-grained features from CLIP (global semantics) and DINO (local spatial details) under contrastive language guidance. A proxy task comparing close-distant image patches is designed to enforce depth-aware feature alignment using text prompts; 2) Next, building on the coarse features, we integrate camera pose information and pixel-wise language alignment to refine depth predictions. This module seamlessly integrates with existing self-supervised MDE pipelines (e.g., Monodepth2, ManyDepth) as a plug-and-play depth encoder, enhancing continuous depth estimation. By aggregating CLIP's semantic context and DINO's spatial details through language guidance, our method effectively addresses feature granularity mismatches. Extensive experiments on the KITTI benchmark demonstrate that our method significantly outperforms SOTA methods across all metrics, which also indeed benefits downstream tasks like BEV perception. Code is available at https://github.com/Zhangwenyao1/Hybrid-depth."

[13.10.2025 13:25] Response: ```python
["OPTIMIZATION"]
```
[13.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper presents a new framework called Hybrid-depth that improves self-supervised monocular depth estimation (MDE) by combining the strengths of CLIP and DINO models. It addresses the limitations of current MDE methods by integrating semantic and spatial features through a language-guided approach. The framework employs a coarse-to-fine learning strategy, first aligning multi-grained features and then refining depth predictions using camera pose and pixel-wise language alignment. Experimental results show that Hybrid-depth significantly outperforms state-of-the-art methods, enhancing depth estimation and benefiting related tasks like BEV perception.","title":"Enhancing Depth Estimation with Hybrid-Depth Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper presents a new framework called Hybrid-depth that improves self-supervised monocular depth estimation (MDE) by combining the strengths of CLIP and DINO models. It addresses the limitations of current MDE methods by integrating semantic and spatial features through a language-guided approach. The framework employs a coarse-to-fine learning strategy, first aligning multi-grained features and then refining depth predictions using camera pose and pixel-wise language alignment. Experimental results show that Hybrid-depth significantly outperforms state-of-the-art methods, enhancing depth estimation and benefiting related tasks like BEV perception.', title='Enhancing Depth Estimation with Hybrid-Depth Framework'))
[13.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种名为Hybrid-depth的框架，旨在通过整合CLIP和DINO模型来增强自监督单目深度估计。该方法通过对比语言指导，聚合多层次特征，解决了语义和空间特征不匹配的问题。Hybrid-depth采用粗到细的渐进学习策略，首先提取全局语义和局部空间细节，然后结合相机位姿信息和像素级语言对齐来优化深度预测。实验结果表明，该方法在KITTI基准测试中显著超越了现有的最先进方法，并对下游任务如BEV感知也有积极影响。","title":"融合CLIP与DINO的深度估计新框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种名为Hybrid-depth的框架，旨在通过整合CLIP和DINO模型来增强自监督单目深度估计。该方法通过对比语言指导，聚合多层次特征，解决了语义和空间特征不匹配的问题。Hybrid-depth采用粗到细的渐进学习策略，首先提取全局语义和局部空间细节，然后结合相机位姿信息和像素级语言对齐来优化深度预测。实验结果表明，该方法在KITTI基准测试中显著超越了现有的最先进方法，并对下游任务如BEV感知也有积极影响。', title='融合CLIP与DINO的深度估计新框架'))
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#inference", "#optimization", "#cv", "#video"], "emoji": "🎨", "ru": {"title": "Параллельная генерация изображений через шумоподавление", "desc": "Авторегрессионные модели генерации изображений из текста работают медленно, так как создают токены последовательно, требуя тысячи проходо
[13.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#optimization", "#reasoning", "#architecture", "#data", "#interpretability"], "emoji": "🔗", "ru": {"title": "Редактирование знаний через управление нейронными путями", "desc": "Статья представляет фреймворк ACE для улучшения редактирования знаний в LLM, особенно для мно
[13.10.2025 13:25] Querying the API.
[13.10.2025 13:25] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel framework integrates functional linguistics, computer science, and psychology to analyze stylistic choices in personal narratives, revealing patterns linked to psychological states.  					AI-generated summary 				 Personal narratives are stories authors construct to make meaning of their experiences. Style, the distinctive way authors use language to express themselves, is fundamental to how these narratives convey subjective experiences. Yet there is a lack of a formal framework for systematically analyzing these stylistic choices. We present a novel approach that formalizes style in personal narratives as patterns in the linguistic choices authors make when communicating subjective experiences. Our framework integrates three domains: functional linguistics establishes language as a system of meaningful choices, computer science provides methods for automatically extracting and analyzing sequential patterns, and these patterns are linked to psychological observations. Using language models, we automatically extract linguistic features such as processes, participants, and circumstances. We apply our framework to hundreds of dream narratives, including a case study on a war veteran with post-traumatic stress disorder. Analysis of his narratives uncovers distinctive patterns, particularly how verbal processes dominate over mental ones, illustrating the relationship between linguistic choices and psychological states.
[13.10.2025 13:25] Response: ```json
{
  "title": "Анализ личных историй через призму лингвистики и психологии",
  "desc": "Исследователи создали новый фреймворк для анализа стилистических особенностей личных историй, объединяющий функциональную лингвистику, компьютерные науки и психологию. С помощью языковых моделей система автоматически извлекает лингвистические характеристики текста, такие как процессы, участники и обстоятельства. Фреймворк был применен к сотням записей о снах, включая исследование ветерана войны с посттравматическим стрессовым расстройством. Анализ выявил устойчивые паттерны в языковых выборах, которые коррелируют с психологическими состояниями авторов.",
  "emoji": "📖",
  "desc": "Исследователи создали новый фреймворк для анализа стилистических особенностей личных историй, объединяющий функциональную лингвистику, компьютерные науки и психологию. С помощью языковых моделей система автоматически извлекает лингвистические характеристики текста, такие как процессы, участники и обстоятельства. Фреймворк был применен к сотням записей о снах, включая исследование ветерана войны с посттравматическим стрессовым расстройством. Анализ выявил устойчивые паттерны в языковых выборах, которые коррелируют с психологическими состояниями авторов."
}
```
[13.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework integrates functional linguistics, computer science, and psychology to analyze stylistic choices in personal narratives, revealing patterns linked to psychological states.  					AI-generated summary 				 Personal narratives are stories authors construct to make meaning of their experiences. Style, the distinctive way authors use language to express themselves, is fundamental to how these narratives convey subjective experiences. Yet there is a lack of a formal framework for systematically analyzing these stylistic choices. We present a novel approach that formalizes style in personal narratives as patterns in the linguistic choices authors make when communicating subjective experiences. Our framework integrates three domains: functional linguistics establishes language as a system of meaningful choices, computer science provides methods for automatically extracting and analyzing sequential patterns, and these patterns are linked to psychological observations. Using language models, we automatically extract linguistic features such as processes, participants, and circumstances. We apply our framework to hundreds of dream narratives, including a case study on a war veteran with post-traumatic stress disorder. Analysis of his narratives uncovers distinctive patterns, particularly how verbal processes dominate over mental ones, illustrating the relationship between linguistic choices and psychological states."

[13.10.2025 13:25] Response: ```python
["MULTIMODAL", "DATA"]
```
[13.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework integrates functional linguistics, computer science, and psychology to analyze stylistic choices in personal narratives, revealing patterns linked to psychological states.  					AI-generated summary 				 Personal narratives are stories authors construct to make meaning of their experiences. Style, the distinctive way authors use language to express themselves, is fundamental to how these narratives convey subjective experiences. Yet there is a lack of a formal framework for systematically analyzing these stylistic choices. We present a novel approach that formalizes style in personal narratives as patterns in the linguistic choices authors make when communicating subjective experiences. Our framework integrates three domains: functional linguistics establishes language as a system of meaningful choices, computer science provides methods for automatically extracting and analyzing sequential patterns, and these patterns are linked to psychological observations. Using language models, we automatically extract linguistic features such as processes, participants, and circumstances. We apply our framework to hundreds of dream narratives, including a case study on a war veteran with post-traumatic stress disorder. Analysis of his narratives uncovers distinctive patterns, particularly how verbal processes dominate over mental ones, illustrating the relationship between linguistic choices and psychological states."

[13.10.2025 13:26] Response: ```python
["STORY_GENERATION", "INTERPRETABILITY", "SCIENCE"]
```
[13.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new framework that combines functional linguistics, computer science, and psychology to analyze the stylistic choices in personal narratives. It formalizes the concept of style as patterns in linguistic choices that reflect authors\' subjective experiences. By using language models, the framework automatically extracts features from narratives, allowing for systematic analysis of these patterns. The study demonstrates how these linguistic features can reveal insights into psychological states, particularly through a case study of a war veteran with PTSD.","title":"Unveiling Psychological States Through Linguistic Patterns in Narratives"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces a new framework that combines functional linguistics, computer science, and psychology to analyze the stylistic choices in personal narratives. It formalizes the concept of style as patterns in linguistic choices that reflect authors' subjective experiences. By using language models, the framework automatically extracts features from narratives, allowing for systematic analysis of these patterns. The study demonstrates how these linguistic features can reveal insights into psychological states, particularly through a case study of a war veteran with PTSD.", title='Unveiling Psychological States Through Linguistic Patterns in Narratives'))
[13.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文提出了一个新框架，结合了功能语言学、计算机科学和心理学，分析个人叙事中的风格选择。个人叙事是作者用来表达经历的故事，而风格是作者使用语言的独特方式。该框架系统地分析这些风格选择，揭示了与心理状态相关的模式。通过自动提取语言特征，研究者能够识别出叙事中的语言模式，并探讨这些模式与心理观察之间的关系。","title":"揭示叙事风格与心理状态的关系"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文提出了一个新框架，结合了功能语言学、计算机科学和心理学，分析个人叙事中的风格选择。个人叙事是作者用来表达经历的故事，而风格是作者使用语言的独特方式。该框架系统地分析这些风格选择，揭示了与心理状态相关的模式。通过自动提取语言特征，研究者能够识别出叙事中的语言模式，并探讨这些模式与心理观察之间的关系。', title='揭示叙事风格与心理状态的关系'))
[13.10.2025 13:26] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#video", "#optimization"], "emoji": "🎯", "ru": {"title": "Декомпозиция задачи видеосегментации через временные промпты", "desc": "Статья представляет фреймворк Tenet для задачи сегментации объектов в видео по текстовому описанию (RVOS). Авторы декомпозируют зада
[13.10.2025 13:26] Querying the API.
[13.10.2025 13:26] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ELMUR, a transformer with structured external memory, enhances decision-making under partial observability by extending effective horizons and improving performance on various tasks.  					AI-generated summary 				 Real-world robotic agents must act under partial observability and long horizons, where key cues may appear long before they affect decision making. However, most modern approaches rely solely on instantaneous information, without incorporating insights from the past. Standard recurrent or transformer models struggle with retaining and leveraging long-term dependencies: context windows truncate history, while naive memory extensions fail under scale and sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a transformer architecture with structured external memory. Each layer maintains memory embeddings, interacts with them via bidirectional cross-attention, and updates them through an Least Recently Used (LRU) memory module using replacement or convex blending. ELMUR extends effective horizons up to 100,000 times beyond the attention window and achieves a 100% success rate on a synthetic T-Maze task with corridors up to one million steps. In POPGym, it outperforms baselines on more than half of the tasks. On MIKASA-Robo sparse-reward manipulation tasks with visual observations, it nearly doubles the performance of strong baselines. These results demonstrate that structured, layer-local external memory offers a simple and scalable approach to decision making under partial observability.
[13.10.2025 13:26] Response: ```json
{
  "desc": "ELMUR - это архитектура трансформера со структурированной внешней памятью для принятия решений в условиях частичной наблюдаемости. Каждый слой модели поддерживает собственные эмбеддинги памяти, взаимодействует с ними через двунаправленное cross-attention и обновляет их с помощью LRU-модуля. Модель расширяет эффективный горизонт до 100,000 раз по сравнению с окном attention и достигает 100% успеха на задаче T-Maze с коридорами длиной до миллиона шагов. ELMUR значительно превосходит базовые модели на бенчмарках POPGym и MIKASA-Robo, демонстрируя эффективность локальной послойной внешней памяти для задач с долгосрочными зависимостями.",
  "emoji": "🧠",
  "title": "Внешняя память для трансформеров: миллион шагов - не предел"
}
```
[13.10.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ELMUR, a transformer with structured external memory, enhances decision-making under partial observability by extending effective horizons and improving performance on various tasks.  					AI-generated summary 				 Real-world robotic agents must act under partial observability and long horizons, where key cues may appear long before they affect decision making. However, most modern approaches rely solely on instantaneous information, without incorporating insights from the past. Standard recurrent or transformer models struggle with retaining and leveraging long-term dependencies: context windows truncate history, while naive memory extensions fail under scale and sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a transformer architecture with structured external memory. Each layer maintains memory embeddings, interacts with them via bidirectional cross-attention, and updates them through an Least Recently Used (LRU) memory module using replacement or convex blending. ELMUR extends effective horizons up to 100,000 times beyond the attention window and achieves a 100% success rate on a synthetic T-Maze task with corridors up to one million steps. In POPGym, it outperforms baselines on more than half of the tasks. On MIKASA-Robo sparse-reward manipulation tasks with visual observations, it nearly doubles the performance of strong baselines. These results demonstrate that structured, layer-local external memory offers a simple and scalable approach to decision making under partial observability."

[13.10.2025 13:26] Response: ```python
['ARCHITECTURE', 'ROBOTICS']
```
[13.10.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ELMUR, a transformer with structured external memory, enhances decision-making under partial observability by extending effective horizons and improving performance on various tasks.  					AI-generated summary 				 Real-world robotic agents must act under partial observability and long horizons, where key cues may appear long before they affect decision making. However, most modern approaches rely solely on instantaneous information, without incorporating insights from the past. Standard recurrent or transformer models struggle with retaining and leveraging long-term dependencies: context windows truncate history, while naive memory extensions fail under scale and sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a transformer architecture with structured external memory. Each layer maintains memory embeddings, interacts with them via bidirectional cross-attention, and updates them through an Least Recently Used (LRU) memory module using replacement or convex blending. ELMUR extends effective horizons up to 100,000 times beyond the attention window and achieves a 100% success rate on a synthetic T-Maze task with corridors up to one million steps. In POPGym, it outperforms baselines on more than half of the tasks. On MIKASA-Robo sparse-reward manipulation tasks with visual observations, it nearly doubles the performance of strong baselines. These results demonstrate that structured, layer-local external memory offers a simple and scalable approach to decision making under partial observability."

[13.10.2025 13:26] Response: ```python
["LONG_CONTEXT", "OPTIMIZATION"]
```
[13.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ELMUR is a novel transformer model designed to improve decision-making in situations where not all information is available, known as partial observability. It incorporates structured external memory that allows it to retain and utilize long-term information, overcoming limitations of traditional models that struggle with long dependencies. By using a bidirectional cross-attention mechanism and an efficient memory update system, ELMUR can extend its effective decision-making horizon significantly. The model has shown remarkable performance improvements across various tasks, demonstrating its potential for real-world applications in robotics and beyond.","title":"ELMUR: Transforming Decision-Making with Structured Memory"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ELMUR is a novel transformer model designed to improve decision-making in situations where not all information is available, known as partial observability. It incorporates structured external memory that allows it to retain and utilize long-term information, overcoming limitations of traditional models that struggle with long dependencies. By using a bidirectional cross-attention mechanism and an efficient memory update system, ELMUR can extend its effective decision-making horizon significantly. The model has shown remarkable performance improvements across various tasks, demonstrating its potential for real-world applications in robotics and beyond.', title='ELMUR: Transforming Decision-Making with Structured Memory'))
[13.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ELMUR是一种具有结构化外部记忆的变换器架构，旨在改善在部分可观察性下的决策能力。它通过扩展有效的时间范围和利用历史信息，克服了传统模型在长期依赖性方面的局限。ELMUR在每一层中维护记忆嵌入，并通过双向交叉注意力与之交互，使用最近最少使用（LRU）内存模块进行更新。实验结果表明，ELMUR在多个任务中表现优异，尤其是在处理稀疏奖励的机器人操作任务时，性能几乎是强基线的两倍。","title":"ELMUR：提升决策能力的变换器架构"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ELMUR是一种具有结构化外部记忆的变换器架构，旨在改善在部分可观察性下的决策能力。它通过扩展有效的时间范围和利用历史信息，克服了传统模型在长期依赖性方面的局限。ELMUR在每一层中维护记忆嵌入，并通过双向交叉注意力与之交互，使用最近最少使用（LRU）内存模块进行更新。实验结果表明，ELMUR在多个任务中表现优异，尤其是在处理稀疏奖励的机器人操作任务时，性能几乎是强基线的两倍。', title='ELMUR：提升决策能力的变换器架构'))
[13.10.2025 13:26] Using data from previous issue: {"categories": ["#games", "#cv", "#video", "#dataset", "#inference", "#benchmark", "#optimization"], "emoji": "⚡", "ru": {"title": "Мгновенная 4D реконструкция сцен из обычного видео за минуты", "desc": "Instant4D — это система для реконструкции динамических сцен из некалиброванного видео, которая р
[13.10.2025 13:26] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal"], "emoji": "🔀", "ru": {"title": "Учимся на разных модальностях без парных данных", "desc": "Статья представляет UML (Unpaired Multimodal Learner) — новый подход к обучению представлений, который использует непарные данные из разных модальностей для
[13.10.2025 13:26] Renaming data file.
[13.10.2025 13:26] Renaming previous data. hf_papers.json to ./d/2025-10-13.json
[13.10.2025 13:26] Saving new data file.
[13.10.2025 13:26] Generating page.
[13.10.2025 13:26] Renaming previous page.
[13.10.2025 13:26] Renaming previous data. index.html to ./d/2025-10-13.html
[13.10.2025 13:26] Writing result.
[13.10.2025 13:26] Renaming log file.
[13.10.2025 13:26] Renaming previous data. log.txt to ./logs/2025-10-13_last_log.txt
