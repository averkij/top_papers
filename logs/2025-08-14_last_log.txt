[14.08.2025 16:16] Read previous papers.
[14.08.2025 16:16] Generating top page (month).
[14.08.2025 16:16] Writing top page (month).
[14.08.2025 17:11] Read previous papers.
[14.08.2025 17:11] Get feed.
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09983
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08401
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07901
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09889
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09736
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09192
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09987
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07750
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06009
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05613
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09456
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09968
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09945
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09667
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06937
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01522
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09776
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07237
[14.08.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06944
[14.08.2025 17:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[14.08.2025 17:11] No deleted papers detected.
[14.08.2025 17:11] Downloading and parsing papers (pdf, html). Total: 19.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09983.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09983.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09983.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.08401.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.08401.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.08401.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.07901.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.07901.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.07901.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09889.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09889.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09889.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09736.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09736.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09736.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09192.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09192.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09192.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09987.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09987.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09987.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.07750.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.07750.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.07750.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.06009.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.06009.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.06009.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.05613.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.05613.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.05613.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09456.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09456.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09456.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09968.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09968.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09968.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09945.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09945.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09945.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09667.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09667.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09667.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.06937.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.06937.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.06937.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.01522.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.01522.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.01522.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.09776.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.09776.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.09776.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.07237.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.07237.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.07237.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2508.06944.
[14.08.2025 17:11] Extra JSON file exists (./assets/json/2508.06944.json), skip PDF parsing.
[14.08.2025 17:11] Paper image links file exists (./assets/img_data/2508.06944.json), skip HTML parsing.
[14.08.2025 17:11] Success.
[14.08.2025 17:11] Enriching papers with extra data.
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 0. Story2Board generates expressive storyboards from natural language using a consistency framework that enhances coherence and diversity without fine-tuning.  					AI-generated summary 				 We present Story2Board, a training-free framework for expressive storyboard generation from natural language. Ex...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 1. Mol-R1 framework enhances molecule discovery by improving reasoning performance and explainability through PRID and MoIA strategies.  					AI-generated summary 				 Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT) reasoning models like DeepSeek-R1 and QWQ, have demonstra...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 2. A lightweight framework for identity preservation in video generation using conditional image branches and restricted self-attentions outperforms full-parameter methods with minimal additional parameters.  					AI-generated summary 				 Generating high-fidelity human videos that match user-specified...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 3. A dynamic Multi-Agent System (MAS) with Execution and Guard Agents improves the reliability and effectiveness of intelligent agents using external tools, outperforming single-agent systems on the GAIA leaderboard.  					AI-generated summary 				 The rapid advancement of large language models (LLMs) ...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 4. M3-Agent, a multimodal agent with long-term memory, performs multi-turn reasoning and outperforms baselines on a new long-video question answering benchmark.  					AI-generated summary 				 We introduce M3-Agent, a novel multimodal agent framework equipped with long-term memory. Like humans, M3-Agen...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 5. Discrete diffusion forcing enhances diffusion large language models with block-wise autoregressive generation and inter-block parallel decoding, significantly improving inference speed while maintaining quality.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have emerged as ...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 6. Echo-4o-Image, a synthetic dataset generated by GPT-4o, enhances image generation models by addressing rare scenarios and providing clean supervision, leading to improved performance and transferability.  					AI-generated summary 				 Recently, GPT-4o has garnered significant attention for its stro...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 7. GRAO, a unified framework combining SFT and RL, enhances language model alignment through multi-sample generation, Group Direct Alignment Loss, and reference-aware parameter updates, demonstrating superior performance across human alignment tasks.  					AI-generated summary 				 Alignment methodolog...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 8. MathReal, a dataset of real-world mathematical questions with images, evaluates the performance of multimodal large language models in authentic educational settings, highlighting challenges and providing insights for improvement.  					AI-generated summary 				 Multimodal Large Language Models (MLL...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 9. A reinforcement learning framework jointly optimizes policy and reward models to enhance robustness and mitigate reward hacking in large language models.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable performance in reasoning tasks, where reinforcement lear...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 10. A novel input-aware backdoor attack method, IAG, manipulates vision-language models to ground specific objects in images regardless of user queries, using a text-conditional U-Net and reconstruction loss to ensure stealthiness.  					AI-generated summary 				 Vision-language models (VLMs) have shown...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 11. A Noise Hypernetwork is introduced to integrate test-time scaling knowledge into diffusion models, reducing computational cost while maintaining quality.  					AI-generated summary 				 The new paradigm of test-time scaling has yielded remarkable breakthroughs in Large Language Models (LLMs) (e.g. r...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 12. VisCodex integrates vision and coding models to enhance multimodal code generation, achieving top performance using a novel dataset and benchmark.  					AI-generated summary 				 Multimodal large language models (MLLMs) have significantly advanced the integration of visual and textual understanding....
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 13. GSFixer enhances 3D Gaussian Splatting reconstructions from sparse views using a DiT-based video diffusion model with reference-guided conditions, improving artifact restoration and 3D consistency.  					AI-generated summary 				 Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from spars...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 14. CannyEdit is a training-free framework that enhances text-to-image editing by balancing text adherence, context fidelity, and seamless integration through Selective Canny Control and Dual-Prompt Guidance.  					AI-generated summary 				 Recent advances in text-to-image (T2I) models have enabled trai...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 15. A decentralized multi-agent reinforcement learning method enables real-world 6-DoF manipulation of cable-suspended loads using MAVs, achieving performance comparable to centralized methods with improved scalability and robustness.  					AI-generated summary 				 This paper presents the first decentr...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 16. Automated generation of textual explanations using large language models improves model performance in natural language inference tasks, offering a scalable alternative to human annotation.  					AI-generated summary 				 In the rapidly evolving field of Explainable Natural Language Processing (NLP)...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 17. ASM-UNet, a Mamba-based architecture with adaptive scan scores, enhances fine-grained segmentation by dynamically adjusting scanning orders to accommodate individual anatomical variations.  					AI-generated summary 				 Precise lesion resection depends on accurately identifying fine-grained anatomi...
[14.08.2025 17:11] ********************************************************************************
[14.08.2025 17:11] Abstract 18. Adaptive Meta Fine-Tuning (AMFT) dynamically balances Supervised Fine-Tuning and Reinforcement Learning using implicit rewards to improve LLM performance and generalization.  					AI-generated summary 				 Large Language Models (LLMs) are typically fine-tuned for reasoning tasks through a two-stage ...
[14.08.2025 17:11] Read previous papers.
[14.08.2025 17:11] Generating reviews via LLM API.
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#multimodal", "#story_generation", "#benchmark", "#cv", "#dataset"], "emoji": "üé¨", "ru": {"title": "–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞—Å–∫–∞–¥—Ä–æ–≤–æ–∫ —Å –ø–æ–º–æ—â—å—é –ò–ò –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Story2Board - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞—Å–∫–∞–¥—Ä–æ–≤–æ–∫ –∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#data", "#rl", "#dataset", "#training"], "emoji": "üß™", "ru": {"title": "Mol-R1: –£–º–Ω–æ–µ –æ—Ç–∫—Ä—ã—Ç–∏–µ –º–æ–ª–µ–∫—É–ª —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "Mol-R1 - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–ª–µ–∫—É–ª —Å –ø–æ–º–æ—â—å—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é P
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#video", "#architecture", "#multimodal", "#training"], "emoji": "üé≠", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Stand-In - –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É—Å–ª–æ–≤–Ω—É—é –≤–µ—Ç–≤—å –∏–∑–æ
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#open_source", "#agi", "#architecture", "#optimization"], "emoji": "ü§ñ", "ru": {"title": "–ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞: –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ò–ò-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É (–ú–ê–°) —Å –∞–≥–µ–Ω—Ç–∞–º–∏ –∏—Å
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#agents", "#reasoning", "#multimodal", "#rl"], "emoji": "ü§ñ", "ru": {"title": "M3-Agent: –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ò–ò-–∞–≥–µ–Ω—Ç —Å —á–µ–ª–æ–≤–µ–∫–æ–ø–æ–¥–æ–±–Ω–æ–π –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é", "desc": "M3-Agent - —ç—Ç–æ –Ω–æ–≤–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é, —Å–ø–æ—Å–æ–±
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#diffusion", "#inference", "#architecture"], "emoji": "üöÄ", "ru": {"title": "D2F: –£—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º 'discrete diffusion forcing' (D2F) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–∏—Ñ
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#synthetic", "#transfer_learning", "#cv", "#dataset", "#benchmark", "#multimodal"], "emoji": "üñºÔ∏è", "ru": {"title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ - –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Echo-4o-Image - —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Å –ø–æ–º–æ—â—å—é GPT-4o –¥–ª
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#training", "#alignment", "#rl", "#rlhf"], "emoji": "ü§ñ", "ru": {"title": "GRAO: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ SFT –∏ RL –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "GRAO - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ SFT –∏ RL. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–µ
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#multimodal", "#science", "#dataset"], "emoji": "üìö", "ru": {"title": "MathReal: —Ä–µ–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –ò–ò –≤ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MathReal - –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ 2000 –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è –æ—Ü–µ–Ω
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#rl", "#optimization", "#training"], "emoji": "ü§ñ", "ru": {"title": "Cooper: —É–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Cooper, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ –æ–ø—Ç–∏–º–∏–∑
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#security", "#multimodal", "#cv"], "emoji": "üïµÔ∏è", "ru": {"title": "–°–∫—Ä—ã—Ç–∞—è –∞—Ç–∞–∫–∞ –Ω–∞ –º–æ–¥–µ–ª–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∞—Ç–∞–∫–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º IA
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#training", "#inference", "#architecture"], "emoji": "üîä", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é —à—É–º–æ–≤–æ–π –≥–∏–ø–µ—Ä—Å–µ—Ç–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è –®—É–º–æ–≤–æ–π –≥–∏–ø–µ—Ä—Å–µ—Ç–∏ (Noise Hypernetwork) –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∑–Ω–∞
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#games", "#open_source", "#dataset"], "emoji": "üîÆ", "ru": {"title": "VisCodex: —Å–ª–∏—è–Ω–∏–µ –∑—Ä–µ–Ω–∏—è –∏ –∫–æ–¥–∞ –¥–ª—è –ø—Ä–æ—Ä—ã–≤–∞ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º", "desc": "VisCodex - —ç—Ç–æ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –º–æ–¥–µ–ª–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#diffusion", "#3d"], "emoji": "üñºÔ∏è", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –æ–ø–æ—Ä–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "GSFixer - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ 3D —Å—Ü–µ–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º 3D Gaussian Splatting –∏–∑ –º–∞–ª–æ–≥–æ —á
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#multimodal", "#cv"], "emoji": "üñåÔ∏è", "ru": {"title": "CannyEdit: –¢–æ—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–µ–∫—Å—Ç–æ–º –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "CannyEdit - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–µ —Ç—Ä–µ–±—É—é—â–∞—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω–∞ –∏—Å
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#transfer_learning", "#robotics", "#rl", "#games", "#agents"], "emoji": "üöÅ", "ru": {"title": "–î–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–∑–æ–º —Å –ø–æ–º–æ—â—å—é —Ä–æ—è –¥—Ä–æ–Ω–æ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ –≥—Ä—É–∑–æ–º, –ø–æ–¥–≤–µ—à–µ–Ω–Ω—ã–º –Ω–∞ —Ç—Ä–æ—Å–µ, —Å –ø–æ–º–æ—â—å—é –≥—Ä—É–ø–ø—ã –º–∏–∫—Ä–æ-–±–µ—Å–ø–∏–ª
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#interpretability", "#multimodal", "#optimization", "#dataset", "#benchmark", "#data"], "emoji": "ü§ñ", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –≤ NLP: LLM –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ —á–µ–ª–æ–≤–µ–∫—É", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#healthcare", "#dataset", "#architecture"], "emoji": "üî¨", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏", "desc": "ASM-UNet - —ç—Ç–æ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Mamba –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ
[14.08.2025 17:11] Using data from previous issue: {"categories": ["#alignment", "#agi", "#rl", "#benchmark", "#reasoning", "#multimodal", "#optimization", "#open_source", "#training"], "emoji": "‚öñÔ∏è", "ru": {"title": "–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö
[14.08.2025 17:11] Renaming data file.
[14.08.2025 17:11] Renaming previous data. hf_papers.json to ./d/2025-08-14.json
[14.08.2025 17:11] Saving new data file.
[14.08.2025 17:11] Generating page.
[14.08.2025 17:11] Renaming previous page.
[14.08.2025 17:11] Renaming previous data. index.html to ./d/2025-08-14.html
[14.08.2025 17:11] Writing result.
[14.08.2025 17:11] Renaming log file.
[14.08.2025 17:11] Renaming previous data. log.txt to ./logs/2025-08-14_last_log.txt
