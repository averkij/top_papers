[14.08.2025 05:14] Read previous papers.
[14.08.2025 05:14] Generating top page (month).
[14.08.2025 05:14] Writing top page (month).
[14.08.2025 06:18] Read previous papers.
[14.08.2025 06:18] Get feed.
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08401
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09889
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09987
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06009
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09456
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05613
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09192
[14.08.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09968
[14.08.2025 06:18] Extract page data from URL. URL: https://huggingface.co/papers/2508.09983
[14.08.2025 06:18] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[14.08.2025 06:18] No deleted papers detected.
[14.08.2025 06:18] Downloading and parsing papers (pdf, html). Total: 9.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.08401.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.08401.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.08401.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.09889.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.09889.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.09889.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.09987.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.09987.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.09987.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.06009.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.06009.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.06009.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.09456.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.09456.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.09456.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.05613.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.05613.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.05613.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.09192.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.09192.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.09192.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.09968.
[14.08.2025 06:18] Extra JSON file exists (./assets/json/2508.09968.json), skip PDF parsing.
[14.08.2025 06:18] Paper image links file exists (./assets/img_data/2508.09968.json), skip HTML parsing.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2508.09983.
[14.08.2025 06:18] Downloading paper 2508.09983 from http://arxiv.org/pdf/2508.09983v1...
[14.08.2025 06:18] Extracting affiliations from text.
[14.08.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 1 ] . [ 1 3 8 9 9 0 . 8 0 5 2 : r Story2Board: Training-Free Approach for Expressive Storyboard Generation David Dinkevich1, Matan Levy1, Omri Avrahami1, Dvir Samuel2,3, and Dani Lischinski1 1Hebrew University of Jerusalem, Israel 2OriginAI, Israel 3Bar-Ilan University, Israel Figure 1: Story2Board generates coherent multi-panel storyboards from natural language prompt, maintaining subject identity while allowing dynamic changes in character pose, size, and position. Unlike prior work, it introduces lightweight consistency mechanism that preserves the models generative prior, supporting rich, expressive storytelling without fine-tuning or architectural changes. Full story texts are available in the appendix (Section A.6). We present Story2Board, training-free framework for expressive storyboard generation from natural language. Existing methods narrowly focus on subject identity, overlooking key aspects of visual storytelling such as spatial composition, background evolution, and narrative pacing. To address this, we introduce lightweight consistency framework composed of two components: Latent Panel Anchoring, which preserves shared character reference across panels, and Reciprocal Attention Value Mixing, which softly blends visual features between token pairs with strong reciprocal attention. Together, these mechanisms enhance coherence without architectural changes or fine-tuning, enabling stateof-the-art diffusion models to generate visually diverse yet consistent storyboards. To structure generation, we use an off-theshelf language model to convert free-form stories into grounded panel-level prompts. To evaluate, we propose the Rich Storyboard Benchmark, suite of open-domain narratives designed to assess layout diversity and background-grounded storytelling, in addition to consistency. We also introduce new Scene Diversity metric that quantifies spatial and pose variation across storyboards. Our qualitative and quantitative results, as well as user st"
[14.08.2025 06:18] Response: ```python
["Hebrew University of Jerusalem, Israel", "OriginAI, Israel", "Bar-Ilan University, Israel"]
```
[14.08.2025 06:18] Deleting PDF ./assets/pdf/2508.09983.pdf.
[14.08.2025 06:18] Success.
[14.08.2025 06:18] Enriching papers with extra data.
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 0. Mol-R1 framework enhances molecule discovery by improving reasoning performance and explainability through PRID and MoIA strategies.  					AI-generated summary 				 Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT) reasoning models like DeepSeek-R1 and QWQ, have demonstra...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 1. A dynamic Multi-Agent System (MAS) with Execution and Guard Agents improves the reliability and effectiveness of intelligent agents using external tools, outperforming single-agent systems on the GAIA leaderboard.  					AI-generated summary 				 The rapid advancement of large language models (LLMs) ...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 2. Echo-4o-Image, a synthetic dataset generated by GPT-4o, enhances image generation models by addressing rare scenarios and providing clean supervision, leading to improved performance and transferability.  					AI-generated summary 				 Recently, GPT-4o has garnered significant attention for its stro...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 3. MathReal, a dataset of real-world mathematical questions with images, evaluates the performance of multimodal large language models in authentic educational settings, highlighting challenges and providing insights for improvement.  					AI-generated summary 				 Multimodal Large Language Models (MLL...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 4. A novel input-aware backdoor attack method, IAG, manipulates vision-language models to ground specific objects in images regardless of user queries, using a text-conditional U-Net and reconstruction loss to ensure stealthiness.  					AI-generated summary 				 Vision-language models (VLMs) have shown...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 5. A reinforcement learning framework jointly optimizes policy and reward models to enhance robustness and mitigate reward hacking in large language models.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable performance in reasoning tasks, where reinforcement lear...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 6. Discrete diffusion forcing enhances diffusion large language models with block-wise autoregressive generation and inter-block parallel decoding, significantly improving inference speed while maintaining quality.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have emerged as ...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 7. A Noise Hypernetwork is introduced to integrate test-time scaling knowledge into diffusion models, reducing computational cost while maintaining quality.  					AI-generated summary 				 The new paradigm of test-time scaling has yielded remarkable breakthroughs in Large Language Models (LLMs) (e.g. r...
[14.08.2025 06:18] ********************************************************************************
[14.08.2025 06:18] Abstract 8. Story2Board generates expressive storyboards from natural language using a consistency framework that enhances coherence and diversity without fine-tuning.  					AI-generated summary 				 We present Story2Board, a training-free framework for expressive storyboard generation from natural language. Ex...
[14.08.2025 06:18] Read previous papers.
[14.08.2025 06:18] Generating reviews via LLM API.
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#data", "#rl", "#dataset", "#training"], "emoji": "🧪", "ru": {"title": "Mol-R1: Умное открытие молекул с помощью ИИ", "desc": "Mol-R1 - это новая система для улучшения генерации молекул с помощью больших языковых моделей. Она использует стратегию P
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#open_source", "#agi", "#architecture", "#optimization"], "emoji": "🤖", "ru": {"title": "Мультиагентная система: надежность и эффективность в использовании ИИ-инструментов", "desc": "Статья представляет динамическую мультиагентную систему (МАС) с агентами ис
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#synthetic", "#transfer_learning", "#cv", "#dataset", "#benchmark", "#multimodal"], "emoji": "🖼️", "ru": {"title": "Синтетические данные - ключ к улучшению генерации изображений", "desc": "Исследователи представили Echo-4o-Image - синтетический датасет, созданный с помощью GPT-4o дл
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#multimodal", "#science", "#dataset"], "emoji": "📚", "ru": {"title": "MathReal: реальный тест для ИИ в математическом образовании", "desc": "Статья представляет MathReal - набор данных из 2000 математических задач с реальными изображениями для оцен
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#security", "#multimodal", "#cv"], "emoji": "🕵️", "ru": {"title": "Скрытая атака на модели компьютерного зрения с помощью адаптивного генератора триггеров", "desc": "Статья представляет новый метод атаки на модели компьютерного зрения и обработки естественного языка под названием IA
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#rl", "#optimization", "#training"], "emoji": "🤖", "ru": {"title": "Cooper: умное обучение с подкреплением для больших языковых моделей", "desc": "В этой статье представлена новая система обучения с подкреплением под названием Cooper, которая совместно оптимиз
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#diffusion", "#inference", "#architecture"], "emoji": "🚀", "ru": {"title": "D2F: Ускорение диффузионных языковых моделей без потери качества", "desc": "Статья представляет новый метод под названием 'discrete diffusion forcing' (D2F) для улучшения диф
[14.08.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#training", "#inference", "#architecture"], "emoji": "🔊", "ru": {"title": "Эффективное масштабирование диффузионных моделей с помощью шумовой гиперсети", "desc": "В статье представлена концепция Шумовой гиперсети (Noise Hypernetwork) для интеграции зна
[14.08.2025 06:18] Querying the API.
[14.08.2025 06:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Story2Board generates expressive storyboards from natural language using a consistency framework that enhances coherence and diversity without fine-tuning.  					AI-generated summary 				 We present Story2Board, a training-free framework for expressive storyboard generation from natural language. Existing methods narrowly focus on subject identity, overlooking key aspects of visual storytelling such as spatial composition, background evolution, and narrative pacing. To address this, we introduce a lightweight consistency framework composed of two components: Latent Panel Anchoring, which preserves a shared character reference across panels, and Reciprocal Attention Value Mixing, which softly blends visual features between token pairs with strong reciprocal attention. Together, these mechanisms enhance coherence without architectural changes or fine-tuning, enabling state-of-the-art diffusion models to generate visually diverse yet consistent storyboards. To structure generation, we use an off-the-shelf language model to convert free-form stories into grounded panel-level prompts. To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain narratives designed to assess layout diversity and background-grounded storytelling, in addition to consistency. We also introduce a new Scene Diversity metric that quantifies spatial and pose variation across storyboards. Our qualitative and quantitative results, as well as a user study, show that Story2Board produces more dynamic, coherent, and narratively engaging storyboards than existing baselines.
[14.08.2025 06:18] Response: {
  "desc": "Статья представляет Story2Board - фреймворк для генерации выразительных раскадровок из естественного языка без дополнительного обучения. Он использует механизмы сохранения согласованности персонажей и смешивания визуальных признаков для улучшения когерентности и разнообразия генерируемых изображений. Авторы предлагают новый набор данных Rich Storyboard Benchmark и метрику Scene Diversity для оценки качества раскадровок. Результаты показывают, что Story2Board создает более динамичные и увлекательные раскадровки по сравнению с существующими методами.",
  "emoji": "🎬",
  "title": "Создание выразительных раскадровок с помощью ИИ без дополнительного обучения"
}
[14.08.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Story2Board generates expressive storyboards from natural language using a consistency framework that enhances coherence and diversity without fine-tuning.  					AI-generated summary 				 We present Story2Board, a training-free framework for expressive storyboard generation from natural language. Existing methods narrowly focus on subject identity, overlooking key aspects of visual storytelling such as spatial composition, background evolution, and narrative pacing. To address this, we introduce a lightweight consistency framework composed of two components: Latent Panel Anchoring, which preserves a shared character reference across panels, and Reciprocal Attention Value Mixing, which softly blends visual features between token pairs with strong reciprocal attention. Together, these mechanisms enhance coherence without architectural changes or fine-tuning, enabling state-of-the-art diffusion models to generate visually diverse yet consistent storyboards. To structure generation, we use an off-the-shelf language model to convert free-form stories into grounded panel-level prompts. To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain narratives designed to assess layout diversity and background-grounded storytelling, in addition to consistency. We also introduce a new Scene Diversity metric that quantifies spatial and pose variation across storyboards. Our qualitative and quantitative results, as well as a user study, show that Story2Board produces more dynamic, coherent, and narratively engaging storyboards than existing baselines."

[14.08.2025 06:19] Response: ```python
['DATASET', 'BENCHMARK', 'CV', 'MULTIMODAL']
```
[14.08.2025 06:19] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Story2Board generates expressive storyboards from natural language using a consistency framework that enhances coherence and diversity without fine-tuning.  					AI-generated summary 				 We present Story2Board, a training-free framework for expressive storyboard generation from natural language. Existing methods narrowly focus on subject identity, overlooking key aspects of visual storytelling such as spatial composition, background evolution, and narrative pacing. To address this, we introduce a lightweight consistency framework composed of two components: Latent Panel Anchoring, which preserves a shared character reference across panels, and Reciprocal Attention Value Mixing, which softly blends visual features between token pairs with strong reciprocal attention. Together, these mechanisms enhance coherence without architectural changes or fine-tuning, enabling state-of-the-art diffusion models to generate visually diverse yet consistent storyboards. To structure generation, we use an off-the-shelf language model to convert free-form stories into grounded panel-level prompts. To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain narratives designed to assess layout diversity and background-grounded storytelling, in addition to consistency. We also introduce a new Scene Diversity metric that quantifies spatial and pose variation across storyboards. Our qualitative and quantitative results, as well as a user study, show that Story2Board produces more dynamic, coherent, and narratively engaging storyboards than existing baselines."

[14.08.2025 06:19] Response: ```python
["STORY_GENERATION"]
```
[14.08.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Story2Board is a novel framework that generates expressive storyboards from natural language descriptions without the need for fine-tuning. It addresses limitations in existing methods by focusing on important visual storytelling elements like spatial composition and narrative pacing. The framework employs Latent Panel Anchoring to maintain character consistency across panels and Reciprocal Attention Value Mixing to enhance visual feature blending. This approach allows for the creation of coherent and diverse storyboards, evaluated through the Rich Storyboard Benchmark and a new Scene Diversity metric, demonstrating superior performance compared to traditional methods.","title":"Expressive Storyboards from Natural Language, No Fine-Tuning Needed!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Story2Board is a novel framework that generates expressive storyboards from natural language descriptions without the need for fine-tuning. It addresses limitations in existing methods by focusing on important visual storytelling elements like spatial composition and narrative pacing. The framework employs Latent Panel Anchoring to maintain character consistency across panels and Reciprocal Attention Value Mixing to enhance visual feature blending. This approach allows for the creation of coherent and diverse storyboards, evaluated through the Rich Storyboard Benchmark and a new Scene Diversity metric, demonstrating superior performance compared to traditional methods.', title='Expressive Storyboards from Natural Language, No Fine-Tuning Needed!'))
[14.08.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Story2Board是一个无需训练的框架，可以从自然语言生成富有表现力的故事板。现有的方法主要关注角色身份，忽视了视觉叙事中的重要方面，如空间构图、背景演变和叙事节奏。为了解决这个问题，我们引入了一个轻量级的一致性框架，包括潜在面板锚定和互惠注意力值混合两个组件，以增强故事板的一致性和多样性。我们的实验结果表明，Story2Board生成的故事板在动态性、一致性和叙事吸引力方面优于现有的基线。","title":"从自然语言生成一致且多样的故事板"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Story2Board是一个无需训练的框架，可以从自然语言生成富有表现力的故事板。现有的方法主要关注角色身份，忽视了视觉叙事中的重要方面，如空间构图、背景演变和叙事节奏。为了解决这个问题，我们引入了一个轻量级的一致性框架，包括潜在面板锚定和互惠注意力值混合两个组件，以增强故事板的一致性和多样性。我们的实验结果表明，Story2Board生成的故事板在动态性、一致性和叙事吸引力方面优于现有的基线。', title='从自然语言生成一致且多样的故事板'))
[14.08.2025 06:19] Renaming data file.
[14.08.2025 06:19] Renaming previous data. hf_papers.json to ./d/2025-08-14.json
[14.08.2025 06:19] Saving new data file.
[14.08.2025 06:19] Generating page.
[14.08.2025 06:19] Renaming previous page.
[14.08.2025 06:19] Renaming previous data. index.html to ./d/2025-08-14.html
[14.08.2025 06:19] Writing result.
[14.08.2025 06:19] Renaming log file.
[14.08.2025 06:19] Renaming previous data. log.txt to ./logs/2025-08-14_last_log.txt
