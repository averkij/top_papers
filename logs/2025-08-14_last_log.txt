[14.08.2025 21:11] Read previous papers.
[14.08.2025 21:11] Generating top page (month).
[14.08.2025 21:11] Writing top page (month).
[14.08.2025 22:11] Read previous papers.
[14.08.2025 22:11] Get feed.
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09983
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08401
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07901
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09192
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09889
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09736
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09987
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07750
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06009
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05613
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09456
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09968
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09945
[14.08.2025 22:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.09726
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06937
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09667
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01522
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09776
[14.08.2025 22:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.09752
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07237
[14.08.2025 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06944
[14.08.2025 22:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.07321
[14.08.2025 22:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[14.08.2025 22:11] No deleted papers detected.
[14.08.2025 22:11] Downloading and parsing papers (pdf, html). Total: 22.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09983.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09983.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09983.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.08401.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.08401.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.08401.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.07901.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.07901.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.07901.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09192.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09192.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09192.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09889.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09889.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09889.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09736.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09736.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09736.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09987.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09987.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09987.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.07750.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.07750.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.07750.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.06009.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.06009.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.06009.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.05613.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.05613.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.05613.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09456.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09456.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09456.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09968.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09968.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09968.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09945.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09945.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09945.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09726.
[14.08.2025 22:11] Downloading paper 2508.09726 from http://arxiv.org/pdf/2508.09726v1...
[14.08.2025 22:11] Failed to download and parse paper https://huggingface.co/papers/2508.09726: 'LTChar' object is not iterable
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.06937.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.06937.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.06937.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09667.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09667.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09667.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.01522.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.01522.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.01522.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09776.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.09776.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.09776.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.09752.
[14.08.2025 22:11] Downloading paper 2508.09752 from http://arxiv.org/pdf/2508.09752v1...
[14.08.2025 22:11] Extracting affiliations from text.
[14.08.2025 22:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"µ-Parametrization for Mixture of Experts Jan Małasnicki * 1 Kamil Ciebiera * 1 Mateusz Boru 1 2 Maciej Pioro 3 4 Jan Ludziejewski 1 Maciej Stefaniak 1 Michał Krutul 1 3 Sebastian Jaszczur 1 3 Marek Cygan 1 5 Kamil Adamczewski 3 6 Jakub Krajewski * 1 3 5 2 0 2 3 1 ] . [ 1 2 5 7 9 0 . 8 0 5 2 : r a "
[14.08.2025 22:11] Response: ```python
[]
```
[14.08.2025 22:11] Extracting affiliations from text.
[14.08.2025 22:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"µ-Parametrization for Mixture of Experts Jan Małasnicki * 1 Kamil Ciebiera * 1 Mateusz Boru 1 2 Maciej Pioro 3 4 Jan Ludziejewski 1 Maciej Stefaniak 1 Michał Krutul 1 3 Sebastian Jaszczur 1 3 Marek Cygan 1 5 Kamil Adamczewski 3 6 Jakub Krajewski * 1 3 5 2 0 2 3 1 ] . [ 1 2 5 7 9 0 . 8 0 5 2 : r aRecent years have seen growing interest and adoption of LLMs, with µTransfer becoming key technique for tuning hyperparameters in large-scale training. Meanwhile, Mixture-ofExperts (MoE) has emerged as leading architecture in extremely large models. However, the intersection of these two advancements has remained unexplored. In this work, we derive µParameterization (µP) for MoE, providing theoretical guarantees for feature learning across model widths in both the router and experts. We empirically validate our parameterization and further investigate how scaling the number of experts and granularity affects the optimal learning rate. 1. Introduction Scaling deep learning models has become fundamental driver of progress in modern AI (Fedus et al., 2022; Touvron et al., 2023; OpenAI, 2025). Nevertheless, efficiently tuning hyperparameters across different model sizes remains major challenge, often requiring extensive trial-and-error or computationally expensive grid searches (Feurer et al., 2015). The µParameterization (µP) (Yang, 2021) offers principled solution by enabling stable and predictable training dynamics across model widthswithout the need to retune learning rates or initialization schemes. By reparameterizing models to preserve feature learning in the infinitewidth limit, µP makes it possible to identify optimal hyperparameters on small models and seamlessly transfer them to larger ones, significantly reducing tuning costs. On the other hand, Mixture-of-Experts (MoE) models have *Core contributors 1University of Warsaw 2Syntro 3IDEAS NCBR 4Institute of Fundamental Technological Research, Polish Academy of Sciences 5Nomagic 6Wroclaw University of Science and Technology. Correspondence to: Jan Małasnicki <jan.malasnicki@gmail.com>, Kamil Ciebiera <kp.ciebiera@student.uw.edu.pl>, Mateusz Borun <mateusz@syntro.ai>, Jakub Krajewski <gim.jakubk@gmail.com>. emerged as compelling approach for scaling large language models efficiently, offering substantial computational savings through sparse activation (Clark et al., 2022; Ludziejewski et al., 2024). However, the sparsity patterns and routing mechanisms intrinsic to MoE architectures fall outside the scope of current µP theory. Consequently, it remains unclear whether the parameterization developed for dense Transformers can be directly applied to MoE models, or whether adaptations are required to retain the transferability and stability benefits that µP provides. In this work, we extend µP to Mixture-of-Experts (MoE) architectures, offering both theoretical grounding and empirical validation. Our main contributions are: Theoretical framework for µP in MoE. Building on (Yang et al., 2022), we derive parameterization scheme that ensures that feature learning is preserved across all weights within MoE layers. Empirical validation of learning rate transfer. We show that our parameterization enables consistent learning dynamics across model widths, confirming that hyperparameters can be transferred effectively in MoE setups. Investigation of hyperparameter transferability across other MoE parameters. We observe that learning rate transferability breaks down across different values of top-k and granular expert sizes, highlighting boundary of current hyperparameter transferability in MoE settings. 2. Background and Related Work Mixture of Experts. Mixture of Experts was originally introduced by (Jacobs et al., 1991), and later proposed in the context of language modeling by (Shazeer et al., 2017). This approach has since been succesfully integrated into the Transformer (Vaswani et al., 2023) architecture in multiple works, including (Fedus et al., 2022; Lepikhin et al., 2020; Du et al., 2022; Zhou et al., 2022). In Transformer model, the MoE layer is typically constructed by replacing the Feed-Forward component with set of experts. Each expert retains the design of the original Feed-Forward layer, 1 µ-Parametrization for Mixture of Experts consisting of two linear layers with non-linearity between them. Crucially, for any given input token, only fraction of these experts are activated. The selection of experts for each token is determined by routing mechanism - simple linear layer followed by softmax normalization and Top-k choice. In the standard, Switch layer (Fedus et al., 2022), each of the experts is of the same size as in the corresponding dense (non-MoE) Transformer. This assumption is relaxed in finegrained MoE (Dai et al., 2024; Ludziejewski et al., 2024), where for granularity G, the hidden size of each expert is reduced by factor of G, while the number of experts and the routers top-k value are both multiplied by G. This way, the model has greater flexibility in mapping tokens to experts, while the number total and activated parameters remains approximately constant. transfer. Zero-shot hyperparameter Standard parametrization (SP) often fails to preserve stability and hyperparameter transfer in scaling neural networks. To overcome this limitation, (Yang, 2021) introduced Maximal Update Parametrization (µParametrization, or µP). µP ensures that each layer in network receives updates of the same order of magnitude during training, regardless of width. This allows for what is known as the feature learning regime, where internal representations evolve in meaningful way as training progresses. Crucially, µP enables hyperparameter transfer across model sizes: one can tune learning rates and initialization on small model and zero-shot transfer them to large one, as shown empirically and theoretically in (Yang et al., 2022). This paradigm, called µTransfer, has been shown to dramatically reduce the cost of training large models while maintaining performance. Later works (Yang et al., 2024; Everett et al., 2024) reformulate and generalize µP theory, while (Dey et al., 2025) and (Yang et al., 2023) include transfer across model depths. Despite its success on many architectures such as Transformers and ResNets, extending µP to Mixture-of-Experts models remains an open challenge. In this work, we address this open problem. 3. Principled approach to µP for MoE In this section, we analyze the behavior of MoE (Fedus et al., 2022) during traini"
[14.08.2025 22:11] Mistral response. {"id": "469b3518010e4b919b9ed718ec645d7f", "created": 1755209508, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1583, "total_tokens": 1641, "completion_tokens": 58}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"University of Warsaw\",\n    \"Syntro\",\n    \"IDEAS NCBR\",\n    \"Institute of Fundamental Technological Research, Polish Academy of Sciences\",\n    \"Nomagic\",\n    \"Wroclaw University of Science and Technology\"\n]\n```"}}]}
[14.08.2025 22:11] Response: ```python
[
    "University of Warsaw",
    "Syntro",
    "IDEAS NCBR",
    "Institute of Fundamental Technological Research, Polish Academy of Sciences",
    "Nomagic",
    "Wroclaw University of Science and Technology"
]
```
[14.08.2025 22:11] Deleting PDF ./assets/pdf/2508.09752.pdf.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.07237.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.07237.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.07237.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.06944.
[14.08.2025 22:11] Extra JSON file exists (./assets/json/2508.06944.json), skip PDF parsing.
[14.08.2025 22:11] Paper image links file exists (./assets/img_data/2508.06944.json), skip HTML parsing.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Downloading and parsing paper https://huggingface.co/papers/2508.07321.
[14.08.2025 22:11] Downloading paper 2508.07321 from http://arxiv.org/pdf/2508.07321v1...
[14.08.2025 22:11] Extracting affiliations from text.
[14.08.2025 22:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ObfusQAte: Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering Shubhra Ghosh 1,*, Abhilekh Borah2,*, Aditya Kumar Guru 2,*, Kripabandhu Ghosh 3 1Indian Institute of Technology Patna, India, 2Manipal University Jaipur, India, 3IISER Kolkata, India shubhra_2303res116@iitp.ac.in, {abhilekh.229301149, aditya.23fe10cds00348}@muj.manipal.edu, kripaghosh@iiserkol.ac.in 5 2 0 2 0 1 ] . [ 1 1 2 3 7 0 . 8 0 5 2 : r a "
[14.08.2025 22:11] Response: ```python
["Indian Institute of Technology Patna, India", "Manipal University Jaipur, India", "IISER Kolkata, India"]
```
[14.08.2025 22:11] Deleting PDF ./assets/pdf/2508.07321.pdf.
[14.08.2025 22:11] Success.
[14.08.2025 22:11] Enriching papers with extra data.
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 0. Story2Board generates expressive storyboards from natural language using a consistency framework that enhances coherence and diversity without fine-tuning.  					AI-generated summary 				 We present Story2Board, a training-free framework for expressive storyboard generation from natural language. Ex...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 1. Mol-R1 framework enhances molecule discovery by improving reasoning performance and explainability through PRID and MoIA strategies.  					AI-generated summary 				 Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT) reasoning models like DeepSeek-R1 and QWQ, have demonstra...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 2. A lightweight framework for identity preservation in video generation using conditional image branches and restricted self-attentions outperforms full-parameter methods with minimal additional parameters.  					AI-generated summary 				 Generating high-fidelity human videos that match user-specified...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 3. Discrete diffusion forcing enhances diffusion large language models with block-wise autoregressive generation and inter-block parallel decoding, significantly improving inference speed while maintaining quality.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have emerged as ...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 4. A dynamic Multi-Agent System (MAS) with Execution and Guard Agents improves the reliability and effectiveness of intelligent agents using external tools, outperforming single-agent systems on the GAIA leaderboard.  					AI-generated summary 				 The rapid advancement of large language models (LLMs) ...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 5. M3-Agent, a multimodal agent with long-term memory, performs multi-turn reasoning and outperforms baselines on a new long-video question answering benchmark.  					AI-generated summary 				 We introduce M3-Agent, a novel multimodal agent framework equipped with long-term memory. Like humans, M3-Agen...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 6. Echo-4o-Image, a synthetic dataset generated by GPT-4o, enhances image generation models by addressing rare scenarios and providing clean supervision, leading to improved performance and transferability.  					AI-generated summary 				 Recently, GPT-4o has garnered significant attention for its stro...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 7. GRAO, a unified framework combining SFT and RL, enhances language model alignment through multi-sample generation, Group Direct Alignment Loss, and reference-aware parameter updates, demonstrating superior performance across human alignment tasks.  					AI-generated summary 				 Alignment methodolog...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 8. MathReal, a dataset of real-world mathematical questions with images, evaluates the performance of multimodal large language models in authentic educational settings, highlighting challenges and providing insights for improvement.  					AI-generated summary 				 Multimodal Large Language Models (MLL...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 9. A reinforcement learning framework jointly optimizes policy and reward models to enhance robustness and mitigate reward hacking in large language models.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable performance in reasoning tasks, where reinforcement lear...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 10. A novel input-aware backdoor attack method, IAG, manipulates vision-language models to ground specific objects in images regardless of user queries, using a text-conditional U-Net and reconstruction loss to ensure stealthiness.  					AI-generated summary 				 Vision-language models (VLMs) have shown...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 11. A Noise Hypernetwork is introduced to integrate test-time scaling knowledge into diffusion models, reducing computational cost while maintaining quality.  					AI-generated summary 				 The new paradigm of test-time scaling has yielded remarkable breakthroughs in Large Language Models (LLMs) (e.g. r...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 12. VisCodex integrates vision and coding models to enhance multimodal code generation, achieving top performance using a novel dataset and benchmark.  					AI-generated summary 				 Multimodal large language models (MLLMs) have significantly advanced the integration of visual and textual understanding....
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 13. GFPO reduces length inflation in large language models by sampling larger groups and filtering responses based on length and token efficiency, maintaining accuracy and improving computational efficiency.  					AI-generated summary 				 Large language models trained with reinforcement learning with v...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 14. CannyEdit is a training-free framework that enhances text-to-image editing by balancing text adherence, context fidelity, and seamless integration through Selective Canny Control and Dual-Prompt Guidance.  					AI-generated summary 				 Recent advances in text-to-image (T2I) models have enabled trai...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 15. GSFixer enhances 3D Gaussian Splatting reconstructions from sparse views using a DiT-based video diffusion model with reference-guided conditions, improving artifact restoration and 3D consistency.  					AI-generated summary 				 Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from spars...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 16. A decentralized multi-agent reinforcement learning method enables real-world 6-DoF manipulation of cable-suspended loads using MAVs, achieving performance comparable to centralized methods with improved scalability and robustness.  					AI-generated summary 				 This paper presents the first decentr...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 17. Automated generation of textual explanations using large language models improves model performance in natural language inference tasks, offering a scalable alternative to human annotation.  					AI-generated summary 				 In the rapidly evolving field of Explainable Natural Language Processing (NLP)...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 18. A new parameterization for Mixture-of-Experts models provides theoretical guarantees for feature learning and investigates the impact of scaling experts and granularity on learning rates.  					AI-generated summary 				 Recent years have seen a growing interest and adoption of LLMs, with muTransfer ...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 19. ASM-UNet, a Mamba-based architecture with adaptive scan scores, enhances fine-grained segmentation by dynamically adjusting scanning orders to accommodate individual anatomical variations.  					AI-generated summary 				 Precise lesion resection depends on accurately identifying fine-grained anatomi...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 20. Adaptive Meta Fine-Tuning (AMFT) dynamically balances Supervised Fine-Tuning and Reinforcement Learning using implicit rewards to improve LLM performance and generalization.  					AI-generated summary 				 Large Language Models (LLMs) are typically fine-tuned for reasoning tasks through a two-stage ...
[14.08.2025 22:11] ********************************************************************************
[14.08.2025 22:11] Abstract 21. ObfusQA, a novel framework with multi-tiered obfuscation levels, evaluates the robustness and adaptability of Large Language Models (LLMs) by examining their performance on obfuscated questions.  					AI-generated summary 				 The rapid proliferation of Large Language Models (LLMs) has significantly...
[14.08.2025 22:11] Read previous papers.
[14.08.2025 22:11] Generating reviews via LLM API.
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#multimodal", "#story_generation", "#benchmark", "#cv", "#dataset"], "emoji": "🎬", "ru": {"title": "Создание выразительных раскадровок с помощью ИИ без дополнительного обучения", "desc": "Статья представляет Story2Board - фреймворк для генерации выразительных раскадровок из естестве
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#data", "#rl", "#dataset", "#training"], "emoji": "🧪", "ru": {"title": "Mol-R1: Умное открытие молекул с помощью ИИ", "desc": "Mol-R1 - это новая система для улучшения генерации молекул с помощью больших языковых моделей. Она использует стратегию P
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#video", "#architecture", "#multimodal", "#training"], "emoji": "🎭", "ru": {"title": "Эффективное сохранение идентичности в генерации видео", "desc": "Статья представляет Stand-In - легковесный фреймворк для сохранения идентичности в генерации видео. Он использует условную ветвь изо
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#diffusion", "#inference", "#architecture"], "emoji": "🚀", "ru": {"title": "D2F: Ускорение диффузионных языковых моделей без потери качества", "desc": "Статья представляет новый метод под названием 'discrete diffusion forcing' (D2F) для улучшения диф
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#open_source", "#agi", "#architecture", "#optimization"], "emoji": "🤖", "ru": {"title": "Мультиагентная система: надежность и эффективность в использовании ИИ-инструментов", "desc": "Статья представляет динамическую мультиагентную систему (МАС) с агентами ис
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#agents", "#reasoning", "#multimodal", "#rl"], "emoji": "🤖", "ru": {"title": "M3-Agent: мультимодальный ИИ-агент с человекоподобной долговременной памятью", "desc": "M3-Agent - это новая мультимодальная агентная система с долговременной памятью, способ
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#synthetic", "#transfer_learning", "#cv", "#dataset", "#benchmark", "#multimodal"], "emoji": "🖼️", "ru": {"title": "Синтетические данные - ключ к улучшению генерации изображений", "desc": "Исследователи представили Echo-4o-Image - синтетический датасет, созданный с помощью GPT-4o дл
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#training", "#alignment", "#rl", "#rlhf"], "emoji": "🤖", "ru": {"title": "GRAO: Объединение SFT и RL для эффективного выравнивания языковых моделей", "desc": "GRAO - это новый фреймворк для улучшения выравнивания языковых моделей, объединяющий преимущества SFT и RL. Он использует ге
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#multimodal", "#science", "#dataset"], "emoji": "📚", "ru": {"title": "MathReal: реальный тест для ИИ в математическом образовании", "desc": "Статья представляет MathReal - набор данных из 2000 математических задач с реальными изображениями для оцен
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#rl", "#optimization", "#training"], "emoji": "🤖", "ru": {"title": "Cooper: умное обучение с подкреплением для больших языковых моделей", "desc": "В этой статье представлена новая система обучения с подкреплением под названием Cooper, которая совместно оптимиз
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#security", "#multimodal", "#cv"], "emoji": "🕵️", "ru": {"title": "Скрытая атака на модели компьютерного зрения с помощью адаптивного генератора триггеров", "desc": "Статья представляет новый метод атаки на модели компьютерного зрения и обработки естественного языка под названием IA
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#training", "#inference", "#architecture"], "emoji": "🔊", "ru": {"title": "Эффективное масштабирование диффузионных моделей с помощью шумовой гиперсети", "desc": "В статье представлена концепция Шумовой гиперсети (Noise Hypernetwork) для интеграции зна
[14.08.2025 22:11] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#games", "#open_source", "#dataset"], "emoji": "🔮", "ru": {"title": "VisCodex: слияние зрения и кода для прорыва в мультимодальной генерации программ", "desc": "VisCodex - это инновационная система, объединяющая модели компьютерного зрения и генерации ко
[14.08.2025 22:11] Querying the API.
[14.08.2025 22:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

GFPO reduces length inflation in large language models by sampling larger groups and filtering responses based on length and token efficiency, maintaining accuracy and improving computational efficiency.  					AI-generated summary 				 Large language models trained with reinforcement learning with verifiable rewards tend to trade accuracy for length--inflating response lengths to achieve gains in accuracy. While longer answers may be warranted for harder problems, many tokens are merely "filler": repetitive, verbose text that makes no real progress. We introduce GFPO (Group Filtered Policy Optimization), which curbs this length explosion by sampling larger groups per problem during training and filtering responses to train on based on two key metrics: (1) response length and (2) token efficiency: reward per token ratio. By sampling more at training time, we teach models to think less at inference time. On the Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH, LiveCodeBench) while maintaining accuracy. Optimizing for reward per token further increases reductions in length inflation to 71-85%. We also propose Adaptive Difficulty GFPO, which dynamically allocates more training resources to harder problems based on real-time difficulty estimates, improving the balance between computational efficiency and accuracy especially on difficult questions. GFPO demonstrates that increased training-time compute directly translates to reduced test-time compute--a simple yet effective trade-off for efficient reasoning.
[14.08.2025 22:11] Response: {
  "desc": "Статья представляет метод GFPO (Group Filtered Policy Optimization) для уменьшения избыточной длины ответов в больших языковых моделях. GFPO отбирает более крупные группы ответов во время обучения и фильтрует их по длине и эффективности использования токенов. Это позволяет сократить длину ответов на 46-71% при сохранении точности на сложных задачах STEM и программирования. Метод демонстрирует, что увеличение вычислительных ресурсов при обучении приводит к уменьшению вычислений при использовании модели.",
  "emoji": "✂️",
  "title": "Эффективное обучение для лаконичных ответов"
}
[14.08.2025 22:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"GFPO reduces length inflation in large language models by sampling larger groups and filtering responses based on length and token efficiency, maintaining accuracy and improving computational efficiency.  					AI-generated summary 				 Large language models trained with reinforcement learning with verifiable rewards tend to trade accuracy for length--inflating response lengths to achieve gains in accuracy. While longer answers may be warranted for harder problems, many tokens are merely "filler": repetitive, verbose text that makes no real progress. We introduce GFPO (Group Filtered Policy Optimization), which curbs this length explosion by sampling larger groups per problem during training and filtering responses to train on based on two key metrics: (1) response length and (2) token efficiency: reward per token ratio. By sampling more at training time, we teach models to think less at inference time. On the Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH, LiveCodeBench) while maintaining accuracy. Optimizing for reward per token further increases reductions in length inflation to 71-85%. We also propose Adaptive Difficulty GFPO, which dynamically allocates more training resources to harder problems based on real-time difficulty estimates, improving the balance between computational efficiency and accuracy especially on difficult questions. GFPO demonstrates that increased training-time compute directly translates to reduced test-time compute--a simple yet effective trade-off for efficient reasoning."

[14.08.2025 22:11] Response: ```python
["RL", "TRAINING", "BENCHMARK"]
```
[14.08.2025 22:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"GFPO reduces length inflation in large language models by sampling larger groups and filtering responses based on length and token efficiency, maintaining accuracy and improving computational efficiency.  					AI-generated summary 				 Large language models trained with reinforcement learning with verifiable rewards tend to trade accuracy for length--inflating response lengths to achieve gains in accuracy. While longer answers may be warranted for harder problems, many tokens are merely "filler": repetitive, verbose text that makes no real progress. We introduce GFPO (Group Filtered Policy Optimization), which curbs this length explosion by sampling larger groups per problem during training and filtering responses to train on based on two key metrics: (1) response length and (2) token efficiency: reward per token ratio. By sampling more at training time, we teach models to think less at inference time. On the Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH, LiveCodeBench) while maintaining accuracy. Optimizing for reward per token further increases reductions in length inflation to 71-85%. We also propose Adaptive Difficulty GFPO, which dynamically allocates more training resources to harder problems based on real-time difficulty estimates, improving the balance between computational efficiency and accuracy especially on difficult questions. GFPO demonstrates that increased training-time compute directly translates to reduced test-time compute--a simple yet effective trade-off for efficient reasoning."

[14.08.2025 22:12] Response: ```python
["OPTIMIZATION", "REASONING"]
```
[14.08.2025 22:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces GFPO (Group Filtered Policy Optimization), a method designed to reduce the excessive length of responses generated by large language models. It addresses the issue where models inflate response lengths to improve accuracy, often resulting in unnecessary filler content. By sampling larger groups during training and filtering based on response length and token efficiency, GFPO enhances computational efficiency while maintaining accuracy. Additionally, the Adaptive Difficulty GFPO variant allocates more resources to harder problems, optimizing the balance between efficiency and performance.","title":"Streamlining Language Models: Less Length, More Efficiency!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces GFPO (Group Filtered Policy Optimization), a method designed to reduce the excessive length of responses generated by large language models. It addresses the issue where models inflate response lengths to improve accuracy, often resulting in unnecessary filler content. By sampling larger groups during training and filtering based on response length and token efficiency, GFPO enhances computational efficiency while maintaining accuracy. Additionally, the Adaptive Difficulty GFPO variant allocates more resources to harder problems, optimizing the balance between efficiency and performance.', title='Streamlining Language Models: Less Length, More Efficiency!'))
[14.08.2025 22:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"GFPO（组过滤策略优化）通过在训练过程中对更大组进行采样，并根据响应长度和令牌效率进行过滤，减少了大型语言模型的长度膨胀。许多生成的文本只是冗余的填充内容，GFPO通过优化每个令牌的奖励比率，显著提高了计算效率。实验表明，GFPO在Phi-4推理模型上减少了46-71%的长度膨胀，同时保持了准确性。我们还提出了自适应难度GFPO，根据实时难度估计动态分配更多训练资源，从而在处理困难问题时提高了计算效率与准确性的平衡。","title":"GFPO：高效减少语言模型长度膨胀的创新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='GFPO（组过滤策略优化）通过在训练过程中对更大组进行采样，并根据响应长度和令牌效率进行过滤，减少了大型语言模型的长度膨胀。许多生成的文本只是冗余的填充内容，GFPO通过优化每个令牌的奖励比率，显著提高了计算效率。实验表明，GFPO在Phi-4推理模型上减少了46-71%的长度膨胀，同时保持了准确性。我们还提出了自适应难度GFPO，根据实时难度估计动态分配更多训练资源，从而在处理困难问题时提高了计算效率与准确性的平衡。', title='GFPO：高效减少语言模型长度膨胀的创新方法'))
[14.08.2025 22:12] Using data from previous issue: {"categories": ["#multimodal", "#cv"], "emoji": "🖌️", "ru": {"title": "CannyEdit: Точное редактирование изображений текстом без дополнительного обучения", "desc": "CannyEdit - это новая система для редактирования изображений с помощью текстовых запросов, не требующая дополнительного обучения. Она ис
[14.08.2025 22:12] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#diffusion", "#3d"], "emoji": "🖼️", "ru": {"title": "Улучшение 3D реконструкции с помощью генеративных моделей и опорных изображений", "desc": "GSFixer - это новый метод улучшения реконструкции 3D сцен с использованием 3D Gaussian Splatting из малого ч
[14.08.2025 22:12] Using data from previous issue: {"categories": ["#transfer_learning", "#robotics", "#rl", "#games", "#agents"], "emoji": "🚁", "ru": {"title": "Децентрализованное управление грузом с помощью роя дронов", "desc": "Эта статья представляет децентрализованный метод манипуляции грузом, подвешенным на тросе, с помощью группы микро-беспил
[14.08.2025 22:12] Using data from previous issue: {"categories": ["#interpretability", "#multimodal", "#optimization", "#dataset", "#benchmark", "#data"], "emoji": "🤖", "ru": {"title": "Автоматизация объяснений в NLP: LLM как альтернатива человеку", "desc": "Исследователи разработали автоматизированный метод генерации текстовых объяснений с использ
[14.08.2025 22:12] Querying the API.
[14.08.2025 22:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A new parameterization for Mixture-of-Experts models provides theoretical guarantees for feature learning and investigates the impact of scaling experts and granularity on learning rates.  					AI-generated summary 				 Recent years have seen a growing interest and adoption of LLMs, with muTransfer becoming a key technique for tuning hyperparameters in large-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a leading architecture in extremely large models. However, the intersection of these two advancements has remained unexplored. In this work, we derive a mu-Parameterization (muP) for MoE, providing theoretical guarantees for feature learning across model widths in both the router and experts. We empirically validate our parameterization and further investigate how scaling the number of experts and granularity affects the optimal learning rate.
[14.08.2025 22:12] Response: {
  "desc": "Статья представляет новую параметризацию для моделей Mixture-of-Experts (MoE), которая обеспечивает теоретические гарантии обучения признаков. Исследователи изучают влияние масштабирования экспертов и гранулярности на скорость обучения. Работа объединяет достижения в области больших языковых моделей (LLM) и архитектуры MoE. Авторы эмпирически подтверждают свою параметризацию и анализируют, как увеличение числа экспертов влияет на оптимальную скорость обучения.",
  "emoji": "🧠",
  "title": "Новая параметризация MoE: теория встречается с практикой"
}
[14.08.2025 22:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new parameterization for Mixture-of-Experts models provides theoretical guarantees for feature learning and investigates the impact of scaling experts and granularity on learning rates.  					AI-generated summary 				 Recent years have seen a growing interest and adoption of LLMs, with muTransfer becoming a key technique for tuning hyperparameters in large-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a leading architecture in extremely large models. However, the intersection of these two advancements has remained unexplored. In this work, we derive a mu-Parameterization (muP) for MoE, providing theoretical guarantees for feature learning across model widths in both the router and experts. We empirically validate our parameterization and further investigate how scaling the number of experts and granularity affects the optimal learning rate."

[14.08.2025 22:12] Response: ```python
["ARCHITECTURE", "TRAINING"]
```
[14.08.2025 22:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new parameterization for Mixture-of-Experts models provides theoretical guarantees for feature learning and investigates the impact of scaling experts and granularity on learning rates.  					AI-generated summary 				 Recent years have seen a growing interest and adoption of LLMs, with muTransfer becoming a key technique for tuning hyperparameters in large-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a leading architecture in extremely large models. However, the intersection of these two advancements has remained unexplored. In this work, we derive a mu-Parameterization (muP) for MoE, providing theoretical guarantees for feature learning across model widths in both the router and experts. We empirically validate our parameterization and further investigate how scaling the number of experts and granularity affects the optimal learning rate."

[14.08.2025 22:12] Response: ```python
["OPTIMIZATION"]
```
[14.08.2025 22:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new parameterization method called mu-Parameterization (muP) for Mixture-of-Experts (MoE) models, which enhances feature learning capabilities. It provides theoretical guarantees that ensure effective learning across different model widths, specifically in the router and expert components. The study also explores how varying the number of experts and their granularity influences the optimal learning rate during training. Empirical validation of the muP method demonstrates its effectiveness in improving the performance of large-scale models.","title":"Enhancing Mixture-of-Experts with mu-Parameterization for Better Learning Rates"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a new parameterization method called mu-Parameterization (muP) for Mixture-of-Experts (MoE) models, which enhances feature learning capabilities. It provides theoretical guarantees that ensure effective learning across different model widths, specifically in the router and expert components. The study also explores how varying the number of experts and their granularity influences the optimal learning rate during training. Empirical validation of the muP method demonstrates its effectiveness in improving the performance of large-scale models.', title='Enhancing Mixture-of-Experts with mu-Parameterization for Better Learning Rates'))
[14.08.2025 22:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的混合专家模型的参数化方法，称为mu-Parameterization（muP），为特征学习提供了理论保证。我们研究了专家数量和粒度的缩放对学习速率的影响。通过实验证明了我们的参数化方法的有效性，并探讨了在不同模型宽度下路由器和专家的特征学习。该研究为大规模训练中的超参数调优提供了新的视角。","title":"探索混合专家模型的新参数化方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的混合专家模型的参数化方法，称为mu-Parameterization（muP），为特征学习提供了理论保证。我们研究了专家数量和粒度的缩放对学习速率的影响。通过实验证明了我们的参数化方法的有效性，并探讨了在不同模型宽度下路由器和专家的特征学习。该研究为大规模训练中的超参数调优提供了新的视角。', title='探索混合专家模型的新参数化方法'))
[14.08.2025 22:12] Using data from previous issue: {"categories": ["#healthcare", "#dataset", "#architecture"], "emoji": "🔬", "ru": {"title": "Адаптивная сегментация для точной диагностики", "desc": "ASM-UNet - это новая архитектура на основе Mamba для сегментации медицинских изображений. Она использует адаптивные оценки сканирования для динамическо
[14.08.2025 22:12] Using data from previous issue: {"categories": ["#alignment", "#agi", "#rl", "#benchmark", "#reasoning", "#multimodal", "#optimization", "#open_source", "#training"], "emoji": "⚖️", "ru": {"title": "Балансирование обучения языковых моделей: новый подход к тонкой настройке", "desc": "Статья представляет новый метод обучения больших
[14.08.2025 22:12] Querying the API.
[14.08.2025 22:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ObfusQA, a novel framework with multi-tiered obfuscation levels, evaluates the robustness and adaptability of Large Language Models (LLMs) by examining their performance on obfuscated questions.  					AI-generated summary 				 The rapid proliferation of Large Language Models (LLMs) has significantly contributed to the development of equitable AI systems capable of factual question-answering (QA). However, no known study tests the LLMs' robustness when presented with obfuscated versions of questions. To systematically evaluate these limitations, we propose a novel technique, ObfusQAte and, leveraging the same, introduce ObfusQA, a comprehensive, first of its kind, framework with multi-tiered obfuscation levels designed to examine LLM capabilities across three distinct dimensions: (i) Named-Entity Indirection, (ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these fine-grained distinctions in language, ObfusQA provides a comprehensive benchmark for evaluating LLM robustness and adaptability. Our study observes that LLMs exhibit a tendency to fail or generate hallucinated responses when confronted with these increasingly nuanced variations. To foster research in this direction, we make ObfusQAte publicly available.
[14.08.2025 22:12] Response: {
  "desc": "ObfusQA - это новая система для оценки устойчивости и адаптивности больших языковых моделей (LLM) путем анализа их производительности на обфусцированных вопросах. Система использует многоуровневую обфускацию, включая косвенное именование сущностей, отвлекающие факторы и контекстуальную перегрузку. Исследование показало, что LLM склонны давать ошибочные или галлюцинаторные ответы при столкновении с такими вариациями вопросов. ObfusQAte, инструмент для создания обфусцированных вопросов, был опубликован для дальнейших исследований в этой области.",
  "emoji": "🔍",
  "title": "Проверка прочности языковых моделей: ObfusQA раскрывает слабые места LLM"
}
[14.08.2025 22:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ObfusQA, a novel framework with multi-tiered obfuscation levels, evaluates the robustness and adaptability of Large Language Models (LLMs) by examining their performance on obfuscated questions.  					AI-generated summary 				 The rapid proliferation of Large Language Models (LLMs) has significantly contributed to the development of equitable AI systems capable of factual question-answering (QA). However, no known study tests the LLMs' robustness when presented with obfuscated versions of questions. To systematically evaluate these limitations, we propose a novel technique, ObfusQAte and, leveraging the same, introduce ObfusQA, a comprehensive, first of its kind, framework with multi-tiered obfuscation levels designed to examine LLM capabilities across three distinct dimensions: (i) Named-Entity Indirection, (ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these fine-grained distinctions in language, ObfusQA provides a comprehensive benchmark for evaluating LLM robustness and adaptability. Our study observes that LLMs exhibit a tendency to fail or generate hallucinated responses when confronted with these increasingly nuanced variations. To foster research in this direction, we make ObfusQAte publicly available."

[14.08.2025 22:12] Response: ```python
['BENCHMARK', 'DATASET']
```
[14.08.2025 22:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ObfusQA, a novel framework with multi-tiered obfuscation levels, evaluates the robustness and adaptability of Large Language Models (LLMs) by examining their performance on obfuscated questions.  					AI-generated summary 				 The rapid proliferation of Large Language Models (LLMs) has significantly contributed to the development of equitable AI systems capable of factual question-answering (QA). However, no known study tests the LLMs' robustness when presented with obfuscated versions of questions. To systematically evaluate these limitations, we propose a novel technique, ObfusQAte and, leveraging the same, introduce ObfusQA, a comprehensive, first of its kind, framework with multi-tiered obfuscation levels designed to examine LLM capabilities across three distinct dimensions: (i) Named-Entity Indirection, (ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these fine-grained distinctions in language, ObfusQA provides a comprehensive benchmark for evaluating LLM robustness and adaptability. Our study observes that LLMs exhibit a tendency to fail or generate hallucinated responses when confronted with these increasingly nuanced variations. To foster research in this direction, we make ObfusQAte publicly available."

[14.08.2025 22:12] Response: ```python
["HALLUCINATIONS", "SECURITY", "ALIGNMENT", "OPEN_SOURCE"]
```
[14.08.2025 22:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ObfusQA is a new framework designed to test how well Large Language Models (LLMs) handle tricky, obfuscated questions. It introduces different levels of obfuscation to assess LLMs\' robustness in three areas: how they deal with named entities, distractors, and overloaded context. The study found that LLMs often struggle or produce incorrect answers when faced with these complex question formats. By making ObfusQAte available, the authors aim to encourage further research into improving LLM performance under challenging conditions.","title":"Testing LLMs: The Challenge of Obfuscated Questions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="ObfusQA is a new framework designed to test how well Large Language Models (LLMs) handle tricky, obfuscated questions. It introduces different levels of obfuscation to assess LLMs' robustness in three areas: how they deal with named entities, distractors, and overloaded context. The study found that LLMs often struggle or produce incorrect answers when faced with these complex question formats. By making ObfusQAte available, the authors aim to encourage further research into improving LLM performance under challenging conditions.", title='Testing LLMs: The Challenge of Obfuscated Questions'))
[14.08.2025 22:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ObfusQA是一个新颖的框架，旨在通过对模糊化问题的评估来测试大型语言模型（LLMs）的鲁棒性和适应性。该框架采用多层次的模糊化级别，涵盖了命名实体间接、干扰者间接和上下文过载三个维度。研究发现，当LLMs面对这些复杂的模糊化问题时，往往会出现失败或生成虚假回答的情况。为了推动这一领域的研究，我们将ObfusQAte公开发布。","title":"测试大型语言模型的鲁棒性与适应性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ObfusQA是一个新颖的框架，旨在通过对模糊化问题的评估来测试大型语言模型（LLMs）的鲁棒性和适应性。该框架采用多层次的模糊化级别，涵盖了命名实体间接、干扰者间接和上下文过载三个维度。研究发现，当LLMs面对这些复杂的模糊化问题时，往往会出现失败或生成虚假回答的情况。为了推动这一领域的研究，我们将ObfusQAte公开发布。', title='测试大型语言模型的鲁棒性与适应性'))
[14.08.2025 22:12] Renaming data file.
[14.08.2025 22:12] Renaming previous data. hf_papers.json to ./d/2025-08-14.json
[14.08.2025 22:12] Saving new data file.
[14.08.2025 22:12] Generating page.
[14.08.2025 22:12] Renaming previous page.
[14.08.2025 22:12] Renaming previous data. index.html to ./d/2025-08-14.html
[14.08.2025 22:12] Writing result.
[14.08.2025 22:12] Renaming log file.
[14.08.2025 22:12] Renaming previous data. log.txt to ./logs/2025-08-14_last_log.txt
