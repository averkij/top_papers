[18.12.2024 18:14] Read previous papers.
[18.12.2024 18:14] Generating top page (month).
[18.12.2024 18:14] Writing top page (month).
[18.12.2024 19:08] Read previous papers.
[18.12.2024 19:08] Get feed.
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.13147
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.12606
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.13018
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.13171
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.12276
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.13180
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.13194
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.10704
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.11713
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.12527
[18.12.2024 19:08] Get page data from previous paper. URL: https://huggingface.co/papers/2412.12877
[18.12.2024 19:08] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.12.2024 19:08] No deleted papers detected.
[18.12.2024 19:08] Downloading and parsing papers (pdf, html). Total: 11.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.13147.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.13147.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.13147.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.12606.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.12606.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.12606.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.13018.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.13018.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.13018.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.13171.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.13171.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.13171.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.12276.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.12276.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.12276.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.13180.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.13180.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.13180.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.13194.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.13194.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.13194.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.10704.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.10704.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.10704.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.11713.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.11713.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.11713.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.12527.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.12527.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.12527.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Downloading and parsing paper https://huggingface.co/papers/2412.12877.
[18.12.2024 19:08] Extra JSON file exists (./assets/json/2412.12877.json), skip PDF parsing.
[18.12.2024 19:08] Paper image links file exists (./assets/img_data/2412.12877.json), skip HTML parsing.
[18.12.2024 19:08] Success.
[18.12.2024 19:08] Enriching papers with extra data.
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 0. The rapid advancement of Large Language Models (LLMs) has demonstrated remarkable progress in complex reasoning tasks. However, a significant discrepancy persists between benchmark performances and real-world applications. We identify this gap as primarily stemming from current evaluation protocols ...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 1. The rapidly developing field of large multimodal models (LMMs) has led to the emergence of diverse models with remarkable capabilities. However, existing benchmarks fail to comprehensively, objectively and accurately evaluate whether LMMs align with the diverse needs of humans in real-world scenario...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 2. As a typical and practical application of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) techniques have gained extensive attention, particularly in vertical domains where LLMs may lack domain-specific knowledge. In this paper, we introduce an omnidirectional and automatic RAG be...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 3. Chain-of-thought (CoT) decoding enables language models to improve reasoning performance at the cost of high generation latency in decoding. Recent proposals have explored variants of contemplation tokens, a term we introduce that refers to special tokens used during inference to allow for extra com...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 4. Humans distill complex experiences into fundamental abstractions that enable rapid learning and adaptation. Similarly, autoregressive transformers exhibit adaptive learning through in-context learning (ICL), which begs the question of how. In this paper, we propose concept encoding-decoding mechanis...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 5. Recent works on accelerating Vision-Language Models show that strong performance can be maintained across a variety of vision-language tasks despite highly compressing visual information. In this work, we examine the popular acceleration approach of early pruning of visual tokens inside the language...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 6. The vision of a broadly capable and goal-directed agent, such as an Internet-browsing agent in the digital world and a household humanoid in the physical world, has rapidly advanced, thanks to the generalization capability of foundation models. Such a generalist agent needs to have a large and diver...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 7. Understanding information from a collection of multiple documents, particularly those with visually rich elements, is important for document-grounded question answering. This paper introduces VisDoMBench, the first comprehensive benchmark designed to evaluate QA systems in multi-document settings wi...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 8. In real world software development, improper or missing exception handling can severely impact the robustness and reliability of code. Exception handling mechanisms require developers to detect, capture, and manage exceptions according to high standards, but many developers struggle with these tasks...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 9. Large Language Models (LLMs) demonstrate exceptional performance across diverse tasks by leveraging both pre-trained knowledge (i.e., parametric knowledge) and external knowledge (i.e., contextual knowledge). While substantial efforts have been made to leverage both forms of knowledge, scenarios in ...
[18.12.2024 19:08] ********************************************************************************
[18.12.2024 19:08] Abstract 10. Recent AI-based video editing has enabled users to edit videos through simple text prompts, significantly simplifying the editing process. However, recent zero-shot video editing techniques primarily focus on global or single-object edits, which can lead to unintended changes in other parts of the v...
[18.12.2024 19:08] Read previous papers.
[18.12.2024 19:08] Generating reviews via LLM API.
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#math", "#benchmark", "#evaluation", "#reasoning", "#leakage"], "emoji": "🧮", "ru": {"title": "Новый подход к оценке способностей языковых моделей в сложных математических задачах", "desc": "Статья представляет новый метод оценки больших языковых моделей (LLM) в задачах сложных расс
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#reasoning", "#alignment", "#benchmark", "#multimodal"], "emoji": "🎯", "ru": {"title": "Многомерная оценка мультимодальных моделей для реальных задач", "desc": "Предложен новый бенчмарк Multi-Dimensional Insights (MDI) для оценки мультимодальных моделей. MDI включает более 500 изобр
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#rag", "#science"], "emoji": "📊", "ru": {"title": "OmniEval: Всесторонняя оценка RAG-систем в финансовой сфере", "desc": "Статья представляет OmniEval - многомерный бенчмарк для оценки методов Retrieval-Augmented Generation (RAG) в финансовой сфере. Авт
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#training", "#architecture", "#reasoning", "#inference"], "emoji": "🧠", "ru": {"title": "Сжатые цепочки рассуждений для более эффективных языковых моделей", "desc": "Статья представляет новый метод под названием Compressed Chain-of-Thought (CCoT) для улучшения рассуждений языковых м
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#synthetic", "#interpretability", "#transfer_learning", "#architecture", "#training"], "emoji": "🧠", "ru": {"title": "Раскрытие тайн обучения в контексте: как трансформеры формируют и используют абстракции", "desc": "Статья исследует механизмы обучения в контексте (ICL) у трансформе
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#inference", "#training", "#optimization"], "emoji": "🪶", "ru": {"title": "Эффективное ускорение мультимодальных моделей без потери точности", "desc": "Исследование посвящено ускорению моделей компьютерного зрения и обработки естественного языка (Vision-Language
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#rl", "#agents", "#agi"], "emoji": "🤖", "ru": {"title": "Автономное обучение агентов: от предложения задач до их выполнения", "desc": "Эта статья представляет новую систему обучения под названием Proposer-Agent-Evaluator (PAE) для агентов на основе ф
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#rag", "#reasoning", "#optimization", "#games", "#benchmark"], "emoji": "🔍", "ru": {"title": "Мультимодальный RAG для вопросно-ответного поиска в документах", "desc": "Статья представляет VisDoMBench - первый комплексный бенчмарк для оценки систем вопр
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#agents", "#open_source", "#science", "#plp"], "emoji": "🛡️", "ru": {"title": "Повышение надежности кода: LLM на страже обработки исключений", "desc": "Данная статья исследует использование больших языковых моделей (LLM) для улучшения обработки исключений в программном коде. Авторы 
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#multimodal", "#dataset", "#alignment", "#hallucinations", "#training"], "emoji": "🧠", "ru": {"title": "CDA: умное воздержание для надежных языковых моделей", "desc": "Эта статья представляет новый метод декодирования для больших языковых моделей (LLM) под названием Contrastive Deco
[18.12.2024 19:08] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#video", "#optimization", "#leakage"], "emoji": "🎬", "ru": {"title": "MIVE: Точное редактирование нескольких объектов в видео с помощью ИИ", "desc": "Статья представляет новый подход к редактированию видео с помощью искусственного интеллекта, названный MIVE
[18.12.2024 19:08] Loading Chinese text from previous data.
[18.12.2024 19:08] Renaming data file.
[18.12.2024 19:08] Renaming previous data. hf_papers.json to ./d/2024-12-18.json
[18.12.2024 19:08] Saving new data file.
[18.12.2024 19:08] Generating page.
[18.12.2024 19:08] Renaming previous page.
[18.12.2024 19:08] Renaming previous data. index.html to ./d/2024-12-18.html
[18.12.2024 19:08] [Experimental] Generating Chinese page for reading.
[18.12.2024 19:08] Chinese vocab [{'word': '大型', 'pinyin': 'dà xíng', 'trans': 'large-scale'}, {'word': '语言模型', 'pinyin': 'yǔ yán mó xíng', 'trans': 'language model'}, {'word': '复杂', 'pinyin': 'fù zá', 'trans': 'complex'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '任务', 'pinyin': 'rèn wu', 'trans': 'task'}, {'word': '取得', 'pinyin': 'qǔ dé', 'trans': 'achieve'}, {'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '实际', 'pinyin': 'shí jì', 'trans': 'actual'}, {'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'application'}, {'word': '差距', 'pinyin': 'chā jù', 'trans': 'gap'}, {'word': '存在', 'pinyin': 'cún zài', 'trans': 'exist'}, {'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluation'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '指标', 'pinyin': 'zhǐ biāo', 'trans': 'metric'}, {'word': '捕捉', 'pinyin': 'bǔ zhuō', 'trans': 'capture'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'capability'}, {'word': '准确性', 'pinyin': 'zhǔn què xìng', 'trans': 'accuracy'}, {'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '采样', 'pinyin': 'cǎi yàng', 'trans': 'sampling'}, {'word': '连续', 'pinyin': 'lián xù', 'trans': 'continuous'}, {'word': '量化', 'pinyin': 'liàng huà', 'trans': 'quantify'}, {'word': '潜力', 'pinyin': 'qián lì', 'trans': 'potential'}, {'word': '稳定性', 'pinyin': 'wěn dìng xìng', 'trans': 'stability'}, {'word': '推出', 'pinyin': 'tuī chū', 'trans': 'launch'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'}, {'word': '挑战性', 'pinyin': 'tiǎo zhàn xìng', 'trans': 'challenging'}, {'word': '当代', 'pinyin': 'dāng dài', 'trans': 'contemporary'}, {'word': '数学', 'pinyin': 'shù xué', 'trans': 'mathematics'}, {'word': '问题', 'pinyin': 'wèn tí', 'trans': 'problem'}, {'word': '旨在', 'pinyin': 'zhǐ zài', 'trans': 'aim to'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '泄露', 'pinyin': 'xiè lòu', 'trans': 'leak'}, {'word': '风险', 'pinyin': 'fēng xiǎn', 'trans': 'risk'}, {'word': '详细', 'pinyin': 'xiáng xì', 'trans': 'detailed'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '访问', 'pinyin': 'fǎng wèn', 'trans': 'access'}]
[18.12.2024 19:08] Renaming previous Chinese page.
[18.12.2024 19:08] Renaming previous data. zh.html to ./d/2024-12-17_zh_reading_task.html
[18.12.2024 19:08] Writing Chinese reading task.
[18.12.2024 19:08] Writing result.
[18.12.2024 19:08] Renaming log file.
[18.12.2024 19:08] Renaming previous data. log.txt to ./logs/2024-12-18_last_log.txt
