[18.12.2024 08:14] Read previous papers.
[18.12.2024 08:14] Generating top page (month).
[18.12.2024 08:14] Writing top page (month).
[18.12.2024 09:11] Read previous papers.
[18.12.2024 09:11] Get feed.
[18.12.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2412.13147
[18.12.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2412.12606
[18.12.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2412.13018
[18.12.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2412.12276
[18.12.2024 09:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.12.2024 09:11] No deleted papers detected.
[18.12.2024 09:11] Downloading and parsing papers (pdf, html). Total: 4.
[18.12.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2412.13147.
[18.12.2024 09:11] Extra JSON file exists (./assets/json/2412.13147.json), skip PDF parsing.
[18.12.2024 09:11] Paper image links file exists (./assets/img_data/2412.13147.json), skip HTML parsing.
[18.12.2024 09:11] Success.
[18.12.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2412.12606.
[18.12.2024 09:11] Extra JSON file exists (./assets/json/2412.12606.json), skip PDF parsing.
[18.12.2024 09:11] Paper image links file exists (./assets/img_data/2412.12606.json), skip HTML parsing.
[18.12.2024 09:11] Success.
[18.12.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2412.13018.
[18.12.2024 09:11] Extra JSON file exists (./assets/json/2412.13018.json), skip PDF parsing.
[18.12.2024 09:11] Paper image links file exists (./assets/img_data/2412.13018.json), skip HTML parsing.
[18.12.2024 09:11] Success.
[18.12.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2412.12276.
[18.12.2024 09:11] Extra JSON file exists (./assets/json/2412.12276.json), skip PDF parsing.
[18.12.2024 09:11] Paper image links file exists (./assets/img_data/2412.12276.json), skip HTML parsing.
[18.12.2024 09:11] Success.
[18.12.2024 09:11] Enriching papers with extra data.
[18.12.2024 09:11] ********************************************************************************
[18.12.2024 09:11] Abstract 0. The rapid advancement of Large Language Models (LLMs) has demonstrated remarkable progress in complex reasoning tasks. However, a significant discrepancy persists between benchmark performances and real-world applications. We identify this gap as primarily stemming from current evaluation protocols ...
[18.12.2024 09:11] ********************************************************************************
[18.12.2024 09:11] Abstract 1. The rapidly developing field of large multimodal models (LMMs) has led to the emergence of diverse models with remarkable capabilities. However, existing benchmarks fail to comprehensively, objectively and accurately evaluate whether LMMs align with the diverse needs of humans in real-world scenario...
[18.12.2024 09:11] ********************************************************************************
[18.12.2024 09:11] Abstract 2. As a typical and practical application of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) techniques have gained extensive attention, particularly in vertical domains where LLMs may lack domain-specific knowledge. In this paper, we introduce an omnidirectional and automatic RAG be...
[18.12.2024 09:11] ********************************************************************************
[18.12.2024 09:11] Abstract 3. Humans distill complex experiences into fundamental abstractions that enable rapid learning and adaptation. Similarly, autoregressive transformers exhibit adaptive learning through in-context learning (ICL), which begs the question of how. In this paper, we propose concept encoding-decoding mechanis...
[18.12.2024 09:11] Read previous papers.
[18.12.2024 09:11] Generating reviews via LLM API.
[18.12.2024 09:11] Using data from previous issue: {"categories": ["#math", "#benchmark", "#evaluation", "#reasoning", "#leakage"], "emoji": "🧮", "ru": {"title": "Новый подход к оценке способностей языковых моделей в сложных математических задачах", "desc": "Статья представляет новый метод оценки больших языковых моделей (LLM) в задачах сложных расс
[18.12.2024 09:11] Using data from previous issue: {"categories": ["#reasoning", "#alignment", "#benchmark", "#multimodal"], "emoji": "🎯", "ru": {"title": "Многомерная оценка мультимодальных моделей для реальных задач", "desc": "Предложен новый бенчмарк Multi-Dimensional Insights (MDI) для оценки мультимодальных моделей. MDI включает более 500 изобр
[18.12.2024 09:11] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#rag", "#science"], "emoji": "📊", "ru": {"title": "OmniEval: Всесторонняя оценка RAG-систем в финансовой сфере", "desc": "Статья представляет OmniEval - многомерный бенчмарк для оценки методов Retrieval-Augmented Generation (RAG) в финансовой сфере. Авт
[18.12.2024 09:11] Using data from previous issue: {"categories": ["#synthetic", "#interpretability", "#transfer_learning", "#architecture", "#training"], "emoji": "🧠", "ru": {"title": "Раскрытие тайн обучения в контексте: как трансформеры формируют и используют абстракции", "desc": "Статья исследует механизмы обучения в контексте (ICL) у трансформе
[18.12.2024 09:11] Trying to get texts in Chinese.
[18.12.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

The rapid advancement of Large Language Models (LLMs) has demonstrated remarkable progress in complex reasoning tasks. However, a significant discrepancy persists between benchmark performances and real-world applications. We identify this gap as primarily stemming from current evaluation protocols and metrics, which inadequately capture the full spectrum of LLM capabilities, particularly in complex reasoning tasks where both accuracy and consistency are crucial. This work makes two key contributions. First, we introduce G-Pass@k, a novel evaluation metric that provides a continuous assessment of model performance across multiple sampling attempts, quantifying both the model's peak performance potential and its stability. Second, we present LiveMathBench, a dynamic benchmark comprising challenging, contemporary mathematical problems designed to minimize data leakage risks during evaluation. Through extensive experiments using G-Pass@k on state-of-the-art LLMs with LiveMathBench, we provide comprehensive insights into both their maximum capabilities and operational consistency. Our findings reveal substantial room for improvement in LLMs' "realistic" reasoning capabilities, highlighting the need for more robust evaluation methods. The benchmark and detailed results are available at: https://github.com/open-compass/GPassK.
[18.12.2024 09:11] Mistral response. {"id": "8efd73e14cba46f1815491defb0bb7cf", "object": "chat.completion", "created": 1734513091, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002\u7136\u800c\uff0c\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u4ecd\u5b58\u5728\u5dee\u8ddd\u3002\u4e3b\u8981\u539f\u56e0\u662f\u5f53\u524d\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u6307\u6807\u65e0\u6cd5\u5145\u5206\u6355\u6349LLMs\u7684\u5168\u90e8\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u3002\u672c\u6587\u63d0\u51fa\u4e86G-Pass@k\uff0c\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u80fd\u591f\u5728\u591a\u6b21\u91c7\u6837\u4e2d\u8fde\u7eed\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u91cf\u5316\u6a21\u578b\u7684\u6700\u9ad8\u6027\u80fd\u6f5c\u529b\u548c\u7a33\u5b9a\u6027\u3002\u540c\u65f6\uff0c\u6211\u4eec\u63a8\u51fa\u4e86LiveMathBench\uff0c\u4e00\u4e2a\u5305\u542b\u5177\u6709\u6311\u6218\u6027\u3001\u5f53\u4ee3\u6570\u5b66\u95ee\u9898\u7684\u52a8\u6001\u57fa\u51c6\uff0c\u65e8\u5728\u51cf\u5c11\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u7684\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002\u8be6\u7ec6\u7ed3\u679c\u548c\u57fa\u51c6\u53ef\u8bbf\u95ee\uff1ahttps://github.com/open-compass/GPassK\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 280, "total_tokens": 529, "completion_tokens": 249}}
[18.12.2024 09:11] Response: 大型语言模型（LLMs）在复杂推理任务中取得了显著进展。然而，基准测试性能与实际应用之间仍存在差距。主要原因是当前的评估方法和指标无法充分捕捉LLMs的全部能力，特别是在需要准确性和一致性的复杂推理任务中。本文提出了G-Pass@k，一个新的评估指标，能够在多次采样中连续评估模型性能，量化模型的最高性能潜力和稳定性。同时，我们推出了LiveMathBench，一个包含具有挑战性、当代数学问题的动态基准，旨在减少评估过程中的数据泄露风险。详细结果和基准可访问：https://github.com/open-compass/GPassK。
[18.12.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

大型语言模型（LLMs）在复杂推理任务中取得了显著进展。然而，基准测试性能与实际应用之间仍存在差距。主要原因是当前的评估方法和指标无法充分捕捉LLMs的全部能力，特别是在需要准确性和一致性的复杂推理任务中。本文提出了G-Pass@k，一个新的评估指标，能够在多次采样中连续评估模型性能，量化模型的最高性能潜力和稳定性。同时，我们推出了LiveMathBench，一个包含具有挑战性、当代数学问题的动态基准，旨在减少评估过程中的数据泄露风险。详细结果和基准可访问：https://github.com/open-compass/GPassK。
[18.12.2024 09:11] Mistral response. {"id": "0cbbcd8ca8ec428b80ed5c7242388bf1", "object": "chat.completion", "created": 1734513100, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "D\u00e0x\u00edng y\u01d4y\u00e1n m\u00f3x\u00edng (LLMs) z\u00e0i f\u00f9z\u00e1 x\u012bngl\u01d0 r\u00e8nw\u00f9 zh\u014dng q\u01d4d\u00e9le xi\u01cenzh\u00f9 j\u00ecnb\u00f9. R\u00e1n'\u00e9r, j\u012bzh\u01d4n c\u00e8sh\u01d0 x\u00ecngn\u00e9ng y\u01d4 sh\u00edj\u00ec y\u00ecngy\u00f2ng zh\u012bji\u0101n r\u00e9ng c\u00fanz\u00e0i ch\u0101j\u00f9. Zh\u01d4y\u00e0o yu\u00e1ny\u012bn sh\u00ec d\u0101ngqi\u00e1n de p\u00edngg\u01d4 f\u0101ngf\u01ce h\u00e9 zh\u01d0bi\u0101o w\u00faf\u01ce ch\u014dngf\u0113n b\u01d0ngq\u01d4 LLMs de qu\u00e1nb\u00f9 n\u00e9ngl\u00ec, t\u00e8bi\u00e9 sh\u00ec z\u00e0i x\u016by\u00e0o zh\u01d4nqu\u00e8x\u00ecng h\u00e9 y\u012bzh\u00ecx\u00ecng de f\u00f9z\u00e1 x\u012bngl\u01d0 r\u00e8nw\u00f9 zh\u014dng. B\u011bnw\u00e9n t\u00edch\u016ble G-Pass@k, y\u012bg\u00e8 x\u012bn de p\u00edngg\u01d4 zh\u01d0bi\u0101o, n\u00e9ngg\u00f2u z\u00e0i du\u014dc\u00ec c\u01ceiy\u00e0ng zh\u014dng li\u00e1nx\u00f9 p\u00edngg\u01d4 m\u00f3x\u00edng x\u00ecngn\u00e9ng, li\u00e0ngzh\u00ec m\u00f3x\u00edng de zu\u00ecg\u0101o x\u00ecngn\u00e9ng qi\u00e1nl\u00ec h\u00e9 w\u011bnd\u00edngx\u00ecng. T\u00f3ngsh\u00ed, w\u01d2men tu\u012bch\u016ble LiveMathBench, y\u012bg\u00e8 b\u0101oh\u00e1n j\u00f9y\u01d2u ti\u01ceozh\u00e0nx\u00ecng, d\u0101ngd\u00e0i sh\u00f9xu\u00e9 w\u00e8nt\u00ed de d\u00f2ngt\u00e0i j\u012bzh\u01d4n, zh\u01d0y\u00fa ji\u01censh\u01ceo p\u00edngg\u01d4 gu\u00f2ch\u00e9ng zh\u014dng de sh\u00f9j\u00f9 l\u00f2ush\u00ec f\u0113ngxi\u01cen. Xi\u00e1ngx\u00ec ji\u00e9gu\u01d2 h\u00e9 j\u012bzh\u01d4n k\u011b f\u0101ngw\u00e8n: https://github.com/open-compass/GPassK."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 264, "total_tokens": 746, "completion_tokens": 482}}
[18.12.2024 09:11] Response: Dàxíng yǔyán móxíng (LLMs) zài fùzá xīnglǐ rènwù zhōng qǔdéle xiǎnzhù jìnbù. Rán'ér, jīzhǔn cèshǐ xìngnéng yǔ shíjì yìngyòng zhījiān réng cúnzài chājù. Zhǔyào yuányīn shì dāngqián de pínggǔ fāngfǎ hé zhǐbiāo wúfǎ chōngfēn bǐngqǔ LLMs de quánbù nénglì, tèbié shì zài xūyào zhǔnquèxìng hé yīzhìxìng de fùzá xīnglǐ rènwù zhōng. Běnwén tíchūle G-Pass@k, yīgè xīn de pínggǔ zhǐbiāo, nénggòu zài duōcì cǎiyàng zhōng liánxù pínggǔ móxíng xìngnéng, liàngzhì móxíng de zuìgāo xìngnéng qiánlì hé wěndíngxìng. Tóngshí, wǒmen tuīchūle LiveMathBench, yīgè bāohán jùyǒu tiǎozhànxìng, dāngdài shùxué wèntí de dòngtài jīzhǔn, zhǐyú jiǎnshǎo pínggǔ guòchéng zhōng de shùjù lòushì fēngxiǎn. Xiángxì jiéguǒ hé jīzhǔn kě fāngwèn: https://github.com/open-compass/GPassK.
[18.12.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

大型语言模型（LLMs）在复杂推理任务中取得了显著进展。然而，基准测试性能与实际应用之间仍存在差距。主要原因是当前的评估方法和指标无法充分捕捉LLMs的全部能力，特别是在需要准确性和一致性的复杂推理任务中。本文提出了G-Pass@k，一个新的评估指标，能够在多次采样中连续评估模型性能，量化模型的最高性能潜力和稳定性。同时，我们推出了LiveMathBench，一个包含具有挑战性、当代数学问题的动态基准，旨在减少评估过程中的数据泄露风险。详细结果和基准可访问：https://github.com/open-compass/GPassK。
[18.12.2024 09:12] Mistral response. {"id": "86525f9df3d3484fad0183260608a68d", "object": "chat.completion", "created": 1734513110, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[{'word': '\u5927\u578b', 'pinyin': 'd\u00e0 x\u00edng', 'trans': 'large-scale'},\n{'word': '\u8bed\u8a00\u6a21\u578b', 'pinyin': 'y\u01d4 y\u00e1n m\u00f3 x\u00edng', 'trans': 'language model'},\n{'word': '\u590d\u6742', 'pinyin': 'f\u00f9 z\u00e1', 'trans': 'complex'},\n{'word': '\u63a8\u7406', 'pinyin': 'tu\u012b l\u01d0', 'trans': 'reasoning'},\n{'word': '\u4efb\u52a1', 'pinyin': 'r\u00e8n wu', 'trans': 'task'},\n{'word': '\u53d6\u5f97', 'pinyin': 'q\u01d4 d\u00e9', 'trans': 'achieve'},\n{'word': '\u8fdb\u5c55', 'pinyin': 'j\u00ecn zh\u01cen', 'trans': 'progress'},\n{'word': '\u57fa\u51c6', 'pinyin': 'j\u012b zh\u01d4n', 'trans': 'benchmark'},\n{'word': '\u6d4b\u8bd5', 'pinyin': 'c\u00e8 sh\u00ec', 'trans': 'test'},\n{'word': '\u6027\u80fd', 'pinyin': 'x\u00ecng n\u00e9ng', 'trans': 'performance'},\n{'word': '\u5b9e\u9645', 'pinyin': 'sh\u00ed j\u00ec', 'trans': 'actual'},\n{'word': '\u5e94\u7528', 'pinyin': 'y\u00ecng y\u00f2ng', 'trans': 'application'},\n{'word': '\u5dee\u8ddd', 'pinyin': 'ch\u0101 j\u00f9', 'trans': 'gap'},\n{'word': '\u5b58\u5728', 'pinyin': 'c\u00fan z\u00e0i', 'trans': 'exist'},\n{'word': '\u8bc4\u4f30', 'pinyin': 'p\u00edng g\u016b', 'trans': 'evaluation'},\n{'word': '\u65b9\u6cd5', 'pinyin': 'f\u0101ng f\u01ce', 'trans': 'method'},\n{'word': '\u6307\u6807', 'pinyin': 'zh\u01d0 bi\u0101o', 'trans': 'metric'},\n{'word': '\u6355\u6349', 'pinyin': 'b\u01d4 zhu\u014d', 'trans': 'capture'},\n{'word': '\u80fd\u529b', 'pinyin': 'n\u00e9ng l\u00ec', 'trans': 'capability'},\n{'word': '\u51c6\u786e\u6027', 'pinyin': 'zh\u01d4n qu\u00e8 x\u00ecng', 'trans': 'accuracy'},\n{'word': '\u4e00\u81f4\u6027', 'pinyin': 'y\u012b zh\u00ec x\u00ecng', 'trans': 'consistency'},\n{'word': '\u63d0\u51fa', 'pinyin': 't\u00ed ch\u016b', 'trans': 'propose'},\n{'word': '\u91c7\u6837', 'pinyin': 'c\u01cei y\u00e0ng', 'trans': 'sampling'},\n{'word': '\u8fde\u7eed', 'pinyin': 'li\u00e1n x\u00f9', 'trans': 'continuous'},\n{'word': '\u91cf\u5316', 'pinyin': 'li\u00e0ng hu\u00e0', 'trans': 'quantify'},\n{'word': '\u6f5c\u529b', 'pinyin': 'qi\u00e1n l\u00ec', 'trans': 'potential'},\n{'word': '\u7a33\u5b9a\u6027', 'pinyin': 'w\u011bn d\u00ecng x\u00ecng', 'trans': 'stability'},\n{'word': '\u63a8\u51fa', 'pinyin': 'tu\u012b ch\u016b', 'trans': 'launch'},\n{'word': '\u52a8\u6001', 'pinyin': 'd\u00f2ng t\u00e0i', 'trans': 'dynamic'},\n{'word': '\u6311\u6218\u6027', 'pinyin': 'ti\u01ceo zh\u00e0n x\u00ecng', 'trans': 'challenging'},\n{'word': '\u5f53\u4ee3', 'pinyin': 'd\u0101ng d\u00e0i', 'trans': 'contemporary'},\n{'word': '\u6570\u5b66', 'pinyin': 'sh\u00f9 xu\u00e9', 'trans': 'mathematics'},\n{'word': '\u95ee\u9898', 'pinyin': 'w\u00e8n t\u00ed', 'trans': 'problem'},\n{'word': '\u65e8\u5728', 'pinyin': 'zh\u01d0 z\u00e0i', 'trans': 'aim to'},\n{'word': '\u51cf\u5c11', 'pinyin': 'ji\u01cen sh\u01ceo', 'trans': 'reduce'},\n{'word': '\u6cc4\u9732', 'pinyin': 'xi\u00e8 l\u00f2u', 'trans': 'leak'},\n{'word': '\u98ce\u9669', 'pinyin': 'f\u0113ng xi\u01cen', 'trans': 'risk'},\n{'word': '\u8be6\u7ec6', 'pinyin': 'xi\u00e1ng x\u00ec', 'trans': 'detailed'},\n{'word': '\u7ed3\u679c', 'pinyin': 'ji\u00e9 gu\u01d2', 'trans': 'result'},\n{'word': '\u8bbf\u95ee', 'pinyin': 'f\u01ceng w\u00e8n', 'trans': 'access'}]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 296, "total_tokens": 1408, "completion_tokens": 1112}}
[18.12.2024 09:12] Response: [{'word': '大型', 'pinyin': 'dà xíng', 'trans': 'large-scale'},
{'word': '语言模型', 'pinyin': 'yǔ yán mó xíng', 'trans': 'language model'},
{'word': '复杂', 'pinyin': 'fù zá', 'trans': 'complex'},
{'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'},
{'word': '任务', 'pinyin': 'rèn wu', 'trans': 'task'},
{'word': '取得', 'pinyin': 'qǔ dé', 'trans': 'achieve'},
{'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'},
{'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'},
{'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'},
{'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'},
{'word': '实际', 'pinyin': 'shí jì', 'trans': 'actual'},
{'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'application'},
{'word': '差距', 'pinyin': 'chā jù', 'trans': 'gap'},
{'word': '存在', 'pinyin': 'cún zài', 'trans': 'exist'},
{'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluation'},
{'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'},
{'word': '指标', 'pinyin': 'zhǐ biāo', 'trans': 'metric'},
{'word': '捕捉', 'pinyin': 'bǔ zhuō', 'trans': 'capture'},
{'word': '能力', 'pinyin': 'néng lì', 'trans': 'capability'},
{'word': '准确性', 'pinyin': 'zhǔn què xìng', 'trans': 'accuracy'},
{'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'},
{'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'},
{'word': '采样', 'pinyin': 'cǎi yàng', 'trans': 'sampling'},
{'word': '连续', 'pinyin': 'lián xù', 'trans': 'continuous'},
{'word': '量化', 'pinyin': 'liàng huà', 'trans': 'quantify'},
{'word': '潜力', 'pinyin': 'qián lì', 'trans': 'potential'},
{'word': '稳定性', 'pinyin': 'wěn dìng xìng', 'trans': 'stability'},
{'word': '推出', 'pinyin': 'tuī chū', 'trans': 'launch'},
{'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'},
{'word': '挑战性', 'pinyin': 'tiǎo zhàn xìng', 'trans': 'challenging'},
{'word': '当代', 'pinyin': 'dāng dài', 'trans': 'contemporary'},
{'word': '数学', 'pinyin': 'shù xué', 'trans': 'mathematics'},
{'word': '问题', 'pinyin': 'wèn tí', 'trans': 'problem'},
{'word': '旨在', 'pinyin': 'zhǐ zài', 'trans': 'aim to'},
{'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'},
{'word': '泄露', 'pinyin': 'xiè lòu', 'trans': 'leak'},
{'word': '风险', 'pinyin': 'fēng xiǎn', 'trans': 'risk'},
{'word': '详细', 'pinyin': 'xiáng xì', 'trans': 'detailed'},
{'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'},
{'word': '访问', 'pinyin': 'fǎng wèn', 'trans': 'access'}]
[18.12.2024 09:12] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

大型语言模型（LLMs）在复杂推理任务中取得了显著进展。然而，基准测试性能与实际应用之间仍存在差距。主要原因是当前的评估方法和指标无法充分捕捉LLMs的全部能力，特别是在需要准确性和一致性的复杂推理任务中。本文提出了G-Pass@k，一个新的评估指标，能够在多次采样中连续评估模型性能，量化模型的最高性能潜力和稳定性。同时，我们推出了LiveMathBench，一个包含具有挑战性、当代数学问题的动态基准，旨在减少评估过程中的数据泄露风险。详细结果和基准可访问：https://github.com/open-compass/GPassK。
[18.12.2024 09:12] Mistral response. {"id": "4df555df4e7c48aa99e900f142751b53", "object": "chat.completion", "created": 1734513132, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "Large language models (LLMs) have made significant strides in complex reasoning tasks. However, there remains a gap between benchmark test performance and real-world applications. The primary reason is that current evaluation methods and metrics fail to fully capture the capabilities of LLMs, especially in complex reasoning tasks that require accuracy and consistency. This paper introduces G-Pass@k, a new evaluation metric that can continuously assess model performance across multiple samples, quantifying the model's peak performance potential and stability. Additionally, we present LiveMathBench, a dynamic benchmark containing challenging, contemporary mathematical problems aimed at reducing the risk of data leakage during the evaluation process. Detailed results and benchmarks are available at: https://github.com/open-compass/GPassK."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 262, "total_tokens": 420, "completion_tokens": 158}}
[18.12.2024 09:12] Response: Large language models (LLMs) have made significant strides in complex reasoning tasks. However, there remains a gap between benchmark test performance and real-world applications. The primary reason is that current evaluation methods and metrics fail to fully capture the capabilities of LLMs, especially in complex reasoning tasks that require accuracy and consistency. This paper introduces G-Pass@k, a new evaluation metric that can continuously assess model performance across multiple samples, quantifying the model's peak performance potential and stability. Additionally, we present LiveMathBench, a dynamic benchmark containing challenging, contemporary mathematical problems aimed at reducing the risk of data leakage during the evaluation process. Detailed results and benchmarks are available at: https://github.com/open-compass/GPassK.
[18.12.2024 09:12] Renaming data file.
[18.12.2024 09:12] Renaming previous data. hf_papers.json to ./d/2024-12-18.json
[18.12.2024 09:12] Saving new data file.
[18.12.2024 09:12] Generating page.
[18.12.2024 09:12] Renaming previous page.
[18.12.2024 09:12] Renaming previous data. index.html to ./d/2024-12-18.html
[18.12.2024 09:12] [Experimental] Generating Chinese page for reading.
[18.12.2024 09:12] Chinese vocab [{'word': '大型', 'pinyin': 'dà xíng', 'trans': 'large-scale'}, {'word': '语言模型', 'pinyin': 'yǔ yán mó xíng', 'trans': 'language model'}, {'word': '复杂', 'pinyin': 'fù zá', 'trans': 'complex'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '任务', 'pinyin': 'rèn wu', 'trans': 'task'}, {'word': '取得', 'pinyin': 'qǔ dé', 'trans': 'achieve'}, {'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '实际', 'pinyin': 'shí jì', 'trans': 'actual'}, {'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'application'}, {'word': '差距', 'pinyin': 'chā jù', 'trans': 'gap'}, {'word': '存在', 'pinyin': 'cún zài', 'trans': 'exist'}, {'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluation'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '指标', 'pinyin': 'zhǐ biāo', 'trans': 'metric'}, {'word': '捕捉', 'pinyin': 'bǔ zhuō', 'trans': 'capture'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'capability'}, {'word': '准确性', 'pinyin': 'zhǔn què xìng', 'trans': 'accuracy'}, {'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '采样', 'pinyin': 'cǎi yàng', 'trans': 'sampling'}, {'word': '连续', 'pinyin': 'lián xù', 'trans': 'continuous'}, {'word': '量化', 'pinyin': 'liàng huà', 'trans': 'quantify'}, {'word': '潜力', 'pinyin': 'qián lì', 'trans': 'potential'}, {'word': '稳定性', 'pinyin': 'wěn dìng xìng', 'trans': 'stability'}, {'word': '推出', 'pinyin': 'tuī chū', 'trans': 'launch'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'}, {'word': '挑战性', 'pinyin': 'tiǎo zhàn xìng', 'trans': 'challenging'}, {'word': '当代', 'pinyin': 'dāng dài', 'trans': 'contemporary'}, {'word': '数学', 'pinyin': 'shù xué', 'trans': 'mathematics'}, {'word': '问题', 'pinyin': 'wèn tí', 'trans': 'problem'}, {'word': '旨在', 'pinyin': 'zhǐ zài', 'trans': 'aim to'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '泄露', 'pinyin': 'xiè lòu', 'trans': 'leak'}, {'word': '风险', 'pinyin': 'fēng xiǎn', 'trans': 'risk'}, {'word': '详细', 'pinyin': 'xiáng xì', 'trans': 'detailed'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '访问', 'pinyin': 'fǎng wèn', 'trans': 'access'}]
[18.12.2024 09:12] Renaming previous Chinese page.
[18.12.2024 09:12] Renaming previous data. zh.html to ./d/2024-12-17_zh_reading_task.html
[18.12.2024 09:12] Writing Chinese reading task.
[18.12.2024 09:12] Writing result.
[18.12.2024 09:12] Renaming log file.
[18.12.2024 09:12] Renaming previous data. log.txt to ./logs/2024-12-18_last_log.txt
