[28.01.2026 09:37] Read previous papers.
[28.01.2026 09:37] Generating top page (month).
[28.01.2026 09:37] Writing top page (month).
[28.01.2026 10:31] Read previous papers.
[28.01.2026 10:31] Get feed.
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18491
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18631
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18692
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19834
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.09150
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17645
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19375
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19362
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19149
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18292
[28.01.2026 10:31] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18116
[28.01.2026 10:31] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.01.2026 10:31] No deleted papers detected.
[28.01.2026 10:31] Downloading and parsing papers (pdf, html). Total: 11.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.18491.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.18491.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.18491.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.18631.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.18631.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.18631.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.18692.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.18692.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.18692.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.19834.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.19834.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.19834.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.09150.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.09150.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.09150.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.17645.
[28.01.2026 10:31] Downloading paper 2601.17645 from https://arxiv.org/pdf/2601.17645v1...
[28.01.2026 10:31] Failed to download and parse paper https://huggingface.co/papers/2601.17645: 'LTChar' object is not iterable
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.19375.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.19375.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.19375.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.19362.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.19362.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.19362.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.19149.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.19149.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.19149.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.18292.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.18292.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.18292.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Downloading and parsing paper https://huggingface.co/papers/2601.18116.
[28.01.2026 10:31] Extra JSON file exists (./assets/json/2601.18116.json), skip PDF parsing.
[28.01.2026 10:31] Paper image links file exists (./assets/img_data/2601.18116.json), skip HTML parsing.
[28.01.2026 10:31] Success.
[28.01.2026 10:31] Enriching papers with extra data.
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 0. AI agents face safety and security challenges from autonomous tool use and environmental interactions, requiring advanced guardrail frameworks for risk diagnosis and transparent monitoring.  					AI-generated summary 				 The rise of AI agents introduces complex safety and security challenges arisin...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 1. AdaReasoner enables multimodal models to learn tool usage as a general reasoning skill through scalable data curation, reinforcement learning for tool selection, and adaptive learning mechanisms that improve performance on complex visual reasoning tasks.  					AI-generated summary 				 When humans f...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 2. A Vision-Language-Action model trained on extensive real-world robotic data demonstrates superior performance and generalization across multiple platforms while offering enhanced efficiency through optimized training infrastructure.  					AI-generated summary 				 Offering great potential in robotic...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 3. Visual generation enhances reasoning capabilities in multimodal models by providing more natural world models for physical and spatial tasks, while verbal reasoning remains sufficient for abstract domains.  					AI-generated summary 				 Humans construct internal world models and reason by manipulat...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 4. World Craft enables non-expert users to create executable and visualizable AI environments through textual descriptions by combining structured scaffolding and multi-agent intent analysis.  					AI-generated summary 				 Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Tow...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 5. Current multimodal models demonstrate limited understanding of cultural and contextual audio-visual content, particularly excelling only in surface-level analysis rather than deeper semantic comprehension.  					AI-generated summary 				 Internet audio-visual clips convey meaning through time-varyin...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 6. Selective Steering enables continuous, norm-preserving control of language model behavior through targeted layer selection and mathematically rigorous rotation techniques.  					AI-generated summary 				 Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adv...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 7. On-Demand Communication (ODC) adapts parameter server principles to Fully Sharded Data Parallel training by replacing collective communication with point-to-point communication, improving device utilization and throughput in imbalanced large language model training scenarios.  					AI-generated summ...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 8. GPCR-Filter is a deep learning framework that combines protein language models and graph neural networks to identify GPCR modulators with high accuracy and generalization across unseen receptors and ligands.  					AI-generated summary 				 G protein-coupled receptors (GPCRs) govern diverse physiolog...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 9. A closed-loop reinforcement learning framework enables iterative collaboration between attacker, defender, and evaluator roles for improved large language model safety alignment without manual annotations.  					AI-generated summary 				 In recent years, safety risks associated with large language m...
[28.01.2026 10:31] ********************************************************************************
[28.01.2026 10:31] Abstract 10. FABLE is a forest-based adaptive bi-path retrieval framework that enhances LLM-based information retrieval through hierarchical indexing and structured evidence acquisition, achieving superior performance with reduced token usage compared to traditional RAG methods.  					AI-generated summary 				 T...
[28.01.2026 10:31] Read previous papers.
[28.01.2026 10:31] Generating reviews via LLM API.
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#agents", "#benchmark", "#alignment", "#security"], "emoji": "üõ°Ô∏è", "ru": {"title": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º –ø—Ä–∏—á–∏–Ω —Ä–∏—Å–∫–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –≤—ã–∑–æ–≤—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ AI-–∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∏–Ω
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#reasoning", "#data", "#rl", "#optimization", "#training", "#multimodal", "#benchmark"], "emoji": "üîß", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –∫–∞–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–º—É –Ω–∞–≤—ã–∫—É –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "AdaReasoner ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—É—á–∞—é—Ç—Å—è –∏—Å–ø–æ
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#multimodal", "#inference", "#benchmark", "#robotics", "#dataset", "#training"], "emoji": "ü§ñ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–æ–±–æ—Ç–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑—Ä–µ–Ω–∏—è, —è–∑—ã–∫–∞ –∏ –¥–µ–π—Å—Ç–≤–∏—è", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å Vision-Language-Action (VLA), –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ 20,000 —á–∞—Å–æ–≤ —Ä–µ–∞–ª—å–Ω—ã—Ö
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#multimodal"], "emoji": "üé®", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∏—Ä–∞ —É–ª—É—á—à–∞–µ—Ç –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∞–≤—Ç–æ—Ä—ã –∏—Å—Å–ª–µ–¥—É—é—Ç, –∫–æ–≥–¥–∞ –∏ –∫–∞–∫ –≤–∏–∑—É–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö. –û–Ω–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#open_source", "#games"], "emoji": "üéÆ", "ru": {"title": "–î–µ–º–æ–∫—Ä–∞—Ç–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –º–∏—Ä–æ–≤ —á–µ—Ä–µ–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫", "desc": "World Craft ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö AI-–æ–∫—Ä—É–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è. –°–∏
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#video", "#multimodal", "#benchmark", "#audio"], "emoji": "üé¨", "ru": {"title": "–ó–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏: –∫—É–ª—å—Ç—É—Ä–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ AVMeme Exam –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM) 
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#security", "#alignment", "#interpretability"], "emoji": "üéØ", "ru": {"title": "–°–µ–ª–µ–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Å–æ—Ö—Ä–∞–Ω—è—é—â–∏–µ –Ω–æ—Ä–º—É —Ä–æ—Ç–∞—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Selective Steering –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#training"], "emoji": "‚ö°", "ru": {"title": "–ì–∏–±–∫–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è –≤–º–µ—Å—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: —É—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –Ω–µ—É—Ä–∞–≤–Ω–æ–≤–µ—à–µ–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç On-Demand Communication (ODC) ‚Äî –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#science", "#graphs"], "emoji": "üíä", "ru": {"title": "–ö–æ–≥–¥–∞ –º–∞—à–∏–Ω—ã —É—á–∞—Ç—Å—è –Ω–∞—Ö–æ–¥–∏—Ç—å –ª–µ–∫–∞—Ä—Å—Ç–≤–∞: GPCR-Filter –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥—É–ª—è—Ç–æ—Ä–æ–≤ —Ä–µ—Ü–µ–ø—Ç–æ—Ä–æ–≤", "desc": "GPCR-Filter ‚Äî —ç—Ç–æ –≥–ª—É–±–æ–∫–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–æ–¥–µ–ª–∏ —è–∑—ã–∫–æ–≤ –±–µ–ª–∫–æ–≤ –∏ –≥—Ä–∞—Ñ–æ–≤—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥—É
[28.01.2026 10:31] Using data from previous issue: {"categories": ["#security", "#training", "#alignment", "#optimization", "#rl", "#rlhf"], "emoji": "üîÑ", "ru": {"title": "–ó–∞–º–∫–Ω—É—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ LLM", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∑–∞–º–∫–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ
[28.01.2026 10:31] Using data from previous issue: {"categories": [], "emoji": "üå≤", "ru": {"title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è RAG —á–µ—Ä–µ–∑ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ª–µ—Å–∞", "desc": "FABLE ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–µ—Å–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç LLM –≤ –ø—Ä–æ—Ü–µ—Å—Å—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π –∏ –∏—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏—è. –°–∏—Å
[28.01.2026 10:31] Renaming data file.
[28.01.2026 10:31] Renaming previous data. hf_papers.json to ./d/2026-01-28.json
[28.01.2026 10:31] Saving new data file.
[28.01.2026 10:31] Generating page.
[28.01.2026 10:31] Renaming previous page.
[28.01.2026 10:31] Renaming previous data. index.html to ./d/2026-01-28.html
[28.01.2026 10:31] Writing result.
[28.01.2026 10:31] Renaming log file.
[28.01.2026 10:31] Renaming previous data. log.txt to ./logs/2026-01-28_last_log.txt
