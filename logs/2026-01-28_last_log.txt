[28.01.2026 10:31] Read previous papers.
[28.01.2026 10:31] Generating top page (month).
[28.01.2026 10:31] Writing top page (month).
[28.01.2026 11:24] Read previous papers.
[28.01.2026 11:24] Get feed.
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18491
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18631
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18692
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19834
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.09150
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17645
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19375
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19362
[28.01.2026 11:24] Extract page data from URL. URL: https://huggingface.co/papers/2601.19895
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19149
[28.01.2026 11:24] Extract page data from URL. URL: https://huggingface.co/papers/2601.18724
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18292
[28.01.2026 11:24] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18116
[28.01.2026 11:24] Extract page data from URL. URL: https://huggingface.co/papers/2601.19532
[28.01.2026 11:24] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.01.2026 11:24] No deleted papers detected.
[28.01.2026 11:24] Downloading and parsing papers (pdf, html). Total: 14.
[28.01.2026 11:24] Downloading and parsing paper https://huggingface.co/papers/2601.18491.
[28.01.2026 11:24] Extra JSON file exists (./assets/json/2601.18491.json), skip PDF parsing.
[28.01.2026 11:24] Paper image links file exists (./assets/img_data/2601.18491.json), skip HTML parsing.
[28.01.2026 11:24] Success.
[28.01.2026 11:24] Downloading and parsing paper https://huggingface.co/papers/2601.18631.
[28.01.2026 11:24] Extra JSON file exists (./assets/json/2601.18631.json), skip PDF parsing.
[28.01.2026 11:24] Paper image links file exists (./assets/img_data/2601.18631.json), skip HTML parsing.
[28.01.2026 11:24] Success.
[28.01.2026 11:24] Downloading and parsing paper https://huggingface.co/papers/2601.18692.
[28.01.2026 11:24] Extra JSON file exists (./assets/json/2601.18692.json), skip PDF parsing.
[28.01.2026 11:24] Paper image links file exists (./assets/img_data/2601.18692.json), skip HTML parsing.
[28.01.2026 11:24] Success.
[28.01.2026 11:24] Downloading and parsing paper https://huggingface.co/papers/2601.19834.
[28.01.2026 11:24] Extra JSON file exists (./assets/json/2601.19834.json), skip PDF parsing.
[28.01.2026 11:24] Paper image links file exists (./assets/img_data/2601.19834.json), skip HTML parsing.
[28.01.2026 11:24] Success.
[28.01.2026 11:24] Downloading and parsing paper https://huggingface.co/papers/2601.09150.
[28.01.2026 11:24] Extra JSON file exists (./assets/json/2601.09150.json), skip PDF parsing.
[28.01.2026 11:24] Paper image links file exists (./assets/img_data/2601.09150.json), skip HTML parsing.
[28.01.2026 11:24] Success.
[28.01.2026 11:24] Downloading and parsing paper https://huggingface.co/papers/2601.17645.
[28.01.2026 11:24] Downloading paper 2601.17645 from https://arxiv.org/pdf/2601.17645v1...
[28.01.2026 11:25] Failed to download and parse paper https://huggingface.co/papers/2601.17645: 'LTChar' object is not iterable
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.19375.
[28.01.2026 11:25] Extra JSON file exists (./assets/json/2601.19375.json), skip PDF parsing.
[28.01.2026 11:25] Paper image links file exists (./assets/img_data/2601.19375.json), skip HTML parsing.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.19362.
[28.01.2026 11:25] Extra JSON file exists (./assets/json/2601.19362.json), skip PDF parsing.
[28.01.2026 11:25] Paper image links file exists (./assets/img_data/2601.19362.json), skip HTML parsing.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.19895.
[28.01.2026 11:25] Downloading paper 2601.19895 from https://arxiv.org/pdf/2601.19895v1...
[28.01.2026 11:25] Extracting affiliations from text.
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Post-LayerNorm Is Back: Stable, ExpressivE, and Deep Chen Chen, Lai Wei, Equal Contribution, Corresponding authors "
[28.01.2026 11:25] Response: ```python
[]
```
[28.01.2026 11:25] Extracting affiliations from text.
[28.01.2026 11:25] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Post-LayerNorm Is Back: Stable, ExpressivE, and Deep Chen Chen, Lai Wei,Equal Contribution, Corresponding authorsLarge language model (LLM) scaling is hitting wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, Post-LN Transformer that replaces this residual path with Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with Highway-style connection, provides simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures. Date: January 28, 2026 Correspondence: Lai Wei at laiwei.future@bytedance.com 6 2 0 2 7 2 ] . [ 1 5 9 8 9 1 . 1 0 6 2 : r (a) Training Stability (b) Expressiveness (c) Depth Scaling Figure 1 KEEL enables stable, expressive, and deep LLM training. (a) Training Stability: Keel maintains smooth convergence at aggressive learning rates, while Pre-LN exhibits severe instability under the same configuration. (b) Expressiveness: Keel demonstrates superior performance across all capability domains, particularly in Math & Code (+16.5%). (c) Depth Scaling: Keel consistently outperforms Pre-LN across all depths (64-1024 layers). Together, these results demonstrate that Keels architectural improvements enable stable optimization of ultra-deep networks with enhanced learning efficiency and model expressiveness.Large language model (LLM) progress has been driven primarily by scaling: bigger models, longer context windows, and larger training corpora. Yet these conventional scaling axes are beginning to show diminishing returns. Width scaling saturates quickly, context scaling grows increasingly expensive, and parameter growth alone does not unlock qualitatively new behaviors. As result, LLM scaling is hitting wall, and there is increasing interest in architectural directions that can deliver more expressivity per parameter. Depth scaling offers promising path forward. In principle, deeper networks can represent exponentially richer functions and support more hierarchical reasoning. However, current LLM architectures struggle to capitalize on depth. Training becomes increasingly unstable at extreme depths, and even when optimization succeeds, depth scaling delivers substantially worse returns than width scaling under current architectures. The placement of Layer Normalization (LN), which is seemingly simple architectural choice, has an enormous effect on depth scaling. The original Transformer architecture used Post-LayerNorm (Post-LN), but modern LLMs overwhelmingly adopt Pre-LayerNorm (Pre-LN) [4, 25]. Pre-LN stabilizes early training by normalizing each sublayers input, preventing the divergence commonly seen in deep Post-LN networks [29]. However, Pre-LN introduces its own structural limitations: it weakens gradient propagation and reduces the effective contribution of deeper layers [17]. As models grow deeper, this results in poor depth scaling and representational expressivity, limiting the potential of depth as new scaling axis. In contrast, Post-LN maintains large gradient signals in deeper layers, which can support superior depth scaling. Yet its training instability has made it unsuitable for LLM-scale models. When the residual output and transformed features are summed and then normalized, gradients in LayerNorm can exhibit extreme variability, especially in deep regimes [29]. Previous attempts to revive Post-LN, such as DeepNorm [27], Admin [15], and more recent hybrid normalization strategies [14, 35], mitigate some failure modes but do not fundamentally resolve the gradient pathologies of Post-LN LLMs, nor do they demonstrate reliable behavior at the depths needed to break the scaling limits of today. To understand the root cause of these instabilities, we formally analyze the gradient dynamics of Post-LN. We derive bounds on the backward signal and show that the ResNet-style residual path is the primary source of gradient vanishing. These issues arise not from normalization itself, but from the way that residual and transformed activations are mixed before normalization. Motivated by this analysis, we consider small yet impactful architectural change: replace the ResNet-style residual branch with simplified Highway-style connection, and re-express its gradient dynamics under the same theoretical framework. Our results show that this Highway-style pathway provides provable control of gradient magnitudes, allowing signals to propagate through depth without vanishing. Crucially, it maintains the inter-layer coupling that makes Post-LN expressive, while suppressing the unstable mixing that previously made Post-LN difficult to train. Guided by these findings, we introduce Keel, Post-LN architecture that incorporates lightweight Highwaystyle gated connection [21]. The gate dynamically balances carry and transform signals, regulating both forward and backward information flow. This simple modification stabilizes Post-LN at scale, enabling it to realize its expressivity advantages without special initialization or customized residual scaling. Empirically, Keel delivers substantial gains in depth scalability and model performance, effectively addressing the training stability issues often associated with traditional deep architectures. By integrating Highwaystyle pathway with revived Post-LN configuration, Keel enables robust training at depths exceeding 1000 layers.1 While standard Post-LN or Pre-LN architectures often exhibit severe instability when subjected to aggressive learning rates, Keel maintains smooth convergence, suggesting more well-conditione"
[28.01.2026 11:25] Mistral response. {"id": "f3f6454e89354257811dcf4c5c27c8af", "created": 1769599509, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1308, "total_tokens": 1319, "completion_tokens": 11, "num_cached_tokens": 1307}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Bytedance\"]\n```"}}]}
[28.01.2026 11:25] Response: ```python
["Bytedance"]
```
[28.01.2026 11:25] Deleting PDF ./assets/pdf/2601.19895.pdf.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.19149.
[28.01.2026 11:25] Extra JSON file exists (./assets/json/2601.19149.json), skip PDF parsing.
[28.01.2026 11:25] Paper image links file exists (./assets/img_data/2601.19149.json), skip HTML parsing.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.18724.
[28.01.2026 11:25] Downloading paper 2601.18724 from https://arxiv.org/pdf/2601.18724v1...
[28.01.2026 11:25] Extracting affiliations from text.
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 6 2 ] . [ 1 4 2 7 8 1 . 1 0 6 2 : r HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe Nara Institute of Science and Technology (NAIST), Japan {sakai.yusuke.sr9, kamigaito.h, taro}@is.naist.jp "
[28.01.2026 11:25] Response: ```python
["Nara Institute of Science and Technology (NAIST), Japan"]
```
[28.01.2026 11:25] Deleting PDF ./assets/pdf/2601.18724.pdf.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.18292.
[28.01.2026 11:25] Extra JSON file exists (./assets/json/2601.18292.json), skip PDF parsing.
[28.01.2026 11:25] Paper image links file exists (./assets/img_data/2601.18292.json), skip HTML parsing.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.18116.
[28.01.2026 11:25] Extra JSON file exists (./assets/json/2601.18116.json), skip PDF parsing.
[28.01.2026 11:25] Paper image links file exists (./assets/img_data/2601.18116.json), skip HTML parsing.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Downloading and parsing paper https://huggingface.co/papers/2601.19532.
[28.01.2026 11:25] Downloading paper 2601.19532 from https://arxiv.org/pdf/2601.19532v1...
[28.01.2026 11:25] Extracting affiliations from text.
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 7 2 ] . [ 1 2 3 5 9 1 . 1 0 6 2 : r a Marthe Ballon1,2, 0009-0000-4586-234X Andres Algaba1,2 0000-0002-0532-3066 Brecht Verbeken1,2 0000-0002-7506-3298 Vincent Ginis1,2,3 0000-0003-0063-9608 1Data Analytics Lab, Vrije Universiteit Brussel, Pleinlaan 5, 1050 Brussel, Belgium 2imec-SMIT, Vrije Universiteit Brussel, Pleinlaan 9, 1050 Brussels, Belgium 3School of Engineering and Applied Sciences, Harvard University, Cambridge, Massachusetts 02138, USA January 28, "
[28.01.2026 11:25] Response: ```python
[
    "Data Analytics Lab, Vrije Universiteit Brussel",
    "imec-SMIT, Vrije Universiteit Brussel",
    "School of Engineering and Applied Sciences, Harvard University"
]
```
[28.01.2026 11:25] Deleting PDF ./assets/pdf/2601.19532.pdf.
[28.01.2026 11:25] Success.
[28.01.2026 11:25] Enriching papers with extra data.
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 0. AI agents face safety and security challenges from autonomous tool use and environmental interactions, requiring advanced guardrail frameworks for risk diagnosis and transparent monitoring.  					AI-generated summary 				 The rise of AI agents introduces complex safety and security challenges arisin...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 1. AdaReasoner enables multimodal models to learn tool usage as a general reasoning skill through scalable data curation, reinforcement learning for tool selection, and adaptive learning mechanisms that improve performance on complex visual reasoning tasks.  					AI-generated summary 				 When humans f...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 2. A Vision-Language-Action model trained on extensive real-world robotic data demonstrates superior performance and generalization across multiple platforms while offering enhanced efficiency through optimized training infrastructure.  					AI-generated summary 				 Offering great potential in robotic...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 3. Visual generation enhances reasoning capabilities in multimodal models by providing more natural world models for physical and spatial tasks, while verbal reasoning remains sufficient for abstract domains.  					AI-generated summary 				 Humans construct internal world models and reason by manipulat...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 4. World Craft enables non-expert users to create executable and visualizable AI environments through textual descriptions by combining structured scaffolding and multi-agent intent analysis.  					AI-generated summary 				 Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Tow...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 5. Current multimodal models demonstrate limited understanding of cultural and contextual audio-visual content, particularly excelling only in surface-level analysis rather than deeper semantic comprehension.  					AI-generated summary 				 Internet audio-visual clips convey meaning through time-varyin...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 6. Selective Steering enables continuous, norm-preserving control of language model behavior through targeted layer selection and mathematically rigorous rotation techniques.  					AI-generated summary 				 Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adv...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 7. On-Demand Communication (ODC) adapts parameter server principles to Fully Sharded Data Parallel training by replacing collective communication with point-to-point communication, improving device utilization and throughput in imbalanced large language model training scenarios.  					AI-generated summ...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 8. A novel Post-LayerNorm Transformer architecture called Keel addresses training instability in extremely deep networks by replacing residual connections with Highway-style connections, enabling stable training beyond 1000 layers.  					AI-generated summary 				 Large language model (LLM) scaling is h...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 9. GPCR-Filter is a deep learning framework that combines protein language models and graph neural networks to identify GPCR modulators with high accuracy and generalization across unseen receptors and ligands.  					AI-generated summary 				 G protein-coupled receptors (GPCRs) govern diverse physiolog...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 10. Hallucinated citations, defined as false references to non-existent works, are prevalent in recent NLP conference publications, with significant implications for scientific reliability and conference credibility.  					AI-generated summary 				 Recently, we have often observed hallucinated citations...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 11. A closed-loop reinforcement learning framework enables iterative collaboration between attacker, defender, and evaluator roles for improved large language model safety alignment without manual annotations.  					AI-generated summary 				 In recent years, safety risks associated with large language m...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 12. FABLE is a forest-based adaptive bi-path retrieval framework that enhances LLM-based information retrieval through hierarchical indexing and structured evidence acquisition, achieving superior performance with reduced token usage compared to traditional RAG methods.  					AI-generated summary 				 T...
[28.01.2026 11:25] ********************************************************************************
[28.01.2026 11:25] Abstract 13. A revised mathematical benchmark dataset was created through manual auditing to reduce noise and improve model performance assessment accuracy.  					AI-generated summary 				 Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in dat...
[28.01.2026 11:25] Read previous papers.
[28.01.2026 11:25] Generating reviews via LLM API.
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#agents", "#benchmark", "#alignment", "#security"], "emoji": "üõ°Ô∏è", "ru": {"title": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º –ø—Ä–∏—á–∏–Ω —Ä–∏—Å–∫–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –≤—ã–∑–æ–≤—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ AI-–∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∏–Ω
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#reasoning", "#data", "#rl", "#optimization", "#training", "#multimodal", "#benchmark"], "emoji": "üîß", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –∫–∞–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–º—É –Ω–∞–≤—ã–∫—É –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "AdaReasoner ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—É—á–∞—é—Ç—Å—è –∏—Å–ø–æ
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#multimodal", "#inference", "#benchmark", "#robotics", "#dataset", "#training"], "emoji": "ü§ñ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–æ–±–æ—Ç–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑—Ä–µ–Ω–∏—è, —è–∑—ã–∫–∞ –∏ –¥–µ–π—Å—Ç–≤–∏—è", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å Vision-Language-Action (VLA), –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ 20,000 —á–∞—Å–æ–≤ —Ä–µ–∞–ª—å–Ω—ã—Ö
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#multimodal"], "emoji": "üé®", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∏—Ä–∞ —É–ª—É—á—à–∞–µ—Ç –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∞–≤—Ç–æ—Ä—ã –∏—Å—Å–ª–µ–¥—É—é—Ç, –∫–æ–≥–¥–∞ –∏ –∫–∞–∫ –≤–∏–∑—É–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö. –û–Ω–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#open_source", "#games"], "emoji": "üéÆ", "ru": {"title": "–î–µ–º–æ–∫—Ä–∞—Ç–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –º–∏—Ä–æ–≤ —á–µ—Ä–µ–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫", "desc": "World Craft ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö AI-–æ–∫—Ä—É–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è. –°–∏
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#video", "#multimodal", "#benchmark", "#audio"], "emoji": "üé¨", "ru": {"title": "–ó–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏: –∫—É–ª—å—Ç—É—Ä–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ AVMeme Exam –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM) 
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#security", "#alignment", "#interpretability"], "emoji": "üéØ", "ru": {"title": "–°–µ–ª–µ–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Å–æ—Ö—Ä–∞–Ω—è—é—â–∏–µ –Ω–æ—Ä–º—É —Ä–æ—Ç–∞—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Selective Steering –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#training"], "emoji": "‚ö°", "ru": {"title": "–ì–∏–±–∫–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è –≤–º–µ—Å—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: —É—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –Ω–µ—É—Ä–∞–≤–Ω–æ–≤–µ—à–µ–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç On-Demand Communication (ODC) ‚Äî –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω
[28.01.2026 11:25] Querying the API.
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel Post-LayerNorm Transformer architecture called Keel addresses training instability in extremely deep networks by replacing residual connections with Highway-style connections, enabling stable training beyond 1000 layers.  					AI-generated summary 				 Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures.
[28.01.2026 11:25] Response: ```json
{
  "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç Keel ‚Äî –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Post-LayerNorm, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –≤ –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç—è—Ö. –û—Å–Ω–æ–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –∑–∞–º–µ–Ω–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö —Å–≤—è–∑–µ–π –Ω–∞ Highway-–ø–æ–¥–æ–±–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ª—É—á—à–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø—Ä–∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ –≥–ª—É–±–æ–∫—É—é —Å–µ—Ç—å. –¢–∞–∫–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ –≥–ª—É–±–∏–Ω–æ–π —Å–≤—ã—à–µ 1000 —Å–ª–æ—ë–≤ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç—Ä—é–∫–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. Keel –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ª—É—á—à–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–µ—Ä–ø–ª–µ–∫—Å–∏–∏ –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –≥–ª—É–±–∏–Ω–µ –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ Pre-LN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏.",
  "emoji": "üèóÔ∏è",
  "title": "–ì–ª—É–±–∏–Ω–∞ –≤–º–µ—Å—Ç–æ —à–∏—Ä–∏–Ω—ã: Highway-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ—Ä—Ö–≥–ª—É–±–æ–∫–∏—Ö –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤"
}
```
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel Post-LayerNorm Transformer architecture called Keel addresses training instability in extremely deep networks by replacing residual connections with Highway-style connections, enabling stable training beyond 1000 layers.  					AI-generated summary 				 Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures."

[28.01.2026 11:25] Response: ```python
["ARCHITECTURE", "TRAINING"]
```
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel Post-LayerNorm Transformer architecture called Keel addresses training instability in extremely deep networks by replacing residual connections with Highway-style connections, enabling stable training beyond 1000 layers.  					AI-generated summary 				 Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures."

[28.01.2026 11:25] Response: ```python
['OPTIMIZATION', 'LONG_CONTEXT']
```
[28.01.2026 11:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Keel, a new Post-LayerNorm Transformer architecture designed to improve training stability in very deep networks. By replacing traditional residual connections with Highway-style connections, Keel maintains better gradient flow, which helps prevent issues like gradient vanishing. This allows the model to be trained effectively at depths exceeding 1000 layers without the need for complex initialization or optimization techniques. The results show that Keel outperforms previous architectures in perplexity and depth-scaling, suggesting a promising direction for future deep learning models.","title":"Keel: Unlocking the Power of Deep Transformers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces Keel, a new Post-LayerNorm Transformer architecture designed to improve training stability in very deep networks. By replacing traditional residual connections with Highway-style connections, Keel maintains better gradient flow, which helps prevent issues like gradient vanishing. This allows the model to be trained effectively at depths exceeding 1000 layers without the need for complex initialization or optimization techniques. The results show that Keel outperforms previous architectures in perplexity and depth-scaling, suggesting a promising direction for future deep learning models.', title='Keel: Unlocking the Power of Deep Transformers'))
[28.01.2026 11:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂêéÂ±ÇÂΩí‰∏ÄÂåñÂèòÊç¢Âô®Êû∂ÊûÑÔºåÁß∞‰∏∫KeelÔºåÊó®Âú®Ëß£ÂÜ≥ÊûÅÊ∑±ÁΩëÁªúËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÁöÑÈóÆÈ¢ò„ÄÇKeelÈÄöËøáÁî®È´òÈÄüÂÖ¨Ë∑ØÈ£éÊ†ºÁöÑËøûÊé•Êõø‰ª£ÊÆãÂ∑ÆËøûÊé•Ôºå‰ΩøÂæóÂú®Ë∂ÖËøá1000Â±ÇÁöÑÊ∑±Â∫¶‰∏ã‰πüËÉΩÂÆûÁé∞Á®≥ÂÆöËÆ≠ÁªÉ„ÄÇ‰∏é‰º†ÁªüÁöÑÂêéÂ±ÇÂΩí‰∏ÄÂåñÊñπÊ≥ïÁõ∏ÊØîÔºåKeelËÉΩÂ§üÊúâÊïàÂú∞‰øùÊåÅÊ¢ØÂ∫¶ÊµÅÂä®ÔºåÈò≤Ê≠¢‰ø°Âè∑Âú®Ê∑±Â±ÇÁΩëÁªú‰∏≠Ê∂àÂ§±„ÄÇÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÁªìÂêàÈ´òÈÄüÂÖ¨Ë∑ØËøûÊé•ÁöÑÂêéÂ±ÇÂΩí‰∏ÄÂåñ‰∏∫ÊûÑÂª∫Ê∑±Â∫¶ÂèØÊâ©Â±ïÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõ‰∫ÜÁÆÄÂçïËÄåÊúâÊïàÁöÑÂü∫Á°Ä„ÄÇ","title":"KeelÔºöÊ∑±Â∫¶ÂèØÊâ©Â±ïÁöÑÂèòÊç¢Âô®Êñ∞ÈÄâÊã©"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂêéÂ±ÇÂΩí‰∏ÄÂåñÂèòÊç¢Âô®Êû∂ÊûÑÔºåÁß∞‰∏∫KeelÔºåÊó®Âú®Ëß£ÂÜ≥ÊûÅÊ∑±ÁΩëÁªúËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÁöÑÈóÆÈ¢ò„ÄÇKeelÈÄöËøáÁî®È´òÈÄüÂÖ¨Ë∑ØÈ£éÊ†ºÁöÑËøûÊé•Êõø‰ª£ÊÆãÂ∑ÆËøûÊé•Ôºå‰ΩøÂæóÂú®Ë∂ÖËøá1000Â±ÇÁöÑÊ∑±Â∫¶‰∏ã‰πüËÉΩÂÆûÁé∞Á®≥ÂÆöËÆ≠ÁªÉ„ÄÇ‰∏é‰º†ÁªüÁöÑÂêéÂ±ÇÂΩí‰∏ÄÂåñÊñπÊ≥ïÁõ∏ÊØîÔºåKeelËÉΩÂ§üÊúâÊïàÂú∞‰øùÊåÅÊ¢ØÂ∫¶ÊµÅÂä®ÔºåÈò≤Ê≠¢‰ø°Âè∑Âú®Ê∑±Â±ÇÁΩëÁªú‰∏≠Ê∂àÂ§±„ÄÇÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÁªìÂêàÈ´òÈÄüÂÖ¨Ë∑ØËøûÊé•ÁöÑÂêéÂ±ÇÂΩí‰∏ÄÂåñ‰∏∫ÊûÑÂª∫Ê∑±Â∫¶ÂèØÊâ©Â±ïÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõ‰∫ÜÁÆÄÂçïËÄåÊúâÊïàÁöÑÂü∫Á°Ä„ÄÇ', title='KeelÔºöÊ∑±Â∫¶ÂèØÊâ©Â±ïÁöÑÂèòÊç¢Âô®Êñ∞ÈÄâÊã©'))
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#science", "#graphs"], "emoji": "üíä", "ru": {"title": "–ö–æ–≥–¥–∞ –º–∞—à–∏–Ω—ã —É—á–∞—Ç—Å—è –Ω–∞—Ö–æ–¥–∏—Ç—å –ª–µ–∫–∞—Ä—Å—Ç–≤–∞: GPCR-Filter –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥—É–ª—è—Ç–æ—Ä–æ–≤ —Ä–µ—Ü–µ–ø—Ç–æ—Ä–æ–≤", "desc": "GPCR-Filter ‚Äî —ç—Ç–æ –≥–ª—É–±–æ–∫–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–æ–¥–µ–ª–∏ —è–∑—ã–∫–æ–≤ –±–µ–ª–∫–æ–≤ –∏ –≥—Ä–∞—Ñ–æ–≤—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥—É
[28.01.2026 11:25] Querying the API.
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Hallucinated citations, defined as false references to non-existent works, are prevalent in recent NLP conference publications, with significant implications for scientific reliability and conference credibility.  					AI-generated summary 				 Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.
[28.01.2026 11:25] Response: ```json
{
  "desc": "–í –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è—Ö (HalluCitation) ‚Äî –ª–æ–∂–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã –≤ —Å—Ç–∞—Ç—å—è—Ö –Ω–∞ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è—Ö NLP. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–µ–ª–∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π –Ω–∞ ACL, NAACL –∏ EMNLP –∑–∞ 2024-2025 –≥–æ–¥—ã –∏ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –ø–æ—á—Ç–∏ 300 —Å—Ç–∞—Ç–µ–π —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–∞–∫–∏–µ –æ—à–∏–±–æ—á–Ω—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –ü—Ä–æ–±–ª–µ–º–∞ –æ—Å–æ–±–µ–Ω–Ω–æ –æ—Å—Ç—Ä–∞—è –¥–ª—è EMNLP 2025, –≥–¥–µ –±–æ–ª–µ–µ –ø–æ–ª–æ–≤–∏–Ω—ã –≤—Å–µ—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –ø–æ—è–≤–∏–ª–∏—Å—å –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–æ–∫–ª–∞–¥–∞—Ö –∏ —Å–µ–∫—Ü–∏–∏ Findings. –≠—Ç–æ –ø–æ–¥–Ω–∏–º–∞–µ—Ç —Å–µ—Ä—å—ë–∑–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –æ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∏ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–π –≤ —ç–ø–æ—Ö—É –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.",
  "emoji": "üö®",
  "title": "–ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –≤ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è—Ö —É–≥—Ä–æ–∂–∞—é—Ç –Ω–∞—É—á–Ω–æ–π –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ NLP-–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–π"
}
```
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hallucinated citations, defined as false references to non-existent works, are prevalent in recent NLP conference publications, with significant implications for scientific reliability and conference credibility.  					AI-generated summary 				 Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility."

[28.01.2026 11:25] Response: ```python
["BENCHMARK"]
```

**Reasoning:** This paper systematically analyzes and evaluates the prevalence of hallucinated citations across major NLP conference publications (ACL, NAACL, EMNLP). It establishes metrics and findings about a quality issue in published research, which relates to evaluating and benchmarking the reliability of scientific publications in the NLP field. The paper functions as an analysis framework for assessing conference paper quality.
[28.01.2026 11:25] Error. Failed to parse JSON from LLM. ["BENCHMARK"]


**Reasoning:** This paper systematically analyzes and evaluates the prevalence of hallucinated citations across major NLP conference publications (ACL, NAACL, EMNLP). It establishes metrics and findings about a quality issue in published research, which relates to evaluating and benchmarking the reliability of scientific publications in the NLP field. The paper functions as an analysis framework for assessing conference paper quality.
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hallucinated citations, defined as false references to non-existent works, are prevalent in recent NLP conference publications, with significant implications for scientific reliability and conference credibility.  					AI-generated summary 				 Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility."

[28.01.2026 11:25] Response: ```python
["HALLUCINATIONS"]
```
[28.01.2026 11:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the issue of hallucinated citations, which are false references to non-existent works, in recent NLP conference publications. The authors define these misleading citations as \'HalluCitation\' and highlight their prevalence in papers from major conferences like ACL, NAACL, and EMNLP. Their analysis shows that nearly 300 papers published in 2024 and 2025 contain at least one HalluCitation, with a significant concentration in the latest EMNLP conference. The findings raise serious concerns about the reliability of scientific literature and the credibility of conferences due to the increasing occurrence of these citations.","title":"Addressing the Rise of HalluCitations in NLP Research"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper investigates the issue of hallucinated citations, which are false references to non-existent works, in recent NLP conference publications. The authors define these misleading citations as 'HalluCitation' and highlight their prevalence in papers from major conferences like ACL, NAACL, and EMNLP. Their analysis shows that nearly 300 papers published in 2024 and 2025 contain at least one HalluCitation, with a significant concentration in the latest EMNLP conference. The findings raise serious concerns about the reliability of scientific literature and the credibility of conferences due to the increasing occurrence of these citations.", title='Addressing the Rise of HalluCitations in NLP Research'))
[28.01.2026 11:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÁ†îÁ©∂‰∫ÜÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰ºöËÆÆËÆ∫Êñá‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑËôöÂÅáÂºïÁî®Áé∞Ë±°ÔºåÁß∞‰∏∫\\"HalluCitation\\"„ÄÇËøô‰∫õËôöÂÅáÂºïÁî®ÊåáÁöÑÊòØÂØπ‰∏çÂ≠òÂú®ÁöÑÊñáÁåÆÁöÑÈîôËØØÂºïÁî®Ôºå‰∏•ÈáçÂΩ±Âìç‰∫ÜÁßëÂ≠¶Á†îÁ©∂ÁöÑÂèØÈù†ÊÄß„ÄÇÈÄöËøáÂàÜÊûê2024Âíå2025Âπ¥Âú®ACL„ÄÅNAACLÂíåEMNLP‰ºöËÆÆ‰∏äÂèëË°®ÁöÑËÆ∫ÊñáÔºåÂèëÁé∞Ëøë300ÁØáËÆ∫Êñá‰∏≠Ëá≥Â∞ëÂåÖÂê´‰∏Ä‰∏™HalluCitation„ÄÇÂ∞§ÂÖ∂ÊòØÂú®EMNLP 2025‰ºöËÆÆ‰∏äÔºåÊé•ÂèóÁöÑËÆ∫Êñá‰∏≠ÊúâË∂ÖËøá100ÁØáÂ≠òÂú®Ê≠§ÈóÆÈ¢òÔºåËøõ‰∏ÄÊ≠•ÊçüÂÆ≥‰∫Ü‰ºöËÆÆÁöÑ‰ø°Ë™â„ÄÇ","title":"ËôöÂÅáÂºïÁî®Âç±Êú∫ÔºöÂΩ±ÂìçÁßëÂ≠¶ÂèØÈù†ÊÄß‰∏é‰ºöËÆÆ‰ø°Ë™â"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÁ†îÁ©∂‰∫ÜÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰ºöËÆÆËÆ∫Êñá‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑËôöÂÅáÂºïÁî®Áé∞Ë±°ÔºåÁß∞‰∏∫"HalluCitation"„ÄÇËøô‰∫õËôöÂÅáÂºïÁî®ÊåáÁöÑÊòØÂØπ‰∏çÂ≠òÂú®ÁöÑÊñáÁåÆÁöÑÈîôËØØÂºïÁî®Ôºå‰∏•ÈáçÂΩ±Âìç‰∫ÜÁßëÂ≠¶Á†îÁ©∂ÁöÑÂèØÈù†ÊÄß„ÄÇÈÄöËøáÂàÜÊûê2024Âíå2025Âπ¥Âú®ACL„ÄÅNAACLÂíåEMNLP‰ºöËÆÆ‰∏äÂèëË°®ÁöÑËÆ∫ÊñáÔºåÂèëÁé∞Ëøë300ÁØáËÆ∫Êñá‰∏≠Ëá≥Â∞ëÂåÖÂê´‰∏Ä‰∏™HalluCitation„ÄÇÂ∞§ÂÖ∂ÊòØÂú®EMNLP 2025‰ºöËÆÆ‰∏äÔºåÊé•ÂèóÁöÑËÆ∫Êñá‰∏≠ÊúâË∂ÖËøá100ÁØáÂ≠òÂú®Ê≠§ÈóÆÈ¢òÔºåËøõ‰∏ÄÊ≠•ÊçüÂÆ≥‰∫Ü‰ºöËÆÆÁöÑ‰ø°Ë™â„ÄÇ', title='ËôöÂÅáÂºïÁî®Âç±Êú∫ÔºöÂΩ±ÂìçÁßëÂ≠¶ÂèØÈù†ÊÄß‰∏é‰ºöËÆÆ‰ø°Ë™â'))
[28.01.2026 11:25] Using data from previous issue: {"categories": ["#security", "#training", "#alignment", "#optimization", "#rl", "#rlhf"], "emoji": "üîÑ", "ru": {"title": "–ó–∞–º–∫–Ω—É—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ LLM", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∑–∞–º–∫–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ
[28.01.2026 11:25] Using data from previous issue: {"categories": [], "emoji": "üå≤", "ru": {"title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è RAG —á–µ—Ä–µ–∑ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ª–µ—Å–∞", "desc": "FABLE ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–µ—Å–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç LLM –≤ –ø—Ä–æ—Ü–µ—Å—Å—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π –∏ –∏—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏—è. –°–∏—Å
[28.01.2026 11:25] Querying the API.
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A revised mathematical benchmark dataset was created through manual auditing to reduce noise and improve model performance assessment accuracy.  					AI-generated summary 				 Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset (n{=}4181) and a tagged, non-standard subset (n{=}247). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in 96.4% of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.
[28.01.2026 11:25] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω Omni-MATH-2, –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –ø—É—Ç—ë–º —Ä—É—á–Ω–æ–π –∞—É–¥–∏—Ü–∏–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å LaTeX-—Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞, —Ä–∞–∑—Ä–µ—à–∏–º–æ—Å—Ç—å –∏ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ–º–æ—Å—Ç—å, —É–¥–∞–ª–∏–ª–∏ —à—É–º –∏ –¥–æ–±–∞–≤–∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —à—É–º, –≤–Ω–æ—Å–∏–º—ã–π —Å—É–¥—å—ë–π-–æ—Ü–µ–Ω–∏–≤–∞—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π: GPT-4 Judge –æ—à–∏–±–∞–µ—Ç—Å—è –≤ 96.4% —Å–ª—É—á–∞–µ–≤ —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞, —Ç–∞–∫ –∏ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤.",
  "emoji": "üîß",
  "title": "–ß–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –Ω–∞–¥–µ–∂–Ω—ã–µ —Å—É–¥—å–∏ ‚Äî –æ—Å–Ω–æ–≤–∞ —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π"
}
```
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A revised mathematical benchmark dataset was created through manual auditing to reduce noise and improve model performance assessment accuracy.  					AI-generated summary 				 Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset (n{=}4181) and a tagged, non-standard subset (n{=}247). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in 96.4% of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance."

[28.01.2026 11:25] Response: ```python
['DATASET', 'BENCHMARK', 'MATH']
```
[28.01.2026 11:25] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A revised mathematical benchmark dataset was created through manual auditing to reduce noise and improve model performance assessment accuracy.  					AI-generated summary 				 Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset (n{=}4181) and a tagged, non-standard subset (n{=}247). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in 96.4% of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance."

[28.01.2026 11:25] Response: ```python
['REASONING', 'SURVEY']
```
[28.01.2026 11:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Omni-MATH-2, a revised benchmark dataset aimed at improving the evaluation of Large Language Models (LLMs). The dataset was meticulously audited to eliminate noise and ensure that each problem is solvable and verifiable, which enhances the accuracy of model performance assessments. By comparing the performance of GPT-5 mini against the original Omni-Judge, the study highlights significant discrepancies in judge evaluations, revealing that the original judge often misclassifies model capabilities. The findings emphasize the importance of high-quality datasets and reliable judges in accurately benchmarking model performance, especially as problem complexity increases.","title":"Enhancing Model Evaluation with Clean Benchmarks"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Omni-MATH-2, a revised benchmark dataset aimed at improving the evaluation of Large Language Models (LLMs). The dataset was meticulously audited to eliminate noise and ensure that each problem is solvable and verifiable, which enhances the accuracy of model performance assessments. By comparing the performance of GPT-5 mini against the original Omni-Judge, the study highlights significant discrepancies in judge evaluations, revealing that the original judge often misclassifies model capabilities. The findings emphasize the importance of high-quality datasets and reliable judges in accurately benchmarking model performance, especially as problem complexity increases.', title='Enhancing Model Evaluation with Clean Benchmarks'))
[28.01.2026 11:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Êñá‰ªãÁªç‰∫Ü‰∏Ä‰∏™ÁªèËøáÊâãÂä®ÂÆ°Ê†∏ÁöÑÊï∞Â≠¶Âü∫ÂáÜÊï∞ÊçÆÈõÜOmni-MATH-2ÔºåÊó®Âú®ÂáèÂ∞ëÂô™Â£∞Âπ∂ÊèêÈ´òÊ®°ÂûãÊÄßËÉΩËØÑ‰º∞ÁöÑÂáÜÁ°ÆÊÄß„ÄÇËØ•Êï∞ÊçÆÈõÜÂåÖÂê´4181‰∏™Ê∏ÖÊô∞„ÄÅÂáÜÁ°ÆÁ≠îÊ°àÁöÑÈ¢òÁõÆÂíå247‰∏™Ê†áËÆ∞ÁöÑÈùûÊ†áÂáÜÈ¢òÁõÆÔºåÁ°Æ‰øù‰∫ÜÊØè‰∏™ÈóÆÈ¢òÁöÑÂèØËß£ÊÄßÂíåÂèØÈ™åËØÅÊÄß„ÄÇÈÄöËøáÊ∑ªÂä†Áº∫Â§±ÁöÑ‰ø°ÊÅØÂíåÂõæÂΩ¢ÔºåÊ†áËÆ∞ÈúÄË¶ÅËØÅÊòéÊàñ‰º∞ÁÆóÁöÑÈóÆÈ¢òÔºåÂπ∂ÂéªÈô§ÂÜó‰ΩôÂÜÖÂÆπÔºåÊòæËëóÈôç‰Ωé‰∫ÜÊï∞ÊçÆÈõÜÂºïÂÖ•ÁöÑÂô™Â£∞„ÄÇÁ†îÁ©∂ËøòË°®ÊòéÔºåËØÑÂÆ°ËÄÖÁöÑÂà§Êñ≠Â≠òÂú®ÊòæËëóÂ∑ÆÂºÇÔºåÂº∫Ë∞É‰∫ÜÊï∞ÊçÆÈõÜË¥®ÈáèÂíåËØÑÂÆ°ËÄÖÂèØÈù†ÊÄßÂú®Ê®°ÂûãÊÄßËÉΩÂü∫ÂáÜÂºÄÂèë‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ","title":"ÊèêÂçáÊ®°ÂûãËØÑ‰º∞ÂáÜÁ°ÆÊÄßÁöÑÊï∞Â≠¶Âü∫ÂáÜÊï∞ÊçÆÈõÜ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Êñá‰ªãÁªç‰∫Ü‰∏Ä‰∏™ÁªèËøáÊâãÂä®ÂÆ°Ê†∏ÁöÑÊï∞Â≠¶Âü∫ÂáÜÊï∞ÊçÆÈõÜOmni-MATH-2ÔºåÊó®Âú®ÂáèÂ∞ëÂô™Â£∞Âπ∂ÊèêÈ´òÊ®°ÂûãÊÄßËÉΩËØÑ‰º∞ÁöÑÂáÜÁ°ÆÊÄß„ÄÇËØ•Êï∞ÊçÆÈõÜÂåÖÂê´4181‰∏™Ê∏ÖÊô∞„ÄÅÂáÜÁ°ÆÁ≠îÊ°àÁöÑÈ¢òÁõÆÂíå247‰∏™Ê†áËÆ∞ÁöÑÈùûÊ†áÂáÜÈ¢òÁõÆÔºåÁ°Æ‰øù‰∫ÜÊØè‰∏™ÈóÆÈ¢òÁöÑÂèØËß£ÊÄßÂíåÂèØÈ™åËØÅÊÄß„ÄÇÈÄöËøáÊ∑ªÂä†Áº∫Â§±ÁöÑ‰ø°ÊÅØÂíåÂõæÂΩ¢ÔºåÊ†áËÆ∞ÈúÄË¶ÅËØÅÊòéÊàñ‰º∞ÁÆóÁöÑÈóÆÈ¢òÔºåÂπ∂ÂéªÈô§ÂÜó‰ΩôÂÜÖÂÆπÔºåÊòæËëóÈôç‰Ωé‰∫ÜÊï∞ÊçÆÈõÜÂºïÂÖ•ÁöÑÂô™Â£∞„ÄÇÁ†îÁ©∂ËøòË°®ÊòéÔºåËØÑÂÆ°ËÄÖÁöÑÂà§Êñ≠Â≠òÂú®ÊòæËëóÂ∑ÆÂºÇÔºåÂº∫Ë∞É‰∫ÜÊï∞ÊçÆÈõÜË¥®ÈáèÂíåËØÑÂÆ°ËÄÖÂèØÈù†ÊÄßÂú®Ê®°ÂûãÊÄßËÉΩÂü∫ÂáÜÂºÄÂèë‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ', title='ÊèêÂçáÊ®°ÂûãËØÑ‰º∞ÂáÜÁ°ÆÊÄßÁöÑÊï∞Â≠¶Âü∫ÂáÜÊï∞ÊçÆÈõÜ'))
[28.01.2026 11:26] Renaming data file.
[28.01.2026 11:26] Renaming previous data. hf_papers.json to ./d/2026-01-28.json
[28.01.2026 11:26] Saving new data file.
[28.01.2026 11:26] Generating page.
[28.01.2026 11:26] Renaming previous page.
[28.01.2026 11:26] Renaming previous data. index.html to ./d/2026-01-28.html
[28.01.2026 11:26] Writing result.
[28.01.2026 11:26] Renaming log file.
[28.01.2026 11:26] Renaming previous data. log.txt to ./logs/2026-01-28_last_log.txt
