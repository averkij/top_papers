[20.10.2025 04:18] Read previous papers.
[20.10.2025 04:18] Generating top page (month).
[20.10.2025 04:18] Writing top page (month).
[20.10.2025 05:12] Read previous papers.
[20.10.2025 05:12] Get feed.
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15870
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15869
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15868
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15301
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15742
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14265
[20.10.2025 05:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.15280
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14438
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15857
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15110
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15564
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15232
[20.10.2025 05:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.12838
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15831
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15262
[20.10.2025 05:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.15859
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15842
[20.10.2025 05:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15162
[20.10.2025 05:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.10.2025 05:12] No deleted papers detected.
[20.10.2025 05:12] Downloading and parsing papers (pdf, html). Total: 18.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15870.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15870.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15870.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15869.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15869.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15869.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15868.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15868.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15868.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15301.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15301.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15301.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15742.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15742.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15742.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.14265.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.14265.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.14265.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15280.
[20.10.2025 05:12] Downloading paper 2510.15280 from http://arxiv.org/pdf/2510.15280v1...
[20.10.2025 05:12] Extracting affiliations from text.
[20.10.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 1 ] . [ 1 0 8 2 5 1 . 0 1 5 2 : r Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition Fan Liu1, Jindong Han2, Tengfei Lyu1, Weijia Zhang1, Zhe-Rui Yang1, Lu Dai2,1, Cancheng Liu1, Hao Liu1,2 1The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China 2The Hong Kong University of Science and Technology, Hong Kong SAR, China fliu236@connect.hkust-gz.edu.cn; hanjindong01@gmail.com; tlyu077@connect.hkust-gz.edu.cn; vegazhang3@gmail.com; ldaiae@connect.ust.hk; liuh@ust.hk "
[20.10.2025 05:12] Response: ```python
[
    "The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
    "The Hong Kong University of Science and Technology, Hong Kong SAR, China"
]
```
[20.10.2025 05:12] Deleting PDF ./assets/pdf/2510.15280.pdf.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.14438.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.14438.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.14438.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15857.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15857.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15857.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15110.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15110.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15110.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15564.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15564.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15564.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.15232.
[20.10.2025 05:12] Extra JSON file exists (./assets/json/2510.15232.json), skip PDF parsing.
[20.10.2025 05:12] Paper image links file exists (./assets/img_data/2510.15232.json), skip HTML parsing.
[20.10.2025 05:12] Success.
[20.10.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2510.12838.
[20.10.2025 05:12] Downloading paper 2510.12838 from http://arxiv.org/pdf/2510.12838v2...
[20.10.2025 05:13] Extracting affiliations from text.
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"A2FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning "
[20.10.2025 05:13] Response: []
[20.10.2025 05:13] Extracting affiliations from text.
[20.10.2025 05:13] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"A2FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid ReasoningLarge language models split into two families: reasoning-centric LLMs, which strengthen internal chainof-thought reasoning but cannot invoke external tools, and agentic LLMs, which learn to interact with environments and leverage tools but often lag in deep reasoning. This divide arises from fundamentally different training objectives, leading to mismatched strengths and inefficiency on simple queries, where both families tend to overthink or over-call tools. In this work, we present Adaptive Agent Foundation Model (A2FM), unified framework that follows route-then-align principle: the model first learns task-aware routing and then aligns mode-specific trajectories under shared backbone. To address the inefficiency gap, we introduce third mode-instant-that handles simple queries directly, preventing unnecessary reasoning or tool calls while complementing the agentic and reasoning modes. To jointly enhance accuracy and efficiency, we propose Adaptive Policy Optimization (APO), which enforces adaptive sampling across modes and applies cost-regularized reward. On the 32B scale, A2FM achieves 13.4% on BrowseComp, 70.4% on AIME25, and 16.7% on HLE, setting new SOTA among comparable models and performing competitively with frontier LLMs across agentic, reasoning, and general benchmarks. Notably, the adaptive execution achieves cost of pass of only $0.00487 per correct answer-cutting cost by 45.2% relative to reasoning and 33.5% relative to agentic, thus delivering substantially higher cost efficiency while maintaining comparable accuracy. Date: October 17, 2025 Open Source: Code Correspondence: Wangchunshu Zhou at zhouwangchunshu@oppo.com Models 5 2 0 2 6 1 ] . [ 2 8 3 8 2 1 . 0 1 5 2 : r Figure 1 Average performance on agentic, reasoning, and general (ARG) benchmarks. Overall, A2FM ranks 1st, 2nd, and 1st on the three categories, respectively. Note that we uses the best-suited mode for each dataset respectively.3.3 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.1 System Prompt 5 5 5 5 5 7 9 9 6 A.2 Summary Prompt. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Recent reasoning-centric Large Language Models (LLMs)e.g., OpenAI o3 (OpenAI, 2025c) and DeepSeek-R1 (Guo et al., 2025)show strong chain-of-thought (CoT) abilities for mathematics, scientific diagram interpretation, and logic. Their post-training typically optimizes internal deliberation and solution steps. By design, they are trained in closed, text-only settings and do not learn to invoke external tools. This difference in training objective and environment leaves capability gap in tool use. Figure 2 Overview of A2FM. Left: the framework integrates three execution modesinstant, reasoning, and agenticunder unified backbone with task-aware routing. Right: mode allocation across six benchmarks (MMLU-Pro, GPQA-d, AIME25, MATH500, Xbench-DeepSearch (Xbench), and GAIA-text (GAIA), illustrating how A2FM adapts routing to task characteristics. In parallel, agentic LLMse.g., OpenAI GPT-5(OpenAI, 2025a), GLM-4.5 (Zeng et al., 2025), Kimi K2 (Team et al., 2025a), DeepSeek-V3.1 (DeepSeek-AI, 2025), and agent frameworks such as OAgents (Zhu et al., 2025) and BrowseMaster (Pang et al., 2025), as well as Agent Foundation Models (Li et al., 2025b)emphasize environmentdependent interaction. They plan, search, crawl, and execute code. Their post-training focuses on tool correctness, call patterns, and interaction quality. Yet when deep multi-step reasoning is required (e.g., competitive math), these systems often trail state-of-the-art reasoning models (Ji"
[20.10.2025 05:13] Mistral response. {"id": "3d99f992bf3246849b2a66cfe65510f2", "created": 1760937182, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1076, "total_tokens": 1095, "completion_tokens": 19}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"OpenAI\",\n    \"DeepSeek-AI\"\n]\n```"}}]}
[20.10.2025 05:13] Response: ```python
[
    "OpenAI",
    "DeepSeek-AI"
]
```
[20.10.2025 05:13] Deleting PDF ./assets/pdf/2510.12838.pdf.
[20.10.2025 05:13] Success.
[20.10.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2510.15831.
[20.10.2025 05:13] Extra JSON file exists (./assets/json/2510.15831.json), skip PDF parsing.
[20.10.2025 05:13] Paper image links file exists (./assets/img_data/2510.15831.json), skip HTML parsing.
[20.10.2025 05:13] Success.
[20.10.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2510.15262.
[20.10.2025 05:13] Extra JSON file exists (./assets/json/2510.15262.json), skip PDF parsing.
[20.10.2025 05:13] Paper image links file exists (./assets/img_data/2510.15262.json), skip HTML parsing.
[20.10.2025 05:13] Success.
[20.10.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2510.15859.
[20.10.2025 05:13] Downloading paper 2510.15859 from http://arxiv.org/pdf/2510.15859v1...
[20.10.2025 05:13] Extracting affiliations from text.
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training Pengkai Wang * 1 2 Qi Zuo * Pengwei Liu * 3 Zhijie Sang 2 Congkai Xie 2 Hongxia Yang "
[20.10.2025 05:13] Response: []
[20.10.2025 05:13] Extracting affiliations from text.
[20.10.2025 05:13] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training Pengkai Wang * 1 2 Qi Zuo * Pengwei Liu * 3 Zhijie Sang 2 Congkai Xie 2 Hongxia Yangpidneuralode/ORBIT. 5 2 0 2 7 1 ] . [ 1 9 5 8 5 1 . 0 1 5 2 : r Large Language Models (LLMs) have shown substantial advances through reinforcement learning (RL), particularly in domains where rewards can be programmatically verified, such as mathematics and code. In these areas, models benefit from well-defined operational base guided by explicit rule-based objectives. However, this progress reveals significant limitation: in open-ended domains where rewards are ambiguous, subjective, or context-dependent, such as creative writing, scientific reasoning, and notably medical consultation, robust reward functions are lacking, making these areas challenging for current RL strategies. To bridge this gap, we introduce ORBIT, an open-ended rubric-based incremental training framework specifically designed for highstakes medical dialogue. ORBIT integrates synthetic dialogue generation with the dynamic creation of rubrics, employing these rubrics to direct an incremental RL process. In particular, this approach does not depend on external medical knowledge or manual rules, instead utilizing rubric-guided feedback to shape learning. When implemented on the Qwen3-4B-Instruct model, our method can greatly enhance its performance on the HealthBench-Hard benchmark from 7.0 to 27.2 using only 2k samples, thus achieving state-of-the-art results for models of this scale. Our analysis confirms that rubric-driven RL fosters consistent performance gains across diverse consultation scenarios, going beyond simple numerical improvements. These findings underscore rubric-based feedback as scalable strategy for advancing LLMs in intricate, open-ended tasks. Code is available at https://github.com/ *Equal contribution 1Department of Computing, University of Hong Kong Polytechnic University, Hong Kong, China 2InfiX.ai 3Department of Control Science and Engineering, Correspondence to: Hongxia Yang Zhejiang University. <hongxia.yang@polyu.edu.hk>. 1. Introduction In recent years, the significance of the post-training phase in the development of Large Language Models (LLMs) has grown substantially, trend underscored by the emergence of models like DeepSeek-Math (Shao et al., 2024) and corresponding body of literature (Yu et al., 2025; Zheng et al., 2025). prevailing finding in this research is that Supervised Fine-Tuning (SFT) is particularly effective for knowledge memorization, while Reinforcement Learning (RL) excels at enhancing generalization (Chu et al., 2025; Shenfeld et al., 2025). Through the use of comprehensive and diverse SFT corpus, model can acquire domain-specific knowledge and, simultaneously, adapt rapidly to the instructional formats of downstream tasks (Zhang et al., 2024; Liu et al., 2025b). The subsequent RL phase, building upon this strong foundation, then assists the model in exploring the boundaries of its capabilities through reward signals based on interactions with given corpus. As result of extensive practical application, the SFT+RL sequence has become the predominant post-training paradigm, although alternative approaches, such as zero-RL methods (Shao et al., 2024), also exist. RLVR(Reinforcement with Verifiable Rewards) shows promising enhancement on tasks like Math, Code, and other STEM subjects with verifiable format. Despite the quick development of scientific-related reinforcement learning, we have many open-ended subjects in real world scenarios like medicine, psychology, and sociology. Benchmarks which adopt rubrics as assessment criterion are proved to be useful to evaluate the both personality and professional level of LLMs. Among open-ended benchmarks, Healthbench (Arora et al., 2025) pave the way for evaluating the medical ability of LLMs with expert-designed hand-written rubrics for special clinical cases. Many medical expert-level medical QA models (Chen et al., 2024; Huang et al., 2025; Wu et al., 2025) can only get zero points on HealthBench Hard, indicating the huge gap between QA benchmarks and open-ended benchmarks. 1 ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training To enhance the open-ended medical ability of LLMs, we propose ORBIT, post-training system that can greatly enhance the performance of LLMs on HealthBench. We build an automatic rubrics generation strategy without finetuning LLM or requiring human efforts. We first adopt RAG module to recall the top query related to specific clinical query we collected and utilize the in-context learning ability of LLMs to generate corresponding rubrics. We have systematically reviewed the selection of LLMs for the best rubric design. In order to improve both efficiency and performance, we carefully design sample-level and rubric-level selection module. Finally, we conduct comprehensive ablation on variables among the RL training process including rubric design, judge model selection, and data curation. In summary, our contributions include: fully automated rubrics generation paradigm, which can be potentially useful in enhancing performances of various open-ended evaluation benchmarks. systematic verification of strategies to filter data from both sample-level and rubric-level. comprehensive ablation study on components of the ORBIT system to optimize the performance of the rubrics-based RL training paradigm. 2. Related Work 2.1. Open-Ended Benchmarks The evaluation of large language models (LLMs) on openended generation tasks is undergoing paradigm shift, moving from conventional automated metrics toward more holistic, rubric-based frameworks. Early benchmarks were often limited to short-form text grading, fixed entity extraction, or weakly correlated metrics from natural language generation. These methods proved insufficient for capturing the sophisticated, multi-faceted capabilities of modern LLMs. This limitation has spurred the development of new generation of evaluation suites that employ multi-dimensional, fine-grained rubrics. Prominent examples include HealthBench (Arora et al., 2025), VISTA (Scale AI, 2025), PaperBench (Starace et al., 2025), WildBench (Lin et al., 2024), AMEGA (Fast et al., 2024), and MultiChallenge (Deshpande et al., 2025). By systematically defining thousands of evaluation criteria across diverse scenarios, these benchmarks enable more precise and comprehensive assessment "
[20.10.2025 05:13] Mistral response. {"id": "8d926ccbc32e4f85a9c26289f7c1d271", "created": 1760937188, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1461, "total_tokens": 1508, "completion_tokens": 47}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Department of Computing, University of Hong Kong Polytechnic University, Hong Kong, China\",\n    \"InfiX.ai\",\n    \"Department of Control Science and Engineering, Zhejiang University\"\n]\n```"}}]}
[20.10.2025 05:13] Response: ```python
[
    "Department of Computing, University of Hong Kong Polytechnic University, Hong Kong, China",
    "InfiX.ai",
    "Department of Control Science and Engineering, Zhejiang University"
]
```
[20.10.2025 05:13] Deleting PDF ./assets/pdf/2510.15859.pdf.
[20.10.2025 05:13] Success.
[20.10.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2510.15842.
[20.10.2025 05:13] Extra JSON file exists (./assets/json/2510.15842.json), skip PDF parsing.
[20.10.2025 05:13] Paper image links file exists (./assets/img_data/2510.15842.json), skip HTML parsing.
[20.10.2025 05:13] Success.
[20.10.2025 05:13] Downloading and parsing paper https://huggingface.co/papers/2510.15162.
[20.10.2025 05:13] Extra JSON file exists (./assets/json/2510.15162.json), skip PDF parsing.
[20.10.2025 05:13] Paper image links file exists (./assets/img_data/2510.15162.json), skip HTML parsing.
[20.10.2025 05:13] Success.
[20.10.2025 05:13] Enriching papers with extra data.
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 0. OmniVinci, an open-source omni-modal LLM, enhances cross-modal understanding and performance across audio, vision, and robotics applications with innovative architecture and efficient data curation.  					AI-generated summary 				 Advancing machine intelligence requires developing the ability to per...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 1. Skyfall-GS creates large-scale, high-quality 3D urban scenes using satellite imagery and diffusion models, offering real-time exploration and improved geometry and texture consistency.  					AI-generated summary 				 Synthesizing large-scale, explorable, and geometrically accurate 3D urban scenes is...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 2. LightsOut enhances Single Image Flare Removal by reconstructing off-frame light sources using a diffusion-based outpainting framework, improving performance across challenging scenarios.  					AI-generated summary 				 Lens flare significantly degrades image quality, impacting critical computer visi...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 3. SVG, a novel latent diffusion model without VAEs, uses self-supervised representations to enable efficient training, few-step sampling, and high-quality visual generation with semantic and discriminative capabilities.  					AI-generated summary 				 Recent progress in diffusion-based visual generati...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 4. Ditto framework addresses data scarcity in instruction-based video editing by generating a large dataset and using a curriculum learning strategy to train Editto, achieving superior instruction-following ability.  					AI-generated summary 				 Instruction-based video editing promises to democratize...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 5. MorphoBench is a benchmark that evaluates large models' reasoning capabilities using multidisciplinary questions, adaptive difficulty, and simulation-generated questions.  					AI-generated summary 				 With the advancement of powerful large-scale reasoning models, effectively evaluating the reasoni...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 6. Foundation models are evolving scientific methodologies from enhancement to autonomous discovery, prompting a new paradigm in research.  					AI-generated summary 				 Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the landscape of scientific research. Beyond accelerating tasks ...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 7. A new paradigm, Explore to Evolve, is proposed to enhance web agents' information aggregation by constructing a large dataset and developing foundation models that outperform existing models on a challenging benchmark.  					AI-generated summary 				 Deep research web agents not only retrieve inform...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 8. BLIP3o-NEXT, a unified text-to-image generation and image editing model, uses an Autoregressive + Diffusion architecture to achieve superior performance and realism.  					AI-generated summary 				 We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3 series that advances the nex...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 9. DLER, a reinforcement learning training recipe, improves the accuracy-efficiency trade-off in reasoning language models by addressing challenges in advantage estimation, entropy collapse, and sparse reward signals, leading to shorter outputs and better test-time scaling.  					AI-generated summary 	...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 10. A vision-guided 3D layout generation system uses an image generation model and scene graphs to produce rich and coherent 3D scenes from prompts.  					AI-generated summary 				 Generating artistic and coherent 3D scene layouts is crucial in digital content creation. Traditional optimization-based me...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 11. FinTrust is a benchmark designed to evaluate the trustworthiness of LLMs in finance applications, focusing on alignment issues and revealing gaps in legal awareness.  					AI-generated summary 				 Recent LLMs have demonstrated promising ability in solving finance related problems. However, applying...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 12. A unified framework, A$^2$FM, combines reasoning and agentic capabilities in large language models, improving efficiency and accuracy across benchmarks by adaptively routing queries and optimizing policy.  					AI-generated summary 				 Large language models split into two families: reasoning-centri...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 13. VISTA, a multi-agent system, iteratively refines user prompts to enhance video quality and alignment with user intent, outperforming existing methods.  					AI-generated summary 				 Despite rapid advances in text-to-video synthesis, generated video quality remains critically dependent on precise us...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 14. A new weight-decay scaling rule for AdamW is introduced to preserve sublayer gain across widths in modern scale-invariant architectures, enabling zero-shot transfer of learning rate and weight decay.  					AI-generated summary 				 Empirical scaling laws prescribe how to allocate parameters, data, a...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 15. ORBIT, a rubric-based incremental training framework, enhances LLM performance in medical dialogue by using dynamic rubrics for RL, achieving state-of-the-art results on HealthBench-Hard.  					AI-generated summary 				 Large Language Models (LLMs) have shown substantial advances through reinforceme...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 16. Paper2Web is a benchmark and evaluation framework for academic webpage generation, featuring PWAgent, an autonomous pipeline that enhances content and layout through MCP tools, outperforming end-to-end baselines.  					AI-generated summary 				 Academic project websites can more effectively dissemin...
[20.10.2025 05:13] ********************************************************************************
[20.10.2025 05:13] Abstract 17. UniFilter, a Unified Multimodal Data Quality Classifier, enhances Multimodal Large Language Models (MLLMs) by filtering high-quality image-text and interleaved data, leading to improved zero-shot reasoning and in-context learning.  					AI-generated summary 				 The Multimodal Large Language Models ...
[20.10.2025 05:13] Read previous papers.
[20.10.2025 05:13] Generating reviews via LLM API.
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#robotics", "#reasoning", "#healthcare", "#multimodal", "#data", "#alignment"], "emoji": "🎭", "ru": {"title": "Видеть, слышать и понимать: омни-модальный AI с минимальными затратами", "desc": "OmniVinci — это open-source омни-модальная LLM, которая в
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#diffusion", "#synthetic", "#3d"], "emoji": "🛰️", "ru": {"title": "Городские 3D-сцены из спутниковых снимков и диффузии", "desc": "Skyfall-GS — это первая система для создания городских 3D-сцен масштаба целого квартала без дорогостоящей 3D-разметки. Метод использует спутниковые сним
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#optimization", "#training"], "emoji": "💡", "ru": {"title": "Гасим свет: реконструкция источников бликов за пределами кадра", "desc": "Блики от объективов серьёзно ухудшают качество изображений и мешают работе систем компьютерного зрения, особенно в автономном в
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#cv", "#diffusion"], "emoji": "🎨", "ru": {"title": "Генерация изображений через self-supervised представления без VAE", "desc": "Авторы представляют SVG — новую модель latent diffusion, которая отказывается от использования VAE (variational autoencoder)
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#data", "#agents", "#synthetic", "#training", "#dataset", "#cv"], "emoji": "🎬", "ru": {"title": "Миллион примеров для обучения редактированию видео по текстовым инструкциям", "desc": "Фреймворк Ditto решает проблему нехватки данных для редактирования видео по текстовым инструкциям. 
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#benchmark"], "emoji": "🔄", "ru": {"title": "Адаптивный бенчмарк с эволюционирующей сложностью для оценки рассуждений LLM", "desc": "MorphoBench — это новый бенчмарк для оценки способностей к рассуждению у больших языковых моделей, который использует м
[20.10.2025 05:13] Querying the API.
[20.10.2025 05:13] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Foundation models are evolving scientific methodologies from enhancement to autonomous discovery, prompting a new paradigm in research.  					AI-generated summary 				 Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the landscape of scientific research. Beyond accelerating tasks such as hypothesis generation, experimental design, and result interpretation, they prompt a more fundamental question: Are FMs merely enhancing existing scientific methodologies, or are they redefining the way science is conducted? In this paper, we argue that FMs are catalyzing a transition toward a new scientific paradigm. We introduce a three-stage framework to describe this evolution: (1) Meta-Scientific Integration, where FMs enhance workflows within traditional paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active collaborators in problem formulation, reasoning, and discovery; and (3) Autonomous Scientific Discovery, where FMs operate as independent agents capable of generating new scientific knowledge with minimal human intervention. Through this lens, we review current applications and emerging capabilities of FMs across existing scientific paradigms. We further identify risks and future directions for FM-enabled scientific discovery. This position paper aims to support the scientific community in understanding the transformative role of FMs and to foster reflection on the future of scientific discovery. Our project is available at https://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery.
[20.10.2025 05:13] Response: ```json
{
  "desc": "Статья исследует, как foundation models (большие предобученные модели) вроде GPT-4 и AlphaFold трансформируют научные исследования. Авторы предлагают трёхэтапную структуру эволюции: от улучшения существующих методов к гибридной коллаборации человека и AI, и затем к полностью автономным научным открытиям. Работа анализирует текущие применения foundation models в науке и выявляет потенциальные риски такого подхода. Цель статьи — помочь научному сообществу понять трансформационную роль этих моделей в будущем научных открытий.",
  "emoji": "🔬",
  "title": "От помощника учёного к автономному исследователю: три стадии научной революции с foundation models"
}
```
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Foundation models are evolving scientific methodologies from enhancement to autonomous discovery, prompting a new paradigm in research.  					AI-generated summary 				 Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the landscape of scientific research. Beyond accelerating tasks such as hypothesis generation, experimental design, and result interpretation, they prompt a more fundamental question: Are FMs merely enhancing existing scientific methodologies, or are they redefining the way science is conducted? In this paper, we argue that FMs are catalyzing a transition toward a new scientific paradigm. We introduce a three-stage framework to describe this evolution: (1) Meta-Scientific Integration, where FMs enhance workflows within traditional paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active collaborators in problem formulation, reasoning, and discovery; and (3) Autonomous Scientific Discovery, where FMs operate as independent agents capable of generating new scientific knowledge with minimal human intervention. Through this lens, we review current applications and emerging capabilities of FMs across existing scientific paradigms. We further identify risks and future directions for FM-enabled scientific discovery. This position paper aims to support the scientific community in understanding the transformative role of FMs and to foster reflection on the future of scientific discovery. Our project is available at https://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery."

[20.10.2025 05:13] Response: ```python
["AGENTS", "MULTIMODAL"]
```
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Foundation models are evolving scientific methodologies from enhancement to autonomous discovery, prompting a new paradigm in research.  					AI-generated summary 				 Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the landscape of scientific research. Beyond accelerating tasks such as hypothesis generation, experimental design, and result interpretation, they prompt a more fundamental question: Are FMs merely enhancing existing scientific methodologies, or are they redefining the way science is conducted? In this paper, we argue that FMs are catalyzing a transition toward a new scientific paradigm. We introduce a three-stage framework to describe this evolution: (1) Meta-Scientific Integration, where FMs enhance workflows within traditional paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active collaborators in problem formulation, reasoning, and discovery; and (3) Autonomous Scientific Discovery, where FMs operate as independent agents capable of generating new scientific knowledge with minimal human intervention. Through this lens, we review current applications and emerging capabilities of FMs across existing scientific paradigms. We further identify risks and future directions for FM-enabled scientific discovery. This position paper aims to support the scientific community in understanding the transformative role of FMs and to foster reflection on the future of scientific discovery. Our project is available at https://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery."

[20.10.2025 05:13] Response: ```python
['SCIENCE']
```
[20.10.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses how foundation models (FMs) like GPT-4 and AlphaFold are changing the way scientific research is conducted. It presents a three-stage framework: first, FMs enhance traditional scientific methods; second, they collaborate with humans in formulating and solving problems; and third, they can independently discover new scientific knowledge. The authors argue that FMs are not just tools but are redefining scientific methodologies and prompting a new research paradigm. They also highlight potential risks and future directions for the use of FMs in scientific discovery.","title":"Foundation Models: Redefining Scientific Discovery"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses how foundation models (FMs) like GPT-4 and AlphaFold are changing the way scientific research is conducted. It presents a three-stage framework: first, FMs enhance traditional scientific methods; second, they collaborate with humans in formulating and solving problems; and third, they can independently discover new scientific knowledge. The authors argue that FMs are not just tools but are redefining scientific methodologies and prompting a new research paradigm. They also highlight potential risks and future directions for the use of FMs in scientific discovery.', title='Foundation Models: Redefining Scientific Discovery'))
[20.10.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"基础模型（FMs）如GPT-4和AlphaFold正在改变科学研究的方式。它们不仅加速了假设生成、实验设计和结果解释等任务，还引发了一个根本性的问题：基础模型是仅仅增强现有的科学方法，还是在重新定义科学的进行方式？本文提出了一个三阶段框架，描述了这一演变过程，包括元科学整合、混合人机共创和自主科学发现。我们还探讨了基础模型在科学发现中的应用、潜在风险及未来方向。","title":"基础模型：科学发现的新范式"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='基础模型（FMs）如GPT-4和AlphaFold正在改变科学研究的方式。它们不仅加速了假设生成、实验设计和结果解释等任务，还引发了一个根本性的问题：基础模型是仅仅增强现有的科学方法，还是在重新定义科学的进行方式？本文提出了一个三阶段框架，描述了这一演变过程，包括元科学整合、混合人机共创和自主科学发现。我们还探讨了基础模型在科学发现中的应用、潜在风险及未来方向。', title='基础模型：科学发现的新范式'))
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#science", "#benchmark", "#agents"], "emoji": "🕷️", "ru": {"title": "Учимся не просто искать, а думать: веб-агенты, которые анализируют информацию", "desc": "Исследователи предложили новую парадигму Explore to Evolve для обучения веб-агентов не только нах
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#architecture", "#rl", "#open_source", "#benchmark", "#diffusion", "#cv", "#training", "#multimodal"], "emoji": "🎨", "ru": {"title": "Объединение авторегрессии и диффузии для реалистичной генерации изображений", "desc": "BLIP3o-NEXT — это полностью open-source модель, объединяющая г
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#training"], "emoji": "✂️", "ru": {"title": "Короче и точнее: как научить LLM рассуждать эффективно", "desc": "Статья представляет DLER — метод обучения языковых моделей с reinforcement learning, который решает проблему избыточной длины рассужде
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#graphs", "#games", "#3d"], "emoji": "🎨", "ru": {"title": "Создание богатых 3D сцен с помощью визуально управляемой генерации", "desc": "В статье представлена новая система генерации 3D макетов, управляемая визуальными данными, которая использует модель 
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#benchmark"], "emoji": "🏦", "ru": {"title": "FinTrust: проверка AI на надёжность в финансах", "desc": "Исследователи представили FinTrust - benchmark для оценки надёжности LLM в финансовых приложениях. Benchmark фокусируется на проблемах alignment и включает
[20.10.2025 05:13] Querying the API.
[20.10.2025 05:13] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A unified framework, A$^2$FM, combines reasoning and agentic capabilities in large language models, improving efficiency and accuracy across benchmarks by adaptively routing queries and optimizing policy.  					AI-generated summary 				 Large language models split into two families: reasoning-centric LLMs, which strengthen internal chain-of-thought reasoning but cannot invoke external tools, and agentic LLMs, which learn to interact with environments and leverage tools but often lag in deep reasoning. This divide arises from fundamentally different training objectives, leading to mismatched strengths and inefficiency on simple queries, where both families tend to overthink or over-call tools. In this work, we present Adaptive Agent Foundation Model (A^2FM), a unified framework that follows a route-then-align principle: the model first learns task-aware routing and then aligns mode-specific trajectories under a shared backbone. To address the inefficiency gap, we introduce a third mode-instant-that handles simple queries directly, preventing unnecessary reasoning or tool calls while complementing the agentic and reasoning modes. To jointly enhance accuracy and efficiency, we propose Adaptive Policy Optimization (APO), which enforces adaptive sampling across modes and applies a cost-regularized reward. On the 32B scale, A^2FM achieves 13.4% on BrowseComp, 70.4% on AIME25, and 16.7% on HLE, setting new SOTA among comparable models and performing competitively with frontier LLMs across agentic, reasoning, and general benchmarks. Notably, the adaptive execution achieves a cost of pass of only $0.00487 per correct answer-cutting cost by 45.2% relative to reasoning and 33.5% relative to agentic, thus delivering substantially higher cost efficiency while maintaining comparable accuracy.
[20.10.2025 05:13] Response: ```json
{
  "desc": "Статья представляет A²FM — unified framework, который объединяет возможности reasoning и agentic LLM в одной модели. Авторы предлагают принцип route-then-align: модель сначала учится маршрутизировать задачи, а затем выравнивает траектории для разных режимов работы. Введён третий режим — instant — для простых запросов, что предотвращает избыточные вычисления и вызовы инструментов. Метод Adaptive Policy Optimization с регуляризацией по стоимости позволяет достичь SOTA результатов на нескольких бенчмарках при снижении затрат на 45% по сравнению с чисто reasoning подходом.",
  "emoji": "🔀",
  "title": "Адаптивная маршрутизация задач: объединяем reasoning и agentic LLM с тройной экономией"
}
```
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A unified framework, A$^2$FM, combines reasoning and agentic capabilities in large language models, improving efficiency and accuracy across benchmarks by adaptively routing queries and optimizing policy.  					AI-generated summary 				 Large language models split into two families: reasoning-centric LLMs, which strengthen internal chain-of-thought reasoning but cannot invoke external tools, and agentic LLMs, which learn to interact with environments and leverage tools but often lag in deep reasoning. This divide arises from fundamentally different training objectives, leading to mismatched strengths and inefficiency on simple queries, where both families tend to overthink or over-call tools. In this work, we present Adaptive Agent Foundation Model (A^2FM), a unified framework that follows a route-then-align principle: the model first learns task-aware routing and then aligns mode-specific trajectories under a shared backbone. To address the inefficiency gap, we introduce a third mode-instant-that handles simple queries directly, preventing unnecessary reasoning or tool calls while complementing the agentic and reasoning modes. To jointly enhance accuracy and efficiency, we propose Adaptive Policy Optimization (APO), which enforces adaptive sampling across modes and applies a cost-regularized reward. On the 32B scale, A^2FM achieves 13.4% on BrowseComp, 70.4% on AIME25, and 16.7% on HLE, setting new SOTA among comparable models and performing competitively with frontier LLMs across agentic, reasoning, and general benchmarks. Notably, the adaptive execution achieves a cost of pass of only $0.00487 per correct answer-cutting cost by 45.2% relative to reasoning and 33.5% relative to agentic, thus delivering substantially higher cost efficiency while maintaining comparable accuracy."

[20.10.2025 05:13] Response: ```python
['AGENTS', 'BENCHMARK', 'TRAINING', 'ARCHITECTURE']
```
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A unified framework, A$^2$FM, combines reasoning and agentic capabilities in large language models, improving efficiency and accuracy across benchmarks by adaptively routing queries and optimizing policy.  					AI-generated summary 				 Large language models split into two families: reasoning-centric LLMs, which strengthen internal chain-of-thought reasoning but cannot invoke external tools, and agentic LLMs, which learn to interact with environments and leverage tools but often lag in deep reasoning. This divide arises from fundamentally different training objectives, leading to mismatched strengths and inefficiency on simple queries, where both families tend to overthink or over-call tools. In this work, we present Adaptive Agent Foundation Model (A^2FM), a unified framework that follows a route-then-align principle: the model first learns task-aware routing and then aligns mode-specific trajectories under a shared backbone. To address the inefficiency gap, we introduce a third mode-instant-that handles simple queries directly, preventing unnecessary reasoning or tool calls while complementing the agentic and reasoning modes. To jointly enhance accuracy and efficiency, we propose Adaptive Policy Optimization (APO), which enforces adaptive sampling across modes and applies a cost-regularized reward. On the 32B scale, A^2FM achieves 13.4% on BrowseComp, 70.4% on AIME25, and 16.7% on HLE, setting new SOTA among comparable models and performing competitively with frontier LLMs across agentic, reasoning, and general benchmarks. Notably, the adaptive execution achieves a cost of pass of only $0.00487 per correct answer-cutting cost by 45.2% relative to reasoning and 33.5% relative to agentic, thus delivering substantially higher cost efficiency while maintaining comparable accuracy."

[20.10.2025 05:13] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[20.10.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces A$^2$FM, a unified framework that enhances large language models by integrating reasoning and agentic capabilities. It addresses the inefficiencies of existing models by implementing a route-then-align strategy, which optimizes how queries are processed based on their complexity. A$^2$FM introduces a new mode for handling simple queries directly, reducing unnecessary reasoning and tool usage. The framework demonstrates significant improvements in accuracy and cost efficiency, achieving state-of-the-art results on various benchmarks while lowering operational costs.","title":"A$^2$FM: Bridging Reasoning and Action for Efficient Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces A$^2$FM, a unified framework that enhances large language models by integrating reasoning and agentic capabilities. It addresses the inefficiencies of existing models by implementing a route-then-align strategy, which optimizes how queries are processed based on their complexity. A$^2$FM introduces a new mode for handling simple queries directly, reducing unnecessary reasoning and tool usage. The framework demonstrates significant improvements in accuracy and cost efficiency, achieving state-of-the-art results on various benchmarks while lowering operational costs.', title='A$^2$FM: Bridging Reasoning and Action for Efficient Language Models'))
[20.10.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种统一框架A$^2$FM，结合了大型语言模型的推理能力和智能代理能力，提升了在基准测试中的效率和准确性。该模型采用了先路由后对齐的原则，首先学习任务感知的路由，然后在共享的基础上对特定模式的轨迹进行对齐。为了解决效率差距，A$^2$FM引入了一种新的模式，直接处理简单查询，避免了不必要的推理或工具调用。通过自适应策略优化（APO），该模型在多个基准测试中实现了显著的成本效率和准确性，展示了在智能代理、推理和一般基准测试中的竞争力。","title":"统一框架A$^2$FM：提升推理与智能代理的效率与准确性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种统一框架A$^2$FM，结合了大型语言模型的推理能力和智能代理能力，提升了在基准测试中的效率和准确性。该模型采用了先路由后对齐的原则，首先学习任务感知的路由，然后在共享的基础上对特定模式的轨迹进行对齐。为了解决效率差距，A$^2$FM引入了一种新的模式，直接处理简单查询，避免了不必要的推理或工具调用。通过自适应策略优化（APO），该模型在多个基准测试中实现了显著的成本效率和准确性，展示了在智能代理、推理和一般基准测试中的竞争力。', title='统一框架A$^2$FM：提升推理与智能代理的效率与准确性'))
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#multimodal", "#games", "#video", "#optimization", "#agents", "#reasoning"], "emoji": "🎬", "ru": {"title": "Мультиагентная система для автоматического улучшения промптов в генерации видео", "desc": "В работе представлена VISTA — мультиагентная система, которая итеративно улучшает ка
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#optimization", "#synthetic", "#transfer_learning", "#training", "#architecture"], "emoji": "⚖️", "ru": {"title": "Масштабирование weight decay для переноса гиперпараметров между разными размерами моделей", "desc": "Исследователи решили проблему переноса learning rate и weight decay
[20.10.2025 05:13] Querying the API.
[20.10.2025 05:13] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ORBIT, a rubric-based incremental training framework, enhances LLM performance in medical dialogue by using dynamic rubrics for RL, achieving state-of-the-art results on HealthBench-Hard.  					AI-generated summary 				 Large Language Models (LLMs) have shown substantial advances through reinforcement learning (RL), particularly in domains where rewards can be programmatically verified, such as mathematics and code. In these areas, models benefit from a well-defined operational base guided by explicit rule-based objectives. However, this progress reveals a significant limitation: in open-ended domains where rewards are ambiguous, subjective, or context-dependent, such as creative writing, scientific reasoning, and notably medical consultation, robust reward functions are lacking, making these areas challenging for current RL strategies. To bridge this gap, we introduce ORBIT, an open-ended rubric-based incremental training framework specifically designed for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue generation with the dynamic creation of rubrics, employing these rubrics to direct an incremental RL process. In particular, this approach does not depend on external medical knowledge or manual rules, instead utilizing rubric-guided feedback to shape learning. When implemented on the Qwen3-4B-Instruct model, our method can greatly enhance its performance on the HealthBench-Hard benchmark from 7.0 to 27.2 using only 2k samples, thus achieving state-of-the-art results for models of this scale. Our analysis confirms that rubric-driven RL fos-ters consistent performance gains across diverse consultation scenarios, going beyond simple numerical improvements. These findings underscore rubric-based feedback as a scalable strategy for advancing LLMs in intricate, open-ended tasks.
[20.10.2025 05:13] Response: ```json
{
  "desc": "Статья представляет ORBIT — фреймворк для улучшения больших языковых моделей в медицинских диалогах с помощью reinforcement learning. Главная проблема заключается в том, что в открытых областях, таких как медицинские консультации, сложно определить четкую функцию вознаграждения для RL. ORBIT решает это через динамическое создание рубрик (критериев оценки), которые направляют процесс обучения без использования внешних медицинских знаний или ручных правил. На модели Qwen3-4B-Instruct метод улучшил результаты на бенчмарке HealthBench-Hard с 7.0 до 27.2, используя всего 2000 примеров, достигнув state-of-the-art результатов для моделей такого размера.",
  "emoji": "🩺",
  "title": "Обучение медицинских AI через динамические рубрики оценки"
}
```
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ORBIT, a rubric-based incremental training framework, enhances LLM performance in medical dialogue by using dynamic rubrics for RL, achieving state-of-the-art results on HealthBench-Hard.  					AI-generated summary 				 Large Language Models (LLMs) have shown substantial advances through reinforcement learning (RL), particularly in domains where rewards can be programmatically verified, such as mathematics and code. In these areas, models benefit from a well-defined operational base guided by explicit rule-based objectives. However, this progress reveals a significant limitation: in open-ended domains where rewards are ambiguous, subjective, or context-dependent, such as creative writing, scientific reasoning, and notably medical consultation, robust reward functions are lacking, making these areas challenging for current RL strategies. To bridge this gap, we introduce ORBIT, an open-ended rubric-based incremental training framework specifically designed for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue generation with the dynamic creation of rubrics, employing these rubrics to direct an incremental RL process. In particular, this approach does not depend on external medical knowledge or manual rules, instead utilizing rubric-guided feedback to shape learning. When implemented on the Qwen3-4B-Instruct model, our method can greatly enhance its performance on the HealthBench-Hard benchmark from 7.0 to 27.2 using only 2k samples, thus achieving state-of-the-art results for models of this scale. Our analysis confirms that rubric-driven RL fos-ters consistent performance gains across diverse consultation scenarios, going beyond simple numerical improvements. These findings underscore rubric-based feedback as a scalable strategy for advancing LLMs in intricate, open-ended tasks."

[20.10.2025 05:13] Response: ```python
['RL', 'RLHF', 'HEALTHCARE', 'TRAINING', 'BENCHMARK']
```
[20.10.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ORBIT, a rubric-based incremental training framework, enhances LLM performance in medical dialogue by using dynamic rubrics for RL, achieving state-of-the-art results on HealthBench-Hard.  					AI-generated summary 				 Large Language Models (LLMs) have shown substantial advances through reinforcement learning (RL), particularly in domains where rewards can be programmatically verified, such as mathematics and code. In these areas, models benefit from a well-defined operational base guided by explicit rule-based objectives. However, this progress reveals a significant limitation: in open-ended domains where rewards are ambiguous, subjective, or context-dependent, such as creative writing, scientific reasoning, and notably medical consultation, robust reward functions are lacking, making these areas challenging for current RL strategies. To bridge this gap, we introduce ORBIT, an open-ended rubric-based incremental training framework specifically designed for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue generation with the dynamic creation of rubrics, employing these rubrics to direct an incremental RL process. In particular, this approach does not depend on external medical knowledge or manual rules, instead utilizing rubric-guided feedback to shape learning. When implemented on the Qwen3-4B-Instruct model, our method can greatly enhance its performance on the HealthBench-Hard benchmark from 7.0 to 27.2 using only 2k samples, thus achieving state-of-the-art results for models of this scale. Our analysis confirms that rubric-driven RL fos-ters consistent performance gains across diverse consultation scenarios, going beyond simple numerical improvements. These findings underscore rubric-based feedback as a scalable strategy for advancing LLMs in intricate, open-ended tasks."

[20.10.2025 05:13] Response: ```python
["OPTIMIZATION", "SYNTHETIC", "SCIENCE"]
```
[20.10.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces ORBIT, a novel framework that enhances the performance of Large Language Models (LLMs) in medical dialogue through incremental training using dynamic rubrics. By employing reinforcement learning (RL) guided by these rubrics, ORBIT effectively addresses the challenges posed by ambiguous and context-dependent rewards in high-stakes medical consultations. The framework demonstrates significant improvements in model performance on the HealthBench-Hard benchmark, achieving state-of-the-art results with minimal training samples. This approach highlights the potential of rubric-based feedback as a scalable solution for improving LLMs in complex, open-ended tasks.","title":"ORBIT: Elevating Medical Dialogue with Rubric-Driven Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces ORBIT, a novel framework that enhances the performance of Large Language Models (LLMs) in medical dialogue through incremental training using dynamic rubrics. By employing reinforcement learning (RL) guided by these rubrics, ORBIT effectively addresses the challenges posed by ambiguous and context-dependent rewards in high-stakes medical consultations. The framework demonstrates significant improvements in model performance on the HealthBench-Hard benchmark, achieving state-of-the-art results with minimal training samples. This approach highlights the potential of rubric-based feedback as a scalable solution for improving LLMs in complex, open-ended tasks.', title='ORBIT: Elevating Medical Dialogue with Rubric-Driven Learning'))
[20.10.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种名为ORBIT的增量训练框架，旨在提升大型语言模型（LLM）在医疗对话中的表现。ORBIT通过动态创建评分标准，结合合成对话生成，采用增量强化学习（RL）方法进行训练。该方法不依赖于外部医疗知识或手动规则，而是利用评分标准指导反馈来塑造学习过程。实验结果表明，ORBIT在HealthBench-Hard基准测试中显著提高了模型性能，展示了评分标准驱动的RL在复杂开放任务中的可扩展性。","title":"ORBIT：提升医疗对话的智能训练框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种名为ORBIT的增量训练框架，旨在提升大型语言模型（LLM）在医疗对话中的表现。ORBIT通过动态创建评分标准，结合合成对话生成，采用增量强化学习（RL）方法进行训练。该方法不依赖于外部医疗知识或手动规则，而是利用评分标准指导反馈来塑造学习过程。实验结果表明，ORBIT在HealthBench-Hard基准测试中显著提高了模型性能，展示了评分标准驱动的RL在复杂开放任务中的可扩展性。', title='ORBIT：提升医疗对话的智能训练框架'))
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#science", "#dataset", "#agents", "#benchmark"], "emoji": "🌐", "ru": {"title": "Превращаем научные статьи в красивые интерактивные сайты с помощью AI-агента", "desc": "Статья представляет Paper2Web — бенчмарк и фреймворк для оценки генерации академических веб-страниц из научных стат
[20.10.2025 05:13] Using data from previous issue: {"categories": ["#dataset", "#data", "#training", "#reasoning", "#synthetic", "#benchmark", "#open_source", "#multimodal"], "emoji": "🔍", "ru": {"title": "Умная фильтрация мультимодальных данных для более сильных LLM", "desc": "Статья представляет UniFilter - единый мультимодальный классификатор кач
[20.10.2025 05:13] Renaming data file.
[20.10.2025 05:13] Renaming previous data. hf_papers.json to ./d/2025-10-20.json
[20.10.2025 05:13] Saving new data file.
[20.10.2025 05:13] Generating page.
[20.10.2025 05:13] Renaming previous page.
[20.10.2025 05:13] Renaming previous data. index.html to ./d/2025-10-20.html
[20.10.2025 05:13] Writing result.
[20.10.2025 05:13] Renaming log file.
[20.10.2025 05:13] Renaming previous data. log.txt to ./logs/2025-10-20_last_log.txt
