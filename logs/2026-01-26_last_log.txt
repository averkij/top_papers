[26.01.2026 05:35] Read previous papers.
[26.01.2026 05:35] Generating top page (month).
[26.01.2026 05:35] Writing top page (month).
[26.01.2026 06:40] Read previous papers.
[26.01.2026 06:40] Get feed.
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14133
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16973
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16725
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16746
[26.01.2026 06:40] Extract page data from URL. URL: https://huggingface.co/papers/2601.14243
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07251
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16515
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16296
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16443
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16344
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15808
[26.01.2026 06:40] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16018
[26.01.2026 06:40] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.01.2026 06:40] No deleted papers detected.
[26.01.2026 06:40] Downloading and parsing papers (pdf, html). Total: 12.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.14133.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.14133.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.14133.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16973.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16973.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16973.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16725.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16725.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16725.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16746.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16746.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16746.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.14243.
[26.01.2026 06:40] Downloading paper 2601.14243 from https://arxiv.org/pdf/2601.14243v1...
[26.01.2026 06:40] Extracting affiliations from text.
[26.01.2026 06:40] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 2 ] . [ 1 3 4 2 4 1 . 1 0 6 2 : r 2026-1-21 Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow Haocheng Xi1,3 Charlie Ruan3 Peiyuan Liao4 Yujun Lin1 Han Cai1 Yilong Zhao3 Shuo Yang3 Kurt Keutzer3 Song Han1,2 Ligeng Zhu1, 1NVIDIA 2MIT 3UC Berkeley 4Stanford University Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase consuming over 70% of the total training time. Quantized RL training, particularly with FP8, offers promising solution. For example, common approach is to employ FP8 precision during rollout to alleviate this bottleneck while retaining BF16 precision during training. In this work, we present the first comprehensive study of FP8 RL training and show that the commonly adopted BF16-train + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-rollout generation and challenging tasks. Our analysis reveals that these issues arise from the off-policy nature of the approach, which introduces significant numerical mismatch between training and inference. Motivated by these findings, we propose Jet-RL, FP8 RL training framework that enables robust and stable RL training. The key idea is to adopt an unified FP8 precision flow for both training and rollout, minimizing numerical discrepancies and avoiding the need for inefficient inter-step calibration. Extensive experiments demonstrate the effectiveness of Jet-RL. Our method achieves up to 33% rollout phase speedup, up to 41% training phase speedup, and 16% end-to-end speedup over BF16 training while maintaining robust convergence across all settings and exhibiting negligible accuracy degradation. We will release our code and pre-trained models when less anoynomous. Figure 1 Overview of RL training different between JetRL"
[26.01.2026 06:40] Response: ```python
['NVIDIA', 'MIT', 'UC Berkeley', 'Stanford University']
```
[26.01.2026 06:40] Deleting PDF ./assets/pdf/2601.14243.pdf.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.07251.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.07251.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.07251.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16515.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16515.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16515.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16296.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16296.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16296.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16443.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16443.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16443.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16344.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16344.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16344.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.15808.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.15808.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.15808.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Downloading and parsing paper https://huggingface.co/papers/2601.16018.
[26.01.2026 06:40] Extra JSON file exists (./assets/json/2601.16018.json), skip PDF parsing.
[26.01.2026 06:40] Paper image links file exists (./assets/img_data/2601.16018.json), skip HTML parsing.
[26.01.2026 06:40] Success.
[26.01.2026 06:40] Enriching papers with extra data.
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 0. TwinBrainVLA addresses the tension between semantic understanding and motor skills in robot control by coordinating a generalist vision-language model with a specialist model through an asymmetric mixture-of-transformers mechanism.  					AI-generated summary 				 Standard Vision-Language-Action (VLA...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 1. Modern vision-language models exhibit significant challenges in multi-step visual interaction tasks, particularly in long-horizon perception-memory-action integration, with performance declining when handling unbounded historical contexts.  					AI-generated summary 				 Modern Vision-Language Model...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 2. A 560-billion-parameter Mixture-of-Experts reasoning model achieves state-of-the-art performance on agentic benchmarks through a unified training framework combining domain-parallel expert training with fusion, along with enhancements for complex tool interactions and real-world robustness.  					AI...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 3. SWE-Pruner is a self-adaptive context pruning framework for coding agents that uses task-aware pruning to reduce token usage while maintaining performance.  					AI-generated summary 				 LLM agents have demonstrated remarkable capabilities in software development, but their performance is hampered ...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 4. Quantized reinforcement learning training using FP8 precision faces stability issues due to numerical mismatches between training and inference phases, but a unified FP8 framework achieves significant speedups with stable convergence.  					AI-generated summary 				 Reinforcement learning (RL) is es...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 5. MeepleLM enables human-AI collaboration in board game design by providing constructive critique through persona-specific reasoning patterns that align with player experiences.  					AI-generated summary 				 Recent advancements have expanded the role of Large Language Models in board games from play...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 6. Diffusion Transformers for video generation are enhanced with SALAD, a method that combines linear and sparse attention branches to achieve high sparsity and speedup while maintaining quality and requiring minimal training data.  					AI-generated summary 				 Diffusion Transformers have recently de...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 7. Memory-V2V enhances multi-turn video editing by maintaining cross-consistency through explicit memory mechanisms and efficient token compression in video-to-video diffusion models.  					AI-generated summary 				 Recent foundational video-to-video diffusion models have achieved impressive results in...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 8. Endless Terminals introduces an autonomous pipeline for generating procedural terminal tasks that significantly improves agent performance on both synthetic and human-curated benchmarks through scalable reinforcement learning environments.  					AI-generated summary 				 Environments are the bottlen...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 9. DSGym presents a standardized framework for evaluating data science agents with comprehensive task suites and execution-verified training capabilities.  					AI-generated summary 				 Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses ...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 10. A novel self-evolving framework for Deep Research Agents that enhances performance through iterative verification and rubric-based feedback during inference, achieving significant accuracy improvements without additional training.  					AI-generated summary 				 Recent advances in Deep Research Agen...
[26.01.2026 06:40] ********************************************************************************
[26.01.2026 06:40] Abstract 11. A framework for developing specialized Turkish legal language models through domain adaptation, featuring a pre-trained encoder model and decoder models with continual pre-training for enhanced legal text processing.  					AI-generated summary 				 This paper presents Mecellem models, a framework fo...
[26.01.2026 06:40] Read previous papers.
[26.01.2026 06:40] Generating reviews via LLM API.
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#architecture", "#robotics", "#training", "#multimodal"], "emoji": "ğŸ¤–", "ru": {"title": "Ğ”Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ·Ğ³ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°: Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ»Ğ¾Ğ²ĞºĞ¾ÑÑ‚ÑŒÑ", "desc": "TwinBrainVLA Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¸ Ğ¼Ğ¾Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ²Ñ‹ĞºĞ°Ğ¼Ğ¸ Ğ² ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°Ğ¼Ğ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ´Ğ²Ğ°
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#benchmark", "#dataset", "#cv", "#training", "#multimodal"], "emoji": "ğŸ®", "ru": {"title": "ĞšĞ¾Ğ³Ğ´Ğ° Ğ·Ñ€ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ñ‚ĞµÑ€ÑÑÑ‚ Ğ´Ñ€ÑƒĞ³ Ğ´Ñ€ÑƒĞ³Ğ°: Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…", "desc": "ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ VisGym - Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ· 17 ÑĞ¸Ğ¼ÑƒĞ»
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#open_source", "#rl", "#agents", "#architecture", "#reasoning", "#training", "#optimization"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸ĞµĞ¼: MoE-Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸", "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ LongCat-Flash-Thinking-2601 â€” Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ°
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#agents", "#inference", "#plp", "#small_models", "#optimization"], "emoji": "âœ‚ï¸", "ru": {"title": "Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° ĞºĞ¾Ğ´Ğ° Ñ‡ĞµÑ€ĞµĞ· Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ½Ğ¾-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¾Ğ±Ñ€ĞµĞ·ĞºÑƒ", "desc": "SWE-Pruner â€” ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°, ÑĞ¿ĞµÑ†
[26.01.2026 06:40] Querying the API.
[26.01.2026 06:40] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Quantized reinforcement learning training using FP8 precision faces stability issues due to numerical mismatches between training and inference phases, but a unified FP8 framework achieves significant speedups with stable convergence.  					AI-generated summary 				 Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.
[26.01.2026 06:40] Response: ```json
{
  "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ FP8 ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´, ĞºĞ¾Ğ³Ğ´Ğ° FP8 Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ ÑĞ±Ğ¾Ñ€Ğ° Ğ¾Ğ¿Ñ‹Ñ‚Ğ°, Ğ° BF16 Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ·-Ğ·Ğ° Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ… Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ğ¸Ğ¼Ğ¸ Ñ„Ğ°Ğ·Ğ°Ğ¼Ğ¸. ĞĞ½Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ Jet-RL â€” ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ FP8 Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ ÑƒÑÑ‚Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ½ĞµÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ñ€Ğ¾Ğ³Ğ¾ÑÑ‚Ğ¾ÑÑ‰ĞµĞ¹ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑˆĞ°Ğ³Ğ°Ğ¼Ğ¸. ĞœĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğ¹ (Ğ´Ğ¾ 33% Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ ÑĞ±Ğ¾Ñ€Ğ° Ğ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ¸ 16% ĞºĞ¾Ğ½ĞµÑ†-Ğ²-ĞºĞ¾Ğ½ĞµÑ†) Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸.",
  "emoji": "âš¡",
  "title": "Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ FP8 Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼"
}
```
[26.01.2026 06:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Quantized reinforcement learning training using FP8 precision faces stability issues due to numerical mismatches between training and inference phases, but a unified FP8 framework achieves significant speedups with stable convergence.  					AI-generated summary 				 Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation."

[26.01.2026 06:40] Response: ```python
['RL', 'INFERENCE', 'TRAINING']
```
[26.01.2026 06:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Quantized reinforcement learning training using FP8 precision faces stability issues due to numerical mismatches between training and inference phases, but a unified FP8 framework achieves significant speedups with stable convergence.  					AI-generated summary 				 Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation."

[26.01.2026 06:40] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[26.01.2026 06:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenges of quantized reinforcement learning (RL) training using FP8 precision, which often leads to instability due to numerical mismatches between training and inference. The authors highlight that the common practice of using BF16 precision for training and FP8 for rollout can cause significant accuracy issues, especially in long-horizon tasks. To overcome these problems, they introduce Jet-RL, a unified FP8 framework that ensures consistent precision during both training and rollout phases. Their experiments demonstrate that Jet-RL not only speeds up the training and rollout processes but also maintains stable convergence and minimal accuracy loss.","title":"Jet-RL: Unifying FP8 Precision for Stable and Fast Reinforcement Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenges of quantized reinforcement learning (RL) training using FP8 precision, which often leads to instability due to numerical mismatches between training and inference. The authors highlight that the common practice of using BF16 precision for training and FP8 for rollout can cause significant accuracy issues, especially in long-horizon tasks. To overcome these problems, they introduce Jet-RL, a unified FP8 framework that ensures consistent precision during both training and rollout phases. Their experiments demonstrate that Jet-RL not only speeds up the training and rollout processes but also maintains stable convergence and minimal accuracy loss.', title='Jet-RL: Unifying FP8 Precision for Stable and Fast Reinforcement Learning'))
[26.01.2026 06:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬æ–‡æ¢è®¨äº†é‡åŒ–å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­ä½¿ç”¨FP8ç²¾åº¦æ‰€é¢ä¸´çš„ç¨³å®šæ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µä¹‹é—´çš„æ•°å€¼ä¸åŒ¹é…ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¼ ç»Ÿçš„BF16è®­ç»ƒåŠ FP8æ¨ç†ç­–ç•¥åœ¨é•¿æ—¶é—´çš„æ¨ç†å’Œå¤æ‚ä»»åŠ¡ä¸­ä¼šå¯¼è‡´ä¸¥é‡çš„è®­ç»ƒä¸ç¨³å®šå’Œå‡†ç¡®æ€§å´©æºƒã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Jet-RLæ¡†æ¶ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„FP8ç²¾åº¦æµæ¥è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ï¼Œä»è€Œå‡å°‘æ•°å€¼å·®å¼‚å¹¶æ¶ˆé™¤ä½æ•ˆçš„æ­¥éª¤é—´æ ¡å‡†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒJet-RLåœ¨æ¨ç†å’Œè®­ç»ƒé˜¶æ®µå‡å®ç°äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ï¼ŒåŒæ—¶ä¿æŒäº†ç¨³å®šçš„æ”¶æ•›æ€§å’Œè¾ƒå°çš„å‡†ç¡®æ€§ä¸‹é™ã€‚","title":"ç»Ÿä¸€FP8æ¡†æ¶ï¼Œå®ç°ç¨³å®šé«˜æ•ˆçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬æ–‡æ¢è®¨äº†é‡åŒ–å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­ä½¿ç”¨FP8ç²¾åº¦æ‰€é¢ä¸´çš„ç¨³å®šæ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µä¹‹é—´çš„æ•°å€¼ä¸åŒ¹é…ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¼ ç»Ÿçš„BF16è®­ç»ƒåŠ FP8æ¨ç†ç­–ç•¥åœ¨é•¿æ—¶é—´çš„æ¨ç†å’Œå¤æ‚ä»»åŠ¡ä¸­ä¼šå¯¼è‡´ä¸¥é‡çš„è®­ç»ƒä¸ç¨³å®šå’Œå‡†ç¡®æ€§å´©æºƒã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Jet-RLæ¡†æ¶ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„FP8ç²¾åº¦æµæ¥è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ï¼Œä»è€Œå‡å°‘æ•°å€¼å·®å¼‚å¹¶æ¶ˆé™¤ä½æ•ˆçš„æ­¥éª¤é—´æ ¡å‡†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒJet-RLåœ¨æ¨ç†å’Œè®­ç»ƒé˜¶æ®µå‡å®ç°äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ï¼ŒåŒæ—¶ä¿æŒäº†ç¨³å®šçš„æ”¶æ•›æ€§å’Œè¾ƒå°çš„å‡†ç¡®æ€§ä¸‹é™ã€‚', title='ç»Ÿä¸€FP8æ¡†æ¶ï¼Œå®ç°ç¨³å®šé«˜æ•ˆçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒ'))
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#alignment", "#reasoning", "#games"], "emoji": "ğŸ²", "ru": {"title": "Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº Ğ¸Ğ³Ñ€ Ñ‡ĞµÑ€ĞµĞ· Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞµ Ğ³ĞµĞ¹Ğ¼Ğ¿Ğ»ĞµÑ", "desc": "MeepleLM â€” ÑÑ‚Ğ¾ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€Ğ°Ğ¼ Ğ½Ğ°ÑÑ‚Ğ¾Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ³Ñ€ Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ĞºĞ¾
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#diffusion", "#inference", "#optimization", "#training", "#video"], "emoji": "âš¡", "ru": {"title": "Ğ‘Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ‡ĞµÑ€ĞµĞ· Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ", "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´ SALAD Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Diffusion Transfor
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#video", "#inference", "#architecture", "#optimization", "#diffusion"], "emoji": "ğŸ¬", "ru": {"title": "ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ´Ğ»Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¼Ğ¾Ğ½Ñ‚Ğ°Ğ¶Ğ° Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¾Ğº", "desc": "Memory-V2V â€” ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ 
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#benchmark", "#rl", "#agents", "#dataset", "#synthetic", "#transfer_learning", "#training", "#optimization"], "emoji": "ğŸ–¥ï¸", "ru": {"title": "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Endless Terminals â€” Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ°Ğ²
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#dataset", "#agents", "#synthetic", "#science", "#training"], "emoji": "ğŸ§ª", "ru": {"title": "Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…", "desc": "DSGym Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² data science Ñ
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#agents", "#dataset", "#inference", "#reasoning", "#training"], "emoji": "ğŸ”", "ru": {"title": "Ğ¡Ğ°Ğ¼Ğ¾ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¸ Ñ€ÑƒĞ±Ñ€Ğ¸ĞºĞ¸ Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°
[26.01.2026 06:40] Using data from previous issue: {"categories": ["#multilingual", "#low_resource", "#open_source", "#transfer_learning", "#small_models", "#optimization", "#training"], "emoji": "âš–ï¸", "ru": {"title": "Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ñ‚ÑƒÑ€ĞµÑ†ĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ° Ñ‡ĞµÑ€ĞµĞ· ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ Ğº Ğ´Ğ¾Ğ¼ĞµĞ½Ñƒ", "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Mecelle
[26.01.2026 06:40] Renaming data file.
[26.01.2026 06:40] Renaming previous data. hf_papers.json to ./d/2026-01-26.json
[26.01.2026 06:40] Saving new data file.
[26.01.2026 06:40] Generating page.
[26.01.2026 06:40] Renaming previous page.
[26.01.2026 06:40] Renaming previous data. index.html to ./d/2026-01-26.html
[26.01.2026 06:40] Writing result.
[26.01.2026 06:40] Renaming log file.
[26.01.2026 06:40] Renaming previous data. log.txt to ./logs/2026-01-26_last_log.txt
