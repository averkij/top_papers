[26.01.2026 08:36] Read previous papers.
[26.01.2026 08:36] Generating top page (month).
[26.01.2026 08:36] Writing top page (month).
[26.01.2026 09:36] Read previous papers.
[26.01.2026 09:36] Get feed.
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16725
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16746
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14133
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16973
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15808
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14243
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07251
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16515
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16296
[26.01.2026 09:36] Extract page data from URL. URL: https://huggingface.co/papers/2601.11258
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16443
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16344
[26.01.2026 09:36] Extract page data from URL. URL: https://huggingface.co/papers/2601.15715
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13118
[26.01.2026 09:36] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16018
[26.01.2026 09:36] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.01.2026 09:36] No deleted papers detected.
[26.01.2026 09:36] Downloading and parsing papers (pdf, html). Total: 15.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.16725.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.16725.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.16725.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.16746.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.16746.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.16746.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.14133.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.14133.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.14133.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.16973.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.16973.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.16973.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.15808.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.15808.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.15808.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.14243.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.14243.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.14243.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.07251.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.07251.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.07251.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.16515.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.16515.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.16515.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.16296.
[26.01.2026 09:36] Extra JSON file exists (./assets/json/2601.16296.json), skip PDF parsing.
[26.01.2026 09:36] Paper image links file exists (./assets/img_data/2601.16296.json), skip HTML parsing.
[26.01.2026 09:36] Success.
[26.01.2026 09:36] Downloading and parsing paper https://huggingface.co/papers/2601.11258.
[26.01.2026 09:36] Downloading paper 2601.11258 from https://arxiv.org/pdf/2601.11258v1...
[26.01.2026 09:37] Extracting affiliations from text.
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 6 1 ] . [ 1 8 5 2 1 1 . 1 0 6 2 : r Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation 1Institute for Artificial Intelligence, Peking University 2Yuanpei College, Peking University Pingzhi Tang1,2, Yiding Wang1,2, Muhan Zhang1,3 3State Key Laboratory of General Artificial Intelligence, BIGAI *Equal contribution (cid:66) Correspondence to muhan@pku.edu.cn "
[26.01.2026 09:37] Response: ```python
[
    "Institute for Artificial Intelligence, Peking University",
    "Yuanpei College, Peking University",
    "State Key Laboratory of General Artificial Intelligence, BIGAI"
]
```
[26.01.2026 09:37] Deleting PDF ./assets/pdf/2601.11258.pdf.
[26.01.2026 09:37] Success.
[26.01.2026 09:37] Downloading and parsing paper https://huggingface.co/papers/2601.16443.
[26.01.2026 09:37] Extra JSON file exists (./assets/json/2601.16443.json), skip PDF parsing.
[26.01.2026 09:37] Paper image links file exists (./assets/img_data/2601.16443.json), skip HTML parsing.
[26.01.2026 09:37] Success.
[26.01.2026 09:37] Downloading and parsing paper https://huggingface.co/papers/2601.16344.
[26.01.2026 09:37] Extra JSON file exists (./assets/json/2601.16344.json), skip PDF parsing.
[26.01.2026 09:37] Paper image links file exists (./assets/img_data/2601.16344.json), skip HTML parsing.
[26.01.2026 09:37] Success.
[26.01.2026 09:37] Downloading and parsing paper https://huggingface.co/papers/2601.15715.
[26.01.2026 09:37] Downloading paper 2601.15715 from https://arxiv.org/pdf/2601.15715v1...
[26.01.2026 09:37] Extracting affiliations from text.
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 2 ] . [ 1 5 1 7 5 1 . 1 0 6 2 : r Preprint, under review DANCING IN CHAINS: STRATEGIC PERSUASION IN ACADEMIC REBUTTAL VIA THEORY OF MIND Zhitao He, Zongwei Lyu, Yi R. (May) Fung Hong Kong University of Science and Technology zhebu@connect.ust.hk, yrfung@ust.hk "
[26.01.2026 09:37] Response: ```python
["Hong Kong University of Science and Technology"]
```
[26.01.2026 09:37] Deleting PDF ./assets/pdf/2601.15715.pdf.
[26.01.2026 09:37] Success.
[26.01.2026 09:37] Downloading and parsing paper https://huggingface.co/papers/2601.13118.
[26.01.2026 09:37] Extra JSON file exists (./assets/json/2601.13118.json), skip PDF parsing.
[26.01.2026 09:37] Paper image links file exists (./assets/img_data/2601.13118.json), skip HTML parsing.
[26.01.2026 09:37] Success.
[26.01.2026 09:37] Downloading and parsing paper https://huggingface.co/papers/2601.16018.
[26.01.2026 09:37] Extra JSON file exists (./assets/json/2601.16018.json), skip PDF parsing.
[26.01.2026 09:37] Paper image links file exists (./assets/img_data/2601.16018.json), skip HTML parsing.
[26.01.2026 09:37] Success.
[26.01.2026 09:37] Enriching papers with extra data.
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 0. A 560-billion-parameter Mixture-of-Experts reasoning model achieves state-of-the-art performance on agentic benchmarks through a unified training framework combining domain-parallel expert training with fusion, along with enhancements for complex tool interactions and real-world robustness.  					AI...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 1. SWE-Pruner is a self-adaptive context pruning framework for coding agents that uses task-aware pruning to reduce token usage while maintaining performance.  					AI-generated summary 				 LLM agents have demonstrated remarkable capabilities in software development, but their performance is hampered ...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 2. TwinBrainVLA addresses the tension between semantic understanding and motor skills in robot control by coordinating a generalist vision-language model with a specialist model through an asymmetric mixture-of-transformers mechanism.  					AI-generated summary 				 Standard Vision-Language-Action (VLA...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 3. Modern vision-language models exhibit significant challenges in multi-step visual interaction tasks, particularly in long-horizon perception-memory-action integration, with performance declining when handling unbounded historical contexts.  					AI-generated summary 				 Modern Vision-Language Model...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 4. A novel self-evolving framework for Deep Research Agents that enhances performance through iterative verification and rubric-based feedback during inference, achieving significant accuracy improvements without additional training.  					AI-generated summary 				 Recent advances in Deep Research Agen...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 5. Quantized reinforcement learning training using FP8 precision faces stability issues due to numerical mismatches between training and inference phases, but a unified FP8 framework achieves significant speedups with stable convergence.  					AI-generated summary 				 Reinforcement learning (RL) is es...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 6. MeepleLM enables human-AI collaboration in board game design by providing constructive critique through persona-specific reasoning patterns that align with player experiences.  					AI-generated summary 				 Recent advancements have expanded the role of Large Language Models in board games from play...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 7. Diffusion Transformers for video generation are enhanced with SALAD, a method that combines linear and sparse attention branches to achieve high sparsity and speedup while maintaining quality and requiring minimal training data.  					AI-generated summary 				 Diffusion Transformers have recently de...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 8. Memory-V2V enhances multi-turn video editing by maintaining cross-consistency through explicit memory mechanisms and efficient token compression in video-to-video diffusion models.  					AI-generated summary 				 Recent foundational video-to-video diffusion models have achieved impressive results in...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 9. A novel framework called Parametric Skill Transfer (PaST) is presented that enables efficient knowledge adaptation in large language models by combining supervised fine-tuning with skill vector injection, demonstrating superior performance in question answering and tool-use tasks.  					AI-generated...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 10. Endless Terminals introduces an autonomous pipeline for generating procedural terminal tasks that significantly improves agent performance on both synthetic and human-curated benchmarks through scalable reinforcement learning environments.  					AI-generated summary 				 Environments are the bottlen...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 11. DSGym presents a standardized framework for evaluating data science agents with comprehensive task suites and execution-verified training capabilities.  					AI-generated summary 				 Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses ...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 12. RebuttalAgent is a novel framework that applies Theory of Mind to academic rebuttal, utilizing a ToM-Strategy-Response pipeline with supervised fine-tuning and reinforcement learning for improved automated evaluation.  					AI-generated summary 				 Although artificial intelligence (AI) has become d...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 13. Research derives and evaluates prompt optimization guidelines for code generation tasks in software engineering, identifying 10 specific improvement patterns related to input/output specification, conditions, examples, and clarity.  					AI-generated summary 				 Large Language Models (LLMs) are now...
[26.01.2026 09:37] ********************************************************************************
[26.01.2026 09:37] Abstract 14. A framework for developing specialized Turkish legal language models through domain adaptation, featuring a pre-trained encoder model and decoder models with continual pre-training for enhanced legal text processing.  					AI-generated summary 				 This paper presents Mecellem models, a framework fo...
[26.01.2026 09:37] Read previous papers.
[26.01.2026 09:37] Generating reviews via LLM API.
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#open_source", "#rl", "#agents", "#architecture", "#reasoning", "#training", "#optimization"], "emoji": "üß†", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç —Å –≥–ª—É–±–æ–∫–∏–º –º—ã—à–ª–µ–Ω–∏–µ–º: MoE-–º–æ–¥–µ–ª—å –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω LongCat-Flash-Thinking-2601 ‚Äî –æ—Ç–∫—Ä—ã—Ç–∞
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#agents", "#inference", "#plp", "#small_models", "#optimization"], "emoji": "‚úÇÔ∏è", "ru": {"title": "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–æ–¥–∞ —á–µ—Ä–µ–∑ –∑–∞–¥–∞—á–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ–±—Ä–µ–∑–∫—É", "desc": "SWE-Pruner ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –æ–±—Ä–µ–∑–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —Å–ø–µ—Ü
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#architecture", "#robotics", "#training", "#multimodal"], "emoji": "ü§ñ", "ru": {"title": "–î–≤–æ–π–Ω–æ–π –º–æ–∑–≥ —Ä–æ–±–æ—Ç–∞: –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –º—ã—à–ª–µ–Ω–∏–µ–º –∏ –ª–æ–≤–∫–æ—Å—Ç—å—é", "desc": "TwinBrainVLA —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –º–µ–∂–¥—É —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏ –º–æ—Ç–æ—Ä–Ω—ã–º–∏ –Ω–∞–≤—ã–∫–∞–º–∏ –≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —Ä–æ–±–æ—Ç–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—è –¥–≤–∞
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#benchmark", "#dataset", "#cv", "#training", "#multimodal"], "emoji": "üéÆ", "ru": {"title": "–ö–æ–≥–¥–∞ –∑—Ä–µ–Ω–∏–µ –∏ –ø–∞–º—è—Ç—å —Ç–µ—Ä—è—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞: –ø—Ä–æ–±–ª–µ–º—ã —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç VisGym - –Ω–∞–±–æ—Ä –∏–∑ 17 —Å–∏–º—É–ª
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#agents", "#dataset", "#inference", "#reasoning", "#training"], "emoji": "üîç", "ru": {"title": "–°–∞–º–æ—É–ª—É—á—à–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é –∏ —Ä—É–±—Ä–∏–∫–∏ –Ω–∞ —ç—Ç–∞–ø–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#optimization", "#rl", "#inference", "#training", "#reasoning"], "emoji": "‚ö°", "ru": {"title": "–ï–¥–∏–Ω–∞—è FP8 —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –∏ –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ FP8 –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#alignment", "#reasoning", "#games"], "emoji": "üé≤", "ru": {"title": "–í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ –∏–≥—Ä —á–µ—Ä–µ–∑ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –æ –¥–∏–Ω–∞–º–∏–∫–µ –≥–µ–π–º–ø–ª–µ—è", "desc": "MeepleLM ‚Äî —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–º–æ–≥–∞–µ—Ç –¥–∏–∑–∞–π–Ω–µ—Ä–∞–º –Ω–∞—Å—Ç–æ–ª—å–Ω—ã—Ö –∏–≥—Ä –ø—É—Ç—ë–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#diffusion", "#inference", "#optimization", "#training", "#video"], "emoji": "‚ö°", "ru": {"title": "–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –≥–∏–±—Ä–∏–¥–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ SALAD –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è Diffusion Transfor
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#video", "#inference", "#architecture", "#optimization", "#diffusion"], "emoji": "üé¨", "ru": {"title": "–ü–∞–º—è—Ç—å –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ–º–æ–Ω—Ç–∞–∂–∞ —á–µ—Ä–µ–∑ –ø–æ–∫–æ–ª–µ–Ω–∏—è –ø—Ä–∞–≤–æ–∫", "desc": "Memory-V2V ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ 
[26.01.2026 09:37] Querying the API.
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel framework called Parametric Skill Transfer (PaST) is presented that enables efficient knowledge adaptation in large language models by combining supervised fine-tuning with skill vector injection, demonstrating superior performance in question answering and tool-use tasks.  					AI-generated summary 				 Large Language Models (LLMs) face the "knowledge cutoff" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.
[26.01.2026 09:37] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è –º–µ—Ç–æ–¥–∏–∫–∞ Parametric Skill Transfer (PaST), –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –Ω–æ–≤—ã–º –∑–Ω–∞–Ω–∏—è–º. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ supervised fine-tuning –∏ reinforcement learning –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥—É–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –Ω–∞–≤—ã–∫–∏ –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏. –ú–µ—Ç–æ–¥ –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –ª—ë–≥–∫–∏–π supervised fine-tuning —Å –∏–Ω—ä–µ–∫—Ü–∏–µ–π –≤–µ–∫—Ç–æ—Ä–æ–≤ –Ω–∞–≤—ã–∫–æ–≤, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é –∞–¥–∞–ø—Ç–∞—Ü–∏—é –±–µ–∑ –≤—ã—Å–æ–∫–∏—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞ –∑–∞–¥–∞—á–∞—Ö –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, —Å –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ–º baseline'–æ–≤ –Ω–∞ 8-10 –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –ø—É–Ω–∫—Ç–∞.",
  "emoji": "üß†",
  "title": "–ú–æ–¥—É–ª—å–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –Ω–∞–≤—ã–∫–æ–≤ —á–µ—Ä–µ–∑ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
}
```
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework called Parametric Skill Transfer (PaST) is presented that enables efficient knowledge adaptation in large language models by combining supervised fine-tuning with skill vector injection, demonstrating superior performance in question answering and tool-use tasks.  					AI-generated summary 				 Large Language Models (LLMs) face the "knowledge cutoff" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector."

[26.01.2026 09:37] Response: ```python
["TRAINING", "RL", "AGENTS", "BENCHMARK"]
```
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework called Parametric Skill Transfer (PaST) is presented that enables efficient knowledge adaptation in large language models by combining supervised fine-tuning with skill vector injection, demonstrating superior performance in question answering and tool-use tasks.  					AI-generated summary 				 Large Language Models (LLMs) face the "knowledge cutoff" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector."

[26.01.2026 09:37] Response: ```python
["TRANSFER_LEARNING", "REASONING", "LONG_CONTEXT"]
```
[26.01.2026 09:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces a new method called Parametric Skill Transfer (PaST) that helps large language models (LLMs) learn new information more effectively. It combines supervised fine-tuning with a technique called skill vector injection, allowing models to adapt their knowledge without losing their ability to answer questions or make decisions. The authors found that the updates from fine-tuning and reinforcement learning are almost independent, which led to the development of PaST for better skill transfer. Experiments show that PaST significantly improves performance on various tasks, including question answering and tool use, demonstrating its efficiency and versatility.","title":"Efficient Knowledge Adaptation with Parametric Skill Transfer"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces a new method called Parametric Skill Transfer (PaST) that helps large language models (LLMs) learn new information more effectively. It combines supervised fine-tuning with a technique called skill vector injection, allowing models to adapt their knowledge without losing their ability to answer questions or make decisions. The authors found that the updates from fine-tuning and reinforcement learning are almost independent, which led to the development of PaST for better skill transfer. Experiments show that PaST significantly improves performance on various tasks, including question answering and tool use, demonstrating its efficiency and versatility.', title='Efficient Knowledge Adaptation with Parametric Skill Transfer'))
[26.01.2026 09:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞Ê°ÜÊû∂ÔºåÁß∞‰∏∫ÂèÇÊï∞ÊäÄËÉΩËΩ¨ÁßªÔºàPaSTÔºâÔºåÊó®Âú®ÈÄöËøáÁªìÂêàÁõëÁù£ÂæÆË∞ÉÂíåÊäÄËÉΩÂêëÈáèÊ≥®ÂÖ•ÔºåÂÆûÁé∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈ´òÊïàÁü•ËØÜÈÄÇÂ∫î„ÄÇËØ•ÊñπÊ≥ïËß£ÂÜ≥‰∫ÜÊ®°ÂûãÂú®Áü•ËØÜÊõ¥Êñ∞Êó∂ÁöÑÂ±ÄÈôêÊÄßÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáÈóÆÁ≠îÂíåÂ∑•ÂÖ∑‰ΩøÁî®‰ªªÂä°ÁöÑË°®Áé∞„ÄÇÈÄöËøá‰ªéÊ∫êÈ¢ÜÂüüÊèêÂèñÈ¢ÜÂüüÊó†ÂÖ≥ÁöÑÊäÄËÉΩÂêëÈáèÔºåPaSTÂèØ‰ª•Âú®ËΩªÈáèÁ∫ßÂæÆË∞ÉÂêéÔºåÂ∞ÜÁü•ËØÜÊìç‰ΩúÊäÄËÉΩÁ∫øÊÄßÊ≥®ÂÖ•ÁõÆÊ†áÊ®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPaSTÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âº∫Â§ßÁöÑÂèØÊâ©Â±ïÊÄßÂíåË∑®È¢ÜÂüüËΩ¨ÁßªËÉΩÂäõ„ÄÇ","title":"ÂèÇÊï∞ÊäÄËÉΩËΩ¨ÁßªÔºöÈ´òÊïàÁü•ËØÜÈÄÇÂ∫îÁöÑÊñ∞ÊñπÊ≥ï"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞Ê°ÜÊû∂ÔºåÁß∞‰∏∫ÂèÇÊï∞ÊäÄËÉΩËΩ¨ÁßªÔºàPaSTÔºâÔºåÊó®Âú®ÈÄöËøáÁªìÂêàÁõëÁù£ÂæÆË∞ÉÂíåÊäÄËÉΩÂêëÈáèÊ≥®ÂÖ•ÔºåÂÆûÁé∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈ´òÊïàÁü•ËØÜÈÄÇÂ∫î„ÄÇËØ•ÊñπÊ≥ïËß£ÂÜ≥‰∫ÜÊ®°ÂûãÂú®Áü•ËØÜÊõ¥Êñ∞Êó∂ÁöÑÂ±ÄÈôêÊÄßÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáÈóÆÁ≠îÂíåÂ∑•ÂÖ∑‰ΩøÁî®‰ªªÂä°ÁöÑË°®Áé∞„ÄÇÈÄöËøá‰ªéÊ∫êÈ¢ÜÂüüÊèêÂèñÈ¢ÜÂüüÊó†ÂÖ≥ÁöÑÊäÄËÉΩÂêëÈáèÔºåPaSTÂèØ‰ª•Âú®ËΩªÈáèÁ∫ßÂæÆË∞ÉÂêéÔºåÂ∞ÜÁü•ËØÜÊìç‰ΩúÊäÄËÉΩÁ∫øÊÄßÊ≥®ÂÖ•ÁõÆÊ†áÊ®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPaSTÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âº∫Â§ßÁöÑÂèØÊâ©Â±ïÊÄßÂíåË∑®È¢ÜÂüüËΩ¨ÁßªËÉΩÂäõ„ÄÇ', title='ÂèÇÊï∞ÊäÄËÉΩËΩ¨ÁßªÔºöÈ´òÊïàÁü•ËØÜÈÄÇÂ∫îÁöÑÊñ∞ÊñπÊ≥ï'))
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#benchmark", "#rl", "#agents", "#dataset", "#synthetic", "#transfer_learning", "#training", "#optimization"], "emoji": "üñ•Ô∏è", "ru": {"title": "–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ Endless Terminals ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#dataset", "#agents", "#synthetic", "#science", "#training"], "emoji": "üß™", "ru": {"title": "–ï–¥–∏–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏ –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö", "desc": "DSGym –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤ data science —Å
[26.01.2026 09:37] Querying the API.
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

RebuttalAgent is a novel framework that applies Theory of Mind to academic rebuttal, utilizing a ToM-Strategy-Response pipeline with supervised fine-tuning and reinforcement learning for improved automated evaluation.  					AI-generated summary 				 Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.
[26.01.2026 09:37] Response: ```json
{
  "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç RebuttalAgent ‚Äî –ø–µ—Ä–≤—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π, –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ —Ç–µ–æ—Ä–∏–∏ mind (ToM). –§—Ä–µ–π–º–≤–æ—Ä–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä—ë—Ö—ç—Ç–∞–ø–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä: –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Å–∏—Ö–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ—Ü–µ–Ω–∑–µ–Ω—Ç–∞, —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —É–±–µ–∂–¥–µ–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞. –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –≤ –¥–≤–∞ —ç—Ç–∞–ø–∞ ‚Äî —Å–Ω–∞—á–∞–ª–∞ supervised fine-tuning –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, –∑–∞—Ç–µ–º reinforcement learning —Å –º–µ—Ö–∞–Ω–∏–∑–º–æ–º —Å–∞–º–æ–≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è. –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∫–∏ Rebuttal-RM, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ 100K –ø—Ä–∏–º–µ—Ä–∞—Ö, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç GPT-4 –ø–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏.",
  "emoji": "üéØ",
  "title": "–¢–µ–æ—Ä–∏—è —Å–æ–∑–Ω–∞–Ω–∏—è –¥–ª—è —É–±–µ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π"
}
```
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RebuttalAgent is a novel framework that applies Theory of Mind to academic rebuttal, utilizing a ToM-Strategy-Response pipeline with supervised fine-tuning and reinforcement learning for improved automated evaluation.  					AI-generated summary 				 Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response."

[26.01.2026 09:37] Response: ```python
["DATASET", "BENCHMARK", "AGENTS", "TRAINING", "RL", "RLHF"]
```
[26.01.2026 09:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RebuttalAgent is a novel framework that applies Theory of Mind to academic rebuttal, utilizing a ToM-Strategy-Response pipeline with supervised fine-tuning and reinforcement learning for improved automated evaluation.  					AI-generated summary 				 Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response."

[26.01.2026 09:37] Response: ```python
['REASONING', 'ALIGNMENT', 'SCIENCE', 'OPEN_SOURCE']
```
[26.01.2026 09:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RebuttalAgent is a groundbreaking framework that enhances academic rebuttal by incorporating Theory of Mind (ToM) principles. It utilizes a ToM-Strategy-Response pipeline to understand the mental states of reviewers, develop persuasive strategies, and generate contextually relevant responses. The framework is trained using a two-stage process that includes supervised fine-tuning for strategic planning and reinforcement learning for continuous improvement. With the help of a specialized evaluator, Rebuttal-RM, the system demonstrates superior performance in automated evaluations compared to existing models, achieving higher consistency with human preferences.","title":"Empowering Academic Rebuttal with Theory of Mind"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RebuttalAgent is a groundbreaking framework that enhances academic rebuttal by incorporating Theory of Mind (ToM) principles. It utilizes a ToM-Strategy-Response pipeline to understand the mental states of reviewers, develop persuasive strategies, and generate contextually relevant responses. The framework is trained using a two-stage process that includes supervised fine-tuning for strategic planning and reinforcement learning for continuous improvement. With the help of a specialized evaluator, Rebuttal-RM, the system demonstrates superior performance in automated evaluations compared to existing models, achieving higher consistency with human preferences.', title='Empowering Academic Rebuttal with Theory of Mind'))
[26.01.2026 09:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RebuttalAgentÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂà©Áî®ÂøÉÊô∫ÁêÜËÆ∫ÔºàTheory of MindÔºâÊù•Â§ÑÁêÜÂ≠¶ÊúØÂèçÈ©≥ÈóÆÈ¢ò„ÄÇÂÆÉÈÄöËøáToM-Á≠ñÁï•-ÂìçÂ∫îÔºàToM-Strategy-ResponseÔºâÁÆ°ÈÅìÔºåÁªìÂêàÁõëÁù£ÂæÆË∞ÉÂíåÂº∫ÂåñÂ≠¶‰π†ÔºåÊèêÂçáËá™Âä®ËØÑ‰º∞ÁöÑÊïàÊûú„ÄÇËØ•Ê°ÜÊû∂ËÉΩÂ§üÊ®°ÊãüËØÑÂÆ°ËÄÖÁöÑÂøÉÁêÜÁä∂ÊÄÅÔºåÂà∂ÂÆöËØ¥ÊúçÁ≠ñÁï•ÔºåÂπ∂ÁîüÊàêÂü∫‰∫éÁ≠ñÁï•ÁöÑÂõûÂ∫î„ÄÇÈÄöËøáÊûÑÂª∫RebuttalBenchÊï∞ÊçÆÈõÜÂπ∂ËøõË°å‰∏§Èò∂ÊÆµËÆ≠ÁªÉÔºåRebuttalAgentÂú®Ëá™Âä®ÂåñÊåáÊ†á‰∏äÂπ≥ÂùáÊèêÂçá‰∫Ü18.3%ÔºåÂπ∂Âú®Â§öÊ∫êÂèçÈ©≥Êï∞ÊçÆÁöÑËØÑ‰º∞‰∏≠Ë∂ÖË∂ä‰∫Ü‰∫∫Á±ªÂÅèÂ•ΩÁöÑËØÑÂàÜ‰∏ÄËá¥ÊÄß„ÄÇ","title":"ÂøÉÊô∫ÁêÜËÆ∫È©±Âä®ÁöÑÂ≠¶ÊúØÂèçÈ©≥Ê°ÜÊû∂"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RebuttalAgentÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂà©Áî®ÂøÉÊô∫ÁêÜËÆ∫ÔºàTheory of MindÔºâÊù•Â§ÑÁêÜÂ≠¶ÊúØÂèçÈ©≥ÈóÆÈ¢ò„ÄÇÂÆÉÈÄöËøáToM-Á≠ñÁï•-ÂìçÂ∫îÔºàToM-Strategy-ResponseÔºâÁÆ°ÈÅìÔºåÁªìÂêàÁõëÁù£ÂæÆË∞ÉÂíåÂº∫ÂåñÂ≠¶‰π†ÔºåÊèêÂçáËá™Âä®ËØÑ‰º∞ÁöÑÊïàÊûú„ÄÇËØ•Ê°ÜÊû∂ËÉΩÂ§üÊ®°ÊãüËØÑÂÆ°ËÄÖÁöÑÂøÉÁêÜÁä∂ÊÄÅÔºåÂà∂ÂÆöËØ¥ÊúçÁ≠ñÁï•ÔºåÂπ∂ÁîüÊàêÂü∫‰∫éÁ≠ñÁï•ÁöÑÂõûÂ∫î„ÄÇÈÄöËøáÊûÑÂª∫RebuttalBenchÊï∞ÊçÆÈõÜÂπ∂ËøõË°å‰∏§Èò∂ÊÆµËÆ≠ÁªÉÔºåRebuttalAgentÂú®Ëá™Âä®ÂåñÊåáÊ†á‰∏äÂπ≥ÂùáÊèêÂçá‰∫Ü18.3%ÔºåÂπ∂Âú®Â§öÊ∫êÂèçÈ©≥Êï∞ÊçÆÁöÑËØÑ‰º∞‰∏≠Ë∂ÖË∂ä‰∫Ü‰∫∫Á±ªÂÅèÂ•ΩÁöÑËØÑÂàÜ‰∏ÄËá¥ÊÄß„ÄÇ', title='ÂøÉÊô∫ÁêÜËÆ∫È©±Âä®ÁöÑÂ≠¶ÊúØÂèçÈ©≥Ê°ÜÊû∂'))
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#optimization"], "emoji": "üí°", "ru": {"title": "–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∏—Ç –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –∑–∞–¥–∞—á –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ
[26.01.2026 09:37] Using data from previous issue: {"categories": ["#multilingual", "#low_resource", "#open_source", "#transfer_learning", "#small_models", "#optimization", "#training"], "emoji": "‚öñÔ∏è", "ru": {"title": "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç—É—Ä–µ—Ü–∫–æ–≥–æ –ø—Ä–∞–≤–∞ —á–µ—Ä–µ–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é –∞–¥–∞–ø—Ç–∞—Ü–∏—é –∫ –¥–æ–º–µ–Ω—É", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ Mecelle
[26.01.2026 09:37] Renaming data file.
[26.01.2026 09:37] Renaming previous data. hf_papers.json to ./d/2026-01-26.json
[26.01.2026 09:37] Saving new data file.
[26.01.2026 09:37] Generating page.
[26.01.2026 09:37] Renaming previous page.
[26.01.2026 09:37] Renaming previous data. index.html to ./d/2026-01-26.html
[26.01.2026 09:37] Writing result.
[26.01.2026 09:37] Renaming log file.
[26.01.2026 09:37] Renaming previous data. log.txt to ./logs/2026-01-26_last_log.txt
