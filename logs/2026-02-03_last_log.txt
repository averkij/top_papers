[02.02.2026 18:48] Read previous papers.
[02.02.2026 18:48] Generating top page (month).
[02.02.2026 18:48] Writing top page (month).
[03.02.2026 17:21] Read previous papers.
[03.02.2026 17:21] Get feed.
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.00919
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02276
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.22060
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02185
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02084
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02437
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02053
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01566
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02361
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01590
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02493
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02383
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02488
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01624
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01756
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02214
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01801
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02092
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01395
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01541
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01058
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01851
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01538
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01335
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02486
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02343
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02227
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01576
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01479
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02472
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02156
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01322
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.20613
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02453
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01675
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01660
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01511
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01382
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.00986
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.00759
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02110
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01842
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01296
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01077
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.22674
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.22588
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02039
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01997
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01983
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.23000
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.00130
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02354
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02287
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01970
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.00192
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.22296
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.21968
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.21759
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.02338
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01984
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01897
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01815
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.01618
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2602.00521
[03.02.2026 17:21] Extract page data from URL. URL: https://huggingface.co/papers/2601.22801
[03.02.2026 17:21] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.02.2026 17:21] Downloading and parsing papers (pdf, html). Total: 65.
[03.02.2026 17:21] Downloading and parsing paper https://huggingface.co/papers/2602.00919.
[03.02.2026 17:21] Downloading paper 2602.00919 from https://arxiv.org/pdf/2602.00919v1...
[03.02.2026 17:21] Extracting affiliations from text.
[03.02.2026 17:21] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 3 ] . [ 1 9 1 9 0 0 . 2 0 6 2 : r Green-VLA: Staged VisionLanguageAction Model for Generalist Robots Manipulation Team, Sber Robotics Center* *A detailed list of contributors in section 7 We introduce Green-VLA, staged VisionLanguageAction framework for real-world deployment on the humanoid Green robot, while maintaining generalization across diverse embodiments. Green-VLA follows five-stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) RL-based policy alignment. Progression builds semantic and physical priors, learns shared affordances, and aligns policies for long-horizon execution beyond behavior cloning. At its core is unified data and control stack for robot fleets. scalable data-processing pipeline including DataQA and temporal-alignment filters and synchronizes 3,000 hours of demonstrations; unified, embodiment-aware action interface enables single policy to control humanoids, mobile manipulators, and fixedbase arms; and the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance module that generalizes to unseen objects. Optimized for the Green humanoid, Green-VLA generalizes in zero-shot manner to new embodiments and achieves state-of-the-art performance across bimanual systems and benchmarks, with RL alignment providing gains in success rate, robustness, and long-horizon efficiency. Sber Robotics Center Date: February 2026 Code: https://github.com/greenvla/GreenVLA Project Page: https://greenvla.github.io/ VisionLanguageAction (VLA) models have recently emerged as promising foundation for embodied AI, extending the success of large-scale language and vision models into robotics. By conditioning robot control on multimodal context and natural language instructions, VLAs aim to unify perception, reasoning, and action within single end-to-end framework. This paradigm promises genera"
[03.02.2026 17:21] Response: ```python
["Sber Robotics Center"]
```
[03.02.2026 17:21] Deleting PDF ./assets/pdf/2602.00919.pdf.
[03.02.2026 17:21] Success.
[03.02.2026 17:21] Downloading and parsing paper https://huggingface.co/papers/2602.02276.
[03.02.2026 17:21] Downloading paper 2602.02276 from https://arxiv.org/pdf/2602.02276v1...
[03.02.2026 17:23] Extracting affiliations from text.
[03.02.2026 17:23] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"KIMI K2.5: VISUAL AGENTIC INTELLIGENCE TECHNICAL REPORT OF KIMI K2.5 Kimi Team "
[03.02.2026 17:23] Response: ```python
[]
```
[03.02.2026 17:23] Extracting affiliations from text.
[03.02.2026 17:23] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"KIMI K2.5: VISUAL AGENTIC INTELLIGENCE TECHNICAL REPORT OF KIMI K2.5 Kimi TeamWe introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5 over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint1 to facilitate future research and real-world applications of agentic intelligence. 6 2 0 2 2 ] . [ 1 6 7 2 2 0 . 2 0 6 2 : r Figure 1: Kimi K2.5 main results.Large Language Models (LLMs) are rapidly evolving toward agentic intelligence. Recent advances, such as GPT5.2 [41], Claude Opus 4.5 [6], Gemini 3 Pro [20], and Kimi K2-Thinking [1], demonstrate substantial progress in agentic capabilities, particularly in tool calling and reasoning. These models increasingly exhibit the ability to decompose complex problems into multi-step plans and to execute long sequences of interleaved reasoning and actions. 1https://huggingface.co/moonshotai/Kimi-K2.5 Kimi K2.5 TECHNICAL REPORT In this report, we introduce the training methods and evaluation results of Kimi K2.5. Concretely, we improve the training of K2.5 over previous models in the following two key aspects. Joint Optimization of Text and Vision. key insight from the practice of K2.5 is that joint optimization of text and vision enhances both modalities and avoids the conflict. Specifically, we devise set of techniques for this purpose. During pre-training, in contrast to conventional approaches that add visual tokens to text backbone at late stage [8, 21], we find early vision fusion with lower ratios tends to yield better results given the fixed total vision-text tokens. Therefore, K2.5 mixes text and vision tokens with constant ratio throughout the entire training process. Architecturally, Kimi K2.5 employs MoonViT-3D, native-resolution vision encoder incorporating the NaViT packing strategy [15], enabling variable-resolution image inputs. For video understanding, we introduce lightweight 3D ViT compression mechanism: consecutive frames are grouped in fours, processed through the shared MoonViT encoder, and temporally averaged at the patch level. This design allows Kimi K2.5 to process videos up to 4 longer within the same context window while maintaining complete weight sharing between image and video encoders. During post-training, we introduce zero-vision SFTtext-only SFT alone activates visual reasoning and tool use. We find that adding human-designed visual trajectories at this stage hurts generalization. In contrast, text-only SFT performs betterlikely because joint pretraining already establishes strong vision-text alignment, enabling capabilities to generalize naturally across modalities. We then apply joint RL on both text and vision tasks. Crucially, we find visual RL enhances textual performance rather than degrading it, with improvements on MMLU-Pro and GPQADiamond. This bidirectional enhancementtext bootstraps vision, vision refines textrepresents superior crossmodal alignment in joint training. Agent Swarm: Parallel Agent Orchestration. Most existing agentic models rely on sequential execution of tool calls. Even systems capable of hundreds of reasoning steps, such as Kimi K2-Thinking [1], suffer from linear scaling of inference time, leading to unacceptable latency and limiting task complexity. As agentic workloads grow in scope and heterogeneitye.g., building complex project that involves massive-scale research, design, and developmentthe sequential paradigm becomes increasingly inefficient. To overcome the latency and scalability limits of sequential agent execution, Kimi K2.5 introduces Agent Swarm, dynamic framework for parallel agent orchestration. We propose Parallel-Agent Reinforcement Learning (PARL) paradigm that departs from traditional agentic RL [2]. In addition to optimizing tool execution via verifiable rewards, the model is equipped with interfaces for sub-agent creation and task delegation. During training, sub-agents are frozen and their execution trajectories are excluded from the optimization objective; only the orchestrator is updated via reinforcement learning. This decoupling circumvents two challenges of end-to-end co-optimization: credit assignment ambiguity and training instability. Agent Swarm enables complex tasks to be decomposed into heterogeneous subproblems executed concurrently by domain-specialized agents, transforming task complexity from linear scaling to parallel processing. In wide-search scenarios, Agent Swarm reduces inference latency by up to 4.5 while improving item-level F1 from 72.8% to 79.0% compared to single-agent baselines. Kimi K2.5 represents unified architecture for general-purpose agentic intelligence, integrating vision and language, thinking and instant modes, chats and agents. It achieves strong performance across broad range of agentic and frontier benchmarks, including state-of-the-art results in visual-to-code generation (image/video-to-code) and realworld software engineering in our internal evaluations, while scaling both the diversity of specialized agents and the degree of parallelism. To accelerate community progress toward General Agentic Intelligence, we open-source our post-trained checkpoints of Kimi K2.5, enabling researchers and developers to explore, refine, and deploy scalable agentic intelligence.Kimi K2.5 is native multimodal model built upon Kimi K2 through large-scale joint pre-training on approximately 15 trillion mixed visual and text tokens. Unlike vision-adapted models that compromise either linguistic or visual capabilities, our joint pre-training paradigm enhances both modalities simultaneously. This section describes the multimodal joint optimization methodology that extends Kimi K2 to Kimi K2.5. 2.1 Native Multimodal Pre-Training key design question for multimodal pre-training is: Given fixed vision-text to"
[03.02.2026 17:23] Mistral response. {"id": "386599b08cfd455fb187e1e93521d05a", "created": 1770139408, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1410, "total_tokens": 1425, "completion_tokens": 15, "num_cached_tokens": 1409}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Kimi Team\", \"MoonShot AI\"]\n```"}}]}
[03.02.2026 17:23] Response: ```python
["Kimi Team", "MoonShot AI"]
```
[03.02.2026 17:23] Deleting PDF ./assets/pdf/2602.02276.pdf.
[03.02.2026 17:23] Success.
[03.02.2026 17:23] Downloading and parsing paper https://huggingface.co/papers/2601.22060.
[03.02.2026 17:23] Downloading paper 2601.22060 from https://arxiv.org/pdf/2601.22060v1...
[03.02.2026 17:23] Extracting affiliations from text.
[03.02.2026 17:23] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models Wenxuan Huang1,2 Yu Zeng3 Qiuchen Wang3 Zhen Fang3 Shaosheng Cao4(cid:66) Zheng Chu5 Qingyu Yin6 Shuang Chen7 Zhenfei Yin8 Lin Chen3 Zehui Chen3 Yao Hu4 Philip Torr8 Feng Zhao3 Wanli Ouyang1,9(cid:66) 1CUHK MMLab 5Harbin Institute of Technology 6Zhejiang University 7University of California, Los Angeles 3University of Science and Technology of China 2East China Normal University 4Xiaohongshu Inc. 8University of Oxford 9Shenzhen Loop Area Institute wxhuang0616@gmail.com (Wenxuan Huang) *: Equal Contribution : Project Leader (cid:66): Corresponding Author 6 2 0 2 9 2 ] . [ 1 0 6 0 2 2 . 1 0 6 2 : r Figure 1. Panel A: We identify two key limitations of existing multimodal deep-research paradigms for image search. First, prior multimodal deep-research MLLMs largely ignore the search engine hit-rate problem. In image retrieval, single full-image or even entity-level query often fails to retrieve the required evidence; moreover, querying different-scale crops of the same entity can yield highly variable results. Second, existing methods are constrained in both reasoning depth and retrieval breadth, typically producing only short trajectories. In contrast, our approach supports dozens of reasoning steps and hundreds of engine interactions, leading to substantially stronger performance. Panel B: Pipeline Overview. We synthesize high-quality VQA instances and multi-turn trajectories, and then integrate multimodal deep-research capabilities into an MLLM via SFT and RL training. This enables long-horizon reasoning that performs multi-turn, multi-entity, and multi-scale visual and textual search. Bottom Image: Performance Comparison. Our model achieves the SoTA performance on six benchmarks with comparatively smaller parameter. The our Large and Small models correspond to the 30B-A3B and 8B parameter scales, respectively, while Qwen3-VL and WebWatcher refer to Qwen3-VL-30B-A3B-Thinkin"
[03.02.2026 17:23] Response: ```python
[
    "CUHK MMLab",
    "Harbin Institute of Technology",
    "Zhejiang University",
    "University of California, Los Angeles",
    "University of Science and Technology of China",
    "East China Normal University",
    "Xiaohongshu Inc.",
    "University of Oxford",
    "Shenzhen Loop Area Institute"
]
```
[03.02.2026 17:23] Deleting PDF ./assets/pdf/2601.22060.pdf.
[03.02.2026 17:23] Success.
[03.02.2026 17:23] Downloading and parsing paper https://huggingface.co/papers/2602.02185.
[03.02.2026 17:23] Downloading paper 2602.02185 from https://arxiv.org/pdf/2602.02185v1...
[03.02.2026 17:23] Extracting affiliations from text.
[03.02.2026 17:23] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 5 8 1 2 0 . 2 0 6 2 : r Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models Yu Zeng2 Wenxuan Huang1,3(cid:66) Zhen Fang2 Shuang Chen5 Yufan Shen6 Yishuo Cai7 Xiaoman Wang3 Zhenfei Yin8 Lin Chen2 Zehui Chen2 Shiting Huang2 Yiming Zhao2 Yao Hu4 Philip Torr8 Wanli Ouyang1,9 Shaosheng Cao4(cid:66) 1CUHK MMLab 2University of Science and Technology of China 3East China Normal University 4Xiaohongshu Inc. 5The University of California, Los Angeles 6Zhejiang University 9Shenzhen Loop Area Institute wxhuang0616@gmail.com (Wenxuan Huang) *: Equal Contribution : Project Leader (cid:66): Corresponding Author 7Peking University 8University of Oxford "
[03.02.2026 17:23] Response: ```python
[
    "CUHK MMLab",
    "University of Science and Technology of China",
    "East China Normal University",
    "Xiaohongshu Inc.",
    "The University of California, Los Angeles",
    "Zhejiang University",
    "Peking University",
    "University of Oxford",
    "Shenzhen Loop Area Institute"
]
```
[03.02.2026 17:23] Deleting PDF ./assets/pdf/2602.02185.pdf.
[03.02.2026 17:23] Success.
[03.02.2026 17:23] Downloading and parsing paper https://huggingface.co/papers/2602.02084.
[03.02.2026 17:23] Downloading paper 2602.02084 from https://arxiv.org/pdf/2602.02084v1...
[03.02.2026 17:23] Extracting affiliations from text.
[03.02.2026 17:23] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 4 8 0 2 0 . 2 0 6 2 : r Closing the Loop: Universal Repository Representation with RPG-Encoder Jane Luo1,;, , Chengyu yin1 ;,, Xin Zhang1 ,:, Qingtao Li1, Steven Liu1,;, Yiming Huang2, Jie Wu3,;, Hao Liu1,;, Yangyu Huang1, Yu Kang1, Fangkai Yang1, Ying Xin1, Scarlett Li1, 1Microsoft Research Asia 2UCSD 3Tsinghua University Equal contribution : Corresponding author ; Work done during internships at Microsoft Current repository agents encounter reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, framework that generalizes the Repository Planning Graph (RPG) from static generative blueprint into unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPGs high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation. Date: February 3, 2026 Code: https://github.com/microsoft/RPG-ZeroRepo Project: https://ayanami2003.github.io/RPG-Encoder/ Prior Work: https://arxiv.org/abs"
[03.02.2026 17:23] Response: ```python
[
    "Microsoft Research Asia",
    "UCSD",
    "Tsinghua University"
]
```
[03.02.2026 17:23] Deleting PDF ./assets/pdf/2602.02084.pdf.
[03.02.2026 17:23] Success.
[03.02.2026 17:23] Downloading and parsing paper https://huggingface.co/papers/2602.02437.
[03.02.2026 17:23] Downloading paper 2602.02437 from https://arxiv.org/pdf/2602.02437v1...
[03.02.2026 17:23] Extracting affiliations from text.
[03.02.2026 17:23] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"UniReason 1.0: Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing 6 2 0 2 2 ] . [ 1 7 3 4 2 0 . 2 0 6 2 : r Dianyi Wang1,2*, Chaofan Ma3*, Feng Han1,2, Size Wu4, Wei Song2,5, Yibin Wang1,2, Zhixiong Zhang2,3, Tianhang Wang2,5, Siyuan Wang6, Zhongyu Wei1,2, Jiaqi Wang2 1Fudan University, 2Shanghai Innovation Institute, 3Shanghai Jiao Tong University 4Nanyang Technological University, 5Zhejiang University, 6University of Southern California *Equal Contribution, Corresponding Authors "
[03.02.2026 17:23] Response: ```python
[
    "Fudan University",
    "Shanghai Innovation Institute",
    "Shanghai Jiao Tong University",
    "Nanyang Technological University",
    "Zhejiang University",
    "University of Southern California"
]
```
[03.02.2026 17:23] Deleting PDF ./assets/pdf/2602.02437.pdf.
[03.02.2026 17:23] Success.
[03.02.2026 17:23] Downloading and parsing paper https://huggingface.co/papers/2602.02053.
[03.02.2026 17:23] Downloading paper 2602.02053 from https://arxiv.org/pdf/2602.02053v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 3 5 0 2 0 . 2 0 6 2 : r WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora February 3, Pengyu Wang1, Benfeng Xu1,2, Licheng Zhang1, Shaohan Wang1, Mingxuan Du1, Chiwei Zhu1, Zhendong Mao1 1University of Science and Technology of China, Hefei, China 2Metastone Technology, Beijing, China {wangpengyu, benfeng, zlczlc}@mail.ustc.edu.cn, zdmao@ustc.edu.cn Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedias unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page: https://github.com/BstWPY/WildGraphBench. Retrieval-augmented generation (RAG) grounds LLM outputs by retrieving evidence from an external corpus(Lewis et al., 2021), but it may struggle when scattered evidence must be extracted from multiple documents"
[03.02.2026 17:24] Response: ```python
[
    "University of Science and Technology of China, Hefei, China",
    "Metastone Technology, Beijing, China"
]
```
[03.02.2026 17:24] Deleting PDF ./assets/pdf/2602.02053.pdf.
[03.02.2026 17:24] Success.
[03.02.2026 17:24] Downloading and parsing paper https://huggingface.co/papers/2602.01566.
[03.02.2026 17:24] Downloading paper 2602.01566 from https://arxiv.org/pdf/2602.01566v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 6 6 5 1 0 . 2 0 6 2 : r FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents February 3, Chiwei Zhu1,2, Benfeng Xu1,2, Mingxuan Du1, Shaohan Wang1 Xiaorui Wang2, Zhendong Mao1, Yongdong Zhang1 1University of Science and Technology of China 2Metastone Technology {tanz, benfeng}@mail.ustc.edu.cn Deep research is emerging as representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, file-system-based, dual-agent framework that scales deep research beyond the context window via persistent workspace. Specifically, Context Builder agent acts as librarian which browses the internet, writes structured notes, and archives raw sources into hierarchical knowledge base that can grow far beyond context length. Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as durable external memory and shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher. Deep Research has recently emerged as frontier and representative task for autonomous large language model (LLM) agents, demanding PhD-level expertise (OpenAI, 2025; Google, 2025). Given an open-ended resear"
[03.02.2026 17:24] Response: ```python
[
    "University of Science and Technology of China",
    "Metastone Technology"
]
```
[03.02.2026 17:24] Deleting PDF ./assets/pdf/2602.01566.pdf.
[03.02.2026 17:24] Success.
[03.02.2026 17:24] Downloading and parsing paper https://huggingface.co/papers/2602.02361.
[03.02.2026 17:24] Downloading paper 2602.02361 from https://arxiv.org/pdf/2602.02361v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 1 6 3 2 0 . 2 0 6 2 : r 2026-02-03 SWE-Universe: Scale Real-World Verifiable Environments to Millions Mouxiang Chen1,2, Lei Zhang1, Yunlong Feng1, Xuwu Wang1, Wenting Zhao1, Ruisheng Cao1, Jiaxi Yang1, Jiawei Chen1, Mingze Li1, Zeyao Ma1, Hao Ge1, Zongmeng Zhang1, Zeyu Cui1, Dayiheng Liu1, Jingren Zhou1, Jianling Sun2, Junyang Lin1, Binyuan Hui1 1Qwen Team, Alibaba Group, 2Zhejiang University chenmx@zju.edu.cn, junyang.ljy@alibaba-inc.com "
[03.02.2026 17:24] Response: ```python
["Alibaba Group", "Zhejiang University"]
```
[03.02.2026 17:24] Deleting PDF ./assets/pdf/2602.02361.pdf.
[03.02.2026 17:24] Success.
[03.02.2026 17:24] Downloading and parsing paper https://huggingface.co/papers/2602.01590.
[03.02.2026 17:24] Downloading paper 2602.01590 from https://arxiv.org/pdf/2602.01590v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 0 9 5 1 0 . 2 0 6 2 : r Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles February 3, Shaohan Wang1, Benfeng Xu1,2, Licheng Zhang1, Mingxuan Du1, Chiwei Zhu1, Xiaorui Wang2, Zhendong Mao1 and Yongdong Zhang1 1University of Science and Technology of China, Hefei, China 2Metastone Technology, Beijing, China {wsh2000, benfeng, zlczlc}@mail.ustc.edu.cn, zdmao@ustc.edu.cn Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedias strict standards for neutrality, comprehensiveness, and verifiability serve as great challenge for DRAs, with GAs representing the pinnacle of which. We curate dataset of 100 recent Good Articles and propose Wiki Eval, comprehensive evaluation framework comprising fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate significant gap between current DRAs and human expertlevel Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge With the explosive growth of Large Language Model (LLM) capabilities, LLM-driven agents have demonstrated remarkable potential in handling expert-level tasks (Achiam et al., 2023; Yang et al., 2025; Team et al., 2025a; Mialon et al., 2024). These"
[03.02.2026 17:24] Response: ```python
[
    "University of Science and Technology of China, Hefei, China",
    "Metastone Technology, Beijing, China"
]
```
[03.02.2026 17:24] Deleting PDF ./assets/pdf/2602.01590.pdf.
[03.02.2026 17:24] Success.
[03.02.2026 17:24] Downloading and parsing paper https://huggingface.co/papers/2602.02493.
[03.02.2026 17:24] Downloading paper 2602.02493 from https://arxiv.org/pdf/2602.02493v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 3 9 4 2 0 . 2 0 6 2 : r PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss Zehong Ma 1 Ruihan Xu 1 Shiliang Zhang 1 Project Page: https://zehong-ma.github.io/PixelGen "
[03.02.2026 17:24] Response: ```python
[]
```
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 3 9 4 2 0 . 2 0 6 2 : r PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss Zehong Ma 1 Ruihan Xu 1 Shiliang Zhang 1 Project Page: https://zehong-ma.github.io/PixelGenPixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/ Zehong-Ma/PixelGen. Figure 1. This work shows that pixel diffusion with perceptual loss outperforms latent diffusion. (a) traditional two-stage latent diffusion denoises in the latent space, which is influenced by the artifacts of the VAE. (b) PixelGen introduces perceptual loss to encourage the diffusion model to focus on the perceptual manifold, enabling the pixel diffusion to learn meaningful manifold rather than the complex full image manifold. (c) PixelGen outperforms the latent diffusion models using only 80 training epochs on ImageNet without CFG. 1. Introduction Diffusion models (Ho et al., 2020; Song et al., 2020; Dhariwal & Nichol, 2021) have achieved remarkable success in high-fidelity image generation, offering exceptional quality and diversity. Research in this field generally follows two main directions: latent diffusion and pixel diffusion. Latent diffusion models (Rombach et al., 2022; Peebles & Xie, 2023; Ma et al., 2024; Labs, 2024) split generation into two stages. As illustrated in Figure 1(a), VAE first compresses images into latent space, and diffusion model then performs denoising in that space. The performance of 1State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University. latent diffusion methods is largely constrained by the VAEs, where the reconstruction quality limits the upper bound of the generation quality. Furthermore, the learned latent distribution can significantly affect the convergence speed of diffusion training (Yao & Wang, 2025; Leng et al., 2025). These works have demonstrated that VAEs introduce lowlevel artifacts and representational bottlenecks of the latent diffusion model. Pixel diffusion models avoid these limitations by modeling raw pixels directly. This end-to-end pipeline removes the need for latent representations and eliminates VAE-induced artifacts. However, it is difficult for the diffusion model to 1 PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss no VAEs, and no auxiliary stages. We evaluate PixelGen on both class-to-image and text-toimage generation. PixelGen achieves leading FID score of 5.11 on ImageNet 256 without classifier-free guidance (CFG) using only 80 epochs. It outperforms the strong latent diffusion model REPA (Yu et al., 2024), which achieves an FID of 5.90 with 800 training epochs. Our pretrained text-to-image model also achieves an overall score of 0.79 on GenEval. These results show that pixel diffusion with perceptual loss has strong potential to outperform traditional two-stage latent diffusion method. In summary, our contributions are as follows: i) We propose PixelGen, simple end-to-end pixel diffusion framework with two complementary perceptual losses, simplifying the generative pipeline while improving performance. It requires no latent representations, no VAEs, and no auxiliary stages. ii) We demonstrate that pixel diffusion with perceptual losses can outperform the two-stage latent diffusion on ImageNet without CFG, highlighting pixel diffusion as simpler yet more powerful generative paradigm. 2. Related Work This work is closely related to latent diffusion, pixel diffusion, and perceptual supervision. This section briefly reviews recent works. Latent Diffusion. Latent diffusion trains diffusion models in compact latent space learned by VAE (Rombach et al., 2022). Compared to raw pixel space, the latent space significantly reduces spatial dimensionality, easing learning difficulty and computational cost (Rombach et al., 2022; Chen et al., 2024). Consequently, VAEs have become fundamental component in modern diffusion models (Peebles & Xie, 2023; Karras et al., 2024; Yue et al., 2024; Wang et al., 2024; Teng et al., 2024; Song et al., 2025; Gao et al., 2023b; Yao et al., 2024; Gao et al., 2023a). However, training VAEs often involves adversarial objectives, which complicate the overall pipeline (Wang et al., 2025a). Poorly trained VAEs can produce decoding artifacts (Zhou et al., 2024; Chen et al., 2025b) and introduce bottleneck, limiting the generalization quality of latent diffusion models. Early latent diffusion models mainly used U-Net-based architectures. The pioneering DiT (Peebles & Xie, 2023) introduced transformers into diffusion models, replacing the U-Net (Bao et al., 2023; Dhariwal & Nichol, 2021). SiT (Ma et al., 2024) further validated the DiT with linear flow diffusion. Subsequent works explore enhancing latent diffusion through representation alignment and joint optimization. REPA (Yu et al., 2024) and REG align intermediate features with pretrained DINOv2 (Oquab et al., 2023) model to learn better semantics. REG (Wu et al., 2025b) entangles latents with high-level class token from DINOv2 Figure 2. Illustration of different manifolds within the pixel space. The image manifold is large manifold containing both perceptually significant information and imperceptible signals. The perceptual manifold contains perceptually important signals, providing better target for pixel space diffusion. P-D"
[03.02.2026 17:24] Mistral response. {"id": "e554a2cadb6a45e69570959f72c48e44", "created": 1770139469, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1547, "total_tokens": 1569, "completion_tokens": 22, "num_cached_tokens": 1546}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University\"]\n```"}}]}
[03.02.2026 17:24] Response: ```python
["State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University"]
```
[03.02.2026 17:24] Deleting PDF ./assets/pdf/2602.02493.pdf.
[03.02.2026 17:24] Success.
[03.02.2026 17:24] Downloading and parsing paper https://huggingface.co/papers/2602.02383.
[03.02.2026 17:24] Downloading paper 2602.02383 from https://arxiv.org/pdf/2602.02383v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization Maksim Afanasyev * 1 Illarion Iov * 1 Abstract Direct preference optimization methods have emerged as computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) for aligning Large Language Models (LLMs). Latest approaches have streamlined the alignment process by deriving implicit reward functions, yet they often suffer from critical objective mismatch: optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen responses absolute likelihood. This can lead to unlearning, where the model degrades the probability of high-quality outputs to satisfy margin constraints, and formatting collapse caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to stateof-the-art baselines while maintaining higher generation stability. 6 2 0 2 2 ] . [ 1 3 8 3 2 0 . 2 0 6 2 : r 1. Introduction The alignment of Large Language Models (LLMs) with human intent is cornerstone of modern AI development. While Reinforcement Learning from Human Feedback (RLHF) via Proximal Policy Optimization (PPO) (Ouyang *Equal contribution 1Floating Point Sigma Lab. Correspondence to: Maksim Afanasyev <mr.applexz@gmail.com>, Illarion Iov <illariov1809@gmail.com>. Preprint. February 3, 2026. 1 et al., 2022) has been the standard for this task, it is notoriously unstable"
[03.02.2026 17:24] Response: ```python
["Floating Point Sigma Lab"]
```
[03.02.2026 17:24] Deleting PDF ./assets/pdf/2602.02383.pdf.
[03.02.2026 17:24] Success.
[03.02.2026 17:24] Downloading and parsing paper https://huggingface.co/papers/2602.02488.
[03.02.2026 17:24] Downloading paper 2602.02488 from https://arxiv.org/pdf/2602.02488v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 8 8 4 2 0 . 2 0 6 2 : r 2026-02RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System Yinjie Wang , Tianbao Xie , Ke Shen , Mengdi Wang (cid:0) , Ling Yang (cid:0) (cid:0) Corresponding author Code: https://github.com/Gen-Verse/Open-AgentRL Models: Policy & Reward We propose RLAnything, reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on Alf World and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Jointly optimizing the reward model and the 1. environment, in turn, benefits the policys learning curve, yielding higher converged accuracy. 2. Step-wise signals from optimized reward model outperform human-labeled outcome signals. Moreover, integrated feedback is vital for long-trajectory tasks. 3. We demonstrate effectiveness of RLAnything across diverse real-world applications, including computer control, coding, and text-based games. 4. New environment tasks scale linearly, and the reward model gets stronger at evaluating both current-step correctness and outcome influence. Figure 1 Summarized experimental resul"
[03.02.2026 17:24] Response: ```python
[]
```
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 8 8 4 2 0 . 2 0 6 2 : r 2026-02RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System Yinjie Wang , Tianbao Xie , Ke Shen , Mengdi Wang (cid:0) , Ling Yang (cid:0) (cid:0) Corresponding author Code: https://github.com/Gen-Verse/Open-AgentRL Models: Policy & Reward We propose RLAnything, reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on Alf World and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Jointly optimizing the reward model and the 1. environment, in turn, benefits the policys learning curve, yielding higher converged accuracy. 2. Step-wise signals from optimized reward model outperform human-labeled outcome signals. Moreover, integrated feedback is vital for long-trajectory tasks. 3. We demonstrate effectiveness of RLAnything across diverse real-world applications, including computer control, coding, and text-based games. 4. New environment tasks scale linearly, and the reward model gets stronger at evaluating both current-step correctness and outcome influence. Figure 1 Summarized experimental results and key insights from our RLAnything framework. Corresponding author(s): yangling0818@163.com RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System Figure 2 Motivation and takeaways of our RLAnything framework. First, in complex real-world applications, reinforcement learning benefits from integrating step-wise rewards with outcome rewards. Second, the reward model can be jointly optimized with the policy via outcome supervision and self-consistency signals. Third, we show that adapting environment task difficulty to the policys capability not only facilitates policy learning but also improves reward model training within our framework. Environment tasks leverage critic feedback from both the policy and the reward model to drive automatic, targeted adaptation, further enabling active learning from experience. 1. Introduction Reinforcement learning with verifiable rewards (RLVR) is an effective approach for improving the reasoning capabilities of large language models (Guo et al., 2025a; OpenAI, 2024; Shao et al., 2024). However, as real-world applications extend beyond single-turn question answering, especially when policies interact with environments iteratively over long trajectories, binary outcome rewards alone provide insufficient supervision (Lightman et al., 2023; Xi et al., 2025; Xiong et al., 2024). Step-wise signals are typically provided by generative reward models, which often outperform scalarbased models by leveraging the reasoning capabilities of language models (Liu et al., 2025; Zhang et al., 2024). However, training these models usually requires collecting high-quality, task-specific supervision (Xi et al., 2025; Zhang et al., 2025), motivating the need for more automated methods and scalable supervision. Beyond reward design, the quality of the environment is also vital for scaling reinforcement learning. Aligning task difficulty with models current capabilities is known to improve training dynamics (Yang et al., 2025; Yu et al., 2025). In RLVR, it has been shown that adapting task difficulty during optimization can improve policy training (Zeng et al., 2025). In real-world environments, such as computers for GUI agents (Wang et al., 2025a; Xie et al., 2024) or the physical world for robots (Kober et al., 2013), the scope of exploration is largely defined by the task. Moreover, scaling the environment by increasing task diversity can further promote policy generalization in broader scenarios (Cai et al., 2025; Chen et al., 2025; Cobbe et al., 2020; Fang et al., 2025; Song et al., 2026; Team et al., 2021). If there exists an RL system that jointly optimizes the environment, policy, and reward model to amplify learning signals and strengthen the overall system? In this work, we propose RLAnything, dynamic RL framework that forges the environment, policy, and reward model in closed-loop system, where each component continuously receives feedback from the others to amplify learning signals across various complex LLM or agentic scenarios. First, the policy is trained with integrated feedback that combines verifiable outcome rewards with step-wise signals provided by the reward model. Second, the reward model is jointly optimized via consistency feedback based on outcome and self-consistency, producing reliable step-wise supervision that in turn improves policy learning. Finally, motivated by our theoretical results, we show that balancing task difficulty benefits not only policy training but also reward model training in our RL 2 RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System system. Accordingly, we adapt environment tasks using critic feedback from both the policy and reward model, enabling precise and automatic task adjustment. In particular, we feed the reward models summarized information, which captures the policys failures, into language model to perturb the task, providing concrete guidance on how to modify it. To demonstrate the generality of our framework, we conduct empirical studies in three representative scenarios on computer use setting (Xie et al., 2024), text-based interactive games (Ct et al., 2018; Shridhar et al., 2020), and coding LLMs. We summarize our main contributions as follows: We propose RLAnything, fully dynamic RL system that forges the environment, policy, and reward model through closed-loop optimization to amplify learning signals and strengthen the overall system, guided by our theoretical in"
[03.02.2026 17:24] Mistral response. {"id": "6934a044c8574c7d985a6e34b9bf5827", "created": 1770139484, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1488, "total_tokens": 1494, "completion_tokens": 6, "num_cached_tokens": 1487}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[]\n```"}}]}
[03.02.2026 17:24] Response: ```python
[]
```
[03.02.2026 17:24] Deleting PDF ./assets/pdf/2602.02488.pdf.
[03.02.2026 17:24] Success.
[03.02.2026 17:24] Downloading and parsing paper https://huggingface.co/papers/2602.01624.
[03.02.2026 17:24] Downloading paper 2602.01624 from https://arxiv.org/pdf/2602.01624v1...
[03.02.2026 17:24] Extracting affiliations from text.
[03.02.2026 17:24] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards Minh-Quan Le * 1 2 Gaurav Mittal * 1 Cheng Zhao 1 David Gu 2 Dimitris Samaras 2 Mei Chen 1 6 2 0 2 2 ] . [ 1 4 2 6 1 0 . 2 0 6 2 : r Figure 1. (a) Baseline (T2V-Turbo-v2) defines rewards over pre-trained VLM text-video embeddings, which suffer from distributional misalignment. (b) PISCES T2V post-training addresses this by formulating reward supervision over an OT-aligned embedding space. We propose novel Dual OT-aligned Rewards module that aligns text embeddings to the video space, enabling effective visual and semantic alignment. (c) Compared to the baseline, PISCES improves visual quality (temporal coherence, photorealism) and semantic fidelity (object count, attributes) on both short-video (VideoCrafter2) and long-video (HunyuanVideo) generation. "
[03.02.2026 17:25] Response: ```python
[]
```
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards Minh-Quan Le * 1 2 Gaurav Mittal * 1 Cheng Zhao 1 David Gu 2 Dimitris Samaras 2 Mei Chen 1 6 2 0 2 2 ] . [ 1 4 2 6 1 0 . 2 0 6 2 : r Figure 1. (a) Baseline (T2V-Turbo-v2) defines rewards over pre-trained VLM text-video embeddings, which suffer from distributional misalignment. (b) PISCES T2V post-training addresses this by formulating reward supervision over an OT-aligned embedding space. We propose novel Dual OT-aligned Rewards module that aligns text embeddings to the video space, enabling effective visual and semantic alignment. (c) Compared to the baseline, PISCES improves visual quality (temporal coherence, photorealism) and semantic fidelity (object count, attributes) on both short-video (VideoCrafter2) and long-video (HunyuanVideo) generation.Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on largescale human preference annotations or operate on misaligned embeddings from pre-trained visionlanguage models, leading to limited scalability or suboptimal supervision. We present PISCES, an annotation-free post-training algorithm that ad- *Equal contribution. This work was done during Minh-Quans internship at Microsoft. 1Microsoft 2Stony Brook University . Preprint. February 3, 2026. 1 dresses these limitations via novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, PISCES uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) Discrete Token-level OTaligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, PISCES is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both shortand long-video generation show that PISCES outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with PISCES : Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning. 1. Introduction Text-to-video (T2V) generation (Kong et al., 2025; RunwayML, 2024) aims to synthesize videos from textual descriptions such that they appear realistic, temporally consistent, and accurately reflect the prompt. T2V has broad applications in multimedia content creation, robotics, and accessibility. While T2V performance is inherently subjective and judged by human preferences, recent benchmark (Huang et al., 2024) formalizes evaluation along two main dimensions Quality score, for the visual quality and temporal consistency; and Semantic score, factoring the correspondence of generated videos to text prompts. Rapid advances in diffusion and flow matching models (Podell et al., 2024; Esser et al., 2024) and VisionLanguage Models (VLMs) (Chung et al., 2023; Sun et al., 2024; GLM et al., 2024) have enabled the development of recent T2V models (Pika Labs, 2023; RunwayML, 2024; Chen et al., 2024; Kong et al., 2025). To further improve existing T2V models (Chen et al., 2024; Kong et al., 2025), particularly in terms of video-text misalignment in the denoisers, reward-based post-training (Li et al., 2025a; Liu et al., 2025b) has been introduced that provides additional supervision via specially designed rewards to the denoiser. Reward-based T2V post-training methods can be either Annotation-based or Annotation-free. Annotation-based approaches (Liu et al., 2025b; Yang et al., 2025; Wang et al., 2025b) collect large-scale human preference datasets, where annotators judge generated video pairs on quality and semantics, which are used to train reward model or via Direct Preference Optimization (DPO) (Rafailov et al., 2023; Wallace et al., 2024) for post-training. Although effective and serving as existing SoTA, these annotationbased methods cannot easily scale because they need highquality preference-based annotations. Another line of work explores Annotation-free rewards, where supervision is derived from pre-trained VLMs rather than human labels (Li et al., 2024; 2025a). While these approaches do not need large-scale human annotations, their performance is not on par with the Annotation-based techniques. We aim to achieve the best of both worlds by asking: Can an annotation-free T2V post-training method match, or even outperform, annotation-based approaches? From review of annotation-free approaches, we identify reliance on pre-trained visionlanguage models (VLMs) for reward supervision as key limitation. VLMs are trained with non-distributional objectives, such as pointwise matching (Chen et al., 2020) and contrastive learning (Radford et al., 2021), that may not adequately align text with the real-video distribution, consistent with the patterns in Table 4 and Figure 6. This results in both quality and semantic issues, as shown in Figure 1c, such as failure to ensure the correct number and attributes of objects (e.g., zebra and bear, wearing brown beret and glasses) or failing to capture motion descriptors (e.g., closed-mouth smile). We posit that, for annotation-free reward supervision to mimic human preferences, the real-video distribution must be better aligned with the text distribution, which represents the space of human instructions/preferences, without altering the video distributions semantic structure, and the derived rewards should reflect human judgments of textto-video outputs on the dual of quality and semantics. We introduce PISCES1, an annotation-free T2V post-training algorithm that includes novel Dual Optimal Transportaligned Rewards module (Figure 1b). Leveraging Optimal Transport (OT) (Villani, 2009; Cuturi, 2013), we tailor PISCES specifically for T2V post-training by enhancing text-video alignment at both the distribution and the token level to simultaneo"
[03.02.2026 17:25] Mistral response. {"id": "48fe557013ef44bda35f05548112c366", "created": 1770139500, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1573, "total_tokens": 1587, "completion_tokens": 14, "num_cached_tokens": 1572}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Microsoft\", \"Stony Brook University\"]\n```"}}]}
[03.02.2026 17:25] Response: ```python
["Microsoft", "Stony Brook University"]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.01624.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.01756.
[03.02.2026 17:25] Downloading paper 2602.01756 from https://arxiv.org/pdf/2602.01756v1...
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation Jun He * 1 Junyan Ye * 1 3 Zilong Huang 1 Dongzhi Jiang 4 Chenjue Zhang 2 Leqi Zhu 3 Renrui Zhang 4 Xiang Zhang 1 Weijia Li 1 2 https://github.com/PicoTrex/Mind-Brush Github: Dataset: https://huggingface.co/datasets/PicoTrex/Mind-Brush 6 2 0 2 2 ] . [ 1 6 5 7 1 0 . 2 0 6 2 : r Figure 1. We introduce Mind-Brush, an agentic framework that synergizes active search with explicit reasoning for image generation. By decomposing user intent, retrieving multimodal evidence, and inferring latent requirements, our agent effectively bridges the cognitive gaps and interpretative biases prevalent in existing models. Furthermore, we propose Mind-Bench, comprehensive benchmark designed to evaluate model performance on up-to-date long-tail concepts and multimodal reasoning tasks, thereby probing the boundaries of unified understanding and generation capabilities. "
[03.02.2026 17:25] Response: ```python
[]
```
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation Jun He * 1 Junyan Ye * 1 3 Zilong Huang 1 Dongzhi Jiang 4 Chenjue Zhang 2 Leqi Zhu 3 Renrui Zhang 4 Xiang Zhang 1 Weijia Li 1 2 https://github.com/PicoTrex/Mind-Brush Github: Dataset: https://huggingface.co/datasets/PicoTrex/Mind-Brush 6 2 0 2 2 ] . [ 1 6 5 7 1 0 . 2 0 6 2 : r Figure 1. We introduce Mind-Brush, an agentic framework that synergizes active search with explicit reasoning for image generation. By decomposing user intent, retrieving multimodal evidence, and inferring latent requirements, our agent effectively bridges the cognitive gaps and interpretative biases prevalent in existing models. Furthermore, we propose Mind-Bench, comprehensive benchmark designed to evaluate model performance on up-to-date long-tail concepts and multimodal reasoning tasks, thereby probing the boundaries of unified understanding and generation capabilities.While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-topixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge *Jun He and Junyan Ye contribute equally to this work. 1Sun Yat-sen University 2Tsinghua Shenzhen International Graduate School, Tsinghua University 3Shanghai Artificial Intelligence Laboratory 4MMLab, The Chinese University of Hong Kong. Correspondence to: Weijia Li <liweij29@mail.sysu.edu.cn>. Preprint. February 3, 2026. reasoning within single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, unified agentic framework that transforms generation into dynamic, knowledgedriven workflow. Simulating human-like thinkresearch-create paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-ofdistribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive exMind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation periments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE. 1. Introduction Recent advancements in image generation have democratized visual creation, enabling the seamless translation of imagination into high-fidelity imagery (Rombach et al., 2022; Esser et al., 2024; Gong et al., 2025). However, fundamentally, the vast majority of existing models function primarily as static text-to-pixel decoders (Podell et al., 2023; Cai et al., 2025). Confined to mapping explicit user instructions to pixels, these models often fail to grasp implicit, high-level user intentions, thereby diverging significantly from the human artistic creation process. While emerging unified multimodal understanding-generation models, such as GPT-Image (OpenAI, 2024) and Bagel (Deng et al., 2025), demonstrate promising capabilities in comprehending user intent and incorporating world knowledge, their performance remains constrained in tasks demanding complex mathematical or knowledge-intensive reasoning. This limitation suggests that monolithic architectures may struggle to encompass the full spectrum of capabilities required for such intricate, end-to-end tasks. Moreover, constrained by the temporal knowledge cutoff inherent in pre-training data, the cognitive boundaries of current image generation models remain static. Consequently, they struggle to adapt to the evolving dynamics of the real world, resulting in significant capability gaps when handling real-time news or novel IP concepts (Son et al., 2025; Li et al., 2025a). In the realm of Large Language Models (LLMs), researchers have successfully transcended these boundaries by integrating retrieval capabilities through agentic designs (Chen et al., 2024; Yu et al., 2024), as exemplified by Search-o1 (Li et al., 2025c). While recent proprietary models such as Nano Banana Pro (Comanici et al., 2025) and FLUX-2 Max (Black Forest Labs, 2026b) have demonstrated integrated search and reasoning capabilities, significant gap persists within the open-source community. Specifically, there is notable absence of open-source models capable of interacting with the open world, performing complex reasoning, and executing active planning. Recently, agentic approaches for image generation have emerged (Jiang et al., 2026), such as T2I-Copilot (Chen et al., 2025a) and PromptSculptor (Xiang et al., 2025), which focus on elaborating concise instructions into detailrich descriptions. Think-Then-Gen (Kou et al., 2026) advances this further by leveraging LLMs to decompose user queries into sequential drawing steps. Nevertheless, these efforts remain largely confined to standard T2I benchmarks like GenEval++ (Ye et al., 2025a), prioritizing prompt refinement over intricate cognitive tasks such as mathematical derivation or commonsense reasoning. Crucially, due to the absence of external tools, their reasoning relies solely on internalized knowledge. Consequently, these methods falter when tasks demand factual verification of real-time events or evolving contexts. To bridge this gap, we introduce Mind-Brush, unified agentic framework that shifts image generation from static mapping paradigm to dynamic, knowledge-driven workflow. Rather than treating generation as single-step inference, Mind-Brush orchestrates cognitive process: it actively retrieves multimodal evidence to ground out-ofdistribution concepts and employs logical reasoning to deduce implicit visual constraints, thereby realizing the unification of agentic understanding and generation. By effectively simulating the human artists Think-Research-Create workflow, Mind-Brush enables high-fidelity generation requiring real-time knowledge and handles tasks involving complex reasoning. Furthermore, existing image generation benchmarks, such as GenEval (Ghosh et al., 2023) and ImgEdit (Ye et al., 20"
[03.02.2026 17:25] Mistral response. {"id": "150e092e00484ab09f6d5329ecef7e7d", "created": 1770139506, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1456, "total_tokens": 1510, "completion_tokens": 54, "num_cached_tokens": 1455}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Sun Yat-sen University\",\n    \"Tsinghua Shenzhen International Graduate School, Tsinghua University\",\n    \"Shanghai Artificial Intelligence Laboratory\",\n    \"MMLab, The Chinese University of Hong Kong\"\n]\n```"}}]}
[03.02.2026 17:25] Response: ```python
[
    "Sun Yat-sen University",
    "Tsinghua Shenzhen International Graduate School, Tsinghua University",
    "Shanghai Artificial Intelligence Laboratory",
    "MMLab, The Chinese University of Hong Kong"
]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.01756.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.02214.
[03.02.2026 17:25] Downloading paper 2602.02214 from https://arxiv.org/pdf/2602.02214v1...
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation Hongzhou Zhu * 1 2 Min Zhao * 1 2 Guande He 3 Hang Su 1 Chongxuan Li 4 5 6 Jun Zhu 1 2 7 6 2 0 2 2 ] . [ 1 4 1 2 2 0 . 2 0 6 2 : r a "
[03.02.2026 17:25] Response: ```python
[]
```
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation Hongzhou Zhu * 1 2 Min Zhao * 1 2 Guande He 3 Hang Su 1 Chongxuan Li 4 5 6 Jun Zhu 1 2 7 6 2 0 2 2 ] . [ 1 4 1 2 2 0 . 2 0 6 2 : r aTo achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires framelevel injectivity, where each noisy frame must map to unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from bidirectional teacher violates this condition, preventing recovery of the teachers flow map and instead inducing conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3% in Dynamic Degree, 8.7% in VisionReward, and 16.7% in Instruction Following. Project page and the code: https://thuml.github.io/CausalForcing.github.io/ 1. Introduction Recent years have witnessed rapid progress in autoregressive (AR) video diffusion models (Jin et al., 2024; Teng et al., 2025; Chen et al., 2025; Wu et al., 2025). By adopting frame-level autoregressive formulation with diffusion 1Dept. of Comp. *Equal contribution Sci. & Tech., BNRist Center, THU-Bosch ML Center, Tsinghua University. 2ShengShu. 3The University of Texas at Austin. 4Gaoling School of Artificial Intelligence Renmin University of China Beijing, China. 5Beijing Key Laboratory of Research on Large Models 6Engineering Research Center of and Intelligent Governance. Next-Generation Intelligent Search and Recommendation, MOE. 7Pazhou Laboratory (Huangpu). Correspondence to: Jun Zhu <dcszj@tsinghua.edu.cn>. Preprint. February 3, 2026. 1 within each frame, AR video diffusion enables wide range of real-time and interactive applications, including world modeling (Mao et al., 2025; Sun et al., 2025a; Hong et al., 2025), game simulation (Ball et al., 2025; Tang et al., 2025), embodied intelligence (Feng et al., 2025), and interactive content creation (Shin et al., 2025; Huang et al., 2025b; Ki et al., 2026; Xiao et al., 2025). Despite their promise, the computational burden of multi-step diffusion sampling severely limits their real-time capabilities. To alleviate this latency bottleneck, recent works (Huang et al., 2025a; Yin et al., 2025) distill powerful pretrained bidirectional video diffusion model into few-step autoregressive student model. This is typically achieved via twostage pipeline: an initial ODE distillation to initialize the AR student, followed by DMD (Yin et al., 2024) to further boost performance. However, compared to standard stepdistillation, such AR distillation faces more fundamental challenge beyond the shared sampling-step gap, namely, the architectural gap. This gap arises from converting bidirectional model, which has access to future frames, into causal architecture that conditions solely on past context. Empirically, we find that even when distilled from the same bidirectional teacher, SOTA AR distillation methods (Huang et al., 2025a) still lag significantly behind standard DMD, which distills bidirectional student (see Fig. 1). In this paper, we show that the performance degradation stems from the failure of existing methods to properly address the architectural gap theoretically (see Fig. 3 and Sec. 3.2 ). Through controlled experiment, we first show that this gap cannot be resolved by the DMD stage and should instead be addressed during the preceding ODE initialization. Crucially, key requirement for ODE distillation is injectivity (Liu et al., 2022). In standard ODE distillation that distills bidirectional teacher into bidirectional student, injectivity naturally holds at the video level. In contrast, for an AR student, injectivity must hold at the frame level: each noisy frame must map to unique clean frame under the PF-ODE of the AR teacher. We refer to this requirement as frame-level injectivity. However, existing methods (Huang et al., 2025a; Yin et al., 2025) distill an AR student directly from bidirectional teacher, allowing the same noisy frame to correspond to multiple different clean Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation Figure 1. Limitations of existing methods. While distilling from the same bidirectional base model, SOTA autoregressive diffusion distillation methods like Self-Forcing still lag significantly behind standard DMD, which distills bidirectional student. frames. This violation of frame-level injectivity results in blurred and inconsistent video generation. Building on the above analysis, we propose Causal Forcing, which bridges the architectural gap by performing ODE distillation initialization with an AR teacher (see Sec. 3.3). We first train an AR diffusion model using teacher forcing, where we show that diffusion forcing is inferior to teacher forcing for AR diffusion training both theoretically and empirically. With this AR diffusion model as the teacher, we then perform causal ODE distillation by sampling its PFODE trajectories and training the AR student accordingly. Crucially, since the teacher is autoregressive rather than bidirectional, its PF-ODE naturally satisfies frame-level injectivity, enabling the student to accurately learn the flow map. Finally, following Self Forcing, we apply subsequent DMD stage to obtain few-step AR student, enabling efficient real-time video generation. To validate our approach, we conduct comprehensive evaluations against various baseline models (Wan et al., 2025; HaCohen et al., 2024; Deng et al., 2024; Jin et al., 2024; Chen et al., 2025; Teng et al., 2025; Yin et al., 2025; Huang et al., 2025a). Experiments show that our method consistently outperforms all baselines across all metrics, with significant gains in dynamic degree, visual quality, and instructionfollowing capability. Remarkably, under the same training budget as existing distilled autoregressive video models, it surpasses the SOTA Self-Forcing (Huang et al., 2025a) baseline b"
[03.02.2026 17:25] Mistral response. {"id": "14900dea034b46ba9a5b092c89d0de53", "created": 1770139513, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1586, "total_tokens": 1705, "completion_tokens": 119, "num_cached_tokens": 1585}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Dept. of Comp. Sci. & Tech., BNRist Center, THU-Bosch ML Center, Tsinghua University\",\n    \"ShengShu\",\n    \"The University of Texas at Austin\",\n    \"Gaoling School of Artificial Intelligence Renmin University of China Beijing, China\",\n    \"Beijing Key Laboratory of Research on Large Models and Intelligent Governance\",\n    \"Engineering Research Center of Next-Generation Intelligent Search and Recommendation, MOE\",\n    \"Pazhou Laboratory (Huangpu)\"\n]\n```"}}]}
[03.02.2026 17:25] Response: ```python
[
    "Dept. of Comp. Sci. & Tech., BNRist Center, THU-Bosch ML Center, Tsinghua University",
    "ShengShu",
    "The University of Texas at Austin",
    "Gaoling School of Artificial Intelligence Renmin University of China Beijing, China",
    "Beijing Key Laboratory of Research on Large Models and Intelligent Governance",
    "Engineering Research Center of Next-Generation Intelligent Search and Recommendation, MOE",
    "Pazhou Laboratory (Huangpu)"
]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.02214.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.01801.
[03.02.2026 17:25] Downloading paper 2602.01801 from https://arxiv.org/pdf/2602.01801v1...
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Dvir Samuel 1 2 Issar Tzachor 1 Matan Levy 3 Micahel Green 1 Gal Chechik 2 4 Rami Ben-Ari "
[03.02.2026 17:25] Response: ```python
[]
```
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Dvir Samuel 1 2 Issar Tzachor 1 Matan Levy 3 Micahel Green 1 Gal Chechik 2 4 Rami Ben-Ari1. Introduction 6 2 0 2 2 ] . [ 1 1 0 8 1 0 . 2 0 6 2 : r Autoregressive video diffusion models enable streaming generation, opening the door to longform synthesis, video world models, and interactive neural game engines. However, their core attention layers become major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only small subset of tokens matters per frame. Building on these observations, we propose unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to 510 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage. Project Page 1OriginAI, Tel-Aviv, Israel 2Bar-Ilan University, Ramat-Gan, Israel 3The Hebrew University of Jerusalem, Jerusalem, Israel 4NVIDIA, Tel-Aviv, Israel. Correspondence to: Dvir Samuel <dvirsamuel@gmail.com>. Preprint. 1 Video diffusion models (HaCohen et al., 2024; Wang et al., 2025; Kong et al., 2024) have achieved strong results in offline video synthesis, where all frames in short clip are generated jointly, producing high visual fidelity and temporally coherent motion. Recently, autoregressive video diffusion models (Yin et al., 2025; Huang et al., 2025) have emerged to enable streaming generation: frames are produced sequentially in an online manner and can be consumed immediately. This transition from offline to online generation unlocks new applications, including long-form video generation (Liu et al., 2025b), controlled video world models (Agarwal et al., 2025; Gao et al., 2025), and neural game engines (Gao et al., 2025; HunyuanWorld, 2025). Despite these new capabilities, autoregressive video diffusion models expose critical bottleneck in their attention mechanisms, leading to two fundamental challenges: (a) Generation speed. 3D spatio-temporal attention scales with the number of cached keys. As the KV cache grows with each generated frame, the per-step attention cost (and thus latency) increases over time, making long or unbounded generation progressively slower. (b) Memory efficiency. The expanding KV cache also creates substantial memory overhead, limiting how much temporal context can fit on GPU. This often forces short context windows (Liu et al., 2025b), which in turn harms long-range temporal consistency. Despite KV-cache efficiency being central to autoregressive video generation, it remains relatively underexplored: KVcache compression techniques from NLP (for LLMs) can not be applied directly (Anonymous, 2026), and recent methods (Liu et al., 2025a; Anonymous, 2026) offer only modest speedups, sometimes with quality degradation. In parallel, most progress on accelerating 3D spatio-temporal attention targets offline video diffusion (Xi et al., 2025; Yang et al., 2025; Li* et al., 2025). Yet these gains do not reliably transfer to online autoregressive models, where the same methods frequently degrade quality and deliver limited, or even negative, speedups due to unfavorable memory and cache behavior. Following this, we therefore analyze whether autoregressive video diffusion contains exploitable redundancy, and find three consistent sources that are not directly addressed by existing sparse attention designs: (i) many Figure 1. Our method substantially accelerates pre-trained autoregressive video diffusion models and autoregressive world models while maintaining high visual quality, by introducing new KV-cache compression with selfand cross-attention sparsification. On single H100 GPU, it achieves 510 speedups for multi-minute video generation, without further training/optimization, and keeps peak GPU memory nearly constant over long rollouts. cached keys are near-duplicates across frames, enabling aggressive KV merging; (ii) and evolve slowly and are largely semantic, making many querykey dot products (attention score computations) redundant; and (iii) crossattention wastes compute on long prompts although only few tokens matter per frame. Motivated by these observations, we introduce unified attention framework: TempCache compresses the KV cache using temporal correspondence; AnnCA prunes prompt tokens per frame, in cross-attention layers, using fast Approximate Nearest Neighbors (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using lightweight ANN. To the best of our knowledge, this is the first use of ANN-based attention in autoregressive diffusion models in fully training-free manner, requiring no retraining or fine-tuning. Experiments on autoregressive video diffusion and video world models show that our approach yields up to 510 end-to-end speedup (Figure 1), while maintaining nearly constant GPU memory over long rollouts, whereas baselines accumulate cache with increasing memory, and degrade video quality. 2. Related Work Autoregressive video diffusion models and video world models. Modern video diffusion (Wang et al., 2025; HunyuanWorld, 2025; HaCohen et al., 2024) models often adopt diffusion transformers (DiTs), which scale well but make video generation expensive due to long spatiotemporal token sequences and repeated denoising steps. To extend diffusion to long horizons, recent work (Yin et al., 2025; Huang et al., 2025) studies autoregressive (chunked) video diffusion, repeatedly denoising the ne"
[03.02.2026 17:25] Mistral response. {"id": "cd4fedd6f2a94092b79c3f5d5f01d307", "created": 1770139520, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1486, "total_tokens": 1543, "completion_tokens": 57, "num_cached_tokens": 1485}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"OriginAI, Tel-Aviv, Israel\",\n    \"Bar-Ilan University, Ramat-Gan, Israel\",\n    \"The Hebrew University of Jerusalem, Jerusalem, Israel\",\n    \"NVIDIA, Tel-Aviv, Israel\"\n]\n```"}}]}
[03.02.2026 17:25] Response: ```python
[
    "OriginAI, Tel-Aviv, Israel",
    "Bar-Ilan University, Ramat-Gan, Israel",
    "The Hebrew University of Jerusalem, Jerusalem, Israel",
    "NVIDIA, Tel-Aviv, Israel"
]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.01801.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.02092.
[03.02.2026 17:25] Downloading paper 2602.02092 from https://arxiv.org/pdf/2602.02092v1...
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"FSVideo: Fast Speed Video Diffusion Model in Highly-Compressed Latent Space Intelligent Creation, ByteDance "
[03.02.2026 17:25] Response: ```python
["ByteDance"]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.02092.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.01395.
[03.02.2026 17:25] Downloading paper 2602.01395 from https://arxiv.org/pdf/2602.01395v1...
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Almog Tavor 1 Itay Ebenspanger 1 * Neil Cnaan 1 * Mor Geva 1 6 2 0 2 1 ] . [ 1 5 9 3 1 0 . 2 0 6 2 : r Abstract Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SEKD). Across suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance. 1. Introduction Large language models (LLMs) achieve state-of-the-art results across diverse tasks, but their size makes them expensive to serve and difficult to adapt. Knowledge distillation (KD; Hinton et al., 2015) addresses this by training smaller student model to imitate larger teacher. For autoregressive LLMs, this is typically done by matching the teachers nexttoken distribution at every position of the training sequence. However, applying knowledge distillation at every token position is often suboptimal due to the uniform supervision across all positions. Recent studies demonstrate that *Equal contribution 1Blavatnik School of Computer Science and AI, Tel Aviv University. Correspondence to: Almog Tavor <almogt@mail.tau.ac.i"
[03.02.2026 17:25] Response: ```python
["Blavatnik School of Computer Science and AI, Tel Aviv University"]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.01395.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.01541.
[03.02.2026 17:25] Downloading paper 2602.01541 from https://arxiv.org/pdf/2602.01541v1...
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 1 4 5 1 0 . 2 0 6 2 : r a Boyi Li1,, Yifan Shen1,,, Yuanzhe Liu1,, Yifan Xu1, Jiateng Liu1, Xinzhuo Li1, Zhengyuan Li1, Jingyuan Zhu2, Yunhan Zhong1, Fangzhou Lan2, Jianguo Cao2, James M. Rehg1, Heng Ji1, Ismini Lourentzou1,, Xu Cao1,2, 1University of Illinois Urbana-Champaign, 2PediaMed AI Equal contribution, Project lead, Corresponding author Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weight"
[03.02.2026 17:25] Response: ```python
[
    "University of Illinois Urbana-Champaign",
    "PediaMed AI"
]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.01541.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.01058.
[03.02.2026 17:25] Downloading paper 2602.01058 from https://arxiv.org/pdf/2602.01058v1...
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning Dylan Zhang 1 Yufeng (Felix) Xu 1 2 Haojin Wang 1 Qingzhi Chen 1 Hao Peng "
[03.02.2026 17:25] Response: ```python
[]
```
[03.02.2026 17:25] Extracting affiliations from text.
[03.02.2026 17:25] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning Dylan Zhang 1 Yufeng (Felix) Xu 1 2 Haojin Wang 1 Qingzhi Chen 1 Hao Peng1. Introduction 6 2 0 2 1 ] . [ 1 8 5 0 1 0 . 2 0 6 2 : r Post-training of reasoning LLMs is holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone. We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to mismatch typical in current SFTRL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts. We propose PEAR (Policy Evaluationinspired Algorithm for Offline Learning Loss Reweighting), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected. We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen2.5/3 and DeepSeek-distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass@8 gains up to 14.6% on AIME-2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation. 1University of Illinois Urbana-Champaign 2New York University (Shanghai). Work done during internship at UIUC. Correspondence to: Dylan Zhang <shizhuo2@illinois.edu>, Hao Peng <haopeng@illinois.edu>. Preprint. February 3, 2026. 1 Post-training of reasoning language models typically follows two-stage paradigm: an offline supervised fine-tuning (SFT) phase produces an initial checkpoint, which is then used to initialize an online reinforcement learning (RL) phase that further enhances the model (Shao et al., 2024; Guo et al., 2025; Yang et al., 2024). Both areas have become active research fronts. In particular, growing body of work has proposed offline learning objectives to improve SFT, often by reweighting or regularizing next-token likelihood (Qin & Springenberg, 2025; Zhu et al., 2025d; Wu et al., 2025; Lin et al., 2025; Li et al., 2025a). From practical perspective, the performance of interest is usually the models final accuracy after completing both SFT and downstream RL. However, it is common that these existing techniques optimize for SFT-stage performance in isolation, often with the implicit assumption that gains in offline performance will translate to improved performance after RL. Kang et al. (2025) show that repetition and data homogeneity boost SFT but may reduce RL headroom. This motivates us to investigate if offline gains of an objective could also be misleading proxy for its effectiveness as an RL initialization. We empirically show the gains of stronger offline checkpoint over weaker one can shrink, disappear, or even reverse after both undergo identical RL training. Therefore, optimizing for offline performance alone may be counterproductive when the goal is strong final performance after RL (Fig. 1 in 2). We contend that the goal of an offline stage is not merely strong offline accuracy, but an initialization that facilitates improvement under the online RL. This requires addressing distribution mismatch between offline and online stages: Typically, during SFT, the model learns from data sampled from different distribution, often dubbed the behavior policy (Sutton & Barto, 2018; Precup et al., 2000; Uehara et al., 2022). In contrast, during online RL, the target of learning (thereby the target policy), learns from roll-outs generated by itself. There is clear distribution mismatch that needs to be corrected between them (Zhao et al., 2022; Lee et al., 2021; Zu et al., 2025) in order for an effective offline-to-online transition. It is therefore crucial to quantify and correct this distribution mismatch. Inspired by off-policy evaluation (OPE) (Precup Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning Figure 1. Offline v.s. Online pass@1 on SynLogic Games on total of 19 Models. It exhibits significant ranking changes indicating offline performance will not entail online performance. In addtion, our proposed approach remains the most effective initialization for online RL. et al., 2000; Thomas & Brunskill, 2016; Jiang & Li, 2016; Levine et al., 2020), we address this by reweighting offline data using importance weights, i.e., the likelihood ratio between the target policy and the behavior policy (3). Intuitively, this reweighting scales each tokens loss according to how likely the target policy would generate the same continuation relative to the behavior policy, so that offline training better reflects the trajectories that online RL will actually revisit. We present sequence-level (Rowland et al., 2020) and token-wise reweighting based on suffix-ratios (Precup et al., 2000). We also present variants that improve stability by block-wise weighing and leveraging negative data. We evaluate PEAR and its variants on reasoning games and math benchmarks across 6 different models of various sizes: Qwen3-Base-0.6B; 1.7B; 4B and 8B (Yang et al., 2025), Qwen2.5-1.5B-Math (Yang et al., 2024) and DeepSeekDistill-Qwen-1.5B (Guo et al., 2025). Using an SFTRL pipeline that varies only the SFT-stage objectives, PEAR and its variants consistently improve post-RL performance over strong baselines. Comparing checkpoints finetuned from Qwen3-1.7B-Base using PEAR versus canonical SFT on the same data, the former outperform the latter by by 40% absolute accuracy on logic games, and achieve 14% Pass@8 gain on AIME-25 (Balunovic et al., 2026) (See 4.3). Moreover, our analysis shows that PEAR-initialized models undergo less parameter drift during RL 4.6. 2. Offline Performance May Not Entail Online There are various techniques to improve supervised finetuning (SFT) for reasoning, typically targeting stronger offline performance or reduced forgetting. Recent reasoning LM post-training pipeline typically applies an online RL stage to further improve performance after SFT (Shao et al"
[03.02.2026 17:25] Mistral response. {"id": "5f514132d9c848eb87050fbf6241cf01", "created": 1770139557, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1610, "total_tokens": 1633, "completion_tokens": 23, "num_cached_tokens": 1609}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"University of Illinois Urbana-Champaign\", \"New York University (Shanghai)\"]\n```"}}]}
[03.02.2026 17:25] Response: ```python
["University of Illinois Urbana-Champaign", "New York University (Shanghai)"]
```
[03.02.2026 17:25] Deleting PDF ./assets/pdf/2602.01058.pdf.
[03.02.2026 17:25] Success.
[03.02.2026 17:25] Downloading and parsing paper https://huggingface.co/papers/2602.01851.
[03.02.2026 17:25] Downloading paper 2602.01851 from https://arxiv.org/pdf/2602.01851v1...
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"How Well Do Models Follow Visual Instructions? VIBE: Systematic Benchmark for Visual Instruction-Driven Image Editing Huanyu Zhang * 1 2 Xuehai Bai * 3 Chengzu Li * 4 Chen Liang 2 Haochen Tian 1 2 Haodong Li 5 Ruichuan An 6 Yifan Zhang 1 2 Anna Korhonen 4 Zhang Zhang 1 2 Liang Wang 1 2 Tieniu Tan 7 https://vibe-benchmark.github.io/ 6 2 0 2 2 ] . [ 1 1 5 8 1 0 . 2 0 6 2 : r Abstract Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose robust LMM-asa-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform opensource models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research. 1. Introduction Recent advances in generative models have demonstrated impressive capabilities in image editing (Google, 2025b; Seedream et al., 2025). However, most existing systems *Equal contribution 1School of Artificial Intelligence, University of Chinese Academy of Science 2Institute of Automation, Chinese Academy of Sciences 3Hangzhou Dianzi University 4Language Technology Lab, University of Cambridge 5Sou"
[03.02.2026 17:26] Response: ```python
[
    "School of Artificial Intelligence, University of Chinese Academy of Science",
    "Institute of Automation, Chinese Academy of Sciences",
    "Hangzhou Dianzi University",
    "Language Technology Lab, University of Cambridge"
]
```
[03.02.2026 17:26] Deleting PDF ./assets/pdf/2602.01851.pdf.
[03.02.2026 17:26] Success.
[03.02.2026 17:26] Downloading and parsing paper https://huggingface.co/papers/2602.01538.
[03.02.2026 17:26] Downloading paper 2602.01538 from https://arxiv.org/pdf/2602.01538v1...
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars Youliang Zhang1,2 Zhengguang Zhou2 Zhentao Yu2 Teng Hu2 Yi Chen2 Sen Liang2 Zixiang Zhou Guozhen Zhang2 Yuan Zhou2 Ziqiao Peng2 Qinglin Lu2 Ziyao Huang 2 Shunkai Li2 Xiu Li1 6 2 0 2 2 ] . [ 1 8 3 5 1 0 . 2 0 6 2 : r 1Tsinghua University. 2Tencent HY. Figure 1. Input text, audio, and reference image, our method can generate human videos that can talk, act, and interact with objects. Grounded means that all action and object interaction occurs within the environment provided by the reference image. "
[03.02.2026 17:26] Response: ```python
['Tsinghua University', 'Tencent HY']
```
[03.02.2026 17:26] Deleting PDF ./assets/pdf/2602.01538.pdf.
[03.02.2026 17:26] Success.
[03.02.2026 17:26] Downloading and parsing paper https://huggingface.co/papers/2602.01335.
[03.02.2026 17:26] Downloading paper 2602.01335 from https://arxiv.org/pdf/2602.01335v1...
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning Yu Xu1,2* Yuxin Zhang1* Chunyu Wang2 Oliver Deussen3 1University of Chinese Academy of Sciences Juan Cao1 Tong-Yee Lee4 Fan Tang1 2Tencent Hunyuan Lin Gao1 3University of Konstanz 4National Cheng-Kung University 6 2 0 2 1 ] . [ 1 5 3 3 1 0 . 2 0 6 2 : r Figure 1. Diverse image metaphor transfer results generated by our framework. For each pair, the left image serves as the Reference and the right is the Generated Result. Our model demonstrates robust capability across distinct cognitive levels. "
[03.02.2026 17:26] Response: ```python
[
    "University of Chinese Academy of Sciences",
    "Tencent Hunyuan",
    "University of Konstanz",
    "National Cheng-Kung University"
]
```
[03.02.2026 17:26] Deleting PDF ./assets/pdf/2602.01335.pdf.
[03.02.2026 17:26] Success.
[03.02.2026 17:26] Downloading and parsing paper https://huggingface.co/papers/2602.02486.
[03.02.2026 17:26] Downloading paper 2602.02486 from https://arxiv.org/pdf/2602.02486v1...
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents Jialiang Zhu* 1 Gongrui Zhang* 1 Xiaolong Ma* 2 Lin Xu* 3 Miaosen Zhang 1 Ruiqi Yang 4 Song Wang 5 Kai Qiu* 6 Zhirong Wu* 6 Qi Dai 6 Ruichun Ma 6 Bei Liu 6 Yifan Yang 6 Chong Luo 6 Zhengyuan Yang 6 Linjie Li 6 Lijuan Wang 6 Weizhu Chen 6 Xin Geng 1 Baining Guo 6 6 2 0 2 2 ] . [ 1 6 8 4 2 0 . 2 0 6 2 : r a "
[03.02.2026 17:26] Response: ```python
[]
```
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents Jialiang Zhu* 1 Gongrui Zhang* 1 Xiaolong Ma* 2 Lin Xu* 3 Miaosen Zhang 1 Ruiqi Yang 4 Song Wang 5 Kai Qiu* 6 Zhirong Wu* 6 Qi Dai 6 Ruichun Ma 6 Bei Liu 6 Yifan Yang 6 Chong Luo 6 Zhengyuan Yang 6 Linjie Li 6 Lijuan Wang 6 Weizhu Chen 6 Xin Geng 1 Baining Guo 6 6 2 0 2 2 ] . [ 1 6 8 4 2 0 . 2 0 6 2 : r aLLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 1520% on BrowseComp with frontier LLMs. For smaller models, we introduce ReTRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search. Code and models are available at GitHub link. 1. Introduction Large language models (LLMs) have progressed from single-turn question answering to chain-of-thought reasoning (Wei et al., 2022), function calling (Schick et al., 2023), and complex multi-turn agentic applications (Anthropic, the internship *Equal Core Contributors This work was done dur1Southeast University ing 2Waseda University 3Tsinghua University 4Brown University 5Zhejiang University 6Microsoft. Correspondence Kai Qiu <Kai.Qiu@microsoft.com>, Zhirong Wu to: <Wu.Zhirong@microsoft.com>. at MSRA Preprint. February 3, 2026. 1 2025). This evolution reflects shift from passive response generation toward autonomous, goal-directed problem solving in open environments. deep research agent (OpenAI, 2025a; Google, 2025), capable of autonomously searching the open web and gathering and analyzing information from thousands of web pages, represents the next frontier of information retrieval for general intelligence. Most existing deep research agents are built upon the ReAct paradigm (Yao et al., 2022), which interleaves large language model (LLM) reasoning steps with tool invocation, appending both into the model context in linear sequential manner. In this work, we provide an in-depth analysis of the inherent limitations of ReAct-style linear reasoning workflows. Although LLM reasoning can be trained to support behaviors such as backtracking and self-reflection (Guo et al., 2025), this strictly linear agentic workflow is not well suited for open-ended tasks that require broad exploratory investigation. Revisiting earlier reasoning states and branching into alternative search trajectories remains challenging, particularly under long-context settings (e.g., 128K256K tokens), where context management and credit assignment become increasingly difficult. Consequently, the ReAct framework is susceptible to issues such as local optima, redundant exploration, and inefficient search dynamics (Yao et al., 2023). To empower LLM-based agents with diverse exploration capabilities, we propose to explicitly guide agents toward search trajectories that have not been previously explored. This direction is motivated by two key observations. First, existing deep research models (even after extensive reinforcement learning post-training) exhibit substantially higher pass@k performance than pass@1. This gap indicates that repeated inference induces diverse reasoning trajectories, suggesting that model limitations often stem from insufficient exploration within single trajectory rather than inadequate reasoning capacity. Second, prior work shows that LLMs are generally better at verifying candidate solutions than generating them from scratch (Weng et al., 2023; Singhi et al., 2025), motivating search paradigm that emphasizes broad candidate generation followed by verification-driven selection. RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents Figure 1. Comparison of RE-TRAC with state-of-the-art agentic models. Our 4B and 30B models surpass the performance of significantly larger, state-of-the-art models. We propose Re-TRAC, an agentic framework that recursively constructs structured state representation at the end of each trajectory and uses them as the prompting context for subsequent trajectories. Each state representation summarizes the evolving state of investigation along multiple dimensions, including accumulated evidence, unresolved uncertainties, identified failure modes, and forward-looking research plan. Unlike multiple independent trajectories that operate in isolation, Re-TRAC enables iterative reflection, cross-trajectory knowledge consolidation, and globally informed planning. This design transforms exploration from set of disconnected attempts into progressively informed search process. Empirically, we observe that Re-TRAC agents issue fewer tool calls and consume fewer tokens with each successive round of research, indicating improved decision-making efficiency and more targeted information acquisition guided by prior experience. Our experiments demonstrate that Re-TRAC achieves absolute gains of 1520% over ReAct on the BrowseComp benchmark when applied with frontier LLMs. This inspires us to push the limits of abilities of small models via ReTRAC. To unlock the benefits of Re-TRAC for smaller models, we develop post-training recipe that constructs supervised fine-tuning (SFT) data consisting of trajectories explicitly conditioned on structured state representations. This training procedure teaches the model to ground its reasoning, planning, and tool use on structured cross-trajectory summaries rather than relying solely on immediate context. After fine-tuning, our 30B model achieves 53% accuracy on BrowseComp, while the 4B model reaches 30%, establishing state-of-the-art performance among models of 2 comparable scale (see Figure 1). 2. Related Work 2.1. Deep Research Agents The emergence of Deep Research Agents marks t"
[03.02.2026 17:26] Mistral response. {"id": "f20180d0a47f4761a6e4a04031ae3aa6", "created": 1770139585, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1445, "total_tokens": 1490, "completion_tokens": 45, "num_cached_tokens": 1444}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Southeast University\",\n    \"Waseda University\",\n    \"Tsinghua University\",\n    \"Brown University\",\n    \"Zhejiang University\",\n    \"Microsoft\"\n]\n```"}}]}
[03.02.2026 17:26] Response: ```python
[
    "Southeast University",
    "Waseda University",
    "Tsinghua University",
    "Brown University",
    "Zhejiang University",
    "Microsoft"
]
```
[03.02.2026 17:26] Deleting PDF ./assets/pdf/2602.02486.pdf.
[03.02.2026 17:26] Success.
[03.02.2026 17:26] Downloading and parsing paper https://huggingface.co/papers/2602.02343.
[03.02.2026 17:26] Downloading paper 2602.02343 from https://arxiv.org/pdf/2602.02343v1...
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Why Steering Works: Toward Unified View of Language Model Parameter Dynamics Ziwen Xu1,2, Chenyan Wu1, Hengyu Sun1, Haiwen Hong2*, Mengru Wang1, Yunzhi Yao1, Longtao Huang2, Hui Xue2, Shumin Deng3, Zhixuan Chu1, Huajun Chen1, Ningyu Zhang1* 1Zhejiang University, 2Alibaba Group 3National University of Singapore, NUS-NCS Joint Lab, Singapore 6 2 0 2 2 ] . [ 1 3 4 3 2 0 . 2 0 6 2 : r a "
[03.02.2026 17:26] Response: ```python
[
    "Zhejiang University",
    "Alibaba Group",
    "National University of Singapore",
    "NUS-NCS Joint Lab"
]
```
[03.02.2026 17:26] Deleting PDF ./assets/pdf/2602.02343.pdf.
[03.02.2026 17:26] Success.
[03.02.2026 17:26] Downloading and parsing paper https://huggingface.co/papers/2602.02227.
[03.02.2026 17:26] Downloading paper 2602.02227 from https://arxiv.org/pdf/2602.02227v1...
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Show, Dont Tell: Morphing Latent Reasoning into Image Generation Harold Haodong Chen * 1 2 Xinxiang Yin * 1 3 Wen-Jie Shu 2 Hongfei Zhang 1 Zixin Zhang 1 4 Chenfei Liao 1 Litao Guo 1 Qifeng Chen 2 Ying-Cong Chen 1 2 6 2 0 2 2 ] . [ 1 7 2 2 2 0 . 2 0 6 2 : r Abstract Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generationa hallmark of human creativity. Current reasoning-augmented paradigms mostly rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and reencoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) condenser for summarizing intermediate generation states into compact visual memory, (ii) translator for converting latent thoughts into actionable guidance, (iii) shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive selfrefinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by 16% on GenEval and 25% on T2ICompBench; (II) outperforms explicit paradigms (e.g., TwiG) by 15% and 11% on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by 44% and token consumption by 51%; and (IV) exhibits 71% cognitive alignment with human intuition on reasoning invocation. Our code: LatentMorph. 1. Introduction Text-to-image (T2I) generation has progressed rapidly in recent years, driven by advances in diffusion (Rombach *Equal contribution 1HKU"
[03.02.2026 17:26] Response: ```python
["HKU"]
```
[03.02.2026 17:26] Deleting PDF ./assets/pdf/2602.02227.pdf.
[03.02.2026 17:26] Success.
[03.02.2026 17:26] Downloading and parsing paper https://huggingface.co/papers/2602.01576.
[03.02.2026 17:26] Downloading paper 2602.01576 from https://arxiv.org/pdf/2602.01576v1...
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Woosung Koh * 1 2 Sungjun Han * 1 Segyu Lee 1 2 Se-young Yun 2 Jamin Shin "
[03.02.2026 17:26] Response: ```python
[]
```
[03.02.2026 17:26] Extracting affiliations from text.
[03.02.2026 17:26] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Woosung Koh * 1 2 Sungjun Han * 1 Segyu Lee 1 2 Se-young Yun 2 Jamin ShinMobile Graphical User Interface (GUI) World Models (WMs) offer promising path for improving mobile GUI agent performance at trainand inference-time. However, current approaches face critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose novel paradigm: visual world modeling via renderable code generation, where single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with data generation framework that automatically synthesizes code-based training data. In extensive evaluation across 4 in-distribution and 2 out-of-distribution benchmarks, gWorld sets new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25 larger. Further analyses show that (1) scaling training data yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance. Project Page Code gWorld (8B, 32B) MWMBENCH 6 2 0 2 2 ] . [ 1 6 7 5 1 0 . 2 0 6 2 : r 1. Introduction Improving policy performance on mobile Graphical User Interface (GUI) tasks has become rapidly expanding research *Equal contribution 1Trillion Labs 2KAIST AI. Correspondence to: Se-young Yun <yunseyoung@kaist.ac.kr>, Jamin Shin <jay@trillionlabs.co>. Preprint. February 3, 2026. 1 Figure 1. Average Instruction Accuracy (IAcc.) across all six benchmarks. gWorld 8B and 32B achieve new pareto frontier in terms of model size (log10 scaled). The existing pareto frontier was defined by Qwen3 VL 8B, 32B, and GLM 4.6V 106B. Notably, extremely large models (e.g., Llama 4 402B) do not reach this pareto frontier, while text-image-to-image models (e.g., Emu3.5 34B) struggle with mobile GUI dynamics. area (Wang et al., 2024; Ye et al., 2025; Zhang et al., 2025; Li et al., 2025b; Nguyen et al., 2025; Liu et al., 2025; Niu et al., 2025), driven by the ubiquitous nature of mobile computing, with an estimated 8.9 billion mobile subscriptions worldwide (Ericsson, 2025). An emerging line of literature demonstrates that leveraging generative mobile World Model (WM) to predict future states can significantly enhance policy performance during both training (Fang et al., 2025; Wang et al., 2025) and inference (Chae et al., 2025; Gao et al., 2025; Gu et al., 2025; Li et al., 2025c; Cao et al., 2026). While these approaches yield substantial gains, they predict the next state in text; an abstraction over the pixel-space GUI state. This abstraction discards critical GUI information, including fine-grained spatial layout and visual attributes (e.g., iconography, typography, and color) (Chae et al., 2025; Luo et al., 2025; Cao et al., 2026). Moreover, text-only world representations limit Vision-Language Model (VLM)-based policies, which have been shown to outperform languageonly models on mobile GUI tasks (Hong et al., 2024; Lu et al., 2024; Gou et al., 2025). In response, VIMO (Luo et al., 2025) introduced the first visual mobile GUI WM and showed that visual world modeling yields larger policy Figure 2. Mobile GUI world modeling via renderable code. Given an image state St and action At, the model predicts the next state St+1. Our model, gWorld, generates renderable web code to ensure pixel-perfect text and structurally accurate layouts. In contrast, image-gen baselines (e.g., Qwen-Image-Edit 20B) struggle with the discrete nature of GUIs, frequently producing illegible text and distorted layouts. See Appendix Fig. 13, 14, 15 for additional qualitative examples. improvements than text-based alternatives. However, we observe three notable disadvantages of VIMO. First, VIMO relies on complex multi-stage pipeline rather than single self-contained model, resulting in significant computational overhead and latency (Luo et al., 2025; Cao et al., 2026). Concretely, their framework uses (1) an external Optical Character Recognition (OCR) model for text detection, (2) box-based text masking, (3) an external frontier VLM (GPT-4o) to filter masked regions, (4) customtrained diffusion model to generate the next-state image, and (5) two additional GPT-4o calls to fill in next-state text. Second, their formulation converts coordinate-based actions into natural-language instructions via GPT-4o, effectively outsourcing visual grounding to closed-weight model. Lastly, VIMO does not release the weights of its custom-trained diffusion model, making the system difficult to reproduce and deploy. In response, we present gWorld (8B, Contribution. 32B), which to our knowledge, are the first open-weight, single self-contained world models specialized for visual mobile GUI world modeling that operates via renderable code generation. We start by analyzing the limitations of using image-generation model for mobile GUI World Models ( 2.2), with further detailed analysis in 4.3. To alleviate this, we show for the first time that code-based representation can be leveraged for mobile GUI World Models ( 2.3). As there are no code-based GUI world modeling training datasets, we present our data generation framework ( 2.4). Specifically, we repurpose offline mobile-agent trajectories into (St, At)-conditioned next-state pairs, automatically converts St+1 from pixels to renderable web code, and adds free look-ahead reasoning traces, producing large-scale SFT data for training code-generating GUI WMs. Furthermore, due to the lack of comprehensive visual mobile GUI world modeling benchmarks, we present MWMBENCH, curating and open-sourcing four inand two out-of-distribution (OOD) benchmarks to evaluate mobile GUI WMs ( 3, Tab. 1). We empirically demonstrate that our data generation framework and model is effective: Our models outperform 8 frontier open-weight imageand code-generation models up to 50.25 larger, across 6 inand out-of-distribution benchmarks ( 4.2, Fig. 1, Tab. 2). We demonstrate that scaling our dataset size (37K, 77K, 129K, 240K"
[03.02.2026 17:26] Mistral response. {"id": "0918ae245df842f9bdeb474c79f3163c", "created": 1770139614, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1697, "total_tokens": 1712, "completion_tokens": 15, "num_cached_tokens": 1696}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Trillion Labs\", \"KAIST AI\"]\n```"}}]}
[03.02.2026 17:26] Response: ```python
["Trillion Labs", "KAIST AI"]
```
[03.02.2026 17:26] Deleting PDF ./assets/pdf/2602.01576.pdf.
[03.02.2026 17:26] Success.
[03.02.2026 17:26] Downloading and parsing paper https://huggingface.co/papers/2602.01479.
[03.02.2026 17:26] Downloading paper 2602.01479 from https://arxiv.org/pdf/2602.01479v1...
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 ] . [ 1 9 7 4 1 0 . 2 0 6 2 : r EBISU: Benchmarking Large Language Models in Japanese Finance Xueqing Peng2, Ruoyu Xiang3, Fan Zhang4, Mingzi Song5, Mingyang Jiang2, Yan Wang2, Lingfei Qian2, Taiki Hara1, Yuqing Guo2, Jimin Huang1,2, Junichi Tsujii6, Sophia Ananiadou1, 1University of Manchester, 2The Fin AI, 3New York University, 4The University of Tokyo, 5Meiji Gakuin University, 6National Institute of Advanced Industrial Science and Technology (AIST), 7The National Centre for Text Mining Correspondence: jimin.huang@postgrad.manchester.ac.uk "
[03.02.2026 17:27] Response: ```python
[
    "University of Manchester",
    "The Fin AI",
    "New York University",
    "The University of Tokyo",
    "Meiji Gakuin University",
    "National Institute of Advanced Industrial Science and Technology (AIST)",
    "The National Centre for Text Mining"
]
```
[03.02.2026 17:27] Deleting PDF ./assets/pdf/2602.01479.pdf.
[03.02.2026 17:27] Success.
[03.02.2026 17:27] Downloading and parsing paper https://huggingface.co/papers/2602.02472.
[03.02.2026 17:27] Downloading paper 2602.02472 from https://arxiv.org/pdf/2602.02472v1...
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 2 7 4 2 0 . 2 0 6 2 : r SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning Qifan Yu1,2, , Xinyu Ma1, Zhijian Zhuo1, Minrui Wang1, Deyi Liu1, Shiyi Zhan1, Yiyuan Ma1, Liang Xiang1, Xingyan Bin1, , Di He2, 1ByteDance Seed, 2Peking University Work done at ByteDance Seed, Corresponding authors "
[03.02.2026 17:27] Response: ```python
["ByteDance Seed", "Peking University"]
```
[03.02.2026 17:27] Deleting PDF ./assets/pdf/2602.02472.pdf.
[03.02.2026 17:27] Success.
[03.02.2026 17:27] Downloading and parsing paper https://huggingface.co/papers/2602.02156.
[03.02.2026 17:27] Downloading paper 2602.02156 from https://arxiv.org/pdf/2602.02156v1...
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"LoopViT: Scaling Visual ARC with Looped Transformers Wen-Jie Shu1 Xuerui Qiu2 Rui-Jie Zhu3 Harold Haodong Chen1 Yexin Liu1 Harry Yang1 1HKUST 2CASIA 3UC Santa Cruz wenjieshu2003@gmail.com 6 2 0 F 2 ] . [ 1 6 5 1 2 0 . 2 0 6 2 : r a "
[03.02.2026 17:27] Response: ```python
['HKUST', 'CASIA', 'UC Santa Cruz']
```
[03.02.2026 17:27] Deleting PDF ./assets/pdf/2602.02156.pdf.
[03.02.2026 17:27] Success.
[03.02.2026 17:27] Downloading and parsing paper https://huggingface.co/papers/2602.01322.
[03.02.2026 17:27] Downloading paper 2602.01322 from https://arxiv.org/pdf/2602.01322v1...
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding Panagiotis Koromilas 1 2 Andreas D. Demou 1 James Oldfield 3 Yannis Panagakis 2 4 Mihalis A. Nicolaou "
[03.02.2026 17:27] Response: ```python
[]
```
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding Panagiotis Koromilas 1 2 Andreas D. Demou 1 James Oldfield 3 Yannis Panagakis 2 4 Mihalis A. Nicolaou(a) Additive Interactions (b) Multiplicative Interactions Brand Brand 6 2 0 2 ] . [ 1 2 2 3 1 0 . 2 0 6 2 : r Sparse autoencoders (SAEs) have emerged as promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms. However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether Starbucks arises from the composition of star and coffee features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 210 larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency (r = 0.06 vs. = 0.82 for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition, largely independent of surface statistics. 1The Cyprus Institute 2University of Athens 3University of Oxford 4Archimedes AI/Athena Research Center 5University of Cyprus. Correspondence to: Panagiotis Koromilas <pakoromilas@di.uoa.gr>. Preprint. February 3, 2026. 1 Starbucks Coffee (zi) Star (zj ) Famous Star Coffee Constrained to the linear span of features Beverage Famous zi zj Beverage Interaction lifts into new semantic dimensions Figure 1. Semantic Dimension Expansion via Feature Interaction. Consider two semantic directionsFamous and Beverageand their associated learned features Star and Coffee. (a) Additive interactions yield co-occurrence semantics that remain in the original feature span. (b) Multiplicative interactions enable representations to escape this subspace via zi zj, lifting into orthogonal dimensions (Brand) to capture emergent concepts like Starbucks.Starbucks example from Table 3. 1. Introduction As AI systems are increasingly deployed in real-world domains, ensuring their safety and reliability has become critical challenge (Amodei et al., 2016; Hendrycks et al., 2021; Bengio et al., 2025). Developing interpretable models offers promising path towards aligning AI with human values: understanding why model produces given output enables us to (i) monitor its reasoning (Lindsey et al., 2025), (ii) debug failure modes (Wong et al., 2021), and (iii) steer away from unwanted behavior (Rimsky et al., 2024). Mechanistic interpretability pursues this agenda at the level of neural network internals (Bereska & Gavves, 2024), aiming to uncover interpretable features and circuits within model and thereby provide principled insights into its behavior. Sparse Autoencoders (SAEs), grounded in the principles of sparse dictionary learning, have emerged as leading tool for mechanistic interpretability. SAEs decompose neural network activations to recover human-interpretable features that models typically represent in superpositionencoded in overlapping directions due to limited representational capacity (Elhage et al., 2022). This framework has been shown to uncover safety-relevant concepts such as deception, bias, and harmful content, enabling targeted interventions that predictably steer model behavior (Templeton et al., 2024). PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding Figure 2. An overview of PolySAE: (1) sparse latent features are first extracted with standard SAE encoder. (2) Activations in the residual stream are then reconstructed by modeling 2ndand 3rd-order interactions in addition to the standard linear component. The example Investing.com Philippines stocks were higher after comes from Table 4. However, recent work has highlighted fundamental limitations of the SAE paradigm due to their reliance on the strong linear representation hypothesis (Engels et al., 2025; Csords et al., 2024). Standard SAEs reconstruct activations as weighted sums of independent features, expressing each activation as linear combination where features contribute additively. This linearity assumption raises fundamental question: what level of abstraction do learned features naturally capture? The answer has direct implications for mechanistic interpretability. If features truly combine linearly, we would expect individual dictionary atoms to represent atomic components, such as morphemes, simple concepts, or basic semantic primitives, that combine through superposition to form complex expressions. Such atomic features would enable transparent circuit analysis and precise interventions on elemental building blocks of meaning. Yet linguistic theory demonstrates that composition operates non-linearly across multiple levels of language structure. Morphologically, administrators is not simply the sum of stem and suffix; the combination produces distinct lexical item with specific syntactic and semantic properties (Haspelmath & Sims, 2013). Semantically, phrasal meanings such as kick the bucket or proper names like Starbucks (Figure 1) exhibit emergent properties irreducible to their parts (Partee, 1995). Vanilla SAEs demonstrably succeed at many interpretability tasks, yet their linear reconstruction mechanism cannot, in principle, represent nonlinear composition. Without explicit interaction mechanisms, SAEs cannot simultaneously represent atomic features and their non-linear compositions. When Starbucks appears in context, linear model must either (i) allocate dedicated feature for this compositional entity, sacrificing atomicity, or (ii) represent it through separate star and coffee features that cannot distinguish this specific composition from mere co-occurrence. Ideally, SAEs with sufficient capacit"
[03.02.2026 17:27] Mistral response. {"id": "b185829cd470489883452be15c358b6c", "created": 1770139650, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1408, "total_tokens": 1451, "completion_tokens": 43, "num_cached_tokens": 1407}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"The Cyprus Institute\",\n    \"University of Athens\",\n    \"University of Oxford\",\n    \"Archimedes AI/Athena Research Center\",\n    \"University of Cyprus\"\n]\n```"}}]}
[03.02.2026 17:27] Response: ```python
[
    "The Cyprus Institute",
    "University of Athens",
    "University of Oxford",
    "Archimedes AI/Athena Research Center",
    "University of Cyprus"
]
```
[03.02.2026 17:27] Deleting PDF ./assets/pdf/2602.01322.pdf.
[03.02.2026 17:27] Success.
[03.02.2026 17:27] Downloading and parsing paper https://huggingface.co/papers/2601.20613.
[03.02.2026 17:27] Downloading paper 2601.20613 from https://arxiv.org/pdf/2601.20613v2...
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 3 ] . [ 2 3 1 6 0 2 . 1 0 6 2 : r AgentIF-OneDay: Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios xbench.org The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products. Code: github.com/xbench-ai Data: huggingface.co/xbench-ai Corres"
[03.02.2026 17:27] Response: ```python
[]
```
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 3 ] . [ 2 3 1 6 0 2 . 1 0 6 2 : r AgentIF-OneDay: Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios xbench.org The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products. Code: github.com/xbench-ai Data: huggingface.co/xbench-ai Correspondence: team@xbench.orgAI agents driven by Large Language Models (LLMs) have recently exhibited remarkable progress in autonomous reasoning, planning, and tool usage. Although agents have achieved success in handling increasingly complex tasks within vertical domains like vibe coding (Jimenez et al., 2023; Zan et al., 2025), deep research (Wei et al., 2025; Chen et al., 2025) and complex problem solving (Phan et al., 2025), these advancements are not yet fully palpable to ordinary users. We posit that current evaluations lack the necessary diversity to reflect real-world scenarios across work, life, and learning. Addressing this gap, we propose AgentIF-OneDay, framework to assess the efficacy of AI agents in assisting general users with daily tasks through language instructions. AgentIF-OneDay demands the delivery, analysis, and modification of comprehensive work outputs, structured around three key dimensions: * Equal contribution. 1 1. Open Workflow Execution: These tasks assess the agents ability to execute automated processes precisely and exhaustively when the user provides clear and detailed operational procedure. This tests the agents robustness in long-context processing, avoidance of "instruction forgetting," and suppression of hallucinations. 2. Latent Instruction Inference: This dimension requires the agent to autonomously induce and infer implicit, unstated general rules or constraints from task attachments and apply them to new tasks. 3. Iterative Refinement: These tasks simulate multi-turn, progressive collaborative process between the user and the agent. The agent must perform precise content updates and adjustments based on supplementary or corrective instructions from the user upon existing outputs, measuring the efficacy of its state maintenance and human-machine collaboration. We control the distribution of topics in the evaluation set to balance alignment with authentic user needs and maximization of task diversity. The former includes common demands such as daily office software usage, life planning, and research, helping us understand the correlation between agent capabilities and real-world value. The latter primarily increases the difficulty of "hack" evaluation metrics through out-of-domain tasks, including game strategy research and the automation of scientific research workflows. Beyond manually annotated tasks, we designed File-centered Automated Agentic Pipeline for task generation. We utilize the ChatGPT agent to collect information-dense attachments with high potential for question generation. Using human-annotated tasks as seeds, we extract and augment workflow frameworks. Finally, we synthesize the attachments and workflows to produce AgentIF-OneDay evaluation items that are logically coherent and deeply correlated with the attachment information. Furthermore, this methodology is extensible to broader agentic data synthesis applications. We employ Instance-level rubrics for evaluation and have enhanced the consistency between LLM-based Verifiers and human scoring through pipeline design. For instance, we implemented visual parsing for PPT and HTML files and utilized Vision-Language Models (VLMs) as verifiers. Additionally, for rubrics requiring real-time verification, the model defaults to Search Mode. The utilization of superior multimodal foundation models has significantly improved the accuracy of the discriminator. When employing Gemini-3-Pro as the judge model, the consistency between AgentIF-OneDay scoring points and human scoring reaches 80.6%. AgentIF-OneDay comprises 104 tasks and covers 767 scoring points. Through systematic testing and analysis of mainstream AI agent products on this benchmark, we aim to reveal the strengths and bottlenecks of current agent products and agentic models, providing empirically valuable references for the future optimization of AI agents. Simultaneously, the high-quality, finely annotated instruction data accumulated by AgentIF-OneDay holds significant potential as training data for reinforcement learning.Instruction Following Benchmarks. Instruction following benchmarks are crucial for evaluating the ability of large language models to execute tasks based on specific instructions. For instance, IFEval (Zhou et al., 2023) assesses models capability using set of verifiable instructions to ensure accuracy. Another notable benchmark, FOFO (Xia et al., 2024), classifies tasks into various domains and imposes specific format requirements, such as "
[03.02.2026 17:27] Mistral response. {"id": "827d5e1b49634ad3895624feeeb04774", "created": 1770139655, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1309, "total_tokens": 1315, "completion_tokens": 6, "num_cached_tokens": 1308}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[]\n```"}}]}
[03.02.2026 17:27] Response: ```python
[]
```
[03.02.2026 17:27] Deleting PDF ./assets/pdf/2601.20613.pdf.
[03.02.2026 17:27] Success.
[03.02.2026 17:27] Downloading and parsing paper https://huggingface.co/papers/2602.02453.
[03.02.2026 17:27] Downloading paper 2602.02453 from https://arxiv.org/pdf/2602.02453v1...
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling Andong Chen 1 Wenxin Zhu 1 Qiuyu Ding 1 Yuchen Song 1 Muyun Yang 1 Tiejun Zhao 1 Website: https://thinking-with-comics.github.io/ Repository: https://github.com/andongBlue/Think-with-Comics. "
[03.02.2026 17:27] Response: ```python
[]
```
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling Andong Chen 1 Wenxin Zhu 1 Qiuyu Ding 1 Yuchen Song 1 Muyun Yang 1 Tiejun Zhao 1 Website: https://thinking-with-comics.github.io/ Repository: https://github.com/andongBlue/Think-with-Comics.Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, visual reasoning paradigm that uses comics as high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning. 6 2 0 2 2 ] . [ 1 3 5 4 2 0 . 2 0 6 2 : r 1. Introduction Large language models (LLMs) have significantly improved their reasoning ability on complex tasks by adopting explicit Chain-of-Thought (CoT) (Wei et al., 2022; Kojima et al., 2022; Besta et al., 2024; Yao et al., 2023), making stepby-step textual reasoning (Think with text) common 1Harbin Institute of Technology. Correspondence to: Andong Chen <ands691119@gmail.com>, Tiejun Zhao <tjzhao@hit.edu.cn>. Preprint. February 2026. Copyright 2026 by the author(s). paradigm. With the development of multimodal large language models (MLLM), this idea of explicit reasoning has extended from pure text to the visual domain. Under the Thinking with Images (TWI) paradigm (Hurst et al., 2024; Ope; Zhang et al., 2023; Wang et al., 2025; Chen et al., 2025), models not only use images as input signals but also generate intermediate visual representations during reasoning to supplement critical visual information (Li et al., 2025; Hu et al., 2024), thereby improving the reasoning performance of visionlanguage models (VLMs). Building on this, Thinking with Video further introduces temporal structure by generating short video sequences, enabling more complex forms of dynamic reasoning (Tong et al., 2025). Despite the extension of reasoning paradigms from text to images and videos, each modality still exhibits clear limitations. Static images struggle to represent temporal structure and dynamic processes, while the absence of explicit textual cues complicates cross-modal alignment. Videos provide temporal information but introduce substantial redundancy and significantly higher computational overhead, which limits their practical efficiency for reasoning. To address these limitations, we turn to more natural reasoning medium from daily life-comics-and introduce the Thinking with Comics (TwC) paradigm. Comics are distinctive narrative form. Compared with static images, they retain most key properties of video, including temporal logic, embedded text, and dynamic reasoning (Augereau et al., 2017). Yet compared with video, each panel is more information-dense and requires far lower reasoning cost. Recent generative models such as Gemini-3 Pro Image (Google DeepMind, 2025) can convert long text into coherent sequential panels while embedding text naturally within images. This allows comics to combine the highdensity reasoning benefits of images with the dynamic logic of video. Thus, Thinking with Comics has strong potential to expand visual reasoning into new research direction. To comprehensively explore this field, we adopted two paths of Thinking with Comics, namely End-to-End Visualized Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling Figure 1. The selected reasoning tasks and (Long) Context Understanding tasks, along with the Thinking with Comics solution based on Gemini-3 Pro Image. The reasoning tasks primarily involve mathematical and logical reasoning, while the (Long) Context Understanding tasks require the model to comprehend cultural contexts, documents, and other extended information. The model provides the reasoning process and correct answers within the generated comic panels. Reasoning and Comic as Conditioning Context for VLM. Then we evaluate our method on mainstream generalpurpose benchmarks across two task types, as shown in Figure 1: (1) reasoning tasks and (2) (long) context understanding tasks. In the evaluation, we test the two paths and compare them with leading MLLMs as well as models that following the paradigms of Thinking with Text, Thinking with Images, and Thinking with Video. The results show that comics, as form of structured visual storytelling, consistently yield systematic performance gains across different tasks. Further analysis reveals that: (1) different tasks benefit from different role-playing narrative structures in comicsfor example, detective-style narratives are better suited for logical reasoning tasks, while culture-centric narratives are more effective for cultural understanding; (2) Thinking with Comics exhibits scaling behavior similar to Chainof-Thought, where more difficult tasks require larger number of comic panels to support reasoning; (3) comic panels exhibit clear temporal and logical dependencies, and disrupting or permuting their order leads to noticeable performance degradation; (4) embedded textual elements in comics, such as dialogue and narration, work jointly with visual cues to reduce semantic ambiguity in purely visual reasoning; and (5) compared to Thinking with Video, Thinking with Comics achieves substantially lower inference cost while preserving essential temporal structure. These findings indicate that visual expression still offers substantial room for exploration, and that comics provide new reasoning medium positioned between static images and videos. We hope this work will inspire further exploration of Thinking with paradigms and help establish comics as an important component"
[03.02.2026 17:27] Mistral response. {"id": "b75c23ca1a854720a277bd3c0ed52e2b", "created": 1770139664, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1346, "total_tokens": 1358, "completion_tokens": 12, "num_cached_tokens": 1345}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Harbin Institute of Technology\"]\n```"}}]}
[03.02.2026 17:27] Response: ```python
["Harbin Institute of Technology"]
```
[03.02.2026 17:27] Deleting PDF ./assets/pdf/2602.02453.pdf.
[03.02.2026 17:27] Success.
[03.02.2026 17:27] Downloading and parsing paper https://huggingface.co/papers/2602.01675.
[03.02.2026 17:27] Downloading paper 2602.01675 from https://arxiv.org/pdf/2602.01675v1...
[03.02.2026 17:27] Extracting affiliations from text.
[03.02.2026 17:27] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"TRIP-Bench: Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios Yuanzhe Shen * 1 2 Zisu Huang * 2 Zhengyuan Wang * 2 Muzhao Tian * 2 Zhengkang Guo 2 Chenyang Zhang 3 Shuaiyu Zhou 4 Zengjie Hu 4 Dailin Li 5 Jingwen Xu 2 Kaimin Wang 2 Wenhao Liu 6 Tianlong Li 1 Fengpeng Yue 1 Feng Hong 1 Cao Liu 1 Ke Zeng "
[03.02.2026 17:27] Response: ```python
[
    "University 1",
    "University 2",
    "University 3",
    "University 4",
    "University 5",
    "University 6"
]
```
[03.02.2026 17:27] Deleting PDF ./assets/pdf/2602.01675.pdf.
[03.02.2026 17:27] Success.
[03.02.2026 17:27] Downloading and parsing paper https://huggingface.co/papers/2602.01660.
[03.02.2026 17:27] Downloading paper 2602.01660 from https://arxiv.org/pdf/2602.01660v1...
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 0 6 6 1 0 . 2 0 6 2 : r CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation Zhongyuan Peng1,3, Caijun Xu1,2, Changyi Xiao1, Shibo Hong1, Eli Zhang3, Stephen Huang3, Yixin Cao1, 1Fudan University, 2Shanghai Innovation Institute, 3M-A-P Corresponding authors "
[03.02.2026 17:28] Response: ```python
["Fudan University", "Shanghai Innovation Institute", "M-A-P"]
```
[03.02.2026 17:28] Deleting PDF ./assets/pdf/2602.01660.pdf.
[03.02.2026 17:28] Success.
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.01511.
[03.02.2026 17:28] Downloading paper 2602.01511 from https://arxiv.org/pdf/2602.01511v1...
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 1 1 5 1 0 . 2 0 6 2 : r Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training Ran Xu1,* Tianci Liu2,* Zihan Dong3 Tony Yu4 Ilgee Hong4 Carl Yang1 Linjun Zhang Tuo Zhao4 Haoyu Wang5 1Emory University 2Purdue University 3Rutgers University 4Georgia Institute of Technology 5University at Albany Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, framework that jointly optimizes rubric generator and judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that RubricARM achieves strong performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings. Keywords: Rubrics-as-Rewards, Reward Modeling, LLM Alignment, Synthetic Data Date: 2026-02-03 Model Weights & Checkpoints: https://huggingface.co/collections/OpenRubrics/rubricarm Contact: ran.xu@emory.edu; liu3351@purdue.edu; hwang28@albany.edu 1. Introduction Reward modeling serves as the compass for aligning large language models (LLMs) with human intents, typically by generating scalar score or preference label to predict human preferences (Stiennon et al., 2020, Wang et al., 2024a). However, in complex non-verifiable domain, such as creative writing or open-ended instruction following, these scalar or pairwise judgments often fail "
[03.02.2026 17:28] Response: ```python
[
    "Emory University",
    "Purdue University",
    "Rutgers University",
    "Georgia Institute of Technology",
    "University at Albany"
]
```
[03.02.2026 17:28] Deleting PDF ./assets/pdf/2602.01511.pdf.
[03.02.2026 17:28] Success.
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.01382.
[03.02.2026 17:28] Downloading paper 2602.01382 from https://arxiv.org/pdf/2602.01382v1...
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PromptRL: Prompt Matters in RL for Flow-Based Image Generation Fu-Yun Wang 1 2 * Han Zhang 3 Michael Gharbi 2 Hongsheng Li 1 Taesung Park 2 6 2 0 2 1 ] . [ 1 2 8 3 1 0 . 2 0 6 2 : r a "
[03.02.2026 17:28] Response: ```python
[]
```
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PromptRL: Prompt Matters in RL for Flow-Based Image Generation Fu-Yun Wang 1 2 * Han Zhang 3 Michael Gharbi 2 Hongsheng Li 1 Taesung Park 2 6 2 0 2 1 ] . [ 1 2 8 3 1 0 . 2 0 6 2 : r aFlow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as critical posttraining strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore. Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2 fewer rollouts compared *Work done during an internship at Reve. 1The Chinese University of Hong Kong, Hong Kong 2Reve, USA 3Meta Superintelligence Labs, USA. Correspondence to: Han Zhang <hanzhang.ai@gmail.com>, Hongsheng Li <hsli@ee.cuhk.edu.hk>. Preprint. February 3, 2026. 1 to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL. 1. Introduction The advent of flow matching models (FMs) (Liu et al., 2022; Lipman et al., 2022; Labs, 2024; Song et al., 2020) has transformed text-to-image (T2I) generation, enabling photorealistic synthesis from natural language descriptions. To align these models with human preferences and specific reward objectives, reinforcement learning (RL) (Sutton, 2018; Fan et al., 2023; Black et al., 2023) has become the standard posttraining mechanism, refining model behavior beyond the scope of supervised pretraining. Despite these advances, applying RL to FMs remains prohibitively sample-inefficient. Our investigation reveals two underappreciated yet critical failure modes in current flow-based RL pipelines. (i) First, we observe counterintuitive exploration paradox: as T2I models improve at following prompts precisely, they simultaneously lose generative diversity under identical prompts. This increased prompt adherence constrains the behavioral variation necessary for effective RL exploration, causing optimization to stagnate in narrow modes of the generation space. (ii) Second, we identify severe prompt overfitting, where models learn to exploit superficial linguistic patterns in training prompts rather than developing genuine visual understanding. This overfitting manifests as dramatic performance collapse when models encounter semantically equivalent prompts phrased with different syntax at test time. This makes prompt enhancement (PE) (Hao et al., 2023; Rosenman et al., 2024; Manas et al., 2024; Mo et al., 2024), crucial technique for improving generation quality, ineffective or even counterproductive for RL-finetuned FMs. We provide detailed empirical evidence for both phenomena in Section 3. These limitations expose fundamental design oversight in existing approaches: treating prompts as fixed inputs rather than malleable components of the optimization process. Naive augmentation techniques such as random synonym substitution or rule-based paraphrasing prove inadequate, often failing to generate semantically coherent variations at scale. In this paper, we explore the hypothesis that large language models (LMs), when trained as adaptive co-learners PromptRL: Prompt Matters in RL for Flow-Based Image Generation Figure 1. Overview of the PromptRL framework. PromptRL jointly trains language model and flow-matching image generator within unified RL loop. Given an original prompt (and optionally reference image), the LM produces semantically grounded prompt variants that expand the exploration space beyond fixed-prompt training. These prompts are paired with independent noise samples and passed to the flow-matching model to generate diverse images. mixture of reward functions evaluates each image and guides the evolution of the LM (for improved prompt rewriting) and the FM (for improved visual generation). via joint RL, can generate semantically grounded prompt variations that enhance exploration efficiency and serve as co-trained PE module in practical deployment. We introduce PromptRL (Prompt Matters in RL), framework that integrates LMs as adaptive co-learners within flow-based RL training loops, as illustrated in Fig. 1. Rather than employing LMs as static preprocessors, we train them to generate prompt variations that simultaneously preserve semantic intent and maximize downstream image generation rewards. This creates mutually beneficial training dynamic: diverse LM-generated prompts expand the exploration space for FMs, accelerating policy improvement, while reward signals from flow model outputs guide LMs toward discovering linguistically varied yet contextually appropriate reformulations. Our experimental results demonstrate that PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval (Ghosh et al., 2023), 0.98 on OCR accuracy (Cui et al., 2025), and 24.05 on PickScore (Kirstain et al., 2023). Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving EditReward (Wu et al., 2025b) of FLUX.1-Kontext (Labs et al., 2025) from 1.19 to 1.43 with only 0.06 million rollouts. Extensive experiments show that PromptRL consistently achieves higher performance ceilings"
[03.02.2026 17:28] Mistral response. {"id": "30e78caf2be14ac6816065d15c76b89d", "created": 1770139700, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1497, "total_tokens": 1526, "completion_tokens": 29, "num_cached_tokens": 1496}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"The Chinese University of Hong Kong\",\n    \"Reve\",\n    \"Meta Superintelligence Labs\"\n]\n```"}}]}
[03.02.2026 17:28] Response: ```python
[
    "The Chinese University of Hong Kong",
    "Reve",
    "Meta Superintelligence Labs"
]
```
[03.02.2026 17:28] Deleting PDF ./assets/pdf/2602.01382.pdf.
[03.02.2026 17:28] Success.
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.00986.
[03.02.2026 17:28] Downloading paper 2602.00986 from https://arxiv.org/pdf/2602.00986v1...
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 ] . [ 1 6 8 9 0 0 . 2 0 6 2 : r a Guowei Xu 1 Mert Yuksekgonul 2 James Zou "
[03.02.2026 17:28] Response: ```python
[]
```
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 ] . [ 1 6 8 9 0 0 . 2 0 6 2 : r aGuowei Xu 1 Mert Yuksekgonul 2 James Zouexplain why these representations possess such capabilities. In this paper, we identify sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the models internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected. 1. Introduction In recent years, the reasoning capabilities of Large Language Models (LLMs) have achieved significant breakthroughs, even surpassing human expert levels in various mathematical and scientific tasks (Singh et al., 2025; Guo et al., 2025a). Parallel to the continuous pursuit of higher performance, researchers seek to understand the underlying reasoning mechanisms of these models. Recent studies reveal that LLM hidden states encode rich information, which can be leveraged for weighted learning (Oh et al., 2025), predicting confidence and answer correctness (Gekhman et al., 2025), detecting hallucinations (Zhang et al., 2025a), and performing implicit reasoning (Chen et al., 2024). However, most existing work focuses primarily on utilizing the information present in hidden states, while few studies analyze the intrinsic properties of the hidden states themselves or attempt to 1Tsinghua University 2Stanford University. Correspondence to: James Zou <jamesz@stanford.edu>. Preprint. February 3, 2026. 1 In this paper, we find that the ability of LLM hidden states to predict confidence and correctness can be attributed to the existence of small subset of neurons that encode the value information of the current state. This hypothesis is inspired by biological concepts. In neuroscience, the human brain contains reward subsystem composed of small number of neurons that govern how humans explore and learn from their environment. Value neurons and dopamine neurons are two critical types of neurons within this system. Value neurons are primarily identified in the ventromedial prefrontal cortex (vmPFC) and the orbitofrontal cortex (OFC) of human and other primate brains, which are known to represent the subjective value of stimuli during decisionmaking (Tremblay & Schultz, 1999; Padoa-Schioppa & Assad, 2006). Meanwhile, dopamine neurons are mainly located in the ventral tegmental area (VTA) and the substantia nigra pars compacta (SNc). Their core function is to encode the Reward Prediction Error (RPE), the phenomenon where neuronal activation increases when the brain receives higher reward than expected and decreases when the reward falls short of expectations (Schultz, 1998). We demonstrate that similar reward subsystem exists within LLM hidden states, where sparse set of neurons performs functions analogous to biological value and dopamine neurons. Specifically, value neurons represent the models own expectation of the current states value, while the activation levels of dopamine neurons correlate closely with the discrepancy between the actual reward and the models expectation. In the following sections, we first introduce the value neurons within the LLM reward subsystem and describe how to identify their distribution across model layers. Through intervention experiments, we observe that value neurons exert significant influence on the models reasoning capabilities. Specifically, zeroing out the hidden states of even small fraction of value neurons results in substantial performance degradation, whereas randomly zeroing out the same proportion of neurons yields no such effect. Next, we systematically demonstrate the robustness and transferability of these value neurons, showing that they are universal across various datasets (GSM8K (Cobbe et al., 2021), MATH500 (Lightman et al., 2023), Minerva Math (Lewkowycz et al., 2022), ARC (Clark et al., 2018), MMLU STEM (Hendrycks et al., 2021)), model scales (0.5B, 7B, 14B), layers, and archiSparse Reward Subsystem in Large Language Models tectural designs (Qwen (Bai et al., 2023), Llama (Touvron et al., 2023), Phi (Gunasekar et al., 2023), Gemma (Team et al., 2024)). Furthermore, we show that the distribution of these value neurons remain consistent across different models derived from the same base model, as well as across diverse datasets. Subsequently, we identify dopamine neurons by examining cases where value predictions and actual rewards diverge. Through case studies, we demonstrate that these dopamine neurons indeed exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected. In summary, our key contributions are: We identify reward subsystem in LLM hidden states analogous to that of the human brain. Within this subsystem, small subset of neurons acts as value neurons, representing the models value expectation for the current state, while another subset acts as dopamine neurons, whose activation levels reflect the reward prediction error. Intervention experiments reveal that value neurons are critical for reasoning. Ablating even small subset of these neurons severely impairs performance. We demonstrate the robustness of the value neurons across diverse datasets, model scales, and architectures. We demonstrate the transferability of the value neurons across different models derived from the same base model and across diverse datasets. 2. Sparse Value Neurons in Large LanguageOur study focuses on autoregressive large language models. By analyzing the characteristics of hidden states during generation, we demonstrate that large language models exhibit sparse reward subsystem within their hidden states that encodes information regarding value (value neurons, Section 2.3) and prediction error (dopamine neurons, Section 4.1). In this section, we first introduce value neurons. During the gen"
[03.02.2026 17:28] Mistral response. {"id": "e0f6e12357fe485cbb2521095f0ffaa7", "created": 1770139708, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1412, "total_tokens": 1429, "completion_tokens": 17, "num_cached_tokens": 1411}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Tsinghua University\", \"Stanford University\"]\n```"}}]}
[03.02.2026 17:28] Response: ```python
["Tsinghua University", "Stanford University"]
```
[03.02.2026 17:28] Deleting PDF ./assets/pdf/2602.00986.pdf.
[03.02.2026 17:28] Success.
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.00759.
[03.02.2026 17:28] Downloading paper 2602.00759 from https://arxiv.org/pdf/2602.00759v1...
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Zhipeng Chen1,2,, Xiaobo Qin2, Wayne Xin Zhao1,, Youbin Wu2,, Ji-Rong Wen1 1Renmin University of China, 2ByteDance Seed Work done at ByteDance Seed, Corresponding authors "
[03.02.2026 17:28] Response: ```python
[
    "Renmin University of China",
    "ByteDance Seed"
]
```
[03.02.2026 17:28] Deleting PDF ./assets/pdf/2602.00759.pdf.
[03.02.2026 17:28] Success.
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.02110.
[03.02.2026 17:28] Downloading paper 2602.02110 from https://arxiv.org/pdf/2602.02110v1...
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 0 1 1 2 0 . 2 0 6 2 : r a Zhongqian Fu, Tianyi Zhao, Kai Han, Hang Zhou, Xinghao Chen, and Yunhe Wang Huawei Noahs Ark Lab {fuzhongqian, zhaotianyi13, kai.han}@huawei.com Abstract. World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present systematic empirical study of world model quantization using DINO-WM as representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https: //github.com/huawei-noah/noah-research/tree/master/QuantWM. In the field of artificial intelligence, World Model is an internal, predictive representation of an environment that allow"
[03.02.2026 17:28] Response: ```python
["Huawei Noahs Ark Lab"]
```
[03.02.2026 17:28] Deleting PDF ./assets/pdf/2602.02110.pdf.
[03.02.2026 17:28] Success.
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.01842.
[03.02.2026 17:28] Downloading paper 2602.01842 from https://arxiv.org/pdf/2602.01842v1...
[03.02.2026 17:28] Failed to download and parse paper https://huggingface.co/papers/2602.01842: 'LTChar' object is not iterable
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.01296.
[03.02.2026 17:28] Downloading paper 2602.01296 from https://arxiv.org/pdf/2602.01296v1...
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"IEEE TRANS. ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Interacted Planes Reveal 3D Line Mapping Zeran Ke, Bin Tan, Gui-Song Xia, Yujun Shen, Nan Xue Abstract3D line mapping from multi-view RGB images provides compact and structured visual representation of scenes. We study the problem from physical and topological perspective: 3D line most naturally emerges as the edge of finite 3D planar patch. We present LiP-Map, lineplane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research. Index Terms3D Line Mapping, 3D Planar Primitives, Interacted Planes, Structured Visual Geometry, Camera Relocalization Structured 3D reconstruction from multi-view images using simple primitives [1], [2], [3], [4], [5], [6], [7], [8] is compelling, as it parallels how humans intuitively build complex 3D geometries from fundamental elements such as points, lines, curves, and planes, leveraging the parsimony of geometric composition. The symbolic nature of structured 3D scene representations could arguably enhance spatial intelligence, enabling more efficient understanding of our 3D world. Yet this perspective is controversial"
[03.02.2026 17:28] Response: ```python
[]
```
[03.02.2026 17:28] Extracting affiliations from text.
[03.02.2026 17:28] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"IEEE TRANS. ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Interacted Planes Reveal 3D Line Mapping Zeran Ke, Bin Tan, Gui-Song Xia, Yujun Shen, Nan Xue Abstract3D line mapping from multi-view RGB images provides compact and structured visual representation of scenes. We study the problem from physical and topological perspective: 3D line most naturally emerges as the edge of finite 3D planar patch. We present LiP-Map, lineplane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research. Index Terms3D Line Mapping, 3D Planar Primitives, Interacted Planes, Structured Visual Geometry, Camera RelocalizationStructured 3D reconstruction from multi-view images using simple primitives [1], [2], [3], [4], [5], [6], [7], [8] is compelling, as it parallels how humans intuitively build complex 3D geometries from fundamental elements such as points, lines, curves, and planes, leveraging the parsimony of geometric composition. The symbolic nature of structured 3D scene representations could arguably enhance spatial intelligence, enabling more efficient understanding of our 3D world. Yet this perspective is controversial, since many in the community remain unconvinced, citing the limited reconstruction quality of current methods. In this paper, we focus on two key primitives, rectangular planes and line segments, with the goal of achieving accurate, complete, and detailed 3D line mapping1 for man-made environments. The problem of 3D line mapping has been extensively studied through two-view matching [9], [10] and multi-view tracking of 2D line segments, using pipeline analogous to 3D point mapping. However, due to the fundamental differences between line segments and points, establishing reliable line correspondences remains challenging. recent approach, LIMAP [1], attempts to mitigate this issue by considering the top line matches instead of single match, thereby improving the chance of correct correspondences while pruning incorrect ones. Although LIMAP [1] significantly outperforms Line3D++ [3], it is limited by strong dependence on dense viewpoints to achieve successful line triangulation. Other studies [2], [4] aim to bypass 2D line matching by leveraging neural implicit fields, demonstrat- (: equal contribution. : corresponding author) Z.-R. Ke is with the School of Computer Science, Wuhan University, Wuhan 430072, China. He is currently research intern at Ant Group. Gui-Song Xia is with the School of Computer Science and the School of Artificial Intelligence, Wuhan University, Wuhan 430072, China. B. Tan, Y. Shen, and N. Xue are with Ant Group, Hangzhou 310000, China. 1. This terminology is borrowed from LIMAP [1], and this task is also referred to as 3D line reconstruction. ing the potential for matching-free formulations. However, they suffer from the slow optimization process due to their reliance on neural fields. To construct reliable 3D line map from 2D line detections across multiple views, two key ingredients are required: robust cross-view correspondences and accurate spatial placement of the reconstructed 3D lines. common strategy is to utilize an existing surface reconstruction from multi-view inputs with known camera poses and to project detected 2D lines onto the surface using depth maps. However, this approach often fails in practice, as illustrated in Fig. 1. On one hand, view-dependent parallax can cause single image line to correspond to multiple 3D line segments at different depths. On the other hand, inconsistencies in the depth maps can introduce spurious structural lines. Because true 3D lines are inherently inseparable from structural surface edges, joint recovery of surfaces and edges is indispensable, motivating novel formulation of 3D line mapping that explicitly models the geometric relationship and interaction between planes and line segments. Planar representations offer promising opportunity. PlanarSplatting [8] reconstructs structured scene surfaces by optimizing set of learnable planar primitives. This formulation is attractive because plane boundaries are naturally formed by lines, revealing direct geometric and topological link between surfaces and 3D line structures. However, PlanarSplatting is designed for surface reconstruction only, without explicitly connecting multi-view 2D line detections to the learned primitives. Thus, we explore how to associate 2D line segments with 3D planar edges and leverage these associations to reconstruct reliable, consistent 3D line maps. We therefore propose LiP-Map, which explicitly exploits the interaction between planes and lines to recover reliable and consistent 3D line maps. The name stands for LinePlane Joint Optimization for 3D line mapping. Our approach leverages the geometric synergy between line segments and the edges of 3D planar primitives. By applying any existing 2D line segment detector [11], [12], 6 2 0 2 1 ] . [ 1 6 9 2 1 0 . 2 0 6 2 : r IEEE TRANS. ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 2 Fig. 1: Comparison of different 3D line maps on scenes of three public datasets. First row: lift 2D detected lines into 3D lines using depths rendered from the GT mesh. Second row: lift 2D detected lines into 3D lines using depths rendered by PlanarSplatting [8]. Third row: extract planar edges from PlanarSplatting [8]. Last row: our 3D line maps. 2D line segments are detected by DeepLSD [11]. lift means back-project 2D detected lines into 3D using the sensor/predicted depth maps. [13], [14] to multi-view input images, set of 3D planes is optimized with two key learning objectives: The 3D planes should align as closely as possible with the 2.5D depth"
[03.02.2026 17:28] Mistral response. {"id": "f436419467794b1b986c0a289006a05f", "created": 1770139734, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1503, "total_tokens": 1563, "completion_tokens": 60, "num_cached_tokens": 1502}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"School of Computer Science, Wuhan University, Wuhan 430072, China\",\n    \"Ant Group\",\n    \"School of Computer Science and the School of Artificial Intelligence, Wuhan University, Wuhan 430072, China\"\n]\n```"}}]}
[03.02.2026 17:28] Response: ```python
[
    "School of Computer Science, Wuhan University, Wuhan 430072, China",
    "Ant Group",
    "School of Computer Science and the School of Artificial Intelligence, Wuhan University, Wuhan 430072, China"
]
```
[03.02.2026 17:28] Deleting PDF ./assets/pdf/2602.01296.pdf.
[03.02.2026 17:28] Success.
[03.02.2026 17:28] Downloading and parsing paper https://huggingface.co/papers/2602.01077.
[03.02.2026 17:28] Downloading paper 2602.01077 from https://arxiv.org/pdf/2602.01077v1...
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 ] . [ 1 7 7 0 1 0 . 2 0 6 2 : r PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers Haopeng Li 1 Shitong Shao 1 Wenliang Zhong 1 Zikai Zhou 1 Lichen Bai 1 Hui Xiong 1 Zeke Xie 1 calico cat, with carrot and pack of tissues placed in front of it, is staring at the camera with confused look and resting one of its front paws on the carrot, in realistic painting style. (a) Wan2.1-14B Dense Attention Latency: 1468 Dense Attention Ours (r=85%) SpargeAttn (r=80%) Dense Attention Ours (r=85%) SpargeAttn (r=80%) Dense Attention Ours (r=85%) SpargeAttn (r=80%) (b) Wan2.1-14B PISA (Ours) Latency: 687 (2.14 Speedup) PSNR: 24.69 LPIPS: 0.129 LPIPS: 0.373 Latency: 6.87 (c) Text-to-Image generation results on FLUX.1-dev, where denotes the sparsity ratio. Latency: 7.47 Latency: 8.32 PSNR: 22.60 PSNR: 13.32 Figure 1. PISA accelerates diverse generation tasks. Top (a, b): Wan2.1-14B video generation. PISA achieves 2.14 speedup over Dense Attention with no appreciable quality loss. Bottom (c): FLUX.1-dev text-to-image generation. PISA at higher sparsity ratio r=85% preserves better quality and structure than SpargeAttn (Zhang et al., 2025b). "
[03.02.2026 17:29] Response: ```python
[]
```
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 ] . [ 1 7 7 0 1 0 . 2 0 6 2 : r PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers Haopeng Li 1 Shitong Shao 1 Wenliang Zhong 1 Zikai Zhou 1 Lichen Bai 1 Hui Xiong 1 Zeke Xie 1 calico cat, with carrot and pack of tissues placed in front of it, is staring at the camera with confused look and resting one of its front paws on the carrot, in realistic painting style. (a) Wan2.1-14B Dense Attention Latency: 1468 Dense Attention Ours (r=85%) SpargeAttn (r=80%) Dense Attention Ours (r=85%) SpargeAttn (r=80%) Dense Attention Ours (r=85%) SpargeAttn (r=80%) (b) Wan2.1-14B PISA (Ours) Latency: 687 (2.14 Speedup) PSNR: 24.69 LPIPS: 0.129 LPIPS: 0.373 Latency: 6.87 (c) Text-to-Image generation results on FLUX.1-dev, where denotes the sparsity ratio. Latency: 7.47 Latency: 8.32 PSNR: 22.60 PSNR: 13.32 Figure 1. PISA accelerates diverse generation tasks. Top (a, b): Wan2.1-14B video generation. PISA achieves 2.14 speedup over Dense Attention with no appreciable quality loss. Bottom (c): FLUX.1-dev text-to-image generation. PISA at higher sparsity ratio r=85% preserves better quality and structure than SpargeAttn (Zhang et al., 2025b).Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, training-free Piecewise 1The Hong Kong University of Science and Technology (Guangzhou). Correspondence to: Zeke Xie <zekexie@hkustgz.edu.cn>. Preprint. February 3, 2026. 1 Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 and 2.57 speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves 1.2 acceleration without compromising visual quality. Code is available. PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers 1. Introduction Sparse Attention Full Attention PISA (Ours) Diffusion Transformers (DiTs) (Peebles & Xie, 2023) have demonstrated impressive performance and scalability in generating high-fidelity images and videos, leading to their widespread adoption across diverse visual generation tasks (Arnab et al., 2021; Hong et al., 2022; Wan et al., 2025). However, as the demand for higher resolutions and longer video durations grows, the sequence length of input tokens increases dramatically. Consequently, the quadratic complexity of the self-attention mechanism (Vaswani et al., 2017) becomes significant bottleneck, resulting in prohibitively low inference efficiency for large-scale DiTs. To address the computational bottleneck, especially in highresolution image and video generation, recent research has leveraged the inherent sparsity in DiTs to enable sparse attention. Early works (Zhang et al., 2025d; Xi et al., 2025; Yang et al., 2025) capitalized on the spatiotemporal redundancy of video diffusion transformers to introduce static, training-free sparse attention patterns. To improve adaptability, other methods (Zhang et al., 2025b; Xu et al., 2025; Xia et al., 2025) propose computing sparse patterns dynamically at runtime. Moving beyond training-free approaches, methods such as VSA (Zhang et al., 2025c) and Radial Attention (Li et al., 2025) have explored trainable sparse attention; works like SANA (Xie et al., 2024; Chen et al., 2025) and Linfusion (Liu et al., 2024) have adopted linear attention for efficient generation, while methods such as SLA (Zhang et al., 2025a) have made preliminary attempts to combine sparse and linear attention. However, existing methods still face inherent limitations: (1) Hard truncation: Sparse attention directly discards keyvalue pairs, leading to performance drops at high sparsity and inefficiency on shorter sequences (e.g., 4K tokens). (2) Incompatibility with pre-trained weights: Linear and hybrid attention fundamentally alter the attention distribution of pre-trained models, precluding the direct reuse of weights and necessitating expensive retraining. These limitations underscore the need for unified mechanism that enhances efficiency without sacrificing quality or requiring retraining. To this end, we propose PISA, novel training-free sparse attention that accelerates DiTs while maintaining high accuracy through piecewise computation. Unlike standard sparse attention, which computes only critical blocks and discards the rest, PISA treats attention as piecewise process: (1) Exact computation for sparse key-value blocks to preserve critical information; (2) Approximation for the remaining blocks using block-wise Taylor expansion to cover the massive amount of non-critical information. Specifically, we propose hybrid-order approximation strategy that uses block-wise zero-order expansion and global first-order approximation to efficiently improve accuracy. This enables PISA to significantly enhance approximation fidelity relActive Blocks: 20% Active Blocks: 100% Active Blocks: 100% FLOPs: 20.0% L1 Error: 10.34% FLOPs: 100% L1 Error: 0% FLOPs: 20.4% L1 Error: 1.36% Figure 2. Visualization of attention patterns on Wan2.1-1.3B. PISA achieves 100% effective block coverage similar to full attention. This near-lossless approximation with only negligible computational overhead relative to standard sparse attention. ative to full attention, incurring only negligible computational overhead compared to standard sparse attention, as illustrated in Fig. 2. These dual computational pathways are fused into the online softmax process via custom"
[03.02.2026 17:29] Mistral response. {"id": "3a886b96409442ba8deaca9e83fc826b", "created": 1770139743, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1671, "total_tokens": 1691, "completion_tokens": 20, "num_cached_tokens": 1670}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"The Hong Kong University of Science and Technology (Guangzhou)\"]\n```"}}]}
[03.02.2026 17:29] Response: ```python
["The Hong Kong University of Science and Technology (Guangzhou)"]
```
[03.02.2026 17:29] Deleting PDF ./assets/pdf/2602.01077.pdf.
[03.02.2026 17:29] Success.
[03.02.2026 17:29] Downloading and parsing paper https://huggingface.co/papers/2601.22674.
[03.02.2026 17:29] Downloading paper 2601.22674 from https://arxiv.org/pdf/2601.22674v2...
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"VISIONTRIM: UNIFIED VISION TOKEN COMPRESSION FOR TRAINING-FREE MLLM ACCELERATION Hanxun Yu1, Wentong Li2, Xuan Qu1, Song Wang1, Junbo Chen3, Jianke Zhu1 1Zhejiang University Equal contribution. Corresponding authors. 2Nanjing University of Aeronautics and Astronautics 3Udeer.ai 6 2 0 2 ] . [ 2 4 7 6 2 2 . 1 0 6 2 : r a "
[03.02.2026 17:29] Response: ```python
[
    "Zhejiang University",
    "Nanjing University of Aeronautics and Astronautics",
    "Udeer.ai"
]
```
[03.02.2026 17:29] Deleting PDF ./assets/pdf/2601.22674.pdf.
[03.02.2026 17:29] Success.
[03.02.2026 17:29] Downloading and parsing paper https://huggingface.co/papers/2601.22588.
[03.02.2026 17:29] Downloading paper 2601.22588 from https://arxiv.org/pdf/2601.22588v1...
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 3 ] . [ 1 8 8 5 2 2 . 1 0 6 2 : r RETHINKING LLM-AS-A-JUDGE: REPRESENTATIONAS-A-JUDGE WITH SMALL LANGUAGE MODELS VIA SEMANTIC CAPACITY ASYMMETRY Zhuochun Li1,2,, Yong Zhang1,, Ming Li3, Yuelyu Ji2, Yiming Zeng4, Ning Cheng1,*, Yun Zhu1, Yanmeng Wang1, Shaojun Wang1, Jing Xiao1, Daqing He2 1Ping An Technology (Shenzhen) Co., Ltd. 2University of Pittsburgh 3University of Maryland, College Park 4University of Connecticut {zhl163,yuj49,dah44}@pitt.edu {zhangyong203,chengning211}@pingan.com.cn {minglii}@umd.edu {yiming.zeng}@uconn.edu "
[03.02.2026 17:29] Response: ```python
[
    "Ping An Technology (Shenzhen) Co., Ltd.",
    "University of Pittsburgh",
    "University of Maryland, College Park",
    "University of Connecticut"
]
```
[03.02.2026 17:29] Deleting PDF ./assets/pdf/2601.22588.pdf.
[03.02.2026 17:29] Success.
[03.02.2026 17:29] Downloading and parsing paper https://huggingface.co/papers/2602.02039.
[03.02.2026 17:29] Downloading paper 2602.02039 from https://arxiv.org/pdf/2602.02039v1...
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Evaluating Deep Data Research on LLMs Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models Wei Liu, Peijie Yu, Michele Orini, Yali Du, Yulan He Kings College London, Tencent, The Alan Turing Institute Abstract: The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models. Project: https://huggingface.co/spaces/thinkwee/DDR_Bench Correspondence: wei.4.liu@kcl.ac.uk, yulan.he@kcl.ac.uk 6 2 0 2 2 ] . [ 1 9 3 0 2 0 . 2 0 6 2 : r Figure 1: Inference-time scaling performance in DDR-Bench across different dimensions. The y-axis reports checklist accuracy. Beyond final accuracy, DDR-Bench provides rich test-time exploration information from different scaling dimensions, enabling detailed analysis of model agency behaviour. See details in 4. 1. Introduction Agentic large language models (Agentic LLMs) (Zhang et al., 2025b) extend conventional LLMs (Brown et al., 2020; OpenAI, 2022; 2023; 2025) from reactive response to interactive decision making. By integrating models with tools and memory, recent agentic systems are able to complete complex real-world tasks involving long-horizon be1 Evaluating D"
[03.02.2026 17:29] Response: ```python
[
    "Kings College London",
    "Tencent",
    "The Alan Turing Institute"
]
```
[03.02.2026 17:29] Deleting PDF ./assets/pdf/2602.02039.pdf.
[03.02.2026 17:29] Success.
[03.02.2026 17:29] Downloading and parsing paper https://huggingface.co/papers/2602.01997.
[03.02.2026 17:29] Downloading paper 2602.01997 from https://arxiv.org/pdf/2602.01997v1...
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Safal Shrestha * 1 Anubhav Shrestha * 1 Aadim Nepal 1 Minwu Kim 1 Keith Ross "
[03.02.2026 17:29] Response: ```python
[]
```
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Safal Shrestha * 1 Anubhav Shrestha * 1 Aadim Nepal 1 Minwu Kim 1 Keith Ross1. Introduction 6 2 0 2 2 ] . [ 1 7 9 9 1 0 . 2 0 6 2 : r Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90% of baseline performance, and yields substantial gains of up to 20 30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes. 1 2 *Equal contribution 1Department of Computer Science, New York University Abu Dhabi, Abu Dhabi, UAE. Correspondence to: Keith Ross <keithwross@nyu.edu>. Preprint. February 3, 2026. 1Code available at https://github.com/safal312/ on-the-limits-of-layer-pruning available and models 2Data are at https:// huggingface.co/collections/safal312/ on-the-limits-of-generative-reasoning-in-llms Large Language Models (LLMs) have achieved remarkable performance across wide range of tasks, success often attributed to their large parameter counts and extensive training data (Hoffmann et al., 2022; Yang et al., 2025a; Grattafiori et al., 2024). However, the scale of modern LLMs raises significant concerns regarding efficiency and costs (LeCun et al., 1989; Wan et al., 2023; Song et al., 2024). These challenges have motivated substantial body of work on model compression techniques aimed at reducing model size while preserving performance, including pruning at multiple granularities ranging from individual neurons to entire layers (Frantar & Alistarh, 2023; Sun et al., 2024; Muralidharan et al., 2024; Sreenivas et al., 2024; Song et al., 2024; Ashkboos et al., 2024; Ma et al., 2023; Ling et al., 2024). Among these approaches, layer pruning has emerged as particularly appealing strategy. By removing entire transformer blocks of contemporary decoder-only models, layer pruning offers simple method for reducing model depth, often requiring minimal or no additional finetuning (Song et al., 2024; Yang et al., 2024; Lu et al., 2024; Men et al., 2025; Kim et al., 2024; Chen et al., 2024). This approach is further motivated by theoretical and empirical works suggesting redundancy across layers in LLMs (Sun et al., 2025; Lad et al., 2024; Men et al., 2025). Furthermore, layer pruning is largely orthogonal to other efficiency techniques such as quantization and sparsification, enabling it to be combined with complementary methods for additional computational savings (Song et al., 2024; Kim et al., 2024). While this approach has achieved notable success in classification benchmarks, it has proven far less effective for reasoning-intensive generative tasks like math and coding, which require the model to generate multi-step chain of thought to arrive at the correct solution (Lu et al., 2024; Chen et al., 2024; Men et al., 2025; Yang et al., 2024; Kim et al., 2024; Nepal et al., 2025). Prior work has largely attributed the failure of layer pruning on generative tasks to the importance of deeper layers for reasoning, without explicitly characterizing how layer removal degrades model behavior (Wang et al., 2025; Song et al., 2025). Moreover, existing methods that partially recover generative performance typically rely on knowledge distillation with large-scale data (inbillions of tokens) and compute, which can be impractical (Muralidharan et al., 2024; Sreenivas et al., 2024). These limitations motivate closer analysis of pruning-induced failure modes and an examination of how much recovery is achievable under realistic post-training constraints. Rather than proposing new pruning algorithm, our goal is to characterize the limits of layer pruning for generative reasoning and to identify practical regimes in which it remains viable. of layers (Yang et al., 2024; Men et al., 2025; Gromov et al., 2024; Song et al., 2024). However, this success has not consistently extended to generative reasoning tasks such as GSM8K, which require multi-step generation to arrive at correct solution (Chen et al., 2024; Men et al., 2025; Gromov et al., 2024; Wang et al., 2025). This discrepancy raises questions about the extent to which layers are redundant across different task contexts. In this paper, we make the following contributions: We demonstrate that generative reasoning tasks are substantially more sensitive to layer pruning than classification benchmarks, with even single-layer removal causing severe degradation, underscoring the depth dependence of such tasks. We provide systematic analysis of pruning-induced failure modes in generative settings. Beyond surfacelevel text degradation, we show that pruning disrupts core algorithmic abilities such as arithmetic computation and valid syntactic generation, which directly impairs multi-step reasoning. Under realistic post-training constraints, we propose supervised finetuning with Self-Generated Responses (SGR) as simple recovery strategy. We show that this SGR finetuning consistently outperforms finetuning on external open-source datasets, achieving strong retention on classification tasks and also on generative benchmarks at moderate pruning ratios. Finally, we show that even the strongest recovery achieved under these constraints fails to fully restore arithmetic and syntactic capabilities. This exposes fundamental limitation of post-pruning recovery for generative reasoning and suggests that, despite ap"
[03.02.2026 17:29] Mistral response. {"id": "cdbe719a0fc140c29e58354a871e01d0", "created": 1770139781, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1567, "total_tokens": 1584, "completion_tokens": 17, "num_cached_tokens": 1566}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Department of Computer Science, New York University Abu Dhabi\"]\n```"}}]}
[03.02.2026 17:29] Response: ```python
["Department of Computer Science, New York University Abu Dhabi"]
```
[03.02.2026 17:29] Deleting PDF ./assets/pdf/2602.01997.pdf.
[03.02.2026 17:29] Success.
[03.02.2026 17:29] Downloading and parsing paper https://huggingface.co/papers/2602.01983.
[03.02.2026 17:29] Downloading paper 2602.01983 from https://arxiv.org/pdf/2602.01983v1...
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 3 8 9 1 0 . 2 0 6 2 : r Li Auto Base Model Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning Xintian Shen Jiawei Chen Lihao Zheng Hao Ma Tao Wei Kun Zhan Existing Tool-Integrated Reasoning (TIR) models have effectively extended the questionanswering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLMs responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from mere tool user into tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86% and +23.04% on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent. { Last Update Date: February 2, 2026 # Correspondence: zhankun@lixiang.com In recent years, Large Language Models (LLMs) [23, 1, 10, 36, 3, 7, 29"
[03.02.2026 17:29] Response: ```python
[]
```
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 3 8 9 1 0 . 2 0 6 2 : r Li Auto Base Model Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning Xintian Shen Jiawei Chen Lihao Zheng Hao Ma Tao Wei Kun Zhan Existing Tool-Integrated Reasoning (TIR) models have effectively extended the questionanswering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLMs responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from mere tool user into tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86% and +23.04% on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent. { Last Update Date: February 2, 2026 # Correspondence: zhankun@lixiang.comIn recent years, Large Language Models (LLMs) [23, 1, 10, 36, 3, 7, 29, 18] have achieved significant breakthroughs, demonstrating robust knowledge capabilities in tasks such as language understanding and complex reasoning [2]. To further enhance the practical utility of LLMs, existing research has primarily focused on incorporating external tools to transcend their inherent limitations. Traditional tool-augmented approaches [13, 26] typically rely on predefined workflows to orchestrate tool invocation. However, such rigid paradigms struggle to generalize to open and uncertain environments. While multi-agent systems [34, 25, 15, 14] enhance flexibility by employing central model for Co-first author Technique Leader Supervisor Preprint. Figure 1: Comparison of tool-creating agents. (a) For this specific math problem, the standard Chain-of-Thought (CoT) [33, 12] method fails and makes errors even during simple calculations. (b) Previous tool creation methods typically solve problems by generating code specific to the current instance. However, these tools are tailored solely to the immediate problem, making them nonreusable for other tasks and still prone to errors. (c) Ours. We propose framework capable of reusing tool creation experience. During the inference process for task solving, UCT can utilize, create, and self-evolve existing tools. Furthermore, we design an offline memory consolidation module to generalize tool memory and transform it into reusable tool experience assets. planning and delegating sub-tasks to tool-using sub-agents, the deployment of multiple models incurs additional computational costs and introduces interaction latency. With the advancement of thought augmented models [33, 10], Tool Integrated Reasoning (TIR) methods [21, 4] exemplified by the ReAct [37] paradigm have emerged. The core philosophy of TIR involves enabling the model to explicitly generate reasoning traces during the inference process, autonomously invoke tools, and make iterative decisions based on feedback from the external environment. Consequently, TIR agents are capable of dynamically planning multi-step operations, which solves more end-to-end problems in open-world tasks. However, tools employed in existing TIR or tool-using frameworks typically manifest in two forms. The first relies on manual definition, which entails laborious tool construction efforts. Moreover, such hand-crafted tools inevitably fail to cover the exhaustive range of problem-solving requirements during reasoning [19, 22]. The second approach involves generating ad-hoc code to address the immediate problem [8, 5]. However, these methods introduce significant uncertainty, as the generated code may be erroneous, and even when valid tool is produced, the lack of persistence mechanisms restricts the agent to single-use scenarios. Although tool creation has emerged in agent research that allows for the creation of autonomous tools during reasoning [20, 38, 30], these methods are inherently limited. Figure 1 compares existing tool-creating agents. They tend to construct tools bespoke to specific tasks, rendering them single-use. This prevents the agent from internalizing these resource-intensive creations into reusable library of experiential assets. To overcome the shortcomings of current agents, we introduce self-evolving tool construction paradigm. Mimicking human problem-solving, our agent autonomously explores potential strategies when confronting complex tasks and encapsulates these experiences into persistent tools. By consolidating recurring sub-capabilities into reusable library, the agent ensures their availability for future instances. This dynamic mechanism fosters continuous evolution during reasoning, effectively breaking through the rigid boundaries of existing frameworks. In this paper, we propose self-evolving agent that transforms from tool User to Creator via Training-Free experience reuse (UCT). This framework enables the flexible and autonomous creation and execution of tools on demand, allowing the agent to absorb experience from reasoning and evolve accordingly. Built upon the ReAct paradigm, our architecture consists of three distinct modules: the Online Task Loop, the Online Build Loop, and Offline Memory Consolidation. The online task loop focuses on online problem-solving and triggers the online build loop whenever the agent requests tool that does not yet exist. To ensure system stability, the tool creation process is constrained and incorporates rigorous testing and review mechanisms to guarantee t"
[03.02.2026 17:29] Mistral response. {"id": "a45765c7be284609b93e250e43d2b7ff", "created": 1770139786, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1324, "total_tokens": 1336, "completion_tokens": 12, "num_cached_tokens": 1323}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Li Auto\"\n]\n```"}}]}
[03.02.2026 17:29] Response: ```python
[
    "Li Auto"
]
```
[03.02.2026 17:29] Deleting PDF ./assets/pdf/2602.01983.pdf.
[03.02.2026 17:29] Success.
[03.02.2026 17:29] Downloading and parsing paper https://huggingface.co/papers/2601.23000.
[03.02.2026 17:29] Downloading paper 2601.23000 from https://arxiv.org/pdf/2601.23000v1...
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Mano: Restriking Manifold Optimization for LLM Training Yufei Gu 1 Zeke Xie 1 6 2 0 2 0 3 ] . [ 1 0 0 0 3 2 . 1 0 6 2 : r a "
[03.02.2026 17:29] Response: ```python
[]
```
[03.02.2026 17:29] Extracting affiliations from text.
[03.02.2026 17:29] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Mano: Restriking Manifold Optimization for LLM Training Yufei Gu 1 Zeke Xie 1 6 2 0 2 0 3 ] . [ 1 0 0 0 3 2 . 1 0 6 2 : r aWhile large language models (LLMs) have emerged as significant advancement in artificial intelligence, the hardware and computational costs for training LLMs are also significantly burdensome. Among the state-of-the-art optimizers, AdamW relies on diagonal curvature estimates and ignores structural properties, while Muon applies global spectral normalization at the expense of losing curvature information. In this study, we restriked manifold optimization methods for training LLMs, which may address both optimizers limitations, while conventional manifold optimization methods have been largely overlooked due to the poor performance in large-scale model optimization. By innovatively projecting the momentum onto the tangent space of model parameters and constraining it on rotational Oblique manifold, we propose novel, powerful, and efficient optimizer Mano that is the first to bridge the performance gap between manifold optimization and modern optimizers. Extensive experiments on the LLaMA and Qwen3 models demonstrate that Mano consistently and significantly outperforms AdamW and Muon even with less memory consumption and computational complexity, respectively, suggesting an expanded Pareto frontier in terms of space and time efficiency. 1. Introduction Large Language Models (LLMs) are represented as major milestone in artificial intelligence and computing technology (Kumar, 2024; Gao et al., 2025). Nevertheless, training LLMs with billions of parameters requires specialized hardware accelerators, such as GPUs and NPUs, which consumes sunstantial energy and result in enormous computational costs (Samsi et al., 2023; Chowdhury et al., 2025). 1xLeaF Lab, The Hong Kong University of Science and Technology to: Yufei Gu <ygu167@connect.hkust-gz.edu.cn>, Zeke Xie <zekexie@hkust-gz.edu.cn>. Correspondence (Guangzhou). Preprint. February 2, 2026. 1 Consequently, advanced optimization methods are critical for reducing the training costs of LLMs. Adam is widely regarded as one of the most popular optimizers in deep learning, with its variants being extensively used to train deep neural networks (DNNs) across wide range of tasks (Kingma, 2014). In particular, AdamW, which decouples weight decay from the original gradient update of Adam, has been the dominant optimizer in training LLMs with broad infrastructure support for large-scale distributed training (Loshchilov & Hutter, 2017; Kunstner et al., 2024). However, by relying on the diagonal estimates of per-parameter curvature, Adam-based optimizers ignore spectral information and fail to capture the subspace structures of the parameter matrix. To address this limitation, Muon introduces the Newton-Schulz iteration to approximate matrix orthogonalization, allowing uniform exploration across all spectral directions in the loss landscape (Jordan et al., 2024). However, this spectral normalization strategy eliminates the curvature information encoded in the gradient and momentum, which may lead to sub-optimal performance on certain occasions (Su, 2025). For optimization problems with so-called manifold structure, algorithms have been developed to exploit this special structure from the perspective of differential geometry and numerical analysis, referred to as manifold optimization methods (Absil et al., 2008; Hu et al., 2020; Fei et al., 2025). However, these traditional manifold optimization methods have been overlooked for LLMs. In this study, we seek to adapt and extend manifold optimization methods to LLM training, where the underlying manifold structure of natural language or optimal parameters is not explicitly known or well understood, relaxing the constraints and assumptions typically required. Instead of retracting and constraining the parameters onto some manifolds surfaces, we demonstrate that by only projecting the momentum onto the tangent vector spaces of the parameters and mapping it to the Oblique manifold, the constrained gradient steps emerged as simple yet effective learning direction in the solution space with strong escape-from-local-minima properties. Furthermore, we demonstrate the empirical advantages of periodically rotating the Oblique manifold, process equivalent to an alternating column-row normalization scheme applied at each optimization step. Mano: Restriking Manifold Optimization for LLM Training (Zhao et al., 2024b). Its popularity stems from its simplified design, flexibility in per-parameter adaptive learning rate, and robustness in performance across diverse domains. However, the firstand second-moment estimates of AdamW consume double the memory footprint of model weights or gradients, resulting in significant memory overhead, especially for LLMs at scale. Several approaches have emerged to design more memory-efficient optimizers. Adam-mini leverages block-wise learning rate schedules based on Hessian partitions (Zhang et al., 2024a; Wang et al., 2025); Lion uses momentum-sign updates to eliminate the need of second moment (Chen et al., 2023), and Cautious-Adam/Lion applies gradient-aligned selective updates (Liang et al., 2024); SOAP instead applies AdamW updates in the Shampoo eigenbasis while amortizing eigendecomposition costs across multiple steps (Gupta et al., 2018; Vyas et al., 2024). Other notable methods include SWAN (Ma et al., 2024), MARS (Yuan et al., 2024), Sophia (Liu et al., 2023), and etc. Another particularly promising line of research focuses on matrix-based spectral preconditioning methods. Muon, introduced by Jordan et al. (2024) in 2023, utilized the Newton-Schulz iteration to perform spectral normalization on the update steps. This approximation to the matrix-sign function produces semi-orthogonal momentum update that normalized the magnitude at all spectral directions, including those low-magnitude but important directions for model generalization. Empirical studies have later extended Muon to scaled-up LLM training with stability, and demonstrated improved efficiency with halved memory consumption in comparison to AdamW (Liu et al., 2025; Shah et al., 2025; Team et al., 2025; Zeng et al., 2025). Benchmarking studies also demonstrate that matrix-based optimizers with spectral preconditioning (e.g., Kron, Muon, SOAP) often outperform scalar-based counterparts (e.g., AdamW, Lion, MARS), though no optimizer significantly outperforms in every tested scenario (Schlott"
[03.02.2026 17:29] Mistral response. {"id": "f39e7ead33224d0cacd619bbb215ec39", "created": 1770139794, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1478, "total_tokens": 1500, "completion_tokens": 22, "num_cached_tokens": 1477}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"1xLeaF Lab, The Hong Kong University of Science and Technology\"]\n```"}}]}
[03.02.2026 17:29] Response: ```python
["1xLeaF Lab, The Hong Kong University of Science and Technology"]
```
[03.02.2026 17:29] Deleting PDF ./assets/pdf/2601.23000.pdf.
[03.02.2026 17:29] Success.
[03.02.2026 17:29] Downloading and parsing paper https://huggingface.co/papers/2602.00130.
[03.02.2026 17:29] Downloading paper 2602.00130 from https://arxiv.org/pdf/2602.00130v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"On the Relationship Between Representation Geometry and Generalization in Deep Neural Networks Sumit Yadav 1 1Institute of Engineering, Pulchowk Campus, Tribhuvan University, Nepal 076bct088.sumit@pcampus.edu.np Abstract. Understanding the factors that determine neural network generalization remains fundamental challenge in deep learning theory. We investigate the relationship between the geometry of learned represen tations and model performance through systematic empirical studies spanning vision and language domains. Analyzing 52 pretrained ImageNet classifiers across 13 architecture families, we demonstrate that effective dimensionan unsupervised geometric metric requiring no labelsstrongly predicts classification accuracy. Output effective dimension shows the strongest partial correlation with accuracy (partial  = 0.75,  < 1010) after controlling for model capacity, while total compressionthe logratio of output to input effective dimensionalityachieves  = 0.65 (partial  = 0.72). These dual geometric signatures form complemen tary framework: output effective dimension captures representation richness while compression captures information refinement. Our findings replicate across indistribution (ImageNet) and transfer (CIFAR10) settings. We demonstrate crossdomain generalization: effective dimension metrics predict performance for 8 encoder models on NLP tasks (SST2, MNLI) and 15 decoderonly LLMs (GPT2, OPT, Qwen, SmolLM, Phi) on AG News, where compression correlates with representation quality ( = 0.69,  = 0.004) while model size does not ( = 0.07). We establish bidirectional causality through controlled intervention: degrading geometry via noise injection causes accuracy loss ( = 0.94,  < 109), while improving geometry via PCA projection maintains accuracy across multiple architectures (mean 0.03pp loss at 95% variance across ResNet18, ResNet34, DenseNet121). Critically, this relationship is noise-type agnostic: Gaussian ( = 0.94), Uniform ( = 0.96)"
[03.02.2026 17:30] Response: ```python
["Institute of Engineering, Pulchowk Campus, Tribhuvan University, Nepal"]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2602.00130.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2602.02354.
[03.02.2026 17:30] Downloading paper 2602.02354 from https://arxiv.org/pdf/2602.02354v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Albert Kwok, Zheyuan Hu, Dounia Hammou Department of Computer Science and Technology, University of Cambridge, Cambridge, UK. {ak2441, zh369, dh706}@cam.ac.uk denotes equal contribution. 6 2 0 2 2 ] . [ 1 4 5 3 2 0 . 2 0 6 2 : r Figure 1. (left:) 3D scene rendered with our INR textures, showcasing high visual quality and straightforward deployment. (right:) three-channel mipmap pyramid represented by an MLP. "
[03.02.2026 17:30] Response: ```python
["University of Cambridge"]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2602.02354.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2602.02287.
[03.02.2026 17:30] Downloading paper 2602.02287 from https://arxiv.org/pdf/2602.02287v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages Isaac Chung1, Linda Freienthal1 1Zendesk first.last@zendesk.com 6 2 0 2 2 ] . [ 1 7 8 2 2 0 . 2 0 6 2 : r a "
[03.02.2026 17:30] Response: ```python
["Zendesk"]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2602.02287.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2602.01970.
[03.02.2026 17:30] Downloading paper 2602.01970 from https://arxiv.org/pdf/2602.01970v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 0 7 9 1 0 . 2 0 6 2 : r 2026-02Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models Yun Qu1,2, Qi Wang1,, Yixiu Mao1, Heming Zou1,2,, Yuhang Jiang1, Weijie Liu2, Clive Bai2, Kai Yang2, Yangkun Chen2, Saiyong Yang2,, Xiangyang Ji1, 1Department of Automation, Tsinghua University 2LLM Department, Tencent (cid:66) cheemswang@mail.tsinghua.edu.cn, stevesyang@tencent.com, xyji@tsinghua.edu.cn "
[03.02.2026 17:30] Response: ```python
[
    "Department of Automation, Tsinghua University",
    "LLM Department, Tencent"
]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2602.01970.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2602.00192.
[03.02.2026 17:30] Downloading paper 2602.00192 from https://arxiv.org/pdf/2602.00192v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange Elif Nebioglu * 1 Emirhan Bilgic * 2 3 Adrian Popescu "
[03.02.2026 17:30] Response: ```python
[]
```
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange Elif Nebioglu * 1 Emirhan Bilgic * 2 3 Adrian PopescuModern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit dramatic drop in accuracy (e.g., from 91% to 55%), frequently approaching chance level. We provide theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https: //github.com/emirhanbilgic/INP-X. 6 2 0 2 0 3 ] . [ 1 2 9 1 0 0 . 2 0 6 2 : r 1. Introduction Inpainting, the task of filling masked regions with plausible content, has become mainstream image editing capability through diffusion-based tools (Rombach et al., 2022; Podell et al., 2024) and commercial services (DeepImage, 2026). *Equal contribution 1Independent Researcher 2Universite Sorbonne, Pierre et Marie Curie, ISIR 3Institut Polytechnique de Paris, U2IS 4Universite Paris-Saclay, CEA, LIST. Correspondence to: Elif Nebioglu <elifnebiogllu@gmail.com>, Emirhan Bilgic <emirhan.bilgic@ip-paris.fr>. Preprint. February 3, 2026. This accessibility poses significant risks for misinformation and content authenticity (Verdoliva, 2020), making reliable detection of inpainted content critical. Both academic methods (Ojha et al., 2023; Corvi et al., 2023) and commercial APIs (SightEngine, 2026; Hive Moderation, 2026) report high detection accuracy (>90%) on benchmark datasets. However, fundamental question remains: what are these detectors actually learning? For inpainting, which synthesizes only local region, we would expect detectors to focus on the generated content within the edited region. Instead, we show that many state-of-the-art detectors rely primarily on global artifacts introduced by the image generation pipeline, exploiting form of shortcut learning (Geirhos et al., 2020) that undermines their intended purpose. This behavior occurs because diffusion-based inpainting processes the entire image through VAE encoder-decoder, leading to subtle yet widespread spectral shift across the image. This global fingerprint provides trivial detection signal that bypasses the need to identify locally generated content and calls into question the robustness of AI-generated image detectors. We address this problem with the following contributions: We introduce INP-X, illustrated in Figure 1, that surgically restores original pixels outside the edited region while preserving the generated content within the mask. If detectors truly identify synthetic content, they should spot it in exchanged images since the fake content remains intact. We provide theoretical analysis and experimental validation linking the observed spectral shift to high-frequency attenuation caused by VAE information bottleneck constraints (Theorem 3.2), and show that our exchange operation minimizes distributional divergence by eliminating background artifacts (Theorem 3.4). We construct 90K-image benchmark extending SemiTruths across 4 datasets and 3 inpainting models, with matched real/standard/exchanged triplets. We evaluate 11 pretrained detectors and 2 commercial APIs, demonstrating consistent and severe performance degradation under our attack. Notably, commercial systems (HiveModeration, Sightengine) drop from >91% to 55% accuracy, approaching random chance. AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange 2025b), which leverages spectral distributions as invariant patterns, and Artifact Purification Networks (Meng et al., 2024), which separate artifact features from semantic content via frequency-band proposals. Universal Detectors and Generalization. The quest for detectors that generalize across generators has yielded several influential approaches. (Ojha et al., 2023) proposes learning generator-agnostic representations in CLIPs feature space, achieving strong cross-generator performance. Similarly, (Cozzolino et al., 2024a;b) leverage CLIP embeddings with lightweight classifiers, demonstrating impressive generalization and zero-shot capabilities. However, recent studies question whether CLIP-based detectors rely on artifact cues or semantic shortcuts. (Chu et al., 2025) shows that patch shuffling forces models toward artifact-oriented representations, while (Yan et al., 2025a) introduces NULLspace projection to decouple semantic information from forgery-relevant features. Shortcut Learning and Dataset Biases. Despite reported successes, mounting evidence suggests that detector performance may originate in dataset biases rather than genuine detection capabilities. (Rajan & Lee, 2025) argue that detectors largely ignore real-image features, instead relying on easy-to-learn shortcuts in fake images. (Ha et al., 2024) shows that detectors struggle when generators improve sufficiently. (Yan et al., 2025b) provides rigorous sanity check, revealing that many reported gains stem from dataset biases. (Grommelt et al., 2024) exposes systematic biases related to JPEG compression and resolution. (Guillaro et al., 2025) introduce bias-free training paradigm, while (Li et al., 2024) highlight persistent vulnerabilities. Our work provides controlled intervention that demonstrates the phenomenon in the inpainting setting. Manipulation, Localization, and Forensic Analysis. Beyond binary detection, some work tries to address localizing manipulated regions in images. Classical splice detection methods (Farid, 2009) analyze inconsistencies in JPEG compression artifacts, lighting, and noise patterns. P"
[03.02.2026 17:30] Mistral response. {"id": "4fb691ebbae54f1295d824f5504f28dc", "created": 1770139833, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1464, "total_tokens": 1518, "completion_tokens": 54, "num_cached_tokens": 1463}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Independent Researcher\",\n    \"Universite Sorbonne, Pierre et Marie Curie, ISIR\",\n    \"Institut Polytechnique de Paris, U2IS\",\n    \"Universite Paris-Saclay, CEA, LIST\"\n]\n```"}}]}
[03.02.2026 17:30] Response: ```python
[
    "Independent Researcher",
    "Universite Sorbonne, Pierre et Marie Curie, ISIR",
    "Institut Polytechnique de Paris, U2IS",
    "Universite Paris-Saclay, CEA, LIST"
]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2602.00192.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2601.22296.
[03.02.2026 17:30] Downloading paper 2601.22296 from https://arxiv.org/pdf/2601.22296v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ParalESN: Enabling parallel information processing in Reservoir Computing Matteo Pinna * 1 Giacomo Lagomarsini * 1 Andrea Ceni 1 Claudio Gallicchio 1 Abstract Reservoir Computing (RC) has established itself as an efficient paradigm for temporal processing. However, its scalability remains severely constrained by (i) the necessity of processing temporal data sequentially and (ii) the prohibitive memory footprint of high-dimensional reservoirs. In this work, we revisit RC through the lens of structured operators and state space modeling to address these limitations, introducing Parallel Echo State Network (ParalESN). ParalESN enables the construction of high-dimensional and efficient reservoirs based on diagonal linear recurrence in the complex space, enabling parallel processing of temporal data. We provide theoretical analysis demonstrating that ParalESN preserves the Echo State Property and the universality guarantees of traditional Echo State Networks while admitting an equivalent representation of arbitrary linear reservoirs in the complex diagonal form. Empirically, ParalESN matches the predictive accuracy of traditional RC on time series benchmarks, while delivering substantial computational savings. On 1-D pixel-level classification tasks, ParalESN achieves competitive accuracy with fully trainable neural networks while reducing computational costs and energy consumption by orders of magnitude. Overall, ParalESN offers promising, scalable, and principled pathway for integrating RC within the deep learning landscape. 6 2 0 2 9 ] . [ 1 6 9 2 2 2 . 1 0 6 2 : r 1. Introduction Reservoir Computing (RC) has emerged as simple yet powerful paradigm for harnessing the rich dynamics of recurrent systems for learning and prediction (Nakajima & Fischer, 2021; Lukosevicius & Jaeger, 2009). By fixing *Equal contribution. 1Department of Computer Science, University of Pisa, Correspondence to: Matteo Pinna <matteo.pinna@di.unipi.it>, Giacomo Lagomarsini <giacomo.lagomarsini"
[03.02.2026 17:30] Response: ```python
["Department of Computer Science, University of Pisa"]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2601.22296.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2601.21968.
[03.02.2026 17:30] Downloading paper 2601.21968 from https://arxiv.org/pdf/2601.21968v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 9 2 ] . [ 1 8 6 9 1 2 . 1 0 6 2 : r OVD: On-policy Verbal Distillation Jing Xiong 1 Hui Shen 1 Shansan Gong 1 Yuxin Cheng 1 Jianghan Shen 2 Chaofan Tao 3 Haochen Tan 3 Haoli Bai 3 Lifeng Shang 3 Ngai Wong "
[03.02.2026 17:30] Response: ```python
[]
```
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 9 2 ] . [ 1 8 6 9 1 2 . 1 0 6 2 : r OVD: On-policy Verbal Distillation Jing Xiong 1 Hui Shen 1 Shansan Gong 1 Yuxin Cheng 1 Jianghan Shen 2 Chaofan Tao 3 Haochen Tan 3 Haoli Bai 3 Lifeng Shang 3 Ngai WongKnowledge distillation offers promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student models exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (09) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io. 1. Introduction Large language models (LLMs) demonstrate remarkable capabilities across diverse tasks, yet their ability to perform complex multi-step reasoning remains fundamental challenge (Wei et al., 2022; Guo et al., 2025a). While recent advances in reinforcement learning (RL) enable models to develop long-horizon reasoning behaviors (Shao et al., 1The University of Hong Kong, Hong Kong, China 2Nanjing University, Nanjing, China 3Huawei Technologies, China. Correspondence to: Jing Xiong <junexiong@connect.hku.hk>. Preprint. January 30, 2026. 2024; Singh et al., 2023), the high computational costs and resource requirements of training large reasoning models create significant barrier to widespread deployment. Knowledge distillation offers promising solution by transferring reasoning capabilities from powerful teacher models to more efficient student models (Hinton et al., 2015; Hsieh et al., 2023). However, existing distillation approaches face limitations when applied to RL, particularly in terms of memory efficiency and the ability to leverage verbal feedback (Shinn et al., 2023). The traditional knowledge distillation methods for LLMs operate at the token level, requiring the teacher model to output probability distributions over the entire vocabulary at each decoding step (Kim & Rush, 2016; Gu et al., 2023). While this fine-grained supervision provides rich gradient signals, it introduces severe memory bottleneck for RL. For example, with batch size = 8, = 4 samples per problem, sequence length = 8192, and vocabulary size = 152K, storing the Qwen-7B models logits in FP32 consumes around 160 GB of memory per batch, far exceeding modern accelerators capacity. This memory cost scales linearly with trajectory length, making token-level distillation impractical for long-horizon reasoning chains in complex problems. Additionally, token-level distillation fail to capture the hierarchical structure of reasoning, and strictly matching the student and teacher distributions constrains the models exploration. More broadly, the potential of distillation methods that incorporate verbal feedback from environment agents remains underexplored. Recent studies show that training language models with environment agents can substantially enhance models search capabilities (Jin et al., 2025; Sun et al., 2025; Fang et al., 2025). However, the verification capabilities of environment agents, particularly in the context of on-policy distillation (Agarwal et al., 2024), have not been sufficiently studied. This limitation prevents distillation methods from fully leveraging the rich supervision provided by verifiable agents, especially in information retrieval domain. To address these challenges, we introduce On-policy Verbal Distillation (OVD), which reformulates distillation as trajectory matching rather than token-level probability matching, OVD: On-policy Verbal Distillation enabling principled integration of verbal feedback into onpolicy distillation. In OVD, teacher agents provide verbal scores on reasoning correctness to evaluate trajectories, allowing the student model to learn both reasoning patterns and interaction behaviors through RL. By replacing fullvocabulary logit supervision with verbal trajectory evaluation, OVD significantly reduces the memory overhead of distillation. Our main contributions are: We propose On-policy Verbal Distillation (OVD), an on-policy reinforcement learning distillation framework that supervises student trajectories using discrete verbal feedback from teacher models instead of tokenlevel probability matching. This design greatly reduces memory cost and promotes on-policy exploration. We conduct extensive experiments on Web Q&A and mathematical reasoning benchmarks, demonstrating that OVD substantially outperforms existing RL-based web search methods while exhibiting superior sample efficiency. By scaling trajectory sampling on single randomly selected instance, we achieve an 25.7% performance improvement on math benchmarks. We provide theoretical analysis of OVD, showing that its rejection sampling scheme yields unbiased gradient estimates, and demonstrate that an interactive environment agent is key to success on Web Q&A tasks. 2. Why Verbal Distillation? In this section, we explain why OVD adopts verbal scoring over token-level distillation for improved memory efficiency. Memory Bottleneck. Token-level distillation suffers from three fundamental limitations: (i) it treats all tokens equally, ignoring the hierarchical structure of reasoning; (ii) it requires access to the teachers token-level probability distribution, which may be unavailable for black-box models; and (iii) When distillation relies on large-scale rollouts from reasoning model, token-level supervision incurs prohibitive memory overhead, as it requires storing logits over the entire vocabulary for each token in trajectories of length L. In on-policy training with group relative optimization (GRPO) (Shao et al., 2024), mainta"
[03.02.2026 17:30] Mistral response. {"id": "3e6f5434518b4d7ab7a1274de1313742", "created": 1770139848, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1376, "total_tokens": 1415, "completion_tokens": 39, "num_cached_tokens": 1375}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"The University of Hong Kong, Hong Kong, China\",\n    \"Nanjing University, Nanjing, China\",\n    \"Huawei Technologies, China\"\n]\n```"}}]}
[03.02.2026 17:30] Response: ```python
[
    "The University of Hong Kong, Hong Kong, China",
    "Nanjing University, Nanjing, China",
    "Huawei Technologies, China"
]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2601.21968.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2601.21759.
[03.02.2026 17:30] Downloading paper 2601.21759 from https://arxiv.org/pdf/2601.21759v1...
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Meet Doshi 1 Vishwajeet Kumar 1 Yulong Li 1 Jaydeep Sen "
[03.02.2026 17:30] Response: ```python
[]
```
[03.02.2026 17:30] Extracting affiliations from text.
[03.02.2026 17:30] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Meet Doshi 1 Vishwajeet Kumar 1 Yulong Li 1 Jaydeep SenGeneral-purpose open-domain dense retrieval systems are usually trained with large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches sample them uniformly, proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models. We propose Inf-DDS, novel reinforcement learningdriven sampling framework that adaptively reweighs training datasets guided by influence-based reward signals and is much more lightweight w.r.t. GPU consumption. Our technique iteratively refines the sampling policy, prioritizing datasets that maximize model performance on target development set. We evaluate the efficacy of our sampling strategy on wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being 1.5 4 cheaper in GPU compute. Our sampling strategy achieves 5.03 absolute NDCG@10 improvement while training multilingual bge-m3 model and an absolute NDCG@10 improvement of 0.94 while training all-MiniLM-L6-v2, even when starting from expert-assigned weights on large pool of training datasets. 6 2 0 2 9 2 ] I . [ 1 9 5 7 1 2 . 1 0 6 2 : r 1. Introduction Text-to-embedding based dense retriever models have recently gained huge popularity with their strong results across various benchmarks (Karpukhin et al., 2020; Izacard et al., 2022; Wang et al., 2023; Chen et al., 2024; BehnamGhader et al., 2024). These models are prized for their general1IBM Research AI. Correspondence to: Meet Doshi <meet@ibm.com>. Figure 1: Trade-off between training time (GPU hours) and average NDCG@10 on the MLDR-13 test set when optimizing bge-m3-dense on the MLDR-13 dev set. izability across domains without domain-specific tuning, typically trained on vast, diverse datasets. For instance, the Sentence-Transformers project, which develops generic sentence embeddings, utilized billions of instances across multiple datasets, with domain-specific data varying widely in size. However, larger datasets dont inherently improve embedding quality, making it crucial to identify the most informative datasets and their optimal proportions for training. Effective sampling strategies are essential to prevent overfitting or underfitting, making dataset selection central challenge in developing robust, generalizable, or domainspecific embedding models. While random sampling is common default, it is limited by ignoring data source informativeness when sampling from large training datasets. Alternatives include temperature sampling and instance-based proportional sampling. more intensive approach involves creating ad-hoc sampling distributions via iterative experimentation, termed expert weights, requiring expert evaluation. However, these strategies are static and predefined, often suboptimal compared to the unknown ideal distribution for maximizing model performance. dynamic sampling approach, capable of adaptation, may better approximate this optimal distribution. There has consequently been substantial interest in mak1 Influence Guided Sampling for Domain Adaptation of Text Retrievers ing sampling adaptive. Gradient-based approaches such as DDS (Wang et al., 2020a) and its multi-target extension (Wang et al., 2020b) use gradient-derived rewards to adjust the training distribution online. DoGE (Fan et al., 2024) proposes generalization estimation function to approximate data influence, while methods like DoReMi (Xie et al., 2023a; Engstrom et al., 2024) rely on proxy models to estimate dataset utility. In practice, these dynamic methods face two main challenges: (1) instability and high variance introduced by stochastic gradients, which we empirically demonstrate in Section 5, and (2) substantial computational overhead when proxy models or expensive estimators are required. Together, these limitations motivate the design of an online, adaptive optimization strategy that can learn sampling weights efficiently and robustly while remaining computationally tractable. In this paper, we propose Influence-guided Dynamic Data Sampling strategy (Inf-DDS), computationally efficient novel algorithm that addresses the critical challenge of data sampling for domain adaptation, overcoming limitations of existing gradient-based methods. Inf-DDS iteratively takes small gradient-update steps on each domains data, monitoring the impact on the downstream metric. Domains demonstrating greater performance improvements are subsequently assigned higher rewards. This adaptive sampling strategy, inspired by recent influence-based methods (Koh & Liang, 2017; Bae et al., 2022; Fan et al., 2024; Yu et al., 2024; Xia et al., 2024) for sampling training data across multiple domains, focuses learning on the most informative subsets of data. Our algorithm offers three key advantages over prior work: (1) it eliminates the dependence on noisy gradient estimates for reward computation, (2) it efficiently reuses computations from updating the parameterized sampling distribution  parameters to also update the model parameters , making it much more computationally efficient and (3) it produces more reliable and interpretable sampling trajectories for better downstream gains. Our contributions in this work are as follows: a. We propose Inf-DDS, an influence-guided reinforcement learning approach that learns to adjust sampling probabilities across diverse training datasets, improving targetdomain retrieval performance while being much more computationally efficient. b. We validate Inf-DDS against robust benchmarks, including BEIR datasets (Thakur et al., 2021), SentenceTransformers all-MiniLM-L6-v2 (Reimers & Gurevych, 2019) and MLDR (Chen et al., 2024), demonstrating significant improvements while optimizing for target domain. 2. Related Work Recent work on training models with large, diverse data pools has explored both simple heuristic sampling and more adaptive, learned reweighting schemes. common practice is to sample languages uniformly or via temperature-scaled distribution that interpolates between uniform and sizeproportional sampling. For example in language pretraining, Cooldown (Li"
[03.02.2026 17:30] Mistral response. {"id": "f28f2443830d4a17bfd1930f6724e980", "created": 1770139856, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1402, "total_tokens": 1412, "completion_tokens": 10, "num_cached_tokens": 1401}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"IBM Research AI\"]\n```"}}]}
[03.02.2026 17:30] Response: ```python
["IBM Research AI"]
```
[03.02.2026 17:30] Deleting PDF ./assets/pdf/2601.21759.pdf.
[03.02.2026 17:30] Success.
[03.02.2026 17:30] Downloading and parsing paper https://huggingface.co/papers/2602.02338.
[03.02.2026 17:30] Downloading paper 2602.02338 from https://arxiv.org/pdf/2602.02338v1...
[03.02.2026 17:31] Extracting affiliations from text.
[03.02.2026 17:31] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs Yu Liang * 1 Zhongjin Zhang * 1 Yuxuan Zhu 2 Kerui Zhang 2 Zhiluohan Guo 2 Wenhang Zhou 2 Zonqi Yang 2 Kangle Wu 2 Yabo Ni 3 Anxiang Zeng 3 Cong Fu 4 Jianxin Wang 1 Jiazhi Xia 1 6 2 0 2 2 ] I . [ 1 8 3 3 2 0 . 2 0 6 2 : r a "
[03.02.2026 17:31] Response: ```python
[
    "Huazhong University of Science and Technology",
    "Alibaba Group",
    "Meituan"
]
```
[03.02.2026 17:31] Deleting PDF ./assets/pdf/2602.02338.pdf.
[03.02.2026 17:31] Success.
[03.02.2026 17:31] Downloading and parsing paper https://huggingface.co/papers/2602.01984.
[03.02.2026 17:31] Downloading paper 2602.01984 from https://arxiv.org/pdf/2602.01984v1...
[03.02.2026 17:32] Extracting affiliations from text.
[03.02.2026 17:32] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 4 8 9 1 0 . 2 0 6 2 : r Published as conference paper at ICLR ENHANCING MULTI-IMAGE UNDERSTANDING THROUGH DELIMITER TOKEN SCALING Minyoung Lee1, Yeji Park1, Dongjun Hwang1, Yejin Kim1,2, Seong Joon Oh2,3, Junsuk Choe1, 1Sogang University, 2KAIST, 3Tubingen University "
[03.02.2026 17:32] Response: ```python
["Sogang University", "KAIST", "Tubingen University"]
```
[03.02.2026 17:32] Deleting PDF ./assets/pdf/2602.01984.pdf.
[03.02.2026 17:32] Success.
[03.02.2026 17:32] Downloading and parsing paper https://huggingface.co/papers/2602.01897.
[03.02.2026 17:32] Downloading paper 2602.01897 from https://arxiv.org/pdf/2602.01897v1...
[03.02.2026 17:32] Extracting affiliations from text.
[03.02.2026 17:32] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Internal Flow Signatures for Self-Checking and Refinement in LLMs Sungheon Jeong 1 Sanggeon Yun 1 Ryozo Masukawa 1 Wenjun Haung 1 Hanning Chen 1 Mohsen Imani "
[03.02.2026 17:32] Response: ```python
[]
```
[03.02.2026 17:32] Extracting affiliations from text.
[03.02.2026 17:32] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Internal Flow Signatures for Self-Checking and Refinement in LLMs Sungheon Jeong 1 Sanggeon Yun 1 Ryozo Masukawa 1 Wenjun Haung 1 Hanning Chen 1 Mohsen ImaniLarge language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or separate judge after generation. We introduce internal flow signatures that audit decision formation from depthwise dynamics at fixed inter-block monitoring boundary. The method stabilizes token-wise motion via biascentered monitoring, then summarizes trajectories in compact moving readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes culprit depth event and enables targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. Code is available on GitHub. 1. Introduction Large language models (LLMs) often produce fluent answers that are locally consistent yet globally incorrect (Huang et al., 2023; Maynez et al., 2020; Lin et al., 2022; Li et al., 2023). In practical deployments, user typically needs to know not only whether an answer is wrong, but also whether the model was internally confident for the right reasons (Geng et al., 2024). Current safeguards lean on external verification, retrieval, or an additional LLM judge 1Department of Computer Science, University of CalSungheon Jeong Correspondence to: Irvine. ifornia, <sungheoj@uci.edu>. Preprint. February 2, 2026. 1 (Nakano et al., 2021; Lewis et al., 2020; Zheng et al., 2023). These approaches add latency and cost, and they react only after the full generation is produced, while the internal process that formed the decision remains largely unobserved (Gao et al., 2023; Kossen et al., 2024; Farquhar et al., 2024). We take different view of inference. Rather than treating an autoregressive transformer as single input-to-output mapping, we interpret generation as depthwise flow of internal states and intermediate readouts (Belrose et al., 2023; Ferrando et al., 2023; Pal et al., 2023). key lens is how logit competition evolves across depth (Belrose et al., 2023; Chuang et al., 2023): as token decision forms, the top token and its close competitors shift in structured ways (Ferrando et al., 2023; Pal et al., 2023). This yields measurable trace of decision formation that supports internal audits and lightweight self-checking (Elhage et al., 2021; Azaria & Mitchell, 2023; Chen et al., 2024a; Ji et al., 2024; Sriramanan et al., 2024). Unlike Logit lens (Elhage et al., 2021), which inspects what layer encodes, we track how the decision trajectory is shaped across depth, enabling localization of atypical motion to specific internal updates. Turning this intuition into reliable measurements faces two obstacles. First, any fixed global coordinate system can be misleading, since readout-relevant directions and what is linearly decodable can shift with depth (Belrose et al., 2023; Tenney et al., 2019; Ethayarajh, 2019). Second, the monitored boundary typically includes normalization with learned gain and bias, and its placement affects depthwise behavior, introducing depth dependent offsets that can contaminate token-wise motion and complicate depth aggregation (Ba et al., 2016; Xiong et al., 2020). Without resolving these issues, depthwise signatures become unstable and difficult to compare across layers, prompts, or models. This can prevent module level attribution of where the trajectory gets steered off course during generation. We address these obstacles by stabilizing depthwise measurements in local moving frame. We monitor the residual stream at fixed boundary and remove depth dependent token shared offsets, so token motion reflects decision dynamics rather than layer specific shifts. Within each depth window, we build compact readout aligned frame from the top token and close competitors, then align neighboring frames orthogonally so step size, turning, and drift remain Submission and Formatting Instructions for ICML 2026 comparable across depth. These signatures enable self checking by training lightweight validator on geometric flow patterns in depthwise decision formation. From flow features extracted during generation, the validator separates reliable and unreliable regimes by detecting atypical transported step length, turning, and subspace drift in moving readout aligned frame, without modifying the base LLM. Across tasks and models, this supervision is stable and learnable, yielding consistent separation between non hallucination and hallucination like behaviors with minimal overhead. Beyond detection, the same signal localizes single depth localized culprit event. We roll back to the token position where it occurs and regenerate while intervening at only one transformer block. The intervention clamps an abnormally large transported step in the readout aligned low dimensional frame while preserving the orthogonal residual component, producing targeted refinement that reduces hallucination without retraining or modifying the base model. 2. Related Work Hallucination detection and self-checking in LLMs. Prior work mitigates hallucination and factual errors by adding external verification, including retrieval augmentation (Lewis et al., 2020; Nakano et al., 2021), post-hoc checking with an additional language model (Zheng et al., 2023; Li et al., 2023), and faithfulness benchmarks (Maynez et al., 2020; Lin et al., 2022). While effective, these approaches act only after generation, add latency and cost, and treat the base model as black box, offering limited access to the internal decision process that produced the output. Logit-based probing and intermediate readouts. Recent work probes transformer representations via intermediate readouts. Logit Lens (Elhage et al., 2021) and refinements such as Tuned Lens (Belrose et al., 2023) decode logits from hidden states across depth to study "
[03.02.2026 17:32] Mistral response. {"id": "f59ee05a5ab0498a90b3e4184c9a492d", "created": 1770139952, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1505, "total_tokens": 1522, "completion_tokens": 17, "num_cached_tokens": 1504}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Department of Computer Science, University of California, Irvine\"]\n```"}}]}
[03.02.2026 17:32] Response: ```python
["Department of Computer Science, University of California, Irvine"]
```
[03.02.2026 17:32] Deleting PDF ./assets/pdf/2602.01897.pdf.
[03.02.2026 17:32] Success.
[03.02.2026 17:32] Downloading and parsing paper https://huggingface.co/papers/2602.01815.
[03.02.2026 17:32] Downloading paper 2602.01815 from https://arxiv.org/pdf/2602.01815v1...
[03.02.2026 17:32] Extracting affiliations from text.
[03.02.2026 17:32] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery Yunhui Jang 1 Seonghyun Park 1 Jaehyung Kim 2 Sungsoo Ahn 1 6 2 0 2 2 ] . [ 1 5 1 8 1 0 . 2 0 6 2 : r Abstract Multi-agent systems have emerged as powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multiagent system, current frameworks typically assign generic role-based personas such as reviewer or writer or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the scientific DNA of individual agents is essential for high-quality discovery. 1. Introduction Large language models (LLMs) have demonstrated remarkable performance across wide variety of tasks (Singh et al., 2025; Anthropic, 2024; Team et al., 2025; DeepSeek-AI et al., 2025). Beyond direct prompting, recent works have introduced AI agents capable of planning and executing actions over multiple iterations (Yao et al., 2023; Schick et al., 2023; M. Bran et al., 2024). While impressive, singleagent systems often encounter constraints such as bounded context windows and limited perspective diversity. To address this, multi-agent systems have emerged as powerful 1Korea Advanced Institute of Science and Technology (KAIST), South Korea 2Yonsei university, South"
[03.02.2026 17:32] Response: ```python
[
    "Korea Advanced Institute of Science and Technology (KAIST), South Korea",
    "Yonsei university, South"
]
```
[03.02.2026 17:32] Deleting PDF ./assets/pdf/2602.01815.pdf.
[03.02.2026 17:32] Success.
[03.02.2026 17:32] Downloading and parsing paper https://huggingface.co/papers/2602.01618.
[03.02.2026 17:32] Downloading paper 2602.01618 from https://arxiv.org/pdf/2602.01618v1...
[03.02.2026 17:32] Extracting affiliations from text.
[03.02.2026 17:32] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 8 1 6 1 0 . 2 0 6 2 : r SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia Panuthep Tasawong,,*, Jian Gang Ngui, Alham Fikri Aji, Trevor Cohn, Peerat Limkonchotiwat,* VISTEC, Google, AI Singapore panuthep.t_s20@vistec.ac.th, peerat@aisingapore.org "
[03.02.2026 17:32] Response: ```python
['VISTEC', 'Google', 'AI Singapore']
```
[03.02.2026 17:32] Deleting PDF ./assets/pdf/2602.01618.pdf.
[03.02.2026 17:33] Success.
[03.02.2026 17:33] Downloading and parsing paper https://huggingface.co/papers/2602.00521.
[03.02.2026 17:33] Downloading paper 2602.00521 from https://arxiv.org/pdf/2602.00521v1...
[03.02.2026 17:33] Extracting affiliations from text.
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 3 ] . [ 1 1 2 5 0 0 . 2 0 6 2 : r Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory Junhyuk Choi 1 * Sohhyung Park 2 * Chanhee Cho 1 Hyeonchu Park 1 Bugeun Kim 1 Abstract While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce two-phase diagnostic framework for assessing reliability of LLM-as-aJudge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability 1. 1. Introduction Large Language Models (LLMs) have emerged as automated evaluators across diverse domains, commonly referred to as LLM-as-a-Judge (Liu et al., 2023; Gu et al., 2024; Li et al., 2024). This paradigm has been rapidly adopted not only in natural language processing tasks such as summarization (Fabbri et al., 2021; Crupi et al., 2025; Gao et al., 2023) and dialogue evaluation (Mehri & Eskenazi, 2020; Chan et al., 2024), but also extends to visionlanguage models (Ku et al., 2024a; Chen et al., 2024; Lee et al., 2024), and reward modeling for reinforcement learning from human feedback (Wang et al., 2024c; Xu et al., *Equal contribution 1Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea 2Department of Industrial Engineering,"
[03.02.2026 17:33] Response: ```python
[
    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea",
    "Department of Industrial Engineering"
]
```
[03.02.2026 17:33] Deleting PDF ./assets/pdf/2602.00521.pdf.
[03.02.2026 17:33] Success.
[03.02.2026 17:33] Downloading and parsing paper https://huggingface.co/papers/2601.22801.
[03.02.2026 17:33] Downloading paper 2601.22801 from https://arxiv.org/pdf/2601.22801v1...
[03.02.2026 17:33] Extracting affiliations from text.
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Clipping-Free Policy Optimization for Large Language Models Omer Veysel agatan 1 Bars Akg un 1 2 Gozde ul ahin 1 2 Xuandong Zhao 3 6 2 0 2 0 3 ] . [ 1 1 0 8 2 2 . 1 0 6 2 : r Abstract Reinforcement learning has become central to post-training large language models, yet dominant algorithms rely on clipping mechanisms that introduce optimization issues at scale, including zero-gradient regions, reward hacking, and training instability. We propose Clipping-Free Policy Optimization (CFPO), which replaces heuristic clipping with convex quadratic penalty derived from Total Variation divergence constraints, yielding an everywhere-differentiable objective that enforces stable policy updates without hard boundaries. We evaluate CFPO across both reasoning and alignment settings. In reasoning, CFPO matches clipping-based methods on downstream benchmarks while extending the stable training regime. In alignment, CFPO mitigates verbosity exploitation and reduces capability degradation, while achieving competitive instruction-following performance. CFPO requires only one-line code change and no additional hyperparameters. Our results suggest that CFPO is promising drop-in alternative to clipping-based methods for LLM post-training. 1. Introduction Reinforcement learning (RL) has become central component of large language model (LLM) post-training. Early work demonstrated that RL from human feedback (RLHF) could align models with human preferences and instructions (Christiano et al., 2023; Stiennon et al., 2022; Bai et al., 2022; Ouyang et al., 2022), and more recent efforts have shown that RL with verifiable rewards (RLVR) can elicit complex reasoning behaviors (DeepSeek-AI, 2025; OpenAI, 2024b; Google DeepMind, 2025). These successes have established RL as an essential stage in modern LLM training pipelines. 1KUIS AI Center, Koc University, Istanbul, Turkiye Istanbul, Turkiye 3University of Califor2Koc University, Omer Veysel nia, Berkeley, CA, USA. Correspondence to: agatan <oc"
[03.02.2026 17:33] Response: ```python
[
    "KUIS AI Center, Koc University, Istanbul, Turkiye",
    "Koc University",
    "University of California, Berkeley, CA, USA"
]
```
[03.02.2026 17:33] Deleting PDF ./assets/pdf/2601.22801.pdf.
[03.02.2026 17:33] Success.
[03.02.2026 17:33] Enriching papers with extra data.
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 0. Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning.  					AI-generated summary 				 We introduce Green-VLA, a staged Vision-Language-Action (...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 1. Kimi K2.5 is an open-source multimodal agentic model that enhances text and vision processing through joint optimization techniques and introduces Agent Swarm for parallel task execution.  					AI-generated summary 				 We introduce Kimi K2.5, an open-source multimodal agentic model designed to adva...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 2. Vision-DeepResearch introduces a multimodal deep-research paradigm enabling multi-turn, multi-entity, and multi-scale visual and textual search with deep-research capabilities integrated through cold-start supervision and reinforcement learning.  					AI-generated summary 				 Multimodal large langu...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 3. Vision-DeepResearch benchmark addresses limitations in evaluating visual-textual search capabilities of multimodal models by introducing realistic evaluation conditions and improving visual retrieval through multi-round cropped-search workflow.  					AI-generated summary 				 Multimodal Large Langua...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 4. RPG-Encoder framework transforms repository comprehension and generation into a unified cycle by encoding code into high-fidelity Repository Planning Graph representations that improve understanding and reconstruction accuracy.  					AI-generated summary 				 Current repository agents encounter a re...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 5. UniReason integrates text-to-image generation and image editing through a dual reasoning paradigm that enhances planning with world knowledge and uses editing for visual refinement, achieving superior performance on reasoning-intensive benchmarks.  					AI-generated summary 				 Unified multimodal m...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 6. WildGraphBench evaluates GraphRAG performance in realistic scenarios using Wikipedia's structured content to assess multi-fact aggregation and summarization capabilities across diverse document types.  					AI-generated summary 				 Graph-based Retrieval-Augmented Generation (GraphRAG) organizes ext...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 7. A file-system-based dual-agent framework enables large language model agents to perform extended research tasks beyond context window limitations by using persistent storage as external memory.  					AI-generated summary 				 Deep research is emerging as a representative long-horizon task for large ...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 8. A scalable framework for constructing real-world software engineering environments from GitHub pull requests using an efficient building agent with self-verification and hacking detection capabilities.  					AI-generated summary 				 We propose SWE-Universe, a scalable and efficient framework for au...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 9. Deep Research Agents demonstrate capabilities in autonomous information retrieval but show significant gaps when evaluated against expert-level Wikipedia articles using a new live benchmark and comprehensive evaluation framework.  					AI-generated summary 				 Deep Research Agents (DRAs) have demon...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 10. PixelGen is a pixel-space diffusion framework that uses perceptual supervision through LPIPS and DINO-based losses to generate high-quality images without requiring VAEs or latent representations.  					AI-generated summary 				 Pixel diffusion generates images directly in pixel space in an end-to-e...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 11. SLIME is a novel reference-free alignment objective for large language models that decouples preference learning from generation quality through a three-pronged approach combining likelihood maximization, probability stabilization, and dual-margin constraints.  					AI-generated summary 				 Direct ...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 12. RLAnything enhances reinforcement learning for LLMs and agents through dynamic model optimization and closed-loop feedback mechanisms that improve policy and reward model training.  					AI-generated summary 				 We propose RLAnything, a reinforcement learning framework that dynamically forges envir...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 13. PISCES is an annotation-free text-to-video generation method that uses dual optimal transport-aligned rewards to improve visual quality and semantic alignment without human preference annotations.  					AI-generated summary 				 Text-to-video (T2V) generation aims to synthesize videos with high visu...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 14. Mind-Brush presents a unified agentic framework for text-to-image generation that dynamically retrieves multimodal evidence and employs reasoning tools to improve understanding of implicit user intentions and complex knowledge reasoning.  					AI-generated summary 				 While text-to-image generation...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 15. A novel Causal Forcing method addresses the architectural gap in distilling bidirectional video diffusion models into autoregressive models by using AR teachers for ODE initialization, significantly improving video generation performance.  					AI-generated summary 				 To achieve real-time interact...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 16. Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance.  					AI-gener...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 17. FSVideo is a fast transformer-based image-to-video diffusion framework that uses a compressed video autoencoder, diffusion transformer architecture with enhanced layer memory, and multi-resolution generation strategy to achieve high performance with significantly reduced computation time.  					AI-g...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 18. Selective knowledge distillation in autoregressive language models using student-entropy-guided position selection improves accuracy and efficiency while reducing memory and storage requirements.  					AI-generated summary 				 Growing efforts to improve knowledge distillation (KD) in large language...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 19. MLLMs equipped with Cognitive Supersensing and Latent Visual Imagery Prediction demonstrate enhanced cognitive reasoning capabilities through integrated visual and textual reasoning pathways.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have achieved remarkable success in...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 20. Post-training of reasoning large language models can be improved by correcting distribution mismatches between supervised fine-tuning and reinforcement learning stages through importance sampling reweighting of the SFT loss.  					AI-generated summary 				 Post-training of reasoning LLMs is a holist...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 21. Visual Instruction Benchmark for Image Editing introduces a three-level interaction hierarchy for evaluating visual instruction following capabilities in generative models.  					AI-generated summary 				 Recent generative models have achieved remarkable progress in image editing. However, existing ...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 22. A dual-stream framework called InteractAvatar is presented for generating talking avatars that can interact with objects in their environment, addressing challenges in grounded human-object interaction through decoupled perception and planning modules.  					AI-generated summary 				 Generating talk...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 23. Visual metaphor transfer enables creative AI systems to decompose abstract conceptual relationships from reference images and reapply them to new subjects through a multi-agent framework grounded in cognitive theory.  					AI-generated summary 				 A visual metaphor constitutes a high-order form of ...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 24. Re-TRAC is an agentic framework that enhances LLM-based research agents by enabling cross-trajectory exploration and iterative reflection through structured state representations, leading to more efficient and effective problem-solving compared to traditional ReAct approaches.  					AI-generated sum...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 25. Large language model control methods are unified under a dynamic weight update framework, revealing a preference-utility trade-off and enabling improved steering through SPLIT approach.  					AI-generated summary 				 Methods for controlling large language models (LLMs), including local weight fine-...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 26. LatentMorph integrates implicit latent reasoning into text-to-image generation through four lightweight components that enable adaptive self-refinement and improve both efficiency and cognitive alignment.  					AI-generated summary 				 Text-to-image (T2I) generation has achieved remarkable progress...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 27. Visual world models for mobile GUI agents are improved through renderable code generation using vision-language models, achieving better performance with reduced model size compared to existing approaches.  					AI-generated summary 				 Mobile Graphical User Interface (GUI) World Models (WMs) offer...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 28. A Japanese financial language understanding benchmark named Ebisu is introduced, featuring two expert-annotated tasks that evaluate implicit commitment recognition and hierarchical financial terminology extraction, revealing persistent challenges for current language models despite their advanced ca...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 29. SPARKLING is a framework for mid-stage width expansion in deep learning models that maintains signal preservation and breaks symmetry to stabilize training and reduce computational costs.  					AI-generated summary 				 Progressive Learning (PL) reduces pre-training computational overhead by gradual...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 30. Loop-ViT introduces a recursive vision transformer architecture that decouples reasoning depth from model capacity through weight-tied recurrence and dynamic exit mechanisms, achieving superior visual reasoning performance with fewer parameters.  					AI-generated summary 				 Recent advances in vis...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 31. PolySAE extends sparse autoencoders with polynomial decoding to capture feature interactions and compositional structure while maintaining linear encoders for interpretability.  					AI-generated summary 				 Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural netwo...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 32. AgentIF-OneDay evaluates AI agents' ability to handle diverse daily tasks through natural language instructions, requiring problem-solving, attachment understanding, and file-based outputs across three user-centric categories.  					AI-generated summary 				 The capacity of AI agents to effectively ...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 33. Thinking with Comics emerges as an effective visual reasoning approach that bridges images and videos by leveraging comic structures for improved multimodal reasoning efficiency and performance.  					AI-generated summary 				 Chain-of-Thought reasoning has driven large language models to extend fro...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 34. TRIP-Bench presents a comprehensive long-horizon benchmark for travel planning that evaluates LLM agents on complex multi-turn interactions, while GTPO offers an online reinforcement learning approach to enhance constraint satisfaction and robustness in extended dialogues.  					AI-generated summary...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 35. A novel framework called CoDiQ enables controllable difficulty generation for competition-level questions through test-time scaling, resulting in a corpus that significantly improves large reasoning model performance.  					AI-generated summary 				 Large Reasoning Models (LRMs) benefit substantiall...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 36. Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks.  					AI-generated summary 				 Standard reward models typically predict scalar scores that fail to capture the multifaceted na...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 37. Flow matching models for text-to-image generation are enhanced through a reinforcement learning framework that addresses sample inefficiency and prompt overfitting by incorporating language models for prompt refinement, achieving superior performance with reduced computational requirements.  					AI...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 38. Research identifies a sparse reward subsystem in LLM hidden states containing value neurons that represent internal state expectations and dopamine-like neurons encoding reward prediction errors.  					AI-generated summary 				 In this paper, we identify a sparse reward subsystem within the hidden s...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 39. Adaptive Ability Decomposing (AD) enhances reinforcement learning with verifiable rewards by decomposing complex questions into simpler sub-questions, improving LLM reasoning through guided exploration without requiring a teacher model.  					AI-generated summary 				 Reinforcement learning with ve...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 40. Post-training quantization effects in world models reveal unique failure modes and trade-offs between accuracy, bit-width, and planning performance, particularly in encoder-predictor module asymmetries and low-bit rollout stability.  					AI-generated summary 				 World models learn an internal repr...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 41. A new test-time scaling framework called Prism is introduced for discrete diffusion language models that improves reasoning performance through hierarchical trajectory search, local branching with partial remasking, and self-verified feedback mechanisms.  					AI-generated summary 				 Inference-tim...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 42. LiP-Map presents a line-plane joint optimization framework that explicitly models learnable line and planar primitives for accurate 3D line mapping in man-made environments.  					AI-generated summary 				 3D line mapping from multi-view RGB images provides a compact and structured visual representa...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 43. PISA is a novel sparse attention method that improves diffusion transformer efficiency by approximating non-critical attention blocks instead of discarding them, achieving faster processing with maintained quality.  					AI-generated summary 				 Diffusion Transformers are fundamental for video and ...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 44. VisionTrim is a training-free framework that accelerates multimodal large language models by selecting dominant visual tokens and merging them with text-guided complementation, improving efficiency without performance loss.  					AI-generated summary 				 Multimodal large language models (MLLMs) suf...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 45. Small language models can effectively evaluate outputs by leveraging internal representations rather than generating responses, enabling a more efficient and interpretable evaluation approach through a probing-based framework.  					AI-generated summary 				 Large language models (LLMs) are widely u...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 46. Agentic large language models require investigatory intelligence for autonomous data analysis, demonstrated through the Deep Data Research benchmark that evaluates their ability to extract insights from databases without explicit queries.  					AI-generated summary 				 The agency expected of Agenti...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 47. Layer pruning compresses large language models while maintaining classification performance but causes significant degradation in generative reasoning tasks, with limited recovery possible through supervised finetuning on self-generated responses.  					AI-generated summary 				 Recent works have sh...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 48. A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation.  					AI-generated summary 				 Existing Tool-Integrated Reasoning (TIR) models have effectivel...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 49. A novel optimizer called Mano is proposed that combines manifold optimization with momentum projection onto tangent spaces, achieving superior performance over AdamW and Muon while reducing memory and computational requirements.  					AI-generated summary 				 While large language models (LLMs) have...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 50. Effective dimension, an unsupervised geometric metric, strongly predicts neural network performance across different architectures and domains, showing bidirectional causality between representation geometry and accuracy.  					AI-generated summary 				 We investigate the relationship between repres...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 51. Implicit neural representations operate continuously over UV coordinate space, demonstrating good image quality while balancing memory usage and rendering time, with applications in real-time rendering and downstream tasks.  					AI-generated summary 				 Implicit neural representation (INR) has pro...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 52. Controlled cross-lingual evaluation reveals instability in LLM assessment methods when targeting morphologically rich languages, indicating unreliable zero-shot judge transfer for discourse-level tasks.  					AI-generated summary 				 Cross-lingual evaluation of large language models (LLMs) typicall...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 53. Generalizable Predictive Prompt Selection (GPS) uses Bayesian inference with a lightweight generative model to efficiently select informative prompts for reinforcement learning-enhanced language models, improving training efficiency and performance.  					AI-generated summary 				 Reinforcement lear...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 54. VAE-based inpainting creates spectral shifts that fool detection systems, which can be mitigated through Inpainting Exchange to improve content-aware detection performance.  					AI-generated summary 				 Modern deep learning-based inpainting enables realistic local image manipulation, raising criti...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 55. Parallel Echo State Network (ParalESN) addresses reservoir computing limitations by enabling parallel temporal processing through diagonal linear recurrence, maintaining theoretical guarantees while achieving significant computational efficiency gains.  					AI-generated summary 				 Reservoir Compu...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 56. On-policy Verbal Distillation (OVD) enables efficient knowledge transfer from teacher to student models by replacing token-level probability matching with trajectory matching using discrete verbal scores, reducing memory consumption and enabling free exploration without token alignment constraints. ...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 57. An reinforcement learning-based sampling framework adaptively reweights training datasets to improve embedding model performance while reducing GPU costs.  					AI-generated summary 				 General-purpose open-domain dense retrieval systems are usually trained with a large, eclectic mix of corpora and...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 58. ReSID presents a novel recommendation-native framework that improves sequential recommendation by learning predictive item representations and optimizing quantization for information preservation and sequential predictability.  					AI-generated summary 				 Semantic ID (SID)-based recommendation is...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 59. Scaling hidden states of delimiter tokens in vision-language models reduces cross-image information leakage and improves multi-image reasoning performance.  					AI-generated summary 				 Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance dec...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 60. Internal flow signatures analyze depthwise dynamics in large language models to enable self-checking and targeted refinement without modifying the base model.  					AI-generated summary 				 Large language models can generate fluent answers that are unfaithful to the provided context, while many saf...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 61. Multi-agent systems for molecular discovery that use individualized scientist profiles based on publication and molecular history outperform traditional role-based approaches.  					AI-generated summary 				 Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery....
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 62. Researchers developed a novel agentic data-generation framework to create culturally grounded safety datasets for Southeast Asia, resulting in multilingual safeguard models that outperform existing approaches in detecting regionally sensitive content while maintaining general safety performance.  		...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 63. A two-phase diagnostic framework based on Item Response Theory and Graded Response Model is introduced to assess the reliability of LLM-as-a-Judge by examining intrinsic consistency and human alignment.  					AI-generated summary 				 While LLM-as-a-Judge is widely used in automated evaluation, exis...
[03.02.2026 17:33] ********************************************************************************
[03.02.2026 17:33] Abstract 64. Clipping-Free Policy Optimization replaces heuristic clipping with convex quadratic penalty to stabilize reinforcement learning training for large language models without performance loss.  					AI-generated summary 				 Reinforcement learning has become central to post-training large language model...
[03.02.2026 17:33] Read previous papers.
[03.02.2026 17:33] Generating reviews via LLM API.
[03.02.2026 17:33] Querying the API.
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning.  					AI-generated summary 				 We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.
[03.02.2026 17:33] Response: ```json
{
  "desc": "Green-VLA     Vision-Language-Action      .            ,   .          : ,     .   alignment               .",
  "emoji": "",
  "title": "             "
}
```
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning.  					AI-generated summary 				 We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency."

[03.02.2026 17:33] Response: ```python
['ROBOTICS', 'MULTIMODAL', 'RL', 'TRAINING', 'DATA']
```
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning.  					AI-generated summary 				 We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency."

[03.02.2026 17:33] Response: ```python
["TRANSFER_LEARNING", "OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **TRANSFER_LEARNING**: The paper explicitly discusses generalization across different robot embodiments through multi-embodiment pretraining and embodiment-specific adaptation, which are core transfer learning concepts.

- **OPTIMIZATION**: The paper describes reinforcement learning policy alignment and a five-stage curriculum learning approach, which are optimization methods for improving model performance.

- **OPEN_SOURCE**: The paper mentions releasing Green-VLA framework and datasets (3,000 hours of demonstrations) for real-world robot deployment, indicating contribution to open-source resources.
[03.02.2026 17:33] Error. Failed to parse JSON from LLM. ["TRANSFER_LEARNING", "OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **TRANSFER_LEARNING**: The paper explicitly discusses generalization across different robot embodiments through multi-embodiment pretraining and embodiment-specific adaptation, which are core transfer learning concepts.

- **OPTIMIZATION**: The paper describes reinforcement learning policy alignment and a five-stage curriculum learning approach, which are optimization methods for improving model performance.

- **OPEN_SOURCE**: The paper mentions releasing Green-VLA framework and datasets (3,000 hours of demonstrations) for real-world robot deployment, indicating contribution to open-source resources.
[03.02.2026 17:33] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Green-VLA is a comprehensive framework designed for deploying robots in real-world scenarios by integrating vision, language, and action. It consists of five stages that include foundational training, multimodal grounding, and reinforcement learning to adapt to various robot types. The framework utilizes a large dataset of demonstrations and a unified action interface, allowing a single policy to control different robotic embodiments effectively. Experimental results demonstrate significant improvements in generalization, success rates, and efficiency through the reinforcement learning alignment process.","title":"Empowering Robots with Green-VLA: A Unified Vision-Language-Action Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Green-VLA is a comprehensive framework designed for deploying robots in real-world scenarios by integrating vision, language, and action. It consists of five stages that include foundational training, multimodal grounding, and reinforcement learning to adapt to various robot types. The framework utilizes a large dataset of demonstrations and a unified action interface, allowing a single policy to control different robotic embodiments effectively. Experimental results demonstrate significant improvements in generalization, success rates, and efficiency through the reinforcement learning alignment process.', title='Empowering Robots with Green-VLA: A Unified Vision-Language-Action Framework'))
[03.02.2026 17:33] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Green-VLA--Green-VLA","title":"Green-VLA"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Green-VLA--Green-VLA', title='Green-VLA'))
[03.02.2026 17:33] Querying the API.
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Kimi K2.5 is an open-source multimodal agentic model that enhances text and vision processing through joint optimization techniques and introduces Agent Swarm for parallel task execution.  					AI-generated summary 				 We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5times over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.
[03.02.2026 17:33] Response: ```json
{
  "desc": " Kimi K2.5    -,       ,              .     Agent Swarm      ,            .       ,  ,  ,     .    Agent Swarm    4,5      ,        .",
  "emoji": "",
  "title": "     "
}
```
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Kimi K2.5 is an open-source multimodal agentic model that enhances text and vision processing through joint optimization techniques and introduces Agent Swarm for parallel task execution.  					AI-generated summary 				 We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5times over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence."

[03.02.2026 17:33] Response: ```python
["AGENTS", "MULTIMODAL", "CV", "TRAINING", "PLP"]
```
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Kimi K2.5 is an open-source multimodal agentic model that enhances text and vision processing through joint optimization techniques and introduces Agent Swarm for parallel task execution.  					AI-generated summary 				 We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5times over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence."

[03.02.2026 17:33] Response: ```python
["OPEN_SOURCE", "REASONING"]
```
[03.02.2026 17:33] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Kimi K2.5 is an innovative open-source multimodal model that integrates text and vision processing through advanced joint optimization methods. It employs techniques like joint text-vision pre-training and reinforcement learning to ensure that both modalities work together effectively. The model also features Agent Swarm, a framework that allows multiple agents to work on different parts of a task simultaneously, improving efficiency. Evaluations demonstrate that Kimi K2.5 outperforms existing models in various tasks, significantly reducing processing time while enhancing overall performance.","title":"Kimi K2.5: Uniting Text and Vision for Superior Agentic Intelligence"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Kimi K2.5 is an innovative open-source multimodal model that integrates text and vision processing through advanced joint optimization methods. It employs techniques like joint text-vision pre-training and reinforcement learning to ensure that both modalities work together effectively. The model also features Agent Swarm, a framework that allows multiple agents to work on different parts of a task simultaneously, improving efficiency. Evaluations demonstrate that Kimi K2.5 outperforms existing models in various tasks, significantly reducing processing time while enhancing overall performance.', title='Kimi K2.5: Uniting Text and Vision for Superior Agentic Intelligence'))
[03.02.2026 17:33] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Kimi K2.5K2.5Agent SwarmKimi K2.5Agent Swarm4.5","title":"Kimi K2.5"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Kimi K2.5K2.5Agent SwarmKimi K2.5Agent Swarm4.5', title='Kimi K2.5'))
[03.02.2026 17:33] Querying the API.
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Vision-DeepResearch introduces a multimodal deep-research paradigm enabling multi-turn, multi-entity, and multi-scale visual and textual search with deep-research capabilities integrated through cold-start supervision and reinforcement learning.  					AI-generated summary 				 Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.
[03.02.2026 17:33] Response: ```json
{
  "desc": "Vision-DeepResearch      ,   ,       .     ,       ,       .        reinforcement learning         LLM.           ,       .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Vision-DeepResearch introduces a multimodal deep-research paradigm enabling multi-turn, multi-entity, and multi-scale visual and textual search with deep-research capabilities integrated through cold-start supervision and reinforcement learning.  					AI-generated summary 				 Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch."

[03.02.2026 17:33] Response: ```python
["MULTIMODAL", "RAG", "RL", "CV"]
```
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Vision-DeepResearch introduces a multimodal deep-research paradigm enabling multi-turn, multi-entity, and multi-scale visual and textual search with deep-research capabilities integrated through cold-start supervision and reinforcement learning.  					AI-generated summary 				 Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch."

[03.02.2026 17:33] Response: ```python
['REASONING', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[03.02.2026 17:33] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Vision-DeepResearch presents a new approach to multimodal deep research that enhances visual and textual search capabilities. It allows for multi-turn interactions, handling multiple entities and scales, which is essential for addressing complex queries in noisy environments. The model integrates cold-start supervision and reinforcement learning to improve its reasoning depth and search breadth. As a result, it significantly outperforms existing multimodal large language models in real-world applications.","title":"Revolutionizing Multimodal Search with Vision-DeepResearch"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Vision-DeepResearch presents a new approach to multimodal deep research that enhances visual and textual search capabilities. It allows for multi-turn interactions, handling multiple entities and scales, which is essential for addressing complex queries in noisy environments. The model integrates cold-start supervision and reinforcement learning to improve its reasoning depth and search breadth. As a result, it significantly outperforms existing multimodal large language models in real-world applications.', title='Revolutionizing Multimodal Search with Vision-DeepResearch'))
[03.02.2026 17:33] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Vision-DeepResearchVision-DeepResearch","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Vision-DeepResearchVision-DeepResearch', title=''))
[03.02.2026 17:33] Querying the API.
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Vision-DeepResearch benchmark addresses limitations in evaluating visual-textual search capabilities of multimodal models by introducing realistic evaluation conditions and improving visual retrieval through multi-round cropped-search workflow.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.
[03.02.2026 17:33] Response: ```json
{
  "desc": "  Vision-DeepResearch benchmark         -       .       :         ,       .       VDR-Bench  2000    VQA     .  ,       ,           .",
  "emoji": "",
  "title": "      "
}
```
[03.02.2026 17:33] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Vision-DeepResearch benchmark addresses limitations in evaluating visual-textual search capabilities of multimodal models by introducing realistic evaluation conditions and improving visual retrieval through multi-round cropped-search workflow.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch."

[03.02.2026 17:34] Response: ```python
["DATASET", "BENCHMARK", "MULTIMODAL"]
```
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Vision-DeepResearch benchmark addresses limitations in evaluating visual-textual search capabilities of multimodal models by introducing realistic evaluation conditions and improving visual retrieval through multi-round cropped-search workflow.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch."

[03.02.2026 17:34] Response: ```python
['OPEN_SOURCE']
```
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Vision-DeepResearch benchmark (VDR-Bench) addresses the challenges in evaluating the visual-textual search capabilities of multimodal models. It highlights two main issues with existing benchmarks: the reliance on cross-textual cues and overly simplified evaluation scenarios. To overcome these limitations, VDR-Bench includes 2,000 carefully curated visual question-answering instances that reflect real-world conditions. Additionally, it introduces a multi-round cropped-search workflow to enhance the visual retrieval performance of current multimodal large language models (MLLMs).","title":"Enhancing Visual-Textual Search with Realistic Evaluation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Vision-DeepResearch benchmark (VDR-Bench) addresses the challenges in evaluating the visual-textual search capabilities of multimodal models. It highlights two main issues with existing benchmarks: the reliance on cross-textual cues and overly simplified evaluation scenarios. To overcome these limitations, VDR-Bench includes 2,000 carefully curated visual question-answering instances that reflect real-world conditions. Additionally, it introduces a multi-round cropped-search workflow to enhance the visual retrieval performance of current multimodal large language models (MLLMs).', title='Enhancing Visual-Textual Search with Realistic Evaluation'))
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Vision-DeepResearch-2000VDR-Bench","title":"-"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Vision-DeepResearch-2000VDR-Bench', title='-'))
[03.02.2026 17:34] Querying the API.
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

RPG-Encoder framework transforms repository comprehension and generation into a unified cycle by encoding code into high-fidelity Repository Planning Graph representations that improve understanding and reconstruction accuracy.  					AI-generated summary 				 Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.
[03.02.2026 17:34] Response: ```json
{
  "desc": "  RPG-Encoder  ,              Repository Planning Graph.      ,     API      . RPG-Encoder      ,       ,        .         (93.7%   SWE-bench)   98.5%    .",
  "emoji": "",
  "title": "         "
}
```
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RPG-Encoder framework transforms repository comprehension and generation into a unified cycle by encoding code into high-fidelity Repository Planning Graph representations that improve understanding and reconstruction accuracy.  					AI-generated summary 				 Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation."

[03.02.2026 17:34] Response: ```python
["AGENTS", "PLP", "BENCHMARK"]
```
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RPG-Encoder framework transforms repository comprehension and generation into a unified cycle by encoding code into high-fidelity Repository Planning Graph representations that improve understanding and reconstruction accuracy.  					AI-generated summary 				 Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation."

[03.02.2026 17:34] Response: ```python
["GRAPHS", "REASONING"]
```

**Justification:**

1. **GRAPHS**: The paper explicitly focuses on Repository Planning Graph (RPG) representations and graph-based approaches for code understanding. The framework encodes code into graph representations and operates on graph topology, which is central to graph neural network applications.

2. **REASONING**: The paper addresses "reasoning disconnect" in repository agents and proposes mechanisms to "close the reasoning loop" through unified representations that improve logical understanding and navigation of complex codebases.
[03.02.2026 17:34] Error. Failed to parse JSON from LLM. ["GRAPHS", "REASONING"]


**Justification:**

1. **GRAPHS**: The paper explicitly focuses on Repository Planning Graph (RPG) representations and graph-based approaches for code understanding. The framework encodes code into graph representations and operates on graph topology, which is central to graph neural network applications.

2. **REASONING**: The paper addresses "reasoning disconnect" in repository agents and proposes mechanisms to "close the reasoning loop" through unified representations that improve logical understanding and navigation of complex codebases.
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The RPG-Encoder framework enhances the understanding and generation of code repositories by transforming them into high-fidelity Repository Planning Graphs (RPGs). This approach addresses the limitations of existing methods that rely on fragmented representations, allowing for a more cohesive understanding of code. By treating repository comprehension and generation as inverse processes, RPG-Encoder effectively links intent with implementation. The framework demonstrates significant improvements in accuracy and efficiency, achieving state-of-the-art results in repository understanding and reconstruction.","title":"Unifying Code Comprehension and Generation with RPG-Encoder"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The RPG-Encoder framework enhances the understanding and generation of code repositories by transforming them into high-fidelity Repository Planning Graphs (RPGs). This approach addresses the limitations of existing methods that rely on fragmented representations, allowing for a more cohesive understanding of code. By treating repository comprehension and generation as inverse processes, RPG-Encoder effectively links intent with implementation. The framework demonstrates significant improvements in accuracy and efficiency, achieving state-of-the-art results in repository understanding and reconstruction.', title='Unifying Code Comprehension and Generation with RPG-Encoder'))
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RPG-EncoderRPGAPIRPG-Encoder","title":"RPG-Encoder"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RPG-EncoderRPGAPIRPG-Encoder', title='RPG-Encoder'))
[03.02.2026 17:34] Querying the API.
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

UniReason integrates text-to-image generation and image editing through a dual reasoning paradigm that enhances planning with world knowledge and uses editing for visual refinement, achieving superior performance on reasoning-intensive benchmarks.  					AI-generated summary 				 Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.
[03.02.2026 17:34] Response: ```json
{
  "desc": "UniReason   ,           .     ,    ,         .            .      300k ,    ,           .",
  "emoji": "",
  "title": "    :   "
}
```
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"UniReason integrates text-to-image generation and image editing through a dual reasoning paradigm that enhances planning with world knowledge and uses editing for visual refinement, achieving superior performance on reasoning-intensive benchmarks.  					AI-generated summary 				 Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities."

[03.02.2026 17:34] Response: ```python
['MULTIMODAL', 'DATASET', 'BENCHMARK']
```
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"UniReason integrates text-to-image generation and image editing through a dual reasoning paradigm that enhances planning with world knowledge and uses editing for visual refinement, achieving superior performance on reasoning-intensive benchmarks.  					AI-generated summary 				 Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities."

[03.02.2026 17:34] Response: ```python
['REASONING', 'SYNTHETIC']
```
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"UniReason is a novel framework that combines text-to-image generation and image editing into a single process, enhancing reasoning capabilities. It employs a dual reasoning paradigm that integrates world knowledge to improve planning and uses editing for precise visual adjustments. By treating generation and editing as interconnected steps, UniReason mimics human cognitive processes, allowing for better synthesis of complex tasks. The framework is supported by a large dataset designed for reasoning tasks, demonstrating significant improvements in performance on various benchmarks.","title":"Harmonizing Generation and Editing for Enhanced Reasoning in AI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='UniReason is a novel framework that combines text-to-image generation and image editing into a single process, enhancing reasoning capabilities. It employs a dual reasoning paradigm that integrates world knowledge to improve planning and uses editing for precise visual adjustments. By treating generation and editing as interconnected steps, UniReason mimics human cognitive processes, allowing for better synthesis of complex tasks. The framework is supported by a large dataset designed for reasoning tasks, demonstrating significant improvements in performance on various benchmarks.', title='Harmonizing Generation and Editing for Enhanced Reasoning in AI'))
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"UniReason UniReason ","title":"UniReason"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='UniReason UniReason ', title='UniReason'))
[03.02.2026 17:34] Querying the API.
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

WildGraphBench evaluates GraphRAG performance in realistic scenarios using Wikipedia's structured content to assess multi-fact aggregation and summarization capabilities across diverse document types.  					AI-generated summary 				 Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.
[03.02.2026 17:34] Response: ```json
{
  "desc": "   WildGraphBench     GraphRAG        . GraphRAG       ,          .     1100    (     )         .  ,   GraphRAG         ,            .",
  "emoji": "",
  "title": "         "
}
```
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"WildGraphBench evaluates GraphRAG performance in realistic scenarios using Wikipedia's structured content to assess multi-fact aggregation and summarization capabilities across diverse document types.  					AI-generated summary 				 Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench."

[03.02.2026 17:34] Response: ```python
["BENCHMARK", "RAG", "DATASET"]
```
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"WildGraphBench evaluates GraphRAG performance in realistic scenarios using Wikipedia's structured content to assess multi-fact aggregation and summarization capabilities across diverse document types.  					AI-generated summary 				 Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench."

[03.02.2026 17:34] Response: ```python
['GRAPHS', 'LONG_CONTEXT', 'OPEN_SOURCE']
```
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"WildGraphBench is a new benchmark that evaluates the performance of GraphRAG, a model that uses graph-based retrieval to enhance multi-fact aggregation and summarization. It focuses on realistic scenarios by utilizing Wikipedia\'s structured content, which provides a diverse set of long and heterogeneous documents. The benchmark includes 1,100 questions that test different levels of complexity, from single-fact to multi-fact and summarization tasks. Results show that while GraphRAG performs well with moderate sources, it struggles with detailed summarization due to a tendency to prioritize high-level information over finer details.","title":"Evaluating GraphRAG in Real-World Scenarios with WildGraphBench"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="WildGraphBench is a new benchmark that evaluates the performance of GraphRAG, a model that uses graph-based retrieval to enhance multi-fact aggregation and summarization. It focuses on realistic scenarios by utilizing Wikipedia's structured content, which provides a diverse set of long and heterogeneous documents. The benchmark includes 1,100 questions that test different levels of complexity, from single-fact to multi-fact and summarization tasks. Results show that while GraphRAG performs well with moderate sources, it struggles with detailed summarization due to a tendency to prioritize high-level information over finer details.", title='Evaluating GraphRAG in Real-World Scenarios with WildGraphBench'))
[03.02.2026 17:34] Response: ParsedChatCompletionMessage[Article](content='{"desc":"WildGraphBench  GraphRAG GraphRAG  GraphRAG WildGraphBench  12  1,100 ","title":"WildGraphBench"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='WildGraphBench  GraphRAG GraphRAG  GraphRAG WildGraphBench  12  1,100 ', title='WildGraphBench'))
[03.02.2026 17:34] Querying the API.
[03.02.2026 17:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A file-system-based dual-agent framework enables large language model agents to perform extended research tasks beyond context window limitations by using persistent storage as external memory.  					AI-generated summary 				 Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.
[03.02.2026 17:35] Response: ```json
{
  "desc": "   FS-Researcher   ,               ,   ,          .     ,      ,     LLM.             .               .",
  "emoji": "",
  "title": "  :     LLM"
}
```
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A file-system-based dual-agent framework enables large language model agents to perform extended research tasks beyond context window limitations by using persistent storage as external memory.  					AI-generated summary 				 Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher."

[03.02.2026 17:35] Response: ```python
["AGENTS", "BENCHMARK", "DATASET"]
```
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A file-system-based dual-agent framework enables large language model agents to perform extended research tasks beyond context window limitations by using persistent storage as external memory.  					AI-generated summary 				 Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher."

[03.02.2026 17:35] Response: ```python
['LONG_CONTEXT', 'REASONING', 'OPEN_SOURCE']
```
[03.02.2026 17:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents FS-Researcher, a dual-agent framework designed to enhance the capabilities of large language models (LLMs) for deep research tasks that exceed their context window limitations. The framework utilizes a file system as external memory, allowing a Context Builder agent to gather and organize information from the internet into a structured knowledge base. A Report Writer agent then uses this knowledge base to generate comprehensive reports, enabling iterative refinement and improved report quality. Experiments demonstrate that FS-Researcher outperforms existing methods, showing that effective allocation of resources to the Context Builder correlates with higher report quality.","title":"Unlocking Deep Research with FS-Researcher: Beyond Context Limits!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents FS-Researcher, a dual-agent framework designed to enhance the capabilities of large language models (LLMs) for deep research tasks that exceed their context window limitations. The framework utilizes a file system as external memory, allowing a Context Builder agent to gather and organize information from the internet into a structured knowledge base. A Report Writer agent then uses this knowledge base to generate comprehensive reports, enabling iterative refinement and improved report quality. Experiments demonstrate that FS-Researcher outperforms existing methods, showing that effective allocation of resources to the Context Builder correlates with higher report quality.', title='Unlocking Deep Research with FS-Researcher: Beyond Context Limits!'))
[03.02.2026 17:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FS-ResearcherLLMFS-Researcher","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FS-ResearcherLLMFS-Researcher', title=''))
[03.02.2026 17:35] Querying the API.
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A scalable framework for constructing real-world software engineering environments from GitHub pull requests using an efficient building agent with self-verification and hacking detection capabilities.  					AI-generated summary 				 We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.
[03.02.2026 17:35] Response: ```json
{
  "desc": "   SWE-Universe            pull request'  GitHub.     ,              .           (807,693),    .                      .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A scalable framework for constructing real-world software engineering environments from GitHub pull requests using an efficient building agent with self-verification and hacking detection capabilities.  					AI-generated summary 				 We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents."

[03.02.2026 17:35] Response: ```python
["DATASET", "AGENTS", "PLP", "RL", "BENCHMARK", "MULTILINGUAL", "TRAINING"]
```
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A scalable framework for constructing real-world software engineering environments from GitHub pull requests using an efficient building agent with self-verification and hacking detection capabilities.  					AI-generated summary 				 We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents."

[03.02.2026 17:35] Response: ```python
['SYNTHETIC', 'OPEN_SOURCE', 'OPTIMIZATION']
```

**Justification:**

1. **SYNTHETIC**: The paper describes constructing synthetic software engineering environments from GitHub pull requests at scale (807,693 environments). These are artificially generated verifiable tasks used for training.

2. **OPEN_SOURCE**: The paper involves GitHub pull requests and contributes resources/methodology for the community to advance coding agents, indicating open-source contributions.

3. **OPTIMIZATION**: The paper focuses on optimization methods including "iterative self-verification," "in-loop hacking detection," and "large-scale agentic mid-training and reinforcement learning" to improve the efficiency and reliability of the building process.
[03.02.2026 17:35] Error. Failed to parse JSON from LLM. ["SYNTHETIC", "OPEN_SOURCE", "OPTIMIZATION"]


**Justification:**

1. **SYNTHETIC**: The paper describes constructing synthetic software engineering environments from GitHub pull requests at scale (807,693 environments). These are artificially generated verifiable tasks used for training.

2. **OPEN_SOURCE**: The paper involves GitHub pull requests and contributes resources/methodology for the community to advance coding agents, indicating open-source contributions.

3. **OPTIMIZATION**: The paper focuses on optimization methods including "iterative self-verification," "in-loop hacking detection," and "large-scale agentic mid-training and reinforcement learning" to improve the efficiency and reliability of the building process.
[03.02.2026 17:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces SWE-Universe, a framework designed to automatically create verifiable software engineering environments from GitHub pull requests. It addresses common issues in automatic building, such as low success rates and ineffective verification processes, by using a custom-trained building agent. This agent incorporates self-verification and hacking detection to ensure the environments generated are reliable and high-quality. The framework successfully scales to nearly a million environments and demonstrates its effectiveness through applications in reinforcement learning and agent training.","title":"Building Reliable Software Environments at Scale"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces SWE-Universe, a framework designed to automatically create verifiable software engineering environments from GitHub pull requests. It addresses common issues in automatic building, such as low success rates and ineffective verification processes, by using a custom-trained building agent. This agent incorporates self-verification and hacking detection to ensure the environments generated are reliable and high-quality. The framework successfully scales to nearly a million environments and demonstrates its effectiveness through applications in reinforcement learning and agent training.', title='Building Reliable Software Environments at Scale'))
[03.02.2026 17:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SWE-UniverseGitHubQwen3-Max-Thinking75.3%","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SWE-UniverseGitHubQwen3-Max-Thinking75.3%', title=''))
[03.02.2026 17:35] Querying the API.
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Deep Research Agents demonstrate capabilities in autonomous information retrieval but show significant gaps when evaluated against expert-level Wikipedia articles using a new live benchmark and comprehensive evaluation framework.  					AI-generated summary 				 Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge
[03.02.2026 17:35] Response: ```json
{
  "desc": "    benchmark Wiki Live Challenge,    Wikipedia Good Articles        Deep Research Agents.     Wiki Eval  39           ,       .      DRA          ,     Wikipedia.              .",
  "emoji": "",
  "title": "   AI-   "
}
```
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Deep Research Agents demonstrate capabilities in autonomous information retrieval but show significant gaps when evaluated against expert-level Wikipedia articles using a new live benchmark and comprehensive evaluation framework.  					AI-generated summary 				 Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge"

[03.02.2026 17:35] Response: ```python
['AGENTS', 'BENCHMARK', 'DATASET']
```
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Deep Research Agents demonstrate capabilities in autonomous information retrieval but show significant gaps when evaluated against expert-level Wikipedia articles using a new live benchmark and comprehensive evaluation framework.  					AI-generated summary 				 Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge"

[03.02.2026 17:35] Response: ```python
['SURVEY', 'OPEN_SOURCE']
```
[03.02.2026 17:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Deep Research Agents (DRAs) are AI systems designed to autonomously retrieve information and generate reports, showing promise in aiding complex research tasks. However, when evaluated against expert-level Wikipedia articles, DRAs reveal significant shortcomings, particularly in reliability and objective assessment. The Wiki Live Challenge (WLC) introduces a new benchmark using Wikipedia\'s Good Articles as a standard for evaluation, emphasizing neutrality and verifiability. This framework includes a detailed evaluation method with 39 criteria, highlighting the performance gap between DRAs and human experts, thus pushing the boundaries of agent research.","title":"Bridging the Gap: Evaluating AI with Expert Standards"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="Deep Research Agents (DRAs) are AI systems designed to autonomously retrieve information and generate reports, showing promise in aiding complex research tasks. However, when evaluated against expert-level Wikipedia articles, DRAs reveal significant shortcomings, particularly in reliability and objective assessment. The Wiki Live Challenge (WLC) introduces a new benchmark using Wikipedia's Good Articles as a standard for evaluation, emphasizing neutrality and verifiability. This framework includes a detailed evaluation method with 39 criteria, highlighting the performance gap between DRAs and human experts, thus pushing the boundaries of agent research.", title='Bridging the Gap: Evaluating AI with Expert Standards'))
[03.02.2026 17:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DRALLMWLC100Wiki Eval39DRA","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DRALLMWLC100Wiki Eval39DRA', title=''))
[03.02.2026 17:35] Querying the API.
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

PixelGen is a pixel-space diffusion framework that uses perceptual supervision through LPIPS and DINO-based losses to generate high-quality images without requiring VAEs or latent representations.  					AI-generated summary 				 Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.
[03.02.2026 17:35] Response: ```json
{
  "desc": "PixelGen     ,       ,  ,   VAE    .         : LPIPS      DINO-based     .              . PixelGen    (FID 5.11  ImageNet-256),   VAE   ,          .",
  "emoji": "",
  "title": "        "
}
```
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PixelGen is a pixel-space diffusion framework that uses perceptual supervision through LPIPS and DINO-based losses to generate high-quality images without requiring VAEs or latent representations.  					AI-generated summary 				 Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen."

[03.02.2026 17:35] Response: ```python
["CV", "ARCHITECTURE", "TRAINING"]
```

**Justification:**

- **CV**: The paper is fundamentally about image generation and visual content creation, which is a core computer vision task.
- **ARCHITECTURE**: PixelGen proposes a novel framework/architecture for pixel-space diffusion with perceptual supervision mechanisms (LPIPS and DINO-based losses), representing a novel approach to generative modeling.
- **TRAINING**: The paper focuses on improving training methodology through perceptual supervision losses to optimize the diffusion model training process, making it a training improvement paper.
[03.02.2026 17:35] Error. Failed to parse JSON from LLM. ["CV", "ARCHITECTURE", "TRAINING"]


**Justification:**

- **CV**: The paper is fundamentally about image generation and visual content creation, which is a core computer vision task.
- **ARCHITECTURE**: PixelGen proposes a novel framework/architecture for pixel-space diffusion with perceptual supervision mechanisms (LPIPS and DINO-based losses), representing a novel approach to generative modeling.
- **TRAINING**: The paper focuses on improving training methodology through perceptual supervision losses to optimize the diffusion model training process, making it a training improvement paper.
[03.02.2026 17:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PixelGen is a pixel-space diffusion framework that uses perceptual supervision through LPIPS and DINO-based losses to generate high-quality images without requiring VAEs or latent representations.  					AI-generated summary 				 Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen."

[03.02.2026 17:36] Response: ```python
["DIFFUSION", "OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

1. **DIFFUSION**: The paper is explicitly about a diffusion-based generative model (PixelGen) for image generation in pixel space.

2. **OPTIMIZATION**: The paper addresses optimization challenges in training diffusion models on high-dimensional pixel manifolds and proposes perceptual supervision losses (LPIPS and DINO-based) to improve the optimization process.

3. **OPEN_SOURCE**: The paper states "Codes are publicly available at https://github.com/Zehong-Ma/PixelGen," indicating the authors are releasing their code/framework publicly.
[03.02.2026 17:36] Error. Failed to parse JSON from LLM. ["DIFFUSION", "OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

1. **DIFFUSION**: The paper is explicitly about a diffusion-based generative model (PixelGen) for image generation in pixel space.

2. **OPTIMIZATION**: The paper addresses optimization challenges in training diffusion models on high-dimensional pixel manifolds and proposes perceptual supervision losses (LPIPS and DINO-based) to improve the optimization process.

3. **OPEN_SOURCE**: The paper states "Codes are publicly available at https://github.com/Zehong-Ma/PixelGen," indicating the authors are releasing their code/framework publicly.
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PixelGen is a novel pixel-space diffusion framework that generates high-quality images directly in pixel space, eliminating the need for variational autoencoders (VAEs) or latent representations. It utilizes perceptual supervision through two types of losses: LPIPS for enhancing local image patterns and DINO for improving global semantic understanding. This approach allows PixelGen to effectively navigate the complex high-dimensional pixel space, overcoming challenges faced by traditional pixel diffusion methods. As a result, PixelGen achieves impressive performance metrics, including a low FID score on ImageNet-256, demonstrating its capability in large-scale text-to-image generation tasks.","title":"PixelGen: Simplifying Image Generation with Perceptual Supervision"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PixelGen is a novel pixel-space diffusion framework that generates high-quality images directly in pixel space, eliminating the need for variational autoencoders (VAEs) or latent representations. It utilizes perceptual supervision through two types of losses: LPIPS for enhancing local image patterns and DINO for improving global semantic understanding. This approach allows PixelGen to effectively navigate the complex high-dimensional pixel space, overcoming challenges faced by traditional pixel diffusion methods. As a result, PixelGen achieves impressive performance metrics, including a low FID score on ImageNet-256, demonstrating its capability in large-scale text-to-image generation tasks.', title='PixelGen: Simplifying Image Generation with Perceptual Supervision'))
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PixelGenLPIPSDINOVAEPixelGenPixelGen","title":"PixelGen"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PixelGenLPIPSDINOVAEPixelGenPixelGen', title='PixelGen'))
[03.02.2026 17:36] Querying the API.
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SLIME is a novel reference-free alignment objective for large language models that decouples preference learning from generation quality through a three-pronged approach combining likelihood maximization, probability stabilization, and dual-margin constraints.  					AI-generated summary 				 Direct preference optimization methods have emerged as a computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) for aligning Large Language Models (LLMs). Latest approaches have streamlined the alignment process by deriving implicit reward functions, yet they often suffer from a critical objective mismatch: optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen response's absolute likelihood. This can lead to ``unlearning'', where the model degrades the probability of high-quality outputs to satisfy margin constraints, and ``formatting collapse'' caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), a reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates a three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) a stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) a dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to state-of-the-art baselines while maintaining higher generation stability.
[03.02.2026 17:36] Response: ```json
{
  "desc": "SLIME        ,           .           :    ,       margin-.         ,       .   ,  SLIME   ,      .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SLIME is a novel reference-free alignment objective for large language models that decouples preference learning from generation quality through a three-pronged approach combining likelihood maximization, probability stabilization, and dual-margin constraints.  					AI-generated summary 				 Direct preference optimization methods have emerged as a computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) for aligning Large Language Models (LLMs). Latest approaches have streamlined the alignment process by deriving implicit reward functions, yet they often suffer from a critical objective mismatch: optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen response's absolute likelihood. This can lead to ``unlearning'', where the model degrades the probability of high-quality outputs to satisfy margin constraints, and ``formatting collapse'' caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), a reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates a three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) a stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) a dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to state-of-the-art baselines while maintaining higher generation stability."

[03.02.2026 17:36] Response: ```python
["RLHF", "TRAINING"]
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SLIME is a novel reference-free alignment objective for large language models that decouples preference learning from generation quality through a three-pronged approach combining likelihood maximization, probability stabilization, and dual-margin constraints.  					AI-generated summary 				 Direct preference optimization methods have emerged as a computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) for aligning Large Language Models (LLMs). Latest approaches have streamlined the alignment process by deriving implicit reward functions, yet they often suffer from a critical objective mismatch: optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen response's absolute likelihood. This can lead to ``unlearning'', where the model degrades the probability of high-quality outputs to satisfy margin constraints, and ``formatting collapse'' caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), a reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates a three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) a stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) a dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to state-of-the-art baselines while maintaining higher generation stability."

[03.02.2026 17:36] Response: ```python
['ALIGNMENT']
```
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SLIME is a new method for aligning large language models without needing reference data. It separates the learning of user preferences from the quality of the generated text. The approach uses three key strategies: maximizing the likelihood of preferred responses, stabilizing the probabilities of less preferred options, and applying dual-margin constraints for better control. This results in improved performance and stability in the model\'s outputs compared to existing methods.","title":"SLIME: Aligning Preferences with Stability in Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="SLIME is a new method for aligning large language models without needing reference data. It separates the learning of user preferences from the quality of the generated text. The approach uses three key strategies: maximizing the likelihood of preferred responses, stabilizing the probabilities of less preferred options, and applying dual-margin constraints for better control. This results in improved performance and stability in the model's outputs compared to existing methods.", title='SLIME: Aligning Preferences with Stability in Language Models'))
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SLIMESLIMESLIME","title":"SLIME"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SLIMESLIMESLIME', title='SLIME'))
[03.02.2026 17:36] Querying the API.
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

RLAnything enhances reinforcement learning for LLMs and agents through dynamic model optimization and closed-loop feedback mechanisms that improve policy and reward model training.  					AI-generated summary 				 We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL
[03.02.2026 17:36] Response: ```json
{
  "desc": "RLAnything      ,     ,        .          ,        .        ,      .         LLM  ,    9-18%    .",
  "emoji": "",
  "title": "         "
}
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RLAnything enhances reinforcement learning for LLMs and agents through dynamic model optimization and closed-loop feedback mechanisms that improve policy and reward model training.  					AI-generated summary 				 We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL"

[03.02.2026 17:36] Response: ```python
["RL", "AGENTS", "TRAINING"]
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"RLAnything enhances reinforcement learning for LLMs and agents through dynamic model optimization and closed-loop feedback mechanisms that improve policy and reward model training.  					AI-generated summary 				 We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL"

[03.02.2026 17:36] Response: ```python
['OPTIMIZATION', 'ALIGNMENT', 'OPEN_SOURCE']
```

**Justification:**

1. **OPTIMIZATION**: The paper focuses on "dynamic model optimization" and "closed-loop optimization" for training reinforcement learning systems, which directly relates to advancing training optimization methods.

2. **ALIGNMENT**: The paper discusses reinforcement learning for LLMs with reward model training and feedback mechanisms, which are core techniques for aligning language models with intended behavior and human preferences.

3. **OPEN_SOURCE**: The paper explicitly mentions releasing code on GitHub ("Code: https://github.com/Gen-Verse/Open-AgentRL"), indicating a contribution to open-source projects.
[03.02.2026 17:36] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "ALIGNMENT", "OPEN_SOURCE"]


**Justification:**

1. **OPTIMIZATION**: The paper focuses on "dynamic model optimization" and "closed-loop optimization" for training reinforcement learning systems, which directly relates to advancing training optimization methods.

2. **ALIGNMENT**: The paper discusses reinforcement learning for LLMs with reward model training and feedback mechanisms, which are core techniques for aligning language models with intended behavior and human preferences.

3. **OPEN_SOURCE**: The paper explicitly mentions releasing code on GitHub ("Code: https://github.com/Gen-Verse/Open-AgentRL"), indicating a contribution to open-source projects.
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RLAnything is a novel reinforcement learning framework designed to enhance the training of large language models (LLMs) and agents. It utilizes dynamic model optimization and closed-loop feedback mechanisms to improve both policy and reward model training. By integrating feedback from both step-wise actions and overall outcomes, RLAnything strengthens the learning signals, leading to better performance. The framework also adapts the training environment based on critic feedback, allowing models to learn more effectively from their experiences, resulting in significant performance improvements across various tasks.","title":"Boosting Learning with RLAnything: Dynamic Optimization for LLMs and Agents"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RLAnything is a novel reinforcement learning framework designed to enhance the training of large language models (LLMs) and agents. It utilizes dynamic model optimization and closed-loop feedback mechanisms to improve both policy and reward model training. By integrating feedback from both step-wise actions and overall outcomes, RLAnything strengthens the learning signals, leading to better performance. The framework also adapts the training environment based on critic feedback, allowing models to learn more effectively from their experiences, resulting in significant performance improvements across various tasks.', title='Boosting Learning with RLAnything: Dynamic Optimization for LLMs and Agents'))
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"RLAnythingLLMRLAnything","title":"RLAnything"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='RLAnythingLLMRLAnything', title='RLAnything'))
[03.02.2026 17:36] Querying the API.
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

PISCES is an annotation-free text-to-video generation method that uses dual optimal transport-aligned rewards to improve visual quality and semantic alignment without human preference annotations.  					AI-generated summary 				 Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present PISCES, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, PISCES uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, PISCES is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that PISCES outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.
[03.02.2026 17:36] Response: ```json
{
  "desc": "PISCES       ,        .              :     .              ,        .  ,  PISCES      ,    .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PISCES is an annotation-free text-to-video generation method that uses dual optimal transport-aligned rewards to improve visual quality and semantic alignment without human preference annotations.  					AI-generated summary 				 Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present PISCES, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, PISCES uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, PISCES is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that PISCES outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning."

[03.02.2026 17:36] Response: ```python
['VIDEO', 'TRAINING', 'RL']
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PISCES is an annotation-free text-to-video generation method that uses dual optimal transport-aligned rewards to improve visual quality and semantic alignment without human preference annotations.  					AI-generated summary 				 Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present PISCES, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, PISCES uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, PISCES is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that PISCES outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning."

[03.02.2026 17:36] Response: ```python
["OPTIMIZATION"]
```
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PISCES is a novel method for generating videos from text without needing human annotations. It uses a technique called Dual Optimal Transport to align rewards that improve both the visual quality and the semantic relevance of the generated videos. By bridging text and video embeddings, PISCES ensures that the generated content is coherent and matches the intended meaning. Experiments demonstrate that PISCES outperforms existing methods, making it a significant advancement in text-to-video generation.","title":"PISCES: Annotation-Free Video Generation with Optimal Transport Rewards"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PISCES is a novel method for generating videos from text without needing human annotations. It uses a technique called Dual Optimal Transport to align rewards that improve both the visual quality and the semantic relevance of the generated videos. By bridging text and video embeddings, PISCES ensures that the generated content is coherent and matches the intended meaning. Experiments demonstrate that PISCES outperforms existing methods, making it a significant advancement in text-to-video generation.', title='PISCES: Annotation-Free Video Generation with Optimal Transport Rewards'))
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PISCESPISCESPISCES","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PISCESPISCESPISCES', title=''))
[03.02.2026 17:36] Querying the API.
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Mind-Brush presents a unified agentic framework for text-to-image generation that dynamically retrieves multimodal evidence and employs reasoning tools to improve understanding of implicit user intentions and complex knowledge reasoning.  					AI-generated summary 				 While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.
[03.02.2026 17:36] Response: ```json
{
  "desc": "Mind-Brush        ,               .          ,      '--',             .   Mind-Bench -    500 ,   ,          .        ,       Qwen-Image.",
  "emoji": "",
  "title": "   -      "
}
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mind-Brush presents a unified agentic framework for text-to-image generation that dynamically retrieves multimodal evidence and employs reasoning tools to improve understanding of implicit user intentions and complex knowledge reasoning.  					AI-generated summary 				 While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE."

[03.02.2026 17:36] Response: ```python
["AGENTS", "MULTIMODAL", "BENCHMARK", "RAG"]
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mind-Brush presents a unified agentic framework for text-to-image generation that dynamically retrieves multimodal evidence and employs reasoning tools to improve understanding of implicit user intentions and complex knowledge reasoning.  					AI-generated summary 				 While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE."

[03.02.2026 17:36] Response: ```python
['REASONING']
```
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Mind-Brush is a new framework for generating images from text that improves how AI understands what users really want. Unlike traditional models that just convert text to images, Mind-Brush actively gathers information from various sources to better interpret complex ideas. It uses a \'think-research-create\' approach, allowing it to adapt to new information and solve intricate reasoning tasks. The framework has been tested with a new benchmark called Mind-Bench, showing significant improvements in performance over existing models.","title":"Mind-Brush: Dynamic Understanding for Text-to-Image Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="Mind-Brush is a new framework for generating images from text that improves how AI understands what users really want. Unlike traditional models that just convert text to images, Mind-Brush actively gathers information from various sources to better interpret complex ideas. It uses a 'think-research-create' approach, allowing it to adapt to new information and solve intricate reasoning tasks. The framework has been tested with a new benchmark called Mind-Bench, showing significant improvements in performance over existing models.", title='Mind-Brush: Dynamic Understanding for Text-to-Image Generation'))
[03.02.2026 17:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Mind-BrushMind-Brush--","title":"Mind-Brush"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Mind-BrushMind-Brush--', title='Mind-Brush'))
[03.02.2026 17:36] Querying the API.
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel Causal Forcing method addresses the architectural gap in distilling bidirectional video diffusion models into autoregressive models by using AR teachers for ODE initialization, significantly improving video generation performance.  					AI-generated summary 				 To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\% in Dynamic Degree, 8.7\% in VisionReward, and 16.7\% in Instruction Following. Project page and the code: https://thu-ml.github.io/CausalForcing.github.io/{https://thu-ml.github.io/CausalForcing.github.io/}
[03.02.2026 17:36] Response: ```json
{
  "desc": "     Causal Forcing         ,           .  ,   ODE          ,     .        ODE,       .        :   19.3%  Dynamic Degree, 8.7%  VisionReward  16.7%   Instruction Following.",
  "emoji": "",
  "title": " :       "
}
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel Causal Forcing method addresses the architectural gap in distilling bidirectional video diffusion models into autoregressive models by using AR teachers for ODE initialization, significantly improving video generation performance.  					AI-generated summary 				 To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\% in Dynamic Degree, 8.7\% in VisionReward, and 16.7\% in Instruction Following. Project page and the code: https://thu-ml.github.io/CausalForcing.github.io/{https://thu-ml.github.io/CausalForcing.github.io/}"

[03.02.2026 17:36] Response: ```python
["VIDEO", "ARCHITECTURE", "TRAINING"]
```
[03.02.2026 17:36] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel Causal Forcing method addresses the architectural gap in distilling bidirectional video diffusion models into autoregressive models by using AR teachers for ODE initialization, significantly improving video generation performance.  					AI-generated summary 				 To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\% in Dynamic Degree, 8.7\% in VisionReward, and 16.7\% in Instruction Following. Project page and the code: https://thu-ml.github.io/CausalForcing.github.io/{https://thu-ml.github.io/CausalForcing.github.io/}"

[03.02.2026 17:37] Response: ```python
['DIFFUSION', 'OPEN_SOURCE']
```

**Justification:**

- **DIFFUSION**: The paper explicitly focuses on "distilling bidirectional video diffusion models" and addresses challenges in diffusion-based video generation, which is a core topic of diffusion-based generative models.

- **OPEN_SOURCE**: The paper mentions "Project page and the code" with a GitHub link, indicating the authors are releasing code/resources publicly.
[03.02.2026 17:37] Error. Failed to parse JSON from LLM. ["DIFFUSION", "OPEN_SOURCE"]


**Justification:**

- **DIFFUSION**: The paper explicitly focuses on "distilling bidirectional video diffusion models" and addresses challenges in diffusion-based video generation, which is a core topic of diffusion-based generative models.

- **OPEN_SOURCE**: The paper mentions "Project page and the code" with a GitHub link, indicating the authors are releasing code/resources publicly.
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new method called Causal Forcing, which improves the process of converting bidirectional video diffusion models into autoregressive (AR) models for better video generation. The challenge arises from the architectural differences when switching from full attention to causal attention, which existing methods fail to address theoretically. The authors highlight that previous approaches struggle with ODE initialization due to the requirement of frame-level injectivity, leading to performance degradation. By utilizing an AR teacher for ODE initialization, Causal Forcing effectively bridges this gap, resulting in significant performance improvements over existing methods.","title":"Bridging the Gap in Video Generation with Causal Forcing"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a new method called Causal Forcing, which improves the process of converting bidirectional video diffusion models into autoregressive (AR) models for better video generation. The challenge arises from the architectural differences when switching from full attention to causal attention, which existing methods fail to address theoretically. The authors highlight that previous approaches struggle with ODE initialization due to the requirement of frame-level injectivity, leading to performance degradation. By utilizing an AR teacher for ODE initialization, Causal Forcing effectively bridges this gap, resulting in significant performance improvements over existing methods.', title='Bridging the Gap in Video Generation with Causal Forcing'))
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ODE19.3%8.7%16.7%","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ODE19.3%8.7%16.7%', title=''))
[03.02.2026 17:37] Querying the API.
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance.  					AI-generated summary 				 Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.
[03.02.2026 17:37] Response: ```json
{
  "desc": "          : TempCache  KV-    , AnnCA  -           ,  AnnSA         .     ,          5-10          GPU    .",
  "emoji": "",
  "title": "           "
}
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance.  					AI-generated summary 				 Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage."

[03.02.2026 17:37] Response: ```python
["VIDEO", "INFERENCE"]
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance.  					AI-generated summary 				 Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage."

[03.02.2026 17:37] Response: ```python
['DIFFUSION', 'LONG_CONTEXT', 'OPTIMIZATION']
```
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the efficiency issues in autoregressive video diffusion models, which are crucial for generating long-form videos. The authors introduce three techniques: TempCache, AnnCA, and AnnSA, which optimize the attention mechanisms to reduce computational load while preserving visual quality. TempCache minimizes the growth of the key-value (KV) cache, AnnCA speeds up cross-attention by selecting relevant tokens, and AnnSA limits self-attention to semantically relevant keys. Together, these innovations lead to significant speed improvements and stable performance during video generation, making the models more practical for real-time applications.","title":"Boosting Efficiency in Video Diffusion Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the efficiency issues in autoregressive video diffusion models, which are crucial for generating long-form videos. The authors introduce three techniques: TempCache, AnnCA, and AnnSA, which optimize the attention mechanisms to reduce computational load while preserving visual quality. TempCache minimizes the growth of the key-value (KV) cache, AnnCA speeds up cross-attention by selecting relevant tokens, and AnnSA limits self-attention to semantically relevant keys. Together, these innovations lead to significant speed improvements and stable performance during video generation, making the models more practical for real-time applications.', title='Boosting Efficiency in Video Diffusion Models'))
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"KVTempCacheAnnCAAnnSATempCacheKVAnnCAAnnSA510","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='KVTempCacheAnnCAAnnSATempCacheKVAnnCAAnnSA510', title=''))
[03.02.2026 17:37] Querying the API.
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FSVideo is a fast transformer-based image-to-video diffusion framework that uses a compressed video autoencoder, diffusion transformer architecture with enhanced layer memory, and multi-resolution generation strategy to achieve high performance with significantly reduced computation time.  					AI-generated summary 				 We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space (64times64times4 spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report.
[03.02.2026 17:37] Response: ```json
{
  "desc": "FSVideo              .     -          .        ,         .                .",
  "emoji": "",
  "title": "  :       "
}
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FSVideo is a fast transformer-based image-to-video diffusion framework that uses a compressed video autoencoder, diffusion transformer architecture with enhanced layer memory, and multi-resolution generation strategy to achieve high performance with significantly reduced computation time.  					AI-generated summary 				 We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space (64times64times4 spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report."

[03.02.2026 17:37] Response: ```python
["VIDEO", "ARCHITECTURE", "TRAINING"]
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FSVideo is a fast transformer-based image-to-video diffusion framework that uses a compressed video autoencoder, diffusion transformer architecture with enhanced layer memory, and multi-resolution generation strategy to achieve high performance with significantly reduced computation time.  					AI-generated summary 				 We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space (64times64times4 spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report."

[03.02.2026 17:37] Response: ```python
['DIFFUSION', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FSVideo is a novel framework that transforms images into videos using a fast transformer-based approach. It incorporates a compressed video autoencoder that significantly reduces the data size while maintaining high-quality video reconstruction. The diffusion transformer architecture features an enhanced layer memory, which improves the flow of information between layers, allowing for better context reuse. Additionally, a multi-resolution generation strategy is employed to boost the fidelity of the generated videos, making FSVideo both efficient and effective compared to existing models.","title":"FSVideo: Fast and Efficient Image-to-Video Transformation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FSVideo is a novel framework that transforms images into videos using a fast transformer-based approach. It incorporates a compressed video autoencoder that significantly reduces the data size while maintaining high-quality video reconstruction. The diffusion transformer architecture features an enhanced layer memory, which improves the flow of information between layers, allowing for better context reuse. Additionally, a multi-resolution generation strategy is employed to boost the fidelity of the generated videos, making FSVideo both efficient and effective compared to existing models.', title='FSVideo: Fast and Efficient Image-to-Video Transformation'))
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FSVideo","title":"FSVideo"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FSVideo', title='FSVideo'))
[03.02.2026 17:37] Querying the API.
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Selective knowledge distillation in autoregressive language models using student-entropy-guided position selection improves accuracy and efficiency while reducing memory and storage requirements.  					AI-generated summary 				 Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance.
[03.02.2026 17:37] Response: ```json
{
  "desc": "       (knowledge distillation)    ,  SE-KD,              .            ,    .  SE-KD           ,    SE-KD 3X     .         70%,     18%     80%   .",
  "emoji": "",
  "title": " :      "
}
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Selective knowledge distillation in autoregressive language models using student-entropy-guided position selection improves accuracy and efficiency while reducing memory and storage requirements.  					AI-generated summary 				 Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance."

[03.02.2026 17:37] Response: ```python
['TRAINING', 'SMALL_MODELS', 'INFERENCE']
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Selective knowledge distillation in autoregressive language models using student-entropy-guided position selection improves accuracy and efficiency while reducing memory and storage requirements.  					AI-generated summary 				 Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance."

[03.02.2026 17:37] Response: ```python
['OPTIMIZATION']
```
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a method called student-entropy-guided position selection (SE-KD) for improving knowledge distillation in autoregressive language models. The authors explore how to selectively distill knowledge by focusing on specific token positions, vocabulary classes, and training samples, rather than using all available data. Their approach shows that by carefully choosing which parts of the model to distill, they can enhance accuracy and efficiency while significantly reducing memory and storage needs. The results demonstrate that SE-KD can lead to faster processing times and lower resource consumption without compromising the model\'s performance.","title":"Efficient Knowledge Distillation with Selective Positioning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper presents a method called student-entropy-guided position selection (SE-KD) for improving knowledge distillation in autoregressive language models. The authors explore how to selectively distill knowledge by focusing on specific token positions, vocabulary classes, and training samples, rather than using all available data. Their approach shows that by carefully choosing which parts of the model to distill, they can enhance accuracy and efficiency while significantly reducing memory and storage needs. The results demonstrate that SE-KD can lead to faster processing times and lower resource consumption without compromising the model's performance.", title='Efficient Knowledge Distillation with Selective Positioning'))
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SE-KDSE-KD","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SE-KDSE-KD', title=''))
[03.02.2026 17:37] Querying the API.
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MLLMs equipped with Cognitive Supersensing and Latent Visual Imagery Prediction demonstrate enhanced cognitive reasoning capabilities through integrated visual and textual reasoning pathways.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.
[03.02.2026 17:37] Response: ```json
{
  "desc": "    Cognitive Supersensing               (LVIP).          ,   -  ,      .     CogSense-Bench         -           .          VQA  ,               .",
  "emoji": "",
  "title": "        "
}
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MLLMs equipped with Cognitive Supersensing and Latent Visual Imagery Prediction demonstrate enhanced cognitive reasoning capabilities through integrated visual and textual reasoning pathways.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights."

[03.02.2026 17:37] Response: ```python
["MULTIMODAL", "BENCHMARK", "DATASET", "TRAINING", "RL"]
```
[03.02.2026 17:37] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MLLMs equipped with Cognitive Supersensing and Latent Visual Imagery Prediction demonstrate enhanced cognitive reasoning capabilities through integrated visual and textual reasoning pathways.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights."

[03.02.2026 17:37] Response: ```python
['REASONING', 'OPEN_SOURCE']
```
[03.02.2026 17:37] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new approach called Cognitive Supersensing for Multimodal Large Language Models (MLLMs) to enhance their cognitive reasoning abilities. It introduces a Latent Visual Imagery Prediction (LVIP) mechanism that allows these models to integrate visual and textual reasoning, mimicking human-like visual memory. The authors also propose a reinforcement learning stage to optimize reasoning paths based on visual information, improving the model\'s performance on complex cognitive tasks. The results show that MLLMs using this method significantly outperform existing models on a new benchmark called CogSense-Bench, indicating the importance of visual imagery in cognitive understanding.","title":"Enhancing MLLMs with Visual Imagery for Better Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper presents a new approach called Cognitive Supersensing for Multimodal Large Language Models (MLLMs) to enhance their cognitive reasoning abilities. It introduces a Latent Visual Imagery Prediction (LVIP) mechanism that allows these models to integrate visual and textual reasoning, mimicking human-like visual memory. The authors also propose a reinforcement learning stage to optimize reasoning paths based on visual information, improving the model's performance on complex cognitive tasks. The results show that MLLMs using this method significantly outperform existing models on a new benchmark called CogSense-Bench, indicating the importance of visual imagery in cognitive understanding.", title='Enhancing MLLMs with Visual Imagery for Better Reasoning'))
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MLLMMLLMMLLM","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MLLMMLLMMLLM', title=''))
[03.02.2026 17:38] Querying the API.
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Post-training of reasoning large language models can be improved by correcting distribution mismatches between supervised fine-tuning and reinforcement learning stages through importance sampling reweighting of the SFT loss.  					AI-generated summary 				 Post-training of reasoning LLMs is a holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone.   We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to a mismatch typical in current SFT-RL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts.   We propose PEAR (Policy Evaluation-inspired Algorithm for Offline Learning Loss Re-weighting), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected.   We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen 2.5 and 3 and DeepSeek-distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass at 8 gains up to a 14.6 percent on AIME2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation.
[03.02.2026 17:38] Response: ```json
{
  "desc": "    PEAR         supervised fine-tuning  reinforcement learning.         SFT  ,    RL-,     .   importance sampling      ,    .           14,6%   pass@8   AIME2025.",
  "emoji": "",
  "title": "    SFT  RL   "
}
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Post-training of reasoning large language models can be improved by correcting distribution mismatches between supervised fine-tuning and reinforcement learning stages through importance sampling reweighting of the SFT loss.  					AI-generated summary 				 Post-training of reasoning LLMs is a holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone.   We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to a mismatch typical in current SFT-RL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts.   We propose PEAR (Policy Evaluation-inspired Algorithm for Offline Learning Loss Re-weighting), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected.   We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen 2.5 and 3 and DeepSeek-distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass at 8 gains up to a 14.6 percent on AIME2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation."

[03.02.2026 17:38] Response: ```python
["TRAINING", "RL", "MATH"]
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Post-training of reasoning large language models can be improved by correcting distribution mismatches between supervised fine-tuning and reinforcement learning stages through importance sampling reweighting of the SFT loss.  					AI-generated summary 				 Post-training of reasoning LLMs is a holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone.   We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to a mismatch typical in current SFT-RL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts.   We propose PEAR (Policy Evaluation-inspired Algorithm for Offline Learning Loss Re-weighting), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected.   We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen 2.5 and 3 and DeepSeek-distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass at 8 gains up to a 14.6 percent on AIME2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation."

[03.02.2026 17:38] Response: ```python
['REASONING', 'OPTIMIZATION']
```
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses how to improve the post-training of reasoning large language models (LLMs) by addressing the differences between supervised fine-tuning (SFT) and reinforcement learning (RL) stages. The authors introduce a method called PEAR, which uses importance sampling to adjust the SFT loss, ensuring that the model is better prepared for the RL phase. They demonstrate that models trained with PEAR show significant performance improvements in reasoning tasks compared to those trained with traditional SFT methods. The findings highlight the importance of aligning SFT and RL processes to enhance overall model effectiveness.","title":"Bridging the Gap: Enhancing LLMs with PEAR for Better Post-Training Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses how to improve the post-training of reasoning large language models (LLMs) by addressing the differences between supervised fine-tuning (SFT) and reinforcement learning (RL) stages. The authors introduce a method called PEAR, which uses importance sampling to adjust the SFT loss, ensuring that the model is better prepared for the RL phase. They demonstrate that models trained with PEAR show significant performance improvements in reasoning tasks compared to those trained with traditional SFT methods. The findings highlight the importance of aligning SFT and RL processes to enhance overall model effectiveness.', title='Bridging the Gap: Enhancing LLMs with PEAR for Better Post-Training Performance'))
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LLMSFTRLSFTRLSFTPEARSFTRLPEARRLSFTRL","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LLMSFTRLSFTRLSFTPEARSFTRLPEARRLSFTRL', title=''))
[03.02.2026 17:38] Querying the API.
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Visual Instruction Benchmark for Image Editing introduces a three-level interaction hierarchy for evaluating visual instruction following capabilities in generative models.  					AI-generated summary 				 Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.
[03.02.2026 17:38] Response: ```json
{
  "desc": "  VIBE  Visual Instruction Benchmark for Image Editing,             .     ,    , VIBE    :  ,    - .                 .   17  ,     ,           .",
  "emoji": "",
  "title": " :     "
}
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual Instruction Benchmark for Image Editing introduces a three-level interaction hierarchy for evaluating visual instruction following capabilities in generative models.  					AI-generated summary 				 Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research."

[03.02.2026 17:38] Response: ```python
["BENCHMARK", "CV", "MULTIMODAL"]
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual Instruction Benchmark for Image Editing introduces a three-level interaction hierarchy for evaluating visual instruction following capabilities in generative models.  					AI-generated summary 				 Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research."

[03.02.2026 17:38] Response: ```python
['REASONING', 'OPEN_SOURCE']
```

**Justification:**

- **REASONING**: The paper discusses a three-level interaction hierarchy that includes "causal reasoning" as one of the evaluation dimensions for visual instruction following capabilities.

- **OPEN_SOURCE**: The paper explicitly mentions evaluating "17 representative open-source and proprietary image editing models" and discusses comparisons between open-source and proprietary systems.
[03.02.2026 17:38] Error. Failed to parse JSON from LLM. ["REASONING", "OPEN_SOURCE"]


**Justification:**

- **REASONING**: The paper discusses a three-level interaction hierarchy that includes "causal reasoning" as one of the evaluation dimensions for visual instruction following capabilities.

- **OPEN_SOURCE**: The paper explicitly mentions evaluating "17 representative open-source and proprietary image editing models" and discusses comparisons between open-source and proprietary systems.
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper presents the Visual Instruction Benchmark for Image Editing (VIBE), which introduces a structured way to evaluate how well generative models can follow visual instructions. It emphasizes the importance of multimodal communication, as humans often use visual cues like sketches to convey complex ideas. VIBE features a three-level interaction hierarchy that includes deictic grounding, morphological manipulation, and causal reasoning, allowing for a nuanced assessment of model capabilities. The study evaluates various image editing models, revealing that while proprietary models perform better overall, they struggle with more complex tasks, indicating areas for future improvement.","title":"Enhancing Image Editing with Visual Instructions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper presents the Visual Instruction Benchmark for Image Editing (VIBE), which introduces a structured way to evaluate how well generative models can follow visual instructions. It emphasizes the importance of multimodal communication, as humans often use visual cues like sketches to convey complex ideas. VIBE features a three-level interaction hierarchy that includes deictic grounding, morphological manipulation, and causal reasoning, allowing for a nuanced assessment of model capabilities. The study evaluates various image editing models, revealing that while proprietary models perform better overall, they struggle with more complex tasks, indicating areas for future improvement.', title='Enhancing Image Editing with Visual Instructions'))
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"VIBEVIBE ","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='VIBEVIBE ', title=''))
[03.02.2026 17:38] Querying the API.
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A dual-stream framework called InteractAvatar is presented for generating talking avatars that can interact with objects in their environment, addressing challenges in grounded human-object interaction through decoupled perception and planning modules.  					AI-generated summary 				 Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io
[03.02.2026 17:38] Response: ```json
{
  "desc": "     InteractAvatar     ,        .            ,         .            ,    -      .      GroundedInter         .",
  "emoji": "",
  "title": " ,     "
}
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A dual-stream framework called InteractAvatar is presented for generating talking avatars that can interact with objects in their environment, addressing challenges in grounded human-object interaction through decoupled perception and planning modules.  					AI-generated summary 				 Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io"

[03.02.2026 17:38] Response: ```python
["VIDEO", "MULTIMODAL", "BENCHMARK", "ARCHITECTURE"]
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A dual-stream framework called InteractAvatar is presented for generating talking avatars that can interact with objects in their environment, addressing challenges in grounded human-object interaction through decoupled perception and planning modules.  					AI-generated summary 				 Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io"

[03.02.2026 17:38] Response: ```python
["GAMES"]
```
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces InteractAvatar, a dual-stream framework designed to create talking avatars that can interact with objects in their environment. It addresses the challenge of grounded human-object interaction (GHOI) by separating perception and planning from video synthesis. The framework includes a Perception and Interaction Module (PIM) for generating interaction motions based on environmental detection, and an Audio-Interaction Aware Generation Module (AIM) for synthesizing realistic talking avatars. By allowing parallel generation of motions and videos, InteractAvatar effectively improves the quality of interactions while establishing a benchmark for evaluating GHOI video generation.","title":"InteractAvatar: Talking Avatars that Interact with Their World"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces InteractAvatar, a dual-stream framework designed to create talking avatars that can interact with objects in their environment. It addresses the challenge of grounded human-object interaction (GHOI) by separating perception and planning from video synthesis. The framework includes a Perception and Interaction Module (PIM) for generating interaction motions based on environmental detection, and an Audio-Interaction Aware Generation Module (AIM) for synthesizing realistic talking avatars. By allowing parallel generation of motions and videos, InteractAvatar effectively improves the quality of interactions while establishing a benchmark for evaluating GHOI video generation.', title='InteractAvatar: Talking Avatars that Interact with Their World'))
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"InteractAvatarGHOIPIMAIM","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='InteractAvatarGHOIPIMAIM', title=''))
[03.02.2026 17:38] Querying the API.
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Visual metaphor transfer enables creative AI systems to decompose abstract conceptual relationships from reference images and reapply them to new subjects through a multi-agent framework grounded in cognitive theory.  					AI-generated summary 				 A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the "creative essence" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar ("G"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available.
[03.02.2026 17:38] Response: ```json
{
  "desc": "     Visual Metaphor Transfer,                 .    ,     Conceptual Blending,    Schema Grammar          .    , ,   ,                .                       .",
  "emoji": "",
  "title": "         "
}
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual metaphor transfer enables creative AI systems to decompose abstract conceptual relationships from reference images and reapply them to new subjects through a multi-agent framework grounded in cognitive theory.  					AI-generated summary 				 A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the "creative essence" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar ("G"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available."

[03.02.2026 17:38] Response: ```python
["CV", "AGENTS", "MULTIMODAL"]
```

**Justification:**

- **CV**: The paper focuses on visual processing and generation, dealing with image analysis and synthesis tasks (visual metaphor transfer, image generation).

- **AGENTS**: The paper explicitly proposes "a multi-agent framework" with "specialized agents: a perception agent, a transfer agent, a generation agent and a hierarchical diagnostic agent" that work collaboratively.

- **MULTIMODAL**: The task involves processing both visual inputs (reference images) and textual inputs (user-specified target subjects) to generate visual outputs, combining multiple modalities.
[03.02.2026 17:38] Error. Failed to parse JSON from LLM. ["CV", "AGENTS", "MULTIMODAL"]


**Justification:**

- **CV**: The paper focuses on visual processing and generation, dealing with image analysis and synthesis tasks (visual metaphor transfer, image generation).

- **AGENTS**: The paper explicitly proposes "a multi-agent framework" with "specialized agents: a perception agent, a transfer agent, a generation agent and a hierarchical diagnostic agent" that work collaboratively.

- **MULTIMODAL**: The task involves processing both visual inputs (reference images) and textual inputs (user-specified target subjects) to generate visual outputs, combining multiple modalities.
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual metaphor transfer enables creative AI systems to decompose abstract conceptual relationships from reference images and reapply them to new subjects through a multi-agent framework grounded in cognitive theory.  					AI-generated summary 				 A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the "creative essence" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar ("G"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available."

[03.02.2026 17:38] Response: ```python
['OPEN_SOURCE']
```
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Visual Metaphor Transfer (VMT), a novel approach that allows AI to creatively reinterpret abstract concepts from reference images and apply them to new subjects. The authors propose a multi-agent framework inspired by cognitive theory, specifically Conceptual Blending Theory, to facilitate this process. By using a structured Schema Grammar, the framework separates the essential creative elements from specific visuals, enabling the AI to generate meaningful metaphors. The results show that this method significantly improves metaphor consistency and visual creativity compared to existing models, suggesting its potential for applications in advertising and media.","title":"Transforming Abstract Concepts into Visual Metaphors with AI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Visual Metaphor Transfer (VMT), a novel approach that allows AI to creatively reinterpret abstract concepts from reference images and apply them to new subjects. The authors propose a multi-agent framework inspired by cognitive theory, specifically Conceptual Blending Theory, to facilitate this process. By using a structured Schema Grammar, the framework separates the essential creative elements from specific visuals, enabling the AI to generate meaningful metaphors. The results show that this method significantly improves metaphor consistency and visual creativity compared to existing models, suggesting its potential for applications in advertising and media.', title='Transforming Abstract Concepts into Visual Metaphors with AI'))
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"VMTAICBT","title":"AI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='VMTAICBT', title='AI'))
[03.02.2026 17:38] Querying the API.
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Re-TRAC is an agentic framework that enhances LLM-based research agents by enabling cross-trajectory exploration and iterative reflection through structured state representations, leading to more efficient and effective problem-solving compared to traditional ReAct approaches.  					AI-generated summary 				 LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.
[03.02.2026 17:38] Response: ```json
{
  "desc": "Re-TRAC          ,      ReAct,           .        ,      ,   .   ,  Re-TRAC  ReAct  15-20%  ,           .           ,      .",
  "emoji": "",
  "title": " :    - "
}
```
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Re-TRAC is an agentic framework that enhances LLM-based research agents by enabling cross-trajectory exploration and iterative reflection through structured state representations, leading to more efficient and effective problem-solving compared to traditional ReAct approaches.  					AI-generated summary 				 LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search."

[03.02.2026 17:38] Response: ```python
["AGENTS", "TRAINING"]
```

**Justification:**

- **AGENTS**: The paper explicitly focuses on "LLM-based research agents" and proposes "Re-TRAC, an agentic framework" that enhances agent-based problem-solving through cross-trajectory exploration and structured state representations. This is directly about autonomous agents and agent-based architectures.

- **TRAINING**: The paper mentions "Re-TRAC-aware supervised fine-tuning" for smaller models, which is a training methodology improvement discussed as part of their approach.
[03.02.2026 17:38] Error. Failed to parse JSON from LLM. ["AGENTS", "TRAINING"]


**Justification:**

- **AGENTS**: The paper explicitly focuses on "LLM-based research agents" and proposes "Re-TRAC, an agentic framework" that enhances agent-based problem-solving through cross-trajectory exploration and structured state representations. This is directly about autonomous agents and agent-based architectures.

- **TRAINING**: The paper mentions "Re-TRAC-aware supervised fine-tuning" for smaller models, which is a training methodology improvement discussed as part of their approach.
[03.02.2026 17:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Re-TRAC is an agentic framework that enhances LLM-based research agents by enabling cross-trajectory exploration and iterative reflection through structured state representations, leading to more efficient and effective problem-solving compared to traditional ReAct approaches.  					AI-generated summary 				 LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search."

[03.02.2026 17:38] Response: ```python
["REASONING", "LONG_CONTEXT", "OPTIMIZATION"]
```
[03.02.2026 17:38] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Re-TRAC is a new framework designed to improve the performance of large language model (LLM)-based research agents by allowing them to explore different paths and reflect on their findings. Unlike traditional ReAct methods, which follow a linear approach, Re-TRAC uses structured state representations to summarize past experiences and guide future actions. This method helps the agents avoid getting stuck in local optima and reduces unnecessary exploration, making the problem-solving process more efficient. Empirical results demonstrate that Re-TRAC outperforms ReAct by 15-20% and achieves better performance with smaller models through fine-tuning.","title":"Re-TRAC: Enhancing Research Agents with Iterative Reflection and Exploration"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Re-TRAC is a new framework designed to improve the performance of large language model (LLM)-based research agents by allowing them to explore different paths and reflect on their findings. Unlike traditional ReAct methods, which follow a linear approach, Re-TRAC uses structured state representations to summarize past experiences and guide future actions. This method helps the agents avoid getting stuck in local optima and reduces unnecessary exploration, making the problem-solving process more efficient. Empirical results demonstrate that Re-TRAC outperforms ReAct by 15-20% and achieves better performance with smaller models through fine-tuning.', title='Re-TRAC: Enhancing Research Agents with Iterative Reflection and Exploration'))
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Re-TRACLLMReActRe-TRACRe-TRACBrowseCompReAct15-20%","title":"Re-TRAC"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Re-TRACLLMReActRe-TRACRe-TRACBrowseCompReAct15-20%', title='Re-TRAC'))
[03.02.2026 17:39] Querying the API.
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language model control methods are unified under a dynamic weight update framework, revealing a preference-utility trade-off and enabling improved steering through SPLIT approach.  					AI-generated summary 				 Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.
[03.02.2026 17:39] Response: ```json
{
  "desc": "         (LLM) -     LoRA    -       .     ,      (   )   (    ),       .    :    ,     .         SPLIT,            .",
  "emoji": "",
  "title": "    :    LLM"
}
```
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language model control methods are unified under a dynamic weight update framework, revealing a preference-utility trade-off and enabling improved steering through SPLIT approach.  					AI-generated summary 				 Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md."

[03.02.2026 17:39] Response: ```python
["TRAINING", "ARCHITECTURE"]
```

**Justification:**

- **TRAINING**: The paper focuses on improving model training and fine-tuning methods, specifically addressing control methods for LLMs including "local weight fine-tuning, LoRA-based adaptation, and activation-based interventions." It proposes improved steering approaches and analyzes how to better preserve utility during model control.

- **ARCHITECTURE**: The paper analyzes neural components and their behavior through an "activation manifold perspective," examining how interventions affect model representations and proposing architectural insights about how control shifts representations along target-concept directions.
[03.02.2026 17:39] Error. Failed to parse JSON from LLM. ["TRAINING", "ARCHITECTURE"]


**Justification:**

- **TRAINING**: The paper focuses on improving model training and fine-tuning methods, specifically addressing control methods for LLMs including "local weight fine-tuning, LoRA-based adaptation, and activation-based interventions." It proposes improved steering approaches and analyzes how to better preserve utility during model control.

- **ARCHITECTURE**: The paper analyzes neural components and their behavior through an "activation manifold perspective," examining how interventions affect model representations and proposing architectural insights about how control shifts representations along target-concept directions.
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language model control methods are unified under a dynamic weight update framework, revealing a preference-utility trade-off and enabling improved steering through SPLIT approach.  					AI-generated summary 				 Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md."

[03.02.2026 17:39] Response: ```python
['ALIGNMENT', 'INTERPRETABILITY', 'OPTIMIZATION']
```

**Justification:**

1. **ALIGNMENT**: The paper focuses on controlling and steering LLMs toward target concepts while maintaining alignment with human preferences and intended behavior (preference-utility trade-off analysis).

2. **INTERPRETABILITY**: The paper analyzes model behavior through an "activation manifold perspective," examining how control methods affect internal representations and explaining the mechanisms behind preference-utility trade-offs.

3. **OPTIMIZATION**: The paper presents methods for optimizing LLM control through dynamic weight updates, fine-tuning approaches (LoRA), and proposes SPLIT as an improved steering approach that optimizes the balance between preference and utility.
[03.02.2026 17:39] Error. Failed to parse JSON from LLM. ["ALIGNMENT", "INTERPRETABILITY", "OPTIMIZATION"]


**Justification:**

1. **ALIGNMENT**: The paper focuses on controlling and steering LLMs toward target concepts while maintaining alignment with human preferences and intended behavior (preference-utility trade-off analysis).

2. **INTERPRETABILITY**: The paper analyzes model behavior through an "activation manifold perspective," examining how control methods affect internal representations and explaining the mechanisms behind preference-utility trade-offs.

3. **OPTIMIZATION**: The paper presents methods for optimizing LLM control through dynamic weight updates, fine-tuning approaches (LoRA), and proposes SPLIT as an improved steering approach that optimizes the balance between preference and utility.
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a unified framework for controlling large language models (LLMs) by viewing various control methods as dynamic weight updates influenced by a control signal. It introduces a preference-utility analysis that distinguishes between preference, which drives the model towards a desired concept, and utility, which ensures the output remains coherent and task-relevant. The study reveals a trade-off where stronger control enhances preference but can diminish utility, explained through the concept of an activation manifold. To address this, the authors propose a new steering method called SPLIT, which aims to improve preference while maintaining higher utility in model outputs.","title":"Balancing Preference and Utility in Language Model Control"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a unified framework for controlling large language models (LLMs) by viewing various control methods as dynamic weight updates influenced by a control signal. It introduces a preference-utility analysis that distinguishes between preference, which drives the model towards a desired concept, and utility, which ensures the output remains coherent and task-relevant. The study reveals a trade-off where stronger control enhances preference but can diminish utility, explained through the concept of an activation manifold. To address this, the authors propose a new steering method called SPLIT, which aims to improve preference while maintaining higher utility in model outputs.', title='Balancing Preference and Utility in Language Model Control'))
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SPLIT","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SPLIT', title=''))
[03.02.2026 17:39] Querying the API.
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

LatentMorph integrates implicit latent reasoning into text-to-image generation through four lightweight components that enable adaptive self-refinement and improve both efficiency and cognitive alignment.  					AI-generated summary 				 Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by 16% on GenEval and 25% on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by 15% and 11% on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by 44% and token consumption by 51%; and (IV) exhibits 71% cognitive alignment with human intuition on reasoning invocation.
[03.02.2026 17:39] Response: ```json
{
  "desc": "LatentMorph        ,        .     :     ,       ,        reinforcement learning      .        ,            .        ( 16-25%   ),     44%      51%.",
  "emoji": "",
  "title": "      "
}
```
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LatentMorph integrates implicit latent reasoning into text-to-image generation through four lightweight components that enable adaptive self-refinement and improve both efficiency and cognitive alignment.  					AI-generated summary 				 Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by 16% on GenEval and 25% on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by 15% and 11% on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by 44% and token consumption by 51%; and (IV) exhibits 71% cognitive alignment with human intuition on reasoning invocation."

[03.02.2026 17:39] Response: ```python
['CV', 'MULTIMODAL', 'RL', 'TRAINING']
```
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LatentMorph integrates implicit latent reasoning into text-to-image generation through four lightweight components that enable adaptive self-refinement and improve both efficiency and cognitive alignment.  					AI-generated summary 				 Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by 16% on GenEval and 25% on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by 15% and 11% on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by 44% and token consumption by 51%; and (IV) exhibits 71% cognitive alignment with human intuition on reasoning invocation."

[03.02.2026 17:39] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LatentMorph is a new framework for text-to-image (T2I) generation that incorporates implicit latent reasoning to enhance the creative process. It features four key components: a condenser for summarizing generation states, a translator for turning latent thoughts into guidance, a shaper for directing image predictions, and an RL-trained invoker for deciding when to reason. This approach allows for reasoning to occur in continuous latent spaces, which improves efficiency and reduces information loss compared to traditional explicit reasoning methods. Experiments show that LatentMorph significantly boosts performance and cognitive alignment with human intuition while also cutting down on inference time and resource usage.","title":"Empowering Creativity in T2I with Implicit Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LatentMorph is a new framework for text-to-image (T2I) generation that incorporates implicit latent reasoning to enhance the creative process. It features four key components: a condenser for summarizing generation states, a translator for turning latent thoughts into guidance, a shaper for directing image predictions, and an RL-trained invoker for deciding when to reason. This approach allows for reasoning to occur in continuous latent spaces, which improves efficiency and reduces information loss compared to traditional explicit reasoning methods. Experiments show that LatentMorph significantly boosts performance and cognitive alignment with human intuition while also cutting down on inference time and resource usage.', title='Empowering Creativity in T2I with Implicit Reasoning'))
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LatentMorph LatentMorph ","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LatentMorph LatentMorph ', title=''))
[03.02.2026 17:39] Querying the API.
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Visual world models for mobile GUI agents are improved through renderable code generation using vision-language models, achieving better performance with reduced model size compared to existing approaches.  					AI-generated summary 				 Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.
[03.02.2026 17:39] Response: ```json
{
  "desc": "           GUI-    -   vision-language .    , VLM    GUI   ,     ,       .   gWorld           8B  32B ,        .   ,               GUI-.",
  "emoji": "",
  "title": "   :       -"
}
```
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual world models for mobile GUI agents are improved through renderable code generation using vision-language models, achieving better performance with reduced model size compared to existing approaches.  					AI-generated summary 				 Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance."

[03.02.2026 17:39] Response: ```python
["AGENTS", "CV", "MULTIMODAL", "DATASET", "BENCHMARK", "SMALL_MODELS"]
```
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual world models for mobile GUI agents are improved through renderable code generation using vision-language models, achieving better performance with reduced model size compared to existing approaches.  					AI-generated summary 				 Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance."

[03.02.2026 17:39] Response: ```python
["OPEN_SOURCE", "SYNTHETIC"]
```

**Justification:**

1. **OPEN_SOURCE**: The paper explicitly mentions releasing "gWorld (8B, 32B), the first open-weight visual mobile GUI WMs" to the public, which constitutes a contribution of open-source models.

2. **SYNTHETIC**: The paper describes "a data generation framework (gWorld) that automatically synthesizes code-based training data," which directly relates to generating and leveraging synthetic data for training purposes.
[03.02.2026 17:39] Error. Failed to parse JSON from LLM. ["OPEN_SOURCE", "SYNTHETIC"]


**Justification:**

1. **OPEN_SOURCE**: The paper explicitly mentions releasing "gWorld (8B, 32B), the first open-weight visual mobile GUI WMs" to the public, which constitutes a contribution of open-source models.

2. **SYNTHETIC**: The paper describes "a data generation framework (gWorld) that automatically synthesizes code-based training data," which directly relates to generating and leveraging synthetic data for training purposes.
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new approach to creating visual world models for mobile graphical user interface (GUI) agents by generating renderable code using vision-language models (VLMs). Unlike traditional methods that either compromise visual quality or rely on complex pipelines, this method allows for precise text rendering while maintaining high visual fidelity. The proposed system, called gWorld, generates executable web code that can be rendered into images, effectively combining the strengths of text-based and visual models. The results show that gWorld significantly improves performance while reducing model size, outperforming existing models in various benchmarks.","title":"Revolutionizing Mobile GUI Agents with Renderable Code Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new approach to creating visual world models for mobile graphical user interface (GUI) agents by generating renderable code using vision-language models (VLMs). Unlike traditional methods that either compromise visual quality or rely on complex pipelines, this method allows for precise text rendering while maintaining high visual fidelity. The proposed system, called gWorld, generates executable web code that can be rendered into images, effectively combining the strengths of text-based and visual models. The results show that gWorld significantly improves performance while reducing model size, outperforming existing models in various benchmarks.', title='Revolutionizing Mobile GUI Agents with Renderable Code Generation'))
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"GUI-VLMgWorldGUIgWorld","title":"GUI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='GUI-VLMgWorldGUIgWorld', title='GUI'))
[03.02.2026 17:39] Querying the API.
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A Japanese financial language understanding benchmark named Ebisu is introduced, featuring two expert-annotated tasks that evaluate implicit commitment recognition and hierarchical financial terminology extraction, revealing persistent challenges for current language models despite their advanced capabilities.  					AI-generated summary 				 Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.
[03.02.2026 17:39] Response: ```json
{
  "desc": "     Ebisu         .    - :     Q&A          .    LLM,   ,       ,  ,           .  ,       ,         .",
  "emoji": "",
  "title": " :  LLM     "
}
```
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A Japanese financial language understanding benchmark named Ebisu is introduced, featuring two expert-annotated tasks that evaluate implicit commitment recognition and hierarchical financial terminology extraction, revealing persistent challenges for current language models despite their advanced capabilities.  					AI-generated summary 				 Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released."

[03.02.2026 17:39] Response: ```python
["DATASET", "BENCHMARK", "MULTILINGUAL"]
```
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A Japanese financial language understanding benchmark named Ebisu is introduced, featuring two expert-annotated tasks that evaluate implicit commitment recognition and hierarchical financial terminology extraction, revealing persistent challenges for current language models despite their advanced capabilities.  					AI-generated summary 				 Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released."

[03.02.2026 17:39] Response: ```python
['LOW_RESOURCE', 'SCIENCE', 'OPEN_SOURCE']
```
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Ebisu, a benchmark designed to assess language understanding in Japanese finance. It includes two expert-annotated tasks: JF-ICR for recognizing implicit commitments in investor Q&A, and JF-TE for extracting hierarchical financial terminology. Despite advancements in language models, the study finds that even the best-performing models struggle with these tasks, highlighting the complexity of Japanese financial language. The results indicate that simply increasing model size or adapting to specific domains does not significantly enhance performance, revealing ongoing challenges in financial natural language processing.","title":"Ebisu: Bridging Gaps in Japanese Financial Language Understanding"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces Ebisu, a benchmark designed to assess language understanding in Japanese finance. It includes two expert-annotated tasks: JF-ICR for recognizing implicit commitments in investor Q&A, and JF-TE for extracting hierarchical financial terminology. Despite advancements in language models, the study finds that even the best-performing models struggle with these tasks, highlighting the complexity of Japanese financial language. The results indicate that simply increasing model size or adapting to specific domains does not significantly enhance performance, revealing ongoing challenges in financial natural language processing.', title='Ebisu: Bridging Gaps in Japanese Financial Language Understanding'))
[03.02.2026 17:39] Response: ParsedChatCompletionMessage[Article](content='{"desc":"EbisuEbisu","title":"Ebisu"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='EbisuEbisu', title='Ebisu'))
[03.02.2026 17:39] Querying the API.
[03.02.2026 17:39] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SPARKLING is a framework for mid-stage width expansion in deep learning models that maintains signal preservation and breaks symmetry to stabilize training and reduce computational costs.  					AI-generated summary 				 Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under 2times width expansion.
[03.02.2026 17:40] Response: ```json
{
  "desc": "SPARKLING           ,         .           ,   RMS-      .     ,    ,   ,   , SPARKLING    ,    .     Mixture-of-Experts      35%    .",
  "emoji": "",
  "title": "   :      "
}
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SPARKLING is a framework for mid-stage width expansion in deep learning models that maintains signal preservation and breaks symmetry to stabilize training and reduce computational costs.  					AI-generated summary 				 Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under 2times width expansion."

[03.02.2026 17:40] Response: ```python
["TRAINING", "ARCHITECTURE"]
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SPARKLING is a framework for mid-stage width expansion in deep learning models that maintains signal preservation and breaks symmetry to stabilize training and reduce computational costs.  					AI-generated summary 				 Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under 2times width expansion."

[03.02.2026 17:40] Response: ```python
['OPTIMIZATION']
```
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SPARKLING is a new framework designed to expand the width of deep learning models during the mid-stage of training while ensuring that the signal is preserved and symmetry is broken. This approach addresses the challenges of training instabilities that arise when increasing model width, which can lead to loss spikes and reduced feature diversity. By maintaining consistent activation statistics and employing techniques like asymmetric optimizer state resetting, SPARKLING stabilizes the training process. Experimental results show that this method can significantly reduce computational costs, achieving up to 35% savings compared to traditional training methods.","title":"Enhancing Deep Learning Efficiency with Mid-Stage Width Expansion"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SPARKLING is a new framework designed to expand the width of deep learning models during the mid-stage of training while ensuring that the signal is preserved and symmetry is broken. This approach addresses the challenges of training instabilities that arise when increasing model width, which can lead to loss spikes and reduced feature diversity. By maintaining consistent activation statistics and employing techniques like asymmetric optimizer state resetting, SPARKLING stabilizes the training process. Experimental results show that this method can significantly reduce computational costs, achieving up to 35% savings compared to traditional training methods.', title='Enhancing Deep Learning Efficiency with Mid-Stage Width Expansion'))
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SPARKLINGSPARKLINGRMSSPARKLING235%","title":"SPARKLING"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SPARKLINGSPARKLINGRMSSPARKLING235%', title='SPARKLING'))
[03.02.2026 17:40] Querying the API.
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Loop-ViT introduces a recursive vision transformer architecture that decouples reasoning depth from model capacity through weight-tied recurrence and dynamic exit mechanisms, achieving superior visual reasoning performance with fewer parameters.  					AI-generated summary 				 Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT.
[03.02.2026 17:40] Response: ```json
{
  "desc": "Loop-ViT      ,               .     feed-forward ,       , Loop-ViT    ,     ,   .    Dynamic Exit    ,        .   ARC-AGI-1   18M   65.8% ,    73M .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Loop-ViT introduces a recursive vision transformer architecture that decouples reasoning depth from model capacity through weight-tied recurrence and dynamic exit mechanisms, achieving superior visual reasoning performance with fewer parameters.  					AI-generated summary 				 Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT."

[03.02.2026 17:40] Response: ```python
["ARCHITECTURE", "CV", "BENCHMARK", "SMALL_MODELS"]
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Loop-ViT introduces a recursive vision transformer architecture that decouples reasoning depth from model capacity through weight-tied recurrence and dynamic exit mechanisms, achieving superior visual reasoning performance with fewer parameters.  					AI-generated summary 				 Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT."

[03.02.2026 17:40] Response: ```python
["REASONING", "OPTIMIZATION", "OPEN_SOURCE"]
```
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Loop-ViT presents a novel recursive vision transformer architecture that separates the depth of reasoning from the model\'s capacity, allowing for more efficient visual reasoning. It utilizes weight-tied recurrence and a Dynamic Exit mechanism to optimize performance while maintaining fewer parameters. The architecture incorporates a Hybrid Block that combines local convolutions with global attention, creating a chain of thought that iteratively refines its predictions. Empirical results show that Loop-ViT outperforms larger models on the ARC-AGI benchmark, highlighting the advantages of adaptive iterative computation in visual reasoning tasks.","title":"Decoupling Reasoning Depth from Model Capacity in Visual Transformers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="Loop-ViT presents a novel recursive vision transformer architecture that separates the depth of reasoning from the model's capacity, allowing for more efficient visual reasoning. It utilizes weight-tied recurrence and a Dynamic Exit mechanism to optimize performance while maintaining fewer parameters. The architecture incorporates a Hybrid Block that combines local convolutions with global attention, creating a chain of thought that iteratively refines its predictions. Empirical results show that Loop-ViT outperforms larger models on the ARC-AGI benchmark, highlighting the advantages of adaptive iterative computation in visual reasoning tasks.", title='Decoupling Reasoning Depth from Model Capacity in Visual Transformers'))
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Loop-ViTLoop-ViTARC-AGI-118M65.8%73M","title":"Loop-ViT"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Loop-ViTLoop-ViTARC-AGI-118M65.8%73M', title='Loop-ViT'))
[03.02.2026 17:40] Querying the API.
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

PolySAE extends sparse autoencoders with polynomial decoding to capture feature interactions and compositional structure while maintaining linear encoders for interpretability.  					AI-generated summary 				 Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms. However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether "Starbucks" arises from the composition of "star" and "coffee" features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on a shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 2-10times larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency (r = 0.06 vs. r = 0.82 for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition, largely independent of surface statistics.
[03.02.2026 17:40] Response: ```json
{
  "desc": "PolySAE    (SAE)    ,            .  SAE    ,    ,             . PolySAE     ,           .         8%           ,       .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PolySAE extends sparse autoencoders with polynomial decoding to capture feature interactions and compositional structure while maintaining linear encoders for interpretability.  					AI-generated summary 				 Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms. However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether "Starbucks" arises from the composition of "star" and "coffee" features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on a shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 2-10times larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency (r = 0.06 vs. r = 0.82 for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition, largely independent of surface statistics."

[03.02.2026 17:40] Response: ```python
["ARCHITECTURE", "TRAINING"]
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PolySAE extends sparse autoencoders with polynomial decoding to capture feature interactions and compositional structure while maintaining linear encoders for interpretability.  					AI-generated summary 				 Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms. However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether "Starbucks" arises from the composition of "star" and "coffee" features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on a shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 2-10times larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency (r = 0.06 vs. r = 0.82 for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition, largely independent of surface statistics."

[03.02.2026 17:40] Response: ```python
["INTERPRETABILITY"]
```
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PolySAE is a novel approach that enhances sparse autoencoders by incorporating polynomial decoding to better understand feature interactions and compositional structures. Traditional sparse autoencoders rely on linear reconstruction, which limits their ability to differentiate between co-occurring features and those that are compositionally related. By introducing higher-order terms in the decoding process, PolySAE allows for a more nuanced representation of features while keeping the linear encoder for interpretability. The results show that PolySAE significantly improves performance in probing tasks while effectively capturing complex relationships between features without increasing the model\'s complexity significantly.","title":"PolySAE: Enhancing Interpretability with Polynomial Feature Interactions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="PolySAE is a novel approach that enhances sparse autoencoders by incorporating polynomial decoding to better understand feature interactions and compositional structures. Traditional sparse autoencoders rely on linear reconstruction, which limits their ability to differentiate between co-occurring features and those that are compositionally related. By introducing higher-order terms in the decoding process, PolySAE allows for a more nuanced representation of features while keeping the linear encoder for interpretability. The results show that PolySAE significantly improves performance in probing tasks while effectively capturing complex relationships between features without increasing the model's complexity significantly.", title='PolySAE: Enhancing Interpretability with Polynomial Feature Interactions'))
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PolySAEPolySAEPolySAE","title":"PolySAE"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PolySAEPolySAEPolySAE', title='PolySAE'))
[03.02.2026 17:40] Querying the API.
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

AgentIF-OneDay evaluates AI agents' ability to handle diverse daily tasks through natural language instructions, requiring problem-solving, attachment understanding, and file-based outputs across three user-centric categories.  					AI-generated summary 				 The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products.
[03.02.2026 17:40] Response: ```json
{
  "desc": "    AgentIF-OneDay    AI     ,    .    :    ,         .   104   767      ,     LLM    (  80.1%).  ,   AI       API  ,     .",
  "emoji": "",
  "title": "  AI     "
}
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AgentIF-OneDay evaluates AI agents' ability to handle diverse daily tasks through natural language instructions, requiring problem-solving, attachment understanding, and file-based outputs across three user-centric categories.  					AI-generated summary 				 The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products."

[03.02.2026 17:40] Response: ```python
["AGENTS", "BENCHMARK", "DATASET"]
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AgentIF-OneDay evaluates AI agents' ability to handle diverse daily tasks through natural language instructions, requiring problem-solving, attachment understanding, and file-based outputs across three user-centric categories.  					AI-generated summary 				 The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products."

[03.02.2026 17:40] Response: ```python
["REASONING"]
```

The paper discusses AI agents' ability to handle complex problem-solving tasks, understand instructions, and perform iterative refinementall of which relate to enhancing reasoning capabilities. The focus on agents solving problems through dialogue and inferring implicit instructions from context aligns with the REASONING topic.
[03.02.2026 17:40] Error. Failed to parse JSON from LLM. ["REASONING"]


The paper discusses AI agents" ability to handle complex problem-solving tasks, understand instructions, and perform iterative refinementall of which relate to enhancing reasoning capabilities. The focus on agents solving problems through dialogue and inferring implicit instructions from context aligns with the REASONING topic.
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"AgentIF-OneDay is a benchmark designed to evaluate AI agents\' performance in completing a variety of daily tasks using natural language instructions. It focuses on three main categories: Open Workflow Execution, Latent Instruction, and Iterative Refinement, which test the agents\' problem-solving abilities and understanding of different attachment types. The study highlights that while AI agents excel in complex tasks, their effectiveness in everyday scenarios is not fully recognized by users. By employing a refined evaluation pipeline and instance-level rubrics, the research demonstrates a high agreement rate between AI assessments and human judgment, showcasing the capabilities of leading AI models in practical applications.","title":"Empowering AI Agents for Everyday Tasks"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="AgentIF-OneDay is a benchmark designed to evaluate AI agents' performance in completing a variety of daily tasks using natural language instructions. It focuses on three main categories: Open Workflow Execution, Latent Instruction, and Iterative Refinement, which test the agents' problem-solving abilities and understanding of different attachment types. The study highlights that while AI agents excel in complex tasks, their effectiveness in everyday scenarios is not fully recognized by users. By employing a refined evaluation pipeline and instance-level rubrics, the research demonstrates a high agreement rate between AI assessments and human judgment, showcasing the capabilities of leading AI models in practical applications.", title='Empowering AI Agents for Everyday Tasks'))
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"AgentIF-OneDay AIAI","title":"AI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='AgentIF-OneDay AIAI', title='AI'))
[03.02.2026 17:40] Querying the API.
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Thinking with Comics emerges as an effective visual reasoning approach that bridges images and videos by leveraging comic structures for improved multimodal reasoning efficiency and performance.  					AI-generated summary 				 Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.
[03.02.2026 17:40] Response: ```json
{
  "desc": "       ,          .    ,          .                    .   ,             - ,    ,   .",
  "emoji": "",
  "title": "           "
}
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Thinking with Comics emerges as an effective visual reasoning approach that bridges images and videos by leveraging comic structures for improved multimodal reasoning efficiency and performance.  					AI-generated summary 				 Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning."

[03.02.2026 17:40] Response: ```python
['MULTIMODAL', 'VIDEO', 'CV', 'BENCHMARK']
```
[03.02.2026 17:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Thinking with Comics emerges as an effective visual reasoning approach that bridges images and videos by leveraging comic structures for improved multimodal reasoning efficiency and performance.  					AI-generated summary 				 Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning."

[03.02.2026 17:40] Response: ```python
['REASONING', 'LONG_CONTEXT']
```
[03.02.2026 17:40] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces \'Thinking with Comics\', a novel visual reasoning method that enhances the understanding of images and videos by utilizing comic structures. This approach addresses the limitations of static images, which lack temporal context, and the inefficiencies of videos, which can be redundant and computationally expensive. By leveraging the high information density of comics, the method maintains narrative coherence and embedded text while reducing reasoning costs. Experimental results demonstrate that this comic-based reasoning outperforms traditional image-based reasoning in complex tasks, highlighting the effectiveness of comics as an intermediate visual representation for multimodal reasoning.","title":"Comics: The Bridge for Smarter Visual Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces 'Thinking with Comics', a novel visual reasoning method that enhances the understanding of images and videos by utilizing comic structures. This approach addresses the limitations of static images, which lack temporal context, and the inefficiencies of videos, which can be redundant and computationally expensive. By leveraging the high information density of comics, the method maintains narrative coherence and embedded text while reducing reasoning costs. Experimental results demonstrate that this comic-based reasoning outperforms traditional image-based reasoning in complex tasks, highlighting the effectiveness of comics as an intermediate visual representation for multimodal reasoning.", title='Comics: The Bridge for Smarter Visual Reasoning'))
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='', title=''))
[03.02.2026 17:41] Querying the API.
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

TRIP-Bench presents a comprehensive long-horizon benchmark for travel planning that evaluates LLM agents on complex multi-turn interactions, while GTPO offers an online reinforcement learning approach to enhance constraint satisfaction and robustness in extended dialogues.  					AI-generated summary 				 As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce TRIP-Bench, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\% success on the easy split, with performance dropping below 10\% on hard subsets. We further propose GTPO, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.
[03.02.2026 17:41] Response: ```json
{
  "desc": "   TRIP-Bench       LLM           150      200k .    GTPO      ,            .   ,       50%     ,         10%.  GTPO   Qwen2.5-32B-Instruct          Gemini-3-Pro.",
  "emoji": "",
  "title": "  :      "
}
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TRIP-Bench presents a comprehensive long-horizon benchmark for travel planning that evaluates LLM agents on complex multi-turn interactions, while GTPO offers an online reinforcement learning approach to enhance constraint satisfaction and robustness in extended dialogues.  					AI-generated summary 				 As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce TRIP-Bench, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\% success on the easy split, with performance dropping below 10\% on hard subsets. We further propose GTPO, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training."

[03.02.2026 17:41] Response: ```python
["DATASET", "BENCHMARK", "AGENTS", "RL"]
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TRIP-Bench presents a comprehensive long-horizon benchmark for travel planning that evaluates LLM agents on complex multi-turn interactions, while GTPO offers an online reinforcement learning approach to enhance constraint satisfaction and robustness in extended dialogues.  					AI-generated summary 				 As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce TRIP-Bench, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\% success on the easy split, with performance dropping below 10\% on hard subsets. We further propose GTPO, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training."

[03.02.2026 17:41] Response: ```python
["LONG_CONTEXT", "REASONING", "OPTIMIZATION"]
```
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces TRIP-Bench, a benchmark designed to evaluate large language model (LLM) agents in complex travel planning scenarios that require multi-turn interactions. It highlights the limitations of existing benchmarks in addressing challenges like global constraint enforcement and multi-tool coordination. The benchmark includes a variety of difficulty levels, with a focus on long, ambiguous dialogues that test the models\' capabilities over extended interactions. Additionally, the paper presents GTPO, a reinforcement learning approach that enhances the performance of LLMs in these scenarios by improving constraint satisfaction and robustness during dialogues.","title":"Enhancing Travel Planning with TRIP-Bench and GTPO"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces TRIP-Bench, a benchmark designed to evaluate large language model (LLM) agents in complex travel planning scenarios that require multi-turn interactions. It highlights the limitations of existing benchmarks in addressing challenges like global constraint enforcement and multi-tool coordination. The benchmark includes a variety of difficulty levels, with a focus on long, ambiguous dialogues that test the models' capabilities over extended interactions. Additionally, the paper presents GTPO, a reinforcement learning approach that enhances the performance of LLMs in these scenarios by improving constraint satisfaction and robustness during dialogues.", title='Enhancing Travel Planning with TRIP-Bench and GTPO'))
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TRIP-BenchLLM184050%10%GTPO","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TRIP-BenchLLM184050%10%GTPO', title=''))
[03.02.2026 17:41] Querying the API.
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel framework called CoDiQ enables controllable difficulty generation for competition-level questions through test-time scaling, resulting in a corpus that significantly improves large reasoning model performance.  					AI-generated summary 				 Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.
[03.02.2026 17:41] Response: ```json
{
  "desc": "     CoDiQ              .   ,        ,    .    Qwen3-8B   CoDiQ-Generator,       .         44K    (CoDiQ-Corpus)           .",
  "emoji": "",
  "title": "          "
}
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework called CoDiQ enables controllable difficulty generation for competition-level questions through test-time scaling, resulting in a corpus that significantly improves large reasoning model performance.  					AI-generated summary 				 Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research."

[03.02.2026 17:41] Response: ```python
["DATASET", "TRAINING", "BENCHMARK", "PLP"]
```

**Justification:**

- **DATASET**: The paper introduces CoDiQ-Corpus, a new dataset of 44K competition-grade question sequences.
- **TRAINING**: The paper focuses on improving model training through a novel framework for generating training data and demonstrates that training LRMs on this corpus improves reasoning performance.
- **BENCHMARK**: The paper references LiveCodeBench/AIME as benchmarks and evaluates questions against them, contributing to model evaluation frameworks.
- **PLP**: The paper deals with competition-level programming questions and code generation, which falls under Programming Language Processing.
[03.02.2026 17:41] Error. Failed to parse JSON from LLM. ["DATASET", "TRAINING", "BENCHMARK", "PLP"]


**Justification:**

- **DATASET**: The paper introduces CoDiQ-Corpus, a new dataset of 44K competition-grade question sequences.
- **TRAINING**: The paper focuses on improving model training through a novel framework for generating training data and demonstrates that training LRMs on this corpus improves reasoning performance.
- **BENCHMARK**: The paper references LiveCodeBench/AIME as benchmarks and evaluates questions against them, contributing to model evaluation frameworks.
- **PLP**: The paper deals with competition-level programming questions and code generation, which falls under Programming Language Processing.
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework called CoDiQ enables controllable difficulty generation for competition-level questions through test-time scaling, resulting in a corpus that significantly improves large reasoning model performance.  					AI-generated summary 				 Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research."

[03.02.2026 17:41] Response: ```python
["REASONING", "SYNTHETIC", "OPEN_SOURCE"]
```
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces CoDiQ, a framework designed to generate competition-level questions with controllable difficulty. It addresses the limitations of existing methods that struggle with difficulty control and high computational costs. By using test-time scaling, CoDiQ allows for fine-tuned difficulty adjustments while maintaining question solvability. The resulting CoDiQ-Corpus, containing 44,000 high-quality questions, significantly enhances the performance of large reasoning models during training.","title":"CoDiQ: Mastering Question Difficulty for Enhanced AI Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces CoDiQ, a framework designed to generate competition-level questions with controllable difficulty. It addresses the limitations of existing methods that struggle with difficulty control and high computational costs. By using test-time scaling, CoDiQ allows for fine-tuned difficulty adjustments while maintaining question solvability. The resulting CoDiQ-Corpus, containing 44,000 high-quality questions, significantly enhances the performance of large reasoning models during training.', title='CoDiQ: Mastering Question Difficulty for Enhanced AI Reasoning'))
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CoDiQCoDiQCoDiQ44K","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CoDiQCoDiQCoDiQ44K', title=''))
[03.02.2026 17:41] Querying the API.
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks.  					AI-generated summary 				 Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.
[03.02.2026 17:41] Response: ```json
{
  "desc": "Rubric-ARM   ,                 .      ,          ,        .        ,        ,     .          ,        .",
  "emoji": "",
  "title": "         "
}
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks.  					AI-generated summary 				 Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings."

[03.02.2026 17:41] Response: ```python
["RL", "RLHF", "BENCHMARK"]
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks.  					AI-generated summary 				 Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings."

[03.02.2026 17:41] Response: ```python
['ALIGNMENT', 'OPTIMIZATION', 'REASONING']
```

**Justification:**

1. **ALIGNMENT**: The paper discusses "policy alignment" and improving response quality assessment, which relates to aligning model outputs with desired behavior and human preferences.

2. **OPTIMIZATION**: The paper explicitly focuses on "jointly optimizes rubric generation and judging" and introduces "an alternating optimization strategy" with theoretical analysis of gradient variance reduction during training.

3. **REASONING**: The framework addresses assessment of "creative and open-ended tasks" and improving judgment accuracy through learned rubrics, which involves reasoning about response quality in complex domains.
[03.02.2026 17:41] Error. Failed to parse JSON from LLM. ["ALIGNMENT", "OPTIMIZATION", "REASONING"]


**Justification:**

1. **ALIGNMENT**: The paper discusses "policy alignment" and improving response quality assessment, which relates to aligning model outputs with desired behavior and human preferences.

2. **OPTIMIZATION**: The paper explicitly focuses on "jointly optimizes rubric generation and judging" and introduces "an alternating optimization strategy" with theoretical analysis of gradient variance reduction during training.

3. **REASONING**: The framework addresses assessment of "creative and open-ended tasks" and improving judgment accuracy through learned rubrics, which involves reasoning about response quality in complex domains.
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Rubric-ARM framework enhances the assessment of creative responses by integrating rubric generation and judging through reinforcement learning. Traditional reward models often provide simple scores that overlook the complexity of quality in creative tasks. Rubric-ARM innovatively treats rubric creation as a dynamic process, optimizing it alongside the judging mechanism to improve accuracy. By employing an alternating optimization strategy, the framework effectively reduces training variability, leading to superior performance in various benchmarks and better alignment in reinforcement learning applications.","title":"Revolutionizing Response Quality Assessment with Rubric-ARM"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Rubric-ARM framework enhances the assessment of creative responses by integrating rubric generation and judging through reinforcement learning. Traditional reward models often provide simple scores that overlook the complexity of quality in creative tasks. Rubric-ARM innovatively treats rubric creation as a dynamic process, optimizing it alongside the judging mechanism to improve accuracy. By employing an alternating optimization strategy, the framework effectively reduces training variability, leading to superior performance in various benchmarks and better alignment in reinforcement learning applications.', title='Revolutionizing Response Quality Assessment with Rubric-ARM'))
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Rubric-ARMRubric-ARM","title":"Rubric-ARM"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Rubric-ARMRubric-ARM', title='Rubric-ARM'))
[03.02.2026 17:41] Querying the API.
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Flow matching models for text-to-image generation are enhanced through a reinforcement learning framework that addresses sample inefficiency and prompt overfitting by incorporating language models for prompt refinement, achieving superior performance with reduced computational requirements.  					AI-generated summary 				 Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore.   Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2times fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL.
[03.02.2026 17:41] Response: ```json
{
  "desc": "   PromptRL  ,    flow matching      ,          .  ,   RL             ,         .         flow-based RL,              .   ,  PromptRL       ,   ,        .",
  "emoji": "",
  "title": "        "
}
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Flow matching models for text-to-image generation are enhanced through a reinforcement learning framework that addresses sample inefficiency and prompt overfitting by incorporating language models for prompt refinement, achieving superior performance with reduced computational requirements.  					AI-generated summary 				 Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore.   Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2times fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL."

[03.02.2026 17:41] Response: ```python
['RL', 'RLHF', 'MULTIMODAL', 'TRAINING', 'BENCHMARK']
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Flow matching models for text-to-image generation are enhanced through a reinforcement learning framework that addresses sample inefficiency and prompt overfitting by incorporating language models for prompt refinement, achieving superior performance with reduced computational requirements.  					AI-generated summary 				 Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore.   Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2times fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL."

[03.02.2026 17:41] Response: ```python
['OPTIMIZATION', 'ALIGNMENT', 'OPEN_SOURCE']
```

**Justification:**

1. **OPTIMIZATION**: The paper focuses on improving training efficiency and performance of flow matching models through reinforcement learning, addressing sample inefficiency and achieving superior performance with reduced computational requirements.

2. **ALIGNMENT**: The paper explicitly discusses using RL as a "post-training strategy for alignment with reward objectives" and uses reward-based optimization to align the model's outputs with desired objectives.

3. **OPEN_SOURCE**: The paper states "Our code is available at https://github.com/G-U-N/UniRL," indicating the authors are releasing their code publicly.
[03.02.2026 17:41] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "ALIGNMENT", "OPEN_SOURCE"]


**Justification:**

1. **OPTIMIZATION**: The paper focuses on improving training efficiency and performance of flow matching models through reinforcement learning, addressing sample inefficiency and achieving superior performance with reduced computational requirements.

2. **ALIGNMENT**: The paper explicitly discusses using RL as a "post-training strategy for alignment with reward objectives" and uses reward-based optimization to align the model"s outputs with desired objectives.

3. **OPEN_SOURCE**: The paper states "Our code is available at https://github.com/G-U-N/UniRL," indicating the authors are releasing their code publicly.
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces PromptRL, a novel framework that enhances flow matching models for text-to-image generation using reinforcement learning. It addresses two key issues: sample inefficiency, which limits the diversity of generated images, and prompt overfitting, where models fail to generalize to varied prompts. By integrating language models for prompt refinement within the reinforcement learning process, PromptRL improves the model\'s ability to generate diverse and high-quality images. The results show significant performance improvements on various benchmarks while reducing the computational resources needed for training.","title":"Enhancing Text-to-Image Generation with Prompt Refinement in RL"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces PromptRL, a novel framework that enhances flow matching models for text-to-image generation using reinforcement learning. It addresses two key issues: sample inefficiency, which limits the diversity of generated images, and prompt overfitting, where models fail to generalize to varied prompts. By integrating language models for prompt refinement within the reinforcement learning process, PromptRL improves the model's ability to generate diverse and high-quality images. The results show significant performance improvements on various benchmarks while reducing the computational resources needed for training.", title='Enhancing Text-to-Image Generation with Prompt Refinement in RL'))
[03.02.2026 17:41] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PromptRLPromptRLPromptRL","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PromptRLPromptRLPromptRL', title=''))
[03.02.2026 17:41] Querying the API.
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Research identifies a sparse reward subsystem in LLM hidden states containing value neurons that represent internal state expectations and dopamine-like neurons encoding reward prediction errors.  					AI-generated summary 				 In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.
[03.02.2026 17:41] Response: ```json
{
  "desc": "          ,     .      ,        ,        .           ,       .  ,    ,          ,      .",
  "emoji": "",
  "title": "     "
}
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research identifies a sparse reward subsystem in LLM hidden states containing value neurons that represent internal state expectations and dopamine-like neurons encoding reward prediction errors.  					AI-generated summary 				 In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected."

[03.02.2026 17:41] Response: ```python
["ARCHITECTURE", "TRAINING"]
```
[03.02.2026 17:41] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research identifies a sparse reward subsystem in LLM hidden states containing value neurons that represent internal state expectations and dopamine-like neurons encoding reward prediction errors.  					AI-generated summary 				 In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected."

[03.02.2026 17:41] Response: ```python
["INTERPRETABILITY", "REASONING", "TRANSFER_LEARNING"]
```
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores a specific subsystem in the hidden states of Large Language Models (LLMs) that functions similarly to the reward system in the human brain. It identifies \'value neurons\' that predict the expected value of states, which are crucial for the model\'s reasoning capabilities. The research shows that these neurons are consistent across various datasets and model architectures, indicating their robustness and transferability. Additionally, the study uncovers \'dopamine neurons\' that signal reward prediction errors, highlighting their role in adjusting expectations based on actual rewards received.","title":"Unlocking the Reward System in Large Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper explores a specific subsystem in the hidden states of Large Language Models (LLMs) that functions similarly to the reward system in the human brain. It identifies 'value neurons' that predict the expected value of states, which are crucial for the model's reasoning capabilities. The research shows that these neurons are consistent across various datasets and model architectures, indicating their robustness and transferability. Additionally, the study uncovers 'dopamine neurons' that signal reward prediction errors, highlighting their role in adjusting expectations based on actual rewards received.", title='Unlocking the Reward System in Large Language Models'))
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LLMRPE","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LLMRPE', title=''))
[03.02.2026 17:42] Querying the API.
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Adaptive Ability Decomposing (AD) enhances reinforcement learning with verifiable rewards by decomposing complex questions into simpler sub-questions, improving LLM reasoning through guided exploration without requiring a teacher model.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A^2D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A^2D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.
[03.02.2026 17:42] Response: ```json
{
  "desc": "    Adaptive Ability Decomposing (AD)                 .         ,        .    LLM         ,    . AD                .",
  "emoji": "",
  "title": " :      "
}
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adaptive Ability Decomposing (AD) enhances reinforcement learning with verifiable rewards by decomposing complex questions into simpler sub-questions, improving LLM reasoning through guided exploration without requiring a teacher model.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A^2D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A^2D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities."

[03.02.2026 17:42] Response: ```python
["RL", "TRAINING"]
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adaptive Ability Decomposing (AD) enhances reinforcement learning with verifiable rewards by decomposing complex questions into simpler sub-questions, improving LLM reasoning through guided exploration without requiring a teacher model.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A^2D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A^2D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities."

[03.02.2026 17:42] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Adaptive Ability Decomposing (AD) is a method that improves reinforcement learning with verifiable rewards (RLVR) by breaking down complex questions into simpler sub-questions. This approach enhances the reasoning capabilities of large language models (LLMs) by providing structured guidance during the learning process, allowing for more effective exploration. AD trains a decomposer to create these sub-questions without needing a teacher model, which helps the main model learn better. The method has been shown to be effective compared to other techniques and can be integrated into various RLVR algorithms as a flexible module.","title":"Decomposing Complexity for Smarter Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Adaptive Ability Decomposing (AD) is a method that improves reinforcement learning with verifiable rewards (RLVR) by breaking down complex questions into simpler sub-questions. This approach enhances the reasoning capabilities of large language models (LLMs) by providing structured guidance during the learning process, allowing for more effective exploration. AD trains a decomposer to create these sub-questions without needing a teacher model, which helps the main model learn better. The method has been shown to be effective compared to other techniques and can be integrated into various RLVR algorithms as a flexible module.', title='Decomposing Complexity for Smarter Learning'))
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ADLLMRLVRADADRLVR","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ADLLMRLVRADADRLVR', title=''))
[03.02.2026 17:42] Querying the API.
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Post-training quantization effects in world models reveal unique failure modes and trade-offs between accuracy, bit-width, and planning performance, particularly in encoder-predictor module asymmetries and low-bit rollout stability.  					AI-generated summary 				 World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM.
[03.02.2026 17:42] Response: ```json
{
  "desc": "    -   world models,          .             ,          .  ,            ,           .        world models    .",
  "emoji": "",
  "title": "    :    "
}
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Post-training quantization effects in world models reveal unique failure modes and trade-offs between accuracy, bit-width, and planning performance, particularly in encoder-predictor module asymmetries and low-bit rollout stability.  					AI-generated summary 				 World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM."

[03.02.2026 17:42] Response: ```python
["INFERENCE", "AGENTS", "RL"]
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Post-training quantization effects in world models reveal unique failure modes and trade-offs between accuracy, bit-width, and planning performance, particularly in encoder-predictor module asymmetries and low-bit rollout stability.  					AI-generated summary 				 World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM."

[03.02.2026 17:42] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **OPTIMIZATION**: The paper focuses on post-training quantization (PTQ), which is a model optimization technique aimed at reducing computational cost and memory footprint for efficient deployment. The systematic study of quantization methods, bit-widths, and their effects on model performance directly relates to optimization.

- **OPEN_SOURCE**: The paper explicitly states "The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM," indicating the authors are releasing code/resources publicly.
[03.02.2026 17:42] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **OPTIMIZATION**: The paper focuses on post-training quantization (PTQ), which is a model optimization technique aimed at reducing computational cost and memory footprint for efficient deployment. The systematic study of quantization methods, bit-widths, and their effects on model performance directly relates to optimization.

- **OPEN_SOURCE**: The paper explicitly states "The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM," indicating the authors are releasing code/resources publicly.
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the impact of post-training quantization (PTQ) on world models, which are used for simulating and planning in environments. The authors conduct experiments to evaluate how different quantization methods affect model performance, particularly focusing on accuracy, bit-width, and planning capabilities. They discover that quantization can lead to unique failure modes, especially due to asymmetries between the encoder and predictor modules. The findings highlight the importance of careful quantization strategies to maintain performance while reducing computational costs.","title":"Navigating the Trade-offs of Quantization in World Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the impact of post-training quantization (PTQ) on world models, which are used for simulating and planning in environments. The authors conduct experiments to evaluate how different quantization methods affect model performance, particularly focusing on accuracy, bit-width, and planning capabilities. They discover that quantization can lead to unique failure modes, especially due to asymmetries between the encoder and predictor modules. The findings highlight the importance of careful quantization strategies to maintain performance while reducing computational costs.', title='Navigating the Trade-offs of Quantization in World Models'))
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PTQ","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PTQ', title=''))
[03.02.2026 17:42] Querying the API.
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A new test-time scaling framework called Prism is introduced for discrete diffusion language models that improves reasoning performance through hierarchical trajectory search, local branching with partial remasking, and self-verified feedback mechanisms.  					AI-generated summary 				 Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.
[03.02.2026 17:42] Response: ```json
{
  "desc": "    Prism          .            ,     masking'     ,        .                ,   best-of-N      .",
  "emoji": "",
  "title": " :        "
}
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new test-time scaling framework called Prism is introduced for discrete diffusion language models that improves reasoning performance through hierarchical trajectory search, local branching with partial remasking, and self-verified feedback mechanisms.  					AI-generated summary 				 Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism."

[03.02.2026 17:42] Response: ```python
["INFERENCE", "TRAINING", "BENCHMARK"]
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new test-time scaling framework called Prism is introduced for discrete diffusion language models that improves reasoning performance through hierarchical trajectory search, local branching with partial remasking, and self-verified feedback mechanisms.  					AI-generated summary 				 Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism."

[03.02.2026 17:42] Response: ```python
['DIFFUSION', 'REASONING', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Prism, a new framework designed to enhance the reasoning capabilities of discrete diffusion language models (dLLMs) during inference. It employs a Hierarchical Trajectory Search (HTS) to optimize computational resources by dynamically pruning and reallocating them in the denoising process. Additionally, Prism utilizes Local Branching with Partial Remasking to maintain high-confidence tokens while exploring diverse outputs. Finally, it incorporates Self-Verified Feedback (SVF) to improve the model\'s self-evaluation, resulting in better performance with fewer function evaluations across various benchmarks.","title":"Unlocking dLLMs: Efficient Reasoning with Prism"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces Prism, a new framework designed to enhance the reasoning capabilities of discrete diffusion language models (dLLMs) during inference. It employs a Hierarchical Trajectory Search (HTS) to optimize computational resources by dynamically pruning and reallocating them in the denoising process. Additionally, Prism utilizes Local Branching with Partial Remasking to maintain high-confidence tokens while exploring diverse outputs. Finally, it incorporates Self-Verified Feedback (SVF) to improve the model's self-evaluation, resulting in better performance with fewer function evaluations across various benchmarks.", title='Unlocking dLLMs: Efficient Reasoning with Prism'))
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PrismPrismPrism","title":"Prism"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PrismPrismPrism', title='Prism'))
[03.02.2026 17:42] Querying the API.
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

LiP-Map presents a line-plane joint optimization framework that explicitly models learnable line and planar primitives for accurate 3D line mapping in man-made environments.  					AI-generated summary 				 3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch. We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research.
[03.02.2026 17:42] Response: ```json
{
  "desc": "LiP-Map               RGB-.        ,      ,           .                  (   3-5 ).          100             .",
  "emoji": "",
  "title": "       3D-"
}
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LiP-Map presents a line-plane joint optimization framework that explicitly models learnable line and planar primitives for accurate 3D line mapping in man-made environments.  					AI-generated summary 				 3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch. We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research."

[03.02.2026 17:42] Response: ```python
["3D", "CV"]
```
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LiP-Map presents a line-plane joint optimization framework that explicitly models learnable line and planar primitives for accurate 3D line mapping in man-made environments.  					AI-generated summary 				 3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch. We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research."

[03.02.2026 17:42] Response: ```python
[]
```

This paper is about 3D line mapping and reconstruction from RGB images using geometric primitives (lines and planes). It does not relate to any of the provided topics, which focus on machine learning, language models, and AI systems. The paper is primarily a computer vision/3D reconstruction work that falls outside the scope of the given classification topics.
[03.02.2026 17:42] Error. Failed to parse JSON from LLM. []


This paper is about 3D line mapping and reconstruction from RGB images using geometric primitives (lines and planes). It does not relate to any of the provided topics, which focus on machine learning, language models, and AI systems. The paper is primarily a computer vision/3D reconstruction work that falls outside the scope of the given classification topics.
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LiP-Map introduces a novel framework for 3D line mapping that combines line and planar elements to enhance accuracy in man-made environments. By modeling learnable line and planar primitives, it effectively captures the relationship between lines and planes, which are essential for structured scene representation. The framework operates efficiently, completing reconstructions in just 3 to 5 minutes per scene, while significantly improving mapping quality on various datasets. Additionally, LiP-Map enhances line-assisted visual localization, demonstrating its effectiveness in practical applications.","title":"Revolutionizing 3D Line Mapping with LiP-Map"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LiP-Map introduces a novel framework for 3D line mapping that combines line and planar elements to enhance accuracy in man-made environments. By modeling learnable line and planar primitives, it effectively captures the relationship between lines and planes, which are essential for structured scene representation. The framework operates efficiently, completing reconstructions in just 3 to 5 minutes per scene, while significantly improving mapping quality on various datasets. Additionally, LiP-Map enhances line-assisted visual localization, demonstrating its effectiveness in practical applications.', title='Revolutionizing 3D Line Mapping with LiP-Map'))
[03.02.2026 17:42] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LiP-Map3D3D3D3DLiP-Map3DLiP-Map","title":"LiP-Map3D"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LiP-Map3D3D3D3DLiP-Map3DLiP-Map', title='LiP-Map3D'))
[03.02.2026 17:42] Querying the API.
[03.02.2026 17:42] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

PISA is a novel sparse attention method that improves diffusion transformer efficiency by approximating non-critical attention blocks instead of discarding them, achieving faster processing with maintained quality.  					AI-generated summary 				 Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: https://github.com/xie-lab-ml/piecewise-sparse-attention.
[03.02.2026 17:43] Response: ```json
{
  "desc": "    PISA,              .  ,         ,       . PISA   exact-or-approximate:               .     1.91-2.57    ,        .",
  "emoji": "",
  "title": "  ,  :   "
}
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PISA is a novel sparse attention method that improves diffusion transformer efficiency by approximating non-critical attention blocks instead of discarding them, achieving faster processing with maintained quality.  					AI-generated summary 				 Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: https://github.com/xie-lab-ml/piecewise-sparse-attention."

[03.02.2026 17:43] Response: ```python
["INFERENCE", "ARCHITECTURE", "VIDEO", "MULTIMODAL"]
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"PISA is a novel sparse attention method that improves diffusion transformer efficiency by approximating non-critical attention blocks instead of discarding them, achieving faster processing with maintained quality.  					AI-generated summary 				 Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: https://github.com/xie-lab-ml/piecewise-sparse-attention."

[03.02.2026 17:43] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PISA is a new method for sparse attention in diffusion transformers that enhances efficiency by approximating non-critical attention blocks instead of discarding them. This approach addresses the inefficiencies caused by the quadratic complexity of traditional attention mechanisms, which can slow down processing. By leveraging the stable distribution of attention scores in non-critical blocks, PISA maintains high-quality outputs while significantly speeding up computations. The method achieves impressive speedups in various applications, demonstrating its effectiveness in balancing performance and quality in machine learning tasks.","title":"PISA: Efficient Attention Without Compromise"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PISA is a new method for sparse attention in diffusion transformers that enhances efficiency by approximating non-critical attention blocks instead of discarding them. This approach addresses the inefficiencies caused by the quadratic complexity of traditional attention mechanisms, which can slow down processing. By leveraging the stable distribution of attention scores in non-critical blocks, PISA maintains high-quality outputs while significantly speeding up computations. The method achieves impressive speedups in various applications, demonstrating its effectiveness in balancing performance and quality in machine learning tasks.', title='PISA: Efficient Attention Without Compromise'))
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"PISAPISAPISA","title":"PISA"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='PISAPISAPISA', title='PISA'))
[03.02.2026 17:43] Querying the API.
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

VisionTrim is a training-free framework that accelerates multimodal large language models by selecting dominant visual tokens and merging them with text-guided complementation, improving efficiency without performance loss.  					AI-generated summary 				 Multimodal large language models (MLLMs) suffer from high computational costs due to excessive visual tokens, particularly in high-resolution and video-based scenarios. Existing token reduction methods typically focus on isolated pipeline components and often neglect textual alignment, leading to performance degradation. In this paper, we propose VisionTrim, a unified framework for training-free MLLM acceleration, integrating two effective plug-and-play modules: 1) the Dominant Vision Token Selection (DVTS) module, which preserves essential visual tokens via a global-local view, and 2) the Text-Guided Vision Complement (TGVC) module, which facilitates context-aware token merging guided by textual cues. Extensive experiments across diverse image and video multimodal benchmarks demonstrate the performance superiority of our VisionTrim, advancing practical MLLM deployment in real-world applications. The code is available at: https://github.com/hanxunyu/VisionTrim.
[03.02.2026 17:43] Response: ```json
{
  "desc": "VisionTrim               .    :     ,     - ,      ,        .             ,    .             MLLM   .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VisionTrim is a training-free framework that accelerates multimodal large language models by selecting dominant visual tokens and merging them with text-guided complementation, improving efficiency without performance loss.  					AI-generated summary 				 Multimodal large language models (MLLMs) suffer from high computational costs due to excessive visual tokens, particularly in high-resolution and video-based scenarios. Existing token reduction methods typically focus on isolated pipeline components and often neglect textual alignment, leading to performance degradation. In this paper, we propose VisionTrim, a unified framework for training-free MLLM acceleration, integrating two effective plug-and-play modules: 1) the Dominant Vision Token Selection (DVTS) module, which preserves essential visual tokens via a global-local view, and 2) the Text-Guided Vision Complement (TGVC) module, which facilitates context-aware token merging guided by textual cues. Extensive experiments across diverse image and video multimodal benchmarks demonstrate the performance superiority of our VisionTrim, advancing practical MLLM deployment in real-world applications. The code is available at: https://github.com/hanxunyu/VisionTrim."

[03.02.2026 17:43] Response: ```python
['MULTIMODAL', 'INFERENCE', 'VIDEO']
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VisionTrim is a training-free framework that accelerates multimodal large language models by selecting dominant visual tokens and merging them with text-guided complementation, improving efficiency without performance loss.  					AI-generated summary 				 Multimodal large language models (MLLMs) suffer from high computational costs due to excessive visual tokens, particularly in high-resolution and video-based scenarios. Existing token reduction methods typically focus on isolated pipeline components and often neglect textual alignment, leading to performance degradation. In this paper, we propose VisionTrim, a unified framework for training-free MLLM acceleration, integrating two effective plug-and-play modules: 1) the Dominant Vision Token Selection (DVTS) module, which preserves essential visual tokens via a global-local view, and 2) the Text-Guided Vision Complement (TGVC) module, which facilitates context-aware token merging guided by textual cues. Extensive experiments across diverse image and video multimodal benchmarks demonstrate the performance superiority of our VisionTrim, advancing practical MLLM deployment in real-world applications. The code is available at: https://github.com/hanxunyu/VisionTrim."

[03.02.2026 17:43] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

1. **OPTIMIZATION**: The paper focuses on accelerating multimodal large language models through token reduction and efficiency improvements. VisionTrim is explicitly described as a framework for "training-free MLLM acceleration" that improves computational efficiency, which directly relates to optimization of model performance and resource usage.

2. **OPEN_SOURCE**: The paper explicitly states "The code is available at: https://github.com/hanxunyu/VisionTrim," indicating that the authors are releasing their framework and code publicly as an open-source contribution.
[03.02.2026 17:43] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

1. **OPTIMIZATION**: The paper focuses on accelerating multimodal large language models through token reduction and efficiency improvements. VisionTrim is explicitly described as a framework for "training-free MLLM acceleration" that improves computational efficiency, which directly relates to optimization of model performance and resource usage.

2. **OPEN_SOURCE**: The paper explicitly states "The code is available at: https://github.com/hanxunyu/VisionTrim," indicating that the authors are releasing their framework and code publicly as an open-source contribution.
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"VisionTrim is a novel framework designed to enhance the efficiency of multimodal large language models (MLLMs) without the need for training. It addresses the challenge of high computational costs caused by an abundance of visual tokens, especially in high-resolution and video contexts. The framework introduces two key modules: the Dominant Vision Token Selection (DVTS) module, which identifies and retains the most important visual tokens, and the Text-Guided Vision Complement (TGVC) module, which merges visual tokens with textual information for better context understanding. Through extensive testing, VisionTrim has shown to improve performance while reducing resource usage, making it suitable for real-world applications.","title":"Accelerating MLLMs with VisionTrim: Efficiency Meets Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='VisionTrim is a novel framework designed to enhance the efficiency of multimodal large language models (MLLMs) without the need for training. It addresses the challenge of high computational costs caused by an abundance of visual tokens, especially in high-resolution and video contexts. The framework introduces two key modules: the Dominant Vision Token Selection (DVTS) module, which identifies and retains the most important visual tokens, and the Text-Guided Vision Complement (TGVC) module, which merges visual tokens with textual information for better context understanding. Through extensive testing, VisionTrim has shown to improve performance while reducing resource usage, making it suitable for real-world applications.', title='Accelerating MLLMs with VisionTrim: Efficiency Meets Performance'))
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"VisionTrimMLLMDominant Vision Token SelectionDVTSText-Guided Vision ComplementTGVCVisionTrimMLLM","title":"VisionTrim"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='VisionTrimMLLMDominant Vision Token SelectionDVTSText-Guided Vision ComplementTGVCVisionTrimMLLM', title='VisionTrim'))
[03.02.2026 17:43] Querying the API.
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Small language models can effectively evaluate outputs by leveraging internal representations rather than generating responses, enabling a more efficient and interpretable evaluation approach through a probing-based framework.  					AI-generated summary 				 Large language models (LLMs) are widely used as reference-free evaluators via prompting, but this "LLM-as-a-Judge" paradigm is costly, opaque, and sensitive to prompt design. In this work, we investigate whether smaller models can serve as efficient evaluators by leveraging internal representations instead of surface generation. We uncover a consistent empirical pattern: small LMs, despite with weak generative ability, encode rich evaluative signals in their hidden states. This motivates us to propose the Semantic Capacity Asymmetry Hypothesis: evaluation requires significantly less semantic capacity than generation and can be grounded in intermediate representations, suggesting that evaluation does not necessarily need to rely on large-scale generative models but can instead leverage latent features from smaller ones. Our findings motivate a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge, a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output. We instantiate this paradigm through INSPECTOR, a probing-based framework that predicts aspect-level evaluation scores from small model representations. Experiments on reasoning benchmarks (GSM8K, MATH, GPQA) show that INSPECTOR substantially outperforms prompting-based small LMs and closely approximates full LLM judges, while offering a more efficient, reliable, and interpretable alternative for scalable evaluation.
[03.02.2026 17:43] Response: ```json
{
  "desc": " ,         ,      .      :       ,   .   \"LLM-as-a-Judge\"    \"Representation-as-a-Judge\"     ,    .   INSPECTOR        ,     ,       .",
  "emoji": "",
  "title": "  :       "
}
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Small language models can effectively evaluate outputs by leveraging internal representations rather than generating responses, enabling a more efficient and interpretable evaluation approach through a probing-based framework.  					AI-generated summary 				 Large language models (LLMs) are widely used as reference-free evaluators via prompting, but this "LLM-as-a-Judge" paradigm is costly, opaque, and sensitive to prompt design. In this work, we investigate whether smaller models can serve as efficient evaluators by leveraging internal representations instead of surface generation. We uncover a consistent empirical pattern: small LMs, despite with weak generative ability, encode rich evaluative signals in their hidden states. This motivates us to propose the Semantic Capacity Asymmetry Hypothesis: evaluation requires significantly less semantic capacity than generation and can be grounded in intermediate representations, suggesting that evaluation does not necessarily need to rely on large-scale generative models but can instead leverage latent features from smaller ones. Our findings motivate a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge, a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output. We instantiate this paradigm through INSPECTOR, a probing-based framework that predicts aspect-level evaluation scores from small model representations. Experiments on reasoning benchmarks (GSM8K, MATH, GPQA) show that INSPECTOR substantially outperforms prompting-based small LMs and closely approximates full LLM judges, while offering a more efficient, reliable, and interpretable alternative for scalable evaluation."

[03.02.2026 17:43] Response: ```python
["SMALL_MODELS", "BENCHMARK", "TRAINING"]
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Small language models can effectively evaluate outputs by leveraging internal representations rather than generating responses, enabling a more efficient and interpretable evaluation approach through a probing-based framework.  					AI-generated summary 				 Large language models (LLMs) are widely used as reference-free evaluators via prompting, but this "LLM-as-a-Judge" paradigm is costly, opaque, and sensitive to prompt design. In this work, we investigate whether smaller models can serve as efficient evaluators by leveraging internal representations instead of surface generation. We uncover a consistent empirical pattern: small LMs, despite with weak generative ability, encode rich evaluative signals in their hidden states. This motivates us to propose the Semantic Capacity Asymmetry Hypothesis: evaluation requires significantly less semantic capacity than generation and can be grounded in intermediate representations, suggesting that evaluation does not necessarily need to rely on large-scale generative models but can instead leverage latent features from smaller ones. Our findings motivate a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge, a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output. We instantiate this paradigm through INSPECTOR, a probing-based framework that predicts aspect-level evaluation scores from small model representations. Experiments on reasoning benchmarks (GSM8K, MATH, GPQA) show that INSPECTOR substantially outperforms prompting-based small LMs and closely approximates full LLM judges, while offering a more efficient, reliable, and interpretable alternative for scalable evaluation."

[03.02.2026 17:43] Response: ```python
['INTERPRETABILITY', 'REASONING']
```

**Justification:**

1. **INTERPRETABILITY**: The paper explicitly focuses on analyzing and explaining model behavior through internal representations. Key phrases include "interpretable evaluation approach," "probes internal model structure," "leveraging internal representations," and "understanding of latent features from smaller ones." The entire framework is about making model decisions more transparent and explainable.

2. **REASONING**: The paper evaluates models on reasoning benchmarks (GSM8K, MATH, GPQA), which are standard reasoning tasks. The evaluation framework is specifically tested on reasoning capabilities.
[03.02.2026 17:43] Error. Failed to parse JSON from LLM. ["INTERPRETABILITY", "REASONING"]


**Justification:**

1. **INTERPRETABILITY**: The paper explicitly focuses on analyzing and explaining model behavior through internal representations. Key phrases include "interpretable evaluation approach," "probes internal model structure," "leveraging internal representations," and "understanding of latent features from smaller ones." The entire framework is about making model decisions more transparent and explainable.

2. **REASONING**: The paper evaluates models on reasoning benchmarks (GSM8K, MATH, GPQA), which are standard reasoning tasks. The evaluation framework is specifically tested on reasoning capabilities.
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how small language models can evaluate outputs more efficiently by using their internal representations instead of generating responses. The authors propose the Semantic Capacity Asymmetry Hypothesis, which suggests that evaluating text requires less semantic capacity than generating it. They introduce a new framework called INSPECTOR, which uses probing techniques to predict evaluation scores based on the hidden states of smaller models. The results show that INSPECTOR outperforms traditional prompting methods and provides a more interpretable and scalable evaluation approach.","title":"Unlocking Evaluation Efficiency with Small Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how small language models can evaluate outputs more efficiently by using their internal representations instead of generating responses. The authors propose the Semantic Capacity Asymmetry Hypothesis, which suggests that evaluating text requires less semantic capacity than generating it. They introduce a new framework called INSPECTOR, which uses probing techniques to predict evaluation scores based on the hidden states of smaller models. The results show that INSPECTOR outperforms traditional prompting methods and provides a more interpretable and scalable evaluation approach.', title='Unlocking Evaluation Efficiency with Small Models'))
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"INSPECTOR","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='INSPECTOR', title=''))
[03.02.2026 17:43] Querying the API.
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Agentic large language models require investigatory intelligence for autonomous data analysis, demonstrated through the Deep Data Research benchmark that evaluates their ability to extract insights from databases without explicit queries.  					AI-generated summary 				 The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.
[03.02.2026 17:43] Response: ```json
{
  "desc": "        ,        ,      .    Deep Data Research,             .  ,       ,     .           ,       .",
  "emoji": "",
  "title": " :       "
}
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic large language models require investigatory intelligence for autonomous data analysis, demonstrated through the Deep Data Research benchmark that evaluates their ability to extract insights from databases without explicit queries.  					AI-generated summary 				 The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models."

[03.02.2026 17:43] Response: ```python
["AGENTS", "BENCHMARK", "DATASET"]
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic large language models require investigatory intelligence for autonomous data analysis, demonstrated through the Deep Data Research benchmark that evaluates their ability to extract insights from databases without explicit queries.  					AI-generated summary 				 The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models."

[03.02.2026 17:43] Response: ```python
['REASONING', 'BENCHMARK', 'OPEN_SOURCE']
```

Wait, let me reconsider. Looking at the topics provided, 'BENCHMARK' is not in the list. Let me re-analyze:

The paper discusses:
- Agentic LLMs and autonomous decision-making (relates to REASONING - logical reasoning and planning)
- A new benchmark (DDR-Bench) for evaluation (relates to SURVEY as it's evaluating/reviewing capabilities, though not a comprehensive survey)
- Open-ended autonomous exploration and investigatory intelligence

The most relevant topics from the provided list are:

```python
['REASONING']
```
[03.02.2026 17:43] Error. Failed to parse JSON from LLM. ["REASONING", "BENCHMARK", "OPEN_SOURCE"]


Wait, let me reconsider. Looking at the topics provided, "BENCHMARK" is not in the list. Let me re-analyze:

The paper discusses:
- Agentic LLMs and autonomous decision-making (relates to REASONING - logical reasoning and planning)
- A new benchmark (DDR-Bench) for evaluation (relates to SURVEY as it"s evaluating/reviewing capabilities, though not a comprehensive survey)
- Open-ended autonomous exploration and investigatory intelligence

The most relevant topics from the provided list are:


["REASONING"]
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces the concept of investigatory intelligence in large language models (LLMs), which is the ability to autonomously analyze data and extract insights without specific queries. The authors present the Deep Data Research (DDR) benchmark, designed to evaluate LLMs\' performance in this area by allowing them to explore databases and derive key insights independently. The study reveals that while advanced models show some level of agency, they struggle with long-term exploration tasks. The findings suggest that developing effective investigatory intelligence requires more than just improving model size; it also involves enhancing the intrinsic strategies used by these models.","title":"Empowering LLMs with Investigatory Intelligence for Autonomous Data Insights"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces the concept of investigatory intelligence in large language models (LLMs), which is the ability to autonomously analyze data and extract insights without specific queries. The authors present the Deep Data Research (DDR) benchmark, designed to evaluate LLMs' performance in this area by allowing them to explore databases and derive key insights independently. The study reveals that while advanced models show some level of agency, they struggle with long-term exploration tasks. The findings suggest that developing effective investigatory intelligence requires more than just improving model size; it also involves enhancing the intrinsic strategies used by these models.", title='Empowering LLMs with Investigatory Intelligence for Autonomous Data Insights'))
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Agentic LLMsDeep Data Research, DDR","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Agentic LLMsDeep Data Research, DDR', title=''))
[03.02.2026 17:43] Querying the API.
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Layer pruning compresses large language models while maintaining classification performance but causes significant degradation in generative reasoning tasks, with limited recovery possible through supervised finetuning on self-generated responses.  					AI-generated summary 				 Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.
[03.02.2026 17:43] Response: ```json
{
  "desc": "         , ,       ,        .      ,         .          90%           20-30  .                    .",
  "emoji": "",
  "title": "   :     ,  "
}
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Layer pruning compresses large language models while maintaining classification performance but causes significant degradation in generative reasoning tasks, with limited recovery possible through supervised finetuning on self-generated responses.  					AI-generated summary 				 Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes."

[03.02.2026 17:43] Response: ```python
["INFERENCE", "TRAINING", "BENCHMARK"]
```
[03.02.2026 17:43] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Layer pruning compresses large language models while maintaining classification performance but causes significant degradation in generative reasoning tasks, with limited recovery possible through supervised finetuning on self-generated responses.  					AI-generated summary 				 Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes."

[03.02.2026 17:43] Response: ```python
['OPTIMIZATION', 'REASONING']
```
[03.02.2026 17:43] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the effects of layer pruning on large language models (LLMs), which is a technique used to reduce model size while trying to keep performance intact. The authors find that while classification tasks can maintain performance after pruning, generative reasoning tasks suffer significantly, especially those requiring multi-step reasoning. They propose a supervised finetuning method using self-generated responses to recover some performance, achieving notable improvements in classification tasks and moderate gains in generative tasks. However, the recovery for generative reasoning remains limited, highlighting the challenges of applying layer pruning effectively in these scenarios.","title":"Balancing Compression and Reasoning in Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the effects of layer pruning on large language models (LLMs), which is a technique used to reduce model size while trying to keep performance intact. The authors find that while classification tasks can maintain performance after pruning, generative reasoning tasks suffer significantly, especially those requiring multi-step reasoning. They propose a supervised finetuning method using self-generated responses to recover some performance, achieving notable improvements in classification tasks and moderate gains in generative tasks. However, the recovery for generative reasoning remains limited, highlighting the challenges of applying layer pruning effectively in these scenarios.', title='Balancing Compression and Reasoning in Language Models'))
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='', title=''))
[03.02.2026 17:44] Querying the API.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation.  					AI-generated summary 				 Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%uparrow and +23.04%uparrow on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.
[03.02.2026 17:44] Response: ```json
{
  "desc": "  UCT,          .           ,    .         ,       .       20-23%      .",
  "emoji": "",
  "title": ",       "
}
```
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation.  					AI-generated summary 				 Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%uparrow and +23.04%uparrow on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent."

[03.02.2026 17:44] Response: ```python
["AGENTS", "TRAINING", "INFERENCE"]
```

**Justification:**

- **AGENTS**: The paper explicitly focuses on "language model agents" and their autonomous capabilities, including "tool creation," "self-evolution," and agent-based reasoning systems.

- **TRAINING**: While the framework is described as "training-free," the paper is fundamentally about improving model capabilities through self-optimization and memory consolidation mechanisms during inference, which relates to enhancing how agents learn and improve.

- **INFERENCE**: The paper emphasizes that improvements occur "during inference" and "without additional training," making inference-time optimization a core contribution of the work.
[03.02.2026 17:44] Error. Failed to parse JSON from LLM. ["AGENTS", "TRAINING", "INFERENCE"]


**Justification:**

- **AGENTS**: The paper explicitly focuses on "language model agents" and their autonomous capabilities, including "tool creation," "self-evolution," and agent-based reasoning systems.

- **TRAINING**: While the framework is described as "training-free," the paper is fundamentally about improving model capabilities through self-optimization and memory consolidation mechanisms during inference, which relates to enhancing how agents learn and improve.

- **INFERENCE**: The paper emphasizes that improvements occur "during inference" and "without additional training," making inference-time optimization a core contribution of the work.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation.  					AI-generated summary 				 Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%uparrow and +23.04%uparrow on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent."

[03.02.2026 17:44] Response: ```python
["REASONING", "OPTIMIZATION"]
```

**Justification:**

- **REASONING**: The paper explicitly focuses on enhancing reasoning capabilities of language model agents. It discusses "Tool-Integrated Reasoning (TIR) models," improving "reasoning capabilities through self-evolution," and demonstrates performance gains on "mathematical and scientific reasoning tasks."

- **OPTIMIZATION**: The framework enables agents to "automatically create and optimize tools during inference" and includes "self-optimization mechanisms" and "self-updating during the inference process," which relates to optimizing agent behavior and tool quality without additional training.
[03.02.2026 17:44] Error. Failed to parse JSON from LLM. ["REASONING", "OPTIMIZATION"]


**Justification:**

- **REASONING**: The paper explicitly focuses on enhancing reasoning capabilities of language model agents. It discusses "Tool-Integrated Reasoning (TIR) models," improving "reasoning capabilities through self-evolution," and demonstrates performance gains on "mathematical and scientific reasoning tasks."

- **OPTIMIZATION**: The framework enables agents to "automatically create and optimize tools during inference" and includes "self-optimization mechanisms" and "self-updating during the inference process," which relates to optimizing agent behavior and tool quality without additional training.
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a training-free framework called UCT that allows language model agents to create and optimize their own tools during inference. By leveraging their reasoning experiences, these agents can evolve and improve their problem-solving capabilities without needing additional training. The framework includes a memory consolidation mechanism that helps maintain a library of tools, ensuring they are reusable for future tasks. Experimental results show that this approach significantly enhances the performance of existing Tool-Integrated Reasoning models in various reasoning tasks.","title":"Empowering Language Models: From Tool Users to Tool Creators"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a training-free framework called UCT that allows language model agents to create and optimize their own tools during inference. By leveraging their reasoning experiences, these agents can evolve and improve their problem-solving capabilities without needing additional training. The framework includes a memory consolidation mechanism that helps maintain a library of tools, ensuring they are reusable for future tasks. Experimental results show that this approach significantly enhances the performance of existing Tool-Integrated Reasoning models in various reasoning tasks.', title='Empowering Language Models: From Tool Users to Tool Creators'))
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"UCTUCT","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='UCTUCT', title=''))
[03.02.2026 17:44] Querying the API.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel optimizer called Mano is proposed that combines manifold optimization with momentum projection onto tangent spaces, achieving superior performance over AdamW and Muon while reducing memory and computational requirements.  					AI-generated summary 				 While large language models (LLMs) have emerged as a significant advancement in artificial intelligence, the hardware and computational costs for training LLMs are also significantly burdensome. Among the state-of-the-art optimizers, AdamW relies on diagonal curvature estimates and ignores structural properties, while Muon applies global spectral normalization at the expense of losing curvature information. In this study, we restriked manifold optimization methods for training LLMs, which may address both optimizers' limitations, while conventional manifold optimization methods have been largely overlooked due to the poor performance in large-scale model optimization. By innovatively projecting the momentum onto the tangent space of model parameters and constraining it on a rotational Oblique manifold, we propose a novel, powerful, and efficient optimizer **Mano** that is the first to bridge the performance gap between manifold optimization and modern optimizers. Extensive experiments on the LLaMA and Qwen3 models demonstrate that Mano consistently and significantly outperforms AdamW and Muon even with less memory consumption and computational complexity, respectively, suggesting an expanded Pareto frontier in terms of space and time efficiency.
[03.02.2026 17:44] Response: ```json
{
  "desc": "    Mano,              .    AdamW,     ,  Muon,    , Mano       .      LLaMA  Qwen ,  Mano           .           .",
  "emoji": "",
  "title": "          "
}
```
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel optimizer called Mano is proposed that combines manifold optimization with momentum projection onto tangent spaces, achieving superior performance over AdamW and Muon while reducing memory and computational requirements.  					AI-generated summary 				 While large language models (LLMs) have emerged as a significant advancement in artificial intelligence, the hardware and computational costs for training LLMs are also significantly burdensome. Among the state-of-the-art optimizers, AdamW relies on diagonal curvature estimates and ignores structural properties, while Muon applies global spectral normalization at the expense of losing curvature information. In this study, we restriked manifold optimization methods for training LLMs, which may address both optimizers' limitations, while conventional manifold optimization methods have been largely overlooked due to the poor performance in large-scale model optimization. By innovatively projecting the momentum onto the tangent space of model parameters and constraining it on a rotational Oblique manifold, we propose a novel, powerful, and efficient optimizer **Mano** that is the first to bridge the performance gap between manifold optimization and modern optimizers. Extensive experiments on the LLaMA and Qwen3 models demonstrate that Mano consistently and significantly outperforms AdamW and Muon even with less memory consumption and computational complexity, respectively, suggesting an expanded Pareto frontier in terms of space and time efficiency."

[03.02.2026 17:44] Response: ```python
["TRAINING", "ARCHITECTURE"]
```

**Justification:**

- **TRAINING**: The paper proposes a novel optimizer (Mano) for improving model training efficiency. It directly addresses training methodologies, comparing performance with other optimizers (AdamW, Muon) and demonstrating improvements in computational and memory efficiency during LLM training.

- **ARCHITECTURE**: The paper introduces a novel architectural component - a new optimizer that combines manifold optimization with momentum projection onto tangent spaces. This represents a novel neural architecture/component for model optimization.
[03.02.2026 17:44] Error. Failed to parse JSON from LLM. ["TRAINING", "ARCHITECTURE"]


**Justification:**

- **TRAINING**: The paper proposes a novel optimizer (Mano) for improving model training efficiency. It directly addresses training methodologies, comparing performance with other optimizers (AdamW, Muon) and demonstrating improvements in computational and memory efficiency during LLM training.

- **ARCHITECTURE**: The paper introduces a novel architectural component - a new optimizer that combines manifold optimization with momentum projection onto tangent spaces. This represents a novel neural architecture/component for model optimization.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel optimizer called Mano is proposed that combines manifold optimization with momentum projection onto tangent spaces, achieving superior performance over AdamW and Muon while reducing memory and computational requirements.  					AI-generated summary 				 While large language models (LLMs) have emerged as a significant advancement in artificial intelligence, the hardware and computational costs for training LLMs are also significantly burdensome. Among the state-of-the-art optimizers, AdamW relies on diagonal curvature estimates and ignores structural properties, while Muon applies global spectral normalization at the expense of losing curvature information. In this study, we restriked manifold optimization methods for training LLMs, which may address both optimizers' limitations, while conventional manifold optimization methods have been largely overlooked due to the poor performance in large-scale model optimization. By innovatively projecting the momentum onto the tangent space of model parameters and constraining it on a rotational Oblique manifold, we propose a novel, powerful, and efficient optimizer **Mano** that is the first to bridge the performance gap between manifold optimization and modern optimizers. Extensive experiments on the LLaMA and Qwen3 models demonstrate that Mano consistently and significantly outperforms AdamW and Muon even with less memory consumption and computational complexity, respectively, suggesting an expanded Pareto frontier in terms of space and time efficiency."

[03.02.2026 17:44] Response: ```python
["OPTIMIZATION"]
```
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces a new optimizer named Mano, which integrates manifold optimization techniques with momentum projection onto tangent spaces. This approach enhances the training of large language models (LLMs) by addressing the limitations of existing optimizers like AdamW and Muon, which either overlook structural properties or sacrifice curvature information. Mano is designed to be more efficient, requiring less memory and computational resources while still achieving superior performance. Experimental results on models such as LLaMA and Qwen3 show that Mano significantly outperforms its predecessors, expanding the efficiency frontier in model training.","title":"Mano: Bridging Efficiency and Performance in Optimizers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces a new optimizer named Mano, which integrates manifold optimization techniques with momentum projection onto tangent spaces. This approach enhances the training of large language models (LLMs) by addressing the limitations of existing optimizers like AdamW and Muon, which either overlook structural properties or sacrifice curvature information. Mano is designed to be more efficient, requiring less memory and computational resources while still achieving superior performance. Experimental results on models such as LLaMA and Qwen3 show that Mano significantly outperforms its predecessors, expanding the efficiency frontier in model training.', title='Mano: Bridging Efficiency and Performance in Optimizers'))
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ManoManoAdamWMuonManoManoLLaMAQwen3","title":"Mano"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ManoManoAdamWMuonManoManoLLaMAQwen3', title='Mano'))
[03.02.2026 17:44] Querying the API.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Effective dimension, an unsupervised geometric metric, strongly predicts neural network performance across different architectures and domains, showing bidirectional causality between representation geometry and accuracy.  					AI-generated summary 				 We investigate the relationship between representation geometry and neural network performance. Analyzing 52 pretrained ImageNet models across 13 architecture families, we show that effective dimension -- an unsupervised geometric metric -- strongly predicts accuracy. Output effective dimension achieves partial r=0.75 (p < 10^(-10)) after controlling for model capacity, while total compression achieves partial r=-0.72. These findings replicate across ImageNet and CIFAR-10, and generalize to NLP: effective dimension predicts performance for 8 encoder models on SST-2/MNLI and 15 decoder-only LLMs on AG News (r=0.69, p=0.004), while model size does not (r=0.07). We establish bidirectional causality: degrading geometry via noise causes accuracy loss (r=-0.94, p < 10^(-9)), while improving geometry via PCA maintains accuracy across architectures (-0.03pp at 95% variance). This relationship is noise-type agnostic -- Gaussian, Uniform, Dropout, and Salt-and-pepper noise all show |r| > 0.90. These results establish that effective dimension provides domain-agnostic predictive and causal information about neural network performance, computed entirely without labels.
[03.02.2026 17:44] Response: ```json
{
  "desc": "          .  ,        ,           .   52    ImageNet,       NLP,       (r=0.69).   :         ,     PCA      .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Effective dimension, an unsupervised geometric metric, strongly predicts neural network performance across different architectures and domains, showing bidirectional causality between representation geometry and accuracy.  					AI-generated summary 				 We investigate the relationship between representation geometry and neural network performance. Analyzing 52 pretrained ImageNet models across 13 architecture families, we show that effective dimension -- an unsupervised geometric metric -- strongly predicts accuracy. Output effective dimension achieves partial r=0.75 (p < 10^(-10)) after controlling for model capacity, while total compression achieves partial r=-0.72. These findings replicate across ImageNet and CIFAR-10, and generalize to NLP: effective dimension predicts performance for 8 encoder models on SST-2/MNLI and 15 decoder-only LLMs on AG News (r=0.69, p=0.004), while model size does not (r=0.07). We establish bidirectional causality: degrading geometry via noise causes accuracy loss (r=-0.94, p < 10^(-9)), while improving geometry via PCA maintains accuracy across architectures (-0.03pp at 95% variance). This relationship is noise-type agnostic -- Gaussian, Uniform, Dropout, and Salt-and-pepper noise all show |r| > 0.90. These results establish that effective dimension provides domain-agnostic predictive and causal information about neural network performance, computed entirely without labels."

[03.02.2026 17:44] Response: ```python
["BENCHMARK", "CV", "ARCHITECTURE", "TRAINING"]
```
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Effective dimension, an unsupervised geometric metric, strongly predicts neural network performance across different architectures and domains, showing bidirectional causality between representation geometry and accuracy.  					AI-generated summary 				 We investigate the relationship between representation geometry and neural network performance. Analyzing 52 pretrained ImageNet models across 13 architecture families, we show that effective dimension -- an unsupervised geometric metric -- strongly predicts accuracy. Output effective dimension achieves partial r=0.75 (p < 10^(-10)) after controlling for model capacity, while total compression achieves partial r=-0.72. These findings replicate across ImageNet and CIFAR-10, and generalize to NLP: effective dimension predicts performance for 8 encoder models on SST-2/MNLI and 15 decoder-only LLMs on AG News (r=0.69, p=0.004), while model size does not (r=0.07). We establish bidirectional causality: degrading geometry via noise causes accuracy loss (r=-0.94, p < 10^(-9)), while improving geometry via PCA maintains accuracy across architectures (-0.03pp at 95% variance). This relationship is noise-type agnostic -- Gaussian, Uniform, Dropout, and Salt-and-pepper noise all show |r| > 0.90. These results establish that effective dimension provides domain-agnostic predictive and causal information about neural network performance, computed entirely without labels."

[03.02.2026 17:44] Response: ```python
['INTERPRETABILITY']
```
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how the geometry of representations in neural networks relates to their performance. It introduces \'effective dimension\', a geometric metric that can predict the accuracy of various neural network architectures without needing labeled data. The study shows a strong correlation between effective dimension and accuracy across different datasets, including ImageNet and CIFAR-10, as well as in natural language processing tasks. Additionally, it establishes a two-way relationship where changes in representation geometry directly affect model accuracy, regardless of the type of noise introduced.","title":"Geometry Matters: Effective Dimension Predicts Neural Network Success"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper explores how the geometry of representations in neural networks relates to their performance. It introduces 'effective dimension', a geometric metric that can predict the accuracy of various neural network architectures without needing labeled data. The study shows a strong correlation between effective dimension and accuracy across different datasets, including ImageNet and CIFAR-10, as well as in natural language processing tasks. Additionally, it establishes a two-way relationship where changes in representation geometry directly affect model accuracy, regardless of the type of noise introduced.", title='Geometry Matters: Effective Dimension Predicts Neural Network Success'))
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"52ImageNetPCA","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='52ImageNetPCA', title=''))
[03.02.2026 17:44] Querying the API.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Implicit neural representations operate continuously over UV coordinate space, demonstrating good image quality while balancing memory usage and rendering time, with applications in real-time rendering and downstream tasks.  					AI-generated summary 				 Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation.
[03.02.2026 17:44] Response: ```json
{
  "desc": "       (INR)  ,      UV-   .                      .      ,    .     -    ,    mipmaps     INR.",
  "emoji": "",
  "title": "     "
}
```
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Implicit neural representations operate continuously over UV coordinate space, demonstrating good image quality while balancing memory usage and rendering time, with applications in real-time rendering and downstream tasks.  					AI-generated summary 				 Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation."

[03.02.2026 17:44] Response: ```python
['CV', 'ARCHITECTURE', 'INFERENCE']
```

**Justification:**
- **CV**: The paper focuses on implicit neural representations for texture processing and image quality, which are computer vision methods for visual processing.
- **ARCHITECTURE**: The paper proposes novel neural network designs for texture INRs operating in continuous UV coordinate space, representing a novel neural architecture component.
- **INFERENCE**: The paper explicitly analyzes and optimizes rendering inference time and memory usage, which are key deployment optimization concerns.
[03.02.2026 17:44] Error. Failed to parse JSON from LLM. ["CV", "ARCHITECTURE", "INFERENCE"]


**Justification:**
- **CV**: The paper focuses on implicit neural representations for texture processing and image quality, which are computer vision methods for visual processing.
- **ARCHITECTURE**: The paper proposes novel neural network designs for texture INRs operating in continuous UV coordinate space, representing a novel neural architecture component.
- **INFERENCE**: The paper explicitly analyzes and optimizes rendering inference time and memory usage, which are key deployment optimization concerns.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Implicit neural representations operate continuously over UV coordinate space, demonstrating good image quality while balancing memory usage and rendering time, with applications in real-time rendering and downstream tasks.  					AI-generated summary 				 Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation."

[03.02.2026 17:44] Response: ```python
[]
```

The paper discusses implicit neural representations (INRs) for texture representation and rendering applications. While it involves neural networks, it does not directly address any of the specified topics. The paper focuses on technical aspects of neural representation design, image quality, memory efficiency, and rendering performance, but does not engage with AGI, games, interpretability, reasoning, transfer learning, graphs, ethics, security, optimization methods, surveys, diffusion models, alignment, story generation, hallucinations, long context, synthetic data, translation, data leakage, open-source contributions, scientific applications, or low-resource languages.
[03.02.2026 17:44] Error. Failed to parse JSON from LLM. []


The paper discusses implicit neural representations (INRs) for texture representation and rendering applications. While it involves neural networks, it does not directly address any of the specified topics. The paper focuses on technical aspects of neural representation design, image quality, memory efficiency, and rendering performance, but does not engage with AGI, games, interpretability, reasoning, transfer learning, graphs, ethics, security, optimization methods, surveys, diffusion models, alignment, story generation, hallucinations, long context, synthetic data, translation, data leakage, open-source contributions, scientific applications, or low-resource languages.
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses implicit neural representations (INRs) that work continuously over UV coordinate space, which helps in achieving high-quality images while optimizing memory and rendering time. The authors propose a new texture INR design that enhances performance in real-time rendering applications. Through extensive experiments, they show that these INRs maintain excellent image quality while being efficient in memory usage and inference speed. The study also explores various applications of INRs, including mipmap fitting and INR-space generation, highlighting their versatility in downstream tasks.","title":"Efficient Image Quality with Implicit Neural Representations"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses implicit neural representations (INRs) that work continuously over UV coordinate space, which helps in achieving high-quality images while optimizing memory and rendering time. The authors propose a new texture INR design that enhances performance in real-time rendering applications. Through extensive experiments, they show that these INRs maintain excellent image quality while being efficient in memory usage and inference speed. The study also explores various applications of INRs, including mipmap fitting and INR-space generation, highlighting their versatility in downstream tasks.', title='Efficient Image Quality with Implicit Neural Representations'))
[03.02.2026 17:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"INRUVUV","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='INRUVUV', title=''))
[03.02.2026 17:44] Querying the API.
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Controlled cross-lingual evaluation reveals instability in LLM assessment methods when targeting morphologically rich languages, indicating unreliable zero-shot judge transfer for discourse-level tasks.  					AI-generated summary 				 Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.   This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges.
[03.02.2026 17:44] Response: ```json
{
  "desc": "          - , ,             .        -  (,   ),            LLM-as-a-judge.  ,    ( ,  )    ,    (,  )      .  ,                 -  .",
  "emoji": "",
  "title": "  :  -  LLM    "
}
```
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Controlled cross-lingual evaluation reveals instability in LLM assessment methods when targeting morphologically rich languages, indicating unreliable zero-shot judge transfer for discourse-level tasks.  					AI-generated summary 				 Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.   This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges."

[03.02.2026 17:44] Response: ```python
['MULTILINGUAL', 'BENCHMARK', 'DATASET', 'DATA']
```
[03.02.2026 17:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Controlled cross-lingual evaluation reveals instability in LLM assessment methods when targeting morphologically rich languages, indicating unreliable zero-shot judge transfer for discourse-level tasks.  					AI-generated summary 				 Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.   This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges."

[03.02.2026 17:45] Response: ```python
['LOW_RESOURCE', 'TRANSLATION', 'OPEN_SOURCE']
```
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the reliability of evaluating large language models (LLMs) when applied to morphologically rich languages. It highlights that while some surface-level metrics remain stable across languages, pragmatic judgments like coherence and instruction-following show significant inconsistencies. The study uses controlled generation conditions to reveal that these instabilities are due to the evaluation methods rather than actual differences in model performance. The authors advocate for language-specific calibration to improve the reliability of zero-shot assessments in discourse-level tasks.","title":"Evaluating Language Models: Stability Matters!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the reliability of evaluating large language models (LLMs) when applied to morphologically rich languages. It highlights that while some surface-level metrics remain stable across languages, pragmatic judgments like coherence and instruction-following show significant inconsistencies. The study uses controlled generation conditions to reveal that these instabilities are due to the evaluation methods rather than actual differences in model performance. The authors advocate for language-specific calibration to improve the reliability of zero-shot assessments in discourse-level tasks.', title='Evaluating Language Models: Stability Matters!'))
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LLMLLM","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LLMLLM', title=''))
[03.02.2026 17:45] Querying the API.
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Generalizable Predictive Prompt Selection (GPS) uses Bayesian inference with a lightweight generative model to efficiently select informative prompts for reinforcement learning-enhanced language models, improving training efficiency and performance.  					AI-generated summary 				 Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.
[03.02.2026 17:45] Response: ```json
{
  "desc": "    Generalizable Predictive Prompt Selection (GPS),               .          ,     .    diversity,   ,     ,    .           ,       .",
  "emoji": "",
  "title": "      "
}
```
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Generalizable Predictive Prompt Selection (GPS) uses Bayesian inference with a lightweight generative model to efficiently select informative prompts for reinforcement learning-enhanced language models, improving training efficiency and performance.  					AI-generated summary 				 Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods."

[03.02.2026 17:45] Response: ```python
["RL", "TRAINING", "SMALL_MODELS"]
```
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Generalizable Predictive Prompt Selection (GPS) uses Bayesian inference with a lightweight generative model to efficiently select informative prompts for reinforcement learning-enhanced language models, improving training efficiency and performance.  					AI-generated summary 				 Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods."

[03.02.2026 17:45] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents Generalizable Predictive Prompt Selection (GPS), a method that uses Bayesian inference to choose the most informative prompts for training reinforcement learning-enhanced language models. By employing a lightweight generative model, GPS reduces the computational costs associated with traditional prompt selection methods. The approach focuses on prioritizing prompts based on their difficulty and incorporates diversity to ensure a well-rounded selection. Experimental results show that GPS significantly enhances training efficiency and overall model performance compared to existing techniques.","title":"Efficient Prompt Selection for Enhanced Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents Generalizable Predictive Prompt Selection (GPS), a method that uses Bayesian inference to choose the most informative prompts for training reinforcement learning-enhanced language models. By employing a lightweight generative model, GPS reduces the computational costs associated with traditional prompt selection methods. The approach focuses on prioritizing prompts based on their difficulty and incorporates diversity to ensure a well-rounded selection. Experimental results show that GPS significantly enhances training efficiency and overall model performance compared to existing techniques.', title='Efficient Prompt Selection for Enhanced Learning'))
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"GPSGPS","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='GPSGPS', title=''))
[03.02.2026 17:45] Querying the API.
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

VAE-based inpainting creates spectral shifts that fool detection systems, which can be mitigated through Inpainting Exchange to improve content-aware detection performance.  					AI-generated summary 				 Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\% to 55\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X.
[03.02.2026 17:45] Response: ```json
{
  "desc": "     ,    VAE-based .  ,       ,      ,    .  ,  VAE-      ,   ,    Inpainting Exchange       .   ,          ,       -    .",
  "emoji": "",
  "title": "  VAE-:     - "
}
```
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VAE-based inpainting creates spectral shifts that fool detection systems, which can be mitigated through Inpainting Exchange to improve content-aware detection performance.  					AI-generated summary 				 Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\% to 55\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X."

[03.02.2026 17:45] Response: ```python
["DATASET", "CV", "BENCHMARK"]
```

**Justification:**
- **DATASET**: The paper introduces a new 90K test dataset including real, inpainted, and exchanged images for evaluation purposes.
- **CV**: The paper focuses on image inpainting, detection of inpainted images, and visual content manipulation - all core computer vision tasks.
- **BENCHMARK**: The paper evaluates and analyzes the performance of state-of-the-art detectors on their proposed dataset, contributing to model evaluation frameworks for inpainting detection.
[03.02.2026 17:45] Error. Failed to parse JSON from LLM. ["DATASET", "CV", "BENCHMARK"]


**Justification:**
- **DATASET**: The paper introduces a new 90K test dataset including real, inpainted, and exchanged images for evaluation purposes.
- **CV**: The paper focuses on image inpainting, detection of inpainted images, and visual content manipulation - all core computer vision tasks.
- **BENCHMARK**: The paper evaluates and analyzes the performance of state-of-the-art detectors on their proposed dataset, contributing to model evaluation frameworks for inpainting detection.
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VAE-based inpainting creates spectral shifts that fool detection systems, which can be mitigated through Inpainting Exchange to improve content-aware detection performance.  					AI-generated summary 				 Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\% to 55\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X."

[03.02.2026 17:45] Response: ```python
['SECURITY', 'OPEN_SOURCE']
```

**Justification:**

- **SECURITY**: The paper directly addresses adversarial robustness and model security by analyzing how VAE-based inpainting can fool detection systems through spectral shifts, and proposes methods to improve detector robustness against these manipulations.

- **OPEN_SOURCE**: The paper explicitly states "Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X," indicating a contribution of open-source resources (dataset and code).
[03.02.2026 17:45] Error. Failed to parse JSON from LLM. ["SECURITY", "OPEN_SOURCE"]


**Justification:**

- **SECURITY**: The paper directly addresses adversarial robustness and model security by analyzing how VAE-based inpainting can fool detection systems through spectral shifts, and proposes methods to improve detector robustness against these manipulations.

- **OPEN_SOURCE**: The paper explicitly states "Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X," indicating a contribution of open-source resources (dataset and code).
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the challenges posed by Variational Autoencoder (VAE)-based inpainting techniques, which can create subtle spectral shifts in images that mislead detection systems. The authors introduce a method called Inpainting Exchange (INP-X) that restores original pixels outside the edited areas while keeping the newly synthesized content intact. They demonstrate that current detection systems often fail because they focus on global artifacts rather than local details, leading to significant drops in detection accuracy when using INP-X. The study emphasizes the importance of developing content-aware detection methods to improve the reliability of detecting inpainted images.","title":"Enhancing Detection with Inpainting Exchange"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the challenges posed by Variational Autoencoder (VAE)-based inpainting techniques, which can create subtle spectral shifts in images that mislead detection systems. The authors introduce a method called Inpainting Exchange (INP-X) that restores original pixels outside the edited areas while keeping the newly synthesized content intact. They demonstrate that current detection systems often fail because they focus on global artifacts rather than local details, leading to significant drops in detection accuracy when using INP-X. The study emphasizes the importance of developing content-aware detection methods to improve the reliability of detecting inpainted images.', title='Enhancing Detection with Inpainting Exchange'))
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"VAEInpainting ExchangeINP-X90K","title":"Inpainting Exchange"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='VAEInpainting ExchangeINP-X90K', title='Inpainting Exchange'))
[03.02.2026 17:45] Querying the API.
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Parallel Echo State Network (ParalESN) addresses reservoir computing limitations by enabling parallel temporal processing through diagonal linear recurrence, maintaining theoretical guarantees while achieving significant computational efficiency gains.  					AI-generated summary 				 Reservoir Computing (RC) has established itself as an efficient paradigm for temporal processing. However, its scalability remains severely constrained by (i) the necessity of processing temporal data sequentially and (ii) the prohibitive memory footprint of high-dimensional reservoirs. In this work, we revisit RC through the lens of structured operators and state space modeling to address these limitations, introducing Parallel Echo State Network (ParalESN). ParalESN enables the construction of high-dimensional and efficient reservoirs based on diagonal linear recurrence in the complex space, enabling parallel processing of temporal data. We provide a theoretical analysis demonstrating that ParalESN preserves the Echo State Property and the universality guarantees of traditional Echo State Networks while admitting an equivalent representation of arbitrary linear reservoirs in the complex diagonal form. Empirically, ParalESN matches the predictive accuracy of traditional RC on time series benchmarks, while delivering substantial computational savings. On 1-D pixel-level classification tasks, ParalESN achieves competitive accuracy with fully trainable neural networks while reducing computational costs and energy consumption by orders of magnitude. Overall, ParalESN offers a promising, scalable, and principled pathway for integrating RC within the deep learning landscape.
[03.02.2026 17:45] Response: ```json
{
  "desc": "   Parallel Echo State Network (ParalESN)     reservoir computing,      .         ,     ,     .   ,  ParalESN   Echo State Property    Echo State Networks.             ,        .",
  "emoji": "",
  "title": "  :     "
}
```
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Parallel Echo State Network (ParalESN) addresses reservoir computing limitations by enabling parallel temporal processing through diagonal linear recurrence, maintaining theoretical guarantees while achieving significant computational efficiency gains.  					AI-generated summary 				 Reservoir Computing (RC) has established itself as an efficient paradigm for temporal processing. However, its scalability remains severely constrained by (i) the necessity of processing temporal data sequentially and (ii) the prohibitive memory footprint of high-dimensional reservoirs. In this work, we revisit RC through the lens of structured operators and state space modeling to address these limitations, introducing Parallel Echo State Network (ParalESN). ParalESN enables the construction of high-dimensional and efficient reservoirs based on diagonal linear recurrence in the complex space, enabling parallel processing of temporal data. We provide a theoretical analysis demonstrating that ParalESN preserves the Echo State Property and the universality guarantees of traditional Echo State Networks while admitting an equivalent representation of arbitrary linear reservoirs in the complex diagonal form. Empirically, ParalESN matches the predictive accuracy of traditional RC on time series benchmarks, while delivering substantial computational savings. On 1-D pixel-level classification tasks, ParalESN achieves competitive accuracy with fully trainable neural networks while reducing computational costs and energy consumption by orders of magnitude. Overall, ParalESN offers a promising, scalable, and principled pathway for integrating RC within the deep learning landscape."

[03.02.2026 17:45] Response: ```python
["ARCHITECTURE", "TRAINING", "BENCHMARK"]
```
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Parallel Echo State Network (ParalESN) addresses reservoir computing limitations by enabling parallel temporal processing through diagonal linear recurrence, maintaining theoretical guarantees while achieving significant computational efficiency gains.  					AI-generated summary 				 Reservoir Computing (RC) has established itself as an efficient paradigm for temporal processing. However, its scalability remains severely constrained by (i) the necessity of processing temporal data sequentially and (ii) the prohibitive memory footprint of high-dimensional reservoirs. In this work, we revisit RC through the lens of structured operators and state space modeling to address these limitations, introducing Parallel Echo State Network (ParalESN). ParalESN enables the construction of high-dimensional and efficient reservoirs based on diagonal linear recurrence in the complex space, enabling parallel processing of temporal data. We provide a theoretical analysis demonstrating that ParalESN preserves the Echo State Property and the universality guarantees of traditional Echo State Networks while admitting an equivalent representation of arbitrary linear reservoirs in the complex diagonal form. Empirically, ParalESN matches the predictive accuracy of traditional RC on time series benchmarks, while delivering substantial computational savings. On 1-D pixel-level classification tasks, ParalESN achieves competitive accuracy with fully trainable neural networks while reducing computational costs and energy consumption by orders of magnitude. Overall, ParalESN offers a promising, scalable, and principled pathway for integrating RC within the deep learning landscape."

[03.02.2026 17:45] Response: ```python
["OPTIMIZATION"]
```

The paper focuses on improving the computational efficiency and scalability of reservoir computing through parallel processing and structured operators, which directly relates to optimization of training methods and computational performance.
[03.02.2026 17:45] Error. Failed to parse JSON from LLM. ["OPTIMIZATION"]


The paper focuses on improving the computational efficiency and scalability of reservoir computing through parallel processing and structured operators, which directly relates to optimization of training methods and computational performance.
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Parallel Echo State Network (ParalESN) improves reservoir computing by allowing parallel processing of temporal data, which overcomes the limitations of traditional methods that require sequential data handling. It utilizes diagonal linear recurrence in complex space to create efficient, high-dimensional reservoirs while maintaining the essential properties of Echo State Networks. Theoretical analysis confirms that ParalESN retains the Echo State Property and universality guarantees, making it a robust alternative to conventional approaches. Empirical results show that ParalESN achieves similar predictive accuracy to traditional reservoir computing while significantly reducing computational costs and energy usage, making it a scalable solution for deep learning applications.","title":"Parallel Processing for Efficient Temporal Data Handling"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Parallel Echo State Network (ParalESN) improves reservoir computing by allowing parallel processing of temporal data, which overcomes the limitations of traditional methods that require sequential data handling. It utilizes diagonal linear recurrence in complex space to create efficient, high-dimensional reservoirs while maintaining the essential properties of Echo State Networks. Theoretical analysis confirms that ParalESN retains the Echo State Property and universality guarantees, making it a robust alternative to conventional approaches. Empirical results show that ParalESN achieves similar predictive accuracy to traditional reservoir computing while significantly reducing computational costs and energy usage, making it a scalable solution for deep learning applications.', title='Parallel Processing for Efficient Temporal Data Handling'))
[03.02.2026 17:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ParalESNParalESNParalESN","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ParalESNParalESNParalESN', title=''))
[03.02.2026 17:45] Querying the API.
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

On-policy Verbal Distillation (OVD) enables efficient knowledge transfer from teacher to student models by replacing token-level probability matching with trajectory matching using discrete verbal scores, reducing memory consumption and enabling free exploration without token alignment constraints.  					AI-generated summary 				 Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io
[03.02.2026 17:45] Response: ```json
{
  "desc": "   On-policy Verbal Distillation (OVD),           ,          .   OVD             - ,       .         0  9,   ,          .                    +12.9%  +25.7% .",
  "emoji": "",
  "title": " :     - "
}
```
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"On-policy Verbal Distillation (OVD) enables efficient knowledge transfer from teacher to student models by replacing token-level probability matching with trajectory matching using discrete verbal scores, reducing memory consumption and enabling free exploration without token alignment constraints.  					AI-generated summary 				 Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io"

[03.02.2026 17:45] Response: ```python
["TRAINING", "RL", "BENCHMARK"]
```
[03.02.2026 17:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"On-policy Verbal Distillation (OVD) enables efficient knowledge transfer from teacher to student models by replacing token-level probability matching with trajectory matching using discrete verbal scores, reducing memory consumption and enabling free exploration without token alignment constraints.  					AI-generated summary 				 Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io"

[03.02.2026 17:45] Response: ```python
["TRANSFER_LEARNING", "REASONING", "OPTIMIZATION"]
```
[03.02.2026 17:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"On-policy Verbal Distillation (OVD) is a new method for transferring knowledge from large teacher models to smaller student models in machine learning. Instead of matching probabilities at the token level, OVD uses trajectory matching with discrete verbal scores, which helps reduce memory usage. This approach allows student models to explore freely without being constrained by token alignment, making it more effective in interactive environments. Experiments show that OVD significantly improves performance on tasks like web question answering and mathematical reasoning, achieving notable gains in accuracy and training efficiency.","title":"Efficient Knowledge Transfer with On-policy Verbal Distillation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='On-policy Verbal Distillation (OVD) is a new method for transferring knowledge from large teacher models to smaller student models in machine learning. Instead of matching probabilities at the token level, OVD uses trajectory matching with discrete verbal scores, which helps reduce memory usage. This approach allows student models to explore freely without being constrained by token alignment, making it more effective in interactive environments. Experiments show that OVD significantly improves performance on tasks like web question answering and mathematical reasoning, achieving notable gains in accuracy and training efficiency.', title='Efficient Knowledge Transfer with On-policy Verbal Distillation'))
[03.02.2026 17:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"OVDOVDOVD","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='OVDOVDOVD', title=''))
[03.02.2026 17:46] Querying the API.
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

An reinforcement learning-based sampling framework adaptively reweights training datasets to improve embedding model performance while reducing GPU costs.  					AI-generated summary 				 General-purpose open-domain dense retrieval systems are usually trained with a large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches sample them uniformly, proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models. We propose Inf-DDS, a novel reinforcement learning driven sampling framework that adaptively reweighs training datasets guided by influence-based reward signals and is much more lightweight with respect to GPU consumption. Our technique iteratively refines the sampling policy, prioritizing datasets that maximize model performance on a target development set. We evaluate the efficacy of our sampling strategy on a wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being 1.5x to 4x cheaper in GPU compute. Our sampling strategy achieves a 5.03 absolute NDCG@10 improvement while training a multilingual bge-m3 model and an absolute NDCG@10 improvement of 0.94 while training all-MiniLM-L6-v2, even when starting from expert-assigned weights on a large pool of training datasets.
[03.02.2026 17:46] Response: ```json
{
  "desc": "     Inf-DDS,        weighting      .        (influence-based rewards)     ,  ,       .            1.5-4     GPU     gradient-based .    NDCG@10  5.03      BGE-m3      .",
  "emoji": "",
  "title": " weighting:   ,   "
}
```
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"An reinforcement learning-based sampling framework adaptively reweights training datasets to improve embedding model performance while reducing GPU costs.  					AI-generated summary 				 General-purpose open-domain dense retrieval systems are usually trained with a large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches sample them uniformly, proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models. We propose Inf-DDS, a novel reinforcement learning driven sampling framework that adaptively reweighs training datasets guided by influence-based reward signals and is much more lightweight with respect to GPU consumption. Our technique iteratively refines the sampling policy, prioritizing datasets that maximize model performance on a target development set. We evaluate the efficacy of our sampling strategy on a wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being 1.5x to 4x cheaper in GPU compute. Our sampling strategy achieves a 5.03 absolute NDCG@10 improvement while training a multilingual bge-m3 model and an absolute NDCG@10 improvement of 0.94 while training all-MiniLM-L6-v2, even when starting from expert-assigned weights on a large pool of training datasets."

[03.02.2026 17:46] Response: ```python
["RL", "DATA", "TRAINING", "MULTILINGUAL", "SMALL_MODELS"]
```
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"An reinforcement learning-based sampling framework adaptively reweights training datasets to improve embedding model performance while reducing GPU costs.  					AI-generated summary 				 General-purpose open-domain dense retrieval systems are usually trained with a large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches sample them uniformly, proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models. We propose Inf-DDS, a novel reinforcement learning driven sampling framework that adaptively reweighs training datasets guided by influence-based reward signals and is much more lightweight with respect to GPU consumption. Our technique iteratively refines the sampling policy, prioritizing datasets that maximize model performance on a target development set. We evaluate the efficacy of our sampling strategy on a wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being 1.5x to 4x cheaper in GPU compute. Our sampling strategy achieves a 5.03 absolute NDCG@10 improvement while training a multilingual bge-m3 model and an absolute NDCG@10 improvement of 0.94 while training all-MiniLM-L6-v2, even when starting from expert-assigned weights on a large pool of training datasets."

[03.02.2026 17:46] Response: ```python
["OPTIMIZATION"]
```
[03.02.2026 17:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Inf-DDS, a reinforcement learning-based framework that optimizes the sampling of training datasets for embedding models. By using influence-based reward signals, it adaptively reweights datasets to enhance model performance while significantly reducing GPU costs. The framework iteratively refines its sampling policy, focusing on datasets that yield the best results on a specific development set. The results show substantial improvements in retrieval performance across various tasks, achieving notable gains in efficiency and effectiveness compared to traditional sampling methods.","title":"Optimize Sampling, Maximize Performance!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Inf-DDS, a reinforcement learning-based framework that optimizes the sampling of training datasets for embedding models. By using influence-based reward signals, it adaptively reweights datasets to enhance model performance while significantly reducing GPU costs. The framework iteratively refines its sampling policy, focusing on datasets that yield the best results on a specific development set. The results show substantial improvements in retrieval performance across various tasks, achieving notable gains in efficiency and effectiveness compared to traditional sampling methods.', title='Optimize Sampling, Maximize Performance!'))
[03.02.2026 17:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Inf-DDSGPUInf-DDSInf-DDSGPU1.54","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Inf-DDSGPUInf-DDSInf-DDSGPU1.54', title=''))
[03.02.2026 17:46] Querying the API.
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ReSID presents a novel recommendation-native framework that improves sequential recommendation by learning predictive item representations and optimizing quantization for information preservation and sequential predictability.  					AI-generated summary 				 Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.
[03.02.2026 17:46] Response: ```json
{
  "desc": "ReSID      ,    ,   .       ,   ,           .   ReSID        ,      .   ,  ReSID     10%      .",
  "emoji": "",
  "title": "      "
}
```
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ReSID presents a novel recommendation-native framework that improves sequential recommendation by learning predictive item representations and optimizing quantization for information preservation and sequential predictability.  					AI-generated summary 				 Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID."

[03.02.2026 17:46] Response: ```python
["TRAINING", "ARCHITECTURE"]
```
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ReSID presents a novel recommendation-native framework that improves sequential recommendation by learning predictive item representations and optimizing quantization for information preservation and sequential predictability.  					AI-generated summary 				 Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID."

[03.02.2026 17:46] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **OPTIMIZATION**: The paper focuses on optimizing quantization schemes and representation learning for sequential recommendation systems. It proposes methods (FAMAE and GAOQ) to improve information preservation and reduce uncertainty, which are core optimization objectives.

- **OPEN_SOURCE**: The paper explicitly states "Code is available at https://github.com/FuCongResearchSquad/ReSID", indicating the authors are releasing their code publicly.
[03.02.2026 17:46] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **OPTIMIZATION**: The paper focuses on optimizing quantization schemes and representation learning for sequential recommendation systems. It proposes methods (FAMAE and GAOQ) to improve information preservation and reduce uncertainty, which are core optimization objectives.

- **OPEN_SOURCE**: The paper explicitly states "Code is available at https://github.com/FuCongResearchSquad/ReSID", indicating the authors are releasing their code publicly.
[03.02.2026 17:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ReSID is a new framework designed to enhance sequential recommendation systems by focusing on how items are represented and how information is quantized. It introduces two main components: Field-Aware Masked Auto-Encoding (FAMAE) for creating effective item representations, and Globally Aligned Orthogonal Quantization (GAOQ) for optimizing the way these representations are stored. This approach aims to improve the accuracy of predictions while minimizing the loss of important information during the quantization process. The results show that ReSID significantly outperforms existing methods, making it a promising advancement in the field of recommendation systems.","title":"ReSID: Revolutionizing Sequential Recommendations with Smart Representations"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ReSID is a new framework designed to enhance sequential recommendation systems by focusing on how items are represented and how information is quantized. It introduces two main components: Field-Aware Masked Auto-Encoding (FAMAE) for creating effective item representations, and Globally Aligned Orthogonal Quantization (GAOQ) for optimizing the way these representations are stored. This approach aims to improve the accuracy of predictions while minimizing the loss of important information during the quantization process. The results show that ReSID significantly outperforms existing methods, making it a promising advancement in the field of recommendation systems.', title='ReSID: Revolutionizing Sequential Recommendations with Smart Representations'))
[03.02.2026 17:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ReSIDReSIDFAMAEGAOQSIDReSID10%122","title":"ReSID"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ReSIDReSIDFAMAEGAOQSIDReSID10%122', title='ReSID'))
[03.02.2026 17:46] Querying the API.
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Scaling hidden states of delimiter tokens in vision-language models reduces cross-image information leakage and improves multi-image reasoning performance.  					AI-generated summary 				 Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.
[03.02.2026 17:46] Response: ```json
{
  "desc": "         -       .       -,     ,           .                   ,         .  ,              .",
  "emoji": "",
  "title": "       "
}
```
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scaling hidden states of delimiter tokens in vision-language models reduces cross-image information leakage and improves multi-image reasoning performance.  					AI-generated summary 				 Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost."

[03.02.2026 17:46] Response: ```python
["MULTIMODAL", "ARCHITECTURE", "BENCHMARK"]
```
[03.02.2026 17:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scaling hidden states of delimiter tokens in vision-language models reduces cross-image information leakage and improves multi-image reasoning performance.  					AI-generated summary 				 Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost."

[03.02.2026 17:46] Response: ```python
['LEAKAGE', 'REASONING']
```
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the issue of cross-image information leakage in Large Vision-Language Models (LVLMs) when processing multiple images. The authors propose a novel approach that scales the hidden states of delimiter tokens, which are used to separate images in the input. By enhancing these tokens, the model can better maintain image-specific information and reduce confusion between different images. The results show significant improvements in multi-image reasoning tasks and also benefit text-only tasks without incurring extra training or inference costs.","title":"Enhancing Image Distinction in Vision-Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the issue of cross-image information leakage in Large Vision-Language Models (LVLMs) when processing multiple images. The authors propose a novel approach that scales the hidden states of delimiter tokens, which are used to separate images in the input. By enhancing these tokens, the model can better maintain image-specific information and reduce confusion between different images. The results show significant improvements in multi-image reasoning tasks and also benefit text-only tasks without incurring extra training or inference costs.', title='Enhancing Image Distinction in Vision-Language Models'))
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='', title=''))
[03.02.2026 17:47] Querying the API.
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Internal flow signatures analyze depthwise dynamics in large language models to enable self-checking and targeted refinement without modifying the base model.  					AI-generated summary 				 Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce internal flow signatures that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact moving readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. Code is available at github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs.
[03.02.2026 17:47] Response: ```json
{
  "desc": "                 .         ,    ,      .     GRU          .       ,       ,           .",
  "emoji": "",
  "title": "  LLM:      "
}
```
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Internal flow signatures analyze depthwise dynamics in large language models to enable self-checking and targeted refinement without modifying the base model.  					AI-generated summary 				 Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce internal flow signatures that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact moving readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. Code is available at github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs."

[03.02.2026 17:47] Response: ```python
["TRAINING", "ARCHITECTURE"]
```
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Internal flow signatures analyze depthwise dynamics in large language models to enable self-checking and targeted refinement without modifying the base model.  					AI-generated summary 				 Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce internal flow signatures that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact moving readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. Code is available at github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs."

[03.02.2026 17:47] Response: ```python
['INTERPRETABILITY', 'HALLUCINATIONS', 'OPEN_SOURCE']
```
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a novel approach called internal flow signatures to analyze the decision-making processes in large language models (LLMs). By monitoring the dynamics of token movements within the model\'s architecture, the method allows for self-checking of generated outputs without altering the original model. The approach utilizes a lightweight GRU validator that identifies and localizes errors in the model\'s decision-making, enabling targeted refinements. This technique enhances the reliability of LLMs by providing a mechanism for auditing and correcting outputs based on internal dynamics.","title":"Self-Check and Refine: Enhancing LLMs with Internal Flow Signatures"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper presents a novel approach called internal flow signatures to analyze the decision-making processes in large language models (LLMs). By monitoring the dynamics of token movements within the model's architecture, the method allows for self-checking of generated outputs without altering the original model. The approach utilizes a lightweight GRU validator that identifies and localizes errors in the model's decision-making, enabling targeted refinements. This technique enhances the reliability of LLMs by providing a mechanism for auditing and correcting outputs based on internal dynamics.", title='Self-Check and Refine: Enhancing LLMs with Internal Flow Signatures'))
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"GRU","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='GRU', title=''))
[03.02.2026 17:47] Querying the API.
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Multi-agent systems for molecular discovery that use individualized scientist profiles based on publication and molecular history outperform traditional role-based approaches.  					AI-generated summary 				 Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.
[03.02.2026 17:47] Response: ```json
{
  "desc": "    INDIBATOR    ,    .       ,       ,      .     (, ),    ,      ,   .   ,         ,       .",
  "emoji": "",
  "title": "  :      "
}
```
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multi-agent systems for molecular discovery that use individualized scientist profiles based on publication and molecular history outperform traditional role-based approaches.  					AI-generated summary 				 Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery."

[03.02.2026 17:47] Response: ```python
["AGENTS", "MULTIMODAL"]
```

**Justification:**
- **AGENTS**: The paper explicitly focuses on multi-agent systems for molecular discovery, discussing agent behavior differentiation, agent personas, and multi-turn debate mechanisms between agents.
- **MULTIMODAL**: The framework (INDIBATOR) grounds agents in individualized scientist profiles constructed from two modalities: publication history and molecular history, combining multiple input modalities.
[03.02.2026 17:47] Error. Failed to parse JSON from LLM. ["AGENTS", "MULTIMODAL"]


**Justification:**
- **AGENTS**: The paper explicitly focuses on multi-agent systems for molecular discovery, discussing agent behavior differentiation, agent personas, and multi-turn debate mechanisms between agents.
- **MULTIMODAL**: The framework (INDIBATOR) grounds agents in individualized scientist profiles constructed from two modalities: publication history and molecular history, combining multiple input modalities.
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Multi-agent systems for molecular discovery that use individualized scientist profiles based on publication and molecular history outperform traditional role-based approaches.  					AI-generated summary 				 Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery."

[03.02.2026 17:47] Response: ```python
['SCIENCE', 'MULTI_AGENT']
```

Wait, let me reconsider. Looking at the available topics list, 'MULTI_AGENT' is not included. Let me classify based only on the provided topics:

```python
['SCIENCE']
```

The paper is clearly about scientific applications of AI/LMs, specifically for molecular discovery using multi-agent systems. It falls under the SCIENCE category as it addresses "scientific applications of LM including understanding of science articles and research automatization.
[03.02.2026 17:47] Error. Failed to parse JSON from LLM. ["SCIENCE", "MULTI_AGENT"]


Wait, let me reconsider. Looking at the available topics list, "MULTI_AGENT" is not included. Let me classify based only on the provided topics:


["SCIENCE"]


The paper is clearly about scientific applications of AI/LMs, specifically for molecular discovery using multi-agent systems. It falls under the SCIENCE category as it addresses "scientific applications of LM including understanding of science articles and research automatization.
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces INDIBATOR, a multi-agent system designed for molecular discovery that utilizes individualized scientist profiles. Unlike traditional systems that use generic roles, INDIBATOR tailors agent behavior based on unique publication and molecular histories. The agents engage in a structured debate process, allowing for proposal, critique, and voting, which enhances collaboration and decision-making. The results show that these personalized agents significantly outperform those using broad, role-based personas, highlighting the importance of individual research trajectories in scientific discovery.","title":"Harnessing Individuality for Superior Molecular Discovery"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces INDIBATOR, a multi-agent system designed for molecular discovery that utilizes individualized scientist profiles. Unlike traditional systems that use generic roles, INDIBATOR tailors agent behavior based on unique publication and molecular histories. The agents engage in a structured debate process, allowing for proposal, critique, and voting, which enhances collaboration and decision-making. The results show that these personalized agents significantly outperform those using broad, role-based personas, highlighting the importance of individual research trajectories in scientific discovery.', title='Harnessing Individuality for Superior Molecular Discovery'))
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"INDIBATORINDIBATOR","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='INDIBATORINDIBATOR', title=''))
[03.02.2026 17:47] Querying the API.
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Researchers developed a novel agentic data-generation framework to create culturally grounded safety datasets for Southeast Asia, resulting in multilingual safeguard models that outperform existing approaches in detecting regionally sensitive content while maintaining general safety performance.  					AI-generated summary 				 Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance.
[03.02.2026 17:47] Response: ```json
{
  "desc": "            - .         SEA-Guard     ,   -  .           ,         .   ,    ,      ,     .",
  "emoji": "",
  "title": "-    - "
}
```
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers developed a novel agentic data-generation framework to create culturally grounded safety datasets for Southeast Asia, resulting in multilingual safeguard models that outperform existing approaches in detecting regionally sensitive content while maintaining general safety performance.  					AI-generated summary 				 Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance."

[03.02.2026 17:47] Response: ```python
["AGENTS", "DATASET", "MULTILINGUAL", "BENCHMARK"]
```
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers developed a novel agentic data-generation framework to create culturally grounded safety datasets for Southeast Asia, resulting in multilingual safeguard models that outperform existing approaches in detecting regionally sensitive content while maintaining general safety performance.  					AI-generated summary 				 Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance."

[03.02.2026 17:47] Response: ```python
['ALIGNMENT', 'LOW_RESOURCE', 'SYNTHETIC', 'OPEN_SOURCE']
```
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new framework for generating culturally relevant safety datasets specifically for Southeast Asia. The framework addresses the challenges of creating large-scale datasets by utilizing agentic data generation, which allows for the production of authentic, region-specific data. The resulting SEA-Guard models are multilingual and designed to better detect sensitive content that aligns with local cultural values and regulations. Evaluations show that these models outperform traditional approaches, ensuring both regional sensitivity and overall safety performance.","title":"Empowering AI with Culturally Grounded Safety in Southeast Asia"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a new framework for generating culturally relevant safety datasets specifically for Southeast Asia. The framework addresses the challenges of creating large-scale datasets by utilizing agentic data generation, which allows for the production of authentic, region-specific data. The resulting SEA-Guard models are multilingual and designed to better detect sensitive content that aligns with local cultural values and regulations. Evaluations show that these models outperform traditional approaches, ensuring both regional sensitivity and overall safety performance.', title='Empowering AI with Culturally Grounded Safety in Southeast Asia'))
[03.02.2026 17:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SEA-Guard","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SEA-Guard', title=''))
[03.02.2026 17:47] Querying the API.
[03.02.2026 17:47] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A two-phase diagnostic framework based on Item Response Theory and Graded Response Model is introduced to assess the reliability of LLM-as-a-Judge by examining intrinsic consistency and human alignment.  					AI-generated summary 				 While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability.
[03.02.2026 17:48] Response: ```json
{
  "desc": "                   LLM-as-a-Judge        .  ,          ,  ,       .         :           .                LLM.",
  "emoji": "",
  "title": "  LLM-      "
}
```
[03.02.2026 17:48] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A two-phase diagnostic framework based on Item Response Theory and Graded Response Model is introduced to assess the reliability of LLM-as-a-Judge by examining intrinsic consistency and human alignment.  					AI-generated summary 				 While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability."

[03.02.2026 17:48] Response: ```python
["BENCHMARK", "MATH"]
```

**Justification:**

- **BENCHMARK**: The paper proposes a diagnostic framework for assessing the reliability of LLM-as-a-Judge, which is directly related to model evaluation frameworks and benchmarks. The framework is designed to validate and verify the reliability of LLM judges used in automated evaluation.

- **MATH**: The paper is grounded in Item Response Theory (IRT) and uses the Graded Response Model (GRM), which are mathematical frameworks and statistical methodologies for measurement and assessment.
[03.02.2026 17:48] Error. Failed to parse JSON from LLM. ["BENCHMARK", "MATH"]


**Justification:**

- **BENCHMARK**: The paper proposes a diagnostic framework for assessing the reliability of LLM-as-a-Judge, which is directly related to model evaluation frameworks and benchmarks. The framework is designed to validate and verify the reliability of LLM judges used in automated evaluation.

- **MATH**: The paper is grounded in Item Response Theory (IRT) and uses the Graded Response Model (GRM), which are mathematical frameworks and statistical methodologies for measurement and assessment.
[03.02.2026 17:48] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A two-phase diagnostic framework based on Item Response Theory and Graded Response Model is introduced to assess the reliability of LLM-as-a-Judge by examining intrinsic consistency and human alignment.  					AI-generated summary 				 While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability."

[03.02.2026 17:48] Response: ```python
['INTERPRETABILITY', 'ALIGNMENT']
```

**Justification:**

1. **INTERPRETABILITY**: The paper focuses on analyzing and explaining LLM behavior through a diagnostic framework. It examines "intrinsic consistency" and provides "interpretable signals for diagnosing judgments systematically," which directly relates to understanding model behavior and providing explanations.

2. **ALIGNMENT**: The paper explicitly addresses "human alignment, capturing correspondence with human quality assessments," which is about aligning language models with human values and preferences.
[03.02.2026 17:48] Error. Failed to parse JSON from LLM. ["INTERPRETABILITY", "ALIGNMENT"]


**Justification:**

1. **INTERPRETABILITY**: The paper focuses on analyzing and explaining LLM behavior through a diagnostic framework. It examines "intrinsic consistency" and provides "interpretable signals for diagnosing judgments systematically," which directly relates to understanding model behavior and providing explanations.

2. **ALIGNMENT**: The paper explicitly addresses "human alignment, capturing correspondence with human quality assessments," which is about aligning language models with human values and preferences.
[03.02.2026 17:48] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a two-phase diagnostic framework that uses Item Response Theory (IRT) and the Graded Response Model (GRM) to evaluate the reliability of large language models (LLMs) acting as judges. The framework assesses two key aspects: intrinsic consistency, which measures how stable the LLM\'s judgments are when faced with different prompts, and human alignment, which checks how closely the LLM\'s evaluations match those of human judges. By applying this framework, the authors demonstrate that IRT-GRM can provide clear insights into the reliability of LLMs, helping to identify issues that may affect their judgment quality. This approach aims to enhance the understanding and trustworthiness of LLMs in automated evaluation tasks.","title":"Assessing LLM Reliability: A Two-Phase Diagnostic Approach"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper presents a two-phase diagnostic framework that uses Item Response Theory (IRT) and the Graded Response Model (GRM) to evaluate the reliability of large language models (LLMs) acting as judges. The framework assesses two key aspects: intrinsic consistency, which measures how stable the LLM's judgments are when faced with different prompts, and human alignment, which checks how closely the LLM's evaluations match those of human judges. By applying this framework, the authors demonstrate that IRT-GRM can provide clear insights into the reliability of LLMs, helping to identify issues that may affect their judgment quality. This approach aims to enhance the understanding and trustworthiness of LLMs in automated evaluation tasks.", title='Assessing LLM Reliability: A Two-Phase Diagnostic Approach'))
[03.02.2026 17:48] Response: ParsedChatCompletionMessage[Article](content='{"desc":"IRTGRMLLMLLMLLMIRT-GRMLLM","title":"LLM"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='IRTGRMLLMLLMLLMIRT-GRMLLM', title='LLM'))
[03.02.2026 17:48] Querying the API.
[03.02.2026 17:48] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Clipping-Free Policy Optimization replaces heuristic clipping with convex quadratic penalty to stabilize reinforcement learning training for large language models without performance loss.  					AI-generated summary 				 Reinforcement learning has become central to post-training large language models, yet dominant algorithms rely on clipping mechanisms that introduce optimization issues at scale, including zero-gradient regions, reward hacking, and training instability. We propose Clipping-Free Policy Optimization (CFPO), which replaces heuristic clipping with a convex quadratic penalty derived from Total Variation divergence constraints, yielding an everywhere-differentiable objective that enforces stable policy updates without hard boundaries. We evaluate CFPO across both reasoning and alignment settings. In reasoning, CFPO matches clipping-based methods on downstream benchmarks while extending the stable training regime. In alignment, CFPO mitigates verbosity exploitation and reduces capability degradation, while achieving competitive instruction-following performance. CFPO requires only a one-line code change and no additional hyperparameters. Our results suggest that CFPO is a promising drop-in alternative to clipping-based methods for LLM post-training.
[03.02.2026 17:48] Response: ```json
{
  "desc": "  Clipping-Free Policy Optimization (CFPO)          ,     (clipping)    ,      .       ,    ,     . CFPO     ,        .           ,       ,     .",
  "emoji": "",
  "title": "        LLM"
}
```
[03.02.2026 17:48] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Clipping-Free Policy Optimization replaces heuristic clipping with convex quadratic penalty to stabilize reinforcement learning training for large language models without performance loss.  					AI-generated summary 				 Reinforcement learning has become central to post-training large language models, yet dominant algorithms rely on clipping mechanisms that introduce optimization issues at scale, including zero-gradient regions, reward hacking, and training instability. We propose Clipping-Free Policy Optimization (CFPO), which replaces heuristic clipping with a convex quadratic penalty derived from Total Variation divergence constraints, yielding an everywhere-differentiable objective that enforces stable policy updates without hard boundaries. We evaluate CFPO across both reasoning and alignment settings. In reasoning, CFPO matches clipping-based methods on downstream benchmarks while extending the stable training regime. In alignment, CFPO mitigates verbosity exploitation and reduces capability degradation, while achieving competitive instruction-following performance. CFPO requires only a one-line code change and no additional hyperparameters. Our results suggest that CFPO is a promising drop-in alternative to clipping-based methods for LLM post-training."

[03.02.2026 17:48] Response: ```python
['RL', 'RLHF', 'TRAINING']
```
[03.02.2026 17:48] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Clipping-Free Policy Optimization replaces heuristic clipping with convex quadratic penalty to stabilize reinforcement learning training for large language models without performance loss.  					AI-generated summary 				 Reinforcement learning has become central to post-training large language models, yet dominant algorithms rely on clipping mechanisms that introduce optimization issues at scale, including zero-gradient regions, reward hacking, and training instability. We propose Clipping-Free Policy Optimization (CFPO), which replaces heuristic clipping with a convex quadratic penalty derived from Total Variation divergence constraints, yielding an everywhere-differentiable objective that enforces stable policy updates without hard boundaries. We evaluate CFPO across both reasoning and alignment settings. In reasoning, CFPO matches clipping-based methods on downstream benchmarks while extending the stable training regime. In alignment, CFPO mitigates verbosity exploitation and reduces capability degradation, while achieving competitive instruction-following performance. CFPO requires only a one-line code change and no additional hyperparameters. Our results suggest that CFPO is a promising drop-in alternative to clipping-based methods for LLM post-training."

[03.02.2026 17:48] Response: ```python
['OPTIMIZATION', 'ALIGNMENT', 'REASONING']
```
[03.02.2026 17:48] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Clipping-Free Policy Optimization (CFPO), a new method for stabilizing reinforcement learning in large language models. Instead of using clipping, which can cause optimization problems, CFPO employs a convex quadratic penalty to create a smooth and differentiable objective function. This approach allows for stable policy updates without the issues associated with clipping, such as zero-gradient regions and training instability. The results show that CFPO performs comparably to traditional methods while improving training stability and reducing verbosity exploitation in alignment tasks.","title":"Stabilizing Reinforcement Learning with Clipping-Free Policy Optimization"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Clipping-Free Policy Optimization (CFPO), a new method for stabilizing reinforcement learning in large language models. Instead of using clipping, which can cause optimization problems, CFPO employs a convex quadratic penalty to create a smooth and differentiable objective function. This approach allows for stable policy updates without the issues associated with clipping, such as zero-gradient regions and training instability. The results show that CFPO performs comparably to traditional methods while improving training stability and reducing verbosity exploitation in alignment tasks.', title='Stabilizing Reinforcement Learning with Clipping-Free Policy Optimization'))
[03.02.2026 17:48] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CFPOCFPOCFPOCFPO","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CFPOCFPOCFPOCFPO', title=''))
[03.02.2026 17:48] Renaming data file.
[03.02.2026 17:48] Renaming previous data. hf_papers.json to ./d/2026-02-03.json
[03.02.2026 17:48] Saving new data file.
[03.02.2026 17:48] Generating page.
[03.02.2026 17:48] Renaming previous page.
[03.02.2026 17:48] Renaming previous data. index.html to ./d/2026-02-03.html
[03.02.2026 17:48] Writing result.
[03.02.2026 17:48] Renaming log file.
[03.02.2026 17:48] Renaming previous data. log.txt to ./logs/2026-02-03_last_log.txt
