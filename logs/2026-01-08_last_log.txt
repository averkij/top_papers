[08.01.2026 13:42] Read previous papers.
[08.01.2026 13:42] Generating top page (month).
[08.01.2026 13:42] Writing top page (month).
[08.01.2026 14:27] Read previous papers.
[08.01.2026 14:27] Get feed.
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02151
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03986
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03872
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04151
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04194
[08.01.2026 14:27] Extract page data from URL. URL: https://huggingface.co/papers/2601.03509
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03471
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04171
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03699
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02075
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00423
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03448
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03315
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04090
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03467
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03236
[08.01.2026 14:27] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00705
[08.01.2026 14:27] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[08.01.2026 14:27] No deleted papers detected.
[08.01.2026 14:27] Downloading and parsing papers (pdf, html). Total: 17.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.02151.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.02151.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.02151.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03986.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03986.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03986.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03872.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03872.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03872.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.04151.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.04151.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.04151.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.04194.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.04194.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.04194.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03509.
[08.01.2026 14:27] Downloading paper 2601.03509 from https://arxiv.org/pdf/2601.03509v1...
[08.01.2026 14:27] Failed to download and parse paper https://huggingface.co/papers/2601.03509: 'LTChar' object is not iterable
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03471.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03471.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03471.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.04171.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.04171.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.04171.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03699.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03699.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03699.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.02075.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.02075.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.02075.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.00423.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.00423.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.00423.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03448.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03448.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03448.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03315.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03315.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03315.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.04090.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.04090.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.04090.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03467.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03467.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03467.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.03236.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.03236.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.03236.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Downloading and parsing paper https://huggingface.co/papers/2601.00705.
[08.01.2026 14:27] Extra JSON file exists (./assets/json/2601.00705.json), skip PDF parsing.
[08.01.2026 14:27] Paper image links file exists (./assets/img_data/2601.00705.json), skip HTML parsing.
[08.01.2026 14:27] Success.
[08.01.2026 14:27] Enriching papers with extra data.
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 0. Entropy-Adaptive Fine-Tuning addresses catastrophic forgetting in supervised fine-tuning by using token-level entropy to distinguish uncertainty from knowledge conflict, enabling better preservation of general capabilities.  					AI-generated summary 				 Supervised Fine-Tuning (SFT) is the standard...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 1. Researchers developed Benchmark^2, a framework with three metrics to evaluate benchmark quality for large language models, revealing significant variations in existing benchmarks and enabling more efficient evaluation through selective benchmark construction.  					AI-generated summary 				 The rapi...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 2. ATLAS is a dual-path framework that dynamically selects optimal model-tool combinations for cross-domain reasoning through cluster-based routing and reinforcement learning-based multi-step routing, achieving superior performance on complex reasoning tasks.  					AI-generated summary 				 The integra...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 3. Klear addresses audio-video joint generation challenges through a unified model architecture, progressive multitask training, and large-scale dense-caption data construction, achieving superior alignment and generalization.  					AI-generated summary 				 Audio-video joint generation has progressed ...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 4. CHORD is a universal generative framework that extracts Lagrangian motion information from Eulerian video representations to synthesize diverse 4D dynamic scenes without requiring category-specific rules or large datasets.  					AI-generated summary 				 Dynamic objects in our physical 4D (3D + time...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 5. Programmatic Skill Network enables continual skill acquisition through executable symbolic programs that evolve via reflection, progressive optimization, and structural refactoring mechanisms.  					AI-generated summary 				 We study continual skill acquisition in open-ended embodied environments wh...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 6. EpiQAL presents a novel benchmark for evaluating epidemiological reasoning in language models through three distinct subsets measuring factual recall, multi-step inference, and conclusion reconstruction from scientific literature.  					AI-generated summary 				 Reliable epidemiological reasoning re...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 7. Agentic Rubrics enable efficient and scalable verification for software engineering agents by creating context-aware checklists that outperform traditional methods while maintaining interpretability.  					AI-generated summary 				 Verification is critical for improving agents: it provides the rewar...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 8. RedBench presents a unified dataset with standardized risk categorization for evaluating LLM vulnerabilities across multiple domains and attack types.  					AI-generated summary 				 As large language models (LLMs) become integral to safety-critical applications, ensuring their robustness against ad...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 9. MDAgent2 enables automated molecular dynamics code generation and question answering through domain-adapted language models and a multi-agent runtime system.  					AI-generated summary 				 Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials scienc...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 10. Entropy-aware policy optimization method for reinforcement learning in flow matching models that improves exploration through SDE and ODE sampling strategies.  					AI-generated summary 				 Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stoc...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 11. Language models pre-trained with a framework combining standard next-token prediction and structured language learning tasks show enhanced linguistic competence without sacrificing general reasoning capabilities.  					AI-generated summary 				 Language models (LMs) are pre-trained on raw text datas...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 12. A case study of four attempts to autonomously generate ML research papers using LLM agents reveals recurring failure modes and proposes design principles for robust AI-scientist systems.  					AI-generated summary 				 We report a case study of four end-to-end attempts to autonomously generate ML re...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 13. Gen3R combines foundational reconstruction models with video diffusion models to generate 3D scenes with RGB videos and geometric information through aligned latents.  					AI-generated summary 				 We present Gen3R, a method that bridges the strong priors of foundational reconstruction models and v...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 14. ThinkRL-Edit enhances reasoning-centric image editing through reinforcement learning by expanding visual reasoning exploration beyond denoising stochasticity and using unbiased reward strategies.  					AI-generated summary 				 Instruction-driven image editing with unified multimodal generative mode...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 15. MAGMA is a multi-graph memory architecture that improves long-context reasoning in language models by separating memory representation from retrieval logic across semantic, temporal, causal, and entity dimensions.  					AI-generated summary 				 Memory-Augmented Generation (MAG) extends Large Langua...
[08.01.2026 14:27] ********************************************************************************
[08.01.2026 14:27] Abstract 16. RGS-SLAM presents a robust Gaussian-splatting SLAM framework that uses dense multi-view correspondences and DINOv3 descriptors for efficient, stable mapping with improved rendering fidelity.  					AI-generated summary 				 We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replac...
[08.01.2026 14:27] Read previous papers.
[08.01.2026 14:27] Generating reviews via LLM API.
[08.01.2026 14:27] Using data from previous issue: {"categories": [], "emoji": "‚öñÔ∏è", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–±—ã–≤–∞–Ω–∏—è –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –≤—ã—è–≤–∏–ª–∏, —á—Ç–æ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º (SFT) –º–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –ø–æ–ª—É—á–∞–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–µ
[08.01.2026 14:27] Using data from previous issue: {"categories": ["#benchmark"], "emoji": "üìè", "ru": {"title": "–ò–∑–º–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π: —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Benchmark¬≤, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –§—Ä–µ–π–º–≤–æ—Ä–∫ –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ –º–µ—Ç
[08.01.2026 14:27] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#rl", "#agents", "#benchmark", "#multimodal"], "emoji": "üéØ", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é", "desc": "ATLAS ‚Äî —ç—Ç–æ –¥–≤—É—Ö–ø—É—Ç—ë–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å
[08.01.2026 14:27] Using data from previous issue: {"categories": ["#data", "#training", "#dataset", "#audio", "#video", "#multimodal", "#architecture"], "emoji": "üé¨", "ru": {"title": "–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Ä–æ–∂–¥–µ–Ω–∏–µ –∑–≤—É–∫–∞ –∏ –æ–±—Ä–∞–∑–∞: –µ–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Klear ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π –≥–µ–Ω–µ
[08.01.2026 14:27] Using data from previous issue: {"categories": ["#video", "#synthetic", "#3d", "#multimodal", "#robotics"], "emoji": "üé¨", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 4D –¥–∏–Ω–∞–º–∏–∫–∏ –∏–∑ 2D –≤–∏–¥–µ–æ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª", "desc": "CHORD ‚Äî —ç—Ç–æ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–≤–∏–∂–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ 2D –≤–∏–¥–µ–æ –≤ –≠
[08.01.2026 14:27] Querying the API.
[08.01.2026 14:27] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Programmatic Skill Network enables continual skill acquisition through executable symbolic programs that evolve via reflection, progressive optimization, and structural refactoring mechanisms.  					AI-generated summary 				 We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\footnote{We plan to open-source the code.
[08.01.2026 14:27] Response: ```json
{
  "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ Programmatic Skill Network (PSN) ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –≤ –æ—Ç–∫—Ä—ã—Ç—ã—Ö —Å—Ä–µ–¥–∞—Ö, –≥–¥–µ –Ω–∞–≤—ã–∫–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–µ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç—Ä—ë—Ö –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫, –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º, –∏ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ —Å–µ—Ç–µ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –æ—Ç–∫–∞—Ç–æ–≤. PSN –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞–º —Å—Ç—Ä–æ–∏—Ç—å, —É—Ç–æ—á–Ω—è—Ç—å –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞—Å—Ç—É—â—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É –Ω–∞–≤—ã–∫–æ–≤, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—è –¥–∏–Ω–∞–º–∏–∫—É –æ–±—É—á–µ–Ω–∏—è, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö MineDojo –∏ Crafter –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤, –±—ã—Å—Ç—Ä—É—é –∞–¥–∞–ø—Ç–∞—Ü–∏—é –∏ —Ö–æ—Ä–æ—à—É—é –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—é.",
  "emoji": "üß¨",
  "title": "–≠–≤–æ–ª—é—Ü–∏—è –Ω–∞–≤—ã–∫–æ–≤ —á–µ—Ä–µ–∑ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏—é"
}
```
[08.01.2026 14:27] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Programmatic Skill Network enables continual skill acquisition through executable symbolic programs that evolve via reflection, progressive optimization, and structural refactoring mechanisms.  					AI-generated summary 				 We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\footnote{We plan to open-source the code."

[08.01.2026 14:27] Response: ```python
['AGENTS', 'ROBOTICS', 'TRAINING']
```

**Justification:**

- **AGENTS**: The paper explicitly studies "continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills." This is directly about agent-based architectures and autonomous agent capabilities.

- **ROBOTICS**: The paper focuses on "embodied environments" and tests on MineDojo and Crafter, which are embodied AI/robotics simulation environments where agents learn to perform tasks.

- **TRAINING**: The paper proposes mechanisms for improving how agents learn and refine skills over time, including "progressive optimization," "maturity-aware update gating," and discusses "learning dynamics," which are core training methodology contributions.
[08.01.2026 14:27] Error. Failed to parse JSON from LLM. ["AGENTS", "ROBOTICS", "TRAINING"]


**Justification:**

- **AGENTS**: The paper explicitly studies "continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills." This is directly about agent-based architectures and autonomous agent capabilities.

- **ROBOTICS**: The paper focuses on "embodied environments" and tests on MineDojo and Crafter, which are embodied AI/robotics simulation environments where agents learn to perform tasks.

- **TRAINING**: The paper proposes mechanisms for improving how agents learn and refine skills over time, including "progressive optimization," "maturity-aware update gating," and discusses "learning dynamics," which are core training methodology contributions.
[08.01.2026 14:27] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Programmatic Skill Network enables continual skill acquisition through executable symbolic programs that evolve via reflection, progressive optimization, and structural refactoring mechanisms.  					AI-generated summary 				 We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\footnote{We plan to open-source the code."

[08.01.2026 14:27] Response: ```python
["REASONING", "OPEN_SOURCE"]
```

**Justification:**

1. **REASONING**: The paper focuses on continual skill acquisition through structured fault localization (REFLECT mechanism), progressive optimization, and refactoring. These mechanisms enable the agent to construct logical reasoning about skill compositions and improve them through reflection and optimization - core aspects of enhancing logical reasoning capabilities.

2. **OPEN_SOURCE**: The paper explicitly states "We plan to open-source the code," indicating a commitment to releasing code/framework to the public.
[08.01.2026 14:27] Error. Failed to parse JSON from LLM. ["REASONING", "OPEN_SOURCE"]


**Justification:**

1. **REASONING**: The paper focuses on continual skill acquisition through structured fault localization (REFLECT mechanism), progressive optimization, and refactoring. These mechanisms enable the agent to construct logical reasoning about skill compositions and improve them through reflection and optimization - core aspects of enhancing logical reasoning capabilities.

2. **OPEN_SOURCE**: The paper explicitly states "We plan to open-source the code," indicating a commitment to releasing code/framework to the public.
[08.01.2026 14:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Programmatic Skill Network (PSN) is a framework designed for continual skill acquisition in dynamic environments. It allows agents to create and refine a library of executable skills through three main mechanisms: REFLECT for identifying issues in skill combinations, progressive optimization to balance skill reliability and adaptability, and structural refactoring to keep the skill network efficient. PSN utilizes large language models to enhance these processes, enabling agents to learn from their experiences effectively. Experiments show that PSN can adapt quickly and generalize well across various tasks, demonstrating its potential in open-ended learning scenarios.","title":"Evolving Skills for Endless Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Programmatic Skill Network (PSN) is a framework designed for continual skill acquisition in dynamic environments. It allows agents to create and refine a library of executable skills through three main mechanisms: REFLECT for identifying issues in skill combinations, progressive optimization to balance skill reliability and adaptability, and structural refactoring to keep the skill network efficient. PSN utilizes large language models to enhance these processes, enabling agents to learn from their experiences effectively. Experiments show that PSN can adapt quickly and generalize well across various tasks, demonstrating its potential in open-ended learning scenarios.', title='Evolving Skills for Endless Learning'))
[08.01.2026 14:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Á®ãÂ∫èÊäÄËÉΩÁΩëÁªúÔºàPSNÔºâÊòØ‰∏ÄÁßçÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄöËøáÂèØÊâßË°åÁöÑÁ¨¶Âè∑Á®ãÂ∫èÂÆûÁé∞ÊåÅÁª≠ÁöÑÊäÄËÉΩËé∑Âèñ„ÄÇÂÆÉÈÄöËøáÂèçÊÄù„ÄÅÊ∏êËøõ‰ºòÂåñÂíåÁªìÊûÑÈáçÊûÑÊú∫Âà∂Ôºå‰ΩøÊäÄËÉΩÂ∫ì‰∏çÊñ≠Êâ©Â±ïÂíåÊºîÂåñ„ÄÇPSNÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂÆûÁé∞‰∏âÁßçÊ†∏ÂøÉÊú∫Âà∂ÔºöÁªìÊûÑÂåñÊïÖÈöúÂÆö‰Ωç„ÄÅÊàêÁÜüÂ∫¶ÊÑüÁü•ÁöÑ‰ºòÂåñÊõ¥Êñ∞ÂíåÂú®ÂõûÊªöÈ™åËØÅ‰∏ãÁöÑÁªìÊûÑÈáçÊûÑ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPSNÂú®ÂºÄÊîæÂºè‰ªªÂä°ÂàÜÂ∏É‰∏≠Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊäÄËÉΩÈáçÁî®„ÄÅÂø´ÈÄüÈÄÇÂ∫îÂíåËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ","title":"Á®ãÂ∫èÊäÄËÉΩÁΩëÁªúÔºöÊåÅÁª≠ÊäÄËÉΩËé∑ÂèñÁöÑÊñ∞ÊñπÊ≥ï"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Á®ãÂ∫èÊäÄËÉΩÁΩëÁªúÔºàPSNÔºâÊòØ‰∏ÄÁßçÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄöËøáÂèØÊâßË°åÁöÑÁ¨¶Âè∑Á®ãÂ∫èÂÆûÁé∞ÊåÅÁª≠ÁöÑÊäÄËÉΩËé∑Âèñ„ÄÇÂÆÉÈÄöËøáÂèçÊÄù„ÄÅÊ∏êËøõ‰ºòÂåñÂíåÁªìÊûÑÈáçÊûÑÊú∫Âà∂Ôºå‰ΩøÊäÄËÉΩÂ∫ì‰∏çÊñ≠Êâ©Â±ïÂíåÊºîÂåñ„ÄÇPSNÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂÆûÁé∞‰∏âÁßçÊ†∏ÂøÉÊú∫Âà∂ÔºöÁªìÊûÑÂåñÊïÖÈöúÂÆö‰Ωç„ÄÅÊàêÁÜüÂ∫¶ÊÑüÁü•ÁöÑ‰ºòÂåñÊõ¥Êñ∞ÂíåÂú®ÂõûÊªöÈ™åËØÅ‰∏ãÁöÑÁªìÊûÑÈáçÊûÑ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPSNÂú®ÂºÄÊîæÂºè‰ªªÂä°ÂàÜÂ∏É‰∏≠Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊäÄËÉΩÈáçÁî®„ÄÅÂø´ÈÄüÈÄÇÂ∫îÂíåËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ', title='Á®ãÂ∫èÊäÄËÉΩÁΩëÁªúÔºöÊåÅÁª≠ÊäÄËÉΩËé∑ÂèñÁöÑÊñ∞ÊñπÊ≥ï'))
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#benchmark", "#healthcare", "#science"], "emoji": "üî¨", "ru": {"title": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–∏–¥–µ–º–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω EpiQAL ‚Äî –ø–µ—Ä–≤—ã–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç–ø–∏–¥–µ–º–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è 
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#interpretability", "#plp", "#benchmark", "#rl"], "emoji": "‚úÖ", "ru": {"title": "–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —á–µ–∫–ª–∏—Å—Ç—ã –≤–º–µ—Å—Ç–æ –∫–æ–¥–∞: –∞–≥–µ–Ω—Ç–∏–≤–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –º–µ—Ç–æ–¥ Agentic Rubrics –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏–π –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –±
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#open_source", "#security", "#dataset", "#benchmark"], "emoji": "üîí", "ru": {"title": "–ï–¥–∏–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RedBench ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π 37 —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#data", "#training", "#agents", "#dataset", "#plp", "#benchmark", "#rl", "#optimization", "#open_source", "#science", "#small_models"], "emoji": "‚öõÔ∏è", "ru": {"title": "–Ø–∑—ã–∫ –¥–ª—è –Ω–∞—É–∫–∏: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏", "desc": "MDAgent2 ‚Äî —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#training", "#rl", "#alignment", "#optimization"], "emoji": "üé≤", "ru": {"title": "–≠–Ω—Ç—Ä–æ–ø–∏—è –∫–∞–∫ –∫–ª—é—á –∫ –ª—É—á—à–µ–º—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è E-GRPO ‚Äî –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏, —É—á–∏—Ç—ã–≤–∞—é—â–∏–π —ç–Ω—Ç—Ä–æ–ø–∏—é, –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ 
[08.01.2026 14:28] Using data from previous issue: {"categories": [], "emoji": "üìö", "ru": {"title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç L2T ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Å —è–≤–Ω—ã–º–∏ –∑
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#long_context", "#open_source", "#hallucinations", "#science"], "emoji": "ü§ñ", "ru": {"title": "–ù–∞ –ø—É—Ç–∏ –∫ –Ω–∞–¥–µ–∂–Ω—ã–º AI-—É—á–µ–Ω—ã–º: —É—Ä–æ–∫–∏ –∏–∑ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫", "desc": "–í —Å—Ç–∞—Ç—å–µ –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞—É—á–Ω—ã—Ö —Ä–∞–±–æ—Ç –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–º–æ—â—å—é —Å–∏—Å—Ç–µ–º—ã –∏–∑ —à–µ—Å
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#3d", "#multimodal", "#video", "#architecture", "#diffusion"], "emoji": "üé¨", "ru": {"title": "–°–æ–≤–º–µ—Å—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –∏ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ —á–µ—Ä–µ–∑ –≤—ã—Ä–∞–≤–Ω–µ–Ω–Ω—ã–µ –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è", "desc": "Gen3R –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–æ–¥–µ–ª–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö —Å—Ü–µ–Ω. 
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#reasoning", "#training", "#cv", "#rl", "#optimization", "#multimodal"], "emoji": "üé®", "ru": {"title": "–ì–ª—É–±–æ–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ reinforcement learning –≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "ThinkRL-Edit ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ reinforcement learning –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ
[08.01.2026 14:28] Using data from previous issue: {"categories": ["#rag", "#graphs", "#long_context", "#interpretability", "#reasoning", "#agents", "#architecture"], "emoji": "üß†", "ru": {"title": "–ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", "desc": "MAGMA –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–Ω–æ–≥–æ–≥—Ä–∞—Ñ–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–∞–º—è—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–æ–ª–≥–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂
[08.01.2026 14:28] Using data from previous issue: {"categories": [], "emoji": "üó∫Ô∏è", "ru": {"title": "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø–ª–æ—Ç–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –ì–∞—É—Å—Å–æ–≤–∞ SLAM", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç RGS-SLAM, –º–æ—â–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ì–∞—É—Å—Å–æ–≤—ã—Ö —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥–∞ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ü–µ–Ω—ã. –í–º–µ—Å—Ç–æ –ø–æ—Å—Ç–µ–ø
[08.01.2026 14:28] Renaming data file.
[08.01.2026 14:28] Renaming previous data. hf_papers.json to ./d/2026-01-08.json
[08.01.2026 14:28] Saving new data file.
[08.01.2026 14:28] Generating page.
[08.01.2026 14:28] Renaming previous page.
[08.01.2026 14:28] Renaming previous data. index.html to ./d/2026-01-08.html
[08.01.2026 14:28] Writing result.
[08.01.2026 14:28] Renaming log file.
[08.01.2026 14:28] Renaming previous data. log.txt to ./logs/2026-01-08_last_log.txt
