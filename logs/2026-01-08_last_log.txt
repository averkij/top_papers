[08.01.2026 09:31] Read previous papers.
[08.01.2026 09:31] Generating top page (month).
[08.01.2026 09:31] Writing top page (month).
[08.01.2026 10:26] Read previous papers.
[08.01.2026 10:26] Get feed.
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02151
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03986
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03872
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04151
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04194
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03471
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00423
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04171
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03699
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02075
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03467
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03236
[08.01.2026 10:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00705
[08.01.2026 10:26] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[08.01.2026 10:26] No deleted papers detected.
[08.01.2026 10:26] Downloading and parsing papers (pdf, html). Total: 13.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.02151.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.02151.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.02151.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.03986.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.03986.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.03986.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.03872.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.03872.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.03872.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.04151.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.04151.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.04151.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.04194.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.04194.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.04194.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.03471.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.03471.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.03471.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.00423.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.00423.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.00423.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.04171.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.04171.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.04171.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.03699.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.03699.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.03699.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.02075.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.02075.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.02075.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.03467.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.03467.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.03467.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.03236.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.03236.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.03236.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Downloading and parsing paper https://huggingface.co/papers/2601.00705.
[08.01.2026 10:26] Extra JSON file exists (./assets/json/2601.00705.json), skip PDF parsing.
[08.01.2026 10:26] Paper image links file exists (./assets/img_data/2601.00705.json), skip HTML parsing.
[08.01.2026 10:26] Success.
[08.01.2026 10:26] Enriching papers with extra data.
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 0. Entropy-Adaptive Fine-Tuning addresses catastrophic forgetting in supervised fine-tuning by using token-level entropy to distinguish uncertainty from knowledge conflict, enabling better preservation of general capabilities.  					AI-generated summary 				 Supervised Fine-Tuning (SFT) is the standard...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 1. Researchers developed Benchmark^2, a framework with three metrics to evaluate benchmark quality for large language models, revealing significant variations in existing benchmarks and enabling more efficient evaluation through selective benchmark construction.  					AI-generated summary 				 The rapi...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 2. ATLAS is a dual-path framework that dynamically selects optimal model-tool combinations for cross-domain reasoning through cluster-based routing and reinforcement learning-based multi-step routing, achieving superior performance on complex reasoning tasks.  					AI-generated summary 				 The integra...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 3. Klear addresses audio-video joint generation challenges through a unified model architecture, progressive multitask training, and large-scale dense-caption data construction, achieving superior alignment and generalization.  					AI-generated summary 				 Audio-video joint generation has progressed ...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 4. CHORD is a universal generative framework that extracts Lagrangian motion information from Eulerian video representations to synthesize diverse 4D dynamic scenes without requiring category-specific rules or large datasets.  					AI-generated summary 				 Dynamic objects in our physical 4D (3D + time...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 5. EpiQAL presents a novel benchmark for evaluating epidemiological reasoning in language models through three distinct subsets measuring factual recall, multi-step inference, and conclusion reconstruction from scientific literature.  					AI-generated summary 				 Reliable epidemiological reasoning re...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 6. Entropy-aware policy optimization method for reinforcement learning in flow matching models that improves exploration through SDE and ODE sampling strategies.  					AI-generated summary 				 Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stoc...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 7. Agentic Rubrics enable efficient and scalable verification for software engineering agents by creating context-aware checklists that outperform traditional methods while maintaining interpretability.  					AI-generated summary 				 Verification is critical for improving agents: it provides the rewar...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 8. RedBench presents a unified dataset with standardized risk categorization for evaluating LLM vulnerabilities across multiple domains and attack types.  					AI-generated summary 				 As large language models (LLMs) become integral to safety-critical applications, ensuring their robustness against ad...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 9. MDAgent2 enables automated molecular dynamics code generation and question answering through domain-adapted language models and a multi-agent runtime system.  					AI-generated summary 				 Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials scienc...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 10. ThinkRL-Edit enhances reasoning-centric image editing through reinforcement learning by expanding visual reasoning exploration beyond denoising stochasticity and using unbiased reward strategies.  					AI-generated summary 				 Instruction-driven image editing with unified multimodal generative mode...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 11. MAGMA is a multi-graph memory architecture that improves long-context reasoning in language models by separating memory representation from retrieval logic across semantic, temporal, causal, and entity dimensions.  					AI-generated summary 				 Memory-Augmented Generation (MAG) extends Large Langua...
[08.01.2026 10:26] ********************************************************************************
[08.01.2026 10:26] Abstract 12. RGS-SLAM presents a robust Gaussian-splatting SLAM framework that uses dense multi-view correspondences and DINOv3 descriptors for efficient, stable mapping with improved rendering fidelity.  					AI-generated summary 				 We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replac...
[08.01.2026 10:26] Read previous papers.
[08.01.2026 10:26] Generating reviews via LLM API.
[08.01.2026 10:26] Using data from previous issue: {"categories": [], "emoji": "‚öñÔ∏è", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–±—ã–≤–∞–Ω–∏—è –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –≤—ã—è–≤–∏–ª–∏, —á—Ç–æ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º (SFT) –º–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –ø–æ–ª—É—á–∞–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–µ
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#benchmark"], "emoji": "üìè", "ru": {"title": "–ò–∑–º–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π: —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Benchmark¬≤, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –§—Ä–µ–π–º–≤–æ—Ä–∫ –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ –º–µ—Ç
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#rl", "#agents", "#benchmark", "#multimodal"], "emoji": "üéØ", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é", "desc": "ATLAS ‚Äî —ç—Ç–æ –¥–≤—É—Ö–ø—É—Ç—ë–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#data", "#training", "#dataset", "#audio", "#video", "#multimodal", "#architecture"], "emoji": "üé¨", "ru": {"title": "–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Ä–æ–∂–¥–µ–Ω–∏–µ –∑–≤—É–∫–∞ –∏ –æ–±—Ä–∞–∑–∞: –µ–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Klear ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π –≥–µ–Ω–µ
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#video", "#synthetic", "#3d", "#multimodal", "#robotics"], "emoji": "üé¨", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 4D –¥–∏–Ω–∞–º–∏–∫–∏ –∏–∑ 2D –≤–∏–¥–µ–æ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª", "desc": "CHORD ‚Äî —ç—Ç–æ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–≤–∏–∂–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ 2D –≤–∏–¥–µ–æ –≤ –≠
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#benchmark", "#healthcare", "#science"], "emoji": "üî¨", "ru": {"title": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–∏–¥–µ–º–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω EpiQAL ‚Äî –ø–µ—Ä–≤—ã–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç–ø–∏–¥–µ–º–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è 
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#training", "#rl", "#alignment", "#optimization"], "emoji": "üé≤", "ru": {"title": "–≠–Ω—Ç—Ä–æ–ø–∏—è –∫–∞–∫ –∫–ª—é—á –∫ –ª—É—á—à–µ–º—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è E-GRPO ‚Äî –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏, —É—á–∏—Ç—ã–≤–∞—é—â–∏–π —ç–Ω—Ç—Ä–æ–ø–∏—é, –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ 
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#interpretability", "#plp", "#benchmark", "#rl"], "emoji": "‚úÖ", "ru": {"title": "–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —á–µ–∫–ª–∏—Å—Ç—ã –≤–º–µ—Å—Ç–æ –∫–æ–¥–∞: –∞–≥–µ–Ω—Ç–∏–≤–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –º–µ—Ç–æ–¥ Agentic Rubrics –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏–π –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –±
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#open_source", "#security", "#dataset", "#benchmark"], "emoji": "üîí", "ru": {"title": "–ï–¥–∏–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RedBench ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π 37 —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#data", "#training", "#agents", "#dataset", "#plp", "#benchmark", "#rl", "#optimization", "#open_source", "#science", "#small_models"], "emoji": "‚öõÔ∏è", "ru": {"title": "–Ø–∑—ã–∫ –¥–ª—è –Ω–∞—É–∫–∏: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏", "desc": "MDAgent2 ‚Äî —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#reasoning", "#training", "#cv", "#rl", "#optimization", "#multimodal"], "emoji": "üé®", "ru": {"title": "–ì–ª—É–±–æ–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ reinforcement learning –≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "ThinkRL-Edit ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ reinforcement learning –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ
[08.01.2026 10:26] Using data from previous issue: {"categories": ["#rag", "#graphs", "#long_context", "#interpretability", "#reasoning", "#agents", "#architecture"], "emoji": "üß†", "ru": {"title": "–ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", "desc": "MAGMA –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–Ω–æ–≥–æ–≥—Ä–∞—Ñ–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–∞–º—è—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–æ–ª–≥–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂
[08.01.2026 10:26] Using data from previous issue: {"categories": [], "emoji": "üó∫Ô∏è", "ru": {"title": "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø–ª–æ—Ç–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –ì–∞—É—Å—Å–æ–≤–∞ SLAM", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç RGS-SLAM, –º–æ—â–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ì–∞—É—Å—Å–æ–≤—ã—Ö —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥–∞ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ü–µ–Ω—ã. –í–º–µ—Å—Ç–æ –ø–æ—Å—Ç–µ–ø
[08.01.2026 10:26] Renaming data file.
[08.01.2026 10:26] Renaming previous data. hf_papers.json to ./d/2026-01-08.json
[08.01.2026 10:26] Saving new data file.
[08.01.2026 10:26] Generating page.
[08.01.2026 10:26] Renaming previous page.
[08.01.2026 10:26] Renaming previous data. index.html to ./d/2026-01-08.html
[08.01.2026 10:26] Writing result.
[08.01.2026 10:26] Renaming log file.
[08.01.2026 10:26] Renaming previous data. log.txt to ./logs/2026-01-08_last_log.txt
