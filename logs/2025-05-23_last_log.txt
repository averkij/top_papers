[23.05.2025 05:13] Read previous papers.
[23.05.2025 05:13] Generating top page (month).
[23.05.2025 05:13] Writing top page (month).
[23.05.2025 06:16] Read previous papers.
[23.05.2025 06:16] Get feed.
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16938
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16707
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16410
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14810
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16175
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15966
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16933
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17022
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16916
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15270
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14604
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16990
[23.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.14684
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16864
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17012
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16839
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16181
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14625
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15952
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17018
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16854
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15879
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16151
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16400
[23.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.16186
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15963
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11711
[23.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15517
[23.05.2025 06:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.05.2025 06:16] No deleted papers detected.
[23.05.2025 06:16] Downloading and parsing papers (pdf, html). Total: 28.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16938.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16938.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16938.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16707.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16707.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16707.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16410.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16410.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16410.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.14810.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.14810.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.14810.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16175.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16175.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16175.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.15966.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.15966.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.15966.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16933.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16933.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16933.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.17022.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.17022.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.17022.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16916.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16916.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16916.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.15270.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.15270.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.15270.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.14604.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.14604.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.14604.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16990.
[23.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16990.json), skip PDF parsing.
[23.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16990.json), skip HTML parsing.
[23.05.2025 06:16] Success.
[23.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.14684.
[23.05.2025 06:16] Downloading paper 2505.14684 from http://arxiv.org/pdf/2505.14684v2...
[23.05.2025 06:17] Extracting affiliations from text.
[23.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 2 ] . [ 2 4 8 6 4 1 . 5 0 5 2 : r Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning Haolei Xu1 Yuchen Yan1 Yongliang Shen1 Wenqi Zhang1 Guiyang Hou1 Shengpei Jiang2 Kaitao Song3 Weiming Lu1 Jun Xiao1 Yueting Zhuang 1 Zhejiang University 2 The Chinese University of Hong Kong 3 Microsoft Research Asia {xuhaolei,syl,luwm}@zju.edu.cn Project: https://zju-real.github.io/CoT-Bridge "
[23.05.2025 06:17] Response: ```python
["Zhejiang University", "The Chinese University of Hong Kong", "Microsoft Research Asia"]
```
[23.05.2025 06:17] Deleting PDF ./assets/pdf/2505.14684.pdf.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.16864.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.16864.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.16864.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.17012.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.17012.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.17012.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.16839.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.16839.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.16839.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.16181.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.16181.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.16181.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.14625.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.14625.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.14625.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.15952.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.15952.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.15952.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.17018.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.17018.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.17018.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.16854.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.16854.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.16854.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.15879.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.15879.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.15879.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.16151.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.16151.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.16151.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.16400.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.16400.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.16400.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.16186.
[23.05.2025 06:17] Downloading paper 2505.16186 from http://arxiv.org/pdf/2505.16186v1...
[23.05.2025 06:17] Extracting affiliations from text.
[23.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning Kaiwen Zhou1, Xuandong Zhao2, Gaowen Liu3, Jayanth Srinivasa3, Aosong Feng4, Dawn Song2, Xin Eric Wang1 1UC Santa Cruz 2UC Berkeley 3Cisco Research 4Yale University {kzhou35, xwang366}@ucsc.edu 5 2 0 2 2 2 ] . [ 1 6 8 1 6 1 . 5 0 5 2 : r a "
[23.05.2025 06:17] Response: ```python
["UC Santa Cruz", "UC Berkeley", "Cisco Research", "Yale University"]
```
[23.05.2025 06:17] Deleting PDF ./assets/pdf/2505.16186.pdf.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.15963.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.15963.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.15963.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.11711.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.11711.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.11711.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.15517.
[23.05.2025 06:17] Extra JSON file exists (./assets/json/2505.15517.json), skip PDF parsing.
[23.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.15517.json), skip HTML parsing.
[23.05.2025 06:17] Success.
[23.05.2025 06:17] Enriching papers with extra data.
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 0. Artificial Intelligence (AI) is accelerating the transformation of scientific research paradigms, not only enhancing research efficiency but also driving innovation. We introduce NovelSeek, a unified closed-loop multi-agent framework to conduct Autonomous Scientific Research (ASR) across various sci...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 1. Recent advances in multi-modal generative models have enabled significant progress in instruction-based image editing. However, while these models produce visually plausible outputs, their capacity for knowledge-based reasoning editing tasks remains under-explored. In this paper, we introduce KRIS-B...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 2. Tool-Star, an RL-based framework, enables LLMs to autonomously use multiple tools for stepwise reasoning, leveraging data synthesis and hierarchical reward design.  					AI-generated summary 				 Recently, large language models (LLMs) have shown remarkable reasoning capabilities via large-scale rein...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 3. An empirical analysis of MathIF identifies a tension between enhancing reasoning capacity and maintaining instruction adherence in large language models.  					AI-generated summary 				 Instruction-following is essential for aligning large language models (LLMs) with user intent. While recent reason...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 4. QuickVideo accelerates long-video understanding by combining a parallelized video decoder, memory-efficient prefilling, and overlapping video decoding with inference, enabling real-time performance.  					AI-generated summary 				 Long-video understanding has emerged as a crucial capability in real-...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 5. Introducing pixel-space reasoning in Vision-Language Models (VLMs) through visual operations like zoom-in and select-frame enhances their performance on visual tasks.  					AI-generated summary 				 Chain-of-thought reasoning has significantly improved the performance of Large Language Models (LLMs)...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 6. A diffusion-based Multimodal Large Language Model (LLaDA-V) with integrated visual instruction tuning performs competitively on multimodal tasks and outperforms existing models in multimodal understanding.  					AI-generated summary 				 In this work, we introduce LLaDA-V, a purely diffusion-based M...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 7. GoT-R1 enhances visual generation by using reinforcement learning to improve semantic-spatial reasoning, outperforming existing models on complex compositional tasks.  					AI-generated summary 				 Visual generation models have made remarkable progress in creating realistic images from text prompts...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 8. Multimodal Large Language Models (MLLMs) are increasingly deployed in fine-tuning-as-a-service (FTaaS) settings, where user-submitted datasets adapt general-purpose models to downstream tasks. This flexibility, however, introduces serious security risks, as malicious fine-tuning can implant backdoor...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 9. Maximal Update Parametrization (μP) is extended to diffusion Transformers, demonstrating efficient hyperparameter transferability and reduced tuning costs across various models and tasks.  					AI-generated summary 				 Diffusion Transformers have emerged as the foundation for vision generative mode...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 10. A novel Self-Braking Tuning framework reduces overthinking and unnecessary computational overhead in large reasoning models by enabling the model to self-regulate its reasoning process.  					AI-generated summary 				 Large reasoning models (LRMs), such as OpenAI o1 and DeepSeek-R1, have significant...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 11. Dimple, a Discrete Diffusion Multimodal Large Language Model, achieves performance comparable to autoregressive models through a hybrid training approach and enhances inference efficiency with confident decoding and structure priors.  					AI-generated summary 				 In this work, we propose Dimple, t...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 12. A model for detecting and generating missing intermediate steps in mathematical Chain-of-Thought reasoning improves performance and generalization on mathematical and logical reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) have achieved remarkable progress on mathematic...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 13. Jenga, a novel inference pipeline for video Diffusion Transformer models, combines dynamic attention carving and progressive resolution generation to significantly speed up video generation while maintaining high quality.  					AI-generated summary 				 Despite the remarkable generation quality of v...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 14. SpatialScore benchmarks multimodal large language models for 3D spatial understanding, revealing challenges and showcasing the effectiveness of SpatialAgent with specialized tools.  					AI-generated summary 				 Multimodal large language models (MLLMs) have achieved impressive success in question-a...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 15. LaViDa, a family of vision-language models built on discrete diffusion models, offers competitive performance on multimodal benchmarks with advantages in speed, controllability, and bidirectional reasoning.  					AI-generated summary 				 Modern Vision-Language Models (VLMs) can solve a wide range o...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 16. Analysis of 83k image editing requests reveals that AI editors, including GPT-4o, struggle with low-creativity tasks and precise editing, while performing better on open-ended tasks, and human and VLM judges differ in their preferences for AI versus human edits.  					AI-generated summary 				 Gener...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 17. Reinforcement Learning (RL) has become a powerful tool for enhancing the reasoning abilities of large language models (LLMs) by optimizing their policies with reward signals. Yet, RL's success relies on the reliability of rewards, which are provided by verifiers. In this paper, we expose and analyze...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 18. A benchmark called VideoGameQA-Bench is introduced to assess Vision-Language Models in video game quality assurance tasks.  					AI-generated summary 				 With video games now generating the highest revenues in the entertainment industry, optimizing game development workflows has become essential fo...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 19. An enhanced multimodal language model incorporates thinking process rewards to improve reasoning and generalization, achieving superior performance on benchmarks compared to larger models.  					AI-generated summary 				 Recent advances have shown success in eliciting strong reasoning abilities in m...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 20. TON, a two-stage training strategy combining supervised fine-tuning with thought dropout and Group Relative Policy Optimization, reduces unnecessary reasoning steps in vision-language models without sacrificing performance.  					AI-generated summary 				 Reinforcement Learning (RL) has proven to be...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 21. Recent studies have demonstrated the efficacy of using Reinforcement Learning (RL) in building reasoning models that articulate chains of thoughts prior to producing final answers. However, despite ongoing advances that aim at enabling reasoning for vision-language tasks, existing open-source visual...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 22. The FRANK Model enhances multimodal LLMs with reasoning and reflection abilities without retraining, using a hierarchical weight merging approach that merges visual-pretrained and reasoning-specialized models.  					AI-generated summary 				 Recent advances in Reasoning LLMs (e.g., DeepSeek-R1 and O...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 23. Large-scale reinforcement learning enhances reasoning capabilities in small and mid-sized models more effectively than distillation, achieving superior results in both math and code benchmarks.  					AI-generated summary 				 Despite recent progress in large-scale reinforcement learning (RL) for rea...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 24. SafeKey enhances the safety of large reasoning models by focusing on activating a safety aha moment in the key sentence through dual-path safety head and query-mask modeling, thereby improving generalization to harmful prompts.  					AI-generated summary 				 Large Reasoning Models (LRMs) introduce ...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 25. Large vision-language models (LVLMs) remain vulnerable to hallucination, often generating content misaligned with visual inputs. While recent approaches advance multi-modal Direct Preference Optimization (DPO) to mitigate hallucination, they typically rely on predefined or randomly edited negative s...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 26. Reinforcement learning improves large language models with minimal parameter updates, affecting only a small subnetwork without explicit sparsity techniques.  					AI-generated summary 				 Reinforcement learning (RL) yields substantial improvements in large language models (LLMs) downstream task pe...
[23.05.2025 06:17] ********************************************************************************
[23.05.2025 06:17] Abstract 27. Robo2VLM, a framework for generating Visual Question Answering datasets using robot trajectory data, enhances and evaluates Vision-Language Models by leveraging sensory modalities and 3D property understanding.  					AI-generated summary 				 Vision-Language Models (VLMs) acquire real-world knowledg...
[23.05.2025 06:17] Read previous papers.
[23.05.2025 06:17] Generating reviews via LLM API.
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#healthcare", "#multimodal", "#agents", "#science"], "emoji": "🧬", "ru": {"title": "NovelSeek: ИИ-ускоритель научных открытий", "desc": "NovelSeek - это унифицированная мультиагентная система для автономных научных исследований в различных областях. Она обладает масштабируемостью, п
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "KRIS-Bench: когнитивная оценка моделей редактирования изображений", "desc": "Статья представляет KRIS-Bench - диагностический бенчмарк для оценки моделей редактирования изображений с точки зрения когнитивных с
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#training", "#dataset", "#benchmark", "#rl", "#optimization"], "emoji": "🛠️", "ru": {"title": "Tool-Star: Автономное мультиинструментальное рассуждение для больших языковых моделей", "desc": "Tool-Star - это фреймворк на основе обучения с подкреплением, который позволя
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#math", "#reasoning", "#training", "#benchmark", "#optimization", "#alignment"], "emoji": "🤖", "ru": {"title": "Баланс между разумом и послушанием в ИИ", "desc": "Исследование MathIF выявляет противоречие между улучшением способности к рассуждению и сохранением следования инструкция
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#inference", "#optimization", "#video", "#long_context"], "emoji": "🚀", "ru": {"title": "Ускорение анализа длинных видео с помощью QuickVideo", "desc": "QuickVideo - это система, ускоряющая понимание длинных видео для приложений реального времени. Она использует параллельный декодер
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#cv", "#rl", "#optimization", "#benchmark", "#open_source", "#training"], "emoji": "🔍", "ru": {"title": "Рассуждения в пикселях: новый уровень понимания изображений для ИИ", "desc": "Статья представляет новый подход к улучшению работы моделей компьютерно
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#architecture"], "emoji": "🧠", "ru": {"title": "Диффузионная мультимодальная ИИ-модель превосходит аналоги в понимании текста и изображений", "desc": "В статье представлена модель LLaDA-V - мультимодальная большая языковая модель на основе диффузии, инте
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#rl", "#multimodal", "#open_source", "#cv", "#reasoning"], "emoji": "🧠", "ru": {"title": "Умное рассуждение для умной генерации изображений", "desc": "GoT-R1 - это фреймворк, использующий обучение с подкреплением для улучшения семантико-пространственны
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#data", "#training", "#dataset", "#security"], "emoji": "🛡️", "ru": {"title": "Защита мультимодальных ИИ от скрытых угроз: доверяй своим глазам", "desc": "Статья посвящена проблеме безопасности мультимодальных больших языковых моделей (MLLM) в контексте дообучения на 
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#architecture", "#training", "#transfer_learning", "#diffusion", "#optimization"], "emoji": "🔬", "ru": {"title": "μP: Эффективное масштабирование диффузионных трансформеров", "desc": "Статья описывает расширение метода Maximal Update Parametrization (μP) для диффузионных трансформер
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#training", "#math", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "Самоконтроль ИИ: эффективное мышление без лишних раздумий", "desc": "Представлена новая система Self-Braking Tuning для крупных моделей рассуждений, позволяющая им самостоятельно регулировать процесс
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#inference", "#diffusion", "#optimization", "#open_source", "#architecture", "#training"], "emoji": "🧠", "ru": {"title": "Dimple: Дискретная диффузия для эффективных и контролируемых языковых моделей", "desc": "Dimple - это первая дискретная диффузионная мультимодальн
[23.05.2025 06:17] Querying the API.
[23.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A model for detecting and generating missing intermediate steps in mathematical Chain-of-Thought reasoning improves performance and generalization on mathematical and logical reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) have achieved remarkable progress on mathematical tasks through Chain-of-Thought (CoT) reasoning. However, existing mathematical CoT datasets often suffer from Thought Leaps due to experts omitting intermediate steps, which negatively impacts model learning and generalization. We propose the CoT Thought Leap Bridge Task, which aims to automatically detect leaps and generate missing intermediate reasoning steps to restore the completeness and coherence of CoT. To facilitate this, we constructed a specialized training dataset called ScaleQM+, based on the structured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought leaps. Through comprehensive experiments on mathematical reasoning benchmarks, we demonstrate that models fine-tuned on bridged datasets consistently outperform those trained on original datasets, with improvements of up to +5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%) and provides better starting points for reinforcement learning (+3.1%), functioning as a plug-and-play module compatible with existing optimization techniques. Furthermore, CoT-Bridge demonstrate improved generalization to out-of-domain logical reasoning tasks, confirming that enhancing reasoning completeness yields broadly applicable benefits.
[23.05.2025 06:17] Response: {
  "desc": "Эта статья представляет модель для обнаружения и генерации пропущенных промежуточных шагов в математических рассуждениях с использованием метода цепочки мыслей (Chain-of-Thought, CoT). Авторы предлагают задачу CoT Thought Leap Bridge для автоматического обнаружения пропусков и генерации недостающих шагов рассуждения. Они создали специализированный набор данных ScaleQM+ и обучили модель CoT-Bridge для восстановления полноты и связности рассуждений. Эксперименты показали, что модели, дообученные на дополненных наборах данных, превосходят модели, обученные на исходных данных, улучшая производительность и обобщающую способность на задачах математического и логического мышления.",
  "emoji": "🧠",
  "title": "Мост через пропасть в цепочке мыслей: улучшение математических рассуждений ИИ"
}
[23.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A model for detecting and generating missing intermediate steps in mathematical Chain-of-Thought reasoning improves performance and generalization on mathematical and logical reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) have achieved remarkable progress on mathematical tasks through Chain-of-Thought (CoT) reasoning. However, existing mathematical CoT datasets often suffer from Thought Leaps due to experts omitting intermediate steps, which negatively impacts model learning and generalization. We propose the CoT Thought Leap Bridge Task, which aims to automatically detect leaps and generate missing intermediate reasoning steps to restore the completeness and coherence of CoT. To facilitate this, we constructed a specialized training dataset called ScaleQM+, based on the structured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought leaps. Through comprehensive experiments on mathematical reasoning benchmarks, we demonstrate that models fine-tuned on bridged datasets consistently outperform those trained on original datasets, with improvements of up to +5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%) and provides better starting points for reinforcement learning (+3.1%), functioning as a plug-and-play module compatible with existing optimization techniques. Furthermore, CoT-Bridge demonstrate improved generalization to out-of-domain logical reasoning tasks, confirming that enhancing reasoning completeness yields broadly applicable benefits."

[23.05.2025 06:17] Response: ```python
['DATASET', 'DATA', 'MATH', 'TRAINING']
```
[23.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A model for detecting and generating missing intermediate steps in mathematical Chain-of-Thought reasoning improves performance and generalization on mathematical and logical reasoning tasks.  					AI-generated summary 				 Large language models (LLMs) have achieved remarkable progress on mathematical tasks through Chain-of-Thought (CoT) reasoning. However, existing mathematical CoT datasets often suffer from Thought Leaps due to experts omitting intermediate steps, which negatively impacts model learning and generalization. We propose the CoT Thought Leap Bridge Task, which aims to automatically detect leaps and generate missing intermediate reasoning steps to restore the completeness and coherence of CoT. To facilitate this, we constructed a specialized training dataset called ScaleQM+, based on the structured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought leaps. Through comprehensive experiments on mathematical reasoning benchmarks, we demonstrate that models fine-tuned on bridged datasets consistently outperform those trained on original datasets, with improvements of up to +5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%) and provides better starting points for reinforcement learning (+3.1%), functioning as a plug-and-play module compatible with existing optimization techniques. Furthermore, CoT-Bridge demonstrate improved generalization to out-of-domain logical reasoning tasks, confirming that enhancing reasoning completeness yields broadly applicable benefits."

[23.05.2025 06:17] Response: ```python
['REASONING', 'OPTIMIZATION']
```
[23.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a model designed to detect and fill in missing steps in Chain-of-Thought (CoT) reasoning for mathematical tasks. The authors identify a problem where existing datasets have gaps, known as Thought Leaps, which hinder the learning process of large language models (LLMs). To address this, they propose the CoT Thought Leap Bridge Task and create a new training dataset called ScaleQM+ to help models learn to generate the missing reasoning steps. Their experiments show that models trained with this approach significantly outperform those trained on incomplete datasets, leading to better performance in both mathematical and logical reasoning tasks.","title":"Bridging Thought Leaps for Enhanced Reasoning in AI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a model designed to detect and fill in missing steps in Chain-of-Thought (CoT) reasoning for mathematical tasks. The authors identify a problem where existing datasets have gaps, known as Thought Leaps, which hinder the learning process of large language models (LLMs). To address this, they propose the CoT Thought Leap Bridge Task and create a new training dataset called ScaleQM+ to help models learn to generate the missing reasoning steps. Their experiments show that models trained with this approach significantly outperform those trained on incomplete datasets, leading to better performance in both mathematical and logical reasoning tasks.', title='Bridging Thought Leaps for Enhanced Reasoning in AI'))
[23.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种模型，用于检测和生成数学推理中的缺失中间步骤，从而提高模型在数学和逻辑推理任务上的表现和泛化能力。现有的数学链式推理数据集常常因为专家省略中间步骤而导致思维跳跃，这对模型的学习和泛化产生负面影响。我们提出了链式推理思维跳跃桥接任务，旨在自动检测思维跳跃并生成缺失的中间推理步骤，以恢复推理的完整性和连贯性。通过构建专门的训练数据集ScaleQM+并进行实验，我们证明了在桥接数据集上微调的模型在数学推理基准测试中表现优于原始数据集，且在逻辑推理任务上也显示出更好的泛化能力。","title":"填补思维跳跃，提升推理能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种模型，用于检测和生成数学推理中的缺失中间步骤，从而提高模型在数学和逻辑推理任务上的表现和泛化能力。现有的数学链式推理数据集常常因为专家省略中间步骤而导致思维跳跃，这对模型的学习和泛化产生负面影响。我们提出了链式推理思维跳跃桥接任务，旨在自动检测思维跳跃并生成缺失的中间推理步骤，以恢复推理的完整性和连贯性。通过构建专门的训练数据集ScaleQM+并进行实验，我们证明了在桥接数据集上微调的模型在数学推理基准测试中表现优于原始数据集，且在逻辑推理任务上也显示出更好的泛化能力。', title='填补思维跳跃，提升推理能力'))
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#video", "#inference", "#diffusion", "#optimization"], "emoji": "🧩", "ru": {"title": "Ускорение генерации видео без потери качества", "desc": "Jenga - это новый конвейер вывода для моделей видео-диффузионных трансформеров, который сочетает динамическое вырезание внимания и прогресси
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#survey", "#3d", "#benchmark", "#agents"], "emoji": "🧠", "ru": {"title": "SpatialScore: новый рубеж в пространственном понимании для мультимодальных ИИ", "desc": "Статья представляет SpatialScore - комплексный бенчмарк для оценки пространственного понима
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#architecture", "#training", "#games", "#cv", "#diffusion"], "emoji": "🧠", "ru": {"title": "LaViDa: Быстрые и гибкие мультимодальные модели на основе дискретной диффузии", "desc": "LaViDa - это семейство мультимодальных моделей, основанных на дискретных диффузионных м
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#games", "#dataset", "#cv", "#optimization", "#interpretability"], "emoji": "🖼️", "ru": {"title": "ИИ в фоторедактировании: креативность vs точность", "desc": "Анализ 83 тысяч запросов на редактирование изображений показывает, что ИИ-редакторы, включая GPT-4o, испытыв
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#rlhf", "#reasoning", "#training", "#dataset", "#rl", "#optimization"], "emoji": "🔍", "ru": {"title": "Борьба с ложноотрицательными результатами для улучшения RL-обучения языковых моделей", "desc": "В этой статье исследуется проблема ложноотрицательных результатов в верификаторах, и
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#games", "#cv", "#video", "#optimization", "#benchmark"], "emoji": "🎮", "ru": {"title": "VideoGameQA-Bench: Революция в автоматизации контроля качества видеоигр", "desc": "Представлен новый бенчмарк VideoGameQA-Bench для оценки визуально-языковых моделей в задачах контроля качества 
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#rlhf", "#rl", "#optimization", "#benchmark", "#open_source", "#training"], "emoji": "🧠", "ru": {"title": "Улучшение мышления ИИ через вознаграждение за процесс рассуждений", "desc": "Исследователи предложили улучшенную мультимодальную языковую модель So
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Эффективное обучение ИИ рассуждать как человек", "desc": "Статья представляет стратегию обучения TON для улучшения рассуждений в мультимодальных моделях на основе компьютерного зрения и обработки естес
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#rl", "#open_source", "#training"], "emoji": "🧠", "ru": {"title": "GRIT: Визуальное обоснование рассуждений для мультимодальных языковых моделей", "desc": "Статья представляет новый метод обучения мультимодальных языковых моделей (MLLM) под названием GRI
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "FRANK: Мультимодальное рассуждение без переобучения", "desc": "Модель FRANK улучшает мультимодальные языковые модели (MLLM), добавляя им способности к рассуждению и рефлексии без переобучения.
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#rl", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Обучение с подкреплением раскрывает скрытый потенциал малых моделей", "desc": "Исследование показывает, что крупномасштабное обучение с подкреплением (RL) значительно улучшает способности к
[23.05.2025 06:17] Querying the API.
[23.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SafeKey enhances the safety of large reasoning models by focusing on activating a safety aha moment in the key sentence through dual-path safety head and query-mask modeling, thereby improving generalization to harmful prompts.  					AI-generated summary 				 Large Reasoning Models (LRMs) introduce a new generation paradigm of explicitly reasoning before answering, leading to remarkable improvements in complex tasks. However, they pose great safety risks against harmful queries and adversarial attacks. While recent mainstream safety efforts on LRMs, supervised fine-tuning (SFT), improve safety performance, we find that SFT-aligned models struggle to generalize to unseen jailbreak prompts. After thorough investigation of LRMs' generation, we identify a safety aha moment that can activate safety reasoning and lead to a safe response. This aha moment typically appears in the `key sentence', which follows models' query understanding process and can indicate whether the model will proceed safely. Based on these insights, we propose SafeKey, including two complementary objectives to better activate the safety aha moment in the key sentence: (1) a Dual-Path Safety Head to enhance the safety signal in the model's internal representations before the key sentence, and (2) a Query-Mask Modeling objective to improve the models' attention on its query understanding, which has important safety hints. Experiments across multiple safety benchmarks demonstrate that our methods significantly improve safety generalization to a wide range of jailbreak attacks and out-of-distribution harmful prompts, lowering the average harmfulness rate by 9.6\%, while maintaining general abilities. Our analysis reveals how SafeKey enhances safety by reshaping internal attention and improving the quality of hidden representations.
[23.05.2025 06:17] Response: {
  "desc": "Статья представляет метод SafeKey для повышения безопасности крупных моделей рассуждений (LRM). Метод фокусируется на активации 'момента озарения' в ключевом предложении с помощью двухпутевой головки безопасности и моделирования маскировки запроса. SafeKey улучшает генерализацию моделей на вредоносные запросы и атаки. Эксперименты показывают значительное повышение безопасности при сохранении общих способностей модели.",
  "emoji": "🛡️",
  "title": "SafeKey: Активация безопасности в ключевой момент рассуждений ИИ"
}
[23.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SafeKey enhances the safety of large reasoning models by focusing on activating a safety aha moment in the key sentence through dual-path safety head and query-mask modeling, thereby improving generalization to harmful prompts.  					AI-generated summary 				 Large Reasoning Models (LRMs) introduce a new generation paradigm of explicitly reasoning before answering, leading to remarkable improvements in complex tasks. However, they pose great safety risks against harmful queries and adversarial attacks. While recent mainstream safety efforts on LRMs, supervised fine-tuning (SFT), improve safety performance, we find that SFT-aligned models struggle to generalize to unseen jailbreak prompts. After thorough investigation of LRMs' generation, we identify a safety aha moment that can activate safety reasoning and lead to a safe response. This aha moment typically appears in the `key sentence', which follows models' query understanding process and can indicate whether the model will proceed safely. Based on these insights, we propose SafeKey, including two complementary objectives to better activate the safety aha moment in the key sentence: (1) a Dual-Path Safety Head to enhance the safety signal in the model's internal representations before the key sentence, and (2) a Query-Mask Modeling objective to improve the models' attention on its query understanding, which has important safety hints. Experiments across multiple safety benchmarks demonstrate that our methods significantly improve safety generalization to a wide range of jailbreak attacks and out-of-distribution harmful prompts, lowering the average harmfulness rate by 9.6\%, while maintaining general abilities. Our analysis reveals how SafeKey enhances safety by reshaping internal attention and improving the quality of hidden representations."

[23.05.2025 06:17] Response: ```python
["TRAINING", "BENCHMARK", "ARCHITECTURE"]
```
[23.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SafeKey enhances the safety of large reasoning models by focusing on activating a safety aha moment in the key sentence through dual-path safety head and query-mask modeling, thereby improving generalization to harmful prompts.  					AI-generated summary 				 Large Reasoning Models (LRMs) introduce a new generation paradigm of explicitly reasoning before answering, leading to remarkable improvements in complex tasks. However, they pose great safety risks against harmful queries and adversarial attacks. While recent mainstream safety efforts on LRMs, supervised fine-tuning (SFT), improve safety performance, we find that SFT-aligned models struggle to generalize to unseen jailbreak prompts. After thorough investigation of LRMs' generation, we identify a safety aha moment that can activate safety reasoning and lead to a safe response. This aha moment typically appears in the `key sentence', which follows models' query understanding process and can indicate whether the model will proceed safely. Based on these insights, we propose SafeKey, including two complementary objectives to better activate the safety aha moment in the key sentence: (1) a Dual-Path Safety Head to enhance the safety signal in the model's internal representations before the key sentence, and (2) a Query-Mask Modeling objective to improve the models' attention on its query understanding, which has important safety hints. Experiments across multiple safety benchmarks demonstrate that our methods significantly improve safety generalization to a wide range of jailbreak attacks and out-of-distribution harmful prompts, lowering the average harmfulness rate by 9.6\%, while maintaining general abilities. Our analysis reveals how SafeKey enhances safety by reshaping internal attention and improving the quality of hidden representations."

[23.05.2025 06:17] Response: ```python
['SECURITY', 'REASONING']
```
[23.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SafeKey is a method designed to improve the safety of large reasoning models (LRMs) by focusing on a critical moment in the model\'s reasoning process, known as the safety aha moment. This moment occurs in the key sentence, which helps the model determine whether it can respond safely to a query. SafeKey employs a Dual-Path Safety Head to strengthen the safety signals in the model\'s internal representations and a Query-Mask Modeling approach to enhance the model\'s attention to safety-related aspects of the query. Through experiments, SafeKey has shown to significantly reduce the risk of harmful responses while preserving the model\'s overall performance.","title":"Activating Safety Moments in Large Reasoning Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="SafeKey is a method designed to improve the safety of large reasoning models (LRMs) by focusing on a critical moment in the model's reasoning process, known as the safety aha moment. This moment occurs in the key sentence, which helps the model determine whether it can respond safely to a query. SafeKey employs a Dual-Path Safety Head to strengthen the safety signals in the model's internal representations and a Query-Mask Modeling approach to enhance the model's attention to safety-related aspects of the query. Through experiments, SafeKey has shown to significantly reduce the risk of harmful responses while preserving the model's overall performance.", title='Activating Safety Moments in Large Reasoning Models'))
[23.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SafeKey通过激活关键句中的安全时刻来增强大型推理模型的安全性。它采用双路径安全头和查询掩码建模，旨在提高模型对有害提示的泛化能力。研究发现，关键句中的安全时刻能够引导模型做出安全的响应。实验结果表明，SafeKey显著降低了模型在各种攻击下的有害性，同时保持了其一般能力。","title":"SafeKey：激活安全时刻，提升推理模型安全性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SafeKey通过激活关键句中的安全时刻来增强大型推理模型的安全性。它采用双路径安全头和查询掩码建模，旨在提高模型对有害提示的泛化能力。研究发现，关键句中的安全时刻能够引导模型做出安全的响应。实验结果表明，SafeKey显著降低了模型在各种攻击下的有害性，同时保持了其一般能力。', title='SafeKey：激活安全时刻，提升推理模型安全性'))
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#training", "#hallucinations", "#benchmark", "#diffusion", "#rag", "#alignment"], "emoji": "🔮", "ru": {"title": "OViP: Обучение без галлюцинаций для визуально-языковых моделей", "desc": "Статья представляет новый подход к обучению мультимодальных моделей, называемый O
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#rlhf", "#training", "#rl", "#optimization", "#alignment"], "emoji": "🧠", "ru": {"title": "Эффективное обучение языковых моделей: меньше параметров, больше результат", "desc": "Это исследование показывает, что методы обучения с подкреплением (RL) значительно улучшают производительно
[23.05.2025 06:17] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#games", "#dataset", "#3d", "#reasoning"], "emoji": "🤖", "ru": {"title": "Роботы учат ИИ видеть и понимать мир", "desc": "Robo2VLM - это фреймворк для создания наборов данных визуальных вопросов и ответов на основе траекторий робота. Он использует сенсор
[23.05.2025 06:17] Loading Chinese text from previous data.
[23.05.2025 06:17] Renaming data file.
[23.05.2025 06:17] Renaming previous data. hf_papers.json to ./d/2025-05-23.json
[23.05.2025 06:17] Saving new data file.
[23.05.2025 06:17] Generating page.
[23.05.2025 06:17] Renaming previous page.
[23.05.2025 06:17] Renaming previous data. index.html to ./d/2025-05-23.html
[23.05.2025 06:17] [Experimental] Generating Chinese page for reading.
[23.05.2025 06:17] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '网页导航', 'pinyin': 'wǎng yè dǎo háng', 'trans': 'web navigation'}, {'word': '自动化', 'pinyin': 'zì dòng huà', 'trans': 'automation'}, {'word': '任务', 'pinyin': 'rèn wu', 'trans': 'task'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '奖励模型', 'pinyin': 'jiǎng lì mó xíng', 'trans': 'reward model'}, {'word': '限制', 'pinyin': 'xiàn zhì', 'trans': 'limit'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '过程奖励模型', 'pinyin': 'guò chéng jiǎng lì mó xíng', 'trans': 'process reward model'}, {'word': '逐步', 'pinyin': 'zhuó bù', 'trans': 'step-by-step'}, {'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluate'}, {'word': '路径', 'pinyin': 'lù jìng', 'trans': 'path'}, {'word': '创建', 'pinyin': 'chuàng jiàn', 'trans': 'create'}, {'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'}, {'word': '评估基准', 'pinyin': 'píng gū jī zhǔn', 'trans': 'evaluation benchmark'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '证明', 'pinyin': 'zhèng míng', 'trans': 'prove'}, {'word': '有效性', 'pinyin': 'yǒu xiào xìng', 'trans': 'effectiveness'}, {'word': '成本效益', 'pinyin': 'chéng běn xiào yì', 'trans': 'cost-effectiveness'}, {'word': '公开可用', 'pinyin': 'gōng kāi kě yòng', 'trans': 'publicly available'}]
[23.05.2025 06:17] Renaming previous Chinese page.
[23.05.2025 06:17] Renaming previous data. zh.html to ./d/2025-05-22_zh_reading_task.html
[23.05.2025 06:17] Writing Chinese reading task.
[23.05.2025 06:17] Writing result.
[23.05.2025 06:17] Renaming log file.
[23.05.2025 06:17] Renaming previous data. log.txt to ./logs/2025-05-23_last_log.txt
