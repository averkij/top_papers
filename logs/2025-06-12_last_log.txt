[12.06.2025 11:13] Read previous papers.
[12.06.2025 11:13] Generating top page (month).
[12.06.2025 11:13] Writing top page (month).
[12.06.2025 12:22] Read previous papers.
[12.06.2025 12:22] Get feed.
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06395
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09113
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09995
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09350
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09790
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08889
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09003
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09984
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09937
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08001
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08900
[12.06.2025 12:22] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09007
[12.06.2025 12:22] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[12.06.2025 12:22] No deleted papers detected.
[12.06.2025 12:22] Downloading and parsing papers (pdf, html). Total: 12.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.06395.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.06395.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.06395.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09113.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09113.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09113.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09995.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09995.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09995.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09350.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09350.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09350.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09790.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09790.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09790.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.08889.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.08889.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.08889.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09003.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09003.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09003.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09984.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09984.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09984.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09937.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09937.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09937.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.08001.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.08001.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.08001.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.08900.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.08900.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.08900.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Downloading and parsing paper https://huggingface.co/papers/2506.09007.
[12.06.2025 12:22] Extra JSON file exists (./assets/json/2506.09007.json), skip PDF parsing.
[12.06.2025 12:22] Paper image links file exists (./assets/img_data/2506.09007.json), skip HTML parsing.
[12.06.2025 12:22] Success.
[12.06.2025 12:22] Enriching papers with extra data.
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 0. Reinforcement Learning via Self-Confidence (RLSC) improves large language model accuracy using the model's confidence as a reward signal, eliminating the need for human labels or reward engineering.  					AI-generated summary 				 Large language models (LLMs) excel at reasoning, yet post-training re...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 1. Seedance 1.0 offers high-performance video generation by integrating advanced data curation, efficient architecture, post-training optimization, and model acceleration, resulting in superior quality and speed.  					AI-generated summary 				 Notable breakthroughs in diffusion modeling have propelled...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 2. PlayerOne is an egocentric realistic world simulator that constructs and generates videos from user-captured images, using a coarse-to-fine training pipeline and advanced motion injection and reconstruction frameworks.  					AI-generated summary 				 We introduce PlayerOne, the first egocentric real...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 3. Autoregressive adversarial post-training transforms pre-trained latent video diffusion models into real-time, interactive video generators with reduced computational requirements.  					AI-generated summary 				 Existing large-scale video generation models are computationally intensive, preventing a...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 4. ComfyUI-R1, a large reasoning model for automated workflow generation, demonstrates superior performance in creating AI art workflows through long chain-of-thought reasoning and reinforcement learning.  					AI-generated summary 				 AI-generated content has evolved from monolithic models to modular...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 5. SeerAttention-R is a sparse attention framework for reasoning models that maintains high accuracy and achieves significant speedups through optimized sparse decoding kernels.  					AI-generated summary 				 We introduce SeerAttention-R, a sparse attention framework specifically tailored for the long...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 6. A novel data synthesis framework, SWE-Flow, uses unit tests to automatically infer development steps and generate a structured schedule for Test-Driven Development (TDD), significantly improving the performance of open models fine-tuned on real-world projects.  					AI-generated summary 				 We intr...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 7. A novel framework for end-to-end human animation with multi-modal conditions enables high-quality video generation through explicit layout control and region-specific modality matching.  					AI-generated summary 				 End-to-end human animation with rich multi-modal conditions, e.g., text, image and...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 8. SAFE is a failure detector for vision-language-action models that generalizes to unseen tasks by learning from high-level internal features of the models.  					AI-generated summary 				 While vision-language-action models (VLAs) have shown promising robotic behaviors across a diverse set of manipul...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 9. A new reParameterized training algorithm named POET uses Orthogonal Equivalence Transformation to optimize neurons, providing stable optimization and improved generalization for training large-scale neural networks including LLMs.  					AI-generated summary 				 While large language models (LLMs) ar...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 10. MIRAGE, a multimodal foundation model, excels in OCT and SLO image classification and segmentation, outperforming existing general and specialized models.  					AI-generated summary 				 Artificial intelligence (AI) has become a fundamental tool for assisting clinicians in analyzing ophthalmic image...
[12.06.2025 12:22] ********************************************************************************
[12.06.2025 12:22] Abstract 11. BranchSBM, a novel generative modeling framework, extends Schr\"odinger Bridge Matching to model branched stochastic paths and multi-path evolution from a single initial distribution to multiple outcomes.  					AI-generated summary 				 Predicting the intermediate trajectories between an initial and...
[12.06.2025 12:22] Read previous papers.
[12.06.2025 12:22] Generating reviews via LLM API.
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#reasoning", "#optimization", "#inference", "#training", "#alignment"], "emoji": "üß†", "ru": {"title": "–°–∞–º–æ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∫–∞–∫ –∫–ª—é—á –∫ –æ–±—É—á–µ–Ω–∏—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ú–µ—Ç–æ–¥ Reinforcement Learning via Self-Confidence (RLSC) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–∏–≥
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#video", "#dataset", "#optimization", "#architecture", "#benchmark", "#data", "#training", "#rlhf", "#diffusion", "#inference"], "emoji": "üé¨", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: –±—ã—Å—Ç—Ä–æ, –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ, –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ", "desc": "Seedance 1.0 - —ç—Ç–æ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å 
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#video", "#optimization", "#multimodal", "#training", "#games"], "emoji": "üé•", "ru": {"title": "–ü–æ–≥—Ä—É–∂–µ–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å: —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å–∏–º—É–ª—è—Ü–∏—è –º–∏—Ä–∞ —Å PlayerOne", "desc": "PlayerOne - —ç—Ç–æ –ø–µ—Ä–≤—ã–π —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–∏–π —Å–∏–º—É–ª—è—Ç–æ—Ä —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –º–∏—Ä–∞, —Å–ø–æ—Å–æ–±–Ω—ã–π –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ 
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#diffusion", "#training", "#optimization", "#video", "#architecture"], "emoji": "üé¨", "ru": {"title": "–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–æ–º–æ—â—å—é AAPT", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ –∞–≤—Ç–æ—Ä–µgressiv–Ω–æ–≥–æ adversarial post-training (AAPT) –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#rl", "#dataset", "#optimization", "#architecture", "#reasoning", "#training", "#long_context"], "emoji": "üé®", "ru": {"title": "ComfyUI-R1: –ò–ò-—Ö—É–¥–æ–∂–Ω–∏–∫ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "ComfyUI-R1 - —ç—Ç–æ –∫—Ä—É–ø–Ω–∞—è –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –≤ —Å—Ñ–µ
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#benchmark", "#reasoning", "#training", "#long_context"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "SeerAttention-R - —ç—Ç–æ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ö—Ä–∞–Ω—è–µ
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#benchmark", "#data", "#training", "#synthetic"], "emoji": "üß™", "ru": {"title": "SWE-Flow: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è TDD –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ò–ò-–º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏", "desc": "SWE-Flow - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–∞
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#multimodal", "#video", "#games", "#diffusion"], "emoji": "üé≠", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ª—é–¥–µ–π —Å —Ç–æ—á–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –ª—é–¥–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π. –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≥–µ
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#security", "#optimization", "#agents", "#robotics", "#agi"], "emoji": "ü§ñ", "ru": {"title": "SAFE: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –æ—à–∏–±–æ–∫ –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤-–≥–µ–Ω–µ—Ä–∞–ª–∏—Å—Ç–æ–≤", "desc": "SAFE - —ç—Ç–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä –æ—à–∏–±–æ–∫ –¥–ª—è –º–æ–¥–µ–ª–µ–π –∑—Ä–µ–Ω–∏—è-—è–∑—ã–∫–∞-–¥–µ–π—Å—Ç–≤–∏—è (VLA), –∫–æ—Ç–æ—Ä—ã–π –æ–±–æ–±—â–∞–µ—Ç—Å—è –Ω–∞ –Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏, –æ–±—É—á–∞—è—Å—å –Ω–∞ –≤—ã
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "POET: —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "POET - —ç—Ç–æ –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ–ø—Ç–∏–º–∏
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#science", "#open_source", "#cv"], "emoji": "üëÅÔ∏è", "ru": {"title": "MIRAGE: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ò–ò-–∞–Ω–∞–ª–∏–∑–µ –æ—Ñ—Ç–∞–ª—å–º–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "MIRAGE - —ç—Ç–æ –Ω–æ–≤–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å-–æ—Å–Ω–æ–≤–∞ (foundation model) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –û–ö–¢ –∏ –°–õ–û –≤ –æ—Ñ—Ç–∞–ª—å–º–æ–ª–æ
[12.06.2025 12:22] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#dataset", "#data"], "emoji": "üå≥", "ru": {"title": "BranchSBM: –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–Ω—ã—Ö –ø—É—Ç–µ–π –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "BranchSBM - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, —Ä–∞—Å—à–∏—Ä—è—é—â–∞—è –º–µ—Ç–æ–¥ Schr√∂dinger Bridge Matching –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è 
[12.06.2025 12:22] Loading Chinese text from previous data.
[12.06.2025 12:22] Renaming data file.
[12.06.2025 12:22] Renaming previous data. hf_papers.json to ./d/2025-06-12.json
[12.06.2025 12:22] Saving new data file.
[12.06.2025 12:22] Generating page.
[12.06.2025 12:22] Renaming previous page.
[12.06.2025 12:22] Renaming previous data. index.html to ./d/2025-06-12.html
[12.06.2025 12:22] [Experimental] Generating Chinese page for reading.
[12.06.2025 12:22] Chinese vocab [{'word': 'Seedance', 'pinyin': 'Sƒ´d√†ns√¨', 'trans': 'Seedance'}, {'word': 'È´òÊÄßËÉΩ', 'pinyin': 'gƒÅo x√¨ngn√©ng', 'trans': 'high performance'}, {'word': 'ËßÜÈ¢ëÁîüÊàêÊ®°Âûã', 'pinyin': 'sh√¨p√≠n shƒìngch√©ng m√≥x√≠ng', 'trans': 'video generation model'}, {'word': 'ÁªìÂêà', 'pinyin': 'ji√©h√©', 'trans': 'combine'}, {'word': 'ÂÖàËøõ', 'pinyin': 'xiƒÅnj√¨n', 'trans': 'advanced'}, {'word': 'Êï∞ÊçÆÊï¥ÁêÜ', 'pinyin': 'sh√πj√π zhƒõngl«ê', 'trans': 'data processing'}, {'word': 'È´òÊïà', 'pinyin': 'gƒÅoxi√†o', 'trans': 'efficient'}, {'word': 'Êû∂ÊûÑËÆæËÆ°', 'pinyin': 'ji√†g√≤u sh√®j√¨', 'trans': 'architecture design'}, {'word': 'ËÆ≠ÁªÉÂêé‰ºòÂåñ', 'pinyin': 'x√πnli√†n h√≤u y≈çuhu√†', 'trans': 'post-training optimization'}, {'word': 'Ê®°ÂûãÂä†ÈÄü', 'pinyin': 'm√≥x√≠ng jiƒÅs√π', 'trans': 'model acceleration'}, {'word': '1080pÂàÜËæ®Áéá', 'pinyin': '1080p fƒìnbiƒÅnl«ú', 'trans': '1080p resolution'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìngch√©ng', 'trans': 'generate'}, {'word': 'Âè™ÈúÄ', 'pinyin': 'zh«ê x≈´', 'trans': 'only need'}, {'word': 'È°∂Â∞ñ', 'pinyin': 'd«êngjiƒÅn', 'trans': 'top-notch'}, {'word': 'Ë¥®Èáè', 'pinyin': 'zh√¨li√†ng', 'trans': 'quality'}, {'word': 'ÈÄüÂ∫¶', 'pinyin': 's√πd√π', 'trans': 'speed'}, {'word': 'Ë°®Áé∞', 'pinyin': 'bi«éoxi√†n', 'trans': 'performance'}, {'word': 'Âá∫Ëâ≤', 'pinyin': 'ch≈´s√®', 'trans': 'outstanding'}, {'word': '‰ºòË∂ä', 'pinyin': 'y≈çuyu√®', 'trans': 'superior'}, {'word': 'Êó∂Á©∫ÊµÅÁïÖÊÄß', 'pinyin': 'sh√≠k≈çng li√∫ch√†ngx√¨ng', 'trans': 'spatiotemporal smoothness'}, {'word': 'ÁªìÊûÑÁ®≥ÂÆöÊÄß', 'pinyin': 'ji√©g√≤u wƒõnd√¨ngx√¨ng', 'trans': 'structural stability'}]
[12.06.2025 12:22] Renaming previous Chinese page.
[12.06.2025 12:22] Renaming previous data. zh.html to ./d/2025-06-11_zh_reading_task.html
[12.06.2025 12:22] Writing Chinese reading task.
[12.06.2025 12:22] Writing result.
[12.06.2025 12:22] Renaming log file.
[12.06.2025 12:22] Renaming previous data. log.txt to ./logs/2025-06-12_last_log.txt
