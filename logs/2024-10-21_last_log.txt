[21.10.2024 18:16] [Experimental] Generating an image for paper UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models.
[21.10.2024 18:16] [Experimental] Image for paper UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models already exists.
[21.10.2024 18:16] [Experimental] Generating an image for paper Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation.
[21.10.2024 18:16] [Experimental] Image for paper Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation already exists.
[21.10.2024 18:16] [Experimental] Generating an image for paper NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples.
[21.10.2024 18:16] [Experimental] Image for paper NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples already exists.
[21.10.2024 18:16] [Experimental] Generating an image for paper MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models.
[21.10.2024 18:16] [Experimental] Image for paper MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models already exists.
[21.10.2024 20:14] Read previous papers.
[21.10.2024 20:14] Get feed.
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14059
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13232
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14669
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13370
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13276
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13925
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11190
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13674
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14677
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13726
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13782
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.10812
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14470
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13828
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.12791
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14672
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13787
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11331
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14208
[21.10.2024 20:14] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14596
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 0. This paper introduces the UCFE: User-Centric Financial Expertise benchmark, an innovative framework designed to evaluate the ability of large language models (LLMs) to handle complex real-world financial tasks. UCFE benchmark adopts a hybrid approach that combines human expert evaluations with dynam...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 1. Large language models (LLMs) have recently gained much attention in building autonomous agents. However, the performance of current LLM-based web agents in long-horizon tasks is far from optimal, often yielding errors such as repeatedly buying a non-refundable flight ticket. By contrast, humans can ...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 2. Vision-language models (VLMs) have made significant progress in recent visual-question-answering (VQA) benchmarks that evaluate complex visio-linguistic reasoning. However, are these models truly effective? In this work, we show that VLMs still struggle with natural images and questions that humans ...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 3. Recent advancements in text-to-image (T2I) diffusion models have enabled the creation of high-quality images from text prompts, but they still struggle to generate images with precise control over specific visual concepts. Existing approaches can replicate a given concept by learning from reference ...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 4. Attention is the cornerstone of modern Large Language Models (LLMs). Yet its quadratic complexity limits the efficiency and scalability of LLMs, especially for those with a long-context window. A promising approach addressing this limitation is to leverage the sparsity in attention. However, existin...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 5. Nature is infinitely resolution-free. In the context of this reality, existing diffusion models, such as Diffusion Transformers, often face challenges when processing image resolutions outside of their trained domain. To address this limitation, we conceptualize images as sequences of tokens with dy...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 6. GPT-4o, an all-encompassing model, represents a milestone in the development of large multi-modal language models. It can understand visual, auditory, and textual modalities, directly output audio, and support flexible duplex interaction. Models from the open-source community often achieve some func...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 7. Low-quality or scarce data has posed significant challenges for training deep neural networks in practice. While classical data augmentation cannot contribute very different new data, diffusion models opens up a new door to build self-evolving AI by generating high-quality and diverse synthetic data...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 8. The rapid development of autoregressive Large Language Models (LLMs) has significantly improved the quality of generated texts, necessitating reliable machine-generated text detectors. A huge number of detectors and collections with AI fragments have emerged, and several detection methods even showe...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 9. Talking head generation intends to produce vivid and realistic talking head videos from a single portrait and speech audio clip. Although significant progress has been made in diffusion-based talking head generation, almost all methods rely on autoregressive strategies, which suffer from limited con...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 10. Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, a...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 11. We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR) visual generation model capable of directly generating 1024x1024 images, rivaling diffusion models in image generation quality. Existing AR models face limitations due to the poor image reconstruction quality of their disc...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 12. Not all learnable parameters (e.g., weights) contribute equally to a neural network's decision function. In fact, entire layers' parameters can sometimes be reset to random values with little to no impact on the model's decisions. We revisit earlier studies that examined how architecture and task co...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 13. Reinforcement Learning from Human Feedback (RLHF) has become the predominant approach for language model (LM) alignment. At its core, RLHF uses a margin-based loss for preference optimization, specifying ideal LM behavior only by the difference between preferred and dispreferred responses. In this p...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 14. Does the People's Republic of China (PRC) interfere with European elections through ethnic Chinese diaspora media? This question forms the basis of an ongoing research project exploring how PRC narratives about European elections are represented in Chinese diaspora media, and thus the objectives of ...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 15. We introduce BiGR, a novel conditional image generation model using compact binary latent codes for generative training, focusing on enhancing both generation and representation capabilities. BiGR is the first conditional generative model that unifies generation and discrimination within the same fr...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 16. Humans acquire knowledge by observing the external world, but also by introspection. Introspection gives a person privileged access to their current state of mind (e.g., thoughts and feelings) that is not accessible to external observers. Can LLMs introspect? We define introspection as acquiring kno...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 17. We introduce Shakti, a 2.5 billion parameter language model specifically optimized for resource-constrained environments such as edge devices, including smartphones, wearables, and IoT systems. Shakti combines high-performance NLP with optimized efficiency and precision, making it ideal for real-tim...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 18. Synthetic data has been widely used to train large language models, but their generative nature inevitably introduces noisy, non-informative, and misleading learning signals. In this paper, we propose Montessori-Instruct, a novel data synthesis framework that tailors the data synthesis ability of th...
[21.10.2024 20:14] ********************************************************************************
[21.10.2024 20:14] Abstract 19. Large language models (LLMs) are susceptible to persuasion, which can pose risks when models are faced with an adversarial interlocutor. We take a first step towards defending models against persuasion while also arguing that defense against adversarial (i.e. negative) persuasion is only half of the...
[21.10.2024 20:14] Read previous papers.
[21.10.2024 20:14] Generating reviews via LLM API.
[21.10.2024 20:14] Using data from previous issue: {"desc": "Статья представляет UCFE - новый бенчмарк для оценки способности больших языковых моделей (LLM) решать сложные финансовые задачи. Бенчмарк использует гибридный подход, сочетающий оценки экспертов и динамические взаимодействия для симуляции реальных финансовых сценариев. На основе пользоват
[21.10.2024 20:14] Using data from previous issue: {"desc": "Эта статья представляет новый подход к улучшению веб-агентов на основе больших языковых моделей (LLM) путем внедрения 'модели мира'. Авторы обнаружили, что существующие LLM-агенты часто совершают ошибки в задачах с долгосрочными последствиями, например, повторно покупая невозвратные билеты
[21.10.2024 20:14] Using data from previous issue: {"desc": "Исследователи разработали новый бенчмарк NaturalBench для оценки моделей визуально-языкового понимания (VLM) на основе естественных изображений и вопросов. Бенчмарк содержит 10 000 проверенных человеком образцов задач визуального ответа на вопросы (VQA), которые требуют разнообразных навык
[21.10.2024 20:14] Using data from previous issue: {"desc": "Эта статья представляет новый подход к персонализации генерации изображений с помощью текстовых запросов. Авторы предлагают метод MagicTailor, который позволяет пользователям точно контролировать отдельные компоненты визуальных концепций. Система использует динамическое маскированное ухудш
[21.10.2024 20:14] Using data from previous issue: {"desc": "Статья представляет SeerAttention - новый механизм внимания для больших языковых моделей (LLM). Он использует обучаемые gates для адаптивного выбора значимых блоков в карте внимания, что позволяет эффективно балансировать точность и скорость работы. SeerAttention превосходит существующие м
[21.10.2024 20:14] Using data from previous issue: {"desc": "Эта статья представляет Flexible Vision Transformer (FiT) - новую архитектуру трансформера для генерации изображений с произвольным разрешением и соотношением сторон. FiT рассматривает изображения как последовательности токенов динамического размера, что позволяет гибко обучать модель на и
[21.10.2024 20:14] Using data from previous issue: {"desc": "Mini-Omni2 - это мультимодальная модель машинного обучения, способная обрабатывать визуальные, аудио и текстовые данные, а также генерировать голосовые ответы в реальном времени. Модель использует предобученные визуальные и аудио энкодеры для сохранения производительности в отдельных модал
[21.10.2024 20:14] Using data from previous issue: {"desc": "Эта статья представляет новый метод под названием 'Diffusion Curriculum (DisCL)' для улучшения обучения нейронных сетей на ограниченных или некачественных данных. DisCL использует диффузионные модели для генерации синтетических данных, контролируя их близость к исходным изображениям с помо
[21.10.2024 20:14] Using data from previous issue: {"desc": "Статья посвящена проблеме обнаружения текстов, сгенерированных большими языковыми моделями (LLM). Авторы подчеркивают необходимость разработки надежных методов оценки качества датасетов с AI-сгенерированными фрагментами. Они представляют систематический обзор существующих датасетов и предл
[21.10.2024 20:14] Using data from previous issue: {"desc": "DAWN - это новый подход к генерации видео с говорящей головой, использующий неавторегрессивные диффузионные модели. В отличие от существующих методов, DAWN генерирует все кадры видео одновременно, что позволяет избежать накопления ошибок и ускорить процесс. Система состоит из двух основных
[21.10.2024 20:14] Using data from previous issue: {"desc": "DPLM-2 — это мультимодальная языковая модель для белков, которая одновременно моделирует последовательности аминокислот и трехмерные структуры. Модель использует дискретную диффузию и квантование для представления 3D-координат в виде токенов. DPLM-2 обучается на экспериментальных и синтети
[21.10.2024 20:14] Using data from previous issue: {"desc": "Статья представляет Гибридный Авторегрессионный Трансформер (HART) - модель для генерации изображений высокого качества размером 1024x1024 пикселей. HART использует гибридный токенизатор, который разделяет латентное представление на дискретные токены для общей картины и непрерывные токены 
[21.10.2024 20:14] Using data from previous issue: {"desc": "Исследование показывает, что не все параметры нейронной сети одинаково важны для её функции принятия решений. Авторы изучили влияние методов обучения на критичность различных слоёв сети для задачи классификации изображений ImageNet-1k. Обнаружено, что улучшенные режимы обучения и самоконтр
[21.10.2024 20:14] Using data from previous issue: {"desc": "Статья рассматривает проблемы, связанные с использованием методов обучения с подкреплением на основе обратной связи от человека (RLHF) для настройки языковых моделей. Авторы выявляют недостатки подходов, основанных на маржинальных потерях, которые могут привести к нежелательному поведению 
[21.10.2024 20:14] Using data from previous issue: {"desc": "Статья представляет новый подход к моделированию тем в китайских СМИ под названием KeyNMF. Этот метод использует трансформерные контекстные эмбеддинги и показывает конкурентоспособные результаты на нескольких китайских датасетах. Авторы интегрируют KeyNMF с существующими методами анализа д
[21.10.2024 20:14] Using data from previous issue: {"desc": "BiGR - это новая модель условной генерации изображений, использующая компактные бинарные латентные коды. Она объединяет генерацию и дискриминацию в единой структуре, включая бинарный токенизатор и механизм маскированного моделирования. BiGR демонстрирует превосходное качество генерации по 
[21.10.2024 20:14] Using data from previous issue: {"desc": "Исследование рассматривает способность больших языковых моделей (LLM) к интроспекции, определяемой как получение знаний, не содержащихся в обучающих данных. Эксперименты проводились с моделями GPT-4, GPT-4o и Llama-3, дообученными для предсказания собственного поведения в гипотетических сц
[21.10.2024 20:14] Using data from previous issue: {"desc": "Shakti - это языковая модель с 2,5 миллиардами параметров, оптимизированная для устройств с ограниченными ресурсами. Она сочетает высокопроизводительную обработку естественного языка с эффективностью и точностью, что делает ее идеальной для приложений ИИ в реальном времени. Shakti поддержи
[21.10.2024 20:14] Using data from previous issue: {"desc": "В статье представлен новый метод синтеза данных для обучения языковых моделей - Montessori-Instruct. Этот подход адаптирует процесс генерации синтетических данных учительской моделью под предпочтения обучающейся студенческой модели. Используя локальное влияние данных, метод определяет, как
[21.10.2024 20:14] Using data from previous issue: {"desc": "Исследование посвящено проблеме восприимчивости больших языковых моделей (БЯМ) к убеждению и предлагает метод Persuasion-Balanced Training (PBT) для её решения. PBT использует многоагентные рекурсивные диалоговые деревья для создания данных и обучает модели с помощью оптимизации предпочтен
[21.10.2024 20:14] Loading Chinese text from previous data.
[21.10.2024 20:14] Renaming data file.
[21.10.2024 20:14] Renaming previous data. hf_papers.json to ./d/2024-10-21.json
[21.10.2024 20:14] Saving new data file.
[21.10.2024 20:14] Generating page.
[21.10.2024 20:14] Renaming previous page.
[21.10.2024 20:14] Renaming previous data. index.html to ./d/2024-10-21.html
[21.10.2024 20:14] [Experimental] Generating Chinese page for reading.
[21.10.2024 20:14] Chinese vocab [{'word': '自主代理', 'pinyin': 'zìzhǔ dàilǐ', 'trans': 'autonomous agents'}, {'word': '不可逆', 'pinyin': 'bùkě nì', 'trans': 'irreversible'}, {'word': '世界模型', 'pinyin': 'shìjiè móxíng', 'trans': 'world model'}, {'word': '初步分析', 'pinyin': 'chūbù fēnxī', 'trans': 'preliminary analysis'}, {'word': '增强型', 'pinyin': 'zēngqiáng xíng', 'trans': 'enhanced'}, {'word': '过渡聚焦', 'pinyin': 'guòdù jùjiāo', 'trans': 'transitional focus'}, {'word': '观察抽象', 'pinyin': 'guānchá chōuxiàng', 'trans': 'observational abstraction'}, {'word': '时间步', 'pinyin': 'shíjiān bù', 'trans': 'time steps'}, {'word': '策略选择', 'pinyin': 'cèlüè xuǎnzé', 'trans': 'strategy selection'}, {'word': '成本', 'pinyin': 'chéngběn', 'trans': 'cost'}, {'word': '时间效率', 'pinyin': 'shíjiān xiàolǜ', 'trans': 'time efficiency'}]
[21.10.2024 20:14] Renaming previous Chinese page.
[21.10.2024 20:14] Renaming previous data. zh.html to ./d/2024-10-20_zh_reading_task.html
[21.10.2024 20:14] Writing result.
[21.10.2024 20:14] Writing Chinese reading task.
[21.10.2024 20:14] Renaming log file.
[21.10.2024 20:14] Renaming previous data. log.txt to ./logs/2024-10-21_last_log.txt
