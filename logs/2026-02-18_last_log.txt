[18.02.2026 10:37] Read previous papers.
[18.02.2026 10:37] Generating top page (month).
[18.02.2026 10:37] Writing top page (month).
[18.02.2026 11:34] Read previous papers.
[18.02.2026 11:34] Get feed.
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15763
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.14299
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15112
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.12279
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15200
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.14486
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15772
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15322
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09653
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15620
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15278
[18.02.2026 11:34] Extract page data from URL. URL: https://huggingface.co/papers/2602.14111
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.12978
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15327
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07854
[18.02.2026 11:34] Get page data from previous paper. URL: https://huggingface.co/papers/2602.11389
[18.02.2026 11:34] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.02.2026 11:34] No deleted papers detected.
[18.02.2026 11:34] Downloading and parsing papers (pdf, html). Total: 16.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15763.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15763.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15763.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.14299.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.14299.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.14299.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15112.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15112.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15112.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.12279.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.12279.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.12279.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15200.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15200.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15200.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.14486.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.14486.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.14486.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15772.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15772.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15772.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15322.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15322.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15322.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.09653.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.09653.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.09653.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15620.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15620.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15620.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15278.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15278.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15278.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.14111.
[18.02.2026 11:34] Downloading paper 2602.14111 from https://arxiv.org/pdf/2602.14111v1...
[18.02.2026 11:34] Extracting affiliations from text.
[18.02.2026 11:34] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 1 ] . [ 1 1 1 1 4 1 . 2 0 6 2 : r Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines? Anton Korznikov * Andrey Galichin * Alexey Dontsov Oleg Y. Rogov Ivan Oseledets Elena Tutubalina "
[18.02.2026 11:34] Response: ```python
[]
```
[18.02.2026 11:34] Extracting affiliations from text.
[18.02.2026 11:34] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 1 ] . [ 1 1 1 1 4 1 . 2 0 6 2 : r Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines? Anton Korznikov * Andrey Galichin * Alexey Dontsov Oleg Y. Rogov Ivan Oseledets Elena TutubalinaSparse Autoencoders (SAEs) have emerged as promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On synthetic setup with known ground-truth features, we demonstrate that SAEs recover only 9% of true features despite achieving 71% explained variance, showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations, we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models internal mechanisms. 1. Introduction Large Language Models (LLMs) have achieved remarkable performance across wide range of natural language processing tasks, with applications continuing to expand rapidly. As these models grow in capability and deployment, the interpretation of their internal mechanisms becomes increasingly important (Bereska & Gavves, 2024; Grace et al., 2025). Interpretability could potentially help to understand specific learning behaviors, such as safety mechanisms (Arditi et al., 2024) and reasoning processes (Wang et al., 2023; Galichin et al., 2025), identify misalignment risks (Betley et al., 2025; Wang et al., 2025). Sparse Au- *Equal contribution . Correspondence to: Anton Korznikov <korznikovantona@gmail.com>. Preprint. February 17, 2026. 1 toencoders (SAEs) serve as popular tool for this purpose, aiming to decompose dense model activations into sparse human-interpretable features (Bricken et al., 2023; Huben et al., 2024). Recent contributions have introduced various SAE architectures (Rajamanoharan et al., 2024b; Bussmann et al., 2024; Korznikov et al., 2025; Bussmann et al., 2025), with further success in scaling to frontier models (Gao et al., 2025; Lieberum et al., 2024). However, critical challenge remains: lacking ground truth for true features, it is difficult to determine whether SAEs recover meaningful representations. Recent negative results on downstream applications (Smith et al., 2025; Wu et al., 2025) further underscore this challenge. To address this ambiguity, we propose systematic evaluation approach to assess whether SAEs learn meaningful feature decompositions. We first set up synthetic experiment with known ground-truth features and test whether state-of-the-art SAE architectures can recover them. Despite achieving 71% explained variance, SAEs recover only the highest-frequency features (9%), failing to discover the decomposition they are intended to find. Second, to evaluate SAEs on real activations where ground truth is unknown, we compare them against three easy-to-implement baselines on downstream tasks. These baselines constrain SAE feature directions or activation patterns to random values 1: (1) Frozen Decoder fixes directions to random vectors; (2) Frozen Encoder fixes activation patterns to random; (3) Soft-Frozen Decoder restricts directions to remain near random initialization. The rationale is straightforward: the learned directions and activation patterns represent the learned decomposition. Consequently, if SAEs learn meaningful features, they should outperform these baselines. Across multiple SAE architectures (Bricken et al., 2023; Rajamanoharan et al., 2024b; Bussmann et al., 2024), we find that our baselines match fully-trained SAEs on interpretability (Paulo et al., 2025) (0.87 vs 0.90), sparse probing (Karvonen et al., 2025) (0.69 vs 0.72), and causal editing (Huang et al., 2024; Karvonen et al., 2025) (0.73 vs 0.72). Together with our synthetic results, these findings suggest that current evaluation practices may be insufficient, and we offer our baselines as simple sanity checks for validating whether SAEs learn meaningful feature decompositions. Our work makes the following contributions: Submission and Formatting Instructions for ICML Figure 1. Frozen SAE baselines and their performance. (Left) Conceptual diagrams: Frozen Decoder SAE (decoder weights fixed at random initialization), Soft-Frozen Decoder SAE (decoder weights initialized randomly and constrained to maintain CosineSim 0.8 with their initial values throughout training), and Frozen Encoder SAE (encoder weights fixed at random initialization). (Right) For BatchTopK SAE (L0=160), these baselines remain competitive with fully trained SAE across four key evaluation metrics, challenging the assumption that strong performance indicates meaningful feature learning. We demonstrate that SAEs fail on synthetic data with known ground-truth features, revealing disconnect between reconstruction fidelity and feature recovery. We introduce three easy-to-implement baselines for evaluating SAEs quality on real activations. Through extensive experiments, we find that our baselines match fully-trained SAEs, challenging the premise that SAEs learn meaningful features. 2. Background 2.1. Sparse Autoencoders for Interpretability Model Architecture and Decomposition SAEs have emerged as prominent tool for understanding neural network internals. It mainly addresses the challenge of polysemanticity, where individual neurons respond to multiple unrelated concepts (Bricken et al., 2023). The core motivation behind SAEs is the superposition hypothesis (Elhage et al., 2022), which posits that neural networks represent more features than they have dimensions by encoding them as directions in activation space. Formally, for an activation vector Rn, this hypothesis states that can be expressed as sparse linear combination of feature vectors: = (cid:88) j=1 aj fj, (1) ÀÜx = (cid:88) j=1 zj dj = (cid:88) j=1 zj Wdec = Wdecz, (2) where dj Rn are the learned decoder column vectors (the SAEs estimate of the true featu"
[18.02.2026 11:34] Mistral response. {"id": "e81c8fae5eca45eeac07e69c873b2cb3", "created": 1771414478, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1605, "total_tokens": 1611, "completion_tokens": 6, "prompt_tokens_details": {"cached_tokens": 0}}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[]\n```"}}]}
[18.02.2026 11:34] Response: ```python
[]
```
[18.02.2026 11:34] Deleting PDF ./assets/pdf/2602.14111.pdf.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.12978.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.12978.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.12978.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.15327.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.15327.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.15327.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.07854.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.07854.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.07854.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Downloading and parsing paper https://huggingface.co/papers/2602.11389.
[18.02.2026 11:34] Extra JSON file exists (./assets/json/2602.11389.json), skip PDF parsing.
[18.02.2026 11:34] Paper image links file exists (./assets/img_data/2602.11389.json), skip HTML parsing.
[18.02.2026 11:34] Success.
[18.02.2026 11:34] Enriching papers with extra data.
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 0. GLM-5 advances foundation models with DSA for cost reduction, asynchronous reinforcement learning for improved alignment, and enhanced coding capabilities for real-world software engineering.  					AI-generated summary 				 We present GLM-5, a next-generation foundation model designed to transition ...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 1. Large language model agents in networked environments exhibit dynamic stability without true social convergence, maintaining individual diversity while lacking collective influence structures.  					AI-generated summary 				 As large language model agents increasingly populate networked environments...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 2. ResearchGym presents a benchmark environment for evaluating AI agents on end-to-end research tasks, revealing significant capability-reliability gaps in current autonomous agents despite occasional state-of-the-art performance.  					AI-generated summary 				 We introduce ResearchGym, a benchmark an...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 3. UniT framework enables unified multimodal models to perform iterative reasoning and refinement through chain-of-thought test-time scaling, improving both generation and understanding capabilities.  					AI-generated summary 				 Unified models can handle both multimodal understanding and generation ...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 4. COMPOT is a training-free compression framework for Transformer models that uses sparse dictionary learning with orthogonal dictionaries and closed-form updates to achieve better quality-compression trade-offs than traditional low-rank methods.  					AI-generated summary 				 Post-training compressi...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 5. Network representations converge toward shared local neighborhood relationships rather than global statistical models, as revealed by calibrated similarity metrics.  					AI-generated summary 				 The Platonic Representation Hypothesis suggests that representations from neural networks are convergin...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 6. The Reason-Reflect-Refine framework addresses the trade-off between generation and understanding in multimodal models by reformulating single-step generation into a multi-step process that explicitly incorporates understanding during generation.  					AI-generated summary 				 Current research in mu...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 7. Random parameter update masking achieves superior optimization for large language models by inducing curvature-dependent regularization, with a momentum-aligned variant delivering significant performance improvements over state-of-the-art adaptive optimizers.  					AI-generated summary 				 Training...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 8. A two-stage framework addresses alignment of large language models with clinician preferences through physician-verified examples and distilled clinical principles for improved medical reasoning.  					AI-generated summary 				 Although large language models (LLMs) demonstrate expert-level medical k...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 9. Research identifies spurious tokens as the cause of training instability in reinforcement learning fine-tuning of large language models and proposes a solution that selectively masks problematic gradient updates to improve reasoning performance.  					AI-generated summary 				 Reinforcement Learning...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 10. Visual-language models' decision-making preferences are studied through controlled image choice tasks with systematic input perturbations, revealing visual vulnerabilities and safety concerns.  					AI-generated summary 				 The web is littered with images, once created for human consumption and now...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 11. Sparse Autoencoders fail to reliably decompose neural network internals despite strong reconstruction performance, as demonstrated through synthetic and real activation evaluations.  					AI-generated summary 				 Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural ne...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 12. Legato improves action-chunked Vision Language Action models by using training-time continuation methods that ensure smooth trajectories and reduce multimodal switching during real-time execution.  					AI-generated summary 				 Action chunking enables Vision Language Action (VLA) models to run in r...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 13. Large-scale observational analysis estimates capability boundaries and performance predictions for foundation models using quantile regression and evaluates temporal stability across tasks.  					AI-generated summary 				 For deploying foundation models, practitioners increasingly need prescriptive ...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 14. ViewRope, a geometry-aware encoding method, enhances long-term consistency in predictive world models by injecting camera-ray directions into video transformer attention layers, addressing spatial persistence issues through relative ray geometry parameterization.  					AI-generated summary 				 Pred...
[18.02.2026 11:34] ********************************************************************************
[18.02.2026 11:34] Abstract 15. C-JEPA extends masked joint embedding prediction to object-centric representations, enabling robust relational understanding through object-level masking that induces causal inductive biases and improves reasoning and control tasks.  					AI-generated summary 				 World models require robust relatio...
[18.02.2026 11:34] Read previous papers.
[18.02.2026 11:34] Generating reviews via LLM API.
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#inference", "#agents", "#training", "#alignment", "#optimization", "#architecture", "#plp", "#open_source", "#reasoning", "#rl"], "emoji": "ü§ñ", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "desc": "GLM-5 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –º–æ–¥–µ–ª—å
[18.02.2026 11:34] Using data from previous issue: {"categories": [], "emoji": "ü§ñ", "ru": {"title": "–ê–≥–µ–Ω—Ç—ã –±–µ–∑ —Å–æ—Ü–∏—É–º–∞: –ø–æ—á–µ–º—É –ò–ò-–æ–±—â–µ—Å—Ç–≤–∞ –Ω–µ —Å—Ö–æ–¥—è—Ç—Å—è –∫ –∫–æ–Ω—Å–µ–Ω—Å—É—Å—É", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–∑—É—á–∞–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Å–µ—Ç–µ–≤—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è—Ö, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—è, –ø–æ–¥–≤–µ—Ä–≥–∞—é—Ç—Å—è –ª–∏ –æ–Ω–∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏ –ø–æ–¥–æ–±–Ω–æ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º —Å–∏—Å—Ç–µ–º
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#benchmark", "#science", "#agents", "#long_context", "#dataset"], "emoji": "üß™", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö AI –∞–≥–µ–Ω—Ç–æ–≤ –≤ –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö", "desc": "ResearchGym –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –±–µ–Ω—á–º–∞—Ä–∫ –∏ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ AI –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —Å–∫–≤–æ–∑–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#multimodal", "#training", "#agents", "#inference"], "emoji": "üîÑ", "ru": {"title": "–ú—ã—Å–ª—è—â–∏–µ –º–æ–¥–µ–ª–∏: –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "UniT ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –µ–¥–∏–Ω–æ–π –º—É–ª—å—Ç–∏–º–æ
[18.02.2026 11:34] Using data from previous issue: {"categories": [], "emoji": "üóúÔ∏è", "ru": {"title": "–û—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–∂–∞—Ç–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è", "desc": "COMPOT ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–∂–∞—Ç–∏—è –º–æ–¥–µ–ª–µ–π Transformer –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–∞—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞—Ä—è–º–∏ –≤–º–µ—Å—Ç–æ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#interpretability"], "emoji": "üèõÔ∏è", "ru": {"title": "–û—Ç –ü–ª–∞—Ç–æ–Ω–∞ –∫ –ê—Ä–∏—Å—Ç–æ—Ç–µ–ª—é: –ª–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ—Å–µ–¥—Å—Ç–≤–æ –≤–º–µ—Å—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –≥–∏–ø–æ—Ç–µ–∑–∞ –æ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∫ –µ–¥–∏–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª–∏ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏. –ê–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Å—É—â–µ
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#open_source", "#training", "#architecture", "#reasoning", "#multimodal"], "emoji": "üîÑ", "ru": {"title": "–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —á–µ—Ä–µ–∑ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ Reason-Reflect-Refine (R3), –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç –º–µ–∂–¥—É —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture"], "emoji": "üéØ", "ru": {"title": "–°–ª—É—á–∞–π–Ω–æ–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π ‚Äî –ø—Ä–æ—Å—Ç–æ–π –ø—É—Ç—å –∫ –ª—É—á—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LLM", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Å–ª—É—á–∞–π–Ω–æ–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#dataset", "#training", "#healthcare", "#rlhf", "#alignment", "#reasoning", "#science", "#small_models"], "emoji": "üè•", "ru": {"title": "–ö–ª–∏–Ω–∏—á–µ—Å–∫–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ LLM —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –≤—Ä–∞—á–∞–º–∏ –ø—Ä–∏–º–µ—Ä—ã –∏ –¥–∏—Å—Ç–∏–ª–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã", "desc": "–†–∞–±–æ—Ç–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è 
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#training", "#optimization", "#reasoning", "#rl"], "emoji": "üéØ", "ru": {"title": "–ù–∞—Ö–æ–¥–∏ –∏ –∏—Å–∫–ª—é—á–∞–π: –∫–∞–∫ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–¥–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—ã—è–≤–∏–ª–æ, —á—Ç–æ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ fine-tuning –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –∏—Å–ø–æ–ª—å
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#multimodal", "#cv"], "emoji": "üîç", "ru": {"title": "–í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–∑—É—á–∞–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ –∑–∞–¥–∞—á–∏ –≤—ã–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫
[18.02.2026 11:34] Querying the API.
[18.02.2026 11:34] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Sparse Autoencoders fail to reliably decompose neural network internals despite strong reconstruction performance, as demonstrated through synthetic and real activation evaluations.  					AI-generated summary 				 Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, a growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On a synthetic setup with known ground-truth features, we demonstrate that SAEs recover only 9% of true features despite achieving 71% explained variance, showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations, we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models' internal mechanisms.
[18.02.2026 11:34] Response: ```json
{
  "desc": "–í —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –∞–≤—Ç–æ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–≤ (SAE) –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –ø—É—Ç–µ–º —Ä–∞–∑–ª–æ–∂–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π –Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞—é—Ç, —á—Ç–æ SAE –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ 9% –∏—Å—Ç–∏–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ 71%. –î–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∞–∫—Ç–∏–≤–∞—Ü–∏—è—Ö –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç—Å—è —Ç—Ä–∏ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–∏ —Å —Å–ª—É—á–∞–π–Ω—ã–º–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å—Ä–∞–≤–Ω–∏–º—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–Ω—ã–º–∏ SAE. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤—É—é—Ç –æ —Ç–æ–º, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ SAE –Ω–µ –Ω–∞–¥–µ–∂–Ω–æ —Ä–∞–∑–ª–∞–≥–∞—é—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã –º–æ–¥–µ–ª–µ–π.",
  "emoji": "üîç",
  "title": "–•–æ—Ä–æ—à–∞—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–∏–Ω–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å"
}
```
[18.02.2026 11:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Sparse Autoencoders fail to reliably decompose neural network internals despite strong reconstruction performance, as demonstrated through synthetic and real activation evaluations.  					AI-generated summary 				 Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, a growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On a synthetic setup with known ground-truth features, we demonstrate that SAEs recover only 9% of true features despite achieving 71% explained variance, showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations, we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models' internal mechanisms."

[18.02.2026 11:34] Response: ```python
["BENCHMARK", "ARCHITECTURE"]
```

**Justification:**

- **BENCHMARK**: The paper introduces evaluation frameworks and baselines to assess Sparse Autoencoders' performance, including synthetic evaluations with ground-truth features and three new baselines for evaluating interpretability, sparse probing, and causal editing.

- **ARCHITECTURE**: The paper analyzes Sparse Autoencoders (SAEs) as neural network components/architectures and discusses multiple SAE variants, examining their structural properties and how they decompose neural network internals.
[18.02.2026 11:34] Error. Failed to parse JSON from LLM. ["BENCHMARK", "ARCHITECTURE"]


**Justification:**

- **BENCHMARK**: The paper introduces evaluation frameworks and baselines to assess Sparse Autoencoders" performance, including synthetic evaluations with ground-truth features and three new baselines for evaluating interpretability, sparse probing, and causal editing.

- **ARCHITECTURE**: The paper analyzes Sparse Autoencoders (SAEs) as neural network components/architectures and discusses multiple SAE variants, examining their structural properties and how they decompose neural network internals.
[18.02.2026 11:34] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Sparse Autoencoders fail to reliably decompose neural network internals despite strong reconstruction performance, as demonstrated through synthetic and real activation evaluations.  					AI-generated summary 				 Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, a growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On a synthetic setup with known ground-truth features, we demonstrate that SAEs recover only 9% of true features despite achieving 71% explained variance, showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations, we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models' internal mechanisms."

[18.02.2026 11:34] Response: ```python
["INTERPRETABILITY"]
```
[18.02.2026 11:34] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"Sparse Autoencoders (SAEs) are designed to help us understand neural networks by breaking down their activations into simpler, interpretable features. However, this paper shows that despite good performance in reconstructing data, SAEs only identify a small fraction of the actual features present in the data. Through experiments with both synthetic and real data, the authors find that SAEs do not consistently provide meaningful insights into the workings of neural networks. The results indicate that current SAE methods may not be effective for reliably interpreting neural network internals.","title":"Sparse Autoencoders: Strong Reconstruction, Weak Interpretation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Sparse Autoencoders (SAEs) are designed to help us understand neural networks by breaking down their activations into simpler, interpretable features. However, this paper shows that despite good performance in reconstructing data, SAEs only identify a small fraction of the actual features present in the data. Through experiments with both synthetic and real data, the authors find that SAEs do not consistently provide meaningful insights into the workings of neural networks. The results indicate that current SAE methods may not be effective for reliably interpreting neural network internals.', title='Sparse Autoencoders: Strong Reconstruction, Weak Interpretation'))
[18.02.2026 11:34] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"Á®ÄÁñèËá™ÁºñÁ†ÅÂô®ÔºàSAEsÔºâË¢´ËÆ§‰∏∫ÊòØÁêÜËß£Á•ûÁªèÁΩëÁªúÁöÑ‰∏ÄÁßçÊúâÂâçÊôØÁöÑÂ∑•ÂÖ∑ÔºåËÉΩÂ§üÂ∞ÜÊøÄÊ¥ªÂàÜËß£‰∏∫Á®ÄÁñèÁöÑ‰∫∫Á±ªÂèØËß£ÈáäÁâπÂæÅ„ÄÇÁÑ∂ËÄåÔºåÂ∞ΩÁÆ°Âú®ÈáçÂª∫ÊÄßËÉΩ‰∏äË°®Áé∞ËâØÂ•ΩÔºåSAEsÂú®ÂÆûÈôÖ‰ªªÂä°‰∏≠Âç¥Êú™ËÉΩÂèØÈù†Âú∞ÊèêÂèñÊúâÊÑè‰πâÁöÑÁâπÂæÅ„ÄÇÈÄöËøáÂØπÂêàÊàêÊï∞ÊçÆÂíåÁúüÂÆûÊøÄÊ¥ªÁöÑËØÑ‰º∞ÔºåÊàë‰ª¨ÂèëÁé∞SAEs‰ªÖËÉΩÊÅ¢Â§ç9%ÁöÑÁúüÂÆûÁâπÂæÅÔºåË°®ÊòéÂÆÉ‰ª¨Âú®Ê†∏ÂøÉ‰ªªÂä°‰∏äÂ≠òÂú®Â§±Ë¥•„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂΩìÂâçÁä∂ÊÄÅ‰∏ãÁöÑSAEsÊó†Ê≥ïÊúâÊïàÂàÜËß£Ê®°ÂûãÁöÑÂÜÖÈÉ®Êú∫Âà∂„ÄÇ","title":"Á®ÄÁñèËá™ÁºñÁ†ÅÂô®ÁöÑÂ±ÄÈôêÊÄßÔºöÈáçÂª∫Âº∫‰ΩÜÁâπÂæÅÊèêÂèñÂº±"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Á®ÄÁñèËá™ÁºñÁ†ÅÂô®ÔºàSAEsÔºâË¢´ËÆ§‰∏∫ÊòØÁêÜËß£Á•ûÁªèÁΩëÁªúÁöÑ‰∏ÄÁßçÊúâÂâçÊôØÁöÑÂ∑•ÂÖ∑ÔºåËÉΩÂ§üÂ∞ÜÊøÄÊ¥ªÂàÜËß£‰∏∫Á®ÄÁñèÁöÑ‰∫∫Á±ªÂèØËß£ÈáäÁâπÂæÅ„ÄÇÁÑ∂ËÄåÔºåÂ∞ΩÁÆ°Âú®ÈáçÂª∫ÊÄßËÉΩ‰∏äË°®Áé∞ËâØÂ•ΩÔºåSAEsÂú®ÂÆûÈôÖ‰ªªÂä°‰∏≠Âç¥Êú™ËÉΩÂèØÈù†Âú∞ÊèêÂèñÊúâÊÑè‰πâÁöÑÁâπÂæÅ„ÄÇÈÄöËøáÂØπÂêàÊàêÊï∞ÊçÆÂíåÁúüÂÆûÊøÄÊ¥ªÁöÑËØÑ‰º∞ÔºåÊàë‰ª¨ÂèëÁé∞SAEs‰ªÖËÉΩÊÅ¢Â§ç9%ÁöÑÁúüÂÆûÁâπÂæÅÔºåË°®ÊòéÂÆÉ‰ª¨Âú®Ê†∏ÂøÉ‰ªªÂä°‰∏äÂ≠òÂú®Â§±Ë¥•„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂΩìÂâçÁä∂ÊÄÅ‰∏ãÁöÑSAEsÊó†Ê≥ïÊúâÊïàÂàÜËß£Ê®°ÂûãÁöÑÂÜÖÈÉ®Êú∫Âà∂„ÄÇ', title='Á®ÄÁñèËá™ÁºñÁ†ÅÂô®ÁöÑÂ±ÄÈôêÊÄßÔºöÈáçÂª∫Âº∫‰ΩÜÁâπÂæÅÊèêÂèñÂº±'))
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#robotics", "#cv", "#training", "#multimodal"], "emoji": "ü§ñ", "ru": {"title": "–ì–ª–∞–¥–∫–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º", "desc": "Legato ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π Vision Language Action, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤. –û—Å–Ω–æ–≤–Ω–∞
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#training", "#optimization", "#science"], "emoji": "üìà", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –±—é–¥–∂–µ—Ç", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–≤–∞–Ω—Ç–∏–ª—å
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#video", "#benchmark", "#architecture", "#3d"], "emoji": "üé¨", "ru": {"title": "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–∞–º–µ—Ä—ã –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ–≥–æ –≤–∏–¥–µ–Ω–∏—è –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –∏ –≤—Ä–µ–º–µ–Ω–∏", "desc": "ViewRope ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏ –æ—Å–≤–µ–¥–æ–º–ª—ë–Ω–Ω–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–¥
[18.02.2026 11:34] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#multimodal", "#open_source", "#robotics"], "emoji": "üß©", "ru": {"title": "–û–±—ä–µ–∫—Ç–Ω–æ-—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —á–µ—Ä–µ–∑ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", "desc": "C-JEPA ‚Äî —ç—Ç–æ –æ–±—ä–µ–∫—Ç–Ω–æ-—Ü–µ–Ω—Ç—Ä–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞—Å—à–∏—Ä—è–µ—Ç –º–µ—Ç–æ–¥ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–≤
[18.02.2026 11:34] Renaming data file.
[18.02.2026 11:34] Renaming previous data. hf_papers.json to ./d/2026-02-18.json
[18.02.2026 11:34] Saving new data file.
[18.02.2026 11:34] Generating page.
[18.02.2026 11:34] Renaming previous page.
[18.02.2026 11:34] Renaming previous data. index.html to ./d/2026-02-18.html
[18.02.2026 11:34] Writing result.
[18.02.2026 11:34] Renaming log file.
[18.02.2026 11:34] Renaming previous data. log.txt to ./logs/2026-02-18_last_log.txt
