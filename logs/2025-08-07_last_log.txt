[07.08.2025 21:11] Read previous papers.
[07.08.2025 21:11] Generating top page (month).
[07.08.2025 21:11] Writing top page (month).
[07.08.2025 22:13] Read previous papers.
[07.08.2025 22:13] Get feed.
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04026
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01191
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02694
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04700
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03501
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04280
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03680
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03159
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03905
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01858
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03560
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23785
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03789
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02215
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02807
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04664
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04586
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01928
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04295
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00222
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.21974
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01197
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04632
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04010
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01778
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01630
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00599
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03983
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03970
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03448
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.03178
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01311
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00428
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23313
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04440
[07.08.2025 22:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.00109
[07.08.2025 22:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[07.08.2025 22:13] No deleted papers detected.
[07.08.2025 22:13] Downloading and parsing papers (pdf, html). Total: 36.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04026.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04026.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04026.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01191.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01191.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01191.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02694.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02694.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02694.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04700.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04700.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04700.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03501.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03501.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03501.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04280.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04280.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04280.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03680.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03680.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03680.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03159.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03159.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03159.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03905.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03905.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03905.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01858.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01858.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01858.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03560.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03560.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03560.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2507.23785.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2507.23785.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2507.23785.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03789.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03789.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03789.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02215.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02215.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02215.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.02807.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.02807.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.02807.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04664.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04664.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04664.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04586.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04586.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04586.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01928.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01928.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01928.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04295.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04295.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04295.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.00222.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.00222.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.00222.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2507.21974.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2507.21974.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2507.21974.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01197.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01197.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01197.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04632.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04632.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04632.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04010.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04010.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04010.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01778.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01778.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01778.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01630.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01630.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01630.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.00599.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.00599.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.00599.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03983.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03983.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03983.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03970.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03970.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03970.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03448.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03448.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03448.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.03178.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.03178.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.03178.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.01311.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.01311.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.01311.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.00428.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.00428.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.00428.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2507.23313.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2507.23313.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2507.23313.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.04440.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.04440.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.04440.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Downloading and parsing paper https://huggingface.co/papers/2508.00109.
[07.08.2025 22:13] Extra JSON file exists (./assets/json/2508.00109.json), skip PDF parsing.
[07.08.2025 22:13] Paper image links file exists (./assets/img_data/2508.00109.json), skip HTML parsing.
[07.08.2025 22:13] Success.
[07.08.2025 22:13] Enriching papers with extra data.
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 0. VeriGUI is a novel dataset for evaluating GUI agents in long-horizon tasks, emphasizing long-chain complexity and subtask-level verifiability.  					AI-generated summary 				 Recent studies have delved into constructing autonomous agents capable of performing complex Graphical User Interface (GUI)-b...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 1. CoT reasoning in LLMs is found to be limited by the distribution discrepancy between training and test data, suggesting it is not a robust form of reasoning.  					AI-generated summary 				 Chain-of-Thought (CoT) prompting has been shown to improve Large Language Model (LLM) performance on various t...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 2. A study on the efficiency-effectiveness trade-off in LLM-driven agent systems identifies optimal agent framework design to reduce costs while maintaining performance.  					AI-generated summary 				 The remarkable capabilities of Large Language Model (LLM)-driven agents have enabled sophisticated sy...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 3. SEAgent, an agentic self-evolving framework, enables computer-use agents to autonomously master novel software through experiential learning and a curriculum of tasks, achieving superior performance compared to existing methods.  					AI-generated summary 				 Repurposing large vision-language model...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 4. Research on applications of Reinforcement Learning (RL) to Large Language Models (LLMs) has mostly been focused on single-turn problems, such as mathematical reasoning or single-shot code generation. While these problems can be viewed as token-level multi-turn MDPs, this view corresponds to a degene...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 5. A lightweight, hyperparameter-free RL algorithm, VL-DAC, enables VLMs to learn generalized policies from inexpensive simulators, improving performance on real-world benchmarks without sacrificing image understanding accuracy.  					AI-generated summary 				 Interactive multimodal agents must convert...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 6. Agent Lightning is a flexible RL framework for training LLMs in various agents, using a hierarchical RL algorithm and decoupling execution from training to handle complex interactions.  					AI-generated summary 				 We present Agent Lightning, a flexible and extensible framework that enables Reinfo...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 7. CoTox, a framework integrating LLMs with chain-of-thought reasoning, enhances multi-toxicity prediction by incorporating chemical structure data, biological pathways, and gene ontology terms, improving interpretability and predictive performance in drug development.  					AI-generated summary 				 D...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 8. Sotopia-RL, a novel reinforcement learning framework, enhances social intelligence in large language models by refining feedback into utterance-level, multi-dimensional rewards, improving performance in social tasks.  					AI-generated summary 				 Social intelligence has become a critical capabilit...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 9. A framework for web agents decomposes their capabilities into knowledge content learning and cognitive processes, using a structured dataset and a novel reasoning framework to enhance generalization and performance.  					AI-generated summary 				 Multimodal large-scale models have significantly adv...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 10. LaTCoder enhances layout preservation in design-to-code tasks by dividing webpage designs into blocks and using Chain-of-Thought reasoning with MLLMs, achieving significant improvements in metrics and human preference.  					AI-generated summary 				 Converting webpage designs into code (design-to-c...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 11. A novel framework uses a Direct 4DMesh-to-GS Variation Field VAE and Gaussian Variation Field diffusion model to generate high-quality dynamic 3D content from single video inputs, demonstrating superior quality and generalization.  					AI-generated summary 				 In this paper, we present a novel fra...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 12. HPSv3, a human preference score using a wide-spectrum dataset and uncertainty-aware ranking loss, enhances text-to-image generation quality through iterative refinement.  					AI-generated summary 				 Evaluating text-to-image generation models requires alignment with human perception, yet existing ...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 13. LeanK, a learning-based method, prunes unimportant key cache channels in large language models to reduce memory usage and accelerate decoding without sacrificing accuracy.  					AI-generated summary 				 Large language models (LLMs) enable long-context tasks but face efficiency challenges due to the...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 14. DreamVVT, a two-stage framework using Diffusion Transformers and LoRA adapters, enhances video virtual try-on by leveraging unpaired human-centric data and pretrained models to preserve garment details and temporal consistency.  					AI-generated summary 				 Video virtual try-on (VVT) technology ha...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 15. Sculptor, a framework for Active Context Management, enhances LLM performance on long contexts by enabling proactive attention and memory control, reducing proactive interference and improving reasoning reliability.  					AI-generated summary 				 Large Language Models (LLMs) suffer from significant...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 16. The paper diagnoses structural issues in AI conferences, including publication rates, carbon footprint, negative community sentiment, and logistical challenges, and proposes a Community-Federated Conference model to address these issues.  					AI-generated summary 				 Artificial Intelligence (AI) c...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 17. IAUNet, a query-based U-Net architecture with a lightweight convolutional Pixel decoder and Transformer decoder, outperforms state-of-the-art models in biomedical instance segmentation.  					AI-generated summary 				 Instance segmentation is critical in biomedical imaging to accurately distinguish ...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 18. EvoC2Rust is an automated framework that translates entire C projects to Rust using a skeleton-guided approach, combining rule-based and LLM-based methods to improve syntax, semantics, and safety.  					AI-generated summary 				 Rust's compile-time safety guarantees make it ideal for safety-critical...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 19. RL-PLUS, a hybrid-policy optimization approach, enhances LLM reasoning capabilities by integrating Multiple Importance Sampling and Exploration-Based Advantage Function, outperforming RLVR on various benchmarks and resolving capability boundary collapse.  					AI-generated summary 				 Reinforcement...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 20. A lightweight framework using Large Language Models (LLMs) with TeleLogs dataset and a two-stage training methodology improves Root Cause Analysis (RCA) in mobile networks by enhancing interpretability and reasoning quality.  					AI-generated summary 				 Root Cause Analysis (RCA) in mobile network...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 21. A benchmark and model for 3D occupancy grounding using natural language and voxel-level annotations improve object perception in autonomous driving.  					AI-generated summary 				 Visual grounding aims to identify objects or regions in a scene based on natural language descriptions, essential for s...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 22. Instruction Following Decorator enhances RLVR by improving sample efficiency, intent alignment, and reducing reward hacking in large language models.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) improves instruction following capabilities of large language mo...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 23. HarmonyGuard is a multi-agent framework that enhances policy compliance and task completion in web environments by adaptively updating security policies and optimizing dual objectives of safety and utility.  					AI-generated summary 				 Large language models enable agents to autonomously perform t...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 24. DiffSemanticFusion enhances autonomous driving by fusing semantic raster and graph-based representations using a map diffusion module, improving trajectory prediction and end-to-end driving performance.  					AI-generated summary 				 Autonomous driving requires accurate scene understanding, includi...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 25. OpenMed NER, a suite of open-source transformer models using DAPT and LoRA, achieves state-of-the-art performance on diverse biomedical NER benchmarks with high efficiency and low computational cost.  					AI-generated summary 				 Named-entity recognition (NER) is fundamental to extracting structur...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 26. DPoser-X, a diffusion-based model, addresses the complexity of 3D human poses using variational diffusion sampling and a novel truncated timestep scheduling method, outperforming existing models across various pose benchmarks.  					AI-generated summary 				 We present DPoser-X, a diffusion-based pr...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 27. MiDashengLM is an open audio-language model using general audio captions for efficient and comprehensive audio understanding, offering faster processing and higher throughput compared to existing models.  					AI-generated summary 				 Current approaches for large audio language models (LALMs) often...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 28. Approaches to govern, assess, and quantify bias in machine learning models, particularly large language models, are discussed, emphasizing data and AI governance frameworks for ethical deployment.  					AI-generated summary 				 In this paper, we cover approaches to systematically govern, assess and...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 29. SonicMaster, a unified generative model, improves music audio quality by addressing various artifacts using text-based control and a flow-matching generative training paradigm.  					AI-generated summary 				 Music recordings often suffer from audio quality issues such as excessive reverberation, di...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 30. A framework using entropy-preserving supervised fine-tuning and token-wise entropy-adaptive reinforcement learning improves instruction adherence in LLMs by fostering rigorous reasoning processes.  					AI-generated summary 				 While advancements in the reasoning abilities of LLMs have significantl...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 31. A continual learning framework for 3D anomaly detection uses Kernel Attention mechanisms and parameter perturbation to handle multiple and emerging classes of point clouds.  					AI-generated summary 				 3D Anomaly Detection (AD) has shown great potential in detecting anomalies or defects of high-p...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 32. Sel3DCraft enhances text-to-3D generation through a dual-branch retrieval and generation system, multi-view hybrid scoring with MLLMs, and prompt-driven visual analytics, improving designer creativity.  					AI-generated summary 				 Text-to-3D (T23D) generation has transformed digital content creat...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 33. Transformer-based text-to-image diffusion models show varying degrees of content-style separation in generated artworks, as revealed by cross-attention heatmaps.  					AI-generated summary 				 Text-to-image diffusion models have demonstrated remarkable capabilities in generating artistic content by...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 34. ThinkingF, a data synthesis and training pipeline, enhances autoformalization by improving formal knowledge and informal-to-formal reasoning, achieving state-of-the-art results in formalization tasks.  					AI-generated summary 				 Autoformalization aims to translate natural-language mathematical s...
[07.08.2025 22:13] ********************************************************************************
[07.08.2025 22:13] Abstract 35. FACTORY, a human-verified prompt set, evaluates the factuality of long-form responses from language models, revealing higher factual accuracy compared to existing datasets.  					AI-generated summary 				 Long-form factuality evaluation assesses the ability of models to generate accurate, comprehens...
[07.08.2025 22:13] Read previous papers.
[07.08.2025 22:13] Generating reviews via LLM API.
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#games", "#agents", "#dataset", "#long_context"], "emoji": "üñ•Ô∏è", "ru": {"title": "VeriGUI: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö GUI-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "VeriGUI - —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ GUI-–∞–≥–µ–Ω—Ç–æ–≤ –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, –∞–∫—Ü–µ–Ω—Ç–∏—Ä—É—é—â–∏–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ü–µ–ø–æ—á–µ
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#reasoning", "#data", "#training", "#interpretability"], "emoji": "üß†", "ru": {"title": "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç—å CoT-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ LLM: –º–∏—Ä–∞–∂ –≤–Ω–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø–æ —Ü–µ–ø–æ—á–∫–µ (CoT) –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM) –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã —Ä–∞—Å
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#agents", "#optimization", "#training", "#open_source", "#benchmark"], "emoji": "ü§ñ", "ru": {"title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º: –±–∞–ª–∞–Ω—Å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –∑–∞—Ç—Ä–∞—Ç", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –∞–Ω–∞–ª–∏–∑—É –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–∞ –º–µ–∂–¥—É —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é –≤ —Å–∏—Å—Ç–µ–º–∞—Ö –∞–≥–µ–Ω—Ç–æ–≤, —É–ø—Ä–∞–≤–ª
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#agents", "#agi", "#open_source", "#optimization", "#rl"], "emoji": "ü§ñ", "ru": {"title": "–°–∞–º–æ–æ–±—É—á–∞—é—â–∏–µ—Å—è –∞–≥–µ–Ω—Ç—ã –¥–ª—è –æ—Å–≤–æ–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –ü–û", "desc": "SEAgent - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞–º –∏—Å—Å–ª
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#open_source", "#agents", "#benchmark", "#optimization", "#rl", "#reasoning"], "emoji": "ü§ñ", "ru": {"title": "RL –¥–ª—è LLM: –ø—Ä–æ—Ä—ã–≤ –≤ –º–Ω–æ–≥–æ—Ö–æ–¥–æ–≤–æ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ü–û", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —É—Å–ø–µ—à–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) –∫ –±–æ–ª—å—à–∏–º —è–∑—ã–∫–æ–≤—ã–º
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#rl", "#training", "#transfer_learning", "#synthetic", "#games", "#rlhf", "#multimodal", "#optimization"], "emoji": "ü§ñ", "ru": {"title": "–ü—Ä–æ—Å—Ç–æ–µ RL-–æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤", "desc": "VL-DAC - —ç—Ç–æ –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#agents", "#rag", "#games", "#math", "#training", "#optimization", "#rl"], "emoji": "‚ö°", "ru": {"title": "Agent Lightning: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "Agent Lightning - —ç—Ç–æ –≥–∏–±–∫–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ä–∞–∑–ª–∏—á
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#science", "#interpretability", "#healthcare", "#reasoning", "#data", "#multimodal"], "emoji": "üß™", "ru": {"title": "CoTox: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ª–µ–∫–∞—Ä—Å—Ç–≤ —Å –ø–æ–º–æ—â—å—é LLM", "desc": "CoTox - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) —Å —Ä–∞
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#games", "#alignment", "#rlhf", "#rl"], "emoji": "ü§ñ", "ru": {"title": "Sotopia-RL: –ø—Ä–æ—Ä—ã–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–º—É –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É –¥–ª—è –ò–ò", "desc": "Sotopia-RL - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω–∞ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—Ä–∞—Ç–Ω
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#dataset", "#reasoning", "#open_source"], "emoji": "üï∏Ô∏è", "ru": {"title": "–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤, —Ä–∞–∑–¥–µ–ª—è—é—â—É—é –∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –Ω–∞ –∏–∑—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∑–Ω–∞–Ω–∏–π –∏ –∫–æ–≥–Ω–∏—Ç–∏–≤
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#reasoning", "#architecture", "#multimodal", "#optimization"], "emoji": "üß©", "ru": {"title": "LaTCoder: —É–ª—É—á—à–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–∞–∫–µ—Ç–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –∏–∑ –¥–∏–∑–∞–π–Ω–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü", "desc": "LaTCoder - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∑–∞–¥–∞—á–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∏–∑–∞–π–Ω–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü 
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#video", "#synthetic", "#3d", "#diffusion"], "emoji": "üé¨", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ 3D-–∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ 3D-–∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –≤–∏–¥–µ–æ–≤—Ö–æ–¥–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è VAE –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#alignment", "#data", "#benchmark", "#dataset", "#cv", "#open_source"], "emoji": "üñºÔ∏è", "ru": {"title": "HPSv3: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É", "desc": "HPSv3 - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —à–∏—Ä–æ–∫–æ–º —Å–ø–µ
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#training", "#long_context", "#inference", "#optimization"], "emoji": "üî™", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ –∫—ç—à–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "LeanK - —ç—Ç–æ –º–µ—Ç–æ–¥ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω —É–º–µ–Ω—å—à–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ —É—Å–∫–æ—Ä—è–µ
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#video", "#cv", "#synthetic", "#multimodal", "#diffusion"], "emoji": "üëö", "ru": {"title": "DreamVVT: –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∏–º–µ—Ä–∫–∞ –æ–¥–µ–∂–¥—ã –Ω–∞ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "DreamVVT - —ç—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–º–µ—Ä–∫–∏ –æ–¥–µ–∂–¥—ã –Ω–∞ –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#multimodal", "#long_context", "#reasoning", "#training"], "emoji": "üß†", "ru": {"title": "Sculptor: –£–º–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Sculptor –¥–ª—è –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#ethics", "#survey"], "emoji": "üåê", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–π –ò–ò: –æ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–∞—Ü–∏–∏ –∫ —Ñ–µ–¥–µ—Ä–∞—Ü–∏–∏", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–π –ø–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É, –≤–∫–ª—é—á–∞—è —Ä–æ—Å—Ç —á–∏—Å–ª–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π, —É–≥–ª–µ—Ä–æ–¥–Ω—ã–π —Å–ª–µ–¥, –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#architecture", "#cv", "#games", "#benchmark", "#science", "#dataset", "#optimization", "#healthcare"], "emoji": "üî¨", "ru": {"title": "IAUNet: –ü—Ä–æ—Ä—ã–≤ –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–µ—Ç–æ–∫ —Å –ø–æ–º–æ—â—å—é –≥–∏–±—Ä–∏–¥–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã", "desc": "IAUNet - —ç—Ç–æ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ U-Ne
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#open_source", "#architecture", "#plp", "#optimization"], "emoji": "üîÑ", "ru": {"title": "EvoC2Rust: –≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –ø–µ—Ä–µ–≤–æ–¥—É C –≤ Rust", "desc": "EvoC2Rust - —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ –Ω–∞ C –≤ Rust, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ø–æ–¥—Ö–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–µ–ª–µ—Ç
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#training", "#benchmark", "#optimization", "#rl", "#reasoning"], "emoji": "üß†", "ru": {"title": "RL-PLUS: –ü—Ä–æ—Ä—ã–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç RL-PLUS - –Ω–æ–≤—ã–π –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è 
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#interpretability", "#dataset", "#training", "#open_source", "#multimodal"], "emoji": "üîç", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–≤–æ–ø—Ä–∏—á–∏–Ω –≤ –º–æ–±–∏–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö —Å –ø–æ–º–æ—â—å—é –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#multimodal", "#games", "#benchmark", "#3d", "#optimization"], "emoji": "üöó", "ru": {"title": "–¢–æ—á–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π —Å –ø–æ–º–æ—â—å—é 3D –≥—Ä—É–Ω—Ç–æ–≤–∫–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –∑–∞–¥–∞—á–∏ 3D –≥—Ä—É–Ω—Ç–æ–≤–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#rlhf", "#open_source", "#alignment", "#training", "#optimization", "#security", "#rl"], "emoji": "üéì", "ru": {"title": "IFDecorator: –ü–æ–≤—ã—à–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Instruction Following Deco
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#optimization", "#security", "#benchmark", "#architecture", "#agents"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ì–∞—Ä–º–æ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ –≤–µ–±-—Å—Ä–µ–¥–µ", "desc": "HarmonyGuard - —ç—Ç–æ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#video", "#optimization", "#games", "#benchmark", "#multimodal", "#agents"], "emoji": "üöó", "ru": {"title": "–°–ª–∏—è–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏–∫–∏ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∞–≤—Ç–æ–ø–∏–ª–æ—Ç–∞", "desc": "DiffSemanticFusion - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –≤–æ–∂–¥–µ–Ω–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Ç—Ä–æ–≤—ã–µ –∏ –≥—Ä–∞—Ñ–æ–≤—ã–µ –ø—Ä–µ–¥
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#healthcare", "#ethics", "#dataset", "#training", "#transfer_learning", "#open_source", "#benchmark", "#data"], "emoji": "üß¨", "ru": {"title": "OpenMed NER: –û—Ç–∫—Ä—ã—Ç—ã–π –ø—Ä–æ—Ä—ã–≤ –≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π", "desc": "OpenMed NER - —ç—Ç–æ –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ —Å –æ
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#benchmark", "#3d", "#diffusion"], "emoji": "üï∫", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ–∑ —á–µ–ª–æ–≤–µ–∫–∞ —Å –ø–æ–º–æ—â—å—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "DPoser-X - —ç—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –ø–æ–∑ —á–µ–ª–æ–≤–µ–∫–∞. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É –¥–∏—Ñ—Ñ—É–∑–∏–∏ –∏ –Ω–æ–≤—ã–π
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#audio", "#dataset", "#open_source"], "emoji": "üéß", "ru": {"title": "MiDashengLM: –û—Ç–∫—Ä—ã—Ç–∞—è –∞—É–¥–∏–æ-—è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∑–≤—É–∫–∞", "desc": "MiDashengLM - —ç—Ç–æ –Ω–æ–≤–∞—è –æ—Ç–∫—Ä—ã—Ç–∞—è –∞—É–¥–∏–æ-—è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏ –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∞—É–¥–∏–æ —Å –∏—Å–ø–æ–ª
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#multimodal", "#data", "#ethics", "#benchmark"], "emoji": "‚öñÔ∏è", "ru": {"title": "–≠—Ç–∏—á–Ω—ã–π –ò–ò: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å—é –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –æ–±—Å—É–∂–¥–∞—é—Ç—Å—è –ø–æ–¥—Ö–æ–¥—ã –∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é, –æ—Ü–µ–Ω–∫–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –≤ –º–æ–¥–µ–ª—è—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –±–æ–ª
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#audio", "#dataset", "#synthetic"], "emoji": "üéµ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º—É–∑—ã–∫–∏ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "SonicMaster - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ –≤ –º—É–∑—ã–∫–µ. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –∏ –ø–∞—Ä–∞–¥–∏–≥–º—É –æ–±—É—á
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#optimization", "#rl", "#dataset", "#benchmark", "#training", "#reasoning"], "emoji": "üß†", "ru": {"title": "–¢–æ—á–Ω–æ–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º —á–µ—Ä–µ–∑ –≥–ª—É–±–æ–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–ª–µ–¥–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º. –ê–≤—Ç–æ—Ä
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#training", "#3d", "#dataset", "#optimization"], "emoji": "üîç", "ru": {"title": "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è 3D-–∞–Ω–æ–º–∞–ª–∏–π: –æ—Ç –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ—Å—Ç–∏ –∫ –Ω–æ–≤—ã–º –∫–ª–∞—Å—Å–∞–º", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è C3D-AD –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ 3D-–æ–±–ª–∞–∫–∞—Ö —Ç–æ—á–µ–∫. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#games", "#3d", "#optimization", "#multimodal"], "emoji": "üé®", "ru": {"title": "Sel3DCraft: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è 3D-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "Sel3DCraft - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –≤ 3D, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#multimodal", "#interpretability", "#cv", "#diffusion"], "emoji": "üé®", "ru": {"title": "–°–∫—Ä—ã—Ç–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–∞: –∫–∞–∫ –ò–ò —Ä–∞–∑–¥–µ–ª—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∏ —Å—Ç–∏–ª—å", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–∏—Ñ—Ñ—É–∑–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#rl", "#training", "#optimization", "#reasoning", "#data", "#dataset"], "emoji": "üß†", "ru": {"title": "ThinkingF: –º–æ—Å—Ç –º–µ–∂–¥—É –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–æ–π –∏ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ–π –º–∞—Ç–µ–º–∞—Ç–∏–∫–æ–π", "desc": "ThinkingF - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ—Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, —É–ª—É—á—à–∞—é—â–∏–π —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –æ—Ç –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ 
[07.08.2025 22:13] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#dataset", "#long_context", "#hallucinations"], "emoji": "üîç", "ru": {"title": "FACTORY: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "FACTORY - —ç—Ç–æ –Ω–∞–±–æ—Ä –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö —á–µ–ª–æ–≤–µ–∫–æ–º –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª–∏–Ω–Ω—ã
[07.08.2025 22:13] Renaming data file.
[07.08.2025 22:13] Renaming previous data. hf_papers.json to ./d/2025-08-07.json
[07.08.2025 22:13] Saving new data file.
[07.08.2025 22:13] Generating page.
[07.08.2025 22:13] Renaming previous page.
[07.08.2025 22:13] Renaming previous data. index.html to ./d/2025-08-07.html
[07.08.2025 22:13] Writing result.
[07.08.2025 22:13] Renaming log file.
[07.08.2025 22:13] Renaming previous data. log.txt to ./logs/2025-08-07_last_log.txt
