[03.10.2025 16:13] Read previous papers.
[03.10.2025 16:13] Generating top page (month).
[03.10.2025 16:13] Writing top page (month).
[03.10.2025 17:09] Read previous papers.
[03.10.2025 17:09] Get feed.
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00446
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02283
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02245
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02314
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02297
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02209
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01444
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2509.22067
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01149
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01591
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02250
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02240
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02190
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02294
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01284
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01265
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02253
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02286
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02173
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02295
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01179
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21789
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00428
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26376
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01304
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02315
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01623
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02259
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01796
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00523
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24203
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01241
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02272
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02263
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01670
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01143
[03.10.2025 17:09] Extract page data from URL. URL: https://huggingface.co/papers/2509.25729
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24304
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02306
[03.10.2025 17:09] Extract page data from URL. URL: https://huggingface.co/papers/2510.01817
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01691
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01538
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00537
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00137
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26313
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01581
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00352
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26330
[03.10.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01260
[03.10.2025 17:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.10.2025 17:09] No deleted papers detected.
[03.10.2025 17:09] Downloading and parsing papers (pdf, html). Total: 49.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.00446.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.00446.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.00446.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02283.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02283.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02283.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02245.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02245.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02245.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02314.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02314.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02314.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02297.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02297.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02297.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02209.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02209.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02209.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01444.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01444.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01444.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2509.22067.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2509.22067.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2509.22067.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01149.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01149.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01149.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01591.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01591.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01591.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02250.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02250.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02250.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02240.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02240.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02240.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02190.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02190.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02190.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02294.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02294.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02294.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01284.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01284.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01284.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01265.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01265.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01265.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02253.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02253.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02253.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02286.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02286.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02286.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02173.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02173.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02173.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02295.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02295.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02295.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01179.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01179.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01179.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2509.21789.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2509.21789.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2509.21789.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.00428.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.00428.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.00428.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2509.26376.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2509.26376.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2509.26376.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01304.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01304.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01304.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02315.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02315.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02315.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01623.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01623.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01623.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02259.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02259.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02259.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01796.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01796.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01796.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.00523.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.00523.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.00523.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2509.24203.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2509.24203.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2509.24203.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01241.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01241.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01241.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02272.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02272.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02272.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02263.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02263.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02263.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01670.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01670.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01670.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01143.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.01143.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.01143.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2509.25729.
[03.10.2025 17:09] Downloading paper 2509.25729 from http://arxiv.org/pdf/2509.25729v1...
[03.10.2025 17:09] Extracting affiliations from text.
[03.10.2025 17:09] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Zihao Zhao Johns Hopkins University zzhao71@jhu.edu Anjalie Field Johns Hopkins University anjalief@jhu.edu 5 2 0 2 0 3 ] . [ 1 9 2 7 5 2 . 9 0 5 2 : r a "
[03.10.2025 17:09] Response: ```python
["Johns Hopkins University"]
```
[03.10.2025 17:09] Deleting PDF ./assets/pdf/2509.25729.pdf.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2509.24304.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2509.24304.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2509.24304.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.02306.
[03.10.2025 17:09] Extra JSON file exists (./assets/json/2510.02306.json), skip PDF parsing.
[03.10.2025 17:09] Paper image links file exists (./assets/img_data/2510.02306.json), skip HTML parsing.
[03.10.2025 17:09] Success.
[03.10.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2510.01817.
[03.10.2025 17:09] Downloading paper 2510.01817 from http://arxiv.org/pdf/2510.01817v1...
[03.10.2025 17:10] Extracting affiliations from text.
[03.10.2025 17:10] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 ] . [ 1 7 1 8 1 0 . 0 1 5 2 : r Sparse Query Attention (SQA): Computationally Efficient Attention Mechanism with Query Heads Reduction Adam Filipek (adamfilipek@rxai.dev) Reactive AI (https://rxai.dev) September 2025 Abstract The Transformer architecture, underpinned by the Multi-Head Attention (MHA) mechanism, has become the de facto standard for state-of-the-art models in artificial intelligence. However, the quadratic computational complexity of MHA with respect to sequence length presents significant barrier to scaling, particularly for applications involving long contexts. Prevailing solutions, such as Multi-Query Attention (MQA) and Grouped-Query Attention (GQA), have effectively addressed the memory bandwidth bottleneck that dominates autoregressive inference latency by sharing Key and Value projections. While highly successful, these methods do not reduce the fundamental number of floating-point operations (FLOPs) required for the attention score computation, which remains critical bottleneck for training and full-sequence processing. This paper introduces Sparse Query Attention (SQA), novel attention architecture that pursues an alternative and complementary optimization path. Instead of reducing Key/Value heads, SQA reduces the number of Query heads. This architectural modification directly decreases the computational complexity of the attention mechanism by factor proportional to the reduction in query heads, thereby lowering the overall FLOPs. This work presents the theoretical foundation of SQA, its mathematical formulation, and family of architectural variants. Empirical benchmarks on long sequences (32k-200k tokens) demonstrate that SQA can achieve significant throughput improvements of up to 3x in computation-bound scenarios such as model pre-training, fine-tuning, and encoder-based tasks, with only minimal impact on model quality in preliminary smallscale experiments. SQA was discovered serendipitously during the development of the upcomin"
[03.10.2025 17:10] Response: ```python
["Reactive AI"]
```
[03.10.2025 17:10] Deleting PDF ./assets/pdf/2510.01817.pdf.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2510.01691.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2510.01691.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2510.01691.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2510.01538.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2510.01538.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2510.01538.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2510.00537.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2510.00537.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2510.00537.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2510.00137.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2510.00137.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2510.00137.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.26313.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2509.26313.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2509.26313.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2510.01581.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2510.01581.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2510.01581.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2510.00352.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2510.00352.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2510.00352.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2509.26330.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2509.26330.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2509.26330.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2510.01260.
[03.10.2025 17:10] Extra JSON file exists (./assets/json/2510.01260.json), skip PDF parsing.
[03.10.2025 17:10] Paper image links file exists (./assets/img_data/2510.01260.json), skip HTML parsing.
[03.10.2025 17:10] Success.
[03.10.2025 17:10] Enriching papers with extra data.
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 0. LongCodeZip is a code compression framework for LLMs that uses dual-stage compression to reduce context size without degrading performance, improving efficiency in code intelligence applications.  					AI-generated summary 				 Code generation under long contexts is becoming increasingly critical as...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 1. A method is proposed to enhance long-horizon video generation by using sampled segments from self-generated long videos to guide student models, maintaining quality and consistency without additional supervision or retraining.  					AI-generated summary 				 Diffusion models have revolutionized imag...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 2. ExGRPO, a framework that prioritizes valuable reasoning experiences, improves and stabilizes reinforcement learning from verifiable rewards for large language models.  					AI-generated summary 				 Reinforcement learning from verifiable rewards (RLVR) is an emerging paradigm for improving the reaso...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 3. A novel density-guided poisoning method for 3D Gaussian Splatting enhances attack effectiveness by strategically injecting Gaussian points and disrupting multi-view consistency.  					AI-generated summary 				 3D scene representation methods like Neural Radiance Fields (NeRF) and 3D Gaussian Splatti...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 4. Interactive Training is a framework that allows real-time, feedback-driven intervention during neural network training, improving stability and adaptability.  					AI-generated summary 				 Traditional neural network training typically follows fixed, predefined optimization recipes, lacking the flex...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 5. StockBench evaluates large language models in realistic stock trading environments, revealing challenges and opportunities in developing LLM-powered financial agents.  					AI-generated summary 				 Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, sho...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 6. VOGUE, a method that shifts exploration to the visual input space by quantifying policy sensitivity to visual perturbations, enhances multimodal reasoning in large language models.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) improves reasoning in large langu...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 7. Activation steering, intended to control LLM behavior, can instead increase harmful compliance and undermine model alignment safeguards.  					AI-generated summary 				 Activation steering is a promising technique for controlling LLM behavior by adding semantically meaningful vectors directly into a...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 8. ModernVBERT, a compact vision-language encoder, outperforms larger models in document retrieval by optimizing attention masking, image resolution, modality alignment, and contrastive objectives.  					AI-generated summary 				 Multimodal embedding models are gaining prevalence, notably for document ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 9. Hidden states in Large Language Models encode correctness as a separable signature, enabling a minimalist verifier (CLUE) to outperform text-level and confidence-based methods in reranking and accuracy.  					AI-generated summary 				 Assessing the quality of Large Language Model (LLM) outputs prese...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 10. Behavior Best-of-N (bBoN) improves the reliability and success rates of computer-use agents by generating and selecting among multiple rollouts using behavior narratives, achieving state-of-the-art performance on OSWorld and strong generalization to different operating systems.  					AI-generated su...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 11. RewardMap, a multi-stage reinforcement learning framework, enhances multimodal large language models' visual understanding and reasoning skills through dense reward signals and a difficulty-aware reward design.  					AI-generated summary 				 Fine-grained visual reasoning remains a core challenge fo...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 12. A benchmark and evaluation framework for Deep Research Agents (DRAs) assesses their performance on complex tasks with multidimensional metrics.  					AI-generated summary 				 Artificial intelligence is undergoing the paradigm shift from closed language models to interconnected agent systems capable...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 13. F2LLM, a suite of large language models, achieves high embedding performance with efficient fine-tuning from foundation models using open-source datasets.  					AI-generated summary 				 We introduce F2LLM - Foundation to Feature Large Language Models, a suite of state-of-the-art embedding models in...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 14. Ovi is a unified audio-video generation model using twin-DiT modules with blockwise cross-modal fusion, enabling natural synchronization and high-quality multimodal outputs.  					AI-generated summary 				 Audio-video generation has often relied on complex multi-stage architectures or sequential syn...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 15. RLP, an information-driven reinforcement pretraining objective, enhances reasoning models by integrating exploration into pretraining, leading to significant performance improvements across various benchmarks.  					AI-generated summary 				 The dominant paradigm for training large reasoning models ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 16. DragFlow leverages FLUX's strong generative priors and region-based editing with affine transformations to achieve state-of-the-art performance in drag-based image editing.  					AI-generated summary 				 Drag-based image editing has long suffered from distortions in the target region, largely becau...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 17. DialTree-RPO, an on-policy reinforcement learning framework with tree search, autonomously discovers diverse multi-turn attack strategies against large language models, achieving higher attack success rates and uncovering new attack trajectories.  					AI-generated summary 				 Despite recent rapid ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 18. A reinforcement learning framework with span-level rewards improves hallucination span detection in large language models by incentivizing reasoning.  					AI-generated summary 				 Large language models (LLMs) often generate hallucinations -- unsupported content that undermines reliability. While m...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 19. VideoNSA, an adaptation of Native Sparse Attention to video-language models, enhances long-video understanding and temporal reasoning through end-to-end training and a hardware-aware hybrid attention approach.  					AI-generated summary 				 Video understanding in multimodal language models remains ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 20. Toucan, a large publicly available tool-agentic dataset, enhances the performance of LLM agents by providing diverse, realistic, and complex multi-tool and multi-turn interactions.  					AI-generated summary 				 Large Language Model (LLM) agents are rapidly emerging as powerful systems for automati...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 21. ViF mitigates visual hallucination snowballing in Multi-Agent Systems by enhancing visual attention and message relay through selected visual tokens.  					AI-generated summary 				 Multi-Agent System (MAS) powered by Visual Language Models (VLMs) enables challenging tasks but suffers from a novel f...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 22. Incorporating clinical context into automated structured radiology report generation improves report quality by addressing temporal hallucinations and utilizing comprehensive patient data.  					AI-generated summary 				 Automated structured radiology report generation (SRRG) from chest X-ray images...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 23. ScalingAR enhances next-token prediction in autoregressive image generation by using token entropy and adaptive scaling, improving model performance and efficiency.  					AI-generated summary 				 Test-time scaling (TTS) has demonstrated remarkable success in enhancing large language models, yet its...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 24. AGILE, an interactive jigsaw-solving framework, enhances visual perception and reasoning in Vision-Language Models through iterative action and feedback, improving performance on jigsaw tasks and general vision tasks.  					AI-generated summary 				 Although current large Vision-Language Models (VLM...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 25. A theoretical framework and algorithms for improving multi-subject fidelity in text-to-image models through control over sampling dynamics.  					AI-generated summary 				 Text-to-image (T2I) models excel on single-entity prompts but struggle with multi-subject descriptions, often showing attribute ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 26. VLA-R1 enhances VLA models with RLVR and GRPO to improve reasoning and execution, achieving better generalization and real-world performance using a new dataset with chain-of-thought supervision.  					AI-generated summary 				 Vision-Language-Action (VLA) models aim to unify perception, language un...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 27. Transformers trained directly on Cartesian coordinates can achieve competitive performance in molecular energy and force prediction without predefined graphs, demonstrating adaptability and scalability.  					AI-generated summary 				 Graph Neural Networks (GNNs) are the dominant architecture for mo...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 28. Hourglass MLP blocks, with skip connections in expanded dimensions and narrow bottlenecks, outperform conventional narrow-wide-narrow MLPs in generative tasks across image datasets.  					AI-generated summary 				 Multi-layer perceptrons (MLPs) conventionally follow a narrow-wide-narrow design where...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 29. VIRTUE, a novel Visual-InteRactive Text-Image Universal Embedder, integrates segmentation and vision-language models to enable visual interactions and localized grounding, achieving state-of-the-art performance in representation learning tasks.  					AI-generated summary 				 Multimodal representati...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 30. Off-policy reinforcement learning for large language models is explored through a new derivation of group-relative REINFORCE, offering insights into importance sampling, clipping, and data-weighting strategies.  					AI-generated summary 				 Off-policy reinforcement learning (RL) for large language...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 31. SKYLENAGE benchmarks evaluate LLMs on math reasoning, revealing performance gaps and ceiling effects across different educational levels.  					AI-generated summary 				 Large language models (LLMs) now perform strongly on many public math suites, yet frontier separation within mathematics increasin...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 32. Research investigates cross-linguistic transferability of reasoning capabilities in Large Reasoning Models, revealing significant variations and proposing a parallel training approach to improve generalization across languages.  					AI-generated summary 				 Recent advancements in Reinforcement Pos...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 33. Introducing reasoning abstractions in reinforcement learning improves structured exploration and generalization for complex problem-solving.  					AI-generated summary 				 Reasoning requires going beyond pattern matching or memorization of solutions to identify and implement "algorithmic procedures...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 34. Computer-Use Agents consistently exhibit Blind Goal-Directedness, a bias that leads to risky behavior regardless of feasibility or context, as demonstrated by the BLIND-ACT benchmark.  					AI-generated summary 				 Computer-Use Agents (CUAs) are an increasingly deployed class of agents that take ac...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 35. Bridge enhances parallel LLM inference by generating interdependent responses, improving accuracy and consistency with minimal additional parameters.  					AI-generated summary 				 Parallel LLM inference scaling involves sampling a set of N>1 responses for a single input prompt. However, these N pa...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 36. A novel methodology for privacy-preserving synthetic text generation using entity-aware control codes and HIPS theory achieves a balance between privacy and utility in sensitive domains.  					AI-generated summary 				 Text anonymization is essential for responsibly developing and deploying AI in hi...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 37. FrameThinker, a novel framework, enhances video reasoning by iteratively interrogating video content through supervised fine-tuning and reinforcement learning, achieving significant improvements and efficiency over existing models.  					AI-generated summary 				 While Large Vision-Language Models (...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 38. Ignoring rating updates for draws in arena-style evaluations of large language models improves battle outcome prediction accuracy by 1-3% across different rating systems.  					AI-generated summary 				 In arena-style evaluation of large language models (LLMs), two LLMs respond to a user query, and ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 39. Sparse Query Attention (SQA) reduces computational complexity in Transformer models by decreasing the number of Query heads, leading to significant throughput improvements with minimal impact on model quality.  					AI-generated summary 				 The Transformer architecture, underpinned by the Multi-Hea...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 40. MedQ-Bench introduces a benchmark for language-based evaluation of medical image quality using Multi-modal Large Language Models, focusing on both perceptual and reasoning capabilities.  					AI-generated summary 				 Medical Image Quality Assessment (IQA) serves as the first-mile safety gate for cl...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 41. TimeSeriesScientist (TSci) is an LLM-driven framework that automates time series forecasting with minimal human intervention, outperforming statistical and LLM-based methods and providing transparent reports.  					AI-generated summary 				 Time series forecasting is central to decision-making in do...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 42. Research on large language models reveals an asymmetric spectral scaling law in feed-forward networks, indicating that increasing width primarily adds low-energy directions while dominant modes saturate early, leading to underutilized latent space.  					AI-generated summary 				 As large language m...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 43. A new training objective, MW loss, is introduced to improve retriever calibration and ranking quality by directly optimizing the Area under the ROC Curve (AUC), outperforming Contrastive Loss in retrieval-augmented generation tasks.  					AI-generated summary 				 Dual-encoder retrievers depend on t...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 44. One-token rollout (OTR) enhances supervised fine-tuning of large language models by incorporating policy gradient methods to improve generalization using on-policy data.  					AI-generated summary 				 Supervised fine-tuning (SFT) is the predominant method for adapting large language models (LLMs), ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 45. TRAAC, an online post-training RL method, improves model accuracy and efficiency by adaptively adjusting reasoning steps based on task difficulty using self-attention.  					AI-generated summary 				 Recent thinking models solve complex reasoning tasks by scaling test-time compute, but this scaling ...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 46. AReUReDi, a discrete optimization algorithm, achieves Pareto optimality in multi-objective biomolecule sequence design, outperforming evolutionary and diffusion-based methods.  					AI-generated summary 				 Designing sequences that satisfy multiple, often conflicting, objectives is a central challe...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 47. SQUARE is a two-stage training-free framework that uses Multimodal Large Language Models to enhance zero-shot Composed Image Retrieval by enriching query embeddings and performing efficient batch reranking.  					AI-generated summary 				 Composed Image Retrieval (CIR) aims to retrieve target images...
[03.10.2025 17:10] ********************************************************************************
[03.10.2025 17:10] Abstract 48. IoT-MCP, a framework using the Model Context Protocol, enables seamless communication between Large Language Models and IoT devices, achieving high task success rates and low resource usage.  					AI-generated summary 				 The integration of Large Language Models (LLMs) with Internet-of-Things (IoT)...
[03.10.2025 17:10] Read previous papers.
[03.10.2025 17:10] Generating reviews via LLM API.
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#long_context", "#data", "#optimization", "#plp"], "emoji": "🗜️", "ru": {"title": "Умное сжатие кода для больших языковых моделей", "desc": "LongCodeZip — это специализированный фреймворк для сжатия программного кода при работе с LLM, использующий двухэтапную стратегию 
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#diffusion", "#long_context", "#video"], "emoji": "🎬", "ru": {"title": "Самообучение на длинных видео без учителя", "desc": "Исследователи предложили метод генерации длинных видео с помощью диффузионных моделей, который решает проблему накопления ошибок при авторегресс
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#reasoning", "#rl", "#optimization"], "emoji": "🎯", "ru": {"title": "Учимся на ценном опыте: эффективное обучение с подкреплением для рассуждений", "desc": "Статья представляет ExGRPO — новый фреймворк для обучения с подкреплением больших языковых моделей на задачах с п
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#security", "#benchmark", "#3d"], "emoji": "🎯", "ru": {"title": "Скрытая атака на 3D Gaussian Splatting через манипуляцию плотностью", "desc": "Исследователи проанализировали уязвимости метода 3D Gaussian Splatting (3DGS) к атакам через отравление обучающих данных. Предложен новый м
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#open_source", "#optimization"], "emoji": "🎮", "ru": {"title": "Интерактивное обучение нейросетей с вмешательством в реальном времени", "desc": "В статье представлен Interactive Training — фреймворк для обучения нейросетей с возможностью вмешательства в реальном времени
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#benchmark", "#agents"], "emoji": "📈", "ru": {"title": "LLM-агенты учатся торговать акциями, но пока проигрывают простым стратегиям", "desc": "StockBench - это новый бенчмарк для оценки больших языковых моделей (LLM) в роли автономных агентов для торгов
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#multimodal", "#rl", "#games", "#reasoning"], "emoji": "🔍", "ru": {"title": "Исследование через визуальную неопределённость для мультимодального обучения", "desc": "Статья представляет метод VOGUE, который улучшает обучение с подкреплением для мультимодальных LLM за счё
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#inference", "#hallucinations", "#interpretability", "#alignment", "#rlhf"], "emoji": "🎯", "ru": {"title": "Управление активациями: точность не гарантирует безопасность", "desc": "Исследование показывает, что activation steering — техника управления поведением LLM через добавление в
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#architecture", "#multimodal", "#open_source", "#training", "#optimization", "#dataset"], "emoji": "🔍", "ru": {"title": "Маленький, но мощный: компактный encoder побеждает гигантов в поиске документов", "desc": "Исследователи разработали ModernVBERT — компактный vision-language enco
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#rlhf", "#training", "#reasoning", "#interpretability"], "emoji": "🎯", "ru": {"title": "Скрытые состояния LLM как геометрический детектор правильности ответов", "desc": "Исследователи обнаружили, что скрытые состояния (hidden states) в больших языковых моделях содержат геометрически
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#agents", "#optimization", "#games"], "emoji": "🎯", "ru": {"title": "Масштабирование агентов через множественные попытки и умный выбор", "desc": "Статья представляет метод Behavior Best-of-N (bBoN) для повышения надежности компьютерных агентов, автоматизирующих задачи на компьютере.
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#rag", "#dataset", "#rl", "#optimization", "#multimodal", "#benchmark"], "emoji": "🗺️", "ru": {"title": "Многоступенчатое обучение с подкреплением для визуального понимания", "desc": "Статья представляет RewardMap — фреймворк для улучшения визуального понимания и рассу
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#evaluation", "#optimization", "#reasoning"], "emoji": "🔍", "ru": {"title": "Комплексная оценка агентов глубокого исследования", "desc": "Статья представляет новый бенчмарк для оценки Deep Research Agents (DRA) — AI-агентов, способных к декомпозиции задач, п
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#open_source", "#dataset", "#small_models", "#optimization"], "emoji": "🎯", "ru": {"title": "Эффективные эмбеддинги из foundation моделей без дорогостоящего предобучения", "desc": "F2LLM — это семейство language models для создания эмбеддингов размером 0.6B, 1.7B и 4B п
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#video", "#audio", "#multimodal", "#open_source", "#architecture"], "emoji": "🎬", "ru": {"title": "Единая генерация аудио и видео через синхронизацию модальностей", "desc": "Ovi — это унифицированная модель для генерации аудио и видео, которая обрабатывает обе модальности как единый
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#reasoning", "#rl", "#optimization"], "emoji": "🧠", "ru": {"title": "Учим модели думать в процессе предобучения через исследование", "desc": "В статье представлен RLP — новый подход к предобучению моделей, который интегрирует принципы reinforcement learning на этапе pre
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#dataset", "#cv", "#multimodal", "#benchmark", "#open_source", "#architecture"], "emoji": "🎯", "ru": {"title": "Региональное перетаскивание с FLUX: новый уровень точности в редактировании изображений", "desc": "DragFlow — это новый фреймворк для редактирования изображений методом пе
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#security"], "emoji": "🌳", "ru": {"title": "Автоматическое открытие многоходовых атак на языковые модели", "desc": "В статье представлена новая система DialTree-RPO, использующая методы reinforcement learning и tree search для автоматического обнаружения многоходовых
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#rlhf", "#optimization", "#hallucinations", "#reasoning", "#benchmark", "#rl"], "emoji": "🎯", "ru": {"title": "Reinforcement learning учит LLM точно находить галлюцинации в тексте", "desc": "Большие языковые модели часто генерируют галлюцинации - неподтверждённый контент, который сн
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#video", "#reasoning", "#long_context", "#architecture", "#multimodal"], "emoji": "🎬", "ru": {"title": "Разреженное внимание для понимания длинных видео", "desc": "В статье представлен VideoNSA — адаптация Native Sparse Attention для видео-языковых моделей, решающая проблему огранич
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#open_source", "#synthetic", "#agents", "#benchmark", "#dataset"], "emoji": "🦜", "ru": {"title": "Toucan: крупнейший датасет для обучения AI-агентов работе с инструментами", "desc": "Исследователи представили Toucan — самый большой публично доступный датасет для обучения LLM-агентов
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#hallucinations", "#agents", "#benchmark", "#cv"], "emoji": "❄️", "ru": {"title": "Остановить снежный ком визуальных галлюцинаций в мультиагентных системах", "desc": "Статья исследует проблему «снежного кома визуальных галлюцинаций» в мультиагентных системах на базе Visual Language 
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#data", "#hallucinations", "#science", "#dataset", "#healthcare", "#multimodal", "#benchmark", "#open_source"], "emoji": "🩻", "ru": {"title": "Клинический контекст против галлюцинаций в радиологических отчётах", "desc": "Статья представляет новый подход к автоматической генерации ст
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#data", "#optimization", "#training", "#benchmark", "#architecture"], "emoji": "🎯", "ru": {"title": "Масштабирование на этапе тестирования для авторегрессивной генерации изображений", "desc": "Статья представляет ScalingAR — первый фреймворк test-time scaling для авторегрессивной ге
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#cv", "#rl", "#agents", "#reasoning", "#optimization", "#multimodal"], "emoji": "🧩", "ru": {"title": "Обучение VLM через интерактивную сборку пазлов", "desc": "Статья представляет AGILE — фреймворк для обучения Vision-Language Models через решение задач-головоломок (jigsaw puzzles) 
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#training", "#cv", "#diffusion"], "emoji": "🎯", "ru": {"title": "Оптимальное управление для точной генерации нескольких объектов", "desc": "Статья представляет теоретический фреймворк для улучшения генерации изображений с несколькими объектами в tex
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#dataset", "#rl", "#training", "#agents"], "emoji": "🤖", "ru": {"title": "VLA с явным рассуждением для более умного управления роботами", "desc": "VLA-R1 улучшает Vision-Language-Action модели, добавляя явное пошаговое рассуждение (chain-of-thought) вме
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#graphs", "#architecture", "#dataset", "#optimization", "#science"], "emoji": "⚛️", "ru": {"title": "Трансформеры побеждают графы в молекулярном моделировании", "desc": "Исследователи показали, что обычные Transformer-модели, обученные напрямую на декартовых координатах атомов без п
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#dataset", "#architecture", "#optimization"], "emoji": "⏳", "ru": {"title": "Песочные часы для нейросетей: skip connections в широком пространстве", "desc": "Авторы предлагают архитектуру Hourglass MLP, которая инвертирует традиционный дизайн многослойных перцептронов: skip connecti
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#interpretability", "#games", "#optimization", "#cv"], "emoji": "👆", "ru": {"title": "Embeddings с визуальным взаимодействием: указывай на объекты и получай точные представления", "desc": "Представлена модель VIRTUE, которая объединяет сегментацию и visi
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#rl", "#agi", "#training", "#rlhf"], "emoji": "🎯", "ru": {"title": "Off-policy обучение для LLM: новый взгляд на REINFORCE", "desc": "Исследователи предлагают новый взгляд на алгоритм REINFORCE для обучения с подкреплением больших языковых моделей, показывая что он 
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#math", "#survey"], "emoji": "📐", "ru": {"title": "SKYLENAGE: новый сложный бенчмарк обнажает пределы математического reasoning в LLM", "desc": "Исследователи представили два новых бенчмарка SKYLENAGE для оценки математических способностей LLM: ReasoningM
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#multilingual", "#reasoning", "#low_resource", "#rlhf", "#transfer_learning"], "emoji": "🌐", "ru": {"title": "Рассуждения AI не переносятся автоматически между языками", "desc": "Исследование изучает способность больших моделей рассуждений (LRM), обученных на английском языке, перен
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#training", "#rlhf", "#rl"], "emoji": "🧩", "ru": {"title": "Абстракции рассуждений: структурированное исследование для сложных задач", "desc": "Исследователи предлагают новый подход к обучению LLM решать сложные задачи через reasoning abstractions — краткие описания пр
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#alignment", "#training", "#benchmark", "#agents", "#security"], "emoji": "🎯", "ru": {"title": "Слепое следование цели: как AI-агенты игнорируют здравый смысл ради выполнения задачи", "desc": "Исследователи обнаружили, что AI-агенты, управляющие компьютером через графи
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization", "#rl"], "emoji": "🌉", "ru": {"title": "Bridge: когда параллельные ответы LLM учатся друг у друга", "desc": "Исследователи предложили метод Bridge, который позволяет языковым моделям генерировать несколько ответов параллельно, но при этом
[03.10.2025 17:10] Querying the API.
[03.10.2025 17:10] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel methodology for privacy-preserving synthetic text generation using entity-aware control codes and HIPS theory achieves a balance between privacy and utility in sensitive domains.  					AI-generated summary 				 Text anonymization is essential for responsibly developing and deploying AI in high-stakes domains such as healthcare, social services, and law. In this work, we propose a novel methodology for privacy-preserving synthetic text generation that leverages the principles of de-identification and the Hiding In Plain Sight (HIPS) theory. Our approach introduces entity-aware control codes to guide controllable generation using either in-context learning (ICL) or prefix tuning. The ICL variant ensures privacy levels consistent with the underlying de-identification system, while the prefix tuning variant incorporates a custom masking strategy and loss function to support scalable, high-quality generation. Experiments on legal and clinical datasets demonstrate that our method achieves a strong balance between privacy protection and utility, offering a practical and effective solution for synthetic text generation in sensitive domains.
[03.10.2025 17:10] Response: ```json
{
  "title": "Синтетические тексты с контролируемой приватностью через управляющие коды",
  "desc": "Статья представляет новый метод генерации синтетических текстов, который сохраняет приватность данных в чувствительных областях, таких как медицина и юриспруденция. Подход основан на деидентификации и теории HIPS (Hiding In Plain Sight), используя специальные управляющие коды, осведомлённые о сущностях в тексте. Метод реализован в двух вариантах: через in-context learning (ICL) и через prefix tuning с кастомной функцией потерь и маскированием. Эксперименты на юридических и клинических данных показали, что метод достигает хорошего баланса между защитой приватности и полезностью сгенерированного текста.",
  "emoji": "🔒"
}
```
[03.10.2025 17:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel methodology for privacy-preserving synthetic text generation using entity-aware control codes and HIPS theory achieves a balance between privacy and utility in sensitive domains.  					AI-generated summary 				 Text anonymization is essential for responsibly developing and deploying AI in high-stakes domains such as healthcare, social services, and law. In this work, we propose a novel methodology for privacy-preserving synthetic text generation that leverages the principles of de-identification and the Hiding In Plain Sight (HIPS) theory. Our approach introduces entity-aware control codes to guide controllable generation using either in-context learning (ICL) or prefix tuning. The ICL variant ensures privacy levels consistent with the underlying de-identification system, while the prefix tuning variant incorporates a custom masking strategy and loss function to support scalable, high-quality generation. Experiments on legal and clinical datasets demonstrate that our method achieves a strong balance between privacy protection and utility, offering a practical and effective solution for synthetic text generation in sensitive domains."

[03.10.2025 17:10] Response: ```python
["DATASET", "DATA", "HEALTHCARE"]
```
[03.10.2025 17:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel methodology for privacy-preserving synthetic text generation using entity-aware control codes and HIPS theory achieves a balance between privacy and utility in sensitive domains.  					AI-generated summary 				 Text anonymization is essential for responsibly developing and deploying AI in high-stakes domains such as healthcare, social services, and law. In this work, we propose a novel methodology for privacy-preserving synthetic text generation that leverages the principles of de-identification and the Hiding In Plain Sight (HIPS) theory. Our approach introduces entity-aware control codes to guide controllable generation using either in-context learning (ICL) or prefix tuning. The ICL variant ensures privacy levels consistent with the underlying de-identification system, while the prefix tuning variant incorporates a custom masking strategy and loss function to support scalable, high-quality generation. Experiments on legal and clinical datasets demonstrate that our method achieves a strong balance between privacy protection and utility, offering a practical and effective solution for synthetic text generation in sensitive domains."

[03.10.2025 17:10] Response: ```python
["SYNTHETIC", "ETHICS"]
```
[03.10.2025 17:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new method for generating synthetic text that protects privacy while maintaining usefulness, especially in sensitive areas like healthcare and law. It uses entity-aware control codes to guide the text generation process, ensuring that sensitive information is de-identified. The methodology incorporates two techniques: in-context learning (ICL) for privacy consistency and prefix tuning with a custom masking strategy for high-quality output. Experiments show that this approach effectively balances privacy and utility, making it a valuable tool for responsible AI development.","title":"Balancing Privacy and Utility in Synthetic Text Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new method for generating synthetic text that protects privacy while maintaining usefulness, especially in sensitive areas like healthcare and law. It uses entity-aware control codes to guide the text generation process, ensuring that sensitive information is de-identified. The methodology incorporates two techniques: in-context learning (ICL) for privacy consistency and prefix tuning with a custom masking strategy for high-quality output. Experiments show that this approach effectively balances privacy and utility, making it a valuable tool for responsible AI development.', title='Balancing Privacy and Utility in Synthetic Text Generation'))
[03.10.2025 17:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新颖的方法，用于在敏感领域实现隐私保护的合成文本生成。该方法结合了去标识化原则和HIPS理论，使用实体感知控制代码来指导可控生成。通过在上下文学习和前缀调优的变体中，确保生成的文本在隐私保护和实用性之间达到良好的平衡。实验结果表明，该方法在法律和临床数据集上表现出色，提供了一种有效的合成文本生成解决方案。","title":"隐私保护与实用性的完美平衡"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新颖的方法，用于在敏感领域实现隐私保护的合成文本生成。该方法结合了去标识化原则和HIPS理论，使用实体感知控制代码来指导可控生成。通过在上下文学习和前缀调优的变体中，确保生成的文本在隐私保护和实用性之间达到良好的平衡。实验结果表明，该方法在法律和临床数据集上表现出色，提供了一种有效的合成文本生成解决方案。', title='隐私保护与实用性的完美平衡'))
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#video", "#long_context", "#rl", "#training", "#benchmark"], "emoji": "🎬", "ru": {"title": "Умное мышление над видео: анализ только нужных кадров", "desc": "FrameThinker - это новый фреймворк для улучшения рассуждений над видео контентом с помощью Large Vision-Language
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#benchmark", "#games"], "emoji": "⚖️", "ru": {"title": "Ничья в арене LLM — это не равенство моделей, а лёгкость вопроса", "desc": "Исследователи изучили систему рейтингования больших языковых моделей в arena-style оценках, где пользователи выбирают лучш
[03.10.2025 17:10] Querying the API.
[03.10.2025 17:10] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Sparse Query Attention (SQA) reduces computational complexity in Transformer models by decreasing the number of Query heads, leading to significant throughput improvements with minimal impact on model quality.  					AI-generated summary 				 The Transformer architecture, underpinned by the Multi-Head Attention (MHA) mechanism, has become the de facto standard for state-of-the-art models in artificial intelligence. However, the quadratic computational complexity of MHA with respect to sequence length presents a significant barrier to scaling, particularly for applications involving long contexts. Prevailing solutions, such as Multi-Query Attention (MQA) and Grouped-Query Attention (GQA), have effectively addressed the memory bandwidth bottleneck that dominates autoregressive inference latency by sharing Key and Value projections. While highly successful, these methods do not reduce the fundamental number of floating-point operations (FLOPs) required for the attention score computation, which remains a critical bottleneck for training and full-sequence processing. This paper introduces Sparse Query Attention (SQA), a novel attention architecture that pursues an alternative and complementary optimization path. Instead of reducing Key/Value heads, SQA reduces the number of Query heads. This architectural modification directly decreases the computational complexity of the attention mechanism by a factor proportional to the reduction in query heads, thereby lowering the overall FLOPs. This work presents the theoretical foundation of SQA, its mathematical formulation, and a family of architectural variants. Empirical benchmarks on long sequences (32k-200k tokens) demonstrate that SQA can achieve significant throughput improvements of up to 3x in computation-bound scenarios such as model pre-training, fine-tuning, and encoder-based tasks, with only a minimal impact on model quality in preliminary smallscale experiments. SQA was discovered serendipitously during the development of the upcoming Reactive Transformer architecture, suggesting its potential as a powerful tool for building more efficient and scalable models
[03.10.2025 17:10] Response: ```json
{
  "desc": "В статье представлена архитектура Sparse Query Attention (SQA), которая снижает вычислительную сложность Transformer-моделей за счёт уменьшения количества Query-головок вместо традиционного подхода с разделением Key/Value проекций. Этот метод напрямую сокращает число операций с плавающей точкой (FLOPs), что критично для обучения и обработки полных последовательностей. Эксперименты на длинных последовательностях (32-200 тысяч токенов) показывают ускорение до 3 раз в сценариях с высокой вычислительной нагрузкой при минимальном влиянии на качество модели. SQA был обнаружен случайно при разработке архитектуры Reactive Transformer и представляет собой комплементарный подход к существующим методам оптимизации внимания.",
  "emoji": "🔍",
  "title": "Меньше запросов — больше скорости: оптимизация Transformer через разреженное внимание"
}
```
[03.10.2025 17:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Sparse Query Attention (SQA) reduces computational complexity in Transformer models by decreasing the number of Query heads, leading to significant throughput improvements with minimal impact on model quality.  					AI-generated summary 				 The Transformer architecture, underpinned by the Multi-Head Attention (MHA) mechanism, has become the de facto standard for state-of-the-art models in artificial intelligence. However, the quadratic computational complexity of MHA with respect to sequence length presents a significant barrier to scaling, particularly for applications involving long contexts. Prevailing solutions, such as Multi-Query Attention (MQA) and Grouped-Query Attention (GQA), have effectively addressed the memory bandwidth bottleneck that dominates autoregressive inference latency by sharing Key and Value projections. While highly successful, these methods do not reduce the fundamental number of floating-point operations (FLOPs) required for the attention score computation, which remains a critical bottleneck for training and full-sequence processing. This paper introduces Sparse Query Attention (SQA), a novel attention architecture that pursues an alternative and complementary optimization path. Instead of reducing Key/Value heads, SQA reduces the number of Query heads. This architectural modification directly decreases the computational complexity of the attention mechanism by a factor proportional to the reduction in query heads, thereby lowering the overall FLOPs. This work presents the theoretical foundation of SQA, its mathematical formulation, and a family of architectural variants. Empirical benchmarks on long sequences (32k-200k tokens) demonstrate that SQA can achieve significant throughput improvements of up to 3x in computation-bound scenarios such as model pre-training, fine-tuning, and encoder-based tasks, with only a minimal impact on model quality in preliminary smallscale experiments. SQA was discovered serendipitously during the development of the upcoming Reactive Transformer architecture, suggesting its potential as a powerful tool for building more efficient and scalable models"

[03.10.2025 17:10] Response: ```python
['ARCHITECTURE', 'TRAINING', 'BENCHMARK']
```
[03.10.2025 17:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Sparse Query Attention (SQA) reduces computational complexity in Transformer models by decreasing the number of Query heads, leading to significant throughput improvements with minimal impact on model quality.  					AI-generated summary 				 The Transformer architecture, underpinned by the Multi-Head Attention (MHA) mechanism, has become the de facto standard for state-of-the-art models in artificial intelligence. However, the quadratic computational complexity of MHA with respect to sequence length presents a significant barrier to scaling, particularly for applications involving long contexts. Prevailing solutions, such as Multi-Query Attention (MQA) and Grouped-Query Attention (GQA), have effectively addressed the memory bandwidth bottleneck that dominates autoregressive inference latency by sharing Key and Value projections. While highly successful, these methods do not reduce the fundamental number of floating-point operations (FLOPs) required for the attention score computation, which remains a critical bottleneck for training and full-sequence processing. This paper introduces Sparse Query Attention (SQA), a novel attention architecture that pursues an alternative and complementary optimization path. Instead of reducing Key/Value heads, SQA reduces the number of Query heads. This architectural modification directly decreases the computational complexity of the attention mechanism by a factor proportional to the reduction in query heads, thereby lowering the overall FLOPs. This work presents the theoretical foundation of SQA, its mathematical formulation, and a family of architectural variants. Empirical benchmarks on long sequences (32k-200k tokens) demonstrate that SQA can achieve significant throughput improvements of up to 3x in computation-bound scenarios such as model pre-training, fine-tuning, and encoder-based tasks, with only a minimal impact on model quality in preliminary smallscale experiments. SQA was discovered serendipitously during the development of the upcoming Reactive Transformer architecture, suggesting its potential as a powerful tool for building more efficient and scalable models"

[03.10.2025 17:10] Response: ```python
["OPTIMIZATION", "LONG_CONTEXT"]
```
[03.10.2025 17:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Sparse Query Attention (SQA) is a new approach that enhances Transformer models by reducing the number of Query heads, which helps lower the computational complexity of the attention mechanism. This reduction leads to significant improvements in throughput, especially for tasks involving long sequences, without greatly affecting the model\'s performance. Unlike previous methods that focused on sharing Key and Value projections, SQA directly decreases the number of floating-point operations (FLOPs) needed for attention score calculations. Empirical results show that SQA can improve computation speed by up to 3 times in demanding scenarios, making it a promising solution for more efficient AI models.","title":"Boosting Transformer Efficiency with Sparse Query Attention"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="Sparse Query Attention (SQA) is a new approach that enhances Transformer models by reducing the number of Query heads, which helps lower the computational complexity of the attention mechanism. This reduction leads to significant improvements in throughput, especially for tasks involving long sequences, without greatly affecting the model's performance. Unlike previous methods that focused on sharing Key and Value projections, SQA directly decreases the number of floating-point operations (FLOPs) needed for attention score calculations. Empirical results show that SQA can improve computation speed by up to 3 times in demanding scenarios, making it a promising solution for more efficient AI models.", title='Boosting Transformer Efficiency with Sparse Query Attention'))
[03.10.2025 17:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"稀疏查询注意力（SQA）通过减少查询头的数量来降低Transformer模型的计算复杂性，从而在保持模型质量的同时显著提高了吞吐量。传统的多头注意力机制在处理长序列时面临二次计算复杂度的挑战，而SQA通过优化查询头的数量，直接降低了注意力机制的计算负担。该论文提供了SQA的理论基础、数学公式以及一系列架构变体的介绍。实验证明，在长序列处理时，SQA在计算密集型场景中可实现高达3倍的吞吐量提升。","title":"稀疏查询注意力：提升Transformer效率的利器"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='稀疏查询注意力（SQA）通过减少查询头的数量来降低Transformer模型的计算复杂性，从而在保持模型质量的同时显著提高了吞吐量。传统的多头注意力机制在处理长序列时面临二次计算复杂度的挑战，而SQA通过优化查询头的数量，直接降低了注意力机制的计算负担。该论文提供了SQA的理论基础、数学公式以及一系列架构变体的介绍。实验证明，在长序列处理时，SQA在计算密集型场景中可实现高达3倍的吞吐量提升。', title='稀疏查询注意力：提升Transformer效率的利器'))
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#healthcare", "#optimization", "#reasoning"], "emoji": "🏥", "ru": {"title": "Оценка качества медицинских изображений через призму человеческого восприятия и рассуждений", "desc": "MedQ-Bench — это новый benchmark для оценки качества медицинских изображен
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#data", "#optimization", "#agents", "#interpretability", "#training", "#benchmark"], "emoji": "📈", "ru": {"title": "Автоматизация прогнозов временных рядов с помощью LLM", "desc": "TimeSeriesScientist (TSci) — это новая система, основанная на LLM, которая автоматизирует прогнозирова
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization"], "emoji": "📊", "ru": {"title": "Широкие сети не значит эффективные: закон спектрального масштабирования", "desc": "Исследование показывает, что увеличение ширины feed-forward сетей в LLM добавляет преимущественно низкоэнергетические напр
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#optimization", "#rag", "#benchmark"], "emoji": "📊", "ru": {"title": "MW loss: оптимизация AUC вместо Contrastive Loss для лучшего ранжирования", "desc": "В статье представлена новая функция потерь MW loss для обучения dual-encoder retriever моделей, которая напрямую оп
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#training", "#optimization", "#benchmark", "#reasoning", "#rl"], "emoji": "🎯", "ru": {"title": "Обучение на каждом токене: когда supervised learning встречает reinforcement learning", "desc": "Статья представляет метод One-Token Rollout (OTR) для файнтюнинга больших языковых моделей
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#training", "#rl", "#optimization"], "emoji": "🎯", "ru": {"title": "Думай столько, сколько нужно: адаптивное сжатие рассуждений", "desc": "TRAAC — это метод пост-тренинга с reinforcement learning, который учит модель адаптивно регулировать длину рассуждений в зависимос
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#math"], "emoji": "🧬", "ru": {"title": "Парето-оптимальный дизайн биомолекул через дискретные потоки с отжигом", "desc": "В статье представлен AReUReDi — алгоритм дискретной оптимизации для дизайна последовательностей биомолекул с множественными целями. 
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#cv", "#reasoning", "#benchmark", "#multimodal", "#games"], "emoji": "🔍", "ru": {"title": "Двухэтапный поиск изображений по композитным запросам без обучения", "desc": "SQUARE — это framework для поиска изображений по композитным запросам (референсное изображение + текстовая модифик
[03.10.2025 17:10] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#open_source", "#benchmark", "#low_resource"], "emoji": "🌉", "ru": {"title": "Мост между LLM и IoT устройствами через единый протокол", "desc": "Статья представляет IoT-MCP — фреймворк для интеграции больших языковых моделей с IoT-устройствами через Model 
[03.10.2025 17:10] Renaming data file.
[03.10.2025 17:10] Renaming previous data. hf_papers.json to ./d/2025-10-03.json
[03.10.2025 17:10] Saving new data file.
[03.10.2025 17:10] Generating page.
[03.10.2025 17:10] Renaming previous page.
[03.10.2025 17:10] Renaming previous data. index.html to ./d/2025-10-03.html
[03.10.2025 17:10] Writing result.
[03.10.2025 17:10] Renaming log file.
[03.10.2025 17:10] Renaming previous data. log.txt to ./logs/2025-10-03_last_log.txt
