[20.11.2024 08:14] Read previous papers.
[20.11.2024 08:14] Generating top page (month).
[20.11.2024 08:14] Writing top page (month).
[20.11.2024 09:11] Read previous papers.
[20.11.2024 09:11] Get feed.
[20.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.11925
[20.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.12734
[20.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.12240
[20.11.2024 09:11] Downloading and parsing papers (pdf, html). Total: 3.
[20.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.11925.
[20.11.2024 09:11] Extra JSON file exists (./assets/json/2411.11925.json), skip PDF parsing.
[20.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.11925.json), skip HTML parsing.
[20.11.2024 09:11] Success.
[20.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.12734.
[20.11.2024 09:11] Extra JSON file exists (./assets/json/2411.12734.json), skip PDF parsing.
[20.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.12734.json), skip HTML parsing.
[20.11.2024 09:11] Success.
[20.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.12240.
[20.11.2024 09:11] Extra JSON file exists (./assets/json/2411.12240.json), skip PDF parsing.
[20.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.12240.json), skip HTML parsing.
[20.11.2024 09:11] Success.
[20.11.2024 09:11] Enriching papers with extra data.
[20.11.2024 09:11] ********************************************************************************
[20.11.2024 09:11] Abstract 0. Continuous-valued Autoregressive (AR) image generation models have demonstrated notable superiority over their discrete-token counterparts, showcasing considerable reconstruction quality and higher generation fidelity. However, the computational demands of the autoregressive framework result in sign...
[20.11.2024 09:11] ********************************************************************************
[20.11.2024 09:11] Abstract 1. Dynamic in-hand manipulation remains a challenging task for soft robotic systems that have demonstrated advantages in safe compliant interactions but struggle with high-speed dynamic tasks. In this work, we present SWIFT, a system for learning dynamic tasks using a soft and compliant robotic hand. U...
[20.11.2024 09:11] ********************************************************************************
[20.11.2024 09:11] Abstract 2. Large Language Models (LLMs) based on transformer architectures have revolutionized a variety of domains, with tokenization playing a pivotal role in their pre-processing and fine-tuning stages. In multilingual models, particularly those tailored for Indic languages, effective tokenization is crucia...
[20.11.2024 09:11] Read previous papers.
[20.11.2024 09:11] Generating reviews via LLM API.
[20.11.2024 09:11] Using data from previous issue: {"categories": ["#optimization", "#inference", "#diffusion", "#cv"], "emoji": "🖼️", "ru": {"title": "Ускорение генерации изображений: от дискретного к непрерывному", "desc": "Статья представляет новый метод ускорения генерации изображений с помощью авторегрессионных моделей с непрерывными значениями
[20.11.2024 09:11] Using data from previous issue: {"categories": ["#robotics"], "emoji": "🤖", "ru": {"title": "Мягкая роботизированная рука осваивает динамичные манипуляции", "desc": "Статья представляет систему SWIFT для обучения динамическим задачам с использованием мягкой роботизированной руки. В отличие от предыдущих подходов, система учится вр
[20.11.2024 09:11] Using data from previous issue: {"categories": ["#low_resource", "#multilingual", "#data", "#dataset"], "emoji": "🇮🇳", "ru": {"title": "SUTRA: Лидер токенизации для индийских языков в больших языковых моделях", "desc": "В статье представлен анализ токенизаторов, используемых в 12 больших языковых моделях (LLM) для 22 официальных я
[20.11.2024 09:11] Trying to get texts in Chinese.
[20.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Continuous-valued Autoregressive (AR) image generation models have demonstrated notable superiority over their discrete-token counterparts, showcasing considerable reconstruction quality and higher generation fidelity. However, the computational demands of the autoregressive framework result in significant inference overhead. While speculative decoding has proven effective in accelerating Large Language Models (LLMs), their adaptation to continuous-valued visual autoregressive models remains unexplored. This work generalizes the speculative decoding algorithm from discrete tokens to continuous space. By analyzing the intrinsic properties of output distribution, we establish a tailored acceptance criterion for the diffusion distributions prevalent in such models. To overcome the inconsistency that occurred in speculative decoding output distributions, we introduce denoising trajectory alignment and token pre-filling methods. Additionally, we identify the hard-to-sample distribution in the rejection phase. To mitigate this issue, we propose a meticulous acceptance-rejection sampling method with a proper upper bound, thereby circumventing complex integration. Experimental results show that our continuous speculative decoding achieves a remarkable 2.33times speed-up on off-the-shelf models while maintaining the output distribution. Codes will be available at https://github.com/MarkXCloud/CSpD
[20.11.2024 09:11] Mistral response. {"id": "39f5643be50e4be089e98e104f1e5109", "object": "chat.completion", "created": 1732093869, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fde\u7eed\u503c\u81ea\u56de\u5f52\uff08AR\uff09\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5c55\u793a\u4e86\u6bd4\u79bb\u6563\u7b26\u53f7\u6a21\u578b\u66f4\u9ad8\u7684\u91cd\u5efa\u8d28\u91cf\u548c\u751f\u6210\u4fdd\u771f\u5ea6\u3002\u7136\u800c\uff0c\u81ea\u56de\u5f52\u6846\u67b6\u7684\u8ba1\u7b97\u9700\u6c42\u5bfc\u81f4\u663e\u8457\u7684\u63a8\u7406\u5f00\u9500\u3002\u867d\u7136\u63a8\u6d4b\u89e3\u7801\u5df2\u88ab\u8bc1\u660e\u6709\u6548\u52a0\u901f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u5176\u5e94\u7528\u4e8e\u8fde\u7eed\u503c\u89c6\u89c9\u81ea\u56de\u5f52\u6a21\u578b\u4ecd\u672a\u88ab\u63a2\u7d22\u3002\u672c\u6587\u5c06\u63a8\u6d4b\u89e3\u7801\u7b97\u6cd5\u4ece\u79bb\u6563\u7b26\u53f7\u63a8\u5e7f\u5230\u8fde\u7eed\u7a7a\u95f4\u3002\u901a\u8fc7\u5206\u6790\u8f93\u51fa\u5206\u5e03\u7684\u5185\u5728\u7279\u6027\uff0c\u6211\u4eec\u4e3a\u8fd9\u4e9b\u6a21\u578b\u4e2d\u5e38\u89c1\u7684\u6269\u6563\u5206\u5e03\u5efa\u7acb\u4e86\u5b9a\u5236\u7684\u63a5\u53d7\u6807\u51c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6211\u4eec\u7684\u8fde\u7eed\u63a8\u6d4b\u89e3\u7801\u5728\u7ef4\u6301\u8f93\u51fa\u5206\u5e03\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u76842.33\u500d\u52a0\u901f\u3002\u4ee3\u7801\u5c06\u5728https://github.com/MarkXCloud/CSpD\u4e0a\u63d0\u4f9b\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 312, "total_tokens": 547, "completion_tokens": 235}}
[20.11.2024 09:11] Response: 连续值自回归（AR）图像生成模型展示了比离散符号模型更高的重建质量和生成保真度。然而，自回归框架的计算需求导致显著的推理开销。虽然推测解码已被证明有效加速大型语言模型（LLMs），但其应用于连续值视觉自回归模型仍未被探索。本文将推测解码算法从离散符号推广到连续空间。通过分析输出分布的内在特性，我们为这些模型中常见的扩散分布建立了定制的接受标准。实验结果显示，我们的连续推测解码在维持输出分布的同时，实现了显著的2.33倍加速。代码将在https://github.com/MarkXCloud/CSpD上提供。
[20.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

连续值自回归（AR）图像生成模型展示了比离散符号模型更高的重建质量和生成保真度。然而，自回归框架的计算需求导致显著的推理开销。虽然推测解码已被证明有效加速大型语言模型（LLMs），但其应用于连续值视觉自回归模型仍未被探索。本文将推测解码算法从离散符号推广到连续空间。通过分析输出分布的内在特性，我们为这些模型中常见的扩散分布建立了定制的接受标准。实验结果显示，我们的连续推测解码在维持输出分布的同时，实现了显著的2.33倍加速。代码将在https://github.com/MarkXCloud/CSpD上提供。
[20.11.2024 09:11] Mistral response. {"id": "98fb5c44d4ce4d7d8f29abc7a185cf88", "object": "chat.completion", "created": 1732093876, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fde\u7eed\u503c\u81ea\u56de\u5f52\uff08AR\uff09\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5c55\u793a\u4e86\u6bd4\u79bb\u6563\u7b26\u53f7\u6a21\u578b\u66f4\u9ad8\u7684\u91cd\u5efa\u8d28\u91cf\u548c\u751f\u6210\u4fdd\u771f\u5ea6\u3002\u7136\u800c\uff0c\u81ea\u56de\u5f52\u6846\u67b6\u7684\u8ba1\u7b97\u9700\u6c42\u5bfc\u81f4\u663e\u8457\u7684\u63a8\u7406\u5f00\u9500\u3002\u867d\u7136\u63a8\u6d4b\u89e3\u7801\u5df2\u88ab\u8bc1\u660e\u6709\u6548\u52a0\u901f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u5176\u5e94\u7528\u4e8e\u8fde\u7eed\u503c\u89c6\u89c9\u81ea\u56de\u5f52\u6a21\u578b\u4ecd\u672a\u88ab\u63a2\u7d22\u3002\u672c\u6587\u5c06\u63a8\u6d4b\u89e3\u7801\u7b97\u6cd5\u4ece\u79bb\u6563\u7b26\u53f7\u63a8\u5e7f\u5230\u8fde\u7eed\u7a7a\u95f4\u3002\u901a\u8fc7\u5206\u6790\u8f93\u51fa\u5206\u5e03\u7684\u5185\u5728\u7279\u6027\uff0c\u6211\u4eec\u4e3a\u8fd9\u4e9b\u6a21\u578b\u4e2d\u5e38\u89c1\u7684\u6269\u6563\u5206\u5e03\u5efa\u7acb\u4e86\u5b9a\u5236\u7684\u63a5\u53d7\u6807\u51c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6211\u4eec\u7684\u8fde\u7eed\u63a8\u6d4b\u89e3\u7801\u5728\u7ef4\u6301\u8f93\u51fa\u5206\u5e03\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u76842.33\u500d\u52a0\u901f\u3002\u4ee3\u7801\u5c06\u5728https://github.com/MarkXCloud/CSpD\u4e0a\u63d0\u4f9b\u3002\n\nli\u00e1n x\u00f9 zh\u00ed z\u00ec hu\u00ed gu\u012b (AR) t\u00fa xi\u00e0ng sh\u0113ng ch\u00e9ng m\u00f3 x\u00edng zh\u00e0n sh\u00ec le b\u01d0 l\u00ed s\u00e0n f\u00fa h\u00e0o m\u00f3 x\u00edng g\u00e8ng g\u0101o de ch\u00f3ng ji\u00e0n zh\u00ec li\u00e0ng h\u00e9 sh\u0113ng ch\u00e9ng b\u01ceo zh\u0113n d\u00f9. r\u00e1n \u00e9r, z\u00ec hu\u00ed gu\u012b ku\u00e0ng ji\u00e0 de j\u00ec su\u01cen x\u016b qi\u00fa d\u01ceo zh\u00ec xi\u01cen zh\u00f9 de tu\u012b l\u01d0 k\u0101i xi\u0101o. su\u012b r\u00e1n, tu\u012b c\u00e8 ji\u011b m\u01ce y\u01d0 b\u00e8i zh\u00e8ng m\u00edng y\u01d2u xi\u00e0o j\u00ed s\u00f9 d\u00e0 x\u00edng y\u01d4 y\u00e1n m\u00f3 x\u00edng (LLMs), d\u00e0n q\u00ed y\u00ecng y\u00f2ng y\u00fa li\u00e1n x\u00f9 zh\u00ed sh\u00ec j\u00f9 sh\u00ed z\u00ec hu\u00ed gu\u012b m\u00f3 x\u00edng r\u00e9ng w\u00e8i b\u00e8i tu\u00e0n su\u01d2. b\u011bn w\u00e9n ji\u0101ng tu\u012b c\u00e8 ji\u011b m\u01ce su\u00e0n f\u01ce c\u00f3ng l\u00ed s\u00e0n f\u00fa h\u00e0o tu\u012b gu\u01ceng d\u00e0o li\u00e1n x\u00f9 k\u014dng ji\u0101n. t\u014dng gu\u00f2 f\u0113n x\u012b ch\u016b zh\u00ec f\u0113n b\u00f9 de n\u00e8i z\u00e0i t\u00e8 x\u00ecng, w\u01d2 men w\u00e8i zh\u00e8 xi\u0113 m\u00f3 x\u00edng zh\u014dng ch\u00e1ng ji\u00e0n de ku\u00f2 s\u00e0n f\u0113n b\u00f9 ji\u00e0n l\u00ec le d\u00ecng zh\u00ec de ji\u0113 sh\u00f2u bi\u0101o zh\u01d4n. sh\u00ed y\u00e0n ji\u00e9 gu\u01d2 xi\u01cen sh\u00ec, w\u01d2 men de li\u00e1n x\u00f9 tu\u012b c\u00e8 ji\u011b m\u01ce z\u00e0i w\u00e9i ch\u00ed ch\u016b zh\u00ec f\u0113n b\u00f9 de t\u00f3ng sh\u00ed, sh\u00ed xi\u00e0n le xi\u01cen zh\u00f9 de 2.33 b\u00e8i j\u00ed s\u00f9. d\u00e0i m\u01ce ji\u0101ng z\u00e0i https://github.com/MarkXCloud/CSpD sh\u00e0ng t\u00ed g\u014dng.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 250, "total_tokens": 1009, "completion_tokens": 759}}
[20.11.2024 09:11] Response: 连续值自回归（AR）图像生成模型展示了比离散符号模型更高的重建质量和生成保真度。然而，自回归框架的计算需求导致显著的推理开销。虽然推测解码已被证明有效加速大型语言模型（LLMs），但其应用于连续值视觉自回归模型仍未被探索。本文将推测解码算法从离散符号推广到连续空间。通过分析输出分布的内在特性，我们为这些模型中常见的扩散分布建立了定制的接受标准。实验结果显示，我们的连续推测解码在维持输出分布的同时，实现了显著的2.33倍加速。代码将在https://github.com/MarkXCloud/CSpD上提供。

lián xù zhí zì huí guī (AR) tú xiàng shēng chéng mó xíng zhàn shì le bǐ lí sàn fú hào mó xíng gèng gāo de chóng jiàn zhì liàng hé shēng chéng bǎo zhēn dù. rán ér, zì huí guī kuàng jià de jì suǎn xū qiú dǎo zhì xiǎn zhù de tuī lǐ kāi xiāo. suī rán, tuī cè jiě mǎ yǐ bèi zhèng míng yǒu xiào jí sù dà xíng yǔ yán mó xíng (LLMs), dàn qí yìng yòng yú lián xù zhí shì jù shí zì huí guī mó xíng réng wèi bèi tuàn suǒ. běn wén jiāng tuī cè jiě mǎ suàn fǎ cóng lí sàn fú hào tuī guǎng dào lián xù kōng jiān. tōng guò fēn xī chū zhì fēn bù de nèi zài tè xìng, wǒ men wèi zhè xiē mó xíng zhōng cháng jiàn de kuò sàn fēn bù jiàn lì le dìng zhì de jiē shòu biāo zhǔn. shí yàn jié guǒ xiǎn shì, wǒ men de lián xù tuī cè jiě mǎ zài wéi chí chū zhì fēn bù de tóng shí, shí xiàn le xiǎn zhù de 2.33 bèi jí sù. dài mǎ jiāng zài https://github.com/MarkXCloud/CSpD shàng tí gōng.
[20.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

连续值自回归（AR）图像生成模型展示了比离散符号模型更高的重建质量和生成保真度。然而，自回归框架的计算需求导致显著的推理开销。虽然推测解码已被证明有效加速大型语言模型（LLMs），但其应用于连续值视觉自回归模型仍未被探索。本文将推测解码算法从离散符号推广到连续空间。通过分析输出分布的内在特性，我们为这些模型中常见的扩散分布建立了定制的接受标准。实验结果显示，我们的连续推测解码在维持输出分布的同时，实现了显著的2.33倍加速。代码将在https://github.com/MarkXCloud/CSpD上提供。
[20.11.2024 09:11] Mistral response. {"id": "765dc9f209f543068bb92d2131ef80ab", "object": "chat.completion", "created": 1732093897, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[{'word': '\u8fde\u7eed\u503c', 'pinyin': 'li\u00e1n x\u00f9 zh\u00ed', 'trans': 'continuous value'},\n{'word': '\u81ea\u56de\u5f52', 'pinyin': 'z\u00ec hu\u00ed gu\u012b', 'trans': 'autoregressive'},\n{'word': '\u5c55\u793a', 'pinyin': 'zh\u01cen sh\u00ec', 'trans': 'demonstrate'},\n{'word': '\u79bb\u6563', 'pinyin': 'l\u00ed s\u00e0n', 'trans': 'discrete'},\n{'word': '\u7b26\u53f7', 'pinyin': 'f\u00fa h\u00e0o', 'trans': 'symbol'},\n{'word': '\u91cd\u5efa', 'pinyin': 'ch\u00f3ng ji\u00e0n', 'trans': 'reconstruction'},\n{'word': '\u8d28\u91cf', 'pinyin': 'zh\u00ec li\u00e0ng', 'trans': 'quality'},\n{'word': '\u751f\u6210', 'pinyin': 'sh\u0113ng ch\u00e9ng', 'trans': 'generation'},\n{'word': '\u4fdd\u771f\u5ea6', 'pinyin': 'b\u01ceo zh\u0113n d\u00f9', 'trans': 'fidelity'},\n{'word': '\u6846\u67b6', 'pinyin': 'ku\u00e0ng ji\u00e0', 'trans': 'framework'},\n{'word': '\u8ba1\u7b97', 'pinyin': 'j\u00ec su\u00e0n', 'trans': 'computation'},\n{'word': '\u9700\u6c42', 'pinyin': 'x\u016b qi\u00fa', 'trans': 'demand'},\n{'word': '\u5bfc\u81f4', 'pinyin': 'd\u01ceo zh\u00ec', 'trans': 'result in'},\n{'word': '\u663e\u8457', 'pinyin': 'xi\u01cen zh\u00f9', 'trans': 'significant'},\n{'word': '\u63a8\u7406', 'pinyin': 'tu\u012b l\u01d0', 'trans': 'inference'},\n{'word': '\u5f00\u9500', 'pinyin': 'k\u0101i xi\u0101o', 'trans': 'cost'},\n{'word': '\u63a8\u6d4b', 'pinyin': 'tu\u012b c\u00e8', 'trans': 'speculative'},\n{'word': '\u89e3\u7801', 'pinyin': 'ji\u011b m\u01ce', 'trans': 'decoding'},\n{'word': '\u52a0\u901f', 'pinyin': 'ji\u0101 s\u00f9', 'trans': 'accelerate'},\n{'word': '\u8bed\u8a00', 'pinyin': 'y\u01d4 y\u00e1n', 'trans': 'language'},\n{'word': '\u6a21\u578b', 'pinyin': 'm\u00f3 x\u00edng', 'trans': 'model'},\n{'word': '\u5e94\u7528', 'pinyin': 'y\u00ecng y\u00f2ng', 'trans': 'application'},\n{'word': '\u89c6\u89c9', 'pinyin': 'sh\u00ec ju\u00e9', 'trans': 'visual'},\n{'word': '\u63a8\u5e7f', 'pinyin': 'tu\u012b gu\u01ceng', 'trans': 'extend'},\n{'word': '\u7a7a\u95f4', 'pinyin': 'k\u014dng ji\u0101n', 'trans': 'space'},\n{'word': '\u5206\u6790', 'pinyin': 'f\u0113n x\u012b', 'trans': 'analysis'},\n{'word': '\u8f93\u51fa', 'pinyin': 'sh\u016b ch\u016b', 'trans': 'output'},\n{'word': '\u5206\u5e03', 'pinyin': 'f\u0113n b\u00f9', 'trans': 'distribution'},\n{'word': '\u5185\u5728', 'pinyin': 'n\u00e8i z\u00e0i', 'trans': 'intrinsic'},\n{'word': '\u7279\u6027', 'pinyin': 't\u00e8 x\u00ecng', 'trans': 'characteristic'},\n{'word': '\u6269\u6563', 'pinyin': 'ku\u00f2 s\u00e0n', 'trans': 'diffusion'},\n{'word': '\u5efa\u7acb', 'pinyin': 'ji\u00e0n l\u00ec', 'trans': 'establish'},\n{'word': '\u5b9a\u5236', 'pinyin': 'd\u00ecng zh\u00ec', 'trans': 'custom'},\n{'word': '\u63a5\u53d7', 'pinyin': 'ji\u0113 sh\u00f2u', 'trans': 'acceptance'},\n{'word': '\u6807\u51c6', 'pinyin': 'bi\u0101o zh\u01d4n', 'trans': 'standard'},\n{'word': '\u5b9e\u9a8c', 'pinyin': 'sh\u00ed y\u00e0n', 'trans': 'experiment'},\n{'word': '\u7ed3\u679c', 'pinyin': 'ji\u00e9 gu\u01d2', 'trans': 'result'},\n{'word': '\u7ef4\u6301', 'pinyin': 'w\u00e9i ch\u00ed', 'trans': 'maintain'},\n{'word': '\u5b9e\u73b0', 'pinyin': 'sh\u00ed xi\u00e0n', 'trans': 'achieve'},\n{'word': '\u4ee3\u7801', 'pinyin': 'd\u00e0i m\u01ce', 'trans': 'code'},\n{'word': '\u63d0\u4f9b', 'pinyin': 't\u00ed g\u014dng', 'trans': 'provide'}]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 282, "total_tokens": 1401, "completion_tokens": 1119}}
[20.11.2024 09:11] Response: [{'word': '连续值', 'pinyin': 'lián xù zhí', 'trans': 'continuous value'},
{'word': '自回归', 'pinyin': 'zì huí guī', 'trans': 'autoregressive'},
{'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'},
{'word': '离散', 'pinyin': 'lí sàn', 'trans': 'discrete'},
{'word': '符号', 'pinyin': 'fú hào', 'trans': 'symbol'},
{'word': '重建', 'pinyin': 'chóng jiàn', 'trans': 'reconstruction'},
{'word': '质量', 'pinyin': 'zhì liàng', 'trans': 'quality'},
{'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generation'},
{'word': '保真度', 'pinyin': 'bǎo zhēn dù', 'trans': 'fidelity'},
{'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'},
{'word': '计算', 'pinyin': 'jì suàn', 'trans': 'computation'},
{'word': '需求', 'pinyin': 'xū qiú', 'trans': 'demand'},
{'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'result in'},
{'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'},
{'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'},
{'word': '开销', 'pinyin': 'kāi xiāo', 'trans': 'cost'},
{'word': '推测', 'pinyin': 'tuī cè', 'trans': 'speculative'},
{'word': '解码', 'pinyin': 'jiě mǎ', 'trans': 'decoding'},
{'word': '加速', 'pinyin': 'jiā sù', 'trans': 'accelerate'},
{'word': '语言', 'pinyin': 'yǔ yán', 'trans': 'language'},
{'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'},
{'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'application'},
{'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'},
{'word': '推广', 'pinyin': 'tuī guǎng', 'trans': 'extend'},
{'word': '空间', 'pinyin': 'kōng jiān', 'trans': 'space'},
{'word': '分析', 'pinyin': 'fēn xī', 'trans': 'analysis'},
{'word': '输出', 'pinyin': 'shū chū', 'trans': 'output'},
{'word': '分布', 'pinyin': 'fēn bù', 'trans': 'distribution'},
{'word': '内在', 'pinyin': 'nèi zài', 'trans': 'intrinsic'},
{'word': '特性', 'pinyin': 'tè xìng', 'trans': 'characteristic'},
{'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'},
{'word': '建立', 'pinyin': 'jiàn lì', 'trans': 'establish'},
{'word': '定制', 'pinyin': 'dìng zhì', 'trans': 'custom'},
{'word': '接受', 'pinyin': 'jiē shòu', 'trans': 'acceptance'},
{'word': '标准', 'pinyin': 'biāo zhǔn', 'trans': 'standard'},
{'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'},
{'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'},
{'word': '维持', 'pinyin': 'wéi chí', 'trans': 'maintain'},
{'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'},
{'word': '代码', 'pinyin': 'dài mǎ', 'trans': 'code'},
{'word': '提供', 'pinyin': 'tí gōng', 'trans': 'provide'}]
[20.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

连续值自回归（AR）图像生成模型展示了比离散符号模型更高的重建质量和生成保真度。然而，自回归框架的计算需求导致显著的推理开销。虽然推测解码已被证明有效加速大型语言模型（LLMs），但其应用于连续值视觉自回归模型仍未被探索。本文将推测解码算法从离散符号推广到连续空间。通过分析输出分布的内在特性，我们为这些模型中常见的扩散分布建立了定制的接受标准。实验结果显示，我们的连续推测解码在维持输出分布的同时，实现了显著的2.33倍加速。代码将在https://github.com/MarkXCloud/CSpD上提供。
[20.11.2024 09:11] Mistral response. {"id": "56620331f4a34f14b000ff433a545b42", "object": "chat.completion", "created": 1732093912, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "Continuous-valued autoregressive (AR) image generation models have demonstrated higher reconstruction quality and generative fidelity compared to discrete symbol models. However, the computational requirements of the autoregressive framework result in significant inference overhead. While speculative decoding has been proven effective in accelerating large language models (LLMs), its application to continuous-valued visual autoregressive models has not been explored. This paper extends the speculative decoding algorithm from discrete symbols to continuous space. By analyzing the intrinsic properties of the output distribution, we establish custom acceptance criteria for the diffusion distributions commonly found in these models. Experimental results show that our continuous speculative decoding achieves a significant 2.33-fold speedup while maintaining the output distribution. The code will be available at https://github.com/MarkXCloud/CSpD.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 248, "total_tokens": 430, "completion_tokens": 182}}
[20.11.2024 09:11] Response: Continuous-valued autoregressive (AR) image generation models have demonstrated higher reconstruction quality and generative fidelity compared to discrete symbol models. However, the computational requirements of the autoregressive framework result in significant inference overhead. While speculative decoding has been proven effective in accelerating large language models (LLMs), its application to continuous-valued visual autoregressive models has not been explored. This paper extends the speculative decoding algorithm from discrete symbols to continuous space. By analyzing the intrinsic properties of the output distribution, we establish custom acceptance criteria for the diffusion distributions commonly found in these models. Experimental results show that our continuous speculative decoding achieves a significant 2.33-fold speedup while maintaining the output distribution. The code will be available at https://github.com/MarkXCloud/CSpD.
[20.11.2024 09:11] Renaming data file.
[20.11.2024 09:11] Renaming previous data. hf_papers.json to ./d/2024-11-20.json
[20.11.2024 09:11] Saving new data file.
[20.11.2024 09:11] Generating page.
[20.11.2024 09:11] Renaming previous page.
[20.11.2024 09:11] Renaming previous data. index.html to ./d/2024-11-20.html
[20.11.2024 09:11] [Experimental] Generating Chinese page for reading.
[20.11.2024 09:11] Chinese vocab [{'word': '连续值', 'pinyin': 'lián xù zhí', 'trans': 'continuous value'}, {'word': '自回归', 'pinyin': 'zì huí guī', 'trans': 'autoregressive'}, {'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'}, {'word': '离散', 'pinyin': 'lí sàn', 'trans': 'discrete'}, {'word': '符号', 'pinyin': 'fú hào', 'trans': 'symbol'}, {'word': '重建', 'pinyin': 'chóng jiàn', 'trans': 'reconstruction'}, {'word': '质量', 'pinyin': 'zhì liàng', 'trans': 'quality'}, {'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generation'}, {'word': '保真度', 'pinyin': 'bǎo zhēn dù', 'trans': 'fidelity'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '计算', 'pinyin': 'jì suàn', 'trans': 'computation'}, {'word': '需求', 'pinyin': 'xū qiú', 'trans': 'demand'}, {'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'result in'}, {'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '开销', 'pinyin': 'kāi xiāo', 'trans': 'cost'}, {'word': '推测', 'pinyin': 'tuī cè', 'trans': 'speculative'}, {'word': '解码', 'pinyin': 'jiě mǎ', 'trans': 'decoding'}, {'word': '加速', 'pinyin': 'jiā sù', 'trans': 'accelerate'}, {'word': '语言', 'pinyin': 'yǔ yán', 'trans': 'language'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'application'}, {'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'}, {'word': '推广', 'pinyin': 'tuī guǎng', 'trans': 'extend'}, {'word': '空间', 'pinyin': 'kōng jiān', 'trans': 'space'}, {'word': '分析', 'pinyin': 'fēn xī', 'trans': 'analysis'}, {'word': '输出', 'pinyin': 'shū chū', 'trans': 'output'}, {'word': '分布', 'pinyin': 'fēn bù', 'trans': 'distribution'}, {'word': '内在', 'pinyin': 'nèi zài', 'trans': 'intrinsic'}, {'word': '特性', 'pinyin': 'tè xìng', 'trans': 'characteristic'}, {'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '建立', 'pinyin': 'jiàn lì', 'trans': 'establish'}, {'word': '定制', 'pinyin': 'dìng zhì', 'trans': 'custom'}, {'word': '接受', 'pinyin': 'jiē shòu', 'trans': 'acceptance'}, {'word': '标准', 'pinyin': 'biāo zhǔn', 'trans': 'standard'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '维持', 'pinyin': 'wéi chí', 'trans': 'maintain'}, {'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'}, {'word': '代码', 'pinyin': 'dài mǎ', 'trans': 'code'}, {'word': '提供', 'pinyin': 'tí gōng', 'trans': 'provide'}]
[20.11.2024 09:11] Renaming previous Chinese page.
[20.11.2024 09:11] Renaming previous data. zh.html to ./d/2024-11-19_zh_reading_task.html
[20.11.2024 09:11] Writing Chinese reading task.
[20.11.2024 09:11] Writing result.
[20.11.2024 09:11] Renaming log file.
[20.11.2024 09:11] Renaming previous data. log.txt to ./logs/2024-11-20_last_log.txt
