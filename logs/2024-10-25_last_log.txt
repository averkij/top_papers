[24.10.2024 22:11] [Experimental] Generating an image for paper MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models.
[24.10.2024 22:11] [Experimental] Image for paper MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models already exists.
[25.10.2024 00:58] Read previous papers.
[25.10.2024 00:58] Get feed.
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17637
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.18072
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.18013
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17891
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.18084
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17883
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17434
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13924
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13458
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.15522
[25.10.2024 00:58] Get page data from previous paper. URL: https://huggingface.co/papers/2410.18071
[25.10.2024 00:58] Extract page data from URL. URL: https://huggingface.co/papers/2410.13816
[25.10.2024 00:58] Extract page data from URL. URL: https://huggingface.co/papers/2410.17242
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 0. Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing optimization algorithms like direct preference optimization (DPO). Existi...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 1. Recent advancements in predictive models have demonstrated exceptional capabilities in predicting the future state of objects and scenes. However, the lack of categorization based on inherent characteristics continues to hinder the progress of predictive model development. Additionally, existing ben...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 2. Direct Preference Optimization (DPO) has emerged as a powerful approach to align text-to-image (T2I) models with human feedback. Unfortunately, successful application of DPO to T2I models requires a huge amount of resources to collect and label large-scale datasets, e.g., millions of generated paire...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 3. Diffusion Language Models (DLMs) have emerged as a promising new paradigm for text generative modeling, potentially addressing limitations of autoregressive (AR) models. However, current DLMs have been studied at a smaller scale compared to their AR counterparts and lack fair comparison on language ...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 4. LiDAR scene generation has been developing rapidly recently. However, existing methods primarily focus on generating static and single-frame scenes, overlooking the inherently dynamic nature of real-world driving environments. In this work, we introduce DynamicCity, a novel 4D LiDAR generation frame...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 5. This paper introduces a novel mobile phone control architecture, termed ``app agents", for efficient interactions and controls across various Android apps. The proposed Lightweight Multi-modal App Control (LiMAC) takes as input a textual goal and a sequence of past mobile observations, such as scree...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 6. Multimodal Large Language Models (MLLMs) have shown promising progress in understanding and analyzing video content. However, processing long videos remains a significant challenge constrained by LLM's context size. To address this limitation, we propose LongVU, a spatiotemporal adaptive compression...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 7. The performance of neural networks scales with both their size and the amount of data they have been trained on. This is shown in both language and image generation. However, this requires scaling-friendly network architectures as well as large-scale datasets. Even though scaling-friendly architectu...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 8. The integration of large language model (LLM) techniques in the field of medical analysis has brought about significant advancements, yet the scarcity of large, diverse, and well-annotated datasets remains a major challenge. Medical data and tasks, which vary in format, size, and other parameters, r...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 9. Reward models (RMs) have driven the state-of-the-art performance of LLMs today by enabling the integration of human feedback into the language modeling process. However, RMs are primarily trained and evaluated in English, and their capabilities in multilingual settings remain largely understudied. I...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 10. Recently, multimodal large language models (MLLMs) have received much attention for their impressive capabilities. The evaluation of MLLMs is becoming critical to analyzing attributes of MLLMs and providing valuable insights. However, current benchmarks overlook the problem of prompt sensitivity - m...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 11. Large, general-purpose robotic policies trained on diverse demonstration datasets have been shown to be remarkably effective both for controlling a variety of robots in a range of different scenes, and for acquiring broad repertoires of manipulation skills. However, the data that such policies are t...
[25.10.2024 00:58] ********************************************************************************
[25.10.2024 00:58] Abstract 12. We propose the Large View Synthesis Model (LVSM), a novel transformer-based approach for scalable and generalizable novel view synthesis from sparse-view inputs. We introduce two architectures: (1) an encoder-decoder LVSM, which encodes input image tokens into a fixed number of 1D latent tokens, fun...
[25.10.2024 00:58] Read previous papers.
[25.10.2024 00:58] Generating reviews via LLM API.
[25.10.2024 00:58] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LVLM) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º MIA-DPO. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–Ω–æ–≥–æ–∏–∑–æ–±—Ä–∞–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ –≤—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, —Ä–µ—à–∞—è –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Ö–≤–∞—Ç–∫–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. MIA-DPO —Ä–∞—Å—à–∏—Ä—è–µ—Ç –æ–¥–Ω–æ–∑–æ–±—Ä–∞–∂–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –¥–æ–±–∞–≤–ª—è—è 
[25.10.2024 00:58] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –Ω–∞–∑—ã–≤–∞–µ–º—ã–π WorldSimBench. –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —è–≤–Ω—É—é –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏ –Ω–µ—è–≤–Ω—É—é –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—É—é –æ—Ü–µ–Ω–∫—É, –æ—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–µ —Ç—Ä–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è: –æ—Ç–∫—Ä—ã—Ç—É—é —Å—Ä–µ–¥—É, –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –≤–æ–∂–¥–µ–Ω–∏–µ –∏ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫—É. –ê–≤—Ç–æ—Ä—ã –≤–≤–æ–¥—è—Ç –¥–∞—Ç–∞—Å–µ—Ç HF-Embodied
[25.10.2024 00:58] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é (text-to-image). –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–º Direct Preference Optimization (DPO), —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å —Ç—Ä—É–¥–æ–µ–º–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–±–æ—Ä–∞ –ø—Ä–µ–¥–ø–æ—á
[25.10.2024 00:58] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (DLM), –∞–¥–∞–ø—Ç–∏—Ä—É—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏. –û–Ω–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —Å–≤—è–∑—å –º–µ–∂–¥—É —Ü–µ–ª–µ–≤—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –≤–≤–æ–¥—è—Ç –º–µ—Ç–æ–¥ –¥–æ–æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è DLM. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞
[25.10.2024 00:58] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç DynamicCity - –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö 4D LiDAR —Å—Ü–µ–Ω. –û—Å–Ω–æ–≤—É —Å–∏—Å—Ç–µ–º—ã —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç VAE –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ 4D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è HexPlane –∏ DiT-based –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ HexPlane. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ä—è–¥ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤, –≤–∫–ª—é—á–∞—è Pro
[25.10.2024 00:58] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–±–∏–ª—å–Ω—ã–º–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º 'app agents'. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ LiMAC –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ü–µ–ª—å –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π. –ê–≤—Ç–æ—Ä—ã –≤–≤–æ–¥—è—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π Action Transformer (AcT) –≤ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ 
[25.10.2024 00:58] Using data from previous issue: {"desc": "LongVU - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ö–∞–Ω–∏–∑–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Å–∂–∞—Ç–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (MLLM). –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—Ä–æ—Å—Å-–º–æ–¥–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –º–µ–∂–∫–∞–¥—Ä–æ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ –≤–∏–¥–µ–æ. LongVU –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ DINOv2 –¥
[25.10.2024 00:58] Using data from previous issue: {"desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç ARKit LabelMaker - –ø–µ—Ä–≤—ã–π –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∞–ª—å–Ω–æ–≥–æ –º–∏—Ä–∞ —Å –ø–ª–æ—Ç–Ω—ã–º–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ –¥–ª—è –∑–∞–¥–∞—á 3D-–∑—Ä–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Ä–∞—Å—à–∏—Ä–∏–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç LabelMaker, —á—Ç–æ–±—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ –±–æ–ª—å—à–∏—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö. –û–Ω–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ —Å–æ
[25.10.2024 00:58] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MedINST - –Ω–æ–≤—ã–π –º–µ—Ç–∞-–¥–∞—Ç–∞—Å–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –æ–±–ª–∞—Å—Ç–∏ –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. MedINST –≤–∫–ª—é—á–∞–µ—Ç 133 –∑–∞–¥–∞—á–∏ –∏ –±–æ–ª–µ–µ 7 –º–∏–ª–ª–∏–æ–Ω–æ–≤ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ —Å–∞–º—ã–º –æ–±—à–∏—Ä–Ω—ã–º –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–æ–Ω–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º –Ω
[25.10.2024 00:58] Using data from previous issue: {"desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è (reward models) –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –ø–µ—Ä–≤—ã–π –≤ —Å–≤–æ–µ–º —Ä–æ–¥–µ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö M-RewardBench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–∞–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ 23 —Ç–∏–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö. –ü—Ä–æ–≤–µ–¥—è —Ç—â–∞—Ç–µ–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
[25.10.2024 00:58] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫ –ø—Ä–æ–º–ø—Ç–∞–º –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (MLLM). –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏ TP-Eval, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–æ–¥ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –æ—Ü–µ–Ω–∫–∏ –∏ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –º–æ–¥–µ–ª–µ–π. TP-Eval –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã
[25.10.2024 00:58] Querying the API.
[25.10.2024 00:58] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large, general-purpose robotic policies trained on diverse demonstration datasets have been shown to be remarkably effective both for controlling a variety of robots in a range of different scenes, and for acquiring broad repertoires of manipulation skills. However, the data that such policies are trained on is generally of mixed quality -- not only are human-collected demonstrations unlikely to perform the task perfectly, but the larger the dataset is, the harder it is to curate only the highest quality examples. It also remains unclear how optimal data from one embodiment is for training on another embodiment. In this paper, we present a general and broadly applicable approach that enhances the performance of such generalist robot policies at deployment time by re-ranking their actions according to a value function learned via offline RL. This approach, which we call Value-Guided Policy Steering (V-GPS), is compatible with a wide range of different generalist policies, without needing to fine-tune or even access the weights of the policy. We show that the same value function can improve the performance of five different state-of-the-art policies with different architectures, even though they were trained on distinct datasets, attaining consistent performance improvement on multiple robotic platforms across a total of 12 tasks. Code and videos can be found at: https://nakamotoo.github.io/V-GPS
[25.10.2024 00:58] Response: {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Value-Guided Policy Steering (V-GPS) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –æ–±–æ–±—â–µ–Ω–Ω—ã—Ö —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–∏—Ç–∏–∫. V-GPS –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é —Ü–µ–Ω–Ω–æ—Å—Ç–∏, –æ–±—É—á–µ–Ω–Ω—É—é —Å –ø–æ–º–æ—â—å—é –æ—Ñ—Ñ–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –¥–ª—è –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª–∏—Ç–∏–∫–∏ –≤–æ –≤—Ä–µ–º—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è. –ú–µ—Ç–æ–¥ —Å–æ–≤–º–µ—Å—Ç–∏–º —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –ø–æ–ª–∏—Ç–∏–∫ –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∏—Ö –≤–µ—Å–∞–º –∏–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ V-GPS —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—è—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–ª–∏—Ç–∏–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏ –Ω–∞ 12 –∑–∞–¥–∞—á–∞—Ö –∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö.",
  "emoji": "ü§ñ",
  "title": "–£–ª—É—á—à–µ–Ω–∏–µ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–∏—Ç–∏–∫ –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"
}
[25.10.2024 00:58] OpenAI request. Model: gpt-4o-mini. Prompt: You are an expert classifier of machine learning research papers. Analyze the following research paper text and classify it into one or more relevant categories from the list below. Consider the paper's main contributions, methodologies, and applications.

Categories:
1. DATASET: Papers that introduce new datasets or make significant modifications to existing ones
2. DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
3. BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
4. AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
5. CV: Papers developing computer vision methods or visual processing systems
6. RL: Papers investigating reinforcement learning theory or applications
7. RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
8. RAG: Papers advancing retrieval-augmented generation techniques
9. PLP: Papers about Programming Language Processing models or programming benchmarks
10. INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
11. 3D: Papers on 3D content generation, processing, or understanding
12. AUDIO: Papers advancing speech/audio processing or generation
13. VIDEO: Papers on video analysis, generation, or understanding
14. MULTIMODAL: Papers combining multiple input/output modalities
15. MATH: Papers focused on mathematical theory and algorithms
16. MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities
17. ARCHITECTURE: Papers proposing novel neural architectures or components
18. MEDICINE: Papers applying ML to medical/healthcare domains
19. TRAINING: Papers improving model training or fine-tuning methods
20. ROBOTICS: Papers on robotic systems and embodied AI
21. AGI: Papers discussing artificial general intelligence concepts
22. GAMES: Papers applying ML to games or game development
23. INTERPRETABILITY: Papers analyzing model behavior and explanations
24. REASONING: Papers enhancing logical reasoning capabilities
25. TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
26. GRAPHS: Papers advancing graph neural networks and applications
27. ETHICS: Papers addressing AI ethics, fairness, and bias
28. SECURITY: Papers on model security and adversarial robustness
29. QUANTUM: Papers combining quantum computing and ML
30. EDGE_COMPUTING: Papers on ML deployment for resource-constrained devices
31. OPTIMIZATION: Papers advancing training optimization methods
32. SURVEY: Papers comprehensively reviewing research areas
33. DIFFUSION: Papers on diffusion-based generative models
34. ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
35. STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
36. HALLUCINATION: Papers about the hallucinations in language models, hallucinations analysis and mitigation

Return only JSON with flat array of categories that match the given text.

Paper text to classify:

"Large, general-purpose robotic policies trained on diverse demonstration datasets have been shown to be remarkably effective both for controlling a variety of robots in a range of different scenes, and for acquiring broad repertoires of manipulation skills. However, the data that such policies are trained on is generally of mixed quality -- not only are human-collected demonstrations unlikely to perform the task perfectly, but the larger the dataset is, the harder it is to curate only the highest quality examples. It also remains unclear how optimal data from one embodiment is for training on another embodiment. In this paper, we present a general and broadly applicable approach that enhances the performance of such generalist robot policies at deployment time by re-ranking their actions according to a value function learned via offline RL. This approach, which we call Value-Guided Policy Steering (V-GPS), is compatible with a wide range of different generalist policies, without needing to fine-tune or even access the weights of the policy. We show that the same value function can improve the performance of five different state-of-the-art policies with different architectures, even though they were trained on distinct datasets, attaining consistent performance improvement on multiple robotic platforms across a total of 12 tasks. Code and videos can be found at: https://nakamotoo.github.io/V-GPS"

[25.10.2024 00:58] Response: ```json
["AGENTS", "RL", "TRAINING", "ROBOTICS"]
```
[25.10.2024 00:58] Get embedding for a paper via LLM API.
[25.10.2024 00:58] Querying the API.
[25.10.2024 00:58] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We propose the Large View Synthesis Model (LVSM), a novel transformer-based approach for scalable and generalizable novel view synthesis from sparse-view inputs. We introduce two architectures: (1) an encoder-decoder LVSM, which encodes input image tokens into a fixed number of 1D latent tokens, functioning as a fully learned scene representation, and decodes novel-view images from them; and (2) a decoder-only LVSM, which directly maps input images to novel-view outputs, completely eliminating intermediate scene representations. Both models bypass the 3D inductive biases used in previous methods -- from 3D representations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar projections, plane sweeps) -- addressing novel view synthesis with a fully data-driven approach. While the encoder-decoder model offers faster inference due to its independent latent representation, the decoder-only LVSM achieves superior quality, scalability, and zero-shot generalization, outperforming previous state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive evaluations across multiple datasets demonstrate that both LVSM variants achieve state-of-the-art novel view synthesis quality. Notably, our models surpass all previous methods even with reduced computational resources (1-2 GPUs). Please see our website for more details: https://haian-jin.github.io/projects/LVSM/ .
[25.10.2024 00:58] Response: {
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å–∏–Ω—Ç–µ–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –±–æ–ª—å—à–∏—Ö —Ä–∞–∫—É—Ä—Å–æ–≤ (LVSM), –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞—Ö. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω—ã –¥–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä –∏ —Ç–æ–ª—å–∫–æ –¥–µ–∫–æ–¥–µ—Ä, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Ö–æ–¥—è—Ç—Å—è –±–µ–∑ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö 3D-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π. –ú–æ–¥–µ–ª–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –æ–±–æ–±—â–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏. LVSM –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞ 1.5-3.5 –¥–ë –ø–æ –º–µ—Ç—Ä–∏–∫–µ PSNR –ø—Ä–∏ –º–µ–Ω—å—à–∏—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç–∞—Ö.",
  "emoji": "üñºÔ∏è",
  "title": "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –ø–æ–∫–æ—Ä—è—é—Ç —Å–∏–Ω—Ç–µ–∑ –Ω–æ–≤—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤"
}
[25.10.2024 00:58] OpenAI request. Model: gpt-4o-mini. Prompt: You are an expert classifier of machine learning research papers. Analyze the following research paper text and classify it into one or more relevant categories from the list below. Consider the paper's main contributions, methodologies, and applications.

Categories:
1. DATASET: Papers that introduce new datasets or make significant modifications to existing ones
2. DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
3. BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
4. AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
5. CV: Papers developing computer vision methods or visual processing systems
6. RL: Papers investigating reinforcement learning theory or applications
7. RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
8. RAG: Papers advancing retrieval-augmented generation techniques
9. PLP: Papers about Programming Language Processing models or programming benchmarks
10. INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
11. 3D: Papers on 3D content generation, processing, or understanding
12. AUDIO: Papers advancing speech/audio processing or generation
13. VIDEO: Papers on video analysis, generation, or understanding
14. MULTIMODAL: Papers combining multiple input/output modalities
15. MATH: Papers focused on mathematical theory and algorithms
16. MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities
17. ARCHITECTURE: Papers proposing novel neural architectures or components
18. MEDICINE: Papers applying ML to medical/healthcare domains
19. TRAINING: Papers improving model training or fine-tuning methods
20. ROBOTICS: Papers on robotic systems and embodied AI
21. AGI: Papers discussing artificial general intelligence concepts
22. GAMES: Papers applying ML to games or game development
23. INTERPRETABILITY: Papers analyzing model behavior and explanations
24. REASONING: Papers enhancing logical reasoning capabilities
25. TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
26. GRAPHS: Papers advancing graph neural networks and applications
27. ETHICS: Papers addressing AI ethics, fairness, and bias
28. SECURITY: Papers on model security and adversarial robustness
29. QUANTUM: Papers combining quantum computing and ML
30. EDGE_COMPUTING: Papers on ML deployment for resource-constrained devices
31. OPTIMIZATION: Papers advancing training optimization methods
32. SURVEY: Papers comprehensively reviewing research areas
33. DIFFUSION: Papers on diffusion-based generative models
34. ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
35. STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
36. HALLUCINATION: Papers about the hallucinations in language models, hallucinations analysis and mitigation

Return only JSON with flat array of categories that match the given text.

Paper text to classify:

"We propose the Large View Synthesis Model (LVSM), a novel transformer-based approach for scalable and generalizable novel view synthesis from sparse-view inputs. We introduce two architectures: (1) an encoder-decoder LVSM, which encodes input image tokens into a fixed number of 1D latent tokens, functioning as a fully learned scene representation, and decodes novel-view images from them; and (2) a decoder-only LVSM, which directly maps input images to novel-view outputs, completely eliminating intermediate scene representations. Both models bypass the 3D inductive biases used in previous methods -- from 3D representations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar projections, plane sweeps) -- addressing novel view synthesis with a fully data-driven approach. While the encoder-decoder model offers faster inference due to its independent latent representation, the decoder-only LVSM achieves superior quality, scalability, and zero-shot generalization, outperforming previous state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive evaluations across multiple datasets demonstrate that both LVSM variants achieve state-of-the-art novel view synthesis quality. Notably, our models surpass all previous methods even with reduced computational resources (1-2 GPUs). Please see our website for more details: https://haian-jin.github.io/projects/LVSM/ ."

[25.10.2024 00:58] Response: ```json
["CV", "3D"]
```
[25.10.2024 00:58] Get embedding for a paper via LLM API.
[25.10.2024 00:58] Loading Chinese text from previous data.
[25.10.2024 00:58] Renaming data file.
[25.10.2024 00:58] Renaming previous data. hf_papers.json to ./d/2024-10-25.json
[25.10.2024 00:58] Saving new data file.
[25.10.2024 00:58] Generating page.
[25.10.2024 00:58] Renaming previous page.
[25.10.2024 00:58] Renaming previous data. index.html to ./d/2024-10-25.html
[25.10.2024 00:58] [Experimental] Generating Chinese page for reading.
[25.10.2024 00:58] Chinese vocab [{'word': 'ËßÜËßâÂÅèÂ•ΩÂØπÈΩêÊñπÊ≥ï', 'pinyin': 'sh√¨ju√© piƒÅnh«éo du√¨q√≠ fƒÅngf«é', 'trans': 'visual preference alignment method'}, {'word': 'Â§öÂõæÂÉèËæìÂÖ•', 'pinyin': 'du≈ç t√∫xi√†ng sh≈´r√π', 'trans': 'multi-image input'}, {'word': 'ÂçïÂõæÂÉèÂú∫ÊôØ', 'pinyin': 'dƒÅn t√∫xi√†ng ch«éngj«êng', 'trans': 'single-image scenario'}, {'word': 'Èöæ‰ª•ÊúâÊïàÂ§ÑÁêÜ', 'pinyin': 'n√°ny«ê y«íuxi√†o ch«îl«ê', 'trans': 'difficult to effectively handle'}, {'word': 'Â§öÂõæÂÉè‰ªªÂä°', 'pinyin': 'du≈ç t√∫xi√†ng r√®nw√π', 'trans': 'multi-image task'}, {'word': 'Êâ©Â±ïÂçïÂõæÂÉèÊï∞ÊçÆ', 'pinyin': 'ku√≤zh«én dƒÅn t√∫xi√†ng sh√πj√π', 'trans': 'extend single-image data'}, {'word': 'Ê≥®ÊÑèÂäõÂÄº', 'pinyin': 'zh√πy√¨l√¨ zh√≠', 'trans': 'attention value'}, {'word': 'Á≠õÈÄâÈîôËØØÂìçÂ∫î', 'pinyin': 'shƒÅixu«én cu√≤w√π xi«éngy√¨ng', 'trans': 'screen out incorrect responses'}, {'word': 'ÊòæËëóÂáèÂ∞ë', 'pinyin': 'xi«énzh√π ji«énsh«éo', 'trans': 'significantly reduce'}, {'word': 'Â§öÂõæÂÉèÊï∞ÊçÆÊ†áÊ≥®ÊàêÊú¨', 'pinyin': 'du≈ç t√∫xi√†ng sh√πj√π biƒÅozh√π ch√©ngbƒõn', 'trans': 'multi-image data annotation cost'}, {'word': '‰∫î‰∏™Â§öÂõæÂÉèÂü∫ÂáÜÊµãËØï', 'pinyin': 'w«î g√® du≈ç t√∫xi√†ng jƒ´zh«în c√®sh√¨', 'trans': 'five multi-image benchmark tests'}, {'word': '‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï', 'pinyin': 'y≈çu y√∫ xi√†ny«íu fƒÅngf«é', 'trans': 'superior to existing methods'}, {'word': 'Âπ≥ÂùáÊÄßËÉΩÊèêÂçá', 'pinyin': 'p√≠ngj≈´n x√¨ngn√©ng t√≠shƒìng', 'trans': 'average performance improvement'}, {'word': 'ÂØπÂçïÂõæÂÉèÁêÜËß£ËÉΩÂäõÂΩ±ÂìçËæÉÂ∞è', 'pinyin': 'du√¨ dƒÅn t√∫xi√†ng l«êjiƒõ n√©ngl√¨ y«êngxi«éng ji√†o xi«éo', 'trans': 'minimal impact on single-image understanding capability'}]
[25.10.2024 00:58] Renaming previous Chinese page.
[25.10.2024 00:58] Renaming previous data. zh.html to ./d/2024-10-24_zh_reading_task.html
[25.10.2024 00:58] Writing result.
[25.10.2024 00:58] Writing Chinese reading task.
[25.10.2024 00:58] Renaming log file.
[25.10.2024 00:58] Renaming previous data. log.txt to ./logs/2024-10-25_last_log.txt
