[28.04.2025 05:16] Read previous papers.
[28.04.2025 05:16] Generating top page (month).
[28.04.2025 05:16] Writing top page (month).
[28.04.2025 06:23] Read previous papers.
[28.04.2025 06:23] Get feed.
[28.04.2025 06:23] Get page data from previous paper. URL: https://huggingface.co/papers/2504.15376
[28.04.2025 06:23] Get page data from previous paper. URL: https://huggingface.co/papers/2504.18415
[28.04.2025 06:23] Get page data from previous paper. URL: https://huggingface.co/papers/2504.16427
[28.04.2025 06:23] Get page data from previous paper. URL: https://huggingface.co/papers/2504.12080
[28.04.2025 06:23] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.04.2025 06:23] No deleted papers detected.
[28.04.2025 06:23] Downloading and parsing papers (pdf, html). Total: 4.
[28.04.2025 06:23] Downloading and parsing paper https://huggingface.co/papers/2504.15376.
[28.04.2025 06:23] Extra JSON file exists (./assets/json/2504.15376.json), skip PDF parsing.
[28.04.2025 06:23] Paper image links file exists (./assets/img_data/2504.15376.json), skip HTML parsing.
[28.04.2025 06:23] Success.
[28.04.2025 06:23] Downloading and parsing paper https://huggingface.co/papers/2504.18415.
[28.04.2025 06:23] Extra JSON file exists (./assets/json/2504.18415.json), skip PDF parsing.
[28.04.2025 06:23] Paper image links file exists (./assets/img_data/2504.18415.json), skip HTML parsing.
[28.04.2025 06:23] Success.
[28.04.2025 06:23] Downloading and parsing paper https://huggingface.co/papers/2504.16427.
[28.04.2025 06:23] Extra JSON file exists (./assets/json/2504.16427.json), skip PDF parsing.
[28.04.2025 06:23] Paper image links file exists (./assets/img_data/2504.16427.json), skip HTML parsing.
[28.04.2025 06:23] Success.
[28.04.2025 06:23] Downloading and parsing paper https://huggingface.co/papers/2504.12080.
[28.04.2025 06:23] Extra JSON file exists (./assets/json/2504.12080.json), skip PDF parsing.
[28.04.2025 06:23] Paper image links file exists (./assets/img_data/2504.12080.json), skip HTML parsing.
[28.04.2025 06:23] Success.
[28.04.2025 06:23] Enriching papers with extra data.
[28.04.2025 06:23] ********************************************************************************
[28.04.2025 06:23] Abstract 0. We introduce CameraBench, a large-scale dataset and benchmark designed to assess and improve camera motion understanding. CameraBench consists of ~3,000 diverse internet videos, annotated by experts through a rigorous multi-stage quality control process. One of our contributions is a taxonomy of cam...
[28.04.2025 06:23] ********************************************************************************
[28.04.2025 06:23] Abstract 1. Efficient deployment of 1-bit Large Language Models (LLMs) is hindered by activation outliers, which complicate quantization to low bit-widths. We introduce BitNet v2, a novel framework enabling native 4-bit activation quantization for 1-bit LLMs. To tackle outliers in attention and feed-forward net...
[28.04.2025 06:23] ********************************************************************************
[28.04.2025 06:23] Abstract 2. Multimodal language analysis is a rapidly evolving field that leverages multiple modalities to enhance the understanding of high-level semantics underlying human conversational utterances. Despite its significance, little research has investigated the capability of multimodal large language models (...
[28.04.2025 06:23] ********************************************************************************
[28.04.2025 06:23] Abstract 3. Given a single labeled example, in-context segmentation aims to segment corresponding objects. This setting, known as one-shot segmentation in few-shot learning, explores the segmentation model's generalization ability and has been applied to various vision tasks, including scene understanding and i...
[28.04.2025 06:23] Read previous papers.
[28.04.2025 06:23] Generating reviews via LLM API.
[28.04.2025 06:23] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#cv", "#multimodal"], "emoji": "üé•", "ru": {"title": "–ù–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã –≤ –≤–∏–¥–µ–æ", "desc": "CameraBench - —ç—Ç–æ –Ω–æ–≤—ã–π –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã –≤ –≤–∏–¥–µ–æ. –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–∫–æ–ª–æ 30
[28.04.2025 06:23] Using data from previous issue: {"categories": ["#small_models", "#optimization", "#inference", "#training"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "BitNet v2 - —ç—Ç–æ –Ω–æ–≤–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è 1-–±–∏—Ç–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –û–Ω–∞ —Ä–µ—à–∞–µ—Ç 
[28.04.2025 06:23] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#open_source", "#multimodal"], "emoji": "üó£Ô∏è", "ru": {"title": "MMLA: –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π —Å–µ–º–∞–Ω—Ç–∏–∫–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MMLA - –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ
[28.04.2025 06:23] Using data from previous issue: {"categories": ["#dataset", "#transfer_learning", "#benchmark", "#cv", "#games"], "emoji": "üé≠", "ru": {"title": "DC-SAM: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Dual Consistency SAM (DC-SAM) –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π SAM –∏ SAM2 –∫ –∑–∞–¥–∞—á–µ —Å–µ–≥–º–µ–Ω
[28.04.2025 06:23] Loading Chinese text from previous data.
[28.04.2025 06:23] Renaming data file.
[28.04.2025 06:23] Renaming previous data. hf_papers.json to ./d/2025-04-28.json
[28.04.2025 06:23] Saving new data file.
[28.04.2025 06:23] Generating page.
[28.04.2025 06:23] Renaming previous page.
[28.04.2025 06:23] Renaming previous data. index.html to ./d/2025-04-28.html
[28.04.2025 06:23] [Experimental] Generating Chinese page for reading.
[28.04.2025 06:23] Chinese vocab [{'word': 'Â∞ΩÁÆ°', 'pinyin': 'j«ên gu«én', 'trans': 'although'}, {'word': 'ËøÖÈÄü', 'pinyin': 'x√πn s√π', 'trans': 'rapidly'}, {'word': 'Áº∫Â§±', 'pinyin': 'quƒì shƒ´', 'trans': 'lack'}, {'word': 'Â§çÁé∞', 'pinyin': 'f√π xi√†n', 'trans': 'reproduce'}, {'word': 'ÊìÖÈïø', 'pinyin': 'sh√†n ch√°ng', 'trans': 'be good at'}, {'word': 'ÂêØÂèë', 'pinyin': 'q«ê fƒÅ', 'trans': 'inspire'}, {'word': 'ÂºïÂÖ•', 'pinyin': 'y«ên r√π', 'trans': 'introduce'}, {'word': 'ËΩ¨Âåñ', 'pinyin': 'zhu«én hu√†', 'trans': 'transform'}, {'word': 'ÂäüËÉΩ', 'pinyin': 'g≈çng n√©ng', 'trans': 'functional'}, {'word': '‰ª£ÁêÜ', 'pinyin': 'd√†i l«ê', 'trans': 'agent'}, {'word': 'Á°Æ‰øù', 'pinyin': 'qu√® b«éo', 'trans': 'ensure'}, {'word': 'Âçè‰Ωú', 'pinyin': 'xi√© zu√≤', 'trans': 'collaborate'}, {'word': 'Âø†ÂÆû', 'pinyin': 'zh≈çng sh√≠', 'trans': 'faithful'}]
[28.04.2025 06:23] Renaming previous Chinese page.
[28.04.2025 06:23] Renaming previous data. zh.html to ./d/2025-04-27_zh_reading_task.html
[28.04.2025 06:23] Writing Chinese reading task.
[28.04.2025 06:23] Writing result.
[28.04.2025 06:23] Renaming log file.
[28.04.2025 06:23] Renaming previous data. log.txt to ./logs/2025-04-28_last_log.txt
