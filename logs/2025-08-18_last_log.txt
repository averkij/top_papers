[18.08.2025 20:13] Read previous papers.
[18.08.2025 20:13] Generating top page (month).
[18.08.2025 20:13] Writing top page (month).
[18.08.2025 21:10] Read previous papers.
[18.08.2025 21:10] Get feed.
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10874
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11630
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10104
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10975
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11116
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10395
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10868
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11203
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11255
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10461
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11616
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10894
[18.08.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06429
[18.08.2025 21:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.08.2025 21:10] No deleted papers detected.
[18.08.2025 21:10] Downloading and parsing papers (pdf, html). Total: 13.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.10874.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.10874.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.10874.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.11630.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.11630.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.11630.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.10104.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.10104.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.10104.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.10975.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.10975.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.10975.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.11116.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.11116.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.11116.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.10395.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.10395.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.10395.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.10868.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.10868.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.10868.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.11203.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.11203.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.11203.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.11255.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.11255.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.11255.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.10461.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.10461.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.10461.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.11616.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.11616.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.11616.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.10894.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.10894.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.10894.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2508.06429.
[18.08.2025 21:10] Extra JSON file exists (./assets/json/2508.06429.json), skip PDF parsing.
[18.08.2025 21:10] Paper image links file exists (./assets/img_data/2508.06429.json), skip HTML parsing.
[18.08.2025 21:10] Success.
[18.08.2025 21:10] Enriching papers with extra data.
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 0. LLMs can serve as efficient simulators for RL tasks, reducing reliance on external search engines through a method called Self-Search RL, which enhances internal knowledge utilization.  					AI-generated summary 				 We investigate the potential of large language models (LLMs) to serve as efficient ...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 1. Thyme, a novel paradigm, enables MLLMs to autonomously perform image manipulations and computations, enhancing performance in perception and reasoning tasks through a two-stage training strategy and GRPO-ATS algorithm.  					AI-generated summary 				 Following OpenAI's introduction of the ``thinking...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 2. DINOv3, a self-supervised learning model, achieves superior performance across various vision tasks by scaling datasets and models, addressing dense feature degradation, and enhancing flexibility with post-hoc strategies.  					AI-generated summary 				 Self-supervised learning holds the promise of ...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 3. BeyondWeb, a synthetic data generation framework, outperforms existing datasets and accelerates training for large language models by optimizing multiple factors.  					AI-generated summary 				 Recent advances in large language model (LLM) pretraining have shown that simply scaling data quantity ev...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 4. PaperRegister enhances paper search by using hierarchical indexing and adaptive retrieval, supporting flexible and fine-grained queries beyond traditional abstract-based systems.  					AI-generated summary 				 Paper search is an important activity for researchers, typically involving using a query ...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 5. XQuant and XQuant-CL reduce memory consumption in LLM inference through low-bit quantization and cross-layer similarity exploitation, achieving significant memory savings with minimal accuracy loss.  					AI-generated summary 				 Although LLM inference has emerged as a critical workload for many do...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 6. TexVerse is a large-scale 3D dataset with high-resolution textures, including PBR materials, rigged models, and animated models, suitable for texture synthesis, PBR material development, and 3D vision tasks.  					AI-generated summary 				 We introduce TexVerse, a large-scale 3D dataset featuring hi...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 7. StyleMM constructs stylized 3DMMs from text descriptions using a diffusion model for image-to-image translation while preserving facial attributes.  					AI-generated summary 				 We introduce StyleMM, a novel framework that can construct a stylized 3D Morphable Model (3DMM) based on user-defined te...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 8. A multimodal reward model and adaptive preference optimization framework improve audio-driven portrait animation by aligning with human preferences across multiple dimensions.  					AI-generated summary 				 Recent advances in audio-driven portrait animation have demonstrated impressive capabilities...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 9. X-Node is a self-explaining GNN framework that generates per-node explanations by encoding local topology features and integrating them into the message-passing pipeline, maintaining accuracy while enhancing interpretability.  					AI-generated summary 				 Graph neural networks (GNNs) have achieved...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 10. A reward-guided decoding method for Multimodal Large Language Models (MLLMs) improves visual grounding by controlling object precision and recall, offering dynamic trade-offs between compute and grounding quality.  					AI-generated summary 				 As Multimodal Large Language Models (MLLMs) gain wides...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 11. MAESTRO, an adapted Masked Autoencoder with optimized fusion strategies and spectral prior normalization, achieves state-of-the-art performance on multitemporal Earth observation tasks.  					AI-generated summary 				 Self-supervised learning holds great promise for remote sensing, but standard self...
[18.08.2025 21:10] ********************************************************************************
[18.08.2025 21:10] Abstract 12. A GAN-based semi-supervised learning framework improves medical image classification with minimal labeled data by integrating specialized neural networks and ensemble-based pseudo-labeling.  					AI-generated summary 				 Deep learning has revolutionized medical imaging, but its effectiveness is sev...
[18.08.2025 21:10] Read previous papers.
[18.08.2025 21:10] Generating reviews via LLM API.
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#rlhf", "#transfer_learning", "#rl", "#agents", "#hallucinations", "#reasoning"], "emoji": "üß†", "ru": {"title": "LLM –∫–∞–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–∏–º—É–ª—è—Ç–æ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –º–æ–≥—É—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á–∏ –ø–æ–∏
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#training", "#optimization", "#agents", "#cv", "#rl"], "emoji": "üß†", "ru": {"title": "–¢–∞–π–º: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –º—ã—à–ª–µ–Ω–∏—è –ò–ò —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏", "desc": "–¢–∞–π–º (Thyme) - —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º (MLLM) –∞–≤—Ç–æ–Ω–æ–º–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –º–∞
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization", "#open_source", "#survey", "#dataset", "#cv"], "emoji": "üî¨", "ru": {"title": "DINOv3: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∞–º–æ–æ–±—É—á–∞—é—â–∞—è—Å—è –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è", "desc": "DINOv3 - —ç—Ç–æ –º–æ–¥–µ–ª—å —Å–∞–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø—Ä–µ–≤
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#training", "#synthetic", "#data", "#optimization", "#dataset"], "emoji": "üöÄ", "ru": {"title": "BeyondWeb: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "BeyondWeb - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#data", "#dataset", "#benchmark"], "emoji": "üîç", "ru": {"title": "–ì–∏–±–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–∞ –ª—é–±–æ–º —É—Ä–æ–≤–Ω–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏", "desc": "PaperRegister - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫. –û–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–∏–±–∫–∏–µ –∏ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization"], "emoji": "üß†", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ LLM: –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏, —Ç–∞ –∂–µ —Ç–æ—á–Ω–æ—Å—Ç—å", "desc": "XQuant –∏ XQuant-CL - —ç—Ç–æ –Ω–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –û–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –Ω–∏–∑
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#3d", "#dataset"], "emoji": "üé®", "ru": {"title": "TexVerse: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –º–∏—Ä–µ 3D-—Ç–µ–∫—Å—Ç—É—Ä –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤", "desc": "TexVerse - —ç—Ç–æ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö 3D-–º–æ–¥–µ–ª–µ–π —Å –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Ç–µ–∫—Å—Ç—É—Ä–∞–º–∏, –≤–∫–ª—é—á–∞—è PBR-–º–∞—Ç–µ—Ä–∏–∞–ª—ã, —Ä–∏–≥–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏. –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#cv", "#3d", "#diffusion", "#open_source"], "emoji": "üé≠", "ru": {"title": "–°—Ç–∏–ª—å–Ω—ã–µ 3D-–ª–∏—Ü–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –∫–æ–Ω—Ç—Ä–æ–ª—è –∏ —Ä–µ–∞–ª–∏–∑–º–∞", "desc": "StyleMM - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö 3D-–º–æ–¥–µ–ª–µ–π –ª–∏—Ü –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å 
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#data", "#training", "#optimization", "#multimodal", "#diffusion", "#alignment", "#dataset"], "emoji": "üó£Ô∏è", "ru": {"title": "–ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–Ω–∏–º–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –∞–Ω–∏–º–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤, —É–ø—Ä
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#cv", "#interpretability", "#healthcare", "#graphs", "#dataset", "#architecture"], "emoji": "üï∏Ô∏è", "ru": {"title": "X-Node: –°–∞–º–æ–æ–±—ä—è—Å–Ω—è—é—â–∏–µ—Å—è –≥—Ä–∞—Ñ–æ–≤—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö", "desc": "X-Node - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥—Ä–∞—Ñ–æ–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π (GNN), –∫–æ—Ç–æ—Ä—ã–π –≥–µ–Ω
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#hallucinations", "#alignment", "#multimodal", "#benchmark", "#inference"], "emoji": "üéõÔ∏è", "ru": {"title": "–£–ø—Ä–∞–≤–ª—è–µ–º–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ MLLM –¥–ª—è —Ç–æ—á–Ω–æ–π –≤–∏–∑—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–≤—è–∑–∫–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ —É–ø—Ä–∞–≤–ª—è–µ–º–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLL
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#multimodal", "#open_source", "#dataset", "#cv"], "emoji": "üõ∞Ô∏è", "ru": {"title": "MAESTRO: –ø—Ä–æ—Ä—ã–≤ –≤ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º—É–ª—å—Ç–∏–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "MAESTRO - —ç—Ç–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –∑–∞–¥–∞—á –º—É–ª—å—Ç–∏–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ
[18.08.2025 21:10] Using data from previous issue: {"categories": ["#low_resource", "#dataset", "#healthcare", "#training", "#synthetic"], "emoji": "üè•", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–∏ –º–∏–Ω–∏–º—É–º–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–ª—É-–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è
[18.08.2025 21:10] Renaming data file.
[18.08.2025 21:10] Renaming previous data. hf_papers.json to ./d/2025-08-18.json
[18.08.2025 21:10] Saving new data file.
[18.08.2025 21:10] Generating page.
[18.08.2025 21:10] Renaming previous page.
[18.08.2025 21:10] Renaming previous data. index.html to ./d/2025-08-18.html
[18.08.2025 21:10] Writing result.
[18.08.2025 21:10] Renaming log file.
[18.08.2025 21:10] Renaming previous data. log.txt to ./logs/2025-08-18_last_log.txt
