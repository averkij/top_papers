[09.04.2025 17:10] Read previous papers.
[09.04.2025 17:10] Generating top page (month).
[09.04.2025 17:10] Writing top page (month).
[09.04.2025 18:15] Read previous papers.
[09.04.2025 18:15] Get feed.
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06263
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06261
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05599
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05979
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05535
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02160
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02810
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06148
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05594
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20533
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06232
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05897
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.00043
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05520
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06122
[09.04.2025 18:15] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03755
[09.04.2025 18:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[09.04.2025 18:15] No deleted papers detected.
[09.04.2025 18:15] Downloading and parsing papers (pdf, html). Total: 16.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.06263.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.06263.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.06263.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.06261.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.06261.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.06261.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.05599.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.05599.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.05599.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.05979.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.05979.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.05979.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.05535.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.05535.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.05535.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.02160.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.02160.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.02160.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.02810.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.02810.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.02810.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.06148.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.06148.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.06148.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.05594.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.05594.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.05594.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2503.20533.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2503.20533.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2503.20533.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.06232.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.06232.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.06232.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.05897.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.05897.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.05897.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.00043.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.00043.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.00043.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.05520.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.05520.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.05520.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.06122.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.06122.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.06122.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Downloading and parsing paper https://huggingface.co/papers/2504.03755.
[09.04.2025 18:15] Extra JSON file exists (./assets/json/2504.03755.json), skip PDF parsing.
[09.04.2025 18:15] Paper image links file exists (./assets/img_data/2504.03755.json), skip HTML parsing.
[09.04.2025 18:15] Success.
[09.04.2025 18:15] Enriching papers with extra data.
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 0. Scalable Vector Graphics (SVG) is an important image format widely adopted in graphic design because of their resolution independence and editability. The study of generating high-quality SVG has continuously drawn attention from both designers and researchers in the AIGC community. However, existin...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 1. Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 2. We introduce Skywork R1V, a multimodal reasoning model extending the an R1-series Large language models (LLM) to visual modalities via an efficient multimodal transfer method. Leveraging a lightweight visual projector, Skywork R1V facilitates seamless multimodal adaptation without necessitating retr...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 3. The landscape of image generation has rapidly evolved, from early GAN-based approaches to diffusion models and, most recently, to unified generative architectures that seek to bridge understanding and generation tasks. Recent advances, especially the GPT-4o, have demonstrated the feasibility of high...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 4. Aligning large language models (LLMs) with human preferences has achieved remarkable success. However, existing Chinese preference datasets are limited by small scale, narrow domain coverage, and lack of rigorous data validation. Additionally, the reliance on human annotators for instruction and res...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 5. Although subject-driven generation has been extensively explored in image generation due to its wide applications, it still has challenges in data scalability and subject expansibility. For the first challenge, moving from curating single-subject datasets to multiple-subject ones and scaling them is...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 6. With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly released benchmarks inevitably become contaminated once inc...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 7. Recent advancements in Multimodal Large Language Models (MLLMs) have led to significant improvements across various multimodal benchmarks. However, as evaluations shift from static datasets to open-world, dynamic environments, current game-based benchmarks remain inadequate because they lack visual-...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 8. Balancing fidelity and editability is essential in text-based image editing (TIE), where failures commonly lead to over- or under-editing issues. Existing methods typically rely on attention injections for structure preservation and leverage the inherent text alignment capabilities of pre-trained te...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 9. Recent advances in reasoning models have demonstrated significant improvements in accuracy, particularly for complex tasks such as mathematical reasoning, by employing detailed and comprehensive reasoning processes. However, generating these lengthy reasoning sequences is computationally expensive a...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 10. Text-to-image (T2I) diffusion/flow models have drawn considerable attention recently due to their remarkable ability to deliver flexible visual creations. Still, high-resolution image synthesis presents formidable challenges due to the scarcity and complexity of high-resolution content. To this end,...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 11. The Mixture of Experts (MoE) architecture has demonstrated significant advantages as it enables to increase the model capacity without a proportional increase in computation. However, the large MoE model size still introduces substantial memory demands, which usually requires expert offloading on re...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 12. Existing reasoning evaluation frameworks for Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) predominantly either assess text-based reasoning or vision-language understanding capabilities, with limited dynamic interplay between textual and visual constraints. To address this li...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 13. Reinforcement finetuning (RFT) has shown great potential for enhancing the mathematical reasoning capabilities of large language models (LLMs), but it is often sample- and compute-inefficient, requiring extensive training. In this work, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuni...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 14. Recent advances in automated theorem proving (ATP) through LLMs have highlighted the potential of formal reasoning with Lean 4 codes. However, ATP has not yet be revolutionized by the recent posttraining scaling as demonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the entir...
[09.04.2025 18:15] ********************************************************************************
[09.04.2025 18:15] Abstract 15. Generalized category discovery (GCD) is a pragmatic but underexplored problem, which requires models to automatically cluster and discover novel categories by leveraging the labeled samples from old classes. The challenge is that unlabeled data contain both old and new classes. Early works leveragin...
[09.04.2025 18:15] Read previous papers.
[09.04.2025 18:15] Generating reviews via LLM API.
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#dataset", "#cv", "#benchmark", "#multimodal"], "emoji": "🎨", "ru": {"title": "OmniSVG: Революция в генерации векторной графики с помощью ИИ", "desc": "OmniSVG - это новая структура для генерации высококачественной векторной графики SVG с использованием предобученных моделей визуаль
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#inference", "#reasoning", "#long_context", "#optimization", "#architecture"], "emoji": "🤖", "ru": {"title": "Самоорганизующееся параллельное сотрудничество языковых моделей", "desc": "Эта статья представляет новый подход к параллельному выполнению задач большими языковыми моделями 
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#transfer_learning", "#benchmark", "#inference", "#architecture", "#multimodal", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективная мультимодальная адаптация для улучшения рассуждений ИИ", "desc": "Статья представляет Skywork R1V 
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#architecture", "#multimodal", "#open_source", "#benchmark"], "emoji": "🖼️", "ru": {"title": "GPT-4o: Новый рубеж в унифицированной генерации изображений", "desc": "Статья посвящена исследованию возможностей генерации изображений моделью GPT-4o. Авторы проводят 
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#alignment", "#data", "#rlhf", "#open_source"], "emoji": "🇨🇳", "ru": {"title": "Автоматизированное создание масштабного китайского датасета предпочтений для улучшения LLM", "desc": "Статья представляет COIG-P - крупномасштабный китайский датасет предпочтени
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#dataset", "#data", "#synthetic", "#multimodal", "#diffusion", "#cv"], "emoji": "🎨", "ru": {"title": "Универсальная генерация изображений с множеством объектов", "desc": "Статья описывает новый подход к генерации изображений с несколькими объектами. Авторы предлагают пайплайн для си
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#reasoning", "#multimodal"], "emoji": "🧠", "ru": {"title": "KUMO: новый способ оценить истинные способности ИИ к рассуждению", "desc": "Исследователи представили KUMO - новую систему для оценки способностей больших языковых моделей (LLM) к рассужде
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#benchmark", "#games", "#multimodal", "#reasoning", "#agents"], "emoji": "🎮", "ru": {"title": "V-MAGE: Новый подход к оценке визуальных способностей ИИ через игровые задачи", "desc": "В статье представлена новая система оценки визуальных способностей мультимодальных больших языковых
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#optimization", "#multimodal"], "emoji": "⚖️", "ru": {"title": "Баланс точности и редактируемости в редактировании изображений на основе текста", "desc": "Статья представляет UnifyEdit - метод редактирования изображений на основе текста, который балансирует межд
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#training", "#math"], "emoji": "🚀", "ru": {"title": "Ускорение рассуждений без потери качества", "desc": "Статья описывает метод ускорения процесса рассуждений в моделях машинного обучения. Авторы предлагают использовать параллелизацию для обработки не
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#diffusion", "#training", "#optimization", "#cv"], "emoji": "🖼️", "ru": {"title": "HiFlow: раскрытие потенциала высокого разрешения в генерации изображений", "desc": "HiFlow - это инновационный подход к улучшению качества генерации изображений высокого разрешения с помощью предобуче
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization", "#inference", "#open_source"], "emoji": "🧠", "ru": {"title": "Эффективный гибридный вывод MoE-моделей на CPU и GPU", "desc": "HybriMoE - это фреймворк для гибридного вывода моделей Mixture of Experts (MoE) на CPU и GPU. Он решает проблем
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#reasoning"], "emoji": "🧩", "ru": {"title": "Кроссворды как инструмент оценки искусственного интеллекта", "desc": "CrossWordBench - это новый метод оценки способностей больших языковых моделей (LLM) и больших визуально-языковых моделей (LVLM) к рассужден
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#training", "#reasoning", "#rl", "#math", "#optimization"], "emoji": "🧠", "ru": {"title": "AdaRFT: Адаптивное обучение для улучшения математических способностей ИИ", "desc": "В этой статье представлен метод AdaRFT (Адаптивное обучение с подкреплением на основе учебной программы), ко
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#data", "#optimization", "#dataset", "#training", "#reasoning", "#rl"], "emoji": "🧠", "ru": {"title": "Революция в автоматическом доказательстве теорем: от языковых моделей к формальной логике", "desc": "Статья описывает исследование в области автоматического доказательства теорем (
[09.04.2025 18:15] Using data from previous issue: {"categories": ["#transfer_learning", "#training", "#data", "#benchmark", "#optimization", "#dataset"], "emoji": "🧠", "ru": {"title": "Унифицированное обучение прототипов для эффективного обнаружения новых категорий", "desc": "Статья представляет новый подход к обобщенному обнаружению категорий (GCD
[09.04.2025 18:15] Loading Chinese text from previous data.
[09.04.2025 18:15] Renaming data file.
[09.04.2025 18:15] Renaming previous data. hf_papers.json to ./d/2025-04-09.json
[09.04.2025 18:15] Saving new data file.
[09.04.2025 18:15] Generating page.
[09.04.2025 18:15] Renaming previous page.
[09.04.2025 18:15] Renaming previous data. index.html to ./d/2025-04-09.html
[09.04.2025 18:15] [Experimental] Generating Chinese page for reading.
[09.04.2025 18:15] Chinese vocab [{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': '转移', 'pinyin': 'zhuǎn yí', 'trans': 'transfer'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '扩展', 'pinyin': 'kuò zhǎn', 'trans': 'extend'}, {'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'}, {'word': '投影器', 'pinyin': 'tóu yǐng qì', 'trans': 'projector'}, {'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'}, {'word': '重新', 'pinyin': 'chóng xīn', 'trans': 're-'}, {'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'train'}, {'word': '编码器', 'pinyin': 'biān mǎ qì', 'trans': 'encoder'}, {'word': '适应', 'pinyin': 'shì yìng', 'trans': 'adapt'}, {'word': '混合', 'pinyin': 'hùn hé', 'trans': 'hybrid'}, {'word': '优化', 'pinyin': 'yōu huà', 'trans': 'optimization'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '自适应', 'pinyin': 'zì shì yìng', 'trans': 'adaptive'}, {'word': '长度', 'pinyin': 'cháng dù', 'trans': 'length'}, {'word': '思维链', 'pinyin': 'sī wéi lián', 'trans': 'chain of thought'}, {'word': '提炼', 'pinyin': 'tí liàn', 'trans': 'extract'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '显示', 'pinyin': 'xiǎn shì', 'trans': 'show'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '出色', 'pinyin': 'chū sè', 'trans': 'outstanding'}, {'word': '权重', 'pinyin': 'quán zhòng', 'trans': 'weights'}, {'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'}]
[09.04.2025 18:15] Renaming previous Chinese page.
[09.04.2025 18:15] Renaming previous data. zh.html to ./d/2025-04-08_zh_reading_task.html
[09.04.2025 18:15] Writing Chinese reading task.
[09.04.2025 18:15] Writing result.
[09.04.2025 18:15] Renaming log file.
[09.04.2025 18:15] Renaming previous data. log.txt to ./logs/2025-04-09_last_log.txt
