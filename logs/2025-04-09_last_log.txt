[09.04.2025 14:12] Read previous papers.
[09.04.2025 14:12] Generating top page (month).
[09.04.2025 14:12] Writing top page (month).
[09.04.2025 15:14] Read previous papers.
[09.04.2025 15:14] Get feed.
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06263
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05599
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06261
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05979
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05535
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02160
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02810
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.05594
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06148
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06232
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.00043
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20533
[09.04.2025 15:14] Extract page data from URL. URL: https://huggingface.co/papers/2504.05520
[09.04.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2504.06122
[09.04.2025 15:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[09.04.2025 15:14] No deleted papers detected.
[09.04.2025 15:14] Downloading and parsing papers (pdf, html). Total: 14.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.06263.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.06263.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.06263.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.05599.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.05599.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.05599.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.06261.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.06261.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.06261.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.05979.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.05979.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.05979.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.05535.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.05535.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.05535.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.02160.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.02160.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.02160.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.02810.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.02810.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.02810.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.05594.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.05594.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.05594.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.06148.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.06148.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.06148.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.06232.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.06232.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.06232.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.00043.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.00043.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.00043.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2503.20533.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2503.20533.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2503.20533.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.05520.
[09.04.2025 15:14] Downloading paper 2504.05520 from http://arxiv.org/pdf/2504.05520v1...
[09.04.2025 15:14] Extracting affiliations from text.
[09.04.2025 15:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 ] . [ 1 0 2 5 5 0 . 4 0 5 2 : r a Taiwei Shi, Yiyang Wu, Linxin Song, Tianyi Zhou, Jieyu Zhao University of Southern California, University of Maryland, College Park {taiweish, wuwendy, linxinso, jieyuz}@usc.edu, tianyi@umd.edu Code: github.com/uscnlp-lime/verl Dataset: huggingface.co/datasets/lime-nlp/DeepScaleR_Difficulty "
[09.04.2025 15:14] Response: ```python
["University of Southern California", "University of Maryland, College Park"]
```
[09.04.2025 15:14] Deleting PDF ./assets/pdf/2504.05520.pdf.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2504.06122.
[09.04.2025 15:14] Extra JSON file exists (./assets/json/2504.06122.json), skip PDF parsing.
[09.04.2025 15:14] Paper image links file exists (./assets/img_data/2504.06122.json), skip HTML parsing.
[09.04.2025 15:14] Success.
[09.04.2025 15:14] Enriching papers with extra data.
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 0. Scalable Vector Graphics (SVG) is an important image format widely adopted in graphic design because of their resolution independence and editability. The study of generating high-quality SVG has continuously drawn attention from both designers and researchers in the AIGC community. However, existin...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 1. We introduce Skywork R1V, a multimodal reasoning model extending the an R1-series Large language models (LLM) to visual modalities via an efficient multimodal transfer method. Leveraging a lightweight visual projector, Skywork R1V facilitates seamless multimodal adaptation without necessitating retr...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 2. Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 3. The landscape of image generation has rapidly evolved, from early GAN-based approaches to diffusion models and, most recently, to unified generative architectures that seek to bridge understanding and generation tasks. Recent advances, especially the GPT-4o, have demonstrated the feasibility of high...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 4. Aligning large language models (LLMs) with human preferences has achieved remarkable success. However, existing Chinese preference datasets are limited by small scale, narrow domain coverage, and lack of rigorous data validation. Additionally, the reliance on human annotators for instruction and res...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 5. Although subject-driven generation has been extensively explored in image generation due to its wide applications, it still has challenges in data scalability and subject expansibility. For the first challenge, moving from curating single-subject datasets to multiple-subject ones and scaling them is...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 6. With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly released benchmarks inevitably become contaminated once inc...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 7. Balancing fidelity and editability is essential in text-based image editing (TIE), where failures commonly lead to over- or under-editing issues. Existing methods typically rely on attention injections for structure preservation and leverage the inherent text alignment capabilities of pre-trained te...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 8. Recent advancements in Multimodal Large Language Models (MLLMs) have led to significant improvements across various multimodal benchmarks. However, as evaluations shift from static datasets to open-world, dynamic environments, current game-based benchmarks remain inadequate because they lack visual-...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 9. Text-to-image (T2I) diffusion/flow models have drawn considerable attention recently due to their remarkable ability to deliver flexible visual creations. Still, high-resolution image synthesis presents formidable challenges due to the scarcity and complexity of high-resolution content. To this end,...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 10. Existing reasoning evaluation frameworks for Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) predominantly either assess text-based reasoning or vision-language understanding capabilities, with limited dynamic interplay between textual and visual constraints. To address this li...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 11. Recent advances in reasoning models have demonstrated significant improvements in accuracy, particularly for complex tasks such as mathematical reasoning, by employing detailed and comprehensive reasoning processes. However, generating these lengthy reasoning sequences is computationally expensive a...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 12. Reinforcement finetuning (RFT) has shown great potential for enhancing the mathematical reasoning capabilities of large language models (LLMs), but it is often sample- and compute-inefficient, requiring extensive training. In this work, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuni...
[09.04.2025 15:14] ********************************************************************************
[09.04.2025 15:14] Abstract 13. Recent advances in automated theorem proving (ATP) through LLMs have highlighted the potential of formal reasoning with Lean 4 codes. However, ATP has not yet be revolutionized by the recent posttraining scaling as demonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the entir...
[09.04.2025 15:14] Read previous papers.
[09.04.2025 15:14] Generating reviews via LLM API.
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#dataset", "#cv", "#benchmark", "#multimodal"], "emoji": "🎨", "ru": {"title": "OmniSVG: Революция в генерации векторной графики с помощью ИИ", "desc": "OmniSVG - это новая структура для генерации высококачественной векторной графики SVG с использованием предобученных моделей визуаль
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#transfer_learning", "#benchmark", "#inference", "#architecture", "#multimodal", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективная мультимодальная адаптация для улучшения рассуждений ИИ", "desc": "Статья представляет Skywork R1V 
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#inference", "#reasoning", "#long_context", "#optimization", "#architecture"], "emoji": "🤖", "ru": {"title": "Самоорганизующееся параллельное сотрудничество языковых моделей", "desc": "Эта статья представляет новый подход к параллельному выполнению задач большими языковыми моделями 
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#architecture", "#multimodal", "#open_source", "#benchmark"], "emoji": "🖼️", "ru": {"title": "GPT-4o: Новый рубеж в унифицированной генерации изображений", "desc": "Статья посвящена исследованию возможностей генерации изображений моделью GPT-4o. Авторы проводят 
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#alignment", "#data", "#rlhf", "#open_source"], "emoji": "🇨🇳", "ru": {"title": "Автоматизированное создание масштабного китайского датасета предпочтений для улучшения LLM", "desc": "Статья представляет COIG-P - крупномасштабный китайский датасет предпочтени
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#dataset", "#data", "#synthetic", "#multimodal", "#diffusion", "#cv"], "emoji": "🎨", "ru": {"title": "Универсальная генерация изображений с множеством объектов", "desc": "Статья описывает новый подход к генерации изображений с несколькими объектами. Авторы предлагают пайплайн для си
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#reasoning", "#multimodal"], "emoji": "🧠", "ru": {"title": "KUMO: новый способ оценить истинные способности ИИ к рассуждению", "desc": "Исследователи представили KUMO - новую систему для оценки способностей больших языковых моделей (LLM) к рассужде
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#optimization", "#multimodal"], "emoji": "⚖️", "ru": {"title": "Баланс точности и редактируемости в редактировании изображений на основе текста", "desc": "Статья представляет UnifyEdit - метод редактирования изображений на основе текста, который балансирует межд
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#games", "#multimodal", "#reasoning", "#agents"], "emoji": "🎮", "ru": {"title": "V-MAGE: Новый подход к оценке визуальных способностей ИИ через игровые задачи", "desc": "В статье представлена новая система оценки визуальных способностей мультимодальных больших языковых
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#diffusion", "#training", "#optimization", "#cv"], "emoji": "🖼️", "ru": {"title": "HiFlow: раскрытие потенциала высокого разрешения в генерации изображений", "desc": "HiFlow - это инновационный подход к улучшению качества генерации изображений высокого разрешения с помощью предобуче
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#reasoning"], "emoji": "🧩", "ru": {"title": "Кроссворды как инструмент оценки искусственного интеллекта", "desc": "CrossWordBench - это новый метод оценки способностей больших языковых моделей (LLM) и больших визуально-языковых моделей (LVLM) к рассужден
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#training", "#math"], "emoji": "🚀", "ru": {"title": "Ускорение рассуждений без потери качества", "desc": "Статья описывает метод ускорения процесса рассуждений в моделях машинного обучения. Авторы предлагают использовать параллелизацию для обработки не
[09.04.2025 15:14] Querying the API.
[09.04.2025 15:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Reinforcement finetuning (RFT) has shown great potential for enhancing the mathematical reasoning capabilities of large language models (LLMs), but it is often sample- and compute-inefficient, requiring extensive training. In this work, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a method that significantly improves both the efficiency and final accuracy of RFT through adaptive curriculum learning. AdaRFT dynamically adjusts the difficulty of training problems based on the model's recent reward signals, ensuring that the model consistently trains on tasks that are challenging but solvable. This adaptive sampling strategy accelerates learning by maintaining an optimal difficulty range, avoiding wasted computation on problems that are too easy or too hard. AdaRFT requires only a lightweight extension to standard RFT algorithms like Proximal Policy Optimization (PPO), without modifying the reward function or model architecture. Experiments on competition-level math datasets-including AMC, AIME, and IMO-style problems-demonstrate that AdaRFT significantly improves both training efficiency and reasoning performance. We evaluate AdaRFT across multiple data distributions and model sizes, showing that it reduces the number of training steps by up to 2x and improves accuracy by a considerable margin, offering a more scalable and effective RFT framework.
[09.04.2025 15:14] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[09.04.2025 15:14] Using data from previous issue: {"categories": ["#data", "#optimization", "#dataset", "#training", "#reasoning", "#rl"], "emoji": "🧠", "ru": {"title": "Революция в автоматическом доказательстве теорем: от языковых моделей к формальной логике", "desc": "Статья описывает исследование в области автоматического доказательства теорем (
[09.04.2025 15:14] Loading Chinese text from previous data.
[09.04.2025 15:14] Renaming data file.
[09.04.2025 15:14] Renaming previous data. hf_papers.json to ./d/2025-04-09.json
[09.04.2025 15:14] Saving new data file.
[09.04.2025 15:14] Generating page.
[09.04.2025 15:14] Renaming previous page.
[09.04.2025 15:14] Renaming previous data. index.html to ./d/2025-04-09.html
[09.04.2025 15:14] [Experimental] Generating Chinese page for reading.
[09.04.2025 15:14] Chinese vocab [{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': '转移', 'pinyin': 'zhuǎn yí', 'trans': 'transfer'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '扩展', 'pinyin': 'kuò zhǎn', 'trans': 'extend'}, {'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'}, {'word': '投影器', 'pinyin': 'tóu yǐng qì', 'trans': 'projector'}, {'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'}, {'word': '重新', 'pinyin': 'chóng xīn', 'trans': 're-'}, {'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'train'}, {'word': '编码器', 'pinyin': 'biān mǎ qì', 'trans': 'encoder'}, {'word': '适应', 'pinyin': 'shì yìng', 'trans': 'adapt'}, {'word': '混合', 'pinyin': 'hùn hé', 'trans': 'hybrid'}, {'word': '优化', 'pinyin': 'yōu huà', 'trans': 'optimization'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '自适应', 'pinyin': 'zì shì yìng', 'trans': 'adaptive'}, {'word': '长度', 'pinyin': 'cháng dù', 'trans': 'length'}, {'word': '思维链', 'pinyin': 'sī wéi lián', 'trans': 'chain of thought'}, {'word': '提炼', 'pinyin': 'tí liàn', 'trans': 'extract'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '显示', 'pinyin': 'xiǎn shì', 'trans': 'show'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '出色', 'pinyin': 'chū sè', 'trans': 'outstanding'}, {'word': '权重', 'pinyin': 'quán zhòng', 'trans': 'weights'}, {'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'}]
[09.04.2025 15:14] Renaming previous Chinese page.
[09.04.2025 15:14] Renaming previous data. zh.html to ./d/2025-04-08_zh_reading_task.html
[09.04.2025 15:14] Writing Chinese reading task.
[09.04.2025 15:14] Writing result.
[09.04.2025 15:14] Renaming log file.
[09.04.2025 15:14] Renaming previous data. log.txt to ./logs/2025-04-09_last_log.txt
