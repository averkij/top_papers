[23.02.2026 20:38] Read previous papers.
[23.02.2026 20:38] Generating top page (month).
[23.02.2026 20:38] Writing top page (month).
[23.02.2026 21:38] Read previous papers.
[23.02.2026 21:38] Get feed.
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10693
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08354
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.18422
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.18292
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15727
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.18071
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.18432
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.17807
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16742
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15814
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.18312
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.17664
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.17186
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.17080
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.17022
[23.02.2026 21:38] Extract page data from URL. URL: https://huggingface.co/papers/2602.14279
[23.02.2026 21:38] Extract page data from URL. URL: https://huggingface.co/papers/2602.13576
[23.02.2026 21:38] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10094
[23.02.2026 21:38] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.02.2026 21:38] No deleted papers detected.
[23.02.2026 21:38] Downloading and parsing papers (pdf, html). Total: 18.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.10693.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.10693.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.10693.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.08354.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.08354.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.08354.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.18422.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.18422.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.18422.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.18292.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.18292.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.18292.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.15727.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.15727.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.15727.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.18071.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.18071.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.18071.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.18432.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.18432.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.18432.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.17807.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.17807.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.17807.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.16742.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.16742.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.16742.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.15814.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.15814.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.15814.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.18312.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.18312.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.18312.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.17664.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.17664.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.17664.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.17186.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.17186.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.17186.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.17080.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.17080.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.17080.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.17022.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.17022.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.17022.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.14279.
[23.02.2026 21:38] Downloading paper 2602.14279 from https://arxiv.org/pdf/2602.14279v1...
[23.02.2026 21:38] Extracting affiliations from text.
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 1 ] . [ 1 9 7 2 4 1 . 2 0 6 2 : r Whom to Query for What: Adaptive Group Elicitation via Multi-Turn LLM Interactions Ruomeng Ding1, Tianwei Gao*1, Thomas P. Zollo2, Eitan Bachmat3, Richard Zemel2, and Zhun Deng1 1University of North Carolina at Chapel Hill 2Columbia University 3Ben-Gurion University of the Negev Abstract Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multiturn interactions in natural language, most existing elicitation methods optimize what to ask with fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including > 12% relative gain on CES at 10% respondent budget. Code is available at: https: //github.com/ZDCSlab/Group-Adaptive-Elicitation. Surveys and other collective assessments work by asking limited set of questions to subset of the population of interest in order to infer latent population properties, for example, countylevel political inclination, stude"
[23.02.2026 21:38] Response: ```python
[
    "University of North Carolina at Chapel Hill",
    "Columbia University",
    "Ben-Gurion University of the Negev"
]
```
[23.02.2026 21:38] Deleting PDF ./assets/pdf/2602.14279.pdf.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.13576.
[23.02.2026 21:38] Downloading paper 2602.13576 from https://arxiv.org/pdf/2602.13576v1...
[23.02.2026 21:38] Extracting affiliations from text.
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 4 1 ] . [ 1 6 7 5 3 1 . 2 0 6 2 : r Rubrics as an Attack Surface: Stealthy Preference Drift in LLM Judges Ruomeng Ding1, Yifei Pang*2, He Sun3, Yizhong Wang4, Zhiwei Steven Wu2, and Zhun Deng1 1University of North Carolina at Chapel Hill 2Carnegie Mellon University 3Yale University 4The University of Texas at Austin Abstract Evaluation and alignment pipelines for large language models increasingly rely on LLM-based judges, whose behavior is guided by natural-language rubrics and validated on benchmarks. We identify previously under-recognized vulnerability in this workflow, which we term Rubric-Induced Preference Drift (RIPD). Even when rubric edits pass benchmark validation, they can still produce systematic and directional shifts in judges preferences on target domains. Because rubrics serve as high-level decision interface, such drift can emerge from seemingly natural, criterion-preserving edits and remain difficult to detect through aggregate benchmark metrics or limited spot-checking. We further show this vulnerability can be exploited through rubric-based preference attacks, in which benchmark-compliant rubric edits steer judgments away from fixed human or trusted reference on target domains, systematically inducing RIPD and reducing target-domain accuracy up to 9.5% (helpfulness) and 27.9% (harmlessness). When these judgments are used to generate preference labels for downstream post-training, the induced bias propagates through alignment pipelines and becomes internalized in trained policies. This leads to persistent and systematic drift in model behavior. Overall, our findings highlight evaluation rubrics as sensitive and manipulable control interface, revealing system-level alignment risk that extends beyond evaluator reliability alone. The code is available at: https://github.com/ZDCSlab/Rubrics-as-an-Attack-Surface. Warning: Certain sections may contain potentially harmful content that may not be appropriate for all readers. Reinforcement learnin"
[23.02.2026 21:38] Response: ```python
[
    "University of North Carolina at Chapel Hill",
    "Carnegie Mellon University",
    "Yale University",
    "The University of Texas at Austin"
]
```
[23.02.2026 21:38] Deleting PDF ./assets/pdf/2602.13576.pdf.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Downloading and parsing paper https://huggingface.co/papers/2602.10094.
[23.02.2026 21:38] Extra JSON file exists (./assets/json/2602.10094.json), skip PDF parsing.
[23.02.2026 21:38] Paper image links file exists (./assets/img_data/2602.10094.json), skip HTML parsing.
[23.02.2026 21:38] Success.
[23.02.2026 21:38] Enriching papers with extra data.
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 0. VESPO addresses training instability in LLM reinforcement learning by using variational formulation with variance reduction to correct policy divergence without length normalization.  					AI-generated summary 				 Training stability remains a central challenge in reinforcement learning (RL) for lar...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 1. Large reasoning models can implicitly determine optimal stopping points for thinking, which SAGE-RL enhances by incorporating efficient reasoning patterns into pass@1 inference for improved accuracy and efficiency.  					AI-generated summary 				 Recent advancements in large reasoning models (LRMs) ...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 2. A human-centric video world model conditioned on tracked head and hand poses is introduced, enabling dexterous interactions through a bidirectional video diffusion model trained for egocentric virtual environment generation.  					AI-generated summary 				 Extended reality (XR) demands generative mo...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 3. Abstract Decoding is reinterpreted as a principled optimization layer that balances model scores with structural preferences, recovering existing methods as special cases and enabling the creation of new decoders like Best-of-K that improve accuracy in mathematical reasoning tasks.  					AI-generate...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 4. Abstract Visual analogy learning via dynamic composition of learned LoRA transformation primitives enables flexible image manipulation with improved generalization over fixed adaptation modules.  					AI-generated summary Visual analogy learning enables image manipulation through demonstration rathe...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 5. EgoPush enables robot manipulation in cluttered environments through perception-driven policy learning that uses object-centric latent spaces and stage-decomposed rewards for long-horizon tasks.  					AI-generated summary 				 Humans can rearrange objects in cluttered environments using egocentric p...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 6. A causal transformer-based variational autoencoder combined with flow matching enables real-time, spatially-aware conversational motion for embodied agents in virtual reality applications.  					AI-generated summary 				 As embodied agents become central to VR, telepresence, and digital human applic...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 7. Abstract A video segmentation model eliminates specialized tracking modules by using a Vision Transformer encoder with query propagation and fusion mechanisms for efficient, high-speed processing.  					AI-generated summary Existing online video segmentation models typically combine a per-frame segm...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 8. DeepVision-103K dataset enhances multimodal reasoning capabilities of large models through diverse mathematical content and visual elements.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has been shown effective in enhancing the visual reflection and reasoning...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 9. Abstract Compact pretrained bidirectional encoders based on Avey architecture outperform Transformer-based models on token classification and information retrieval tasks while scaling more efficiently to long contexts.  					AI-generated summary Compact pretrained bidirectional encoders remain the b...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 10. Reinforcement learning policies are improved by using action Jacobian penalty to eliminate unrealistic high-frequency signals, with a new Linear Policy Net architecture reducing computational overhead while enabling faster convergence and efficient inference for motion imitation tasks.  					AI-gene...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 11. Abstract Diffusion Language Models suffer from high inference costs due to iterative denoising, prompting the development of Sink-Aware Pruning that identifies and removes unstable attention sinks, improving efficiency without retraining.  					AI-generated summary Diffusion Language Models (DLMs) i...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 12. Visual Information Gain metric quantifies the contribution of visual input to prediction uncertainty, enabling selective training that improves visual grounding and reduces language bias in vision-language models.  					AI-generated summary 				 Large Vision Language Models (LVLMs) have achieved rem...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 13. Abstract A new class of optimizers combines orthogonalized momentum with norm-based noise adaptation, achieving improved convergence rates and training performance for large language models.  					AI-generated summary Efficient stochastic optimization typically integrates an update direction that pe...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 14. Abstract Conversational agents with tool integration face challenges from user-induced errors, but a test-time intervention method called Reasoning Inception (ReIn) enables error recovery by injecting external reasoning into the agent's decision-making process without modifying model parameters or p...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 15. Abstract Adaptive group elicitation framework combines LLM-based information gain scoring with graph neural networks to improve population-level predictions under budget constraints.  					AI-generated summary Eliciting information to reduce uncertainty about latent group-level properties from surve...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 16. Abstract LLM-based judges using natural-language rubrics for evaluation can exhibit systematic preference drift from minor rubric modifications, which can be exploited to manipulate alignment pipelines and degrade model performance.  					AI-generated summary Evaluation and alignment pipelines for l...
[23.02.2026 21:38] ********************************************************************************
[23.02.2026 21:38] Abstract 17. Abstract 4RC presents a unified feed-forward framework for 4D reconstruction from monocular videos that learns holistic scene geometry and motion dynamics through a transformer-based encoder-decoder architecture with conditional querying capabilities.  					AI-generated summary We present 4RC, a uni...
[23.02.2026 21:38] Read previous papers.
[23.02.2026 21:38] Generating reviews via LLM API.
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#rl", "#training", "#open_source", "#reasoning", "#math", "#optimization"], "emoji": "âš–ï¸", "ru": {"title": "Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ñ€ĞµĞ´ÑƒĞºÑ†Ğ¸Ñ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¸", "desc": "VESPO Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#training", "#optimization", "#reasoning", "#benchmark", "#rl"], "emoji": "ğŸ§ ", "ru": {"title": "ĞœĞ¾Ğ´ĞµĞ»Ğ¸ ÑĞ°Ğ¼Ğ¸ Ğ·Ğ½Ğ°ÑÑ‚, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒÑÑ: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ½ĞµÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#video", "#architecture", "#training", "#multimodal", "#diffusion", "#3d"], "emoji": "ğŸ¥½", "ru": {"title": "Ğ’Ğ¸Ğ´ĞµĞ¾Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¸Ñ€Ğ° Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ¾Ğ·Ñ‹ Ğ³Ğ¾Ğ»Ğ¾Ğ²Ñ‹ Ğ¸ Ñ€ÑƒĞº Ğ´Ğ»Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸", "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¸Ñ€Ğ°, Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#inference", "#math", "#reasoning", "#optimization"], "emoji": "ğŸ¯", "ru": {"title": "Ğ”ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ°Ğº Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğµcoders", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ¾ÑĞ¼Ñ‹ÑĞ»ÑĞµÑ‚ÑÑ ĞºĞ°Ğº Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ»Ğ¾Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€ÑƒĞµÑ‚ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¾Ñ†ĞµĞ½Ğº
[23.02.2026 21:38] Using data from previous issue: {"categories": [], "emoji": "ğŸ¨", "ru": {"title": "Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ LoRA Ğ¿Ñ€Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ğ²Ğ¾Ğ² Ğ´Ğ»Ñ Ğ³Ğ¸Ğ±ĞºĞ¾Ğ³Ğ¾ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ğ¸", "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´ LoRWeB Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ÑĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ²Ğ¼Ğµ
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#cv", "#robotics", "#rl"], "emoji": "ğŸ¤–", "ru": {"title": "ĞœĞ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ¼ Ğ¸Ğ· Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ»Ğ¸Ñ†Ğ° Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ½Ğ¾-Ñ†ĞµĞ½Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°", "desc": "EgoPush â€” ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ¼ Ğ² Ğ·Ğ°Ğ³Ñ€Ğ¾Ğ¼Ğ¾Ğ¶Ğ´Ñ‘Ğ½Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ… Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ³Ğ¾Ñ†ĞµĞ½Ñ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ½Ğ¸Ñ. 
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#agents", "#dataset", "#video", "#architecture", "#multimodal", "#3d"], "emoji": "ğŸ­", "ru": {"title": "ĞŸÑ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ¾ÑĞ²ĞµĞ´Ğ¾Ğ¼Ğ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ñ‹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸", "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾-Ğ¾ÑĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ‹Ñ… 
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#cv", "#video", "#architecture"], "emoji": "ğŸ¬", "ru": {"title": "Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€ Ğ±ĞµĞ· Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ: Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ‡ĞµÑ€ĞµĞ· Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²", "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑƒĞ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Vision Transformer Ğ±ĞµĞ· ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#multimodal", "#dataset"], "emoji": "ğŸ“Š", "ru": {"title": "Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ¾Ğ¼", "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ Ğ±Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… DeepVision-103K, Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ°Ñ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¼Ñƒ
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#architecture", "#benchmark", "#small_models"], "emoji": "âš¡", "ru": {"title": "ĞšĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¹ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€ Ğ±ĞµĞ· Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ĞµĞµ Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ²", "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒÑÑ‚ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Avey Ğ´Ğ»Ñ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ° Ğ±ĞµĞ· Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ° Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ² Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ 
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#architecture", "#robotics", "#optimization", "#inference", "#rl"], "emoji": "ğŸ¤–", "ru": {"title": "Ğ“Ğ»Ğ°Ğ´ĞºĞ¸Ğµ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· ÑˆÑ‚Ñ€Ğ°Ñ„ ÑĞºĞ¾Ğ±Ğ¸Ğ°Ğ½Ğ° Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑˆÑ‚Ñ€Ğ°Ñ„Ğ° Ğ½Ğ° ÑĞºĞ¾Ğ±Ğ¸Ğ°
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#optimization"], "emoji": "âœ‚ï¸", "ru": {"title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒĞ·Ğ»Ğ¾Ğ² Ğ² Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ñ… Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚ Ğ¸Ğ·-Ğ·Ğ° Ğ¸Ñ‚Ğµ
[23.02.2026 21:38] Using data from previous issue: {"categories": [], "emoji": "ğŸ‘ï¸", "ru": {"title": "Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ Ğ²ĞºĞ»Ğ°Ğ´ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ: Ğ¸Ğ·Ğ±Ğ¸Ñ€Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ·Ñ‹ĞºĞ°", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ° Visual Information Gain (VIG), ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚, Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ 
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture"], "emoji": "âš¡", "ru": {"title": "ĞÑ€Ñ‚Ğ¾Ğ³Ğ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ ÑˆÑƒĞ¼Ğ¾Ğ¼", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ñ‹ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ñ‹ NAMO Ğ¸ NAMO-D, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑÑÑ‚ Ğ¾Ñ€Ñ‚Ğ¾Ğ³Ğ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¾Ğ¹ Ğ¿Ğ¾Ğ´ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ñˆ
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#alignment", "#training"], "emoji": "ğŸ”§", "ru": {"title": "Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ² Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ñ… Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸", "desc": "Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Reasoning Inception (ReIn) Ğ´Ğ»Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¾Ñ‚ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¸Ğ½
[23.02.2026 21:38] Querying the API.
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Abstract Adaptive group elicitation framework combines LLM-based information gain scoring with graph neural networks to improve population-level predictions under budget constraints.  					AI-generated summary Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, a multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose a theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries a small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including a >12% relative gain on CES at a 10% respondent budget.
[23.02.2026 21:38] Response: ```json
{
  "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ ÑĞ±Ğ¾Ñ€Ğ° Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ñƒ Ğ³Ñ€ÑƒĞ¿Ğ¿ Ğ»ÑĞ´ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ LLM-Ğ±Ğ°Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞµÑ‚ÑĞ¼Ğ¸. ĞœĞµÑ‚Ğ¾Ğ´ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° ĞºĞ°Ğº Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ñ‚Ğ°Ğº Ğ¸ Ñ€ĞµÑĞ¿Ğ¾Ğ½Ğ´ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ´ Ğ¶Ñ‘ÑÑ‚ĞºĞ¸Ğ¼Ğ¸ Ğ±ÑĞ´Ğ¶ĞµÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ·Ğ°Ğ¼ĞºĞ½ÑƒÑ‚Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ» Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ¸. Ğ“ĞµÑ‚ĞµÑ€Ğ¾Ğ³ĞµĞ½Ğ½Ğ°Ñ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²Ğ°Ñ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ¸ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ° Ñ€ĞµÑĞ¿Ğ¾Ğ½Ğ´ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ… Ğ¼Ğ½ĞµĞ½Ğ¸Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ½Ğ°ÑĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ±ÑĞ´Ğ¶ĞµÑ‚Ğµ Ğ½Ğ° 12% Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ.",
  "emoji": "ğŸ¯",
  "title": "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ Ñ€ĞµÑĞ¿Ğ¾Ğ½Ğ´ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ½ĞµĞ½Ğ¸Ğ¹ Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²Ğ°"
}
```
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract Adaptive group elicitation framework combines LLM-based information gain scoring with graph neural networks to improve population-level predictions under budget constraints.  					AI-generated summary Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, a multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose a theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries a small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including a >12% relative gain on CES at a 10% respondent budget."

[23.02.2026 21:38] Response: ```python
["AGENTS", "ARCHITECTURE", "DATA"]
```

**Justification:**

- **AGENTS**: The paper describes "an agent [that] adaptively selects both questions and respondents" in a multi-round setting, involving autonomous decision-making about what to ask and whom to query.

- **ARCHITECTURE**: The paper proposes a framework combining LLM-based scoring with "heterogeneous graph neural network propagation," which represents a novel architectural approach combining multiple neural components.

- **DATA**: The paper focuses on data collection and curation methodologies, specifically addressing "eliciting information," "allocating limited questioning effort," handling "missing data," and "imputing missing responses" - all core data processing and collection concerns.
[23.02.2026 21:38] Error. Failed to parse JSON from LLM. ["AGENTS", "ARCHITECTURE", "DATA"]


**Justification:**

- **AGENTS**: The paper describes "an agent [that] adaptively selects both questions and respondents" in a multi-round setting, involving autonomous decision-making about what to ask and whom to query.

- **ARCHITECTURE**: The paper proposes a framework combining LLM-based scoring with "heterogeneous graph neural network propagation," which represents a novel architectural approach combining multiple neural components.

- **DATA**: The paper focuses on data collection and curation methodologies, specifically addressing "eliciting information," "allocating limited questioning effort," handling "missing data," and "imputing missing responses" - all core data processing and collection concerns.
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract Adaptive group elicitation framework combines LLM-based information gain scoring with graph neural networks to improve population-level predictions under budget constraints.  					AI-generated summary Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, a multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose a theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries a small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including a >12% relative gain on CES at a 10% respondent budget."

[23.02.2026 21:38] Response: ```python
['GRAPHS', 'OPTIMIZATION']
```

**Justification:**

- **GRAPHS**: The paper explicitly uses "heterogeneous graph neural networks" as a core component of their framework to aggregate responses and guide respondent selection.

- **OPTIMIZATION**: The paper addresses optimization under budget constraints, focusing on adaptive selection of questions and respondents to maximize information gain while operating under "explicit query and participation budgets.
[23.02.2026 21:38] Error. Failed to parse JSON from LLM. ["GRAPHS", "OPTIMIZATION"]


**Justification:**

- **GRAPHS**: The paper explicitly uses "heterogeneous graph neural networks" as a core component of their framework to aggregate responses and guide respondent selection.

- **OPTIMIZATION**: The paper addresses optimization under budget constraints, focusing on adaptive selection of questions and respondents to maximize information gain while operating under "explicit query and participation budgets.
[23.02.2026 21:38] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"This paper presents an adaptive group elicitation framework that enhances predictions about group-level properties using limited resources. It combines large language models (LLMs) for scoring questions based on expected information gain with graph neural networks to handle incomplete data. The approach allows for dynamic selection of both questions and respondents, optimizing the questioning process under budget constraints. The results show significant improvements in predicting population-level responses, demonstrating the effectiveness of this method in real-world scenarios.","title":"Optimizing Group Insights with Adaptive Elicitation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents an adaptive group elicitation framework that enhances predictions about group-level properties using limited resources. It combines large language models (LLMs) for scoring questions based on expected information gain with graph neural networks to handle incomplete data. The approach allows for dynamic selection of both questions and respondents, optimizing the questioning process under budget constraints. The results show significant improvements in predicting population-level responses, demonstrating the effectiveness of this method in real-world scenarios.', title='Optimizing Group Insights with Adaptive Elicitation'))
[23.02.2026 21:38] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªé€‚åº”ç¾¤ä½“å¼•å¯¼æ¡†æ¶ï¼Œç»“åˆäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æœŸæœ›ä¿¡æ¯å¢ç›Šè¯„åˆ†å’Œå›¾ç¥ç»ç½‘ç»œï¼Œä»¥åœ¨é¢„ç®—é™åˆ¶ä¸‹æ”¹å–„ç¾¤ä½“å±‚é¢çš„é¢„æµ‹ã€‚è¯¥æ–¹æ³•é€šè¿‡å¤šè½®äº’åŠ¨ï¼ŒåŠ¨æ€é€‰æ‹©é—®é¢˜å’Œå—è®¿è€…ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å“åº”ä¸å®Œæ•´æ—¶çš„å±€é™æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨æœ‰é™çš„æé—®å’Œå‚ä¸é¢„ç®—ä¸‹ï¼ŒæŸ¥è¯¢å°‘é‡ä¿¡æ¯ä¸°å¯Œçš„ä¸ªä½“ï¼ŒåŒæ—¶æ¨æ–­å‡ºç¾¤ä½“å±‚é¢çš„å“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œçš„æ„è§æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é¢„ç®—å—é™çš„æƒ…å†µä¸‹ï¼Œç¾¤ä½“å±‚é¢å“åº”é¢„æµ‹çš„å‡†ç¡®æ€§æœ‰æ˜¾è‘—æå‡ã€‚","title":"è‡ªé€‚åº”ç¾¤ä½“å¼•å¯¼ï¼šåœ¨é¢„ç®—é™åˆ¶ä¸‹æå‡é¢„æµ‹å‡†ç¡®æ€§"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªé€‚åº”ç¾¤ä½“å¼•å¯¼æ¡†æ¶ï¼Œç»“åˆäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æœŸæœ›ä¿¡æ¯å¢ç›Šè¯„åˆ†å’Œå›¾ç¥ç»ç½‘ç»œï¼Œä»¥åœ¨é¢„ç®—é™åˆ¶ä¸‹æ”¹å–„ç¾¤ä½“å±‚é¢çš„é¢„æµ‹ã€‚è¯¥æ–¹æ³•é€šè¿‡å¤šè½®äº’åŠ¨ï¼ŒåŠ¨æ€é€‰æ‹©é—®é¢˜å’Œå—è®¿è€…ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å“åº”ä¸å®Œæ•´æ—¶çš„å±€é™æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨æœ‰é™çš„æé—®å’Œå‚ä¸é¢„ç®—ä¸‹ï¼ŒæŸ¥è¯¢å°‘é‡ä¿¡æ¯ä¸°å¯Œçš„ä¸ªä½“ï¼ŒåŒæ—¶æ¨æ–­å‡ºç¾¤ä½“å±‚é¢çš„å“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œçš„æ„è§æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é¢„ç®—å—é™çš„æƒ…å†µä¸‹ï¼Œç¾¤ä½“å±‚é¢å“åº”é¢„æµ‹çš„å‡†ç¡®æ€§æœ‰æ˜¾è‘—æå‡ã€‚', title='è‡ªé€‚åº”ç¾¤ä½“å¼•å¯¼ï¼šåœ¨é¢„ç®—é™åˆ¶ä¸‹æå‡é¢„æµ‹å‡†ç¡®æ€§'))
[23.02.2026 21:38] Querying the API.
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Abstract LLM-based judges using natural-language rubrics for evaluation can exhibit systematic preference drift from minor rubric modifications, which can be exploited to manipulate alignment pipelines and degrade model performance.  					AI-generated summary Evaluation and alignment pipelines for large language models increasingly rely on LLM-based judges, whose behavior is guided by natural-language rubrics and validated on benchmarks. We identify a previously under-recognized vulnerability in this workflow, which we term Rubric-Induced Preference Drift (RIPD). Even when rubric edits pass benchmark validation, they can still produce systematic and directional shifts in a judge's preferences on target domains. Because rubrics serve as a high-level decision interface, such drift can emerge from seemingly natural, criterion-preserving edits and remain difficult to detect through aggregate benchmark metrics or limited spot-checking. We further show this vulnerability can be exploited through rubric-based preference attacks, in which benchmark-compliant rubric edits steer judgments away from a fixed human or trusted reference on target domains, systematically inducing RIPD and reducing target-domain accuracy up to 9.5% (helpfulness) and 27.9% (harmlessness). When these judgments are used to generate preference labels for downstream post-training, the induced bias propagates through alignment pipelines and becomes internalized in trained policies. This leads to persistent and systematic drift in model behavior. Overall, our findings highlight evaluation rubrics as a sensitive and manipulable control interface, revealing a system-level alignment risk that extends beyond evaluator reliability alone. The code is available at: https://github.com/ZDCSlab/Rubrics-as-an-Attack-Surface. Warning: Certain sections may contain potentially harmful content that may not be appropriate for all readers.
[23.02.2026 21:38] Response: ```json
{
  "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ LLM-ÑÑƒĞ´ĞµĞ¹ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ½ÑƒÑ Rubric-Induced Preference Drift (RIPD). Ğ”Ğ°Ğ¶Ğµ Ğ½ĞµĞ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ² ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ñ€ÑƒĞ±Ñ€Ğ¸ĞºĞ°Ñ… Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ñ€Ğ¸Ğ²ĞµÑÑ‚Ğ¸ Ğº ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ ÑÑƒĞ´ÑŒĞ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ğ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, ĞºĞ°Ğº Ğ·Ğ»Ğ¾ÑƒĞ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ğ¸ĞºĞ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ÑƒĞ±Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ñ†ĞµĞ»ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑĞºĞ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ğ¸ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ñ†ĞµĞ»ĞµĞ²Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ´Ğ¾ 27.9%. Ğ­Ñ‚Ğ¾ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· pipeline Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑÑ Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ² Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ñ€Ğ¸ÑĞº Ğ´Ğ»Ñ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ AI-ÑĞ¸ÑÑ‚ĞµĞ¼.",
  "emoji": "âš ï¸",
  "title": "Ğ ÑƒĞ±Ñ€Ğ¸ĞºĞ¸ ĞºĞ°Ğº Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ğ¾ÑÑ‚ÑŒ Ğ°Ñ‚Ğ°ĞºĞ¸: Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼Ğ¸ LLM-ÑÑƒĞ´ĞµĞ¹"
}
```
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract LLM-based judges using natural-language rubrics for evaluation can exhibit systematic preference drift from minor rubric modifications, which can be exploited to manipulate alignment pipelines and degrade model performance.  					AI-generated summary Evaluation and alignment pipelines for large language models increasingly rely on LLM-based judges, whose behavior is guided by natural-language rubrics and validated on benchmarks. We identify a previously under-recognized vulnerability in this workflow, which we term Rubric-Induced Preference Drift (RIPD). Even when rubric edits pass benchmark validation, they can still produce systematic and directional shifts in a judge's preferences on target domains. Because rubrics serve as a high-level decision interface, such drift can emerge from seemingly natural, criterion-preserving edits and remain difficult to detect through aggregate benchmark metrics or limited spot-checking. We further show this vulnerability can be exploited through rubric-based preference attacks, in which benchmark-compliant rubric edits steer judgments away from a fixed human or trusted reference on target domains, systematically inducing RIPD and reducing target-domain accuracy up to 9.5% (helpfulness) and 27.9% (harmlessness). When these judgments are used to generate preference labels for downstream post-training, the induced bias propagates through alignment pipelines and becomes internalized in trained policies. This leads to persistent and systematic drift in model behavior. Overall, our findings highlight evaluation rubrics as a sensitive and manipulable control interface, revealing a system-level alignment risk that extends beyond evaluator reliability alone. The code is available at: https://github.com/ZDCSlab/Rubrics-as-an-Attack-Surface. Warning: Certain sections may contain potentially harmful content that may not be appropriate for all readers."

[23.02.2026 21:38] Response: ```python
["BENCHMARK", "RLHF", "TRAINING"]
```

**Justification:**

- **BENCHMARK**: The paper directly analyzes evaluation frameworks and benchmarks, specifically how LLM-based judges using natural-language rubrics can be vulnerable to manipulation despite passing benchmark validation.

- **RLHF**: The paper discusses alignment pipelines and preference labels used for downstream post-training, which are core components of reinforcement learning from human feedback (RLHF) methods.

- **TRAINING**: The paper examines how induced bias from rubric-based attacks propagates through alignment pipelines and becomes internalized in trained policies, directly addressing model training and fine-tuning vulnerabilities.
[23.02.2026 21:38] Error. Failed to parse JSON from LLM. ["BENCHMARK", "RLHF", "TRAINING"]


**Justification:**

- **BENCHMARK**: The paper directly analyzes evaluation frameworks and benchmarks, specifically how LLM-based judges using natural-language rubrics can be vulnerable to manipulation despite passing benchmark validation.

- **RLHF**: The paper discusses alignment pipelines and preference labels used for downstream post-training, which are core components of reinforcement learning from human feedback (RLHF) methods.

- **TRAINING**: The paper examines how induced bias from rubric-based attacks propagates through alignment pipelines and becomes internalized in trained policies, directly addressing model training and fine-tuning vulnerabilities.
[23.02.2026 21:38] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract LLM-based judges using natural-language rubrics for evaluation can exhibit systematic preference drift from minor rubric modifications, which can be exploited to manipulate alignment pipelines and degrade model performance.  					AI-generated summary Evaluation and alignment pipelines for large language models increasingly rely on LLM-based judges, whose behavior is guided by natural-language rubrics and validated on benchmarks. We identify a previously under-recognized vulnerability in this workflow, which we term Rubric-Induced Preference Drift (RIPD). Even when rubric edits pass benchmark validation, they can still produce systematic and directional shifts in a judge's preferences on target domains. Because rubrics serve as a high-level decision interface, such drift can emerge from seemingly natural, criterion-preserving edits and remain difficult to detect through aggregate benchmark metrics or limited spot-checking. We further show this vulnerability can be exploited through rubric-based preference attacks, in which benchmark-compliant rubric edits steer judgments away from a fixed human or trusted reference on target domains, systematically inducing RIPD and reducing target-domain accuracy up to 9.5% (helpfulness) and 27.9% (harmlessness). When these judgments are used to generate preference labels for downstream post-training, the induced bias propagates through alignment pipelines and becomes internalized in trained policies. This leads to persistent and systematic drift in model behavior. Overall, our findings highlight evaluation rubrics as a sensitive and manipulable control interface, revealing a system-level alignment risk that extends beyond evaluator reliability alone. The code is available at: https://github.com/ZDCSlab/Rubrics-as-an-Attack-Surface. Warning: Certain sections may contain potentially harmful content that may not be appropriate for all readers."

[23.02.2026 21:38] Response: ```python
['ALIGNMENT', 'SECURITY', 'ETHICS']
```
[23.02.2026 21:38] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"This paper discusses a vulnerability in the evaluation process of large language models (LLMs) called Rubric-Induced Preference Drift (RIPD). It shows that even small changes to natural-language rubrics can lead to significant shifts in how LLM-based judges evaluate outputs, which can be exploited to manipulate model alignment. The authors demonstrate that these changes can degrade model performance by causing systematic biases in judgments, affecting accuracy in specific domains. This highlights the need for careful consideration of evaluation rubrics as they can introduce risks that compromise the reliability of AI systems.","title":"Beware the Rubric: Small Changes, Big Drifts!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses a vulnerability in the evaluation process of large language models (LLMs) called Rubric-Induced Preference Drift (RIPD). It shows that even small changes to natural-language rubrics can lead to significant shifts in how LLM-based judges evaluate outputs, which can be exploited to manipulate model alignment. The authors demonstrate that these changes can degrade model performance by causing systematic biases in judgments, affecting accuracy in specific domains. This highlights the need for careful consideration of evaluation rubrics as they can introduce risks that compromise the reliability of AI systems.', title='Beware the Rubric: Small Changes, Big Drifts!'))
[23.02.2026 21:38] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"æœ¬æ–‡æ¢è®¨äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¯„ä¼°ç³»ç»Ÿä¸­å­˜åœ¨çš„ä¸€ä¸ªæ¼æ´ï¼Œç§°ä¸ºâ€œè¯„åˆ†æ ‡å‡†å¼•å‘çš„åå¥½æ¼‚ç§»â€ï¼ˆRIPDï¼‰ã€‚å³ä½¿è¯„åˆ†æ ‡å‡†ç»è¿‡åŸºå‡†éªŒè¯ï¼Œè½»å¾®çš„ä¿®æ”¹ä¹Ÿå¯èƒ½å¯¼è‡´è¯„ä¼°è€…åœ¨ç‰¹å®šé¢†åŸŸçš„åå¥½å‘ç”Ÿç³»ç»Ÿæ€§å˜åŒ–ã€‚è¿™ç§æ¼‚ç§»å¯èƒ½ä¼šè¢«åˆ©ç”¨ï¼Œé€šè¿‡ä¿®æ”¹è¯„åˆ†æ ‡å‡†æ¥æ“æ§è¯„ä¼°ç»“æœï¼Œä»è€Œé™ä½æ¨¡å‹åœ¨ç›®æ ‡é¢†åŸŸçš„å‡†ç¡®æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§åå·®ä¼šåœ¨åç»­çš„è®­ç»ƒè¿‡ç¨‹ä¸­ä¼ æ’­ï¼Œå¯¼è‡´æ¨¡å‹è¡Œä¸ºçš„æŒç»­å’Œç³»ç»Ÿæ€§æ¼‚ç§»ã€‚","title":"è¯„åˆ†æ ‡å‡†çš„å¾®è°ƒå¯èƒ½å¯¼è‡´æ¨¡å‹åå·®"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬æ–‡æ¢è®¨äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¯„ä¼°ç³»ç»Ÿä¸­å­˜åœ¨çš„ä¸€ä¸ªæ¼æ´ï¼Œç§°ä¸ºâ€œè¯„åˆ†æ ‡å‡†å¼•å‘çš„åå¥½æ¼‚ç§»â€ï¼ˆRIPDï¼‰ã€‚å³ä½¿è¯„åˆ†æ ‡å‡†ç»è¿‡åŸºå‡†éªŒè¯ï¼Œè½»å¾®çš„ä¿®æ”¹ä¹Ÿå¯èƒ½å¯¼è‡´è¯„ä¼°è€…åœ¨ç‰¹å®šé¢†åŸŸçš„åå¥½å‘ç”Ÿç³»ç»Ÿæ€§å˜åŒ–ã€‚è¿™ç§æ¼‚ç§»å¯èƒ½ä¼šè¢«åˆ©ç”¨ï¼Œé€šè¿‡ä¿®æ”¹è¯„åˆ†æ ‡å‡†æ¥æ“æ§è¯„ä¼°ç»“æœï¼Œä»è€Œé™ä½æ¨¡å‹åœ¨ç›®æ ‡é¢†åŸŸçš„å‡†ç¡®æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§åå·®ä¼šåœ¨åç»­çš„è®­ç»ƒè¿‡ç¨‹ä¸­ä¼ æ’­ï¼Œå¯¼è‡´æ¨¡å‹è¡Œä¸ºçš„æŒç»­å’Œç³»ç»Ÿæ€§æ¼‚ç§»ã€‚', title='è¯„åˆ†æ ‡å‡†çš„å¾®è°ƒå¯èƒ½å¯¼è‡´æ¨¡å‹åå·®'))
[23.02.2026 21:38] Using data from previous issue: {"categories": ["#video", "#3d", "#architecture"], "emoji": "ğŸ¬", "ru": {"title": "Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ ÑÑ†ĞµĞ½Ñ‹ Ğ¸Ğ· Ğ²Ğ¸Ğ´ĞµĞ¾", "desc": "4RC Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ĞµĞ´Ğ¸Ğ½ÑƒÑ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ²ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ»Ñ 4D Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¸Ğ· Ğ¼Ğ¾Ğ½Ğ¾ĞºÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ°ĞµÑ‚ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ
[23.02.2026 21:38] Renaming data file.
[23.02.2026 21:38] Renaming previous data. hf_papers.json to ./d/2026-02-23.json
[23.02.2026 21:38] Saving new data file.
[23.02.2026 21:38] Generating page.
[23.02.2026 21:38] Renaming previous page.
[23.02.2026 21:38] Renaming previous data. index.html to ./d/2026-02-23.html
[23.02.2026 21:38] Writing result.
[23.02.2026 21:38] Renaming log file.
[23.02.2026 21:38] Renaming previous data. log.txt to ./logs/2026-02-23_last_log.txt
