[23.12.2025 19:19] Read previous papers.
[23.12.2025 19:19] Generating top page (month).
[23.12.2025 19:19] Writing top page (month).
[23.12.2025 20:24] Read previous papers.
[23.12.2025 20:24] Get feed.
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.16676
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19693
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.17650
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.17040
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19134
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.18880
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19678
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19629
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.17385
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19682
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.17206
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.16229
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19432
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19539
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.18658
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19402
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.18003
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19535
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.18314
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.12620
[23.12.2025 20:24] Get page data from previous paper. URL: https://huggingface.co/papers/2512.19399
[23.12.2025 20:24] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.12.2025 20:24] No deleted papers detected.
[23.12.2025 20:24] Downloading and parsing papers (pdf, html). Total: 21.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.16676.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.16676.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.16676.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19693.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19693.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19693.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.17650.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.17650.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.17650.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.17040.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.17040.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.17040.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19134.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19134.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19134.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.18880.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.18880.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.18880.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19678.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19678.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19678.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19629.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19629.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19629.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.17385.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.17385.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.17385.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19682.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19682.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19682.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.17206.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.17206.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.17206.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.16229.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.16229.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.16229.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19432.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19432.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19432.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19539.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19539.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19539.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.18658.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.18658.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.18658.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19402.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19402.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19402.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.18003.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.18003.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.18003.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19535.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19535.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19535.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.18314.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.18314.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.18314.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.12620.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.12620.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.12620.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Downloading and parsing paper https://huggingface.co/papers/2512.19399.
[23.12.2025 20:24] Extra JSON file exists (./assets/json/2512.19399.json), skip PDF parsing.
[23.12.2025 20:24] Paper image links file exists (./assets/img_data/2512.19399.json), skip HTML parsing.
[23.12.2025 20:24] Success.
[23.12.2025 20:24] Enriching papers with extra data.
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 0. DataFlow is an LLM-driven data preparation framework that enhances data quality and reproducibility for various tasks, improving LLM performance with automatically generated pipelines.  					AI-generated summary 				 The rapidly growing demand for high-quality data in Large Language Models (LLMs) ha...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 1. Unified Autoencoding combines semantic and pixel-level information through a frequency-band modulator, resulting in a latent space with state-of-the-art performance on image benchmarks.  					AI-generated summary 				 Deep representations across modalities are inherently intertwined. In this paper, ...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 2. ReCo is a novel instructional video editing paradigm that enhances accuracy and reduces token interference by incorporating constraint modeling and regularization techniques during in-context generation.  					AI-generated summary 				 The In-context generation paradigm recently has demonstrated str...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 3. InfCam generates high-fidelity videos with accurate camera poses by using infinite homography warping and augmenting synthetic datasets with diverse trajectories.  					AI-generated summary 				 Recent progress in video diffusion models has spurred growing interest in camera-controlled novel-view vi...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 4. QuCo-RAG uses objective corpus statistics to mitigate hallucinations in large language models during generation, improving accuracy across various benchmarks.  					AI-generated summary 				 Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate h...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 5. Large Language Models struggle to accurately estimate human cognitive difficulty due to a misalignment with human perceptions and a lack of introspection regarding their own limitations.  					AI-generated summary 				 Accurate estimation of item (question or task) difficulty is critical for educati...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 6. WorldWarp addresses the challenge of generating consistent long-range videos by integrating a 3D geometric cache with a spatio-temporal diffusion model, ensuring structural consistency and textural refinement.  					AI-generated summary 				 Generating long-range, geometrically consistent video pres...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 7. LoGoPlanner is an end-to-end navigation framework that improves trajectory planning in unstructured environments by integrating localization, scene geometry reconstruction, and policy conditioning.  					AI-generated summary 				 Trajectory planning in unstructured environments is a fundamental and ...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 8. IPC is an unsupervised framework that uses internal probing of large language models to generate code without labeled datasets, achieving competitive performance with reduced resource dependency.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable capabilities i...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 9. GenEnv, a framework using a co-evolutionary game with a generative environment simulator, enhances LLM agent performance by 40.3% over 7B baselines and uses less data than offline augmentation.  					AI-generated summary 				 Training capable Large Language Model (LLM) agents is critically bottlenec...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 10. Reasoning Palette enhances large language models by using a latent-modulation framework to guide internal planning and improve both inference and reinforcement learning performance.  					AI-generated summary 				 Exploration capacity shapes both inference-time performance and reinforcement learning...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 11. LoPA, a training-free algorithm, enhances the parallelism of diffusion large language models, doubling the tokens per forward pass and boosting throughput with multi-GPU deployment.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) have demonstrated significant potential for hi...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 12. MobileWorld, a more challenging benchmark than AndroidWorld, includes diverse real-world mobile tasks and interactions, revealing significant gaps in current model capabilities.  					AI-generated summary 				 Among existing online mobile-use benchmarks, AndroidWorld has emerged as the dominant benc...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 13. StoryMem enhances multi-shot video generation with cinematic quality and long-range consistency using a memory bank and pre-trained single-shot video diffusion models.  					AI-generated summary 				 Visual storytelling requires generating multi-shot videos with cinematic quality and long-range cons...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 14. Capitalization tie-out in legal diligence is a complex task that current agentic systems struggle to automate due to its multi-document reasoning and evidence traceability requirements.  					AI-generated summary 				 Before closing venture capital financing rounds, lawyers conduct diligence that in...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 15. A framework called Real2Edit2Real generates new manipulation demonstrations by using 3D reconstruction, editing, and video synthesis, improving data efficiency in robot learning.  					AI-generated summary 				 Recent progress in robot learning has been driven by large-scale datasets and powerful vi...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 16. ALIGN-Parts addresses semantic 3D part segmentation by aligning implicit 3D part representations with part descriptions using geometric, appearance, and semantic cues, supporting open-vocabulary part naming and creating a unified ontology for multiple datasets.  					AI-generated summary 				 We add...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 17. CASA, a cross-attention method enhanced with self-attention, improves vision-language models' performance on detailed visual tasks while maintaining scalability for long-context multimodal applications.  					AI-generated summary 				 Vision-language models (VLMs) are commonly trained by inserting i...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 18. The proposed framework integrates 2D material maps into 3D geometry using diffusion models and Gaussian Splatting, enhancing relighting and photorealism in reconstructed scenes.  					AI-generated summary 				 Manual modeling of material parameters and 3D geometry is a time consuming yet essential t...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 19. Research explores syllogistic reasoning in LLMs, examining their symbolic inference and natural language understanding capabilities, with some models showing perfect symbolic performance.  					AI-generated summary 				 We study syllogistic reasoning in LLMs from the logical and natural language per...
[23.12.2025 20:24] ********************************************************************************
[23.12.2025 20:24] Abstract 20. Neurophysiological brain activity is used to create interpretable axes for large language models, enhancing their controllability and interpretability.  					AI-generated summary 				 Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, whic...
[23.12.2025 20:24] Read previous papers.
[23.12.2025 20:24] Generating reviews via LLM API.
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#open_source", "#synthetic", "#optimization", "#data", "#rag", "#dataset", "#training", "#agents"], "emoji": "üîß", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "DataFlow ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–π –±
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#architecture", "#benchmark"], "emoji": "üåà", "ru": {"title": "–ï–¥–∏–Ω–æ–µ –∞–≤—Ç–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ: –≥–∞—Ä–º–æ–Ω–∏—è –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –∏ –¥–µ—Ç–∞–ª–µ–π —á–µ—Ä–µ–∑ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∞–≤—Ç–æ—Ä—ã –∏—Å—Å–ª–µ–¥—É—é—Ç —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ –∏ –æ—Ç–∫—Ä—ã–≤–∞—é—Ç –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#video", "#dataset", "#training"], "emoji": "üé¨", "ru": {"title": "–¢–æ—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é", "desc": "ReCo ‚Äî —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ –ø–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#video", "#multimodal", "#diffusion", "#dataset", "#synthetic"], "emoji": "üé¨", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å —Ç–æ—á–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∫–∞–º–µ—Ä—ã —á–µ—Ä–µ–∑ –≥–æ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –±–µ–∑ –æ—Ü–µ–Ω–∫–∏ –≥–ª—É–±–∏–Ω—ã", "desc": "InfCam ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∫–∞–º–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#open_source", "#hallucinations", "#benchmark", "#rag"], "emoji": "üîç", "ru": {"title": "–û—Ç —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–π –∫–æ—Ä–ø—É—Å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –≤ RAG", "desc": "QuCo-RAG ‚Äî —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –æ–±—ä–µ–∫—Ç–∏–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#interpretability", "#reasoning", "#alignment"], "emoji": "üß†", "ru": {"title": "–£–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö —Ç—Ä—É–¥–Ω–æ—Å—Ç–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ LLM —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞. –ê–≤—Ç–æ—Ä—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç –±–æ–ª–µ–µ 20 –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#video", "#3d", "#multimodal"], "emoji": "üé¨", "ru": {"title": "3D –≥–µ–æ–º–µ—Ç—Ä–∏—è –≤—Å—Ç—Ä–µ—á–∞–µ—Ç –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏—é: —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –∏–∑ –∫—ç—à–∞", "desc": "WorldWarp —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏, –∫–æ–º–±–∏–Ω–∏—Ä—É—è 3D –∫—ç—à –Ω–∞ –æ—Å–Ω–æ–≤–µ Gaussian Splatting
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#3d", "#agents", "#robotics"], "emoji": "ü§ñ", "ru": {"title": "–ï–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ —Å –Ω–µ—è–≤–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ –≥–µ–æ–º–µ—Ç—Ä–∏—é —Å—Ü–µ–Ω—ã", "desc": "LoGoPlanner –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å–∫–≤–æ–∑–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –º–æ–±–∏–ª—å–Ω—ã—Ö —Ä–æ–±–æ—Ç–æ–≤ –≤ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è—Ö. –°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#plp", "#training", "#benchmark"], "emoji": "üîç", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –±–µ–∑ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –∑–æ–Ω–¥–∏—Ä–æ–≤–∞–Ω–∏–µ LLM", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ IPC ‚Äî –Ω–µ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –∑–æ–Ω–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#training", "#small_models", "#agents", "#benchmark"], "emoji": "üéÆ", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π curriculum learning —á–µ—Ä–µ–∑ —Å–æ—ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—É—é –∏–≥—Ä—É –∞–≥–µ–Ω—Ç–∞ –∏ —Å–∏–º—É–ª—è—Ç–æ—Ä–∞", "desc": "GenEnv ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ—ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—É—é –∏–≥—Ä—É –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–æ–º –∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º —Å–∏–º—É–ª—è—Ç–æ—Ä–æ–º –æ–∫—Ä
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#optimization", "#training", "#benchmark", "#rlhf", "#rl", "#interpretability", "#reasoning", "#architecture"], "emoji": "üé®", "ru": {"title": "–ü–∞–ª–∏—Ç—Ä–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ –º—ã—à–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ –ª–∞—Ç–µ–Ω—Ç–Ω—É—é –º–æ–¥—É–ª—è—Ü–∏—é", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Reasoning Palette, –∫–æ
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#optimization"], "emoji": "‚ö°", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—â–∏–π –ø–∞—Ä–∞–ª–µ–ª–∏–∑–º: –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö LLM", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω LoPA ‚Äî –∞–ª–≥–æ—Ä–∏—Ç–º –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø—Ä–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#dataset", "#games", "#agents", "#benchmark"], "emoji": "üì±", "ru": {"title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ –Ω–∞—Å—ã—â–µ–Ω–∏—è: –Ω–æ–≤—ã–π —Å–ª–æ–∂–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö AI-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ MobileWorld –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π AI-–∞–≥–µ–Ω—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á–∏ –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#story_generation", "#diffusion", "#benchmark", "#video", "#dataset", "#training", "#long_context"], "emoji": "üé¨", "ru": {"title": "–ü–∞–º—è—Ç—å –∫–∞–∫ –∫–ª—é—á –∫ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–º—É –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º—É –≤–∏–¥–µ–æ—Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–Ω–∏—é", "desc": "StoryMem ‚Äî —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–Ω–æ–≥–æ–∫–∞–¥—Ä–æ–≤—ã—Ö –≤–∏–¥–µ–æ —Å –∫–∏–Ω
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#agents", "#benchmark"], "emoji": "‚öñÔ∏è", "ru": {"title": "–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∏—Ä–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∞–±–ª–∏—Ü—ã –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–µ –≤–µ–Ω—á—É—Ä–Ω—ã—Ö –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π. –ê–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#dataset", "#3d", "#training", "#video", "#robotics"], "emoji": "ü§ñ", "ru": {"title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–π –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π —á–µ—Ä–µ–∑ 3D —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–∏–¥–µ–æ—Å–∏–Ω—Ç–µ–∑", "desc": "Real2Edit2Real ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–π –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π —Ä–æ–±–æ—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#3d", "#interpretability", "#multimodal"], "emoji": "üß©", "ru": {"title": "–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–µ—è–≤–Ω—ã—Ö 3D-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —á–∞—Å—Ç–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç ALIGN-Parts ‚Äî –º–µ—Ç–æ–¥ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö 
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#architecture", "#video", "#open_source", "#long_context", "#multimodal"], "emoji": "üëÅÔ∏è", "ru": {"title": "–ü–µ—Ä–µ–∫—Ä—ë—Å—Ç–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏–µ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã—Ö vision-language –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è CASA ‚Äî –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–∫—Ä—ë—Å—Ç–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è, –¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#games", "#diffusion", "#multimodal", "#3d"], "emoji": "üé¨", "ru": {"title": "–°–∏–Ω—Ç–µ–∑ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö —Å—Ü–µ–Ω —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–µ–∫—Ü–∏—é –¥–≤—É–º–µ—Ä–Ω—ã—Ö –∫–∞—Ä—Ç", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–≤—É–º–µ—Ä–Ω—ã—Ö –∫–∞—Ä—Ç –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –≤ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—É—é –≥–µ–æ–º–µ—Ç—Ä–∏—é —Å—Ü–µ–Ω—ã —Å –ø–æ–º–æ—â—å—é –¥–∏
[23.12.2025 20:24] Using data from previous issue: {"categories": [], "emoji": "üß†", "ru": {"title": "–û—Ç –∏–Ω—Ç—É–∏—Ü–∏–∏ –∫ –ª–æ–≥–∏–∫–µ: —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –ª–∏ LLM —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ —Ä–∞—Å—Å—É–∂–¥–∞—é—â–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏?", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–∑—É—á–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ —Å–∏–ª–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–º—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—è –∏—Ö —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –µ—Å—Ç–µ—Å
[23.12.2025 20:24] Using data from previous issue: {"categories": ["#small_models", "#architecture", "#interpretability", "#training"], "emoji": "üß†", "ru": {"title": "–ú–æ–∑–≥ –∫–∞–∫ –∫–æ–º–ø–∞—Å: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ—Ñ–∏–∑–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—è
[23.12.2025 20:24] Renaming data file.
[23.12.2025 20:24] Renaming previous data. hf_papers.json to ./d/2025-12-23.json
[23.12.2025 20:24] Saving new data file.
[23.12.2025 20:24] Generating page.
[23.12.2025 20:24] Renaming previous page.
[23.12.2025 20:24] Renaming previous data. index.html to ./d/2025-12-23.html
[23.12.2025 20:24] Writing result.
[23.12.2025 20:24] Renaming log file.
[23.12.2025 20:24] Renaming previous data. log.txt to ./logs/2025-12-23_last_log.txt
