[23.01.2026 18:37] Read previous papers.
[23.01.2026 18:37] Generating top page (month).
[23.01.2026 18:37] Writing top page (month).
[23.01.2026 19:26] Read previous papers.
[23.01.2026 19:26] Get feed.
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15876
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15165
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14724
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15197
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16206
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15892
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16208
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16093
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16175
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15621
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11868
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16125
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15727
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15369
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15224
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14255
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16163
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16192
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16148
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15549
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16134
[23.01.2026 19:26] Extract page data from URL. URL: https://huggingface.co/papers/2601.15778
[23.01.2026 19:26] Extract page data from URL. URL: https://huggingface.co/papers/2601.15703
[23.01.2026 19:26] Extract page data from URL. URL: https://huggingface.co/papers/2601.15690
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15440
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.08118
[23.01.2026 19:26] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16004
[23.01.2026 19:26] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.01.2026 19:26] No deleted papers detected.
[23.01.2026 19:26] Downloading and parsing papers (pdf, html). Total: 27.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15876.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15876.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15876.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15165.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15165.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15165.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.14724.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.14724.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.14724.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15197.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15197.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15197.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16206.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16206.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16206.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15892.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15892.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15892.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16208.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16208.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16208.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16093.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16093.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16093.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16175.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16175.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16175.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15621.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15621.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15621.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.11868.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.11868.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.11868.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16125.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16125.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16125.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15727.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15727.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15727.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15369.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15369.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15369.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15224.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15224.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15224.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.14255.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.14255.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.14255.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16163.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16163.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16163.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16192.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16192.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16192.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16148.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16148.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16148.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15549.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15549.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15549.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16134.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16134.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16134.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15778.
[23.01.2026 19:26] Downloading paper 2601.15778 from https://arxiv.org/pdf/2601.15778v1...
[23.01.2026 19:26] Extracting affiliations from text.
[23.01.2026 19:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 2 ] . [ 1 8 7 7 5 1 . 1 0 6 2 : r Preprint Salesforce AI Research Jiaxin Zhang Caiming Xiong Chien-Sheng Wu Salesforce AI Research {jiaxin.zhang, cxiong, wu.jason}@salesforce.com "
[23.01.2026 19:26] Response: ```python
["Salesforce AI Research"]
```
[23.01.2026 19:26] Deleting PDF ./assets/pdf/2601.15778.pdf.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15703.
[23.01.2026 19:26] Downloading paper 2601.15703 from https://arxiv.org/pdf/2601.15703v1...
[23.01.2026 19:26] Extracting affiliations from text.
[23.01.2026 19:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Prafulla Kumar Choubey Kung-Hsiang Huang Caiming Xiong Chien-Sheng Wu Salesforce AI Research {jiaxin.zhang, pchoubey, kh.huang, cxiong, wu.jason}@salesforce.com 6 2 0 2 2 2 ] . [ 1 3 0 7 5 1 . 1 0 6 2 : r a "
[23.01.2026 19:26] Response: ```python
["Salesforce AI Research"]
```
[23.01.2026 19:26] Deleting PDF ./assets/pdf/2601.15703.pdf.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15690.
[23.01.2026 19:26] Downloading paper 2601.15690 from https://arxiv.org/pdf/2601.15690v1...
[23.01.2026 19:26] Extracting affiliations from text.
[23.01.2026 19:26] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 2 ] . [ 1 0 9 6 5 1 . 1 0 6 2 : r From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models Jiaxin Zhang1, Wendi Cui2, Zhuohang Li3, Lifu Huang4, Bradley Malin3,5, Caiming Xiong1, Chien-Sheng Wu1 2Intuit 1Salesforce AI Research 3Vanderbilt University 5Vanderbilt University Medical Center 4 University of California, Davis "
[23.01.2026 19:26] Response: ```python
[
    "Salesforce AI Research",
    "Intuit",
    "Vanderbilt University",
    "Vanderbilt University Medical Center",
    "University of California, Davis"
]
```
[23.01.2026 19:26] Deleting PDF ./assets/pdf/2601.15690.pdf.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.15440.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.15440.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.15440.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.08118.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.08118.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.08118.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Downloading and parsing paper https://huggingface.co/papers/2601.16004.
[23.01.2026 19:26] Extra JSON file exists (./assets/json/2601.16004.json), skip PDF parsing.
[23.01.2026 19:26] Paper image links file exists (./assets/img_data/2601.16004.json), skip HTML parsing.
[23.01.2026 19:26] Success.
[23.01.2026 19:26] Enriching papers with extra data.
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 0. EvoCUA introduces an evolutionary approach to computer-use agents that combines autonomous task generation with policy optimization to achieve superior performance in complex, long-horizon tasks.  					AI-generated summary 				 The development of native computer-use agents (CUA) represents a signifi...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 1. Arbitrary order generation in diffusion large language models limits reasoning capability by causing premature solution space collapse, making standard policy optimization more effective.  					AI-generated summary 				 Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 2. HERMES is a training-free architecture that enables real-time video stream understanding by utilizing a hierarchical memory framework based on KV cache reuse, achieving faster response times and maintained accuracy even with reduced video token input.  					AI-generated summary 				 Recent advanceme...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 3. BayesianVLA addresses language-action grounding issues in robot manipulation by using Bayesian decomposition to prevent information collapse and improve out-of-distribution generalization.  					AI-generated summary 				 Vision-Language-Action (VLA) models have shown promise in robot manipulation bu...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 4. LLM-in-Sandbox enables large language models to perform general intelligence tasks across diverse domains by allowing them to explore a code sandbox environment, achieving robust generalization without additional training.  					AI-generated summary 				 We introduce LLM-in-Sandbox, enabling LLMs to...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 5. Stable-DiffCoder demonstrates superior code modeling performance compared to autoregressive baselines through block diffusion continual pretraining and efficient training mechanisms.  					AI-generated summary 				 Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation a...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 6. Representation Autoencoders (RAEs) demonstrate superior performance over VAEs in large-scale text-to-image generation, showing improved stability, faster convergence, and better quality while enabling unified multimodal reasoning in shared representation spaces.  					AI-generated summary 				 Repre...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 7. SAMTok enables pixel-wise capabilities in multi-modal LLMs through discrete mask tokenization and standard training methods, achieving state-of-the-art performance on various vision-language tasks.  					AI-generated summary 				 Pixel-wise capabilities are essential for building interactive intelli...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 8. Test-time training enables AI systems to discover optimal solutions for specific scientific problems through continual learning focused on individual challenges rather than generalization.  					AI-generated summary 				 How can we use AI to discover a new state of the art for a scientific problem? ...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 9. The Qwen3-TTS series presents advanced multilingual text-to-speech models with voice cloning and controllable speech generation capabilities, utilizing dual-track LM architecture and specialized speech tokenizers for efficient streaming synthesis.  					AI-generated summary 				 In this report, we p...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 10. Terminal-Bench 2.0 presents a challenging benchmark with 89 terminal-based tasks to evaluate AI agents' capabilities in real-world scenarios.  					AI-generated summary 				 AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmar...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 11. A novel fine-grained composed image retrieval benchmark is introduced through image editing techniques, revealing significant capability gaps in existing multimodal models and exposing limitations of current benchmarks.  					AI-generated summary 				 Composed Image Retrieval (CIR) is a pivotal and ...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 12. Large language models and agent-based systems are being leveraged to automate kernel generation and optimization, addressing the scalability challenges in hardware-specific code development through structured approaches and systematic benchmarking.  					AI-generated summary 				 The performance of ...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 13. An advanced vision encoder named OpenVision 3 learns a unified visual representation for both image understanding and generation by combining VAE-compressed image latents with ViT architecture and joint optimization of reconstruction and semantic signals.  					AI-generated summary 				 This paper p...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 14. Vision-Language Models struggle with task progress estimation from partial observations, requiring new approaches like ProgressLM-45K and ProgressLM-3B to improve reasoning capabilities.  					AI-generated summary 				 Estimating task progress requires reasoning over long-horizon dynamics rather tha...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 15. VideoMaMa converts coarse masks to accurate alpha mattes using pretrained video diffusion models, enabling zero-shot generalization and scalable pseudo-labeling for video matting.  					AI-generated summary 				 Generalizing video matting models to real-world videos remains a significant challenge d...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 16. A pretrained video model is adapted into a robot policy through single-stage post-training, enabling direct action generation and planning capabilities without architectural modifications.  					AI-generated summary 				 Recent video generation models demonstrate remarkable ability to capture comple...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 17. A geometry-free framework using pre-trained diffusion transformers lifts perspective images and videos to 360¬∞ panoramas without requiring camera metadata, achieving state-of-the-art performance through token sequence processing and addressing seam artifacts via circular latent encoding.  					AI-ge...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 18. ActionMesh generates animated 3D meshes by extending 3D diffusion models with a temporal axis, producing high-quality, rig-free animations from various input types while maintaining topological consistency.  					AI-generated summary 				 Generating animated 3D objects is at the heart of many applic...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 19. VIOLA is a label-efficient framework that combines minimal expert supervision with abundant unlabeled data to enable effective multimodal large language model adaptation in low-resource video domains through density-uncertainty-weighted sampling and confidence-aware retrieval mechanisms.  					AI-ge...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 20. A systematic evaluation framework using tournament-style testing and Glicko2 rating system demonstrates effective prompt engineering for educational LLM applications, prioritizing metacognitive learning strategies.  					AI-generated summary 				 As large language models (LLMs) become increasingly c...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 21. Agentic confidence calibration addresses limitations of static calibration methods by introducing a trajectory-based diagnostic framework that improves reliability across diverse AI agent systems.  					AI-generated summary 				 AI agents are rapidly advancing from passive language models to autonom...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 22. A unified dual-process framework transforms verbalized uncertainty into active control signals for improved reasoning reliability in AI agents.  					AI-generated summary 				 Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hamper...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 23. Large language models face reliability challenges that are being addressed through uncertainty as an active control signal across advanced reasoning, autonomous agents, and reinforcement learning, supported by theoretical frameworks like Bayesian methods and conformal prediction.  					AI-generated ...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 24. We present dla-ideal-solver, a high-performance framework for simulating two-dimensional Diffusion-Limited Aggregation (DLA) using Numba-accelerated Python. By leveraging just-in-time (JIT) compilation, we achieve computational throughput comparable to legacy static implementations while retaining h...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 25. Large language models are evaluated as user simulators through a reproducible benchmark framework that assesses their ability to generate human-like conversational responses across diverse tasks.  					AI-generated summary 				 Large language models (LLMs) are increasingly used as human simulators, ...
[23.01.2026 19:26] ********************************************************************************
[23.01.2026 19:26] Abstract 26. Implementation and benchmarking of quantum circuits for estimating operational inter-branch communication witnesses on IBM Quantum hardware demonstrates visibility and coherence witness measurements under realistic device conditions.  					AI-generated summary 				 We implement and benchmark on IBM ...
[23.01.2026 19:26] Read previous papers.
[23.01.2026 19:26] Generating reviews via LLM API.
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#training", "#benchmark", "#rl"], "emoji": "üß¨", "ru": {"title": "–≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∞–≤—Ç–æ–Ω–æ–º–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏", "desc": "EvoCUA –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#math", "#optimization", "#diffusion", "#reasoning", "#rl", "#rlhf", "#training"], "emoji": "üîÑ", "ru": {"title": "–ì–∏–±–∫–æ—Å—Ç—å, —Å—Ç–∞–≤—à–∞—è –ª–æ–≤—É—à–∫–æ–π: –ø–æ—á–µ–º—É —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ª—É—á—à–µ –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –≥–µ
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#multimodal", "#inference", "#video"], "emoji": "üé¨", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è", "desc": "HERMES ‚Äî —ç—Ç–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º–µ –ø–∞–º—è—Ç–∏ —Å –ø–µ—Ä–µ–∏
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#multimodal", "#alignment", "#robotics", "#reasoning", "#training"], "emoji": "ü§ñ", "ru": {"title": "–Ø–∑—ã–∫ –≤ –¥–µ–π—Å—Ç–≤–∏–∏: –±–∞–π–µ—Å–æ–≤—Å–∫–æ–µ –∑–∞–∑–µ–º–ª–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–æ–±–æ—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω BayesianVLA ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è vision-language-action –º–æ–¥–µ–ª–µ–π —Ä–æ–±–æ—Ç–æ
[23.01.2026 19:26] Using data from previous issue: {"categories": [], "emoji": "üèúÔ∏è", "ru": {"title": "–í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –ø–µ—Å–æ—á–Ω–∏—Ü–∞ –∫–∞–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä —Ä–∞–∑—É–º–∞ –º–æ–¥–µ–ª–∏", "desc": "–†–∞–±–æ—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç LLM-in-Sandbox ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –±–æ–ª—å—à–∏–º —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å –∫–æ–¥–æ–º –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–µ–¥–º–µ—Ç–Ω—ã—Ö –æ
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#low_resource", "#optimization", "#plp", "#diffusion", "#architecture", "#training"], "emoji": "üß©", "ru": {"title": "–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –∞–≤—Ç–æ—Ä¬≠–µ–≥—Ä–µ—Å—Å–∏—é –≤ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–¥–∞", "desc": "Stable-DiffCoder ‚Äî —ç—Ç–æ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#diffusion", "#synthetic", "#open_source", "#architecture", "#training"], "emoji": "üñºÔ∏è", "ru": {"title": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—ã –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç VAE –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã Representation Autoencoders (RAE) ‚Äî –∞—Ä—Ö–∏—Ç
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#dataset", "#rl", "#training", "#benchmark", "#cv", "#multimodal"], "emoji": "üé≠", "ru": {"title": "–ü–∏–∫—Å–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –¥–∏—Å–∫—Ä–µ—Ç–Ω—É—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –º–∞—Å–æ–∫", "desc": "SAMTok ‚Äî —ç—Ç–æ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –º–∞—Å–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–∞—Å–∫–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#math", "#optimization", "#science", "#rl", "#open_source", "#training"], "emoji": "üéØ", "ru": {"title": "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ LLM –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –∑–∞–¥–∞—á", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Test-Time Training to Discover (TTT-Discover), –∫–æ—Ç–æ—Ä—ã
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#multilingual", "#multimodal", "#audio", "#dataset", "#open_source", "#architecture"], "emoji": "üé§", "ru": {"title": "–¢—Ä—ë—Ö—Å–µ–∫—É–Ω–¥–Ω–æ–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —Å —É–ª—å—Ç—Ä–∞–Ω–∏–∑–∫–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π", "desc": "Qwen3-TTS ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#agents"], "emoji": "üñ•Ô∏è", "ru": {"title": "–†–µ–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ AI –∞–≥–µ–Ω—Ç–æ–≤ –∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é —Å–ª–æ–∂–Ω—ã—Ö —Ä–∞–±–æ—Ç", "desc": "Terminal-Bench 2.0 ‚Äî —ç—Ç–æ —Å–ª–æ–∂–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 89 –∑–∞–¥–∞—á –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π AI –∞
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#dataset", "#cv"], "emoji": "üîç", "ru": {"title": "–¢–æ–Ω–∫–æ–∑–µ—Ä–Ω–∏—Å—Ç—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç —Å–ª–∞–±–æ—Å—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö EDIR –¥–ª—è –∑–∞–¥–∞—á–∏ –ø–æ–∏—Å–∫–∞ —Å–æ—Å—Ç–∞–≤–Ω
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#survey", "#open_source", "#benchmark", "#agents", "#optimization", "#science", "#plp", "#dataset"], "emoji": "‚öôÔ∏è", "ru": {"title": "–û—Ç —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∫ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏: LLM-–∞–≥–µ–Ω—Ç—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —è–¥–µ—Ä", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#multimodal", "#open_source", "#architecture", "#cv"], "emoji": "üé®", "ru": {"title": "–ï–¥–∏–Ω–æ–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç OpenVision 3 ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –≤–∏–∑—É–∞–ª—å–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –æ–±—É—á–∞–µ—Ç—Å—è –µ–¥–∏–Ω–æ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#small_models", "#training", "#benchmark"], "emoji": "üìä", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤–∏–¥–µ–Ω–∏—è –∏ —è–∑—ã–∫–∞ –ø–æ–Ω–∏–º–∞—Ç—å —Ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –≤ Vision-Language Models –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–∏—á–Ω—ã—Ö –Ω–∞–±
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#video", "#open_source", "#diffusion", "#synthetic", "#multimodal", "#dataset"], "emoji": "üé¨", "ru": {"title": "–û—Ç –≥—Ä—É–±—ã—Ö –º–∞—Å–æ–∫ –∫ —Ç–æ—á–Ω—ã–º –º–∞—Ç—Ç–∞–º: –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –≤–∏–¥–µ–æ –∫–æ–º–ø–æ–∑–∏—Ç–∏–Ω–≥ —Å –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å VideoMaMa, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≥—Ä—É–±—ã–µ –º–∞
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#benchmark", "#robotics", "#video", "#training"], "emoji": "ü§ñ", "ru": {"title": "–û—Ç –≤–∏–¥–µ–æ–ø—Ä–µ–¥–∏–∫—Ü–∏–∏ –∫ —Ä–æ–±–æ—Ç-–ø–æ–ª–∏—Ç–∏–∫–µ –≤ –æ–¥–∏–Ω —ç—Ç–∞–ø –æ–±—É—á–µ–Ω–∏—è", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è Cosmos Policy ‚Äî –º–µ—Ç–æ–¥ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –≤–∏–¥–µ–æ–º–æ–¥–µ–ª–∏ –≤ –ø–æ–ª–∏—Ç–∏–∫—É —Ä–æ–±–æ—Ç–∞ —á–µ—Ä–µ–∑ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —ç—Ç–∞–ø –ø–æ—Å—Ç–æ–±—É—á–µ–Ω–∏—è 
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#cv", "#video", "#architecture", "#diffusion", "#3d", "#multimodal"], "emoji": "üåê", "ru": {"title": "–û—Ç –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –∫ –ø–∞–Ω–æ—Ä–∞–º–µ: –≥–µ–æ–º–µ—Ç—Ä–∏—è –±–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–∞–º–µ—Ä—ã", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å 360Anything, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—ã—á–Ω—ã–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∏ –≤–∏
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#video", "#multimodal", "#architecture", "#diffusion", "#3d"], "emoji": "üé¨", "ru": {"title": "–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—è –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö 3D-—Å–µ—Ç–æ–∫", "desc": "ActionMesh ‚Äî —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞—Å—à–∏—Ä—è–µ—Ç 3D –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Å—å—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö 3D-
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#transfer_learning", "#video", "#data", "#training", "#multimodal", "#low_resource"], "emoji": "üé¨", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –≤–∏–¥–µ–æ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π", "desc": "VIOLA ‚Äî —ç—Ç–æ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ
[23.01.2026 19:26] Using data from previous issue: {"categories": ["#survey"], "emoji": "üéì", "ru": {"title": "–û—Ç –∏–Ω—Ç—É–∏—Ü–∏–∏ –∫ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º: –Ω–∞—É—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è —Ç—É—Ä–Ω–∏—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏ —Ä–µ
[23.01.2026 19:26] Querying the API.
[23.01.2026 19:26] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Agentic confidence calibration addresses limitations of static calibration methods by introducing a trajectory-based diagnostic framework that improves reliability across diverse AI agent systems.  					AI-generated summary 				 AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.
[23.01.2026 19:26] Response: ```json
{
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–µ –∑–∞–¥–∞—á–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç Holistic Trajectory Calibration (HTC) ‚Äî –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é —Å–∏—Å—Ç–µ–º—É, –∫–æ—Ç–æ—Ä–∞—è –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å—é —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞, –∏–∑–≤–ª–µ–∫–∞—è –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ—Ç –º–∞–∫—Ä–æ–¥–∏–Ω–∞–º–∏–∫–∏ –¥–æ –º–∏–∫—Ä–æ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏. –ú–µ—Ç–æ–¥ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –±–∞–∑–æ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è –ø–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ –≤–æ—Å—å–º–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö LLM. –ü–æ–¥—Ö–æ–¥ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏–π, –ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏ –∏ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ General Agent Calibrator.",
  "emoji": "üéØ",
  "title": "–û—Ç —Å—Ç–∞—Ç–∏—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∫ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ: –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω—ã—Ö AI-–∞–≥–µ–Ω—Ç–æ–≤"
}
```
[23.01.2026 19:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic confidence calibration addresses limitations of static calibration methods by introducing a trajectory-based diagnostic framework that improves reliability across diverse AI agent systems.  					AI-generated summary 				 AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents."

[23.01.2026 19:26] Response: ```python
["AGENTS", "BENCHMARK"]
```
[23.01.2026 19:26] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Agentic confidence calibration addresses limitations of static calibration methods by introducing a trajectory-based diagnostic framework that improves reliability across diverse AI agent systems.  					AI-generated summary 				 AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents."

[23.01.2026 19:26] Response: ```python
['INTERPRETABILITY', 'ALIGNMENT']
```

**Justification:**

1. **INTERPRETABILITY**: The paper explicitly discusses interpretability as a key contribution, stating "HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure." The framework is designed to extract and explain process-level features that reveal why agents fail.

2. **ALIGNMENT**: The paper addresses confidence calibration and reliability of AI agents in high-stakes settings, which relates to aligning agent behavior with human expectations and ensuring trustworthy deployment. The focus on reducing overconfidence and improving reliability is fundamentally about making agents behave in ways humans can trust and depend on.
[23.01.2026 19:26] Error. Failed to parse JSON from LLM. ["INTERPRETABILITY", "ALIGNMENT"]


**Justification:**

1. **INTERPRETABILITY**: The paper explicitly discusses interpretability as a key contribution, stating "HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure." The framework is designed to extract and explain process-level features that reveal why agents fail.

2. **ALIGNMENT**: The paper addresses confidence calibration and reliability of AI agents in high-stakes settings, which relates to aligning agent behavior with human expectations and ensuring trustworthy deployment. The focus on reducing overconfidence and improving reliability is fundamentally about making agents behave in ways humans can trust and depend on.
[23.01.2026 19:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Agentic Confidence Calibration, a new approach to improve the reliability of AI agents by addressing their overconfidence in failure. Traditional calibration methods are inadequate for dynamic, multi-step tasks that AI agents perform, as they often lead to compounding errors. The proposed Holistic Trajectory Calibration (HTC) framework analyzes the entire trajectory of an agent\'s actions, extracting important features that help in understanding and improving confidence levels. HTC not only enhances calibration performance but also offers interpretability, transferability across domains, and generalization capabilities, setting a new standard for confidence calibration in AI systems.","title":"Enhancing AI Reliability with Holistic Trajectory Calibration"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces Agentic Confidence Calibration, a new approach to improve the reliability of AI agents by addressing their overconfidence in failure. Traditional calibration methods are inadequate for dynamic, multi-step tasks that AI agents perform, as they often lead to compounding errors. The proposed Holistic Trajectory Calibration (HTC) framework analyzes the entire trajectory of an agent's actions, extracting important features that help in understanding and improving confidence levels. HTC not only enhances calibration performance but also offers interpretability, transferability across domains, and generalization capabilities, setting a new standard for confidence calibration in AI systems.", title='Enhancing AI Reliability with Holistic Trajectory Calibration'))
[23.01.2026 19:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫‰ª£ÁêÜ‰ø°ÂøÉÊ†°ÂáÜÔºåÊó®Âú®Ëß£ÂÜ≥ÈùôÊÄÅÊ†°ÂáÜÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇÈÄöËøáÂºïÂÖ•Âü∫‰∫éËΩ®ËøπÁöÑËØäÊñ≠Ê°ÜÊû∂ÔºåHolistic Trajectory Calibration (HTC) ËÉΩÂ§üÊèêÈ´ò‰∏çÂêåAI‰ª£ÁêÜÁ≥ªÁªüÁöÑÂèØÈù†ÊÄß„ÄÇHTCÊèêÂèñ‰∫Ü‰∏∞ÂØåÁöÑËøáÁ®ãÁ∫ßÁâπÂæÅÔºåËÉΩÂ§üÂ§ÑÁêÜ‰ª£ÁêÜÁ≥ªÁªüÂú®ÊâßË°åÂ§çÊùÇ‰ªªÂä°Êó∂ÁöÑÈîôËØØÁ¥ØÁßØÂíå‰∏çÁ°ÆÂÆöÊÄß„ÄÇËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÊèê‰æõ‰∫ÜËß£ÈáäÊÄß„ÄÅÂèØËøÅÁßªÊÄßÂíåËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåÊé®Âä®‰∫Ü‰ø°ÂøÉÊ†°ÂáÜÁöÑÊñ∞ËåÉÂºè„ÄÇ","title":"ÊèêÂçáAI‰ª£ÁêÜÁöÑ‰ø°ÂøÉÊ†°ÂáÜÊñ∞ÊñπÊ≥ï"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫‰ª£ÁêÜ‰ø°ÂøÉÊ†°ÂáÜÔºåÊó®Âú®Ëß£ÂÜ≥ÈùôÊÄÅÊ†°ÂáÜÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇÈÄöËøáÂºïÂÖ•Âü∫‰∫éËΩ®ËøπÁöÑËØäÊñ≠Ê°ÜÊû∂ÔºåHolistic Trajectory Calibration (HTC) ËÉΩÂ§üÊèêÈ´ò‰∏çÂêåAI‰ª£ÁêÜÁ≥ªÁªüÁöÑÂèØÈù†ÊÄß„ÄÇHTCÊèêÂèñ‰∫Ü‰∏∞ÂØåÁöÑËøáÁ®ãÁ∫ßÁâπÂæÅÔºåËÉΩÂ§üÂ§ÑÁêÜ‰ª£ÁêÜÁ≥ªÁªüÂú®ÊâßË°åÂ§çÊùÇ‰ªªÂä°Êó∂ÁöÑÈîôËØØÁ¥ØÁßØÂíå‰∏çÁ°ÆÂÆöÊÄß„ÄÇËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÊèê‰æõ‰∫ÜËß£ÈáäÊÄß„ÄÅÂèØËøÅÁßªÊÄßÂíåËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåÊé®Âä®‰∫Ü‰ø°ÂøÉÊ†°ÂáÜÁöÑÊñ∞ËåÉÂºè„ÄÇ', title='ÊèêÂçáAI‰ª£ÁêÜÁöÑ‰ø°ÂøÉÊ†°ÂáÜÊñ∞ÊñπÊ≥ï'))
[23.01.2026 19:27] Querying the API.
[23.01.2026 19:27] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A unified dual-process framework transforms verbalized uncertainty into active control signals for improved reasoning reliability in AI agents.  					AI-generated summary 				 Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents.
[23.01.2026 19:27] Response: ```json
{
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –µ–¥–∏–Ω—É—é –¥–≤—É—Ö–ø—Ä–æ—Ü–µ—Å—Å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å—é –≤ AI –∞–≥–µ–Ω—Ç–∞—Ö, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤–µ—Ä–±–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è. –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º, —á—Ç–æ –æ—à–∏–±–∫–∏ –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è –∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—é—Ç—Å—è –Ω–µ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ, –∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ –∫–∞–∫ –ø–∞—Å—Å–∏–≤–Ω—ã–µ –¥–∞—Ç—á–∏–∫–∏ –±–µ–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ AUQ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤: –ø–µ—Ä–≤—ã–π (UAM) –Ω–µ—è–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ—Ä–±–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Å–ª–µ–ø—ã—Ö —Ä–µ—à–µ–Ω–∏–π, –≤—Ç–æ—Ä–æ–π (UAR) –ø—Ä–∏–º–µ–Ω—è–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–æ–π –Ω–µ —Ç—Ä–µ–±—É—é—â–∏–π—Å—è –º–µ—Ç–æ–¥ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö.",
  "emoji": "üéØ",
  "title": "–ü—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —Å–æ–º–Ω–µ–Ω–∏–π –≤ –¥–µ–π—Å—Ç–≤–∏—è: –∞–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å—é –¥–ª—è –Ω–∞–¥—ë–∂–Ω—ã—Ö AI –∞–≥–µ–Ω—Ç–æ–≤"
}
```
[23.01.2026 19:27] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A unified dual-process framework transforms verbalized uncertainty into active control signals for improved reasoning reliability in AI agents.  					AI-generated summary 				 Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents."

[23.01.2026 19:27] Response: ```python
["AGENTS", "BENCHMARK", "TRAINING"]
```
[23.01.2026 19:27] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A unified dual-process framework transforms verbalized uncertainty into active control signals for improved reasoning reliability in AI agents.  					AI-generated summary 				 Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents."

[23.01.2026 19:27] Response: ```python
['REASONING', 'HALLUCINATIONS', 'ALIGNMENT']
```

**Justification:**

1. **REASONING**: The paper explicitly focuses on "long-horizon reasoning" and improving "reasoning reliability in AI agents" through a framework designed to enhance logical reasoning capabilities.

2. **HALLUCINATIONS**: The paper directly addresses the "Spiral of Hallucination" problem where "early epistemic errors propagate irreversibly," which is a core hallucination issue and mitigation strategy.

3. **ALIGNMENT**: The paper discusses aligning AI agent behavior with intended reliability and trustworthiness through uncertainty quantification and reflection mechanisms that ensure agents behave according to desired principles (avoiding hallucinations and maintaining calibration).
[23.01.2026 19:27] Error. Failed to parse JSON from LLM. ["REASONING", "HALLUCINATIONS", "ALIGNMENT"]


**Justification:**

1. **REASONING**: The paper explicitly focuses on "long-horizon reasoning" and improving "reasoning reliability in AI agents" through a framework designed to enhance logical reasoning capabilities.

2. **HALLUCINATIONS**: The paper directly addresses the "Spiral of Hallucination" problem where "early epistemic errors propagate irreversibly," which is a core hallucination issue and mitigation strategy.

3. **ALIGNMENT**: The paper discusses aligning AI agent behavior with intended reliability and trustworthiness through uncertainty quantification and reflection mechanisms that ensure agents behave according to desired principles (avoiding hallucinations and maintaining calibration).
[23.01.2026 19:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new framework called Dual-Process Agentic Uncertainty Quantification (AUQ) to enhance the reliability of AI agents in reasoning tasks. It addresses the issue of the \'Spiral of Hallucination,\' where initial errors in reasoning can lead to compounding mistakes. The AUQ framework combines two systems: System 1, which uses memory to manage uncertainty and prevent poor decisions, and System 2, which reflects on these uncertainties to make informed corrections only when needed. The results show that this approach improves performance and reliability in AI agents without requiring extensive training.","title":"Transforming Uncertainty into Action for Reliable AI Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces a new framework called Dual-Process Agentic Uncertainty Quantification (AUQ) to enhance the reliability of AI agents in reasoning tasks. It addresses the issue of the 'Spiral of Hallucination,' where initial errors in reasoning can lead to compounding mistakes. The AUQ framework combines two systems: System 1, which uses memory to manage uncertainty and prevent poor decisions, and System 2, which reflects on these uncertainties to make informed corrections only when needed. The results show that this approach improves performance and reliability in AI agents without requiring extensive training.", title='Transforming Uncertainty into Action for Reliable AI Reasoning'))
[23.01.2026 19:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªü‰∏ÄÁöÑÂèåËøáÁ®ãÊ°ÜÊû∂ÔºåÊó®Âú®Â∞ÜËØ≠Ë®ÄÂåñÁöÑ‰∏çÁ°ÆÂÆöÊÄßËΩ¨Âåñ‰∏∫‰∏ªÂä®ÊéßÂà∂‰ø°Âè∑Ôºå‰ªéËÄåÊèêÈ´ò‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÁöÑÊé®ÁêÜÂèØÈù†ÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÊñπÈù¢Â≠òÂú®Â±ÄÈôêÔºåÈÄöÂ∏∏Âè™ËÉΩË¢´Âä®ËØäÊñ≠È£éÈô©ÔºåËÄåÊó†Ê≥ïÊúâÊïàÂ∫îÂØπ„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÂèåËøáÁ®ã‰ª£ÁêÜ‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÔºàAUQÔºâÊ°ÜÊû∂ÁªìÂêà‰∫Ü‰∏§Áßç‰∫íË°•Êú∫Âà∂ÔºåÂàÜÂà´ÊòØÂÖ≥Ê≥®‰∏çÁ°ÆÂÆöÊÄßÁöÑËÆ∞ÂøÜÂíåÂèçÊÄùÔºåËÉΩÂ§üÂú®ÂøÖË¶ÅÊó∂Ëß¶ÂèëÊúâÈíàÂØπÊÄßÁöÑÊé®ÁêÜ„ÄÇÈÄöËøáÂ§ßÈáèÂÆûÈ™åÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÊÄßËÉΩÂíåËΩ®ËøπÊ†°ÂáÜÊñπÈù¢Ë°®Áé∞‰ºòÂºÇÔºåÊ†áÂøóÁùÄÂêëÂèØÈù†‰ª£ÁêÜËøàÂá∫‰∫ÜÈáçË¶Å‰∏ÄÊ≠•„ÄÇ","title":"Â∞Ü‰∏çÁ°ÆÂÆöÊÄßËΩ¨Âåñ‰∏∫‰∏ªÂä®ÊéßÂà∂ÔºåÊèêÂçáAIÊé®ÁêÜÂèØÈù†ÊÄß"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªü‰∏ÄÁöÑÂèåËøáÁ®ãÊ°ÜÊû∂ÔºåÊó®Âú®Â∞ÜËØ≠Ë®ÄÂåñÁöÑ‰∏çÁ°ÆÂÆöÊÄßËΩ¨Âåñ‰∏∫‰∏ªÂä®ÊéßÂà∂‰ø°Âè∑Ôºå‰ªéËÄåÊèêÈ´ò‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÁöÑÊé®ÁêÜÂèØÈù†ÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÊñπÈù¢Â≠òÂú®Â±ÄÈôêÔºåÈÄöÂ∏∏Âè™ËÉΩË¢´Âä®ËØäÊñ≠È£éÈô©ÔºåËÄåÊó†Ê≥ïÊúâÊïàÂ∫îÂØπ„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÂèåËøáÁ®ã‰ª£ÁêÜ‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÔºàAUQÔºâÊ°ÜÊû∂ÁªìÂêà‰∫Ü‰∏§Áßç‰∫íË°•Êú∫Âà∂ÔºåÂàÜÂà´ÊòØÂÖ≥Ê≥®‰∏çÁ°ÆÂÆöÊÄßÁöÑËÆ∞ÂøÜÂíåÂèçÊÄùÔºåËÉΩÂ§üÂú®ÂøÖË¶ÅÊó∂Ëß¶ÂèëÊúâÈíàÂØπÊÄßÁöÑÊé®ÁêÜ„ÄÇÈÄöËøáÂ§ßÈáèÂÆûÈ™åÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÊÄßËÉΩÂíåËΩ®ËøπÊ†°ÂáÜÊñπÈù¢Ë°®Áé∞‰ºòÂºÇÔºåÊ†áÂøóÁùÄÂêëÂèØÈù†‰ª£ÁêÜËøàÂá∫‰∫ÜÈáçË¶Å‰∏ÄÊ≠•„ÄÇ', title='Â∞Ü‰∏çÁ°ÆÂÆöÊÄßËΩ¨Âåñ‰∏∫‰∏ªÂä®ÊéßÂà∂ÔºåÊèêÂçáAIÊé®ÁêÜÂèØÈù†ÊÄß'))
[23.01.2026 19:27] Querying the API.
[23.01.2026 19:27] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models face reliability challenges that are being addressed through uncertainty as an active control signal across advanced reasoning, autonomous agents, and reinforcement learning, supported by theoretical frameworks like Bayesian methods and conformal prediction.  					AI-generated summary 				 While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in advanced reasoning to optimize computation and trigger self-correction; in autonomous agents to govern metacognitive decisions about tool use and information seeking; and in reinforcement learning to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI.
[23.01.2026 19:27] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è —ç–≤–æ–ª—é—Ü–∏—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –æ—Ç –ø–∞—Å—Å–∏–≤–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–π –º–µ—Ç—Ä–∏–∫–∏ –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É —É–ø—Ä–∞–≤–ª—è—é—â–µ–º—É —Å–∏–≥–Ω–∞–ª—É. –ê–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, –∫–∞–∫ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ —Å–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –≤ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –º–µ—Ç–∞–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö –∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞–≥—Ä–∞–¥–æ–π –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º. –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∏—Ç—Å—è –Ω–∞ –±–∞–π–µ—Å–æ–≤—Å–∫–∏—Ö –º–µ—Ç–æ–¥–∞—Ö –∏ –∫–æ–Ω—Ñ–æ—Ä–º–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –≤ –µ–¥–∏–Ω—É—é –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—É. –ê–≤—Ç–æ—Ä—ã —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å—é —è–≤–ª—è–µ—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º —Ñ–∞–∫—Ç–æ—Ä–æ–º –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã—Ö, –Ω–∞–¥—ë–∂–Ω—ã—Ö –∏ –∑–∞—Å–ª—É–∂–∏–≤–∞—é—â–∏—Ö –¥–æ–≤–µ—Ä–∏—è AI-—Å–∏—Å—Ç–µ–º.",
  "emoji": "üéØ",
  "title": "–û—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é: –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å –∫–∞–∫ –∞–∫—Ç–∏–≤–Ω—ã–π —Å–∏–≥–Ω–∞–ª –∫–æ–Ω—Ç—Ä–æ–ª—è –≤ LLM"
}
```
[23.01.2026 19:27] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models face reliability challenges that are being addressed through uncertainty as an active control signal across advanced reasoning, autonomous agents, and reinforcement learning, supported by theoretical frameworks like Bayesian methods and conformal prediction.  					AI-generated summary 				 While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in advanced reasoning to optimize computation and trigger self-correction; in autonomous agents to govern metacognitive decisions about tool use and information seeking; and in reinforcement learning to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI."

[23.01.2026 19:27] Response: ```python
["AGENTS", "RL", "TRAINING"]
```
[23.01.2026 19:27] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models face reliability challenges that are being addressed through uncertainty as an active control signal across advanced reasoning, autonomous agents, and reinforcement learning, supported by theoretical frameworks like Bayesian methods and conformal prediction.  					AI-generated summary 				 While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in advanced reasoning to optimize computation and trigger self-correction; in autonomous agents to govern metacognitive decisions about tool use and information seeking; and in reinforcement learning to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI."

[23.01.2026 19:27] Response: ```python
["SURVEY", "REASONING", "ALIGNMENT"]
```
[23.01.2026 19:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the reliability issues faced by Large Language Models (LLMs) and how uncertainty can be used to improve their performance. It highlights the shift of uncertainty from being a mere diagnostic tool to an active control signal that influences model behavior in real-time. The authors explore three key areas where uncertainty plays a crucial role: enhancing advanced reasoning, guiding autonomous agents, and improving reinforcement learning strategies. By integrating theoretical frameworks like Bayesian methods and Conformal Prediction, the paper presents a cohesive approach to developing more reliable and trustworthy AI systems.","title":"Harnessing Uncertainty for Reliable AI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the reliability issues faced by Large Language Models (LLMs) and how uncertainty can be used to improve their performance. It highlights the shift of uncertainty from being a mere diagnostic tool to an active control signal that influences model behavior in real-time. The authors explore three key areas where uncertainty plays a crucial role: enhancing advanced reasoning, guiding autonomous agents, and improving reinforcement learning strategies. By integrating theoretical frameworks like Bayesian methods and Conformal Prediction, the paper presents a cohesive approach to developing more reliable and trustworthy AI systems.', title='Harnessing Uncertainty for Reliable AI'))
[23.01.2026 19:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®È´òÈ£éÈô©È¢ÜÂüüÁöÑÂ∫îÁî®Èù¢‰∏¥ÂèØÈù†ÊÄßÊåëÊàò„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫Ü‰∏çÁ°ÆÂÆöÊÄßÂ¶Ç‰Ωï‰ªéË¢´Âä®ÁöÑËØäÊñ≠ÊåáÊ†áÊºîÂèò‰∏∫‰∏ªÂä®ÁöÑÊéßÂà∂‰ø°Âè∑Ôºå‰ª•ÊåáÂØºÊ®°ÂûãÁöÑÂÆûÊó∂Ë°å‰∏∫„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü‰∏çÁ°ÆÂÆöÊÄßÂú®È´òÁ∫ßÊé®ÁêÜ„ÄÅËá™‰∏ªÊô∫ËÉΩ‰ΩìÂíåÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÂ∫îÁî®ÔºåÂ∏ÆÂä©‰ºòÂåñËÆ°ÁÆó„ÄÅÂºïÂØºËá™Êàë‰øÆÊ≠£ÂíåÂáèÂ∞ëÂ•ñÂä±ÈªëÂÆ¢Ë°å‰∏∫„ÄÇÈÄöËøáÁªìÂêàË¥ùÂè∂ÊñØÊñπÊ≥ïÂíåÁ¨¶ÂêàÈ¢ÑÊµãÁ≠âÁêÜËÆ∫Ê°ÜÊû∂ÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜÂØπËøô‰∏ÄÂèòÈù©Ë∂ãÂäøÁöÑÁªü‰∏ÄËßÜËßí„ÄÇ","title":"ÊéåÊè°‰∏çÁ°ÆÂÆöÊÄßÔºåÊûÑÂª∫ÂèØÈù†ÁöÑAIÊú™Êù•"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®È´òÈ£éÈô©È¢ÜÂüüÁöÑÂ∫îÁî®Èù¢‰∏¥ÂèØÈù†ÊÄßÊåëÊàò„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫Ü‰∏çÁ°ÆÂÆöÊÄßÂ¶Ç‰Ωï‰ªéË¢´Âä®ÁöÑËØäÊñ≠ÊåáÊ†áÊºîÂèò‰∏∫‰∏ªÂä®ÁöÑÊéßÂà∂‰ø°Âè∑Ôºå‰ª•ÊåáÂØºÊ®°ÂûãÁöÑÂÆûÊó∂Ë°å‰∏∫„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü‰∏çÁ°ÆÂÆöÊÄßÂú®È´òÁ∫ßÊé®ÁêÜ„ÄÅËá™‰∏ªÊô∫ËÉΩ‰ΩìÂíåÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÂ∫îÁî®ÔºåÂ∏ÆÂä©‰ºòÂåñËÆ°ÁÆó„ÄÅÂºïÂØºËá™Êàë‰øÆÊ≠£ÂíåÂáèÂ∞ëÂ•ñÂä±ÈªëÂÆ¢Ë°å‰∏∫„ÄÇÈÄöËøáÁªìÂêàË¥ùÂè∂ÊñØÊñπÊ≥ïÂíåÁ¨¶ÂêàÈ¢ÑÊµãÁ≠âÁêÜËÆ∫Ê°ÜÊû∂ÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜÂØπËøô‰∏ÄÂèòÈù©Ë∂ãÂäøÁöÑÁªü‰∏ÄËßÜËßí„ÄÇ', title='ÊéåÊè°‰∏çÁ°ÆÂÆöÊÄßÔºåÊûÑÂª∫ÂèØÈù†ÁöÑAIÊú™Êù•'))
[23.01.2026 19:27] Using data from previous issue: {"categories": [], "emoji": "üåø", "ru": {"title": "–û—Ç —Ö–∞–æ—Å–∞ –∫ –ø–æ—Ä—è–¥–∫—É: —Ñ–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ—Ö–æ–¥ –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ dla-ideal-solver –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–≤—É–º–µ—Ä–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º JIT-–∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –Ω–∞ Numba. –ê–≤
[23.01.2026 19:27] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#agents", "#open_source"], "emoji": "ü™û", "ru": {"title": "–ó–µ—Ä–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ: –æ—Ü–µ–Ω–∫–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ LLM –∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ –¥–∏–∞–ª–æ–≥–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç MIRRORBENCH ‚Äî –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ–≥–æ, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫
[23.01.2026 19:27] Using data from previous issue: {"categories": [], "emoji": "‚öõÔ∏è", "ru": {"title": "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ —Å–≤–∏–¥–µ—Ç–µ–ª–∏ –º–µ–∂–≤–µ—Ç–≤–µ–≤—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∞–≤—Ç–æ—Ä—ã —Ä–µ–∞–ª–∏–∑—É—é—Ç –∏ —Ç–µ—Å—Ç–∏—Ä—É—é—Ç –Ω–∞ –∫–≤–∞–Ω—Ç–æ–≤–æ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ IBM —Å–µ–º–µ–π—Å—Ç–≤–æ –∫–≤–∞–Ω—Ç–æ–≤—ã—Ö —Å—Ö–µ–º –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–≤–∏–¥–µ—Ç–µ–ª–µ–π –º–µ–∂–≤–µ—Ç–≤–µ–≤—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –≤ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ—Ä–µ–Ω–∏—è—Ö, –ø–æ
[23.01.2026 19:27] Renaming data file.
[23.01.2026 19:27] Renaming previous data. hf_papers.json to ./d/2026-01-23.json
[23.01.2026 19:27] Saving new data file.
[23.01.2026 19:27] Generating page.
[23.01.2026 19:27] Renaming previous page.
[23.01.2026 19:27] Renaming previous data. index.html to ./d/2026-01-23.html
[23.01.2026 19:27] Writing result.
[23.01.2026 19:27] Renaming log file.
[23.01.2026 19:27] Renaming previous data. log.txt to ./logs/2026-01-23_last_log.txt
