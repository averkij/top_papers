[01.08.2025 06:22] Read previous papers.
[01.08.2025 06:22] Generating top page (month).
[01.08.2025 06:22] Writing top page (month).
[01.08.2025 07:19] Read previous papers.
[01.08.2025 07:19] Get feed.
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23726
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23779
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22879
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23682
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22968
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23698
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.21509
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23632
[01.08.2025 07:19] Extract page data from URL. URL: https://huggingface.co/papers/2507.23436
[01.08.2025 07:19] Extract page data from URL. URL: https://huggingface.co/papers/2507.23404
[01.08.2025 07:19] Extract page data from URL. URL: https://huggingface.co/papers/2507.21584
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.20519
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.23374
[01.08.2025 07:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.14793
[01.08.2025 07:19] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[01.08.2025 07:19] No deleted papers detected.
[01.08.2025 07:19] Downloading and parsing papers (pdf, html). Total: 14.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.23726.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.23726.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.23726.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.23779.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.23779.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.23779.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.22879.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.22879.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.22879.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.23682.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.23682.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.23682.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.22968.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.22968.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.22968.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.23698.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.23698.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.23698.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.21509.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.21509.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.21509.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.23632.
[01.08.2025 07:19] Extra JSON file exists (./assets/json/2507.23632.json), skip PDF parsing.
[01.08.2025 07:19] Paper image links file exists (./assets/img_data/2507.23632.json), skip HTML parsing.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.23436.
[01.08.2025 07:19] Downloading paper 2507.23436 from http://arxiv.org/pdf/2507.23436v1...
[01.08.2025 07:19] Extracting affiliations from text.
[01.08.2025 07:19] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 3 ] . [ 1 6 3 4 3 2 . 7 0 5 2 : r Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification Abdellah Zakaria Sellam1,2[0009000368762220], Salah Eddine Bekhouche3[0000000155387407], Cosimo Distante1[0000000210732390], and Abdelmalik Taleb-Ahmed4[0000000172183799] 1 Institute of Applied Sciences and Intelligent Systems CNR, Via per Monteroni, 73100 Lecce, Italy 2 Department of Innovation Engineering, University of Salento 3 UPV/EHU, University of the Basque Country, 20018 San Sebastian, Spain 4 Université Polytechnique Hauts-de-France, Université de Lille, CNRS, 59313 Valenciennes, France Abstract. Art style classification remains formidable challenge in computational aesthetics due to the scarcity of expertly labeled datasets and the intricate, often nonlinear interplay of stylistic elements. While recent dual-teacher self-supervised frameworks reduce reliance on labeled data, their linear projection layers and localized focus struggle to model global compositional context and complex style-feature interactions. We enhance the dual-teacher knowledge distillation framework to address these limitations by replacing conventional MLP projection and prediction heads with KolmogorovArnold Networks (KANs). Our approach retains complementary guidance from two teacher networks, one emphasizing localized texture and brushstroke patterns, the other capturing broader stylistic hierarchies while leveraging KANs spline-based activations to model nonlinear feature correlations with mathematical precision. Experiments on WikiArt and Pandora18k demonstrate that our approach outperforms the base dual-teacher architecture in Top-1 accuracy. Our findings highlight the importance of KANs in disentangling complex style manifolds, leading to better linear probe accuracy than MLP projections. Keywords: KAN Dual-teacher Classification knowledge-distillation Projection Art style classification is vital in computational aesthetics,"
[01.08.2025 07:19] Response: ```python
[
    "Institute of Applied Sciences and Intelligent Systems CNR, Via per Monteroni, 73100 Lecce, Italy",
    "Department of Innovation Engineering, University of Salento",
    "UPV/EHU, University of the Basque Country, 20018 San Sebastian, Spain",
    "Université Polytechnique Hauts-de-France, Université de Lille, CNRS, 59313 Valenciennes, France"
]
```
[01.08.2025 07:19] Deleting PDF ./assets/pdf/2507.23436.pdf.
[01.08.2025 07:19] Success.
[01.08.2025 07:19] Downloading and parsing paper https://huggingface.co/papers/2507.23404.
[01.08.2025 07:19] Downloading paper 2507.23404 from http://arxiv.org/pdf/2507.23404v1...
[01.08.2025 07:20] Extracting affiliations from text.
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 3 ] . [ 1 4 0 4 3 2 . 7 0 5 2 : r 2025 IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING, AUG. 31 SEP. 3, 2025, ISTANBUL, TURKEY Salah Eddine Bekhouche1 Azeddine Benlamoudi2 Yazid Bounab3 Fadi Dornaika1,4 Abdenour Hadid3,5 1 University of the Basque Country UPV/EHU, San Sebastian, Spain 2 Lab. de Genie Electrique (LAGE), University of Ouargla, Ouargla, Algeria 3 Faculty of Pharmacy, Helsinki University, Helsinki, Finland 4 IKERBASQUE, Basque Foundation for Science, Bilbao, Spain 5 Sorbonne University Abu Dhabi, Abu Dhabi, UAE ABSTRACT Arabic poses particular challenge for natural language processing (NLP) and information retrieval (IR) due to its complex morphology, optional diacritics and the coexistence of Modern Standard Arabic (MSA) and various dialects. Despite the growing global significance of Arabic, it is still underrepresented in NLP research and benchmark resources. In this paper, we present an enhanced Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At the core of our approach is novel Attentive Relevance Scoring (ARS) that replaces standard interaction mechanisms with an adaptive scoring function that more effectively models the semantic relevance between questions and passages. Our method integrates pre-trained Arabic language models and architectural refinements to improve retrieval performance and significantly increase ranking accuracy when answering Arabic questions. The code is made publicly available at GitHub. Index Terms Arabic NLP, Dense Passage Retrieval, Attentive Relevance Scoring 1. INTRODUCTION Arabic, one of the most widely spoken languages globally, presents unique linguistic challenges for natural language processing (NLP) and information retrieval (IR). Applying Dense Passage Retrieval (DPR) [1] to Arabic opens new avenues but also introduces unique challenges. Its rich morphology, frequent use of diacritics, syntactic complexity, and the coexistence of Modern Standard Arabic (M"
[01.08.2025 07:20] Response: ```python
[
    "University of the Basque Country UPV/EHU, San Sebastian, Spain",
    "Lab. de Genie Electrique (LAGE), University of Ouargla, Ouargla, Algeria",
    "Faculty of Pharmacy, Helsinki University, Helsinki, Finland",
    "IKERBASQUE, Basque Foundation for Science, Bilbao, Spain",
    "Sorbonne University Abu Dhabi, Abu Dhabi, UAE"
]
```
[01.08.2025 07:20] Deleting PDF ./assets/pdf/2507.23404.pdf.
[01.08.2025 07:20] Success.
[01.08.2025 07:20] Downloading and parsing paper https://huggingface.co/papers/2507.21584.
[01.08.2025 07:20] Downloading paper 2507.21584 from http://arxiv.org/pdf/2507.21584v2...
[01.08.2025 07:20] Extracting affiliations from text.
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:": MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs Project Page: https://kejiazhang-robust.github.io/tars web Kejia Zhang1, Keda Tao2, Zhiming Luo1*, Chang Liu4, Jiasheng Tang3,5, Huan Wang2* 1Department of Artificial Intelligence, Xiamen University 2School of Engineering, Westlake University 3DAMO Academy, Alibaba Group 4AWS AI Lab, Amazon 5Hupan Laboratory 5 2 0 2 1 3 ] . [ 2 4 8 5 1 2 . 7 0 5 2 : r Figure 1: Left: We present TARS, token-adaptive preference strategy for mitigating hallucinations in MLLMs. TARS reformulates direct preference optimization (DPO) as min-max objective that (1) minimizes behavioral misalignment via preference feedback and (2) maximizes adaptability through perturbations of visual-agnostic tokens. Right: Evaluation on LLaVA-v1.513B with preference optimization (PO) (Liu et al. 2023b) and industrial MLLMs under the AMBER benchmark (Wang et al. 2023) shows that TARS surpasses PO baselines and matches GPT-4o (Hurst et al. 2024) in hallucination suppression. Abstract Multimodal large language models (MLLMs) enable visionlanguage reasoning, yet often generate plausible outputs that are factually incorrect or visually ungrounded, thereby compromising their reliability. Direct preference optimization (DPO) is common strategy for correcting hallucinations by aligning model outputs with human preferences. Existing DPO strategies typically treat hallucination-related preferences as fixed targets, relying on static supervision signals during training. This approach tends to overfit to superficial linguistic cues in preference data, leading to distributional rigidity and spurious correlations that impair grounding in causally relevant visual information. To overcome this limitation, we propose TARS, token-adaptive preference strategy that reformulates DPO as min-max optimization problem. TARS maximizes token-level distributional shifts under semantic constraints to simulate alignment uncertainty, and simultaneously mini"
[01.08.2025 07:20] Response: ```python
[
    "Department of Artificial Intelligence, Xiamen University",
    "School of Engineering, Westlake University",
    "DAMO Academy, Alibaba Group",
    "AWS AI Lab, Amazon",
    "Hupan Laboratory"
]
```
[01.08.2025 07:20] Deleting PDF ./assets/pdf/2507.21584.pdf.
[01.08.2025 07:20] Success.
[01.08.2025 07:20] Downloading and parsing paper https://huggingface.co/papers/2507.20519.
[01.08.2025 07:20] Extra JSON file exists (./assets/json/2507.20519.json), skip PDF parsing.
[01.08.2025 07:20] Paper image links file exists (./assets/img_data/2507.20519.json), skip HTML parsing.
[01.08.2025 07:20] Success.
[01.08.2025 07:20] Downloading and parsing paper https://huggingface.co/papers/2507.23374.
[01.08.2025 07:20] Extra JSON file exists (./assets/json/2507.23374.json), skip PDF parsing.
[01.08.2025 07:20] Paper image links file exists (./assets/img_data/2507.23374.json), skip HTML parsing.
[01.08.2025 07:20] Success.
[01.08.2025 07:20] Downloading and parsing paper https://huggingface.co/papers/2507.14793.
[01.08.2025 07:20] Extra JSON file exists (./assets/json/2507.14793.json), skip PDF parsing.
[01.08.2025 07:20] Paper image links file exists (./assets/img_data/2507.14793.json), skip HTML parsing.
[01.08.2025 07:20] Success.
[01.08.2025 07:20] Enriching papers with extra data.
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 0. Seed-Prover, a lemma-style reasoning model using Lean, achieves high performance in formal theorem proving and automated mathematical reasoning through iterative refinement and specialized geometry support.  					AI-generated summary 				 LLMs have demonstrated strong mathematical reasoning abilitie...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 1. The Phi-Ground model family achieves state-of-the-art performance in GUI grounding for multimodal reasoning models, improving accuracy across various benchmarks.  					AI-generated summary 				 With the development of multimodal reasoning models, Computer Use Agents (CUAs), akin to Jarvis from "Iron...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 2. RecGPT integrates large language models into recommender systems to focus on user intent, improving content diversity and satisfaction while enhancing merchant and platform performance.  					AI-generated summary 				 Recommender systems are among the most impactful applications of artificial intell...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 3. The ViLLA framework enhances VLA models by incorporating latent actions, improving performance in both simulated and real-world robot manipulation tasks.  					AI-generated summary 				 Visual-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies th...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 4. A benchmark dataset for Spoken Dialogue Models (SDMs) in English and Chinese is presented to evaluate their performance in understanding and emulating human spoken conversations, addressing challenges like ambiguity and context-dependency.  					AI-generated summary 				 Spoken Dialogue Models (SDMs...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 5. Reinforcement Learning enhances generalizable spatial reasoning and interaction in 3D environments through cross-view goal specification and automated task synthesis, achieving zero-shot generalization and improved interaction success rates.  					AI-generated summary 				 While Reinforcement Learni...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 6. Persona vectors in large language models can monitor and control personality changes during training and deployment, enabling the identification and mitigation of undesirable traits.  					AI-generated summary 				 Large language models interact with users through a simulated 'Assistant' persona. Wh...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 7. Softmax attention is more expressive than linear attention due to its recurrent form, which can be analyzed using RNN components.  					AI-generated summary 				 Since its introduction, softmax attention has become the backbone of modern transformer architectures due to its expressiveness and scalab...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 8. Enhancing dual-teacher self-supervised frameworks with Kolmogorov-Arnold Networks improves art style classification by better modeling nonlinear feature correlations and disentangling complex style manifolds.  					AI-generated summary 				 Art style classification remains a formidable challenge in ...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 9. An enhanced Dense Passage Retrieval framework for Arabic uses a novel Attentive Relevance Scoring mechanism to improve retrieval performance and ranking accuracy.  					AI-generated summary 				 Arabic poses a particular challenge for natural language processing (NLP) and information retrieval (IR) ...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 10. TARS, a token-adaptive preference strategy, improves multimodal large language models by reducing hallucinations through min-max optimization under semantic constraints.  					AI-generated summary 				 Multimodal large language models (MLLMs) enable vision-language reasoning, yet often generate plau...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 11. AgroBench evaluates vision-language models across agricultural tasks, revealing areas for improvement in fine-grained identification, particularly weed identification, with expert-annotated categories.  					AI-generated summary 				 Precise automated understanding of agricultural tasks such as dise...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 12. NeRF-GS combines Neural Radiance Fields and 3D Gaussian Splatting to enhance 3D scene representation and performance through joint optimization and shared spatial information.  					AI-generated summary 				 We introduce NeRF-GS, a novel framework that jointly optimizes Neural Radiance Fields (NeRF)...
[01.08.2025 07:20] ********************************************************************************
[01.08.2025 07:20] Abstract 13. Equivariant neural network architectures are extended to handle time-parameterized transformations, improving performance in sequence models like RNNs.  					AI-generated summary 				 Data arrives at our senses as a continuous stream, smoothly transforming from one instant to the next. These smooth ...
[01.08.2025 07:20] Read previous papers.
[01.08.2025 07:20] Generating reviews via LLM API.
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#optimization", "#training", "#math", "#reasoning", "#rl"], "emoji": "🧠", "ru": {"title": "Прорыв в автоматическом доказательстве теорем с помощью ИИ", "desc": "Seed-Prover - это модель для автоматического доказательства теорем, использующая язык Lean. Она применяет итеративное уточ
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#agents", "#dataset", "#optimization", "#reasoning", "#training", "#multimodal"], "emoji": "🖥️", "ru": {"title": "Phi-Ground: прорыв в точности привязки GUI для ИИ-агентов", "desc": "Семейство моделей Phi-Ground достигает передовых результатов в задаче привязки графического интерфей
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#optimization", "#training", "#reasoning", "#alignment", "#multimodal"], "emoji": "🎯", "ru": {"title": "RecGPT: Рекомендации, ориентированные на намерения пользователей", "desc": "RecGPT - это новая система рекомендаций, интегрирующая большие языковые модели (LLM) для фокусировки на
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#optimization", "#agents", "#agi", "#games", "#robotics", "#architecture"], "emoji": "🤖", "ru": {"title": "ViLLA: Улучшение роботизированных манипуляций с помощью латентных действий", "desc": "Фреймворк ViLLA улучшает модели визуально-языкового действия (VLA) путем включения латентн
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#survey", "#long_context", "#benchmark", "#dataset", "#multimodal"], "emoji": "🗣️", "ru": {"title": "Бенчмарк для оценки разговорных ИИ-моделей в реальных условиях", "desc": "В статье представлен набор данных для оценки разговорных диалоговых моделей на английском и китайском языках
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#games", "#3d", "#rl"], "emoji": "🧠", "ru": {"title": "RL открывает новые горизонты пространственного мышления для ИИ", "desc": "Данная статья представляет метод улучшения пространственного мышления и взаимодействия агентов в 3D-средах с п
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#rlhf", "#hallucinations", "#data", "#ethics", "#training", "#alignment"], "emoji": "🎭", "ru": {"title": "Векторы персоны: ключ к контролю личности ИИ-ассистентов", "desc": "Статья представляет концепцию векторов персоны в больших языковых моделях. Эти векторы позволяют отслеживать 
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#interpretability"], "emoji": "🔍", "ru": {"title": "Раскрывая силу софтмакс-внимания через призму RNN", "desc": "Статья исследует различия между софтмакс-вниманием и линейным вниманием в нейронных сетях. Авторы показывают, что софтмакс-внимание можн
[01.08.2025 07:20] Querying the API.
[01.08.2025 07:20] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Enhancing dual-teacher self-supervised frameworks with Kolmogorov-Arnold Networks improves art style classification by better modeling nonlinear feature correlations and disentangling complex style manifolds.  					AI-generated summary 				 Art style classification remains a formidable challenge in computational aesthetics due to the scarcity of expertly labeled datasets and the intricate, often nonlinear interplay of stylistic elements. While recent dual-teacher self-supervised frameworks reduce reliance on labeled data, their linear projection layers and localized focus struggle to model global compositional context and complex style-feature interactions. We enhance the dual-teacher knowledge distillation framework to address these limitations by replacing conventional MLP projection and prediction heads with Kolmogorov-Arnold Networks (KANs). Our approach retains complementary guidance from two teacher networks, one emphasizing localized texture and brushstroke patterns, the other capturing broader stylistic hierarchies while leveraging KANs' spline-based activations to model nonlinear feature correlations with mathematical precision. Experiments on WikiArt and Pandora18k demonstrate that our approach outperforms the base dual teacher architecture in Top-1 accuracy. Our findings highlight the importance of KANs in disentangling complex style manifolds, leading to better linear probe accuracy than MLP projections.
[01.08.2025 07:20] Response: {
  "desc": "Статья представляет усовершенствованный метод самообучения с двумя учителями для классификации стилей искусства. Авторы заменяют стандартные MLP-слои на сети Колмогорова-Арнольда (KAN) для лучшего моделирования нелинейных корреляций признаков. Этот подход сохраняет преимущества двух сетей-учителей, фокусируясь как на локальных текстурах, так и на глобальных стилистических иерархиях. Эксперименты показывают превосходство предложенного метода над базовой архитектурой с двумя учителями в точности классификации.",
  "emoji": "🎨",
  "title": "Сети Колмогорова-Арнольда улучшают самообучение в классификации стилей искусства"
}
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Enhancing dual-teacher self-supervised frameworks with Kolmogorov-Arnold Networks improves art style classification by better modeling nonlinear feature correlations and disentangling complex style manifolds.  					AI-generated summary 				 Art style classification remains a formidable challenge in computational aesthetics due to the scarcity of expertly labeled datasets and the intricate, often nonlinear interplay of stylistic elements. While recent dual-teacher self-supervised frameworks reduce reliance on labeled data, their linear projection layers and localized focus struggle to model global compositional context and complex style-feature interactions. We enhance the dual-teacher knowledge distillation framework to address these limitations by replacing conventional MLP projection and prediction heads with Kolmogorov-Arnold Networks (KANs). Our approach retains complementary guidance from two teacher networks, one emphasizing localized texture and brushstroke patterns, the other capturing broader stylistic hierarchies while leveraging KANs' spline-based activations to model nonlinear feature correlations with mathematical precision. Experiments on WikiArt and Pandora18k demonstrate that our approach outperforms the base dual teacher architecture in Top-1 accuracy. Our findings highlight the importance of KANs in disentangling complex style manifolds, leading to better linear probe accuracy than MLP projections."

[01.08.2025 07:20] Response: ```python
['CV', 'MATH', 'TRAINING']
```
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Enhancing dual-teacher self-supervised frameworks with Kolmogorov-Arnold Networks improves art style classification by better modeling nonlinear feature correlations and disentangling complex style manifolds.  					AI-generated summary 				 Art style classification remains a formidable challenge in computational aesthetics due to the scarcity of expertly labeled datasets and the intricate, often nonlinear interplay of stylistic elements. While recent dual-teacher self-supervised frameworks reduce reliance on labeled data, their linear projection layers and localized focus struggle to model global compositional context and complex style-feature interactions. We enhance the dual-teacher knowledge distillation framework to address these limitations by replacing conventional MLP projection and prediction heads with Kolmogorov-Arnold Networks (KANs). Our approach retains complementary guidance from two teacher networks, one emphasizing localized texture and brushstroke patterns, the other capturing broader stylistic hierarchies while leveraging KANs' spline-based activations to model nonlinear feature correlations with mathematical precision. Experiments on WikiArt and Pandora18k demonstrate that our approach outperforms the base dual teacher architecture in Top-1 accuracy. Our findings highlight the importance of KANs in disentangling complex style manifolds, leading to better linear probe accuracy than MLP projections."

[01.08.2025 07:20] Response: ```python
["OPTIMIZATION"]
```
[01.08.2025 07:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents an enhancement to dual-teacher self-supervised frameworks for art style classification by integrating Kolmogorov-Arnold Networks (KANs). The authors argue that traditional linear projection layers fail to capture the complex, nonlinear relationships between stylistic features. By using KANs, which utilize spline-based activations, the model can better represent these intricate correlations and disentangle complex style manifolds. Experimental results show that this improved framework significantly increases classification accuracy on datasets like WikiArt and Pandora18k compared to the original dual-teacher architecture.","title":"Harnessing KANs for Superior Art Style Classification"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents an enhancement to dual-teacher self-supervised frameworks for art style classification by integrating Kolmogorov-Arnold Networks (KANs). The authors argue that traditional linear projection layers fail to capture the complex, nonlinear relationships between stylistic features. By using KANs, which utilize spline-based activations, the model can better represent these intricate correlations and disentangle complex style manifolds. Experimental results show that this improved framework significantly increases classification accuracy on datasets like WikiArt and Pandora18k compared to the original dual-teacher architecture.', title='Harnessing KANs for Superior Art Style Classification'))
[01.08.2025 07:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种增强的双教师自监督框架，通过引入Kolmogorov-Arnold网络（KANs）来改善艺术风格分类。传统的线性投影层无法有效建模复杂的风格特征交互，而KANs能够更好地捕捉非线性特征相关性。我们的方法结合了两个教师网络的互补指导，一个专注于局部纹理和笔触模式，另一个则关注更广泛的风格层次。实验结果表明，使用KANs的框架在WikiArt和Pandora18k数据集上显著提高了分类准确率。","title":"利用KANs提升艺术风格分类的准确性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种增强的双教师自监督框架，通过引入Kolmogorov-Arnold网络（KANs）来改善艺术风格分类。传统的线性投影层无法有效建模复杂的风格特征交互，而KANs能够更好地捕捉非线性特征相关性。我们的方法结合了两个教师网络的互补指导，一个专注于局部纹理和笔触模式，另一个则关注更广泛的风格层次。实验结果表明，使用KANs的框架在WikiArt和Pandora18k数据集上显著提高了分类准确率。', title='利用KANs提升艺术风格分类的准确性'))
[01.08.2025 07:20] Querying the API.
[01.08.2025 07:20] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

An enhanced Dense Passage Retrieval framework for Arabic uses a novel Attentive Relevance Scoring mechanism to improve retrieval performance and ranking accuracy.  					AI-generated summary 				 Arabic poses a particular challenge for natural language processing (NLP) and information retrieval (IR) due to its complex morphology, optional diacritics and the coexistence of Modern Standard Arabic (MSA) and various dialects. Despite the growing global significance of Arabic, it is still underrepresented in NLP research and benchmark resources. In this paper, we present an enhanced Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At the core of our approach is a novel Attentive Relevance Scoring (ARS) that replaces standard interaction mechanisms with an adaptive scoring function that more effectively models the semantic relevance between questions and passages. Our method integrates pre-trained Arabic language models and architectural refinements to improve retrieval performance and significantly increase ranking accuracy when answering Arabic questions. The code is made publicly available at https://github.com/Bekhouche/APR{GitHub}.
[01.08.2025 07:20] Response: {
  "desc": "Статья представляет усовершенствованную систему плотного поиска пассажей (Dense Passage Retrieval) для арабского языка. Авторы разработали новый механизм оценки релевантности на основе внимания (Attentive Relevance Scoring), который более эффективно моделирует семантическую связь между вопросами и текстовыми фрагментами. Система интегрирует предобученные языковые модели для арабского языка и архитектурные улучшения для повышения точности ранжирования при ответах на вопросы. Код проекта доступен в открытом репозитории на GitHub.",
  "emoji": "🕌",
  "title": "Улучшенный поиск по арабским текстам с помощью механизма внимания"
}
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"An enhanced Dense Passage Retrieval framework for Arabic uses a novel Attentive Relevance Scoring mechanism to improve retrieval performance and ranking accuracy.  					AI-generated summary 				 Arabic poses a particular challenge for natural language processing (NLP) and information retrieval (IR) due to its complex morphology, optional diacritics and the coexistence of Modern Standard Arabic (MSA) and various dialects. Despite the growing global significance of Arabic, it is still underrepresented in NLP research and benchmark resources. In this paper, we present an enhanced Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At the core of our approach is a novel Attentive Relevance Scoring (ARS) that replaces standard interaction mechanisms with an adaptive scoring function that more effectively models the semantic relevance between questions and passages. Our method integrates pre-trained Arabic language models and architectural refinements to improve retrieval performance and significantly increase ranking accuracy when answering Arabic questions. The code is made publicly available at https://github.com/Bekhouche/APR{GitHub}."

[01.08.2025 07:20] Response: ```python
['DATASET', 'MULTILINGUAL', 'ARCHITECTURE']
```
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"An enhanced Dense Passage Retrieval framework for Arabic uses a novel Attentive Relevance Scoring mechanism to improve retrieval performance and ranking accuracy.  					AI-generated summary 				 Arabic poses a particular challenge for natural language processing (NLP) and information retrieval (IR) due to its complex morphology, optional diacritics and the coexistence of Modern Standard Arabic (MSA) and various dialects. Despite the growing global significance of Arabic, it is still underrepresented in NLP research and benchmark resources. In this paper, we present an enhanced Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At the core of our approach is a novel Attentive Relevance Scoring (ARS) that replaces standard interaction mechanisms with an adaptive scoring function that more effectively models the semantic relevance between questions and passages. Our method integrates pre-trained Arabic language models and architectural refinements to improve retrieval performance and significantly increase ranking accuracy when answering Arabic questions. The code is made publicly available at https://github.com/Bekhouche/APR{GitHub}."

[01.08.2025 07:20] Response: ```python
['LOW_RESOURCE', 'OPEN_SOURCE']
```
[01.08.2025 07:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces an improved Dense Passage Retrieval (DPR) framework tailored for the Arabic language, addressing its unique challenges in natural language processing. The key innovation is the Attentive Relevance Scoring (ARS) mechanism, which enhances the way relevance is assessed between questions and passages. By utilizing pre-trained Arabic language models and refining the architecture, the framework boosts both retrieval performance and ranking accuracy. This advancement aims to better support information retrieval tasks in Arabic, a language that has been underrepresented in NLP research.","title":"Enhancing Arabic Retrieval with Attentive Relevance Scoring"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces an improved Dense Passage Retrieval (DPR) framework tailored for the Arabic language, addressing its unique challenges in natural language processing. The key innovation is the Attentive Relevance Scoring (ARS) mechanism, which enhances the way relevance is assessed between questions and passages. By utilizing pre-trained Arabic language models and refining the architecture, the framework boosts both retrieval performance and ranking accuracy. This advancement aims to better support information retrieval tasks in Arabic, a language that has been underrepresented in NLP research.', title='Enhancing Arabic Retrieval with Attentive Relevance Scoring'))
[01.08.2025 07:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种针对阿拉伯语的增强型密集段落检索框架，旨在提高检索性能和排名准确性。我们引入了一种新颖的注意力相关评分机制，替代了传统的交互机制，更有效地建模问题与段落之间的语义相关性。该方法结合了预训练的阿拉伯语语言模型和架构改进，显著提升了回答阿拉伯语问题时的检索效果。我们的代码已公开，供研究人员使用。","title":"提升阿拉伯语检索性能的新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种针对阿拉伯语的增强型密集段落检索框架，旨在提高检索性能和排名准确性。我们引入了一种新颖的注意力相关评分机制，替代了传统的交互机制，更有效地建模问题与段落之间的语义相关性。该方法结合了预训练的阿拉伯语语言模型和架构改进，显著提升了回答阿拉伯语问题时的检索效果。我们的代码已公开，供研究人员使用。', title='提升阿拉伯语检索性能的新方法'))
[01.08.2025 07:20] Querying the API.
[01.08.2025 07:20] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

TARS, a token-adaptive preference strategy, improves multimodal large language models by reducing hallucinations through min-max optimization under semantic constraints.  					AI-generated summary 				 Multimodal large language models (MLLMs) enable vision-language reasoning, yet often generate plausible outputs that are factually incorrect or visually ungrounded, thereby compromising their reliability. Direct preference optimization (DPO) is a common strategy for correcting hallucinations by aligning model outputs with human preferences. Existing DPO strategies typically treat hallucination-related preferences as fixed targets, relying on static supervision signals during training. This approach tends to overfit to superficial linguistic cues in preference data, leading to distributional rigidity and spurious correlations that impair grounding in causally relevant visual information. To overcome this limitation, we propose TARS, a token-adaptive preference strategy that reformulates DPO as a min-max optimization problem. TARS maximizes token-level distributional shifts under semantic constraints to simulate alignment uncertainty, and simultaneously minimizes the expected preference loss under these controlled perturbations. This joint objective preserves causal grounding while mitigating overfitting to preference patterns, thereby reducing hallucinations in multimodal reasoning. We evaluate TARS on multiple hallucination benchmarks and find consistently strong performance. Using only 4.8k preference samples and no expert feedback, TARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition value from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on several key metrics.
[01.08.2025 07:20] Response: {
  "desc": "TARS - это новая стратегия оптимизации предпочтений для мультимодальных больших языковых моделей. Она использует min-max оптимизацию с семантическими ограничениями для уменьшения галлюцинаций. TARS максимизирует сдвиги распределения на уровне токенов, одновременно минимизируя ожидаемые потери предпочтений. Это позволяет сохранить причинно-следственную связь и уменьшить переобучение на паттернах предпочтений, снижая уровень галлюцинаций в мультимодальных рассуждениях.",
  "emoji": "🧠",
  "title": "TARS: Адаптивная оптимизация для борьбы с галлюцинациями в мультимодальных ИИ"
}
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TARS, a token-adaptive preference strategy, improves multimodal large language models by reducing hallucinations through min-max optimization under semantic constraints.  					AI-generated summary 				 Multimodal large language models (MLLMs) enable vision-language reasoning, yet often generate plausible outputs that are factually incorrect or visually ungrounded, thereby compromising their reliability. Direct preference optimization (DPO) is a common strategy for correcting hallucinations by aligning model outputs with human preferences. Existing DPO strategies typically treat hallucination-related preferences as fixed targets, relying on static supervision signals during training. This approach tends to overfit to superficial linguistic cues in preference data, leading to distributional rigidity and spurious correlations that impair grounding in causally relevant visual information. To overcome this limitation, we propose TARS, a token-adaptive preference strategy that reformulates DPO as a min-max optimization problem. TARS maximizes token-level distributional shifts under semantic constraints to simulate alignment uncertainty, and simultaneously minimizes the expected preference loss under these controlled perturbations. This joint objective preserves causal grounding while mitigating overfitting to preference patterns, thereby reducing hallucinations in multimodal reasoning. We evaluate TARS on multiple hallucination benchmarks and find consistently strong performance. Using only 4.8k preference samples and no expert feedback, TARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition value from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on several key metrics."

[01.08.2025 07:20] Response: ```python
['MULTIMODAL', 'RLHF', 'BENCHMARK']
```
[01.08.2025 07:20] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TARS, a token-adaptive preference strategy, improves multimodal large language models by reducing hallucinations through min-max optimization under semantic constraints.  					AI-generated summary 				 Multimodal large language models (MLLMs) enable vision-language reasoning, yet often generate plausible outputs that are factually incorrect or visually ungrounded, thereby compromising their reliability. Direct preference optimization (DPO) is a common strategy for correcting hallucinations by aligning model outputs with human preferences. Existing DPO strategies typically treat hallucination-related preferences as fixed targets, relying on static supervision signals during training. This approach tends to overfit to superficial linguistic cues in preference data, leading to distributional rigidity and spurious correlations that impair grounding in causally relevant visual information. To overcome this limitation, we propose TARS, a token-adaptive preference strategy that reformulates DPO as a min-max optimization problem. TARS maximizes token-level distributional shifts under semantic constraints to simulate alignment uncertainty, and simultaneously minimizes the expected preference loss under these controlled perturbations. This joint objective preserves causal grounding while mitigating overfitting to preference patterns, thereby reducing hallucinations in multimodal reasoning. We evaluate TARS on multiple hallucination benchmarks and find consistently strong performance. Using only 4.8k preference samples and no expert feedback, TARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition value from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on several key metrics."

[01.08.2025 07:20] Response: ```python
["HALLUCINATIONS", "OPTIMIZATION"]
```
[01.08.2025 07:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces TARS, a novel token-adaptive preference strategy designed to enhance multimodal large language models (MLLMs) by minimizing hallucinations. TARS reformulates direct preference optimization (DPO) as a min-max optimization problem, allowing for dynamic adjustments to token-level distributions while adhering to semantic constraints. This approach helps prevent overfitting to fixed preference patterns, which can lead to misleading outputs, by introducing controlled perturbations that maintain causal grounding. The results demonstrate that TARS significantly reduces hallucination rates and improves performance on various benchmarks, outperforming traditional DPO methods.","title":"TARS: Reducing Hallucinations in MLLMs with Adaptive Preferences"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces TARS, a novel token-adaptive preference strategy designed to enhance multimodal large language models (MLLMs) by minimizing hallucinations. TARS reformulates direct preference optimization (DPO) as a min-max optimization problem, allowing for dynamic adjustments to token-level distributions while adhering to semantic constraints. This approach helps prevent overfitting to fixed preference patterns, which can lead to misleading outputs, by introducing controlled perturbations that maintain causal grounding. The results demonstrate that TARS significantly reduces hallucination rates and improves performance on various benchmarks, outperforming traditional DPO methods.', title='TARS: Reducing Hallucinations in MLLMs with Adaptive Preferences'))
[01.08.2025 07:20] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TARS是一种基于令牌自适应的偏好策略，旨在通过在语义约束下进行最小-最大优化来减少多模态大语言模型中的幻觉现象。传统的直接偏好优化（DPO）方法通常将幻觉相关的偏好视为固定目标，导致模型过拟合于表面语言线索。TARS通过重新构建DPO为最小-最大优化问题，最大化令牌级别的分布变化，同时最小化期望的偏好损失，从而保持因果基础并减少幻觉。实验表明，TARS在多个基准测试中表现优异，显著降低了幻觉率。","title":"TARS：减少幻觉的智能偏好策略"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TARS是一种基于令牌自适应的偏好策略，旨在通过在语义约束下进行最小-最大优化来减少多模态大语言模型中的幻觉现象。传统的直接偏好优化（DPO）方法通常将幻觉相关的偏好视为固定目标，导致模型过拟合于表面语言线索。TARS通过重新构建DPO为最小-最大优化问题，最大化令牌级别的分布变化，同时最小化期望的偏好损失，从而保持因果基础并减少幻觉。实验表明，TARS在多个基准测试中表现优异，显著降低了幻觉率。', title='TARS：减少幻觉的智能偏好策略'))
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#cv", "#open_source", "#science", "#dataset", "#benchmark"], "emoji": "🌾", "ru": {"title": "AgroBench: экспертная оценка ИИ в сельском хозяйстве", "desc": "AgroBench - это новый эталонный тест для оценки моделей компьютерного зрения и обработки естественного языка в сельскохозяйстве
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#3d", "#benchmark"], "emoji": "🌟", "ru": {"title": "NeRF-GS: Синергия нейронных полей и гауссова сплаттинга для революционного 3D-моделирования", "desc": "NeRF-GS - это новая система, объединяющая нейронные радиационные поля (NeRF) и трехмерное гауссово сплаттинг (3DGS) для улучшени
[01.08.2025 07:20] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization"], "emoji": "⏳", "ru": {"title": "Эквивариантность во времени: новый подход к обработке последовательностей", "desc": "Статья расширяет концепцию эквивариантных нейронных сетей для обработки преобразований, параметризованных во времени. Эт
[01.08.2025 07:20] Renaming data file.
[01.08.2025 07:20] Renaming previous data. hf_papers.json to ./d/2025-08-01.json
[01.08.2025 07:20] Saving new data file.
[01.08.2025 07:20] Generating page.
[01.08.2025 07:20] Renaming previous page.
[01.08.2025 07:20] Renaming previous data. index.html to ./d/2025-08-01.html
[01.08.2025 07:20] Writing result.
[01.08.2025 07:20] Renaming log file.
[01.08.2025 07:20] Renaming previous data. log.txt to ./logs/2025-08-01_last_log.txt
