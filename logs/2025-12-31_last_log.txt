[31.12.2025 15:22] Read previous papers.
[31.12.2025 15:22] Generating top page (month).
[31.12.2025 15:22] Writing top page (month).
[31.12.2025 16:28] Read previous papers.
[31.12.2025 16:28] Get feed.
[31.12.2025 16:28] Get page data from previous paper. URL: https://huggingface.co/papers/2512.21185
[31.12.2025 16:28] Get page data from previous paper. URL: https://huggingface.co/papers/2512.22525
[31.12.2025 16:28] Get page data from previous paper. URL: https://huggingface.co/papers/2512.23675
[31.12.2025 16:28] Get page data from previous paper. URL: https://huggingface.co/papers/2512.23165
[31.12.2025 16:28] Get page data from previous paper. URL: https://huggingface.co/papers/2512.22469
[31.12.2025 16:28] Get page data from previous paper. URL: https://huggingface.co/papers/2512.21008
[31.12.2025 16:28] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.12.2025 16:28] No deleted papers detected.
[31.12.2025 16:28] Downloading and parsing papers (pdf, html). Total: 6.
[31.12.2025 16:28] Downloading and parsing paper https://huggingface.co/papers/2512.21185.
[31.12.2025 16:28] Extra JSON file exists (./assets/json/2512.21185.json), skip PDF parsing.
[31.12.2025 16:28] Paper image links file exists (./assets/img_data/2512.21185.json), skip HTML parsing.
[31.12.2025 16:28] Success.
[31.12.2025 16:28] Downloading and parsing paper https://huggingface.co/papers/2512.22525.
[31.12.2025 16:28] Extra JSON file exists (./assets/json/2512.22525.json), skip PDF parsing.
[31.12.2025 16:28] Paper image links file exists (./assets/img_data/2512.22525.json), skip HTML parsing.
[31.12.2025 16:28] Success.
[31.12.2025 16:28] Downloading and parsing paper https://huggingface.co/papers/2512.23675.
[31.12.2025 16:28] Extra JSON file exists (./assets/json/2512.23675.json), skip PDF parsing.
[31.12.2025 16:28] Paper image links file exists (./assets/img_data/2512.23675.json), skip HTML parsing.
[31.12.2025 16:28] Success.
[31.12.2025 16:28] Downloading and parsing paper https://huggingface.co/papers/2512.23165.
[31.12.2025 16:28] Extra JSON file exists (./assets/json/2512.23165.json), skip PDF parsing.
[31.12.2025 16:28] Paper image links file exists (./assets/img_data/2512.23165.json), skip HTML parsing.
[31.12.2025 16:28] Success.
[31.12.2025 16:28] Downloading and parsing paper https://huggingface.co/papers/2512.22469.
[31.12.2025 16:28] Extra JSON file exists (./assets/json/2512.22469.json), skip PDF parsing.
[31.12.2025 16:28] Paper image links file exists (./assets/img_data/2512.22469.json), skip HTML parsing.
[31.12.2025 16:28] Success.
[31.12.2025 16:28] Downloading and parsing paper https://huggingface.co/papers/2512.21008.
[31.12.2025 16:28] Extra JSON file exists (./assets/json/2512.21008.json), skip PDF parsing.
[31.12.2025 16:28] Paper image links file exists (./assets/img_data/2512.21008.json), skip HTML parsing.
[31.12.2025 16:28] Success.
[31.12.2025 16:28] Enriching papers with extra data.
[31.12.2025 16:28] ********************************************************************************
[31.12.2025 16:28] Abstract 0. In this report, we introduce UltraShape 1.0, a scalable 3D diffusion framework for high-fidelity 3D geometry generation. The proposed approach adopts a two-stage generation pipeline: a coarse global structure is first synthesized and then refined to produce detailed, high-quality geometry. To suppor...
[31.12.2025 16:28] ********************************************************************************
[31.12.2025 16:28] Abstract 1. Recently unified generation and editing models have achieved remarkable success with their impressive performance. These models rely mainly on text prompts for instruction-based editing and generation, but language often fails to capture users intended edit locations and fine-grained visual details....
[31.12.2025 16:28] ********************************************************************************
[31.12.2025 16:28] Abstract 2. We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture -- a Transformer with sliding-window attention. However, our model continues learning at test time via next-token prediction on ...
[31.12.2025 16:28] ********************************************************************************
[31.12.2025 16:28] Abstract 3. We systematically evaluate Parameter-Efficient Fine-Tuning (PEFT) methods under the paradigm of Reinforcement Learning with Verifiable Rewards (RLVR). RLVR incentivizes language models to enhance their reasoning capabilities through verifiable feedback; however, while methods like LoRA are commonly ...
[31.12.2025 16:28] ********************************************************************************
[31.12.2025 16:28] Abstract 4. The issue localization task aims to identify the locations in a software repository that requires modification given a natural language issue description. This task is fundamental yet challenging in automated software engineering due to the semantic gap between issue description and source code impl...
[31.12.2025 16:28] ********************************************************************************
[31.12.2025 16:28] Abstract 5. Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understan...
[31.12.2025 16:28] Read previous papers.
[31.12.2025 16:28] Generating reviews via LLM API.
[31.12.2025 16:28] Using data from previous issue: {"categories": ["#3d", "#data", "#diffusion", "#dataset", "#open_source", "#architecture"], "emoji": "üé≤", "ru": {"title": "–î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—è –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ 3D –≥–µ–æ–º–µ—Ç—Ä–∏–∏", "desc": "UltraShape 1.0 ‚Äî —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è 3D –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π 3D –≥–µ–æ–º–µ—Ç—Ä–∏–∏. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ
[31.12.2025 16:28] Using data from previous issue: {"categories": ["#multimodal", "#architecture", "#dataset", "#benchmark"], "emoji": "üé®", "ru": {"title": "–°–∫–µ—Ç—á-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å DreamOmni3, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞
[31.12.2025 16:28] Using data from previous issue: {"categories": ["#long_context", "#optimization", "#open_source", "#training", "#architecture"], "emoji": "üß†", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –¥–ª–∏–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–∞—Ü–∏—é –≤–µ—Å–æ–≤", "desc": "–ê–≤—Ç–æ—Ä—ã –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É—é—Ç –∑–∞–¥–∞—á—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö –∫–∞–∫ –ø—Ä–æ–±–ª–µ–º—É continual 
[31.12.2025 16:28] Using data from previous issue: {"categories": ["#benchmark", "#training", "#optimization", "#rl", "#reasoning", "#math"], "emoji": "üéØ", "ru": {"title": "–í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ Parameter-Efficient
[31.12.2025 16:28] Using data from previous issue: {"categories": ["#benchmark", "#plp"], "emoji": "üîç", "ru": {"title": "–ì—Ä–∞—Ñ –ø—Ä–∏—á–∏–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π –¥–ª—è —É–º–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫ –≤ –∫–æ–¥–µ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç GraphLocator ‚Äî –ø–æ–¥—Ö–æ–¥ –¥–ª—è –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –∫–æ–¥–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ. –û—Å–Ω–æ–≤–Ω–æ–π –≤–∫–ª–∞–¥ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –∏—Å–ø–æ–ª—å–∑–æ
[31.12.2025 16:28] Using data from previous issue: {"categories": ["#interpretability", "#security", "#multimodal", "#architecture", "#alignment"], "emoji": "üîì", "ru": {"title": "–ö–æ–º–ø—Ä–æ–º–µ—Ç–∞—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ MoE –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Ü–µ–ª–µ–≤–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –∑–∞—â–∏—Ç—ã", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω GateBreaker ‚Äî –ø–µ—Ä–≤—ã–π –º–µ—Ç–æ–¥ –∞—Ç–∞–∫–∏ –Ω–∞ –º–µ—Ö–∞–Ω–∏–∑–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
[31.12.2025 16:28] Renaming data file.
[31.12.2025 16:28] Renaming previous data. hf_papers.json to ./d/2025-12-31.json
[31.12.2025 16:28] Saving new data file.
[31.12.2025 16:28] Generating page.
[31.12.2025 16:28] Renaming previous page.
[31.12.2025 16:28] Renaming previous data. index.html to ./d/2025-12-31.html
[31.12.2025 16:28] Writing result.
[31.12.2025 16:28] Renaming log file.
[31.12.2025 16:28] Renaming previous data. log.txt to ./logs/2025-12-31_last_log.txt
