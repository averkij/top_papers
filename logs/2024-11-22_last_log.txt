[22.11.2024 14:10] Read previous papers.
[22.11.2024 14:10] Generating top page (month).
[22.11.2024 14:10] Writing top page (month).
[22.11.2024 15:11] Read previous papers.
[22.11.2024 15:11] Get feed.
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.10442
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14402
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14405
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14199
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14251
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.12364
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13676
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14432
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14430
[22.11.2024 15:11] Extract page data from URL. URL: https://huggingface.co/papers/2411.14257
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14343
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13807
[22.11.2024 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13082
[22.11.2024 15:11] Downloading and parsing papers (pdf, html). Total: 13.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.10442.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.10442.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.10442.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14402.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14402.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14402.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14405.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14405.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14405.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14199.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14199.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14199.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14251.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14251.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14251.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.12364.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.12364.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.12364.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.13676.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.13676.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.13676.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14432.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14432.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14432.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14430.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14430.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14430.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14257.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14257.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14257.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.14343.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.14343.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.14343.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.13807.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.13807.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.13807.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Downloading and parsing paper https://huggingface.co/papers/2411.13082.
[22.11.2024 15:11] Extra JSON file exists (./assets/json/2411.13082.json), skip PDF parsing.
[22.11.2024 15:11] Paper image links file exists (./assets/img_data/2411.13082.json), skip HTML parsing.
[22.11.2024 15:11] Success.
[22.11.2024 15:11] Enriching papers with extra data.
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 0. Existing open-source multimodal large language models (MLLMs) generally follow a training process involving pre-training and supervised fine-tuning. However, these models suffer from distribution shifts, which limit their multimodal reasoning, particularly in the Chain-of-Thought (CoT) performance. ...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 1. We introduce a novel method for pre-training of large-scale vision encoders. Building on recent advancements in autoregressive pre-training of vision models, we extend this framework to a multimodal setting, i.e., images and text. In this paper, we present AIMV2, a family of generalist vision encode...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 2. Currently OpenAI o1 has sparked a surge of interest in the study of large reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on disciplines with standard answers, such as mathematics, physics, and coding -- which are well-suited for reinforcement learning (RL) -- but also p...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 3. Scientific progress depends on researchers' ability to synthesize the growing body of literature. Can large language models (LMs) assist scientists in this task? We introduce OpenScholar, a specialized retrieval-augmented LM that answers scientific queries by identifying relevant passages from 45 mi...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 4. Reinforcement Learning (RL) mathematically formulates decision-making with Markov Decision Process (MDP). With MDPs, researchers have achieved remarkable breakthroughs across various domains, including games, robotics, and language models. This paper seeks a new possibility, Natural Language Reinfor...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 5. It is widely acknowledged that the performance of Transformer models is exponentially related to their number of parameters and computational complexity. While approaches like Mixture of Experts (MoE) decouple parameter count from computational complexity, they still face challenges in inference due...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 6. We propose Hymba, a family of small language models featuring a hybrid-head parallel architecture that integrates transformer attention mechanisms with state space models (SSMs) for enhanced efficiency. Attention heads provide high-resolution recall, while SSM heads enable efficient context summariz...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 7. Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1. Despite various efforts to improve LLM reasoning, high-quality long-chain reasoning data and optimized training pipeli...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 8. Diffusion models have revolutionized the field of content synthesis and editing. Recent models have replaced the traditional UNet architecture with the Diffusion Transformer (DiT), and employed flow-matching for improved training and sampling. However, they exhibit limited generation diversity. In t...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 9. Hallucinations in large language models are a widespread problem, yet the mechanisms behind whether models will hallucinate are poorly understood, limiting our ability to solve this problem. Using sparse autoencoders as an interpretability tool, we discover that a key part of these mechanisms is ent...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 10. Large language models (LLMs) under-perform on low-resource languages due to limited training data. We present a method to efficiently collect text data for low-resource languages from the entire Common Crawl corpus. Our approach, UnifiedCrawl, filters and extracts common crawl using minimal compute ...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 11. The rapid advancement of diffusion models has greatly improved video synthesis, especially in controllable video generation, which is essential for applications like autonomous driving. However, existing methods are limited by scalability and how control conditions are integrated, failing to meet th...
[22.11.2024 15:11] ********************************************************************************
[22.11.2024 15:11] Abstract 12. Recent advancements in the field of large language models, particularly through the Chain of Thought (CoT) approach, have demonstrated significant improvements in solving complex problems. However, existing models either tend to sacrifice detailed reasoning for brevity due to user preferences, or re...
[22.11.2024 15:11] Read previous papers.
[22.11.2024 15:11] Generating reviews via LLM API.
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#training", "#benchmark", "#reasoning", "#open_source", "#dataset", "#multimodal", "#optimization"], "emoji": "🧠", "ru": {"title": "Усиление мультимодальных рассуждений ИИ через оптимизацию предпочтений", "desc": "Исследователи представили новый метод улучшения мультимодальных языко
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#benchmark", "#architecture"], "emoji": "🧠", "ru": {"title": "AIMV2: универсальный энкодер изображений с мультимодальным предобучением", "desc": "Представлен новый метод предобучения крупномасштабных энкодеров изображений под названием AIMV2. Он расширяет автор
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#rl", "#training"], "emoji": "🧠", "ru": {"title": "Расширение границ искусственного интеллекта: от стандартных задач к открытым проблемам", "desc": "Статья описывает разработку модели Marco-o1, которая расширяет возможности OpenAI o1 в области рассужде
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#science", "#rag", "#open_source", "#multimodal", "#benchmark", "#hallucinations"], "emoji": "🔬", "ru": {"title": "OpenScholar: ИИ-помощник для синтеза научной литературы", "desc": "Статья представляет OpenScholar - специализированную языковую модель с расширенным поиском, которая о
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#interpretability", "#rl", "#rlhf", "#open_source", "#games"], "emoji": "🗣️", "ru": {"title": "Обучение с подкреплением заговорило на естественном языке", "desc": "Эта статья представляет новую концепцию - обучение с подкреплением на естественном языке (NLRL). NLRL расширяет традици
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#training", "#inference", "#architecture", "#optimization"], "emoji": "🚀", "ru": {"title": "UltraMem: сверхбыстрые трансформеры с разреженной памятью", "desc": "В этой статье представлен новый подход UltraMem, который использует сверхразреженные слои памяти для улучшения производите
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#small_models", "#training", "#architecture", "#optimization"], "emoji": "🧠", "ru": {"title": "Гибридная архитектура Hymba: эффективность малых языковых моделей на новом уровне", "desc": "Авторы представляют Hymba - семейство малых языковых моделей с гибридной параллельной архитекту
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#reasoning", "#long_context", "#multimodal", "#data", "#dataset", "#benchmark", "#agents", "#training"], "emoji": "🧠", "ru": {"title": "Улучшение визуальных рассуждений ИИ через длинные цепочки и мультиагентное обучение", "desc": "Статья представляет Insight-V - подход к улучшению с
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#cv", "#training", "#diffusion", "#optimization"], "emoji": "🖼️", "ru": {"title": "Стабильное редактирование изображений через выборочное внедрение признаков в DiT", "desc": "Эта статья представляет новый подход к редактированию изображений с использованием диффузионных моделей. Авт
[22.11.2024 15:11] Querying the API.
[22.11.2024 15:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Hallucinations in large language models are a widespread problem, yet the mechanisms behind whether models will hallucinate are poorly understood, limiting our ability to solve this problem. Using sparse autoencoders as an interpretability tool, we discover that a key part of these mechanisms is entity recognition, where the model detects if an entity is one it can recall facts about. Sparse autoencoders uncover meaningful directions in the representation space, these detect whether the model recognizes an entity, e.g. detecting it doesn't know about an athlete or a movie. This suggests that models can have self-knowledge: internal representations about their own capabilities. These directions are causally relevant: capable of steering the model to refuse to answer questions about known entities, or to hallucinate attributes of unknown entities when it would otherwise refuse. We demonstrate that despite the sparse autoencoders being trained on the base model, these directions have a causal effect on the chat model's refusal behavior, suggesting that chat finetuning has repurposed this existing mechanism. Furthermore, we provide an initial exploration into the mechanistic role of these directions in the model, finding that they disrupt the attention of downstream heads that typically move entity attributes to the final token.
[22.11.2024 15:11] Response: {
  "desc": "Исследователи обнаружили, что ключевым механизмом галлюцинаций в больших языковых моделях является распознавание сущностей. Используя разреженные автоэнкодеры, они выявили значимые направления в пространстве представлений, которые определяют, распознает ли модель сущность. Эти направления имеют причинно-следственную связь и могут влиять на поведение модели, заставляя ее отказываться отвечать на вопросы о известных сущностях или галлюцинировать атрибуты неизвестных. Исследование также показало, что эти механизмы сохраняются после файнтюнинга чат-моделей.",

  "emoji": "🧠",

  "title": "Самопознание ИИ: ключ к контролю галлюцинаций"
}
[22.11.2024 15:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hallucinations in large language models are a widespread problem, yet the mechanisms behind whether models will hallucinate are poorly understood, limiting our ability to solve this problem. Using sparse autoencoders as an interpretability tool, we discover that a key part of these mechanisms is entity recognition, where the model detects if an entity is one it can recall facts about. Sparse autoencoders uncover meaningful directions in the representation space, these detect whether the model recognizes an entity, e.g. detecting it doesn't know about an athlete or a movie. This suggests that models can have self-knowledge: internal representations about their own capabilities. These directions are causally relevant: capable of steering the model to refuse to answer questions about known entities, or to hallucinate attributes of unknown entities when it would otherwise refuse. We demonstrate that despite the sparse autoencoders being trained on the base model, these directions have a causal effect on the chat model's refusal behavior, suggesting that chat finetuning has repurposed this existing mechanism. Furthermore, we provide an initial exploration into the mechanistic role of these directions in the model, finding that they disrupt the attention of downstream heads that typically move entity attributes to the final token."

[22.11.2024 15:11] Response: ```python
["RLHF", "TRAINING", "ARCHITECTURE"]
```
[22.11.2024 15:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hallucinations in large language models are a widespread problem, yet the mechanisms behind whether models will hallucinate are poorly understood, limiting our ability to solve this problem. Using sparse autoencoders as an interpretability tool, we discover that a key part of these mechanisms is entity recognition, where the model detects if an entity is one it can recall facts about. Sparse autoencoders uncover meaningful directions in the representation space, these detect whether the model recognizes an entity, e.g. detecting it doesn't know about an athlete or a movie. This suggests that models can have self-knowledge: internal representations about their own capabilities. These directions are causally relevant: capable of steering the model to refuse to answer questions about known entities, or to hallucinate attributes of unknown entities when it would otherwise refuse. We demonstrate that despite the sparse autoencoders being trained on the base model, these directions have a causal effect on the chat model's refusal behavior, suggesting that chat finetuning has repurposed this existing mechanism. Furthermore, we provide an initial exploration into the mechanistic role of these directions in the model, finding that they disrupt the attention of downstream heads that typically move entity attributes to the final token."

[22.11.2024 15:11] Response: ```python
["HALLUCINATIONS", "INTERPRETABILITY"]
```
[22.11.2024 15:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the issue of hallucinations in large language models, which occur when these models generate incorrect or fabricated information. The authors utilize sparse autoencoders to analyze how these models recognize entities and determine their knowledge about them. They find that the model\'s internal representations can indicate whether it knows about an entity, influencing its responses to questions. The study reveals that these representations can affect the model\'s behavior, such as leading it to refuse to answer questions about known entities or to invent details about unknown ones.","title":"Understanding Hallucinations: Entity Recognition in Language Models"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc="This paper investigates the issue of hallucinations in large language models, which occur when these models generate incorrect or fabricated information. The authors utilize sparse autoencoders to analyze how these models recognize entities and determine their knowledge about them. They find that the model's internal representations can indicate whether it knows about an entity, influencing its responses to questions. The study reveals that these representations can affect the model's behavior, such as leading it to refuse to answer questions about known entities or to invent details about unknown ones.", title='Understanding Hallucinations: Entity Recognition in Language Models'))
[22.11.2024 15:11] Response: ParsedChatCompletionMessage[Article](content='{"desc":"在大型语言模型中，幻觉现象普遍存在，但其背后的机制尚不清楚，这限制了我们解决这一问题的能力。通过使用稀疏自编码器作为可解释性工具，我们发现实体识别是这些机制的关键部分，模型能够识别出自己能否回忆起某个实体的事实。稀疏自编码器揭示了表示空间中的有意义方向，这些方向可以检测模型是否认识某个实体，例如识别出它对某个运动员或电影并不了解。这表明模型具有自我知识：关于自身能力的内部表示，这些方向在模型的拒绝回答已知实体问题或对未知实体进行幻觉时具有因果相关性。","title":"揭示大型语言模型的自我知识与幻觉机制"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='在大型语言模型中，幻觉现象普遍存在，但其背后的机制尚不清楚，这限制了我们解决这一问题的能力。通过使用稀疏自编码器作为可解释性工具，我们发现实体识别是这些机制的关键部分，模型能够识别出自己能否回忆起某个实体的事实。稀疏自编码器揭示了表示空间中的有意义方向，这些方向可以检测模型是否认识某个实体，例如识别出它对某个运动员或电影并不了解。这表明模型具有自我知识：关于自身能力的内部表示，这些方向在模型的拒绝回答已知实体问题或对未知实体进行幻觉时具有因果相关性。', title='揭示大型语言模型的自我知识与幻觉机制'))
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#dataset", "#low_resource", "#open_source", "#training", "#multilingual", "#data"], "emoji": "🌍", "ru": {"title": "Улучшение языковых моделей для малоресурсных языков с помощью UnifiedCrawl", "desc": "Статья представляет метод UnifiedCrawl для эффективного сбора текстовых данных для
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#architecture", "#diffusion", "#training", "#video"], "emoji": "🚗", "ru": {"title": "Революция в синтезе видео для беспилотных автомобилей", "desc": "Статья представляет MagicDriveDiT - новый подход к генерации видео для автономного вождения, основанный на архитектуре DiT. Метод улу
[22.11.2024 15:11] Using data from previous issue: {"categories": ["#reasoning", "#training", "#dataset", "#optimization"], "emoji": "🧠", "ru": {"title": "Терпеливые рассуждения: новый путь к улучшению ИИ", "desc": "Статья описывает новый метод улучшения рассуждений больших языковых моделей без необходимости обширного обучения. Авторы предлагают под
[22.11.2024 15:11] Loading Chinese text from previous data.
[22.11.2024 15:11] Renaming data file.
[22.11.2024 15:11] Renaming previous data. hf_papers.json to ./d/2024-11-22.json
[22.11.2024 15:11] Saving new data file.
[22.11.2024 15:11] Generating page.
[22.11.2024 15:11] Renaming previous page.
[22.11.2024 15:11] Renaming previous data. index.html to ./d/2024-11-22.html
[22.11.2024 15:11] [Experimental] Generating Chinese page for reading.
[22.11.2024 15:11] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '现有', 'pinyin': 'xiàn yǒu', 'trans': 'existing'}, {'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open-source'}, {'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'train'}, {'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'}, {'word': '存在', 'pinyin': 'cún zài', 'trans': 'exist'}, {'word': '问题', 'pinyin': 'wèn tí', 'trans': 'problem'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-train'}, {'word': '监督', 'pinyin': 'jiàn dū', 'trans': 'supervise'}, {'word': '微调', 'pinyin': 'wēi tiáo', 'trans': 'fine-tune'}, {'word': '分布', 'pinyin': 'fēn bù', 'trans': 'distribution'}, {'word': '偏移', 'pinyin': 'piān yí', 'trans': 'shift'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '影响', 'pinyin': 'yǐng xiǎng', 'trans': 'affect'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'}, {'word': '特别', 'pinyin': 'tè bié', 'trans': 'especially'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chéng fǎn de Sī xiǎng', 'trans': 'Chain-of-Thought'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '偏好', 'pinyin': 'piān hào', 'trans': 'preference'}, {'word': '优化', 'pinyin': 'yōu huà', 'trans': 'optimize'}, {'word': '创建', 'pinyin': 'chuàng jiàn', 'trans': 'create'}, {'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high-quality'}, {'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'}, {'word': '混合', 'pinyin': 'hùn hé', 'trans': 'hybrid'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '提升', 'pinyin': 'tí shēng', 'trans': 'improve'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '显示', 'pinyin': 'xiǎn shì', 'trans': 'show'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'}, {'word': '任务', 'pinyin': 'rèn wù', 'trans': 'task'}]
[22.11.2024 15:11] Renaming previous Chinese page.
[22.11.2024 15:11] Renaming previous data. zh.html to ./d/2024-11-21_zh_reading_task.html
[22.11.2024 15:11] Writing Chinese reading task.
[22.11.2024 15:11] Writing result.
[22.11.2024 15:11] Renaming log file.
[22.11.2024 15:11] Renaming previous data. log.txt to ./logs/2024-11-22_last_log.txt
