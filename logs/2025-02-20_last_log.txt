[20.02.2025 09:11] Read previous papers.
[20.02.2025 09:11] Generating top page (month).
[20.02.2025 09:11] Writing top page (month).
[20.02.2025 10:11] Read previous papers.
[20.02.2025 10:11] Get feed.
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13923
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13144
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13128
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13685
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13347
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13922
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.12143
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13965
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13946
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13173
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13962
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13233
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13943
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.12638
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13581
[20.02.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.11995
[20.02.2025 10:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.11573
[20.02.2025 10:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.02.2025 10:11] No deleted papers detected.
[20.02.2025 10:11] Downloading and parsing papers (pdf, html). Total: 17.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13923.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13923.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13923.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13144.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13144.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13144.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13128.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13128.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13128.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13685.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13685.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13685.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13347.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13347.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13347.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13922.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13922.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13922.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.12143.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.12143.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.12143.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13965.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13965.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13965.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13946.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13946.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13946.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13173.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13173.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13173.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13962.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13962.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13962.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13233.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13233.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13233.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13943.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13943.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13943.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.12638.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.12638.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.12638.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.13581.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.13581.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.13581.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.11995.
[20.02.2025 10:11] Extra JSON file exists (./assets/json/2502.11995.json), skip PDF parsing.
[20.02.2025 10:11] Paper image links file exists (./assets/img_data/2502.11995.json), skip HTML parsing.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.11573.
[20.02.2025 10:11] Downloading paper 2502.11573 from http://arxiv.org/pdf/2502.11573v1...
[20.02.2025 10:11] Extracting affiliations from text.
[20.02.2025 10:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning Congkai Xie1, Shuo Cai4, Wenjun Wang4, Pengxiang Li6, Zhijie Sang1, Kejing Yang1, Yiming Zhang2, Zhen Li1,2, Guanghao Zhu7, Zeyu Liu5, Yang Yu8, Yuhang Liu3, Su Lu2, Baoyi He3, Qi Zhou5, Xiaotian Han9, Jianbo Yuan10, Shengyu Zhang3, Fei Wu3, Hongxia Yang1,2 1 Reallm Labs, 2 The Hong Kong Polytechnic University, 3 Zhejiang University, 4 South China University of Technology, 5 Harbin Institute of Technology, 6 Dalian University of Technology, 7 University of Electronic Science and Technology of China, 8 Beijing University of Posts and Telecommunications, 9 TikTok, 10 Amazon hongxia.yang@polyu.edu.hk * Corresponding authors. Abstract Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have made significant advancements in reasoning capabilities. However, they still face challenges such as high computational demands and privacy concerns. This paper focuses on developing efficient Small Language Models (SLMs) and Multimodal Small Language Models (MSLMs) that retain competitive reasoning abilities. We introduce novel training pipeline that enhances reasoning capabilities and facilitates deployment on edge devices, achieving state-of-the-art performance while minimizing development costs. InfiR aims to advance AI systems by improving reasoning, reducing adoption barriers, and addressing privacy concerns through smaller model sizes. Resources are available at https://github. com/Reallm-Labs/InfiR. Small models, typically comprising fewer than 2 billion parameters, have emerged as promising solution to these challenges. These models strive to achieve an optimal balance between performance and efficiency. Their considerably lower training and development costs increase accessibility for researchers and organizations. There is key challenge for SLMs and MSLMs in enhancing reasoning capabilities while reducing the size of the model. This paper focuses on: (1)"
[20.02.2025 10:11] Response: ```python
[
    "Reallm Labs",
    "The Hong Kong Polytechnic University",
    "Zhejiang University",
    "South China University of Technology",
    "Harbin Institute of Technology",
    "Dalian University of Technology",
    "University of Electronic Science and Technology of China",
    "Beijing University of Posts and Telecommunications",
    "TikTok",
    "Amazon"
]
```
[20.02.2025 10:11] Deleting PDF ./assets/pdf/2502.11573.pdf.
[20.02.2025 10:11] Success.
[20.02.2025 10:11] Enriching papers with extra data.
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 0. We introduce Qwen2.5-VL, the latest flagship model of Qwen vision-language series, which demonstrates significant advancements in both foundational capabilities and innovative functionalities. Qwen2.5-VL achieves a major leap forward in understanding and interacting with the world through enhanced v...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 1. Existing end-to-end autonomous driving (AD) algorithms typically follow the Imitation Learning (IL) paradigm, which faces challenges such as causal confusion and the open-loop gap. In this work, we establish a 3DGS-based closed-loop Reinforcement Learning (RL) training paradigm. By leveraging 3DGS t...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 2. Text-to-song generation, the task of creating vocals and accompaniment from textual inputs, poses significant challenges due to domain complexity and data scarcity. Existing approaches often employ multi-stage generation procedures, resulting in cumbersome training and inference pipelines. In this p...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 3. Linear sequence modeling methods, such as linear attention, state space modeling, and linear RNNs, offer significant efficiency improvements by reducing the complexity of training and inference. However, these methods typically compress the entire input sequence into a single fixed-size memory state...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 4. Web crawl is a main source of large language models' (LLMs) pretraining data, but the majority of crawled web pages are discarded in pretraining due to low data quality. This paper presents Crawl4LLM, an efficient web crawling method that explores the web graph based on the preference of LLM pretrai...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 5. Large Language Models (LLMs) have demonstrated remarkable capabilities through pretraining and alignment. However, superior short-context LLMs may underperform in long-context scenarios due to insufficient long-context alignment. This alignment process remains challenging due to the impracticality o...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 6. Large language models (LLMs) excel in complex reasoning tasks, and distilling their reasoning capabilities into smaller models has shown promise. However, we uncover an interesting phenomenon, which we term the Small Model Learnability Gap: small models (leq3B parameters) do not consistently benefit...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 7. Large language model (LLM) applications are evolving beyond simple chatbots into dynamic, general-purpose agentic programs, which scale LLM calls and output tokens to help AI agents reason, explore, and solve complex tasks. However, existing LLM serving systems ignore dependencies between programs a...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 8. The safety alignment of large language models (LLMs) remains vulnerable, as their initial behavior can be easily jailbroken by even relatively simple attacks. Since infilling a fixed template between the input instruction and initial model output is a common practice for existing LLMs, we hypothesiz...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 9. Supervised Fine-Tuning (SFT) has been a go-to and effective method for enhancing long chain-of-thought (CoT) reasoning in relatively small LLMs by fine-tuning them with long CoT responses from larger LLMs. To continually improve reasoning abilities, we can either collect new high-quality long CoT re...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 10. Scaling the test-time compute of large language models has demonstrated impressive performance on reasoning benchmarks. However, existing evaluations of test-time scaling make the strong assumption that a reasoning system should always give an answer to any question provided. This overlooks concerns...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 11. Large Language Models (LLMs) have shown remarkable capabilities in general domains but often struggle with tasks requiring specialized knowledge. Conventional Retrieval-Augmented Generation (RAG) techniques typically retrieve external information from static knowledge bases, which can be outdated or...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 12. Current approaches for training Process Reward Models (PRMs) often involve breaking down responses into multiple reasoning steps using rule-based techniques, such as using predefined placeholder tokens or setting the reasoning step's length into a fixed size. These approaches overlook the fact that ...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 13. 3D molecule generation is crucial for drug discovery and material design. While prior efforts focus on 3D diffusion models for their benefits in modeling continuous 3D conformers, they overlook the advantages of 1D SELFIES-based Language Models (LMs), which can generate 100% valid molecules and leve...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 14. Generative recommendation (GR) is an emerging paradigm where user actions are tokenized into discrete token patterns and autoregressively generated as predictions. However, existing GR models tokenize each action independently, assigning the same fixed tokens to identical actions across all sequence...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 15. Names are deeply tied to human identity. They can serve as markers of individuality, cultural heritage, and personal history. However, using names as a core indicator of identity can lead to over-simplification of complex identities. When interacting with LLMs, user names are an important point of i...
[20.02.2025 10:11] ********************************************************************************
[20.02.2025 10:11] Abstract 16. Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have made significant advancements in reasoning capabilities. However, they still face challenges such as high computational demands and privacy concerns. This paper focuses on developing efficient Small Language Models (SLMs)...
[20.02.2025 10:11] Read previous papers.
[20.02.2025 10:11] Generating reviews via LLM API.
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#agi", "#architecture", "#cv", "#multimodal", "#long_context", "#agents", "#reasoning"], "emoji": "🔍", "ru": {"title": "Новый уровень понимания визуальной информации с Qwen2.5-VL", "desc": "Qwen2.5-VL - это новая модель машинного обучения для обработки визуальной и текстовой информа
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#alignment", "#3d", "#games", "#reasoning", "#agents"], "emoji": "🚗", "ru": {"title": "Революция в автономном вождении: обучение с подкреплением в фотореалистичных 3D-мирах", "desc": "Статья представляет новый подход к автономному вождению, основанный на обучени
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#story_generation", "#data", "#audio", "#training", "#open_source", "#dataset"], "emoji": "🎵", "ru": {"title": "SongGen: Революция в генерации песен с помощью ИИ", "desc": "SongGen - это новая модель машинного обучения для генерации песен на основе текстового ввода. Она использует а
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#long_context", "#architecture", "#training", "#open_source"], "emoji": "🧠", "ru": {"title": "Множественная память для эффективного линейного моделирования последовательностей", "desc": "Статья представляет новую архитектуру под названием Mixture-of-Memories (MoM) для линейного моде
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#dataset", "#graphs", "#open_source", "#data"], "emoji": "🕷️", "ru": {"title": "Умный веб-краулинг для эффективного обучения языковых моделей", "desc": "Статья представляет Crawl4LLM - эффективный метод веб-краулинга для предобучения больших языковых моделей (LLM). Метод использует 
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#training", "#transfer_learning", "#benchmark", "#long_context", "#architecture", "#rlhf"], "emoji": "📏", "ru": {"title": "LongPO: Самоэволюция языковых моделей для работы с длинным контекстом", "desc": "Статья представляет новый метод LongPO для улучшения работы языковых моделей с 
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#training", "#transfer_learning", "#optimization", "#reasoning", "#small_models"], "emoji": "🧠", "ru": {"title": "Адаптация сложности рассуждений для эффективного обучения малых языковых моделей", "desc": "Исследование показывает, что маленькие языковые модели (до 3 млрд параметров)
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#optimization", "#inference", "#agents", "#architecture"], "emoji": "🚀", "ru": {"title": "Autellix: Революция в обслуживании LLM для агентных программ", "desc": "Статья представляет Autellix - систему обслуживания больших языковых моделей (LLM), оптимизирующую выполнение агентных пр
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#alignment", "#security", "#training", "#inference", "#rlhf"], "emoji": "🛡️", "ru": {"title": "Преодоление уязвимостей в безопасности языковых моделей", "desc": "Это исследование посвящено проблеме безопасности больших языковых моделей (LLM) и их уязвимости к атакам типа 'jailbreak'
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#math", "#training", "#reasoning", "#long_context", "#optimization"], "emoji": "🧠", "ru": {"title": "Оптимизация предпочтений мышления: новый шаг в улучшении рассуждений ИИ", "desc": "Этот научный труд представляет новый метод под названием Thinking Preference Optimization (ThinkPO)
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#reasoning", "#inference"], "emoji": "🧠", "ru": {"title": "Уверенность языковых моделей: больше вычислений - меньше рисков", "desc": "Статья исследует влияние увеличения вычислительных ресурсов на работу больших языковых моделей при тестировании. А
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#rag", "#synthetic", "#healthcare", "#science"], "emoji": "🩺", "ru": {"title": "SearchRAG: Точные медицинские ответы с помощью актуального поиска", "desc": "Эта статья представляет SearchRAG - новый метод для улучшения ответов больших языковых моделей на медицинские вопросы. В отлич
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#reasoning", "#plp", "#training", "#open_source", "#math", "#transfer_learning"], "emoji": "🧠", "ru": {"title": "AdaptiveStep: умное разбиение на шаги для эффективного обучения PRM", "desc": "Статья представляет новый метод AdaptiveStep для обучения моделей вознаграждения процессов 
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#open_source", "#transfer_learning", "#architecture", "#diffusion", "#dataset", "#3d"], "emoji": "🧪", "ru": {"title": "NExT-Mol: объединение языкового и диффузионного моделирования для генерации 3D-молекул", "desc": "NExT-Mol - это модель для генерации трехмерных молекул, сочетающая
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#optimization", "#data"], "emoji": "🧩", "ru": {"title": "Контекстно-зависимая токенизация действий для улучшения генеративных рекомендаций", "desc": "Статья представляет новый подход к токенизации действий пользователей в генеративных рекомендательных систе
[20.02.2025 10:11] Using data from previous issue: {"categories": ["#multimodal", "#ethics", "#alignment", "#healthcare"], "emoji": "👤", "ru": {"title": "Имена в ИИ: преодоление культурных стереотипов", "desc": "Статья исследует влияние имен на взаимодействие с языковыми моделями (LLM). Авторы изучают, как LLM делают предположения о культурной идент
[20.02.2025 10:11] Querying the API.
[20.02.2025 10:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have made significant advancements in reasoning capabilities. However, they still face challenges such as high computational demands and privacy concerns. This paper focuses on developing efficient Small Language Models (SLMs) and Multimodal Small Language Models (MSLMs) that retain competitive reasoning abilities. We introduce a novel training pipeline that enhances reasoning capabilities and facilitates deployment on edge devices, achieving state-of-the-art performance while minimizing development costs. \InfR~ aims to advance AI systems by improving reasoning, reducing adoption barriers, and addressing privacy concerns through smaller model sizes. Resources are available at https://github. com/Reallm-Labs/InfiR.
[20.02.2025 10:11] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[20.02.2025 10:11] Loading Chinese text from previous data.
[20.02.2025 10:11] Renaming data file.
[20.02.2025 10:11] Renaming previous data. hf_papers.json to ./d/2025-02-20.json
[20.02.2025 10:11] Saving new data file.
[20.02.2025 10:11] Generating page.
[20.02.2025 10:11] Renaming previous page.
[20.02.2025 10:11] Renaming previous data. index.html to ./d/2025-02-20.html
[20.02.2025 10:11] [Experimental] Generating Chinese page for reading.
[20.02.2025 10:11] Chinese vocab [{'word': '介绍', 'pinyin': 'jièshào', 'trans': 'introduce'}, {'word': '旗舰', 'pinyin': 'qíjiàn', 'trans': 'flagship'}, {'word': '显著', 'pinyin': 'xiǎnzhù', 'trans': 'significant'}, {'word': '进展', 'pinyin': 'jìnzhǎn', 'trans': 'progress'}, {'word': '视觉', 'pinyin': 'shìjué', 'trans': 'visual'}, {'word': '识别', 'pinyin': 'shíbié', 'trans': 'recognition'}, {'word': '精确', 'pinyin': 'jīngquè', 'trans': 'precise'}, {'word': '定位', 'pinyin': 'dìngwèi', 'trans': 'locate'}, {'word': '解析', 'pinyin': 'jiěxī', 'trans': 'parse'}, {'word': '理解', 'pinyin': 'lǐjiě', 'trans': 'understand'}, {'word': '提升', 'pinyin': 'tíshēng', 'trans': 'improve'}, {'word': '结构化', 'pinyin': 'jiégòuhuà', 'trans': 'structured'}, {'word': '布局', 'pinyin': 'bùjú', 'trans': 'layout'}, {'word': '动态', 'pinyin': 'dòngtài', 'trans': 'dynamic'}, {'word': '分辨率', 'pinyin': 'fēnbiànlǜ', 'trans': 'resolution'}, {'word': '编码', 'pinyin': 'biānmǎ', 'trans': 'encode'}, {'word': '静态', 'pinyin': 'jìngtài', 'trans': 'static'}, {'word': '场景', 'pinyin': 'chǎngjǐng', 'trans': 'scenario'}, {'word': '推理', 'pinyin': 'tuīlǐ', 'trans': 'reasoning'}, {'word': '执行', 'pinyin': 'zhíxíng', 'trans': 'execute'}, {'word': '边缘', 'pinyin': 'biānyuán', 'trans': 'edge'}, {'word': '高性能', 'pinyin': 'gāo xìngnéng', 'trans': 'high-performance'}, {'word': '用例', 'pinyin': 'yònglì', 'trans': 'use case'}]
[20.02.2025 10:11] Renaming previous Chinese page.
[20.02.2025 10:11] Renaming previous data. zh.html to ./d/2025-02-19_zh_reading_task.html
[20.02.2025 10:11] Writing Chinese reading task.
[20.02.2025 10:11] Writing result.
[20.02.2025 10:11] Renaming log file.
[20.02.2025 10:11] Renaming previous data. log.txt to ./logs/2025-02-20_last_log.txt
