[10.02.2025 04:15] Read previous papers.
[10.02.2025 04:15] Generating top page (month).
[10.02.2025 04:15] Writing top page (month).
[10.02.2025 05:11] Read previous papers.
[10.02.2025 05:11] Get feed.
[10.02.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.05173
[10.02.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.05176
[10.02.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.04520
[10.02.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.04403
[10.02.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.04896
[10.02.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.05171
[10.02.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.04363
[10.02.2025 05:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.04728
[10.02.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.04404
[10.02.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.04350
[10.02.2025 05:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[10.02.2025 05:11] No deleted papers detected.
[10.02.2025 05:11] Downloading and parsing papers (pdf, html). Total: 10.
[10.02.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.05173.
[10.02.2025 05:11] Extra JSON file exists (./assets/json/2502.05173.json), skip PDF parsing.
[10.02.2025 05:11] Paper image links file exists (./assets/img_data/2502.05173.json), skip HTML parsing.
[10.02.2025 05:11] Success.
[10.02.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.05176.
[10.02.2025 05:11] Downloading paper 2502.05176 from http://arxiv.org/pdf/2502.05176v1...
[10.02.2025 05:11] Extracting affiliations from text.
[10.02.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 ] . [ 1 6 7 1 5 0 . 2 0 5 2 : r AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360 Unbounded Scene Inpainting Chung-Ho Wu1 Yang-Jung Chen1 Ying-Huan Chen1 Jie-Ying Lee1 Bo-Hsu Ke1 Chun-Wei Tuan Mu1 Yi-Chuan Huang1 Chin-Yang Lin1 Min-Hung Chen2 Yen-Yu Lin1 Yu-Lun Liu1 1National Yang Ming Chiao Tung University 2NVIDIA https://kkennethwu.github.io/aurafusion360/ Figure 1. Overview of our reference-based 360 unbounded scene inpainting method. Given input images with camera parameters, object masks, and reference image, our AuraFusion360 approach generates an object-masked Gaussian Splatting representation. This representation can then render novel views of the inpainted scene, effectively removing the masked objects while maintaining consistency with the reference image. "
[10.02.2025 05:11] Response: ```python
["National Yang Ming Chiao Tung University", "NVIDIA"]
```
[10.02.2025 05:11] Deleting PDF ./assets/pdf/2502.05176.pdf.
[10.02.2025 05:11] Success.
[10.02.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.04520.
[10.02.2025 05:11] Downloading paper 2502.04520 from http://arxiv.org/pdf/2502.04520v1...
[10.02.2025 05:11] Extracting affiliations from text.
[10.02.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 ] . [ 1 0 2 5 4 0 . 2 0 5 2 : r Linear Correlation in LMs Compositional Generalization and Hallucination Letian Peng 1 Chenyang An 1 Shibo Hao 1 Chengyu Dong 1 Jingbo Shang "
[10.02.2025 05:11] Response: []
[10.02.2025 05:11] Extracting affiliations from text.
[10.02.2025 05:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 ] . [ 1 0 2 5 4 0 . 2 0 5 2 : r Linear Correlation in LMs Compositional Generalization and Hallucination Letian Peng 1 Chenyang An 1 Shibo Hao 1 Chengyu Dong 1 Jingbo ShangThe generalization of language models (LMs) is undergoing active debates, contrasting their potential for general intelligence with their struggles with basic knowledge composition (e.g., reverse/transition curse). This paper uncovers the phenomenon of linear correlations in LMs during knowledge composition. For explanation, there exists linear transformation between certain related knowledge that maps the next token prediction logits from one prompt to another, e.g., lives in the city of lives in the country of for every given X. This mirrors the linearity in human knowledge composition, such as Paris France. Our findings indicate that the linear transformation is 1) resilient to large-scale fine-tuning, 2) generalizing updated knowledge when aligned with real-world relationships, 3) but causing hallucinations when it deviates. Empirical results suggest that linear correlation can serve as potential identifier of LMs generalization. Finally, we show such linear correlations can be learned with single feedforward network and pre-trained vocabulary representations, indicating LM generalization heavily relies on the latter. 1 1. Introduction What knowledge do language models (LMs) learn beyond memorizing the training data? The generalization ability of LMs is undergoing an active debate. Optimists claim that LMs might have the capability in entirely novel tasks with their emergent behavior (Wei et al., 2022) by scaling-up parameters, while pessimists argue that LMs struggle with composing simple knowledge (Peng et al., 2024a; Thomm et al., 2024), such as reverse or transition curses claiming that LMs cannot even simply compose knowledge by reversing or transiting (Berglund et al., 2024; Zhu et al., 2024). 1University of California, San Diego. Correspondence to: Jingbo Shang <jshang@ucsd.edu>. 1Code: https://github.com/KomeijiForce/LinCorr 1 While macroscopically investigating how skills emerge in language models remains challenging, we can gain microscopical insight from the generalization behavior on the smallest learning unit, next token prediction (NTP). We unveil an interesting linear correlation between logits of related NTPs, such as CityCountry, from the source knowledge like logits of FCity(X) = NTP(X lives in the city of) to the target knowledge like logits of FCountry(X) = NTP(X lives in the country of). Between logits in knowledge subdomains (e.g., {Paris, Shanghai, } for FCity(X)), we can fit linear transformation (W, b) that well approximates FCountry(X) = FCity(X) + for any as the input. To fit the transformation, we sample numerous output logits from prompts with arbitrary inputs Xs as shown in Figure 1. Then, (W, b) is fitted with partial logit pairs and tested on the rest. The Pearson correlation coefficients for evaluation reflects the inherent relations of knowledge in the real world, with high correlations in cases like CityCountry and low correlations in cases like CityGender. Examining , we find that its weights mirror the linearity in the knowledge composition of humans. In the CityCountry case, the assigns high weights to realworld (City, Country) pairs such as ParisFrance. In other words, probability (FCountry(X) = France) is correlated with (FCity(X) = Paris). However, there also exists counterfactual weights learned in , for instance, the weight fit in for (Indianapolis, India) is much higher than the correct (Indianapolis, USA). We say is precise when assigns high weights for the correct knowledge pairs. precision is generally low for knowledge pairs with low correlations, but high linear correlation also does not guarantee high precision. This motivates us to explore the connection between 1) such linear correlations, 2) precision, and 3) LMs compositional generalization. Importantly, if the same and also fit the parameter updates after gradient propagation, then learning source knowledge will simultaneously update the target knowledge. We begin with one-step parameter updates, fine-tune the LM with piece of source knowledge, and then check the gradients on the source and target knowledge. When the linear correlation between the source and target knowledge is high, we find capable of estimating the gradients on the target knowledge based on the source gradient. We then extend the comparison to LMs before and after large-scale Linear Correlation in LMs Compositional Generalization and Hallucination Figure 1. Demonstration of our main discoveries. 1) We can fit linear transformation between the output of source and target knowledge prompts, which is resilient against fine-tuning. 2) Updating the source knowledge will generalize to the target one via resilient linearity, causing compositional generalization/hallucination. post-training, which shows fitted before post-training to retain the estimation ability for the LM after post-training. Thus, between highly correlated knowledge is found resilient against gradient propagation, which consistently plays an important role in generalization. To validate the important role of linear correlation in LM generalization, we test the generalization effect between source and target knowledge with different levels of correlation intensity and precision. Our study shows that successful generalization for simultaneous knowledge update between source and target requires high correlation intensity and precision. This implies that LMs struggle to generalize their predictions in non-linear manner, explaining why simple fine-tuning cannot efficiently edit LMs (Cohen et al., 2024). When the Pearson coefficient is high and is imprecise, the resilient linear correlation will consequently lead to compositional hallucination. For instance, learning (City(X) = Indianapolis) unfortunately generalizes to (Country(X) = India). Our linear correlation reflects the occurrence of such hallucinations before fine-tuning, demonstrating its utility in diagnosing potential faults in the knowledge composition of LMs. Finally, we explore the linear correlations origin and hypothesize that vocabulary representations are key. Even when we remove the LMs complex internals (position embeddings, self-attention, etc.) and use only mean-pooling layer plus single feedforward network, the model still learns to compose knowledge from few paired texts (e.g., FCity = Paris p"
[10.02.2025 05:11] Mistral response. {"id": "f25f3c0252e6411cbc4496e119236e90", "object": "chat.completion", "created": 1739164306, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\"University of California, San Diego\"]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1546, "total_tokens": 1555, "completion_tokens": 9}}
[10.02.2025 05:11] Response: ["University of California, San Diego"]
[10.02.2025 05:11] Deleting PDF ./assets/pdf/2502.04520.pdf.
[10.02.2025 05:11] Success.
[10.02.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.04403.
[10.02.2025 05:11] Extra JSON file exists (./assets/json/2502.04403.json), skip PDF parsing.
[10.02.2025 05:11] Paper image links file exists (./assets/img_data/2502.04403.json), skip HTML parsing.
[10.02.2025 05:11] Success.
[10.02.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.04896.
[10.02.2025 05:11] Downloading paper 2502.04896 from http://arxiv.org/pdf/2502.04896v1...
[10.02.2025 05:11] Extracting affiliations from text.
[10.02.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Goku: Flow Based Video Generative Foundation Models Shoufa Chen1 Chongjian Ge1 Yuqi Zhang2 Yida Zhang2 Hongxiang Hao2 Hui Wu2 Zhichao Lai2 Yifei Hu2 Chuan Li2 Xing Wang2 Yanghua Peng2 Peize Sun1 Ting-Che Lin2 Fengda Zhu2 Hao Yang2 Shilong Zhang Fu Li2 Ping Luo1 Yi Jiang2 Zehuan Yuan2 Bingyue Peng2 Xiaobing Liu2 1The University of Hong Kong 2Bytedance Inc Equal Contribution 5 2 0 F 7 ] . [ 1 6 9 8 4 0 . 2 0 5 2 : r https://saiyan-world.github.io/goku/ "
[10.02.2025 05:11] Response: ```python
["The University of Hong Kong", "Bytedance Inc"]
```
[10.02.2025 05:11] Deleting PDF ./assets/pdf/2502.04896.pdf.
[10.02.2025 05:11] Success.
[10.02.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.05171.
[10.02.2025 05:11] Downloading paper 2502.05171 from http://arxiv.org/pdf/2502.05171v1...
[10.02.2025 05:12] Extracting affiliations from text.
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Scaling up Test-Time Compute with Latent Reasoning: Recurrent Depth Approach Jonas Geiping 1 Sean McLeish 2 Neel Jain 2 John Kirchenbauer 2 Siddharth Singh 2 Brian R. Bartoldson 3 Bhavya Kailkhura 3 Abhinav Bhatele 2 Tom Goldstein 2 5 2 0 2 7 ] . [ 1 1 7 1 5 0 . 2 0 5 2 : r a "
[10.02.2025 05:12] Response: ```python
[]
```
[10.02.2025 05:12] Extracting affiliations from text.
[10.02.2025 05:12] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Scaling up Test-Time Compute with Latent Reasoning: Recurrent Depth Approach Jonas Geiping 1 Sean McLeish 2 Neel Jain 2 John Kirchenbauer 2 Siddharth Singh 2 Brian R. Bartoldson 3 Bhavya Kailkhura 3 Abhinav Bhatele 2 Tom Goldstein 2 5 2 0 2 7 ] . [ 1 1 7 1 5 0 . 2 0 5 2 : r aWe study novel language model architecture that is capable of scaling test-time computation by implicitly reasoning in latent space. Our model works by iterating recurrent block, thereby unrolling to arbitrary depth at test-time. This stands in contrast to mainstream reasoning models that scale up compute by producing more tokens. Unlike approaches based on chain-of-thought, our approach does not require any specialized training data, can work with small context windows, and can capture types of reasoning that are not easily represented in words. We scale proof-ofconcept model to 3.5 billion parameters and 800 billion tokens. We show that the resulting model can improve its performance on reasoning benchmarks, sometimes dramatically, up to computation load equivalent to 50 billion parameters. Model: huggingface.co/tomg-group-umd/huginn0125 Code and Data: github.com/seal-rg/recurrentpretraining 1. Scaling by Thinking in Continuous Space Humans naturally expend more mental effort solving some problems than others. While humans are capable of thinking over long time spans by verbalizing intermediate results and writing them down, substantial amount of thought happens through complex, recurrent firing patterns in the brain, before the first word of an answer is uttered. Early attempts at increasing the power of language models focused on scaling model size, practice that requires extreme amounts of data and computation. More recently, researchers have explored ways to enhance the reasoning 1ELLIS Institute Tübingen, Max-Planck Institute for Intelligent Systems, Tübingen AI Center 2University of Maryland, College Park 3Lawrence Livermore National Laboratory. Correspondence to: Jonas Geiping, Tom Goldstein <jonas@tue.ellis.eu, tomg@umd.edu>. Figure 1: We train 3.5B parameter language model with depth recurrence. At test time, the model can iterate longer to use more compute and improve its performance. Instead of scaling test-time reasoning by verbalizing in long Chains-of-Thought, the model improves entirely by reasoning in latent space. Tasks that require less reasoning like OpenBookQA converge quicker than tasks like GSM8k, which effectively make use of more compute. capability of models by scaling test time computation. The mainstream approach involves post-training on long chainof-thought examples to develop the models ability to verbalize intermediate calculations in its context window and thereby externalize thoughts. However, the constraint that expensive internal reasoning must always be projected down to single verbalized next token appears wasteful; it is plausible that models could be more competent if they were able to natively think in their continuous latent space. One way to unlock this untapped dimension of additional compute involves adding recurrent unit to model. This unit runs in loop, iteratively processing and updating its hidden state and enabling computations to be carried on indefinitely. While this is not currently the dominant paradigm, this idea is foundational to machine learning and has been (re-)discovered in every decade, for example as recurrent neural networks, diffusion models, and as universal or looped transformers. In this work, we show that depth-recurrent language models can learn effectively, be trained in an efficient manner, and demonstrate significant performance improvements under the scaling of test-time compute. Our proposed trans1 Scaling up Test-Time Compute with Latent Reasoning: Recurrent Depth Approach former architecture is built upon latent depth-recurrent block that is run for randomly sampled number of iterations during training. We show that this paradigm can scale to several billion parameters and over half trillion tokens of pretraining data. At test-time, the model can improve its performance through recurrent reasoning in latent space, enabling it to compete with other open-source models that benefit from more parameters and training data. Additionally, we show that recurrent depth models naturally support number of features at inference time that require substantial tuning and research effort in non-recurrent models, such as per-token adaptive compute, (self)-speculative decoding, and KV-cache sharing. We finish out our study by tracking token trajectories in latent space, showing that number of interesting computation behaviors simply emerge with scale, such as the model rotating shapes in latent space for numerical computations. 2. Why Train Models with Recurrent Depth? Recurrent layers enable transformer model to perform arbitrarily many computations before emitting token. In principle, recurrent mechanisms provide simple solution for test-time compute scaling. Compared to more standard approach of long context reasoning (OpenAI, 2024; DeepSeek-AI et al., 2025), latent recurrent thinking has several advantages. Latent reasoning does not require construction of bespoke training data. Chain-of-thought reasoning requires the model to be trained on long demonstrations that are constructed in the domain of interest. In contrast, our proposed latent reasoning models can train with variable compute budget, using standard training data with no specialized demonstrations, and enhance their abilities at testtime if given additional compute. Latent reasoning models require less memory for training and inference than chain-of-thought reasoning models. Because the latter require extremely long context windows, specialized training methods such as tokenparallelization (Liu et al., 2023a) may be needed. Recurrent-depth networks perform more FLOPs per parameter than standard transformers, significantly reducing communication costs between accelerators at scale. This especially enables higher device utilization when training with slower interconnects. By constructing an architecture that is compute-heavy and small in parameter count, we hope to set strong prior towards models that solve problems by thinking, i.e. by learning meta-strategies, logic and abstraction, instead of memorizing. The strength of recurrent priors for learning complex algorithms has already been demonstrated in the deep thinking literature (Schwarzschild et al., 2021b; Bansal et al., 2022; Sch"
[10.02.2025 05:12] Mistral response. {"id": "53db042b0bf14c45be3510debd8919c0", "object": "chat.completion", "created": 1739164330, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n['ELLIS Institute T\u00fcbingen, Max-Planck Institute for Intelligent Systems, T\u00fcbingen AI Center', 'University of Maryland, College Park', 'Lawrence Livermore National Laboratory']\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1498, "total_tokens": 1550, "completion_tokens": 52}}
[10.02.2025 05:12] Response: ```python
['ELLIS Institute Tübingen, Max-Planck Institute for Intelligent Systems, Tübingen AI Center', 'University of Maryland, College Park', 'Lawrence Livermore National Laboratory']
```
[10.02.2025 05:12] Deleting PDF ./assets/pdf/2502.05171.pdf.
[10.02.2025 05:12] Success.
[10.02.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2502.04363.
[10.02.2025 05:12] Downloading paper 2502.04363 from http://arxiv.org/pdf/2502.04363v1...
[10.02.2025 05:12] Extracting affiliations from text.
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"On-device Sora: Enabling Diffusion-Based Text-to-Video Generation for Mobile Devices Kyuhwan Lee Ulsan National Institute of Science and Technology South Korea hanbitchan@unist.ac.kr Bosung Kim Ulsan National Institute of Science and Technology South Korea bosung.k@unist.ac.kr Isu Jeong Ulsan National Institute of Science and Technology South Korea ijeong@unist.ac.kr 5 2 0 2 5 ] . [ 1 3 6 3 4 0 . 2 0 5 2 : r Jungmin Cheon Ulsan National Institute of Science and Technology South Korea jungmin0210@unist.ac.kr Yeojin Lee Ulsan National Institute of Science and Technology South Korea yeojin@unist.ac.kr Seulki Lee Ulsan National Institute of Science and Technology South Korea seulki.lee@unist.ac.kr Abstract We present On-device Sora, first pioneering solution for diffusion-based on-device text-to-video generation that operates efficiently on smartphone-grade devices. Building on Open-Sora, On-device Sora applies three novel techniques to address the challenges of diffusion-based text-to-video generation on computationand memory-limited mobile devices. First, Linear Proportional Leap (LPL) reduces the excessive denoising steps required in video diffusion through an efficient leap-based approach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive token-processing computation in attention layers by merging consecutive tokens along the temporal dimension. Third, Concurrent Inference with Dynamic Loading (CI-DL) dynamically partitions large models into smaller blocks and loads them into memory for concurrent model inference, effectively addressing the challenges of limited device memory. We implement On-device Sora on the iPhone 15 Pro, and the experimental evaluations demonstrate that it is capable of generating highquality videos on the device, comparable to those produced by Open-Sora running on high-end GPUs. These results show that On-device Sora enables efficient and high-quality video generation on resource-constrained mobile devices, expanding accessi"
[10.02.2025 05:12] Response: ```python
["Ulsan National Institute of Science and Technology South Korea"]
```
[10.02.2025 05:12] Deleting PDF ./assets/pdf/2502.04363.pdf.
[10.02.2025 05:12] Success.
[10.02.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2502.04728.
[10.02.2025 05:12] Downloading paper 2502.04728 from http://arxiv.org/pdf/2502.04728v1...
[10.02.2025 05:12] Extracting affiliations from text.
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 ] . [ 1 8 2 7 4 0 . 2 0 5 2 : r Generating Symbolic World Models via Test-time Scaling of Large Language Models Zhouliang Yu1,2,* Yuhuan Yuan3,* Tim Z. Xiao4 Fuxiang Frank Xia5 Jie Fu6 Ge Zhang7 Ge Lin3, Weiyang Liu4, 1The Chinese University of Hong Kong 2 The Hong Kong University of Science and Technology 3The Hong Kong University of Science and Technology (Guangzhou) 4Max Planck Institute for Intelligent Systems, Tübingen 5Environmental Systems Research Institute, Inc. 6Shanghai Artificial Intelligence Laboratory 7SEED, Bytedance "
[10.02.2025 05:12] Response: ```python
[
    "The Chinese University of Hong Kong",
    "The Hong Kong University of Science and Technology",
    "The Hong Kong University of Science and Technology (Guangzhou)",
    "Max Planck Institute for Intelligent Systems, Tübingen",
    "Environmental Systems Research Institute, Inc.",
    "Shanghai Artificial Intelligence Laboratory",
    "SEED, Bytedance"
]
```
[10.02.2025 05:12] Deleting PDF ./assets/pdf/2502.04728.pdf.
[10.02.2025 05:12] Success.
[10.02.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2502.04404.
[10.02.2025 05:12] Extra JSON file exists (./assets/json/2502.04404.json), skip PDF parsing.
[10.02.2025 05:12] Paper image links file exists (./assets/img_data/2502.04404.json), skip HTML parsing.
[10.02.2025 05:12] Success.
[10.02.2025 05:12] Downloading and parsing paper https://huggingface.co/papers/2502.04350.
[10.02.2025 05:12] Extra JSON file exists (./assets/json/2502.04350.json), skip PDF parsing.
[10.02.2025 05:12] Paper image links file exists (./assets/img_data/2502.04350.json), skip HTML parsing.
[10.02.2025 05:12] Success.
[10.02.2025 05:12] Enriching papers with extra data.
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 0. While Rotary Position Embedding (RoPE) and its variants are widely adopted for their long-context capabilities, the extension of the 1D RoPE to video, with its complex spatio-temporal structure, remains an open challenge. This work first introduces a comprehensive analysis that identifies four key c...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 1. Three-dimensional scene inpainting is crucial for applications from virtual reality to architectural visualization, yet existing methods struggle with view consistency and geometric accuracy in 360{\deg} unbounded scenes. We present AuraFusion360, a novel reference-based method that enables high-qua...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 2. The generalization of language models (LMs) is undergoing active debates, contrasting their potential for general intelligence with their struggles with basic knowledge composition (e.g., reverse/transition curse). This paper uncovers the phenomenon of linear correlations in LMs during knowledge com...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 3. Agency is a system's capacity to steer outcomes toward a goal, and is a central topic of study across biology, philosophy, cognitive science, and artificial intelligence. Determining if a system exhibits agency is a notoriously difficult question: Dennett (1989), for instance, highlights the puzzle ...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 4. This paper introduces Goku, a state-of-the-art family of joint image-and-video generation models leveraging rectified flow Transformers to achieve industry-leading performance. We detail the foundational elements enabling high-quality visual generation, including the data curation pipeline, model ar...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 5. We study a novel language model architecture that is capable of scaling test-time computation by implicitly reasoning in latent space. Our model works by iterating a recurrent block, thereby unrolling to arbitrary depth at test-time. This stands in contrast to mainstream reasoning models that scale ...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 6. We present On-device Sora, a first pioneering solution for diffusion-based on-device text-to-video generation that operates efficiently on smartphone-grade devices. Building on Open-Sora, On-device Sora applies three novel techniques to address the challenges of diffusion-based text-to-video generat...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 7. Solving complex planning problems requires Large Language Models (LLMs) to explicitly model the state transition to avoid rule violations, comply with constraints, and ensure optimality-a task hindered by the inherent ambiguity of natural language. To overcome such ambiguity, Planning Domain Definit...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 8. The integration of slow-thinking mechanisms into large language models (LLMs) offers a promising way toward achieving Level 2 AGI Reasoners, as exemplified by systems like OpenAI's o1. However, several significant challenges remain, including inefficient overthinking and an overreliance on auxiliary...
[10.02.2025 05:12] ********************************************************************************
[10.02.2025 05:12] Abstract 9. Existing methods fail to effectively steer Large Language Models (LLMs) between textual reasoning and code generation, leaving symbolic computing capabilities underutilized. We introduce CodeSteer, an effective method for guiding LLM code/text generation. We construct a comprehensive benchmark SymBe...
[10.02.2025 05:12] Read previous papers.
[10.02.2025 05:12] Generating reviews via LLM API.
[10.02.2025 05:12] Using data from previous issue: {"categories": ["#hallucinations", "#3d", "#architecture", "#video", "#long_context"], "emoji": "🎥", "ru": {"title": "VideoRoPE: Эффективное позиционное кодирование для глубокого обучения на видео", "desc": "Статья представляет VideoRoPE - новый метод позиционного кодирования для видео, основанный н
[10.02.2025 05:12] Querying the API.
[10.02.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Three-dimensional scene inpainting is crucial for applications from virtual reality to architectural visualization, yet existing methods struggle with view consistency and geometric accuracy in 360{\deg} unbounded scenes. We present AuraFusion360, a novel reference-based method that enables high-quality object removal and hole filling in 3D scenes represented by Gaussian Splatting. Our approach introduces (1) depth-aware unseen mask generation for accurate occlusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shot method for accurate initial point placement without requiring additional training, and (3) SDEdit-based detail enhancement for multi-view coherence. We also introduce 360-USID, the first comprehensive dataset for 360{\deg} unbounded scene inpainting with ground truth. Extensive experiments demonstrate that AuraFusion360 significantly outperforms existing methods, achieving superior perceptual quality while maintaining geometric accuracy across dramatic viewpoint changes. See our project page for video results and the dataset at https://kkennethwu.github.io/aurafusion360/.
[10.02.2025 05:12] Response: {
  "desc": "AuraFusion360 - это новый метод восстановления трехмерных сцен на основе Gaussian Splatting. Он использует генерацию масок невидимых областей с учетом глубины, адаптивную диффузию глубины и улучшение деталей на основе SDEdit для создания высококачественных результатов. Метод превосходит существующие подходы по качеству восприятия и геометрической точности при изменении точки обзора. Авторы также представили первый набор данных 360-USID для оценки методов восстановления сцен с охватом 360 градусов.",
  "emoji": "🌐",
  "title": "Революция в 3D-реконструкции: AuraFusion360 для безупречного восстановления сцен"
}
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Three-dimensional scene inpainting is crucial for applications from virtual reality to architectural visualization, yet existing methods struggle with view consistency and geometric accuracy in 360{\deg} unbounded scenes. We present AuraFusion360, a novel reference-based method that enables high-quality object removal and hole filling in 3D scenes represented by Gaussian Splatting. Our approach introduces (1) depth-aware unseen mask generation for accurate occlusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shot method for accurate initial point placement without requiring additional training, and (3) SDEdit-based detail enhancement for multi-view coherence. We also introduce 360-USID, the first comprehensive dataset for 360{\deg} unbounded scene inpainting with ground truth. Extensive experiments demonstrate that AuraFusion360 significantly outperforms existing methods, achieving superior perceptual quality while maintaining geometric accuracy across dramatic viewpoint changes. See our project page for video results and the dataset at https://kkennethwu.github.io/aurafusion360/."

[10.02.2025 05:12] Response: ```python
["3D", "DATASET"]
```
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Three-dimensional scene inpainting is crucial for applications from virtual reality to architectural visualization, yet existing methods struggle with view consistency and geometric accuracy in 360{\deg} unbounded scenes. We present AuraFusion360, a novel reference-based method that enables high-quality object removal and hole filling in 3D scenes represented by Gaussian Splatting. Our approach introduces (1) depth-aware unseen mask generation for accurate occlusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shot method for accurate initial point placement without requiring additional training, and (3) SDEdit-based detail enhancement for multi-view coherence. We also introduce 360-USID, the first comprehensive dataset for 360{\deg} unbounded scene inpainting with ground truth. Extensive experiments demonstrate that AuraFusion360 significantly outperforms existing methods, achieving superior perceptual quality while maintaining geometric accuracy across dramatic viewpoint changes. See our project page for video results and the dataset at https://kkennethwu.github.io/aurafusion360/."

[10.02.2025 05:12] Response: []
[10.02.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"AuraFusion360 is a new method for filling in missing parts of 3D scenes, which is important for applications like virtual reality. It uses Gaussian Splatting to represent scenes and introduces techniques for better identifying what should be filled in, ensuring that the filled areas look realistic from different angles. The method also places points accurately without needing extra training and enhances details to keep the views consistent. Additionally, it comes with a new dataset for testing these 3D inpainting methods, showing that AuraFusion360 performs better than previous techniques in both quality and accuracy.","title":"Revolutionizing 3D Scene Inpainting with AuraFusion360"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='AuraFusion360 is a new method for filling in missing parts of 3D scenes, which is important for applications like virtual reality. It uses Gaussian Splatting to represent scenes and introduces techniques for better identifying what should be filled in, ensuring that the filled areas look realistic from different angles. The method also places points accurately without needing extra training and enhances details to keep the views consistent. Additionally, it comes with a new dataset for testing these 3D inpainting methods, showing that AuraFusion360 performs better than previous techniques in both quality and accuracy.', title='Revolutionizing 3D Scene Inpainting with AuraFusion360'))
[10.02.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"三维场景修复在虚拟现实和建筑可视化等应用中非常重要，但现有方法在360度无界场景中面临视图一致性和几何精度的挑战。我们提出了AuraFusion360，这是一种新颖的基于参考的方法，能够在高质量的3D场景中进行物体移除和孔填充。该方法引入了深度感知的未见掩码生成、适应性引导深度扩散和基于SDEdit的细节增强，确保多视图的一致性。通过大量实验，AuraFusion360在感知质量和几何精度方面显著优于现有方法，能够在剧烈视角变化中保持高质量的修复效果。","title":"AuraFusion360：三维场景修复的新突破"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='三维场景修复在虚拟现实和建筑可视化等应用中非常重要，但现有方法在360度无界场景中面临视图一致性和几何精度的挑战。我们提出了AuraFusion360，这是一种新颖的基于参考的方法，能够在高质量的3D场景中进行物体移除和孔填充。该方法引入了深度感知的未见掩码生成、适应性引导深度扩散和基于SDEdit的细节增强，确保多视图的一致性。通过大量实验，AuraFusion360在感知质量和几何精度方面显著优于现有方法，能够在剧烈视角变化中保持高质量的修复效果。', title='AuraFusion360：三维场景修复的新突破'))
[10.02.2025 05:12] Querying the API.
[10.02.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The generalization of language models (LMs) is undergoing active debates, contrasting their potential for general intelligence with their struggles with basic knowledge composition (e.g., reverse/transition curse). This paper uncovers the phenomenon of linear correlations in LMs during knowledge composition. For explanation, there exists a linear transformation between certain related knowledge that maps the next token prediction logits from one prompt to another, e.g., "X lives in the city of" rightarrow "X lives in the country of" for every given X. This mirrors the linearity in human knowledge composition, such as Paris rightarrow France. Our findings indicate that the linear transformation is resilient to large-scale fine-tuning, generalizing updated knowledge when aligned with real-world relationships, but causing hallucinations when it deviates. Empirical results suggest that linear correlation can serve as a potential identifier of LM's generalization. Finally, we show such linear correlations can be learned with a single feedforward network and pre-trained vocabulary representations, indicating LM generalization heavily relies on the latter.
[10.02.2025 05:12] Response: {
  "desc": "Статья исследует феномен линейных корреляций в языковых моделях при композиции знаний. Авторы обнаружили, что существует линейное преобразование между связанными знаниями, которое отображает логиты предсказания следующего токена от одного промпта к другому. Это явление устойчиво к масштабному дообучению и может служить потенциальным идентификатором обобщения языковой модели. Исследование показывает, что такие линейные корреляции могут быть изучены с помощью одной полносвязной нейронной сети и предобученных представлений словаря.",
  "emoji": "🧠",
  "title": "Линейность как ключ к обобщению языковых моделей"
}
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The generalization of language models (LMs) is undergoing active debates, contrasting their potential for general intelligence with their struggles with basic knowledge composition (e.g., reverse/transition curse). This paper uncovers the phenomenon of linear correlations in LMs during knowledge composition. For explanation, there exists a linear transformation between certain related knowledge that maps the next token prediction logits from one prompt to another, e.g., "X lives in the city of" rightarrow "X lives in the country of" for every given X. This mirrors the linearity in human knowledge composition, such as Paris rightarrow France. Our findings indicate that the linear transformation is resilient to large-scale fine-tuning, generalizing updated knowledge when aligned with real-world relationships, but causing hallucinations when it deviates. Empirical results suggest that linear correlation can serve as a potential identifier of LM's generalization. Finally, we show such linear correlations can be learned with a single feedforward network and pre-trained vocabulary representations, indicating LM generalization heavily relies on the latter."

[10.02.2025 05:12] Response: ```python
["DATA", "TRAINING", "ARCHITECTURE"]
```
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The generalization of language models (LMs) is undergoing active debates, contrasting their potential for general intelligence with their struggles with basic knowledge composition (e.g., reverse/transition curse). This paper uncovers the phenomenon of linear correlations in LMs during knowledge composition. For explanation, there exists a linear transformation between certain related knowledge that maps the next token prediction logits from one prompt to another, e.g., "X lives in the city of" rightarrow "X lives in the country of" for every given X. This mirrors the linearity in human knowledge composition, such as Paris rightarrow France. Our findings indicate that the linear transformation is resilient to large-scale fine-tuning, generalizing updated knowledge when aligned with real-world relationships, but causing hallucinations when it deviates. Empirical results suggest that linear correlation can serve as a potential identifier of LM's generalization. Finally, we show such linear correlations can be learned with a single feedforward network and pre-trained vocabulary representations, indicating LM generalization heavily relies on the latter."

[10.02.2025 05:12] Response: ```python
['AGI', 'HALLUCINATIONS', 'INTERPRETABILITY']
```
[10.02.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how language models (LMs) handle knowledge composition, revealing that they exhibit linear correlations when predicting the next token. It shows that there is a linear transformation that connects related knowledge, allowing LMs to generalize information effectively, similar to how humans relate concepts. The study finds that while these linear transformations can adapt to new information through fine-tuning, they can also lead to incorrect outputs, or hallucinations, when the relationships are not aligned with reality. Overall, the research suggests that understanding these linear correlations can help identify how well LMs generalize knowledge.","title":"Unlocking Language Models: The Power of Linear Correlations in Knowledge Composition"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper explores how language models (LMs) handle knowledge composition, revealing that they exhibit linear correlations when predicting the next token. It shows that there is a linear transformation that connects related knowledge, allowing LMs to generalize information effectively, similar to how humans relate concepts. The study finds that while these linear transformations can adapt to new information through fine-tuning, they can also lead to incorrect outputs, or hallucinations, when the relationships are not aligned with reality. Overall, the research suggests that understanding these linear correlations can help identify how well LMs generalize knowledge.', title='Unlocking Language Models: The Power of Linear Correlations in Knowledge Composition'))
[10.02.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文探讨了语言模型（LM）在知识组合中的线性相关现象。研究发现，某些相关知识之间存在线性变换，这种变换可以将一个提示的下一个标记预测从一个映射到另一个。比如，从\\"X 住在城市\\"可以转变为\\"X 住在国家\\"。结果表明，线性变换在大规模微调中具有韧性，并且当与现实世界关系一致时能够推广更新的知识，但当偏离时则会导致幻觉。","title":"语言模型的线性相关性与知识组合"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='这篇论文探讨了语言模型（LM）在知识组合中的线性相关现象。研究发现，某些相关知识之间存在线性变换，这种变换可以将一个提示的下一个标记预测从一个映射到另一个。比如，从"X 住在城市"可以转变为"X 住在国家"。结果表明，线性变换在大规模微调中具有韧性，并且当与现实世界关系一致时能够推广更新的知识，但当偏离时则会导致幻觉。', title='语言模型的线性相关性与知识组合'))
[10.02.2025 05:12] Using data from previous issue: {"categories": ["#rl", "#agi", "#reasoning", "#math"], "emoji": "🤖", "ru": {"title": "Агентность: все зависит от точки зрения", "desc": "Статья рассматривает концепцию агентности в контексте обучения с подкреплением. Авторы утверждают, что агентность фундаментально зависит от системы отсчета. Они по
[10.02.2025 05:12] Querying the API.
[10.02.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

This paper introduces Goku, a state-of-the-art family of joint image-and-video generation models leveraging rectified flow Transformers to achieve industry-leading performance. We detail the foundational elements enabling high-quality visual generation, including the data curation pipeline, model architecture design, flow formulation, and advanced infrastructure for efficient and robust large-scale training. The Goku models demonstrate superior performance in both qualitative and quantitative evaluations, setting new benchmarks across major tasks. Specifically, Goku achieves 0.76 on GenEval and 83.65 on DPG-Bench for text-to-image generation, and 84.85 on VBench for text-to-video tasks. We believe that this work provides valuable insights and practical advancements for the research community in developing joint image-and-video generation models.
[10.02.2025 05:12] Response: {
  "desc": "Статья представляет семейство моделей Goku для совместной генерации изображений и видео. Модели используют трансформеры с выпрямленным потоком для достижения передовых результатов. Авторы описывают ключевые элементы, включая подготовку данных, архитектуру модели и инфраструктуру для эффективного обучения. Goku демонстрирует превосходную производительность в качественных и количественных оценках, устанавливая новые стандарты в основных задачах генерации изображений и видео.",
  "emoji": "🐉",
  "title": "Goku: Новый уровень генерации изображений и видео"
}
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"This paper introduces Goku, a state-of-the-art family of joint image-and-video generation models leveraging rectified flow Transformers to achieve industry-leading performance. We detail the foundational elements enabling high-quality visual generation, including the data curation pipeline, model architecture design, flow formulation, and advanced infrastructure for efficient and robust large-scale training. The Goku models demonstrate superior performance in both qualitative and quantitative evaluations, setting new benchmarks across major tasks. Specifically, Goku achieves 0.76 on GenEval and 83.65 on DPG-Bench for text-to-image generation, and 84.85 on VBench for text-to-video tasks. We believe that this work provides valuable insights and practical advancements for the research community in developing joint image-and-video generation models."

[10.02.2025 05:12] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'CV', 'VIDEO', 'ARCHITECTURE', 'TRAINING']
```
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"This paper introduces Goku, a state-of-the-art family of joint image-and-video generation models leveraging rectified flow Transformers to achieve industry-leading performance. We detail the foundational elements enabling high-quality visual generation, including the data curation pipeline, model architecture design, flow formulation, and advanced infrastructure for efficient and robust large-scale training. The Goku models demonstrate superior performance in both qualitative and quantitative evaluations, setting new benchmarks across major tasks. Specifically, Goku achieves 0.76 on GenEval and 83.65 on DPG-Bench for text-to-image generation, and 84.85 on VBench for text-to-video tasks. We believe that this work provides valuable insights and practical advancements for the research community in developing joint image-and-video generation models."

[10.02.2025 05:12] Response: ```python
[]
```
[10.02.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents Goku, a cutting-edge model for generating images and videos using rectified flow Transformers. It discusses key components that contribute to its high-quality output, such as the data curation process and the design of the model architecture. Goku sets new performance records in various tasks, achieving impressive scores on benchmarks for both text-to-image and text-to-video generation. The authors aim to offer insights and advancements that will benefit researchers working on similar generation models.","title":"Goku: Revolutionizing Image and Video Generation with Transformers"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper presents Goku, a cutting-edge model for generating images and videos using rectified flow Transformers. It discusses key components that contribute to its high-quality output, such as the data curation process and the design of the model architecture. Goku sets new performance records in various tasks, achieving impressive scores on benchmarks for both text-to-image and text-to-video generation. The authors aim to offer insights and advancements that will benefit researchers working on similar generation models.', title='Goku: Revolutionizing Image and Video Generation with Transformers'))
[10.02.2025 05:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了Goku，这是一种先进的联合图像和视频生成模型，利用了修正流Transformer以实现行业领先的性能。我们详细阐述了高质量视觉生成的基础要素，包括数据整理流程、模型架构设计、流的公式化以及高效稳健的大规模训练基础设施。Goku模型在定性和定量评估中表现优越，为主要任务设定了新的基准。具体而言，Goku在文本到图像生成中达到了0.76的GenEval和83.65的DPG-Bench，在文本到视频任务中达到了84.85的VBench。","title":"Goku：图像与视频生成的新标杆"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='本文介绍了Goku，这是一种先进的联合图像和视频生成模型，利用了修正流Transformer以实现行业领先的性能。我们详细阐述了高质量视觉生成的基础要素，包括数据整理流程、模型架构设计、流的公式化以及高效稳健的大规模训练基础设施。Goku模型在定性和定量评估中表现优越，为主要任务设定了新的基准。具体而言，Goku在文本到图像生成中达到了0.76的GenEval和83.65的DPG-Bench，在文本到视频任务中达到了84.85的VBench。', title='Goku：图像与视频生成的新标杆'))
[10.02.2025 05:12] Querying the API.
[10.02.2025 05:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We study a novel language model architecture that is capable of scaling test-time computation by implicitly reasoning in latent space. Our model works by iterating a recurrent block, thereby unrolling to arbitrary depth at test-time. This stands in contrast to mainstream reasoning models that scale up compute by producing more tokens. Unlike approaches based on chain-of-thought, our approach does not require any specialized training data, can work with small context windows, and can capture types of reasoning that are not easily represented in words. We scale a proof-of-concept model to 3.5 billion parameters and 800 billion tokens. We show that the resulting model can improve its performance on reasoning benchmarks, sometimes dramatically, up to a computation load equivalent to 50 billion parameters.
[10.02.2025 05:12] Response: {
  "desc": "В статье представлена новая архитектура языковой модели, способная масштабировать вычисления во время тестирования путем неявных рассуждений в латентном пространстве. Модель работает путем итерации рекуррентного блока, разворачиваясь до произвольной глубины во время тестирования. В отличие от подходов, основанных на цепочке рассуждений, этот метод не требует специализированных обучающих данных и может работать с небольшими контекстными окнами. Авторы масштабировали экспериментальную модель до 3,5 миллиардов параметров и 800 миллиардов токенов, показав значительное улучшение производительности на тестах рассуждений.",
  "emoji": "🧠",
  "title": "Глубокие рассуждения в латентном пространстве: новый подход к языковым моделям"
}
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We study a novel language model architecture that is capable of scaling test-time computation by implicitly reasoning in latent space. Our model works by iterating a recurrent block, thereby unrolling to arbitrary depth at test-time. This stands in contrast to mainstream reasoning models that scale up compute by producing more tokens. Unlike approaches based on chain-of-thought, our approach does not require any specialized training data, can work with small context windows, and can capture types of reasoning that are not easily represented in words. We scale a proof-of-concept model to 3.5 billion parameters and 800 billion tokens. We show that the resulting model can improve its performance on reasoning benchmarks, sometimes dramatically, up to a computation load equivalent to 50 billion parameters."

[10.02.2025 05:12] Response: ```python
['ARCHITECTURE', 'TRAINING', 'BENCHMARK']
```
[10.02.2025 05:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We study a novel language model architecture that is capable of scaling test-time computation by implicitly reasoning in latent space. Our model works by iterating a recurrent block, thereby unrolling to arbitrary depth at test-time. This stands in contrast to mainstream reasoning models that scale up compute by producing more tokens. Unlike approaches based on chain-of-thought, our approach does not require any specialized training data, can work with small context windows, and can capture types of reasoning that are not easily represented in words. We scale a proof-of-concept model to 3.5 billion parameters and 800 billion tokens. We show that the resulting model can improve its performance on reasoning benchmarks, sometimes dramatically, up to a computation load equivalent to 50 billion parameters."

[10.02.2025 05:12] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[10.02.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new language model architecture that enhances reasoning capabilities by performing computations in a latent space during test-time. Instead of generating more tokens to scale reasoning, the model uses a recurrent block that allows it to unroll computations to any depth. This method does not rely on specialized training data and can effectively handle small context windows, enabling it to capture complex reasoning patterns. The authors demonstrate that their model, with 3.5 billion parameters, can achieve significant improvements on reasoning tasks, comparable to models with much larger parameter counts.","title":"Scaling Reasoning with Latent Space Computation"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper presents a new language model architecture that enhances reasoning capabilities by performing computations in a latent space during test-time. Instead of generating more tokens to scale reasoning, the model uses a recurrent block that allows it to unroll computations to any depth. This method does not rely on specialized training data and can effectively handle small context windows, enabling it to capture complex reasoning patterns. The authors demonstrate that their model, with 3.5 billion parameters, can achieve significant improvements on reasoning tasks, comparable to models with much larger parameter counts.', title='Scaling Reasoning with Latent Space Computation'))
[10.02.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"我们研究了一种新颖的语言模型架构，该架构能够通过在潜在空间中隐式推理来扩展测试时的计算能力。我们的模型通过迭代递归块工作，从而在测试时可以展开到任意深度。这与主流推理模型不同，后者通过生成更多的标记来增加计算量。我们的模型不需要特殊的训练数据，能够处理小的上下文窗口，并且能够捕捉不易用语言表示的推理类型。","title":"隐式推理，提升语言模型的计算能力"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='我们研究了一种新颖的语言模型架构，该架构能够通过在潜在空间中隐式推理来扩展测试时的计算能力。我们的模型通过迭代递归块工作，从而在测试时可以展开到任意深度。这与主流推理模型不同，后者通过生成更多的标记来增加计算量。我们的模型不需要特殊的训练数据，能够处理小的上下文窗口，并且能够捕捉不易用语言表示的推理类型。', title='隐式推理，提升语言模型的计算能力'))
[10.02.2025 05:13] Querying the API.
[10.02.2025 05:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We present On-device Sora, a first pioneering solution for diffusion-based on-device text-to-video generation that operates efficiently on smartphone-grade devices. Building on Open-Sora, On-device Sora applies three novel techniques to address the challenges of diffusion-based text-to-video generation on computation- and memory-limited mobile devices. First, Linear Proportional Leap (LPL) reduces the excessive denoising steps required in video diffusion through an efficient leap-based approach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive token-processing computation in attention layers by merging consecutive tokens along the temporal dimension. Third, Concurrent Inference with Dynamic Loading (CI-DL) dynamically partitions large models into smaller blocks and loads them into memory for concurrent model inference, effectively addressing the challenges of limited device memory. We implement On-device Sora on the iPhone 15 Pro, and the experimental evaluations demonstrate that it is capable of generating high-quality videos on the device, comparable to those produced by Open-Sora running on high-end GPUs. These results show that On-device Sora enables efficient and high-quality video generation on resource-constrained mobile devices, expanding accessibility, ensuring user privacy, reducing dependence on cloud infrastructure, and lowering associated costs. We envision the proposed On-device Sora as a significant first step toward democratizing state-of-the-art generative technologies, enabling video generation capabilities on commodity mobile and embedded devices. The code implementation is publicly available at an GitHub repository: https://github.com/eai-lab/On-device-Sora.
[10.02.2025 05:13] Response: {
  "desc": "On-device Sora представляет собой инновационное решение для генерации видео на основе текста с использованием диффузионных моделей, работающее на смартфонах. Система применяет три новые техники: Linear Proportional Leap (LPL) для сокращения шагов денойзинга, Temporal Dimension Token Merging (TDTM) для оптимизации вычислений в слоях внимания, и Concurrent Inference with Dynamic Loading (CI-DL) для эффективного использования ограниченной памяти устройства. Эксперименты на iPhone 15 Pro показали, что On-device Sora способна генерировать видео высокого качества, сравнимые с результатами Open-Sora на мощных GPU.",

  "emoji": "📱",

  "title": "Генерация видео по тексту прямо на вашем смартфоне"
}
[10.02.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We present On-device Sora, a first pioneering solution for diffusion-based on-device text-to-video generation that operates efficiently on smartphone-grade devices. Building on Open-Sora, On-device Sora applies three novel techniques to address the challenges of diffusion-based text-to-video generation on computation- and memory-limited mobile devices. First, Linear Proportional Leap (LPL) reduces the excessive denoising steps required in video diffusion through an efficient leap-based approach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive token-processing computation in attention layers by merging consecutive tokens along the temporal dimension. Third, Concurrent Inference with Dynamic Loading (CI-DL) dynamically partitions large models into smaller blocks and loads them into memory for concurrent model inference, effectively addressing the challenges of limited device memory. We implement On-device Sora on the iPhone 15 Pro, and the experimental evaluations demonstrate that it is capable of generating high-quality videos on the device, comparable to those produced by Open-Sora running on high-end GPUs. These results show that On-device Sora enables efficient and high-quality video generation on resource-constrained mobile devices, expanding accessibility, ensuring user privacy, reducing dependence on cloud infrastructure, and lowering associated costs. We envision the proposed On-device Sora as a significant first step toward democratizing state-of-the-art generative technologies, enabling video generation capabilities on commodity mobile and embedded devices. The code implementation is publicly available at an GitHub repository: https://github.com/eai-lab/On-device-Sora."

[10.02.2025 05:13] Response: ```python
['VIDEO', 'INFERENCE', 'ARCHITECTURE']
```
[10.02.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We present On-device Sora, a first pioneering solution for diffusion-based on-device text-to-video generation that operates efficiently on smartphone-grade devices. Building on Open-Sora, On-device Sora applies three novel techniques to address the challenges of diffusion-based text-to-video generation on computation- and memory-limited mobile devices. First, Linear Proportional Leap (LPL) reduces the excessive denoising steps required in video diffusion through an efficient leap-based approach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive token-processing computation in attention layers by merging consecutive tokens along the temporal dimension. Third, Concurrent Inference with Dynamic Loading (CI-DL) dynamically partitions large models into smaller blocks and loads them into memory for concurrent model inference, effectively addressing the challenges of limited device memory. We implement On-device Sora on the iPhone 15 Pro, and the experimental evaluations demonstrate that it is capable of generating high-quality videos on the device, comparable to those produced by Open-Sora running on high-end GPUs. These results show that On-device Sora enables efficient and high-quality video generation on resource-constrained mobile devices, expanding accessibility, ensuring user privacy, reducing dependence on cloud infrastructure, and lowering associated costs. We envision the proposed On-device Sora as a significant first step toward democratizing state-of-the-art generative technologies, enabling video generation capabilities on commodity mobile and embedded devices. The code implementation is publicly available at an GitHub repository: https://github.com/eai-lab/On-device-Sora."

[10.02.2025 05:13] Response: ```python
["DIFFUSION", "OPEN_SOURCE", "LOW_RESOURCE"]
```
[10.02.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"On-device Sora is a groundbreaking solution for generating videos from text using diffusion models directly on smartphones. It introduces three innovative techniques: Linear Proportional Leap (LPL) to reduce denoising steps, Temporal Dimension Token Merging (TDTM) to optimize token processing in attention layers, and Concurrent Inference with Dynamic Loading (CI-DL) to manage memory efficiently. These advancements allow the system to produce high-quality videos comparable to those generated by powerful GPUs, all while operating within the constraints of mobile devices. This work not only enhances accessibility to advanced generative technologies but also prioritizes user privacy and reduces reliance on cloud services.","title":"Empowering Video Creation on Your Smartphone!"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='On-device Sora is a groundbreaking solution for generating videos from text using diffusion models directly on smartphones. It introduces three innovative techniques: Linear Proportional Leap (LPL) to reduce denoising steps, Temporal Dimension Token Merging (TDTM) to optimize token processing in attention layers, and Concurrent Inference with Dynamic Loading (CI-DL) to manage memory efficiently. These advancements allow the system to produce high-quality videos comparable to those generated by powerful GPUs, all while operating within the constraints of mobile devices. This work not only enhances accessibility to advanced generative technologies but also prioritizes user privacy and reduces reliance on cloud services.', title='Empowering Video Creation on Your Smartphone!'))
[10.02.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"我们提出了On-device Sora，这是首个基于扩散模型的移动设备文本到视频生成解决方案，能够高效地在智能手机上运行。该系统采用了三种新技术来解决移动设备在计算和内存方面的限制。首先，线性比例跳跃（LPL）通过高效的跳跃方法减少了视频扩散中所需的去噪步骤。其次，时间维度令牌合并（TDTM）通过沿时间维度合并连续令牌，降低了注意力层中密集的令牌处理计算。","title":"移动设备上的高效视频生成新突破"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='我们提出了On-device Sora，这是首个基于扩散模型的移动设备文本到视频生成解决方案，能够高效地在智能手机上运行。该系统采用了三种新技术来解决移动设备在计算和内存方面的限制。首先，线性比例跳跃（LPL）通过高效的跳跃方法减少了视频扩散中所需的去噪步骤。其次，时间维度令牌合并（TDTM）通过沿时间维度合并连续令牌，降低了注意力层中密集的令牌处理计算。', title='移动设备上的高效视频生成新突破'))
[10.02.2025 05:13] Querying the API.
[10.02.2025 05:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Solving complex planning problems requires Large Language Models (LLMs) to explicitly model the state transition to avoid rule violations, comply with constraints, and ensure optimality-a task hindered by the inherent ambiguity of natural language. To overcome such ambiguity, Planning Domain Definition Language (PDDL) is leveraged as a planning abstraction that enables precise and formal state descriptions. With PDDL, we can generate a symbolic world model where classic searching algorithms, such as A*, can be seamlessly applied to find optimal plans. However, directly generating PDDL domains with current LLMs remains an open challenge due to the lack of PDDL training data. To address this challenge, we propose to scale up the test-time computation of LLMs to enhance their PDDL reasoning capabilities, thereby enabling the generation of high-quality PDDL domains. Specifically, we introduce a simple yet effective algorithm, which first employs a Best-of-N sampling approach to improve the quality of the initial solution and then refines the solution in a fine-grained manner with verbalized machine learning. Our method outperforms o1-mini by a considerable margin in the generation of PDDL domain, achieving over 50% success rate on two tasks (i.e., generating PDDL domains from natural language description or PDDL problems). This is done without requiring additional training. By taking advantage of PDDL as state abstraction, our method is able to outperform current state-of-the-art methods on almost all competition-level planning tasks.
[10.02.2025 05:13] Response: {
  "desc": "Статья представляет новый подход к решению сложных задач планирования с использованием больших языковых моделей (LLM). Авторы предлагают использовать язык определения планирования (PDDL) для создания точной символической модели мира. Метод включает алгоритм Best-of-N для улучшения качества начального решения и последующее уточнение с помощью вербализованного машинного обучения. Результаты показывают значительное превосходство над существующими методами в генерации доменов PDDL и решении задач планирования высокого уровня.",
  "emoji": "🧠",
  "title": "Повышение эффективности планирования с помощью PDDL и LLM"
}
[10.02.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Solving complex planning problems requires Large Language Models (LLMs) to explicitly model the state transition to avoid rule violations, comply with constraints, and ensure optimality-a task hindered by the inherent ambiguity of natural language. To overcome such ambiguity, Planning Domain Definition Language (PDDL) is leveraged as a planning abstraction that enables precise and formal state descriptions. With PDDL, we can generate a symbolic world model where classic searching algorithms, such as A*, can be seamlessly applied to find optimal plans. However, directly generating PDDL domains with current LLMs remains an open challenge due to the lack of PDDL training data. To address this challenge, we propose to scale up the test-time computation of LLMs to enhance their PDDL reasoning capabilities, thereby enabling the generation of high-quality PDDL domains. Specifically, we introduce a simple yet effective algorithm, which first employs a Best-of-N sampling approach to improve the quality of the initial solution and then refines the solution in a fine-grained manner with verbalized machine learning. Our method outperforms o1-mini by a considerable margin in the generation of PDDL domain, achieving over 50% success rate on two tasks (i.e., generating PDDL domains from natural language description or PDDL problems). This is done without requiring additional training. By taking advantage of PDDL as state abstraction, our method is able to outperform current state-of-the-art methods on almost all competition-level planning tasks."

[10.02.2025 05:13] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'ARCHITECTURE', 'TRAINING']
```
[10.02.2025 05:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Solving complex planning problems requires Large Language Models (LLMs) to explicitly model the state transition to avoid rule violations, comply with constraints, and ensure optimality-a task hindered by the inherent ambiguity of natural language. To overcome such ambiguity, Planning Domain Definition Language (PDDL) is leveraged as a planning abstraction that enables precise and formal state descriptions. With PDDL, we can generate a symbolic world model where classic searching algorithms, such as A*, can be seamlessly applied to find optimal plans. However, directly generating PDDL domains with current LLMs remains an open challenge due to the lack of PDDL training data. To address this challenge, we propose to scale up the test-time computation of LLMs to enhance their PDDL reasoning capabilities, thereby enabling the generation of high-quality PDDL domains. Specifically, we introduce a simple yet effective algorithm, which first employs a Best-of-N sampling approach to improve the quality of the initial solution and then refines the solution in a fine-grained manner with verbalized machine learning. Our method outperforms o1-mini by a considerable margin in the generation of PDDL domain, achieving over 50% success rate on two tasks (i.e., generating PDDL domains from natural language description or PDDL problems). This is done without requiring additional training. By taking advantage of PDDL as state abstraction, our method is able to outperform current state-of-the-art methods on almost all competition-level planning tasks."

[10.02.2025 05:13] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[10.02.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of using Large Language Models (LLMs) for complex planning problems by introducing a method to generate Planning Domain Definition Language (PDDL) domains. PDDL serves as a formal language that helps in creating precise state descriptions, which is crucial for avoiding rule violations and ensuring optimal planning. The authors propose a novel algorithm that enhances LLMs\' reasoning capabilities through a Best-of-N sampling approach, followed by fine-grained refinement using verbalized machine learning techniques. Their approach significantly improves the generation of PDDL domains, achieving over 50% success in generating high-quality plans from natural language descriptions without additional training.","title":"Enhancing LLMs for Optimal Planning with PDDL"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc="This paper addresses the challenge of using Large Language Models (LLMs) for complex planning problems by introducing a method to generate Planning Domain Definition Language (PDDL) domains. PDDL serves as a formal language that helps in creating precise state descriptions, which is crucial for avoiding rule violations and ensuring optimal planning. The authors propose a novel algorithm that enhances LLMs' reasoning capabilities through a Best-of-N sampling approach, followed by fine-grained refinement using verbalized machine learning techniques. Their approach significantly improves the generation of PDDL domains, achieving over 50% success in generating high-quality plans from natural language descriptions without additional training.", title='Enhancing LLMs for Optimal Planning with PDDL'))
[10.02.2025 05:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文探讨了如何利用大型语言模型（LLMs）解决复杂的规划问题。为了避免规则违反和确保最优性，研究者们引入了规划领域定义语言（PDDL），作为一种精确的状态描述工具。通过PDDL，可以生成符号世界模型，并应用经典搜索算法（如A*）来寻找最优计划。本文提出了一种简单有效的算法，通过Best-of-N采样和细致的机器学习优化，显著提高了PDDL领域的生成质量，成功率超过50%。","title":"利用PDDL提升规划问题解决能力"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='本论文探讨了如何利用大型语言模型（LLMs）解决复杂的规划问题。为了避免规则违反和确保最优性，研究者们引入了规划领域定义语言（PDDL），作为一种精确的状态描述工具。通过PDDL，可以生成符号世界模型，并应用经典搜索算法（如A*）来寻找最优计划。本文提出了一种简单有效的算法，通过Best-of-N采样和细致的机器学习优化，显著提高了PDDL领域的生成质量，成功率超过50%。', title='利用PDDL提升规划问题解决能力'))
[10.02.2025 05:13] Using data from previous issue: {"categories": ["#agi", "#training", "#inference", "#agents", "#architecture", "#reasoning"], "emoji": "🧠", "ru": {"title": "Самостоятельный возврат: путь к более разумным ИИ", "desc": "Статья представляет новый механизм самостоятельного возврата (self-backtracking) для больших языковых моделей (LLM
[10.02.2025 05:13] Using data from previous issue: {"categories": ["#training", "#dataset", "#benchmark", "#rlhf", "#open_source", "#optimization", "#reasoning"], "emoji": "🧭", "ru": {"title": "CodeSteer: Умное управление для раскрытия потенциала LLM в символьных вычислениях", "desc": "CodeSteer - это новый метод для эффективного управления генераци
[10.02.2025 05:13] Loading Chinese text from previous data.
[10.02.2025 05:13] Renaming data file.
[10.02.2025 05:13] Renaming previous data. hf_papers.json to ./d/2025-02-10.json
[10.02.2025 05:13] Saving new data file.
[10.02.2025 05:13] Generating page.
[10.02.2025 05:13] Renaming previous page.
[10.02.2025 05:13] Renaming previous data. index.html to ./d/2025-02-10.html
[10.02.2025 05:13] [Experimental] Generating Chinese page for reading.
[10.02.2025 05:13] Chinese vocab [{'word': '介绍', 'pinyin': 'jiè shào', 'trans': 'introduce'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '系统地', 'pinyin': 'xì tǒng de', 'trans': 'systematically'}, {'word': '映射', 'pinyin': 'yìng shè', 'trans': 'map'}, {'word': '稀疏', 'pinyin': 'xī shū', 'trans': 'sparse'}, {'word': '自编码器', 'pinyin': 'zì biān mǎ qì', 'trans': 'autoencoder'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '连续层', 'pinyin': 'lián xù céng', 'trans': 'continuous layer'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'discover'}, {'word': '特征', 'pinyin': 'tè zhēng', 'trans': 'feature'}, {'word': '无数据', 'pinyin': 'wú shù jù', 'trans': 'data-free'}, {'word': '余弦相似度', 'pinyin': 'yú xiàn xiāng sì dù', 'trans': 'cosine similarity'}, {'word': '技术', 'pinyin': 'jì shù', 'trans': 'technique'}, {'word': '追踪', 'pinyin': 'zhuī zōng', 'trans': 'track'}, {'word': '持续', 'pinyin': 'chí xù', 'trans': 'persist'}, {'word': '转变', 'pinyin': 'zhuǎn biàn', 'trans': 'transform'}, {'word': '首次', 'pinyin': 'shǒu cì', 'trans': 'first time'}, {'word': '出现', 'pinyin': 'chū xiàn', 'trans': 'appear'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '产生', 'pinyin': 'chǎn shēng', 'trans': 'generate'}, {'word': '演变', 'pinyin': 'yǎn biàn', 'trans': 'evolution'}, {'word': '细粒度', 'pinyin': 'xì lì dù', 'trans': 'fine-grained'}, {'word': '流图', 'pinyin': 'liú tú', 'trans': 'flow chart'}, {'word': '提供', 'pinyin': 'tí gōng', 'trans': 'provide'}, {'word': '可解释性', 'pinyin': 'kě jiě shì xìng', 'trans': 'interpretability'}, {'word': '机制', 'pinyin': 'jī zhì', 'trans': 'mechanism'}, {'word': '洞察', 'pinyin': 'dòng chā', 'trans': 'insight'}, {'word': '关键', 'pinyin': 'guǎn jiàn', 'trans': 'key'}, {'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'}, {'word': '跨层', 'pinyin': 'kuà céng', 'trans': 'cross-layer'}, {'word': '特征图', 'pinyin': 'tè zhēng tú', 'trans': 'feature map'}, {'word': '放大', 'pinyin': 'fàng dà', 'trans': 'amplify'}, {'word': '抑制', 'pinyin': 'yì zhì', 'trans': 'suppress'}, {'word': '选定', 'pinyin': 'xuǎn dìng', 'trans': 'select'}, {'word': '引导', 'pinyin': 'yǐn dǎo', 'trans': 'guide'}, {'word': '模型行为', 'pinyin': 'mó xíng xíng wéi', 'trans': 'model behavior'}, {'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'}, {'word': '文本生成', 'pinyin': 'wén běn shēng chéng', 'trans': 'text generation'}, {'word': '定向', 'pinyin': 'dìng xiàng', 'trans': 'directed'}, {'word': '主题控制', 'pinyin': 'zhǔ tí kòng zhì', 'trans': 'theme control'}, {'word': '总的来说', 'pinyin': 'zǒng de lái shuō', 'trans': 'in summary'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'discover'}, {'word': '突显', 'pinyin': 'tū xiǎn', 'trans': 'highlight'}, {'word': '因果', 'pinyin': 'yīn guǒ', 'trans': 'causal'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '实用性', 'pinyin': 'shí yòng xìng', 'trans': 'practicality'}, {'word': '澄清', 'pinyin': 'chéng qīng', 'trans': 'clarify'}, {'word': '前向传递', 'pinyin': 'qián xiàng chuán dì', 'trans': 'forward propagation'}, {'word': '发展', 'pinyin': 'fā zhǎn', 'trans': 'develop'}, {'word': '提供', 'pinyin': 'tí gōng', 'trans': 'provide'}, {'word': '透明', 'pinyin': 'tòu míng', 'trans': 'transparent'}, {'word': '操作', 'pinyin': 'cāo zuò', 'trans': 'operate'}, {'word': '新方法', 'pinyin': 'xīn fāng fǎ', 'trans': 'new method'}]
[10.02.2025 05:13] Renaming previous Chinese page.
[10.02.2025 05:13] Renaming previous data. zh.html to ./d/2025-02-09_zh_reading_task.html
[10.02.2025 05:13] Writing Chinese reading task.
[10.02.2025 05:13] Writing result.
[10.02.2025 05:13] Renaming log file.
[10.02.2025 05:13] Renaming previous data. log.txt to ./logs/2025-02-10_last_log.txt
