[31.07.2025 07:18] Read previous papers.
[31.07.2025 07:18] Generating top page (month).
[31.07.2025 07:18] Writing top page (month).
[31.07.2025 08:17] Read previous papers.
[31.07.2025 08:17] Get feed.
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22827
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.21493
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22448
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22607
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.20976
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22886
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22853
[31.07.2025 08:17] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22565
[31.07.2025 08:17] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.07.2025 08:17] No deleted papers detected.
[31.07.2025 08:17] Downloading and parsing papers (pdf, html). Total: 8.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.22827.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.22827.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.22827.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.21493.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.21493.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.21493.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.22448.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.22448.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.22448.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.22607.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.22607.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.22607.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.20976.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.20976.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.20976.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.22886.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.22886.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.22886.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.22853.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.22853.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.22853.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2507.22565.
[31.07.2025 08:17] Extra JSON file exists (./assets/json/2507.22565.json), skip PDF parsing.
[31.07.2025 08:17] Paper image links file exists (./assets/img_data/2507.22565.json), skip HTML parsing.
[31.07.2025 08:17] Success.
[31.07.2025 08:17] Enriching papers with extra data.
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 0. A modular multi-agent framework improves UI-to-code generation by integrating vision-language models, hierarchical layout planning, and adaptive prompt-based synthesis, achieving state-of-the-art performance.  					AI-generated summary 				 Automating the transformation of user interface (UI) design...
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 1. BANG is a generative approach that uses latent diffusion models and temporal attention to enable intuitive part-level decomposition and manipulation of 3D objects, enhancing 3D creation workflows.  					AI-generated summary 				 3D creation has always been a unique human strength, driven by our abil...
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 2. Falcon-H1, a new series of large language models with a hybrid architecture combining Transformer-based attention and State Space Models, achieves state-of-the-art performance and efficiency across various tasks and sizes.  					AI-generated summary 				 In this report, we introduce Falcon-H1, a new...
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 3. VL-Cogito, a multimodal reasoning model, uses a Progressive Curriculum Reinforcement Learning framework to improve performance across diverse tasks by dynamically adjusting difficulty and reasoning path length.  					AI-generated summary 				 Reinforcement learning has proven its effectiveness in en...
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 4. A multi-stage, multi-modal knowledge transfer framework using fine-tuned latent diffusion models improves vehicle detection in aerial imagery across different domains.  					AI-generated summary 				 Detecting vehicles in aerial imagery is a critical task with applications in traffic monitoring, urb...
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 5. Omnimodal Referring Audio-Visual Segmentation (OmniAVS) and Omnimodal Instructed Segmentation Assistant (OISA) advance audio-visual segmentation by integrating complex multimodal expressions and leveraging MLLM for reasoning.  					AI-generated summary 				 Referring audio-visual segmentation (RAVS)...
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 6. Repair-R1 enhances automated program repair by integrating test cases into the training phase and prioritizing test generation before repair, improving repair success, test generation success, and test coverage.  					AI-generated summary 				 APR (Automated Program Repair) aims to automatically loc...
[31.07.2025 08:17] ********************************************************************************
[31.07.2025 08:17] Abstract 7. RLDP, a deep reinforcement learning framework, optimizes differentially private training by dynamically adjusting gradient clipping and noise, enhancing model utility and speed while maintaining privacy.  					AI-generated summary 				 The tension between data privacy and model utility has become th...
[31.07.2025 08:17] Read previous papers.
[31.07.2025 08:17] Generating reviews via LLM API.
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#synthetic", "#open_source", "#training", "#dataset", "#interpretability", "#multimodal", "#agents"], "emoji": "üñ•Ô∏è", "ru": {"title": "–£–º–Ω–æ–µ –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ –¥–∏–∑–∞–π–Ω–∞ –≤ –∫–æ–¥ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥—É–ª—å–Ω—É—é –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#diffusion", "#games", "#3d", "#reasoning", "#multimodal"], "emoji": "üß©", "ru": {"title": "BANG: –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å–∫–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "BANG - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –¥–ª—è –∏–Ω—Ç—É–∏—Ç–∏–≤
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#small_models", "#training", "#agi", "#architecture", "#science", "#long_context", "#dataset", "#open_source", "#multilingual"], "emoji": "ü¶Ö", "ru": {"title": "Falcon-H1: –ì–∏–±—Ä–∏–¥–Ω–∞—è –º–æ—â—å –≤ –º–∏—Ä–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "Falcon-H1 - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–µ—Ä–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≥–∏–±—Ä–∏–¥–Ω
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#multimodal", "#training", "#rlhf", "#reasoning", "#benchmark", "#rl"], "emoji": "üß†", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò", "desc": "VL-Cogito - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º.
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#synthetic", "#transfer_learning", "#dataset", "#cv", "#data", "#multimodal"], "emoji": "üöó", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ò–ò –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö —Å
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#games", "#cv", "#reasoning", "#dataset", "#multimodal"], "emoji": "üé≠", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–Ω–∏–º–∞–Ω–∏—è –∞—É–¥–∏–æ-–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "OmniAVS - —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ-–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –≤–∫–ª—é—á–∞—é—â–∏–π 2,098 –≤–∏–¥–µ–æ –∏ 5
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#training", "#dataset", "#optimization", "#rl"], "emoji": "üõ†Ô∏è", "ru": {"title": "Repair-R1: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "Repair-R1 - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø—Ä–æ–≥—Ä–∞–º–º (APR
[31.07.2025 08:17] Using data from previous issue: {"categories": ["#healthcare", "#training", "#security", "#rlhf", "#optimization", "#rl"], "emoji": "üõ°Ô∏è", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RLDP - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–∏–≤–∞—Ç–Ω
[31.07.2025 08:17] Renaming data file.
[31.07.2025 08:17] Renaming previous data. hf_papers.json to ./d/2025-07-31.json
[31.07.2025 08:17] Saving new data file.
[31.07.2025 08:17] Generating page.
[31.07.2025 08:17] Renaming previous page.
[31.07.2025 08:17] Renaming previous data. index.html to ./d/2025-07-31.html
[31.07.2025 08:17] Writing result.
[31.07.2025 08:17] Renaming log file.
[31.07.2025 08:17] Renaming previous data. log.txt to ./logs/2025-07-31_last_log.txt
