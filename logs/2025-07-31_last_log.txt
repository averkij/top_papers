[31.07.2025 21:12] Read previous papers.
[31.07.2025 21:12] Generating top page (month).
[31.07.2025 21:12] Writing top page (month).
[31.07.2025 22:12] Read previous papers.
[31.07.2025 22:12] Get feed.
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22827
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.21493
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22448
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22607
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.20976
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22886
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22565
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.19427
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22853
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22062
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.21802
[31.07.2025 22:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13985
[31.07.2025 22:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.07.2025 22:12] No deleted papers detected.
[31.07.2025 22:12] Downloading and parsing papers (pdf, html). Total: 12.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.22827.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.22827.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.22827.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.21493.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.21493.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.21493.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.22448.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.22448.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.22448.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.22607.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.22607.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.22607.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.20976.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.20976.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.20976.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.22886.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.22886.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.22886.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.22565.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.22565.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.22565.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.19427.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.19427.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.19427.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.22853.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.22853.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.22853.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.22062.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.22062.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.22062.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.21802.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.21802.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.21802.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Downloading and parsing paper https://huggingface.co/papers/2507.13985.
[31.07.2025 22:12] Extra JSON file exists (./assets/json/2507.13985.json), skip PDF parsing.
[31.07.2025 22:12] Paper image links file exists (./assets/img_data/2507.13985.json), skip HTML parsing.
[31.07.2025 22:12] Success.
[31.07.2025 22:12] Enriching papers with extra data.
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 0. A modular multi-agent framework improves UI-to-code generation by integrating vision-language models, hierarchical layout planning, and adaptive prompt-based synthesis, achieving state-of-the-art performance.  					AI-generated summary 				 Automating the transformation of user interface (UI) design...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 1. BANG is a generative approach that uses latent diffusion models and temporal attention to enable intuitive part-level decomposition and manipulation of 3D objects, enhancing 3D creation workflows.  					AI-generated summary 				 3D creation has always been a unique human strength, driven by our abil...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 2. Falcon-H1, a new series of large language models with a hybrid architecture combining Transformer-based attention and State Space Models, achieves state-of-the-art performance and efficiency across various tasks and sizes.  					AI-generated summary 				 In this report, we introduce Falcon-H1, a new...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 3. VL-Cogito, a multimodal reasoning model, uses a Progressive Curriculum Reinforcement Learning framework to improve performance across diverse tasks by dynamically adjusting difficulty and reasoning path length.  					AI-generated summary 				 Reinforcement learning has proven its effectiveness in en...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 4. A multi-stage, multi-modal knowledge transfer framework using fine-tuned latent diffusion models improves vehicle detection in aerial imagery across different domains.  					AI-generated summary 				 Detecting vehicles in aerial imagery is a critical task with applications in traffic monitoring, urb...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 5. Omnimodal Referring Audio-Visual Segmentation (OmniAVS) and Omnimodal Instructed Segmentation Assistant (OISA) advance audio-visual segmentation by integrating complex multimodal expressions and leveraging MLLM for reasoning.  					AI-generated summary 				 Referring audio-visual segmentation (RAVS)...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 6. RLDP, a deep reinforcement learning framework, optimizes differentially private training by dynamically adjusting gradient clipping and noise, enhancing model utility and speed while maintaining privacy.  					AI-generated summary 				 The tension between data privacy and model utility has become th...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 7. Step-3, a 321B-parameter VLM, reduces decoding costs through Multi-Matrix Factorization Attention and Attention-FFN Disaggregation, achieving high efficiency and throughput on long-context tasks.  					AI-generated summary 				 Large language models (LLMs) face low hardware efficiency during decodin...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 8. Repair-R1 enhances automated program repair by integrating test cases into the training phase and prioritizing test generation before repair, improving repair success, test generation success, and test coverage.  					AI-generated summary 				 APR (Automated Program Repair) aims to automatically loc...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 9. MetaCLIP 2, trained on worldwide web-scale image-text pairs, improves zero-shot classification and multilingual benchmarks without system-level confounding factors.  					AI-generated summary 				 Contrastive Language-Image Pretraining (CLIP) is a popular foundation model, supporting from zero-shot ...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 10. MixGRPO, a novel framework integrating SDE and ODE, enhances flow matching models for image generation by optimizing only within a sliding window, improving efficiency and performance.  					AI-generated summary 				 Although GRPO substantially enhances flow matching models in human preference align...
[31.07.2025 22:12] ********************************************************************************
[31.07.2025 22:12] Abstract 11. DreamScene is an end-to-end framework that generates high-quality, editable 3D scenes from text or dialogue, ensuring automation, 3D consistency, and fine-grained control through a combination of scene planning, graph-based placement, formation pattern sampling, and progressive camera sampling.  			...
[31.07.2025 22:12] Read previous papers.
[31.07.2025 22:12] Generating reviews via LLM API.
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#synthetic", "#open_source", "#training", "#dataset", "#interpretability", "#multimodal", "#agents"], "emoji": "üñ•Ô∏è", "ru": {"title": "–£–º–Ω–æ–µ –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ –¥–∏–∑–∞–π–Ω–∞ –≤ –∫–æ–¥ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥—É–ª—å–Ω—É—é –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#diffusion", "#games", "#3d", "#reasoning", "#multimodal"], "emoji": "üß©", "ru": {"title": "BANG: –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å–∫–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "BANG - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –¥–ª—è –∏–Ω—Ç—É–∏—Ç–∏–≤
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#small_models", "#training", "#agi", "#architecture", "#science", "#long_context", "#dataset", "#open_source", "#multilingual"], "emoji": "ü¶Ö", "ru": {"title": "Falcon-H1: –ì–∏–±—Ä–∏–¥–Ω–∞—è –º–æ—â—å –≤ –º–∏—Ä–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "Falcon-H1 - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–µ—Ä–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≥–∏–±—Ä–∏–¥–Ω
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#multimodal", "#training", "#rlhf", "#reasoning", "#benchmark", "#rl"], "emoji": "üß†", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò", "desc": "VL-Cogito - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º.
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#synthetic", "#transfer_learning", "#dataset", "#cv", "#data", "#multimodal"], "emoji": "üöó", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ò–ò –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö —Å
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#games", "#cv", "#reasoning", "#dataset", "#multimodal"], "emoji": "üé≠", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–Ω–∏–º–∞–Ω–∏—è –∞—É–¥–∏–æ-–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "OmniAVS - —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ-–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –≤–∫–ª—é—á–∞—é—â–∏–π 2,098 –≤–∏–¥–µ–æ –∏ 5
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#healthcare", "#training", "#security", "#rlhf", "#optimization", "#rl"], "emoji": "üõ°Ô∏è", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RLDP - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–∏–≤–∞—Ç–Ω
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#architecture", "#training", "#inference", "#optimization", "#long_context"], "emoji": "üöÄ", "ru": {"title": "Step-3: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Step-3, –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å —Å 321 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–ø—Ç–∏–º–∏
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#training", "#dataset", "#optimization", "#rl"], "emoji": "üõ†Ô∏è", "ru": {"title": "Repair-R1: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "Repair-R1 - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø—Ä–æ–≥—Ä–∞–º–º (APR
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#dataset", "#multilingual", "#low_resource", "#cv", "#machine_translation", "#multimodal"], "emoji": "üåê", "ru": {"title": "MetaCLIP 2: –ü—Ä–æ—Ä—ã–≤ –≤ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å MetaCLIP 2, –∫–æ—Ç–æ—Ä–∞—è –æ–±—É—á–µ–Ω–∞ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, –≤–∫–ª—é—á–∞—é—â–∏—Ö –∏–∑
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#alignment", "#optimization", "#training", "#open_source", "#rlhf"], "emoji": "üñºÔ∏è", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ SDE-ODE", "desc": "MixGRPO - —ç—Ç–æ –Ω–æ–≤–∞—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É—Ä–∞–≤–Ω–µ–Ω–∏—è (S
[31.07.2025 22:12] Using data from previous issue: {"categories": ["#3d", "#games", "#open_source"], "emoji": "üé®", "ru": {"title": "DreamScene: –û—Ç —Ç–µ–∫—Å—Ç–∞ –∫ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º 3D-–º–∏—Ä–∞–º", "desc": "DreamScene - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º—ã—Ö 3D-—Å—Ü–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –¥–∏–∞–ª–æ–≥–∞. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥—É–ª—å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ü–µ–Ω—ã —Å G
[31.07.2025 22:12] Renaming data file.
[31.07.2025 22:12] Renaming previous data. hf_papers.json to ./d/2025-07-31.json
[31.07.2025 22:12] Saving new data file.
[31.07.2025 22:12] Generating page.
[31.07.2025 22:12] Renaming previous page.
[31.07.2025 22:12] Renaming previous data. index.html to ./d/2025-07-31.html
[31.07.2025 22:12] Writing result.
[31.07.2025 22:12] Renaming log file.
[31.07.2025 22:12] Renaming previous data. log.txt to ./logs/2025-07-31_last_log.txt
