[16.06.2025 08:20] Read previous papers.
[16.06.2025 08:20] Generating top page (month).
[16.06.2025 08:20] Writing top page (month).
[16.06.2025 09:15] Read previous papers.
[16.06.2025 09:15] Get feed.
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11924
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09600
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10892
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11928
[16.06.2025 09:15] Extract page data from URL. URL: https://huggingface.co/papers/2506.11997
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09427
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09366
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08477
[16.06.2025 09:15] Extract page data from URL. URL: https://huggingface.co/papers/2506.07464
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11702
[16.06.2025 09:15] Extract page data from URL. URL: https://huggingface.co/papers/2506.11130
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08592
[16.06.2025 09:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[16.06.2025 09:15] No deleted papers detected.
[16.06.2025 09:15] Downloading and parsing papers (pdf, html). Total: 12.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11924.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11924.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11924.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.09600.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.09600.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.09600.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.10892.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.10892.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.10892.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11928.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11928.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11928.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11997.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11997.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11997.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.09427.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.09427.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.09427.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.09366.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.09366.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.09366.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.08477.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.08477.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.08477.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.07464.
[16.06.2025 09:15] Downloading paper 2506.07464 from http://arxiv.org/pdf/2506.07464v2...
[16.06.2025 09:15] Extracting affiliations from text.
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 1 ] . [ 2 4 6 4 7 0 . 6 0 5 2 : r DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO Jinyoung Park1 Jeehye Na1 Jinyoung Kim1 Hyunwoo J. Kim2 1Korea University, 2KAIST {lpmn678, sonicdog00, k012100}@korea.ac.kr hyunwoojkim@kaist.ac.kr https://github.com/mlvlab/DeepVideoR "
[16.06.2025 09:15] Response: ```python
["Korea University", "KAIST"]
```
[16.06.2025 09:15] Deleting PDF ./assets/pdf/2506.07464.pdf.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11702.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11702.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11702.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11130.
[16.06.2025 09:15] Downloading paper 2506.11130 from http://arxiv.org/pdf/2506.11130v1...
[16.06.2025 09:15] Extracting affiliations from text.
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data Cheng Kang Chou*1,2, Chan-Jan Hsu*1, Ho-Lam Chung2, Liang-Hsuan Tseng2, Hsi-Chun Cheng2, Yu-Kuan Fu3, Kuan Po Huang2, Hung-Yi Lee2 1MediaTek Research 2National Taiwan University 3Nvidia 5 2 0 J 0 1 ] . [ 1 0 3 1 1 1 . 6 0 5 2 : r AbstractWe propose self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train highfidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as compelling alternative to pseudo-labeling self-distillation approaches and provides practical pathway for improving ASR performance in lowresource or domain-specific settings. Index TermsAutomatic Speech Recognition, Whisper, Pseudo Labeling, Text-to-Speech, Code-Switching, Self-Refining I. INTRODUCTION Automatic speech recognition (ASR) has become cornerstone technology in modern humancomputer interaction, powering applications such as voice assistants, real-time transcription, and accessibility tools. As ASR systems continue to evolve, the demand for transcribed speech data has increased substantially. State-of-the-art generalist ASR models leverage large-scale speech datasets, generally involving at least 25,000 hours and scaling up to millions of hours [1][4]. Even with these advances, the growing spectrum of multilingual and domain-specific applications calls f"
[16.06.2025 09:15] Response: ```python
["MediaTek Research", "National Taiwan University", "Nvidia"]
```
[16.06.2025 09:15] Deleting PDF ./assets/pdf/2506.11130.pdf.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.08592.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.08592.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.08592.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Enriching papers with extra data.
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 0. A diffusion-based framework generates aligned novel views of images and geometry using warping-and-inpainting with cross-modal attention distillation and proximity-based mesh conditioning, achieving high-fidelity synthesis and 3D completion.  					AI-generated summary 				 We introduce a diffusion-b...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 1. CRAFT, a multi-agent system using policy-aware persuasive strategies, challenges policy-adherent LLM-based agents in customer service to assess and improve their robustness against adversarial attacks.  					AI-generated summary 				 Task-oriented LLM-based agents are increasingly used in domains wi...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 2. Duo improves uniform-state discrete diffusion models by transferring techniques from Gaussian diffusion, enhancing training speed and enabling fast few-step text generation.  					AI-generated summary 				 Uniform-state discrete diffusion models hold the promise of fast text generation due to their ...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 3. LLMs perform well on implementation-heavy competitive programming problems but struggle with nuanced algorithmic reasoning, as highlighted by LiveCodeBench Pro.  					AI-generated summary 				 Recent reports claim that large language models (LLMs) now outperform elite humans in competitive programmi...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 4. pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language model...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 5. InterSyn, a large-scale dataset with tightly interleaved image-text outputs and automated quality refinement, improves multimodal understanding and generation through the SEIR method and SynJudge, an automatic evaluation tool.  					AI-generated summary 				 Recent advancements in Large Multimodal M...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 6. SkillBlender is a hierarchical reinforcement learning framework that uses pretrained primitive skills to efficiently solve diverse loco-manipulation tasks for humanoid robots.  					AI-generated summary 				 Humanoid robots hold significant potential in accomplishing daily tasks across diverse envir...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 7. U-CoT+ is a novel framework for detecting harmful memes by converting them into textual descriptions and using human-crafted guidelines with zero-shot CoT prompting to achieve high flexibility and explainability with small-scale LLMs.  					AI-generated summary 				 Detecting harmful memes is essent...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 8. DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-train...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 9. Configurable Preference Tuning enables language models to dynamically adjust their behavior based on human-interprettable directives, using rubric-guided preference data for fine-tuning and inference-time modulation.  					AI-generated summary 				 Models of human feedback for AI alignment, such as ...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 10. A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The ...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 11. A new dataset named CapRetrieval is introduced to evaluate the ability of text encoders to recognize fine-grained entities and events, highlighting challenges in dense retrieval tasks.  					AI-generated summary 				 This work focuses on an observed limitation of text encoders: embeddings may not be...
[16.06.2025 09:15] Read previous papers.
[16.06.2025 09:15] Generating reviews via LLM API.
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#cv", "#3d", "#diffusion"], "emoji": "🖼️", "ru": {"title": "Диффузионная модель для согласованной генерации изображений и геометрии с новых ракурсов", "desc": "Эта статья представляет новую систему генерации изображений и геометрии с новых ракурсов, основанную на диффузионных моделя
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#security", "#benchmark", "#agents"], "emoji": "🛡️", "ru": {"title": "Укрепление защиты ЛЛМ-агентов от манипуляций пользователей", "desc": "Статья представляет CRAFT - многоагентную систему, использующую стратегии убеждения с учетом политик для тестирования устойчивости ЛЛМ-агентов 
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#training", "#dataset", "#benchmark", "#optimization", "#open_source", "#diffusion"], "emoji": "🔄", "ru": {"title": "Duo: Ускорение диффузионных языковых моделей с помощью гауссовских техник", "desc": "Метод Duo улучшает дискретные диффузионные модели с равномерным состоянием, перен
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#dataset", "#games"], "emoji": "🤖", "ru": {"title": "LLM в программировании: сила в реализации, слабость в алгоритмах", "desc": "Исследование показывает, что крупные языковые модели (LLM) хорошо справляются с задачами по программированию, требующими сложн
[16.06.2025 09:15] Querying the API.
[16.06.2025 09:15] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language modeling. However, their structure constrains their applicability to sequences only or requires processing multi-dimensional data structures, such as images or molecular graphs, in a pre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are well suited for data with a higher level structure, like 2D grids, trees, and directed acyclic graphs (DAGs). In this work, we extend the notion of multi-dimensionality to linear RNNs. We introduce parallelizable Linear Source Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that act on the line graph of a general DAG. This enables parallelization in analogy to parallel associative scans and the chunkwise-recurrent form of sequential linear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this scheme can be efficiently implemented using einsum operations, concatenations, and padding in logarithmic time. pLSTMs tackle the vanishing/exploding activation/gradient problem for long distances in DAGs via two distinct modes: a directed propagation mode (P-mode) and a diffusive distribution mode (D-mode). To showcase the long-range capabilities of pLSTM, we introduce arrow-pointing extrapolation as a synthetic computer vision task that contains long-distance directional information. We demonstrate that pLSTMs generalize well to larger image sizes, whereas Transformers struggle to extrapolate. On established molecular graph and computer vision benchmarks, pLSTMs also show strong performance. Code and Datasets are available at: https://github.com/ml-jku/plstm_experiments.
[16.06.2025 09:15] Response: {
  "desc": "В статье представлена новая архитектура нейронной сети pLSTM (parallelizable Linear Source Transition Mark), разработанная для обработки направленных ациклических графов (DAG). pLSTM способна эффективно обрабатывать многомерные структуры данных, такие как изображения или молекулярные графы, преодолевая ограничения современных рекуррентных архитектур. Модель демонстрирует превосходную производительность на задачах с длинными зависимостями и превосходит трансформеры на ряде бенчмарков. pLSTM решает проблему затухающих/взрывающихся градиентов для длинных последовательностей в DAG с помощью двух режимов: направленного распространения и диффузного распределения.",
  "emoji": "🧠",
  "title": "pLSTM: Параллельные линейные RNN для эффективной обработки многомерных данных"
}
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language modeling. However, their structure constrains their applicability to sequences only or requires processing multi-dimensional data structures, such as images or molecular graphs, in a pre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are well suited for data with a higher level structure, like 2D grids, trees, and directed acyclic graphs (DAGs). In this work, we extend the notion of multi-dimensionality to linear RNNs. We introduce parallelizable Linear Source Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that act on the line graph of a general DAG. This enables parallelization in analogy to parallel associative scans and the chunkwise-recurrent form of sequential linear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this scheme can be efficiently implemented using einsum operations, concatenations, and padding in logarithmic time. pLSTMs tackle the vanishing/exploding activation/gradient problem for long distances in DAGs via two distinct modes: a directed propagation mode (P-mode) and a diffusive distribution mode (D-mode). To showcase the long-range capabilities of pLSTM, we introduce arrow-pointing extrapolation as a synthetic computer vision task that contains long-distance directional information. We demonstrate that pLSTMs generalize well to larger image sizes, whereas Transformers struggle to extrapolate. On established molecular graph and computer vision benchmarks, pLSTMs also show strong performance. Code and Datasets are available at: https://github.com/ml-jku/plstm_experiments."

[16.06.2025 09:15] Response: ```python
['ARCHITECTURE', 'BENCHMARK', 'CV']
```
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language modeling. However, their structure constrains their applicability to sequences only or requires processing multi-dimensional data structures, such as images or molecular graphs, in a pre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are well suited for data with a higher level structure, like 2D grids, trees, and directed acyclic graphs (DAGs). In this work, we extend the notion of multi-dimensionality to linear RNNs. We introduce parallelizable Linear Source Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that act on the line graph of a general DAG. This enables parallelization in analogy to parallel associative scans and the chunkwise-recurrent form of sequential linear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this scheme can be efficiently implemented using einsum operations, concatenations, and padding in logarithmic time. pLSTMs tackle the vanishing/exploding activation/gradient problem for long distances in DAGs via two distinct modes: a directed propagation mode (P-mode) and a diffusive distribution mode (D-mode). To showcase the long-range capabilities of pLSTM, we introduce arrow-pointing extrapolation as a synthetic computer vision task that contains long-distance directional information. We demonstrate that pLSTMs generalize well to larger image sizes, whereas Transformers struggle to extrapolate. On established molecular graph and computer vision benchmarks, pLSTMs also show strong performance. Code and Datasets are available at: https://github.com/ml-jku/plstm_experiments."

[16.06.2025 09:15] Response: ```python
["LONG_CONTEXT", "GRAPHS", "OPTIMIZATION", "SYNTHETIC", "OPEN_SOURCE"]
```
[16.06.2025 09:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces parallelizable Linear Source Transition Mark networks (pLSTMs), a new type of linear recurrent neural network (RNN) designed for processing data structured as directed acyclic graphs (DAGs). Unlike traditional RNNs and Transformers, pLSTMs can efficiently handle multi-dimensional data without being limited to sequential processing. They address the vanishing and exploding gradient problems through two modes of operation, allowing for effective long-range dependencies in data. The authors demonstrate that pLSTMs outperform Transformers on various benchmarks, particularly in tasks requiring long-distance extrapolation, such as computer vision and molecular graph analysis.","title":"pLSTMs: Revolutionizing Long-Range Learning in DAGs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces parallelizable Linear Source Transition Mark networks (pLSTMs), a new type of linear recurrent neural network (RNN) designed for processing data structured as directed acyclic graphs (DAGs). Unlike traditional RNNs and Transformers, pLSTMs can efficiently handle multi-dimensional data without being limited to sequential processing. They address the vanishing and exploding gradient problems through two modes of operation, allowing for effective long-range dependencies in data. The authors demonstrate that pLSTMs outperform Transformers on various benchmarks, particularly in tasks requiring long-distance extrapolation, such as computer vision and molecular graph analysis.', title='pLSTMs: Revolutionizing Long-Range Learning in DAGs'))
[16.06.2025 09:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"pLSTMs是一种可并行化的线性递归神经网络，专为有向无环图（DAG）设计，能够在长距离任务和基准测试中表现优于变换器（Transformers）。与现代递归架构相比，pLSTMs通过源、转移和标记门的设计，解决了长距离传播中的消失和爆炸梯度问题。该方法适用于更高结构的数据，如二维网格和树形结构，能够有效处理图像等多维数据。通过引入箭头指向外推的合成计算机视觉任务，pLSTMs展示了其在长距离推断中的强大能力。","title":"pLSTMs：超越变换器的长距离学习新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='pLSTMs是一种可并行化的线性递归神经网络，专为有向无环图（DAG）设计，能够在长距离任务和基准测试中表现优于变换器（Transformers）。与现代递归架构相比，pLSTMs通过源、转移和标记门的设计，解决了长距离传播中的消失和爆炸梯度问题。该方法适用于更高结构的数据，如二维网格和树形结构，能够有效处理图像等多维数据。通过引入箭头指向外推的合成计算机视觉任务，pLSTMs展示了其在长距离推断中的强大能力。', title='pLSTMs：超越变换器的长距离学习新方法'))
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#optimization", "#multimodal", "#games"], "emoji": "🔄", "ru": {"title": "InterSyn: новый уровень мультимодального обучения", "desc": "Статья представляет InterSyn - крупномасштабный мультимодальный датасет для обучения языковых моделей. InterSyn создан с ис
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#benchmark", "#robotics", "#rl", "#open_source", "#games"], "emoji": "🤖", "ru": {"title": "SkillBlender: умное сочетание навыков для универсальных гуманоидных роботов", "desc": "SkillBlender - это новая иерархическая система обучения с подкреплением для универсального управления гум
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#dataset", "#low_resource", "#ethics", "#interpretability", "#small_models", "#multimodal", "#benchmark"], "emoji": "🕵️", "ru": {"title": "Умный детектив для вредных мемов", "desc": "U-CoT+ - это новый фреймворк для обнаружения вредоносных мемов, который преобразует их в текстовые о
[16.06.2025 09:15] Querying the API.
[16.06.2025 09:15] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks.
[16.06.2025 09:15] Response: {
  "desc": "DeepVideo-R1 - это модель для улучшения рассуждений на основе видео, использующая регрессионный подход GRPO (Reg-GRPO) и адаптивное увеличение данных. Модель решает проблемы применения GRPO к видео-ЯБМ, такие как зависимость от защитных механизмов и проблема исчезающего преимущества. Reg-GRPO переформулирует задачу GRPO как регрессионную, напрямую предсказывая преимущество. Стратегия увеличения данных с учетом сложности динамически добавляет обучающие примеры на решаемых уровнях сложности.",
  "emoji": "🎥",
  "title": "DeepVideo-R1: Улучшение рассуждений на видео с помощью регрессионного GRPO"
}
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks."

[16.06.2025 09:15] Response: ```python
["RL", "RLHF", "VIDEO", "BENCHMARK", "TRAINING"]
```
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks."

[16.06.2025 09:15] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[16.06.2025 09:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeepVideo-R1 is a novel approach that enhances video reasoning in large language models by utilizing a regression-based method called Reg-GRPO. This method reformulates the Group Relative Policy Optimization (GRPO) objective into a regression task, allowing for more direct policy guidance without the need for complex safeguards. Additionally, the paper introduces a difficulty-aware data augmentation strategy that adjusts training samples based on their solvable difficulty, which helps in generating diverse and informative reward signals. The results demonstrate that DeepVideo-R1 significantly boosts performance on various video reasoning benchmarks, showcasing its effectiveness in the field.","title":"Enhancing Video Reasoning with Reg-GRPO and Smart Data Augmentation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DeepVideo-R1 is a novel approach that enhances video reasoning in large language models by utilizing a regression-based method called Reg-GRPO. This method reformulates the Group Relative Policy Optimization (GRPO) objective into a regression task, allowing for more direct policy guidance without the need for complex safeguards. Additionally, the paper introduces a difficulty-aware data augmentation strategy that adjusts training samples based on their solvable difficulty, which helps in generating diverse and informative reward signals. The results demonstrate that DeepVideo-R1 significantly boosts performance on various video reasoning benchmarks, showcasing its effectiveness in the field.', title='Enhancing Video Reasoning with Reg-GRPO and Smart Data Augmentation'))
[16.06.2025 09:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeepVideo-R1 是一种增强视频推理性能的模型，采用了回归型的 GRPO 方法和难度感知的数据增强策略。该研究探讨了 GRPO 在视频大语言模型中的应用，并识别出影响有效学习的两个主要问题：依赖保护措施和优势消失问题。为了解决这些挑战，DeepVideo-R1 通过回归 GRPO 重新构建了 GRPO 目标，直接预测优势值，从而简化了政策指导。实验结果表明，DeepVideo-R1 在多个视频推理基准测试中显著提高了视频推理性能。","title":"DeepVideo-R1：提升视频推理的新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DeepVideo-R1 是一种增强视频推理性能的模型，采用了回归型的 GRPO 方法和难度感知的数据增强策略。该研究探讨了 GRPO 在视频大语言模型中的应用，并识别出影响有效学习的两个主要问题：依赖保护措施和优势消失问题。为了解决这些挑战，DeepVideo-R1 通过回归 GRPO 重新构建了 GRPO 目标，直接预测优势值，从而简化了政策指导。实验结果表明，DeepVideo-R1 在多个视频推理基准测试中显著提高了视频推理性能。', title='DeepVideo-R1：提升视频推理的新方法'))
[16.06.2025 09:16] Using data from previous issue: {"categories": ["#rlhf", "#synthetic", "#training", "#dataset", "#alignment", "#open_source"], "emoji": "🎛️", "ru": {"title": "Гибкая настройка языковых моделей под меняющиеся предпочтения пользователей", "desc": "Эта статья представляет новый подход под названием Configurable Preference Tuning (CPT
[16.06.2025 09:16] Querying the API.
[16.06.2025 09:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings.
[16.06.2025 09:16] Response: {
  "desc": "Предложена самосовершенствующаяся система для улучшения распознавания речи с использованием только немаркированных данных. Процесс начинается с генерации псевдо-меток существующей моделью АСР, которые затем используются для обучения высококачественной системы синтеза речи. Затем синтезированные пары речь-текст используются для дообучения исходной модели АСР, замыкая цикл самосовершенствования. Эффективность подхода продемонстрирована на тайваньском мандаринском диалекте, где модель Twister, адаптированная из Whisper-large-v2, показала значительное снижение ошибок по сравнению с базовой моделью.",
  "emoji": "🔁",
  "title": "Самосовершенствующаяся система АСР: от псевдо-меток к улучшенному распознаванию"
}
[16.06.2025 09:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings."

[16.06.2025 09:16] Response: ```python
["DATASET", "DATA", "BENCHMARK", "AUDIO"]
```
[16.06.2025 09:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings."

[16.06.2025 09:16] Response: ```python
['TRANSFER_LEARNING', 'SYNTHETIC', 'LOW_RESOURCE']
```
[16.06.2025 09:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a self-refining framework designed to improve Automatic Speech Recognition (ASR) performance using only unlabeled datasets. The framework begins with an existing ASR model that generates pseudo-labels from unannotated speech data, which are then utilized to train a high-fidelity Text-to-Speech (TTS) system. Synthesized speech and text pairs are incorporated back into the original ASR model, creating a closed-loop system that enhances its accuracy. The proposed method, tested on Taiwanese Mandarin, shows significant error rate reductions, demonstrating its effectiveness in low-resource environments.","title":"Enhancing ASR with Unlabeled Data: The Twister Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a self-refining framework designed to improve Automatic Speech Recognition (ASR) performance using only unlabeled datasets. The framework begins with an existing ASR model that generates pseudo-labels from unannotated speech data, which are then utilized to train a high-fidelity Text-to-Speech (TTS) system. Synthesized speech and text pairs are incorporated back into the original ASR model, creating a closed-loop system that enhances its accuracy. The proposed method, tested on Taiwanese Mandarin, shows significant error rate reductions, demonstrating its effectiveness in low-resource environments.', title='Enhancing ASR with Unlabeled Data: The Twister Framework'))
[16.06.2025 09:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种自我优化框架，通过使用未标注的数据集来提升自动语音识别（ASR）的性能。该框架首先利用现有的ASR模型为未标注的语音生成伪标签，然后训练一个高保真的文本到语音（TTS）系统。接着，将合成的语音文本对引入原始的ASR系统，形成一个闭环的自我改进循环。实验结果表明，该框架在台湾普通话语音上有效，能够显著降低错误率，尤其在低资源或特定领域的应用中具有实际意义。","title":"自我优化框架提升ASR性能的创新之路"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种自我优化框架，通过使用未标注的数据集来提升自动语音识别（ASR）的性能。该框架首先利用现有的ASR模型为未标注的语音生成伪标签，然后训练一个高保真的文本到语音（TTS）系统。接着，将合成的语音文本对引入原始的ASR系统，形成一个闭环的自我改进循环。实验结果表明，该框架在台湾普通话语音上有效，能够显著降低错误率，尤其在低资源或特定领域的应用中具有实际意义。', title='自我优化框架提升ASR性能的创新之路'))
[16.06.2025 09:16] Using data from previous issue: {"categories": ["#data", "#transfer_learning", "#training", "#open_source", "#dataset"], "emoji": "🔍", "ru": {"title": "Точность в деталях: новый взгляд на возможности текстовых энкодеров", "desc": "Представлен новый датасет CapRetrieval для оценки способности текстовых энкодеров распознавать мелкие
[16.06.2025 09:16] Renaming data file.
[16.06.2025 09:16] Renaming previous data. hf_papers.json to ./d/2025-06-16.json
[16.06.2025 09:16] Saving new data file.
[16.06.2025 09:16] Generating page.
[16.06.2025 09:16] Renaming previous page.
[16.06.2025 09:16] Renaming previous data. index.html to ./d/2025-06-16.html
[16.06.2025 09:16] Writing result.
[16.06.2025 09:16] Renaming log file.
[16.06.2025 09:16] Renaming previous data. log.txt to ./logs/2025-06-16_last_log.txt
