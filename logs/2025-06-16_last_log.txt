[16.06.2025 17:11] Read previous papers.
[16.06.2025 17:11] Generating top page (month).
[16.06.2025 17:11] Writing top page (month).
[16.06.2025 18:16] Read previous papers.
[16.06.2025 18:16] Get feed.
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11924
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09600
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10892
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11928
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10128
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08989
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11930
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11886
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11997
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09427
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09366
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11474
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08592
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08477
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.07464
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11702
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11130
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08915
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11116
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11274
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10387
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10082
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11136
[16.06.2025 18:17] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03857
[16.06.2025 18:17] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[16.06.2025 18:17] No deleted papers detected.
[16.06.2025 18:17] Downloading and parsing papers (pdf, html). Total: 24.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11924.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11924.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11924.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.09600.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.09600.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.09600.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.10892.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.10892.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.10892.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11928.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11928.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11928.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.10128.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.10128.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.10128.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.08989.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.08989.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.08989.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11930.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11930.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11930.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11886.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11886.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11886.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11997.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11997.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11997.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.09427.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.09427.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.09427.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.09366.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.09366.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.09366.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11474.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11474.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11474.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.08592.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.08592.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.08592.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.08477.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.08477.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.08477.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.07464.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.07464.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.07464.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11702.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11702.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11702.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11130.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11130.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11130.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.08915.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.08915.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.08915.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11116.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11116.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11116.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11274.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11274.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11274.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.10387.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.10387.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.10387.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.10082.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.10082.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.10082.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.11136.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.11136.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.11136.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Downloading and parsing paper https://huggingface.co/papers/2506.03857.
[16.06.2025 18:17] Extra JSON file exists (./assets/json/2506.03857.json), skip PDF parsing.
[16.06.2025 18:17] Paper image links file exists (./assets/img_data/2506.03857.json), skip HTML parsing.
[16.06.2025 18:17] Success.
[16.06.2025 18:17] Enriching papers with extra data.
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 0. A diffusion-based framework generates aligned novel views of images and geometry using warping-and-inpainting with cross-modal attention distillation and proximity-based mesh conditioning, achieving high-fidelity synthesis and 3D completion.  					AI-generated summary 				 We introduce a diffusion-b...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 1. CRAFT, a multi-agent system using policy-aware persuasive strategies, challenges policy-adherent LLM-based agents in customer service to assess and improve their robustness against adversarial attacks.  					AI-generated summary 				 Task-oriented LLM-based agents are increasingly used in domains wi...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 2. Duo improves uniform-state discrete diffusion models by transferring techniques from Gaussian diffusion, enhancing training speed and enabling fast few-step text generation.  					AI-generated summary 				 Uniform-state discrete diffusion models hold the promise of fast text generation due to their ...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 3. LLMs perform well on implementation-heavy competitive programming problems but struggle with nuanced algorithmic reasoning, as highlighted by LiveCodeBench Pro.  					AI-generated summary 				 Recent reports claim that large language models (LLMs) now outperform elite humans in competitive programmi...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 4. ViCrit, an RL task for fine-tuning VLMs, improves visual perception by training models to detect subtle hallucinations in image captions, with gains transferable to various visual domains.  					AI-generated summary 				 Reinforcement learning (RL) has shown great effectiveness for fine-tuning large...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 5. A self-aware problem synthesis framework that leverages model weaknesses enhances reinforcement learning with verifiable rewards, improving large language model performance on reasoning tasks.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective ...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 6. LLMs show resistance to feedback, termed feedback friction, even under ideal conditions, and sampling-based strategies only partially mitigate this issue.  					AI-generated summary 				 Recent studies have shown LLMs possess some ability to improve their responses when given external feedback. Howe...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 7. FourierAttention is a training-free framework that enhances memory efficiency in Large Language Models by compressing long-context-insensitive transformer head dimensions using orthogonal Fourier bases, while maintaining accuracy.  					AI-generated summary 				 Large Language Models struggle with m...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 8. pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language model...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 9. InterSyn, a large-scale dataset with tightly interleaved image-text outputs and automated quality refinement, improves multimodal understanding and generation through the SEIR method and SynJudge, an automatic evaluation tool.  					AI-generated summary 				 Recent advancements in Large Multimodal M...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 10. SkillBlender is a hierarchical reinforcement learning framework that uses pretrained primitive skills to efficiently solve diverse loco-manipulation tasks for humanoid robots.  					AI-generated summary 				 Humanoid robots hold significant potential in accomplishing daily tasks across diverse envir...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 11. Med-PRM enhances clinical decision making by verifying reasoning steps against medical knowledge bases, achieving state-of-the-art performance in medical QA benchmarks with improved accuracy.  					AI-generated summary 				 Large language models have shown promise in clinical decision making, but cu...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 12. A new dataset named CapRetrieval is introduced to evaluate the ability of text encoders to recognize fine-grained entities and events, highlighting challenges in dense retrieval tasks.  					AI-generated summary 				 This work focuses on an observed limitation of text encoders: embeddings may not be...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 13. U-CoT+ is a novel framework for detecting harmful memes by converting them into textual descriptions and using human-crafted guidelines with zero-shot CoT prompting to achieve high flexibility and explainability with small-scale LLMs.  					AI-generated summary 				 Detecting harmful memes is essent...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 14. DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-train...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 15. Configurable Preference Tuning enables language models to dynamically adjust their behavior based on human-interprettable directives, using rubric-guided preference data for fine-tuning and inference-time modulation.  					AI-generated summary 				 Models of human feedback for AI alignment, such as ...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 16. A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The ...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 17. An attention-based method using learned binary masks improves robustness in object perception by focusing on relevant image regions while filtering out spurious information.  					AI-generated summary 				 We introduce an attention-based method that uses learned binary attention masks to ensure that...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 18. Infinity-Instruct, a comprehensive instruction dataset, enhances both foundational and chat capabilities of large language models through curation and synthesis, achieving superior performance compared to existing datasets.  					AI-generated summary 				 Large Language Models (LLMs) demonstrate str...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 19. A continuous thinking token learned via reinforcement learning improves language model accuracy more effectively than a fixed token during inference.  					AI-generated summary 				 Test-time scaling has emerged as an effective approach for improving language model performance by utilizing additiona...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 20. Hierarchical Multimodal Skills and Skill-Augmented Monte Carlo Tree Search improve multimodal GUI agent performance in long-horizon tasks by abstracting knowledge and bridging the offline-online domain gap.  					AI-generated summary 				 Recent efforts to leverage the Multi-modal Large Language Mod...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 21. A mask-based LoRA tuning method for video editing adapts pretrained Image-to-Video models for flexible and high-quality video editing, using spatial masks and reference images for context-specific adaptation.  					AI-generated summary 				 Video editing using diffusion models has achieved remarkabl...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 22. JAFAR is a lightweight feature upsampler using an attention-based module with Spatial Feature Transform modulation, enabling high-resolution features from Foundation Vision Encoders without high-resolution supervision.  					AI-generated summary 				 Foundation Vision Encoders have become essential ...
[16.06.2025 18:17] ********************************************************************************
[16.06.2025 18:17] Abstract 23. A novel candidate annotation paradigm using a teacher-student framework improves data quality for‰∏ãÊ∏∏ applications by encouraging large language models to output multiple labels when uncertain.  					AI-generated summary 				 Recently, Large Language Models (LLMs) have demonstrated significant potenti...
[16.06.2025 18:17] Read previous papers.
[16.06.2025 18:17] Generating reviews via LLM API.
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#cv", "#3d", "#diffusion"], "emoji": "üñºÔ∏è", "ru": {"title": "–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ —Å –Ω–æ–≤—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ —Å –Ω–æ–≤—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#security", "#benchmark", "#agents"], "emoji": "üõ°Ô∏è", "ru": {"title": "–£–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –∑–∞—â–∏—Ç—ã –õ–õ–ú-–∞–≥–µ–Ω—Ç–æ–≤ –æ—Ç –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç CRAFT - –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É, –∏—Å–ø–æ–ª—å–∑—É—é—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —É–±–µ–∂–¥–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –ø–æ–ª–∏—Ç–∏–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –õ–õ–ú-–∞–≥–µ–Ω—Ç–æ–≤ 
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#training", "#dataset", "#benchmark", "#optimization", "#open_source", "#diffusion"], "emoji": "üîÑ", "ru": {"title": "Duo: –£—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –≥–∞—É—Å—Å–æ–≤—Å–∫–∏—Ö —Ç–µ—Ö–Ω–∏–∫", "desc": "–ú–µ—Ç–æ–¥ Duo —É–ª—É—á—à–∞–µ—Ç –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º, –ø–µ—Ä–µ–Ω
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#dataset", "#games"], "emoji": "ü§ñ", "ru": {"title": "LLM –≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏: —Å–∏–ª–∞ –≤ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, —Å–ª–∞–±–æ—Å—Ç—å –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –∫—Ä—É–ø–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –∑–∞–¥–∞—á–∞–º–∏ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é, —Ç—Ä–µ–±—É—é—â–∏–º–∏ —Å–ª–æ–∂–Ω
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#hallucinations", "#cv", "#transfer_learning"], "emoji": "üîç", "ru": {"title": "ViCrit: –æ–±—É—á–µ–Ω–∏–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º—É –≤–æ—Å–ø—Ä–∏—è—Ç–∏—é –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç ViCrit - –∑–∞–¥–∞—á—É –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "–°–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ò–ò —á–µ—Ä–µ–∑ –æ—Å–æ–∑–Ω–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–ª–∞–±–æ—Å—Ç–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –Ω–∞–∑—ã–≤–∞–µ–º—ã–π Self-aware Weakness-driven
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#training", "#hallucinations", "#alignment", "#reasoning", "#rlhf"], "emoji": "üß†", "ru": {"title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ –±–∞—Ä—å–µ—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è: –±–æ—Ä—å–±–∞ —Å '—Ç—Ä–µ–Ω–∏–µ–º –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏' –≤ LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –æ–±–ª–∞–¥–∞—é—Ç —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ–º –∫ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏, 
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#inference", "#long_context", "#training"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –ø–∞–º—è—Ç–∏ LLM –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "FourierAttention - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#benchmark", "#long_context", "#optimization", "#graphs", "#architecture", "#cv", "#open_source", "#synthetic"], "emoji": "üß†", "ru": {"title": "pLSTM: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ª–∏–Ω–µ–π–Ω—ã–µ RNN –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π 
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#optimization", "#multimodal", "#games"], "emoji": "üîÑ", "ru": {"title": "InterSyn: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç InterSyn - –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. InterSyn —Å–æ–∑–¥–∞–Ω —Å –∏—Å
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#benchmark", "#robotics", "#rl", "#open_source", "#games"], "emoji": "ü§ñ", "ru": {"title": "SkillBlender: —É–º–Ω–æ–µ —Å–æ—á–µ—Ç–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –≥—É–º–∞–Ω–æ–∏–¥–Ω—ã—Ö —Ä–æ–±–æ—Ç–æ–≤", "desc": "SkillBlender - —ç—Ç–æ –Ω–æ–≤–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥—É–º
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#healthcare", "#dataset", "#training", "#rag", "#reasoning", "#benchmark", "#science", "#small_models"], "emoji": "ü©∫", "ru": {"title": "–¢–æ—á–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º: Med-PRM –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —à–∞–≥", "desc": "Med-PRM - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#data", "#transfer_learning", "#training", "#open_source", "#dataset"], "emoji": "üîç", "ru": {"title": "–¢–æ—á–Ω–æ—Å—Ç—å –≤ –¥–µ—Ç–∞–ª—è—Ö: –Ω–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–Ω–∫–æ–¥–µ—Ä–æ–≤", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç CapRetrieval –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –º–µ–ª–∫–∏–µ
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#dataset", "#low_resource", "#ethics", "#interpretability", "#small_models", "#multimodal", "#benchmark"], "emoji": "üïµÔ∏è", "ru": {"title": "–£–º–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–∏–≤ –¥–ª—è –≤—Ä–µ–¥–Ω—ã—Ö –º–µ–º–æ–≤", "desc": "U-CoT+ - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã—Ö –º–µ–º–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Ö –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#rlhf", "#video", "#benchmark", "#optimization", "#reasoning", "#training", "#rl"], "emoji": "üé•", "ru": {"title": "DeepVideo-R1: –£–ª—É—á—à–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –Ω–∞ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–≥–æ GRPO", "desc": "DeepVideo-R1 - —ç—Ç–æ –º–æ–¥–µ–ª—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è 
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#rlhf", "#synthetic", "#training", "#dataset", "#alignment", "#open_source"], "emoji": "üéõÔ∏è", "ru": {"title": "–ì–∏–±–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –º–µ–Ω—è—é—â–∏–µ—Å—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Configurable Preference Tuning (CPT
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#data", "#benchmark", "#dataset", "#transfer_learning", "#low_resource", "#audio", "#synthetic"], "emoji": "üîÅ", "ru": {"title": "–°–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤—É—é—â–∞—è—Å—è —Å–∏—Å—Ç–µ–º–∞ –ê–°–†: –æ—Ç –ø—Å–µ–≤–¥–æ-–º–µ—Ç–æ–∫ –∫ —É–ª—É—á—à–µ–Ω–Ω–æ–º—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤—É—é—â–∞—è—Å—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#optimization", "#architecture", "#interpretability"], "emoji": "üëÅÔ∏è", "ru": {"title": "–§–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–º: —É–ª—É—á—à–µ–Ω–∏–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –º–∞—Å–æ–∫ –≤–Ω–∏–º–∞–Ω–∏—è", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–Ω–∏–º–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –æ–±—É—á–µ–Ω–Ω—ã–µ –±–∏–Ω–∞—Ä–Ω—ã–µ 
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#open_source", "#data", "#transfer_learning", "#benchmark", "#dataset"], "emoji": "üöÄ", "ru": {"title": "Infinity-Instruct: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "Infinity-Instruct - —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –∫–∞–∫ –±–∞
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#inference", "#training", "#math", "#rl"], "emoji": "üß†", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –º—ã—Å–ª–∏ –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –ø—Ä–æ–¥–æ
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#transfer_learning", "#agents", "#benchmark", "#long_context", "#games", "#multimodal"], "emoji": "ü§ñ", "ru": {"title": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –∏ –ú–ö–¢–ü: –ø—Ä–æ—Ä—ã–≤ –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –ì–ü–ò-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#multimodal", "#games", "#diffusion", "#video", "#optimization", "#training"], "emoji": "üé¨", "ru": {"title": "–ì–∏–±–∫–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –º–∞—Å–æ–∫ –∏ LoRA", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LoRA –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Å–æ–∫ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ, –∞–¥–∞–ø—Ç–∏—Ä—É—é—â–∏–π –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ Imag
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#cv"], "emoji": "üîç", "ru": {"title": "JAFAR: –£–º–Ω–æ–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –±–µ–∑ –≤—ã—Å–æ–∫–æ—Ä–∞–∑—Ä–µ—à–∞—é—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "JAFAR - —ç—Ç–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –∏ –º–æ–¥—É–ª—è—Ü–∏—é Spatial Feature Transfor
[16.06.2025 18:17] Using data from previous issue: {"categories": ["#data", "#dataset", "#training", "#optimization", "#alignment"], "emoji": "üè∑Ô∏è", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å –ø–æ–º–æ—â—å—é –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –æ—Ç —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (L
[16.06.2025 18:17] Renaming data file.
[16.06.2025 18:17] Renaming previous data. hf_papers.json to ./d/2025-06-16.json
[16.06.2025 18:17] Saving new data file.
[16.06.2025 18:17] Generating page.
[16.06.2025 18:17] Renaming previous page.
[16.06.2025 18:17] Renaming previous data. index.html to ./d/2025-06-16.html
[16.06.2025 18:17] Writing result.
[16.06.2025 18:17] Renaming log file.
[16.06.2025 18:17] Renaming previous data. log.txt to ./logs/2025-06-16_last_log.txt
