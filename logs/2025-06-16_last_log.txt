[16.06.2025 08:20] Read previous papers.
[16.06.2025 08:20] Generating top page (month).
[16.06.2025 08:20] Writing top page (month).
[16.06.2025 09:15] Read previous papers.
[16.06.2025 09:15] Get feed.
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11924
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09600
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10892
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11928
[16.06.2025 09:15] Extract page data from URL. URL: https://huggingface.co/papers/2506.11997
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09427
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09366
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08477
[16.06.2025 09:15] Extract page data from URL. URL: https://huggingface.co/papers/2506.07464
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11702
[16.06.2025 09:15] Extract page data from URL. URL: https://huggingface.co/papers/2506.11130
[16.06.2025 09:15] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08592
[16.06.2025 09:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[16.06.2025 09:15] No deleted papers detected.
[16.06.2025 09:15] Downloading and parsing papers (pdf, html). Total: 12.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11924.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11924.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11924.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.09600.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.09600.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.09600.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.10892.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.10892.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.10892.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11928.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11928.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11928.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11997.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11997.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11997.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.09427.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.09427.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.09427.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.09366.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.09366.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.09366.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.08477.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.08477.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.08477.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.07464.
[16.06.2025 09:15] Downloading paper 2506.07464 from http://arxiv.org/pdf/2506.07464v2...
[16.06.2025 09:15] Extracting affiliations from text.
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 1 ] . [ 2 4 6 4 7 0 . 6 0 5 2 : r DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO Jinyoung Park1 Jeehye Na1 Jinyoung Kim1 Hyunwoo J. Kim2 1Korea University, 2KAIST {lpmn678, sonicdog00, k012100}@korea.ac.kr hyunwoojkim@kaist.ac.kr https://github.com/mlvlab/DeepVideoR "
[16.06.2025 09:15] Response: ```python
["Korea University", "KAIST"]
```
[16.06.2025 09:15] Deleting PDF ./assets/pdf/2506.07464.pdf.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11702.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.11702.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.11702.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.11130.
[16.06.2025 09:15] Downloading paper 2506.11130 from http://arxiv.org/pdf/2506.11130v1...
[16.06.2025 09:15] Extracting affiliations from text.
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data Cheng Kang Chou*1,2, Chan-Jan Hsu*1, Ho-Lam Chung2, Liang-Hsuan Tseng2, Hsi-Chun Cheng2, Yu-Kuan Fu3, Kuan Po Huang2, Hung-Yi Lee2 1MediaTek Research 2National Taiwan University 3Nvidia 5 2 0 J 0 1 ] . [ 1 0 3 1 1 1 . 6 0 5 2 : r AbstractWe propose self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train highfidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as compelling alternative to pseudo-labeling self-distillation approaches and provides practical pathway for improving ASR performance in lowresource or domain-specific settings. Index TermsAutomatic Speech Recognition, Whisper, Pseudo Labeling, Text-to-Speech, Code-Switching, Self-Refining I. INTRODUCTION Automatic speech recognition (ASR) has become cornerstone technology in modern humancomputer interaction, powering applications such as voice assistants, real-time transcription, and accessibility tools. As ASR systems continue to evolve, the demand for transcribed speech data has increased substantially. State-of-the-art generalist ASR models leverage large-scale speech datasets, generally involving at least 25,000 hours and scaling up to millions of hours [1][4]. Even with these advances, the growing spectrum of multilingual and domain-specific applications calls f"
[16.06.2025 09:15] Response: ```python
["MediaTek Research", "National Taiwan University", "Nvidia"]
```
[16.06.2025 09:15] Deleting PDF ./assets/pdf/2506.11130.pdf.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Downloading and parsing paper https://huggingface.co/papers/2506.08592.
[16.06.2025 09:15] Extra JSON file exists (./assets/json/2506.08592.json), skip PDF parsing.
[16.06.2025 09:15] Paper image links file exists (./assets/img_data/2506.08592.json), skip HTML parsing.
[16.06.2025 09:15] Success.
[16.06.2025 09:15] Enriching papers with extra data.
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 0. A diffusion-based framework generates aligned novel views of images and geometry using warping-and-inpainting with cross-modal attention distillation and proximity-based mesh conditioning, achieving high-fidelity synthesis and 3D completion.  					AI-generated summary 				 We introduce a diffusion-b...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 1. CRAFT, a multi-agent system using policy-aware persuasive strategies, challenges policy-adherent LLM-based agents in customer service to assess and improve their robustness against adversarial attacks.  					AI-generated summary 				 Task-oriented LLM-based agents are increasingly used in domains wi...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 2. Duo improves uniform-state discrete diffusion models by transferring techniques from Gaussian diffusion, enhancing training speed and enabling fast few-step text generation.  					AI-generated summary 				 Uniform-state discrete diffusion models hold the promise of fast text generation due to their ...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 3. LLMs perform well on implementation-heavy competitive programming problems but struggle with nuanced algorithmic reasoning, as highlighted by LiveCodeBench Pro.  					AI-generated summary 				 Recent reports claim that large language models (LLMs) now outperform elite humans in competitive programmi...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 4. pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language model...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 5. InterSyn, a large-scale dataset with tightly interleaved image-text outputs and automated quality refinement, improves multimodal understanding and generation through the SEIR method and SynJudge, an automatic evaluation tool.  					AI-generated summary 				 Recent advancements in Large Multimodal M...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 6. SkillBlender is a hierarchical reinforcement learning framework that uses pretrained primitive skills to efficiently solve diverse loco-manipulation tasks for humanoid robots.  					AI-generated summary 				 Humanoid robots hold significant potential in accomplishing daily tasks across diverse envir...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 7. U-CoT+ is a novel framework for detecting harmful memes by converting them into textual descriptions and using human-crafted guidelines with zero-shot CoT prompting to achieve high flexibility and explainability with small-scale LLMs.  					AI-generated summary 				 Detecting harmful memes is essent...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 8. DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-train...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 9. Configurable Preference Tuning enables language models to dynamically adjust their behavior based on human-interprettable directives, using rubric-guided preference data for fine-tuning and inference-time modulation.  					AI-generated summary 				 Models of human feedback for AI alignment, such as ...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 10. A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The ...
[16.06.2025 09:15] ********************************************************************************
[16.06.2025 09:15] Abstract 11. A new dataset named CapRetrieval is introduced to evaluate the ability of text encoders to recognize fine-grained entities and events, highlighting challenges in dense retrieval tasks.  					AI-generated summary 				 This work focuses on an observed limitation of text encoders: embeddings may not be...
[16.06.2025 09:15] Read previous papers.
[16.06.2025 09:15] Generating reviews via LLM API.
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#cv", "#3d", "#diffusion"], "emoji": "ğŸ–¼ï¸", "ru": {"title": "Ğ”Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ€Ğ°ĞºÑƒÑ€ÑĞ¾Ğ²", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ€Ğ°ĞºÑƒÑ€ÑĞ¾Ğ², Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ½Ğ° Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»Ñ
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#security", "#benchmark", "#agents"], "emoji": "ğŸ›¡ï¸", "ru": {"title": "Ğ£ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ Ğ›Ğ›Ğœ-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¾Ñ‚ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ CRAFT - Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ°Ğ³ĞµĞ½Ñ‚Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ÑƒĞ±ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ›Ğ›Ğœ-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² 
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#training", "#dataset", "#benchmark", "#optimization", "#open_source", "#diffusion"], "emoji": "ğŸ”„", "ru": {"title": "Duo: Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ³Ğ°ÑƒÑÑĞ¾Ğ²ÑĞºĞ¸Ñ… Ñ‚ĞµÑ…Ğ½Ğ¸Ğº", "desc": "ĞœĞµÑ‚Ğ¾Ğ´ Duo ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ñ‹Ğ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸ĞµĞ¼, Ğ¿ĞµÑ€ĞµĞ½
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#dataset", "#games"], "emoji": "ğŸ¤–", "ru": {"title": "LLM Ğ² Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸: ÑĞ¸Ğ»Ğ° Ğ² Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, ÑĞ»Ğ°Ğ±Ğ¾ÑÑ‚ÑŒ Ğ² Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°Ñ…", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LLM) Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½
[16.06.2025 09:15] Querying the API.
[16.06.2025 09:15] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language modeling. However, their structure constrains their applicability to sequences only or requires processing multi-dimensional data structures, such as images or molecular graphs, in a pre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are well suited for data with a higher level structure, like 2D grids, trees, and directed acyclic graphs (DAGs). In this work, we extend the notion of multi-dimensionality to linear RNNs. We introduce parallelizable Linear Source Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that act on the line graph of a general DAG. This enables parallelization in analogy to parallel associative scans and the chunkwise-recurrent form of sequential linear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this scheme can be efficiently implemented using einsum operations, concatenations, and padding in logarithmic time. pLSTMs tackle the vanishing/exploding activation/gradient problem for long distances in DAGs via two distinct modes: a directed propagation mode (P-mode) and a diffusive distribution mode (D-mode). To showcase the long-range capabilities of pLSTM, we introduce arrow-pointing extrapolation as a synthetic computer vision task that contains long-distance directional information. We demonstrate that pLSTMs generalize well to larger image sizes, whereas Transformers struggle to extrapolate. On established molecular graph and computer vision benchmarks, pLSTMs also show strong performance. Code and Datasets are available at: https://github.com/ml-jku/plstm_experiments.
[16.06.2025 09:15] Response: {
  "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ¹ ÑĞµÑ‚Ğ¸ pLSTM (parallelizable Linear Source Transition Mark), Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ°Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ñ†Ğ¸ĞºĞ»Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ² (DAG). pLSTM ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ° ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¼ĞµÑ€Ğ½Ñ‹Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¼Ğ¾Ğ»ĞµĞºÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ Ğ³Ñ€Ğ°Ñ„Ñ‹, Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ²Ğ°Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ€ĞµĞºÑƒÑ€Ñ€ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑĞ¼Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ñ‹ Ğ½Ğ° Ñ€ÑĞ´Ğµ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ². pLSTM Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ·Ğ°Ñ‚ÑƒÑ…Ğ°ÑÑ‰Ğ¸Ñ…/Ğ²Ğ·Ñ€Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ñ…ÑÑ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ² DAG Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ²ÑƒÑ… Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ²: Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ.",
  "emoji": "ğŸ§ ",
  "title": "pLSTM: ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ RNN Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
}
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language modeling. However, their structure constrains their applicability to sequences only or requires processing multi-dimensional data structures, such as images or molecular graphs, in a pre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are well suited for data with a higher level structure, like 2D grids, trees, and directed acyclic graphs (DAGs). In this work, we extend the notion of multi-dimensionality to linear RNNs. We introduce parallelizable Linear Source Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that act on the line graph of a general DAG. This enables parallelization in analogy to parallel associative scans and the chunkwise-recurrent form of sequential linear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this scheme can be efficiently implemented using einsum operations, concatenations, and padding in logarithmic time. pLSTMs tackle the vanishing/exploding activation/gradient problem for long distances in DAGs via two distinct modes: a directed propagation mode (P-mode) and a diffusive distribution mode (D-mode). To showcase the long-range capabilities of pLSTM, we introduce arrow-pointing extrapolation as a synthetic computer vision task that contains long-distance directional information. We demonstrate that pLSTMs generalize well to larger image sizes, whereas Transformers struggle to extrapolate. On established molecular graph and computer vision benchmarks, pLSTMs also show strong performance. Code and Datasets are available at: https://github.com/ml-jku/plstm_experiments."

[16.06.2025 09:15] Response: ```python
['ARCHITECTURE', 'BENCHMARK', 'CV']
```
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.  					AI-generated summary 				 Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language modeling. However, their structure constrains their applicability to sequences only or requires processing multi-dimensional data structures, such as images or molecular graphs, in a pre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are well suited for data with a higher level structure, like 2D grids, trees, and directed acyclic graphs (DAGs). In this work, we extend the notion of multi-dimensionality to linear RNNs. We introduce parallelizable Linear Source Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that act on the line graph of a general DAG. This enables parallelization in analogy to parallel associative scans and the chunkwise-recurrent form of sequential linear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this scheme can be efficiently implemented using einsum operations, concatenations, and padding in logarithmic time. pLSTMs tackle the vanishing/exploding activation/gradient problem for long distances in DAGs via two distinct modes: a directed propagation mode (P-mode) and a diffusive distribution mode (D-mode). To showcase the long-range capabilities of pLSTM, we introduce arrow-pointing extrapolation as a synthetic computer vision task that contains long-distance directional information. We demonstrate that pLSTMs generalize well to larger image sizes, whereas Transformers struggle to extrapolate. On established molecular graph and computer vision benchmarks, pLSTMs also show strong performance. Code and Datasets are available at: https://github.com/ml-jku/plstm_experiments."

[16.06.2025 09:15] Response: ```python
["LONG_CONTEXT", "GRAPHS", "OPTIMIZATION", "SYNTHETIC", "OPEN_SOURCE"]
```
[16.06.2025 09:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces parallelizable Linear Source Transition Mark networks (pLSTMs), a new type of linear recurrent neural network (RNN) designed for processing data structured as directed acyclic graphs (DAGs). Unlike traditional RNNs and Transformers, pLSTMs can efficiently handle multi-dimensional data without being limited to sequential processing. They address the vanishing and exploding gradient problems through two modes of operation, allowing for effective long-range dependencies in data. The authors demonstrate that pLSTMs outperform Transformers on various benchmarks, particularly in tasks requiring long-distance extrapolation, such as computer vision and molecular graph analysis.","title":"pLSTMs: Revolutionizing Long-Range Learning in DAGs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces parallelizable Linear Source Transition Mark networks (pLSTMs), a new type of linear recurrent neural network (RNN) designed for processing data structured as directed acyclic graphs (DAGs). Unlike traditional RNNs and Transformers, pLSTMs can efficiently handle multi-dimensional data without being limited to sequential processing. They address the vanishing and exploding gradient problems through two modes of operation, allowing for effective long-range dependencies in data. The authors demonstrate that pLSTMs outperform Transformers on various benchmarks, particularly in tasks requiring long-distance extrapolation, such as computer vision and molecular graph analysis.', title='pLSTMs: Revolutionizing Long-Range Learning in DAGs'))
[16.06.2025 09:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"pLSTMsæ˜¯ä¸€ç§å¯å¹¶è¡ŒåŒ–çš„çº¿æ€§é€’å½’ç¥ç»ç½‘ç»œï¼Œä¸“ä¸ºæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨é•¿è·ç¦»ä»»åŠ¡å’ŒåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºå˜æ¢å™¨ï¼ˆTransformersï¼‰ã€‚ä¸ç°ä»£é€’å½’æ¶æ„ç›¸æ¯”ï¼ŒpLSTMsé€šè¿‡æºã€è½¬ç§»å’Œæ ‡è®°é—¨çš„è®¾è®¡ï¼Œè§£å†³äº†é•¿è·ç¦»ä¼ æ’­ä¸­çš„æ¶ˆå¤±å’Œçˆ†ç‚¸æ¢¯åº¦é—®é¢˜ã€‚è¯¥æ–¹æ³•é€‚ç”¨äºæ›´é«˜ç»“æ„çš„æ•°æ®ï¼Œå¦‚äºŒç»´ç½‘æ ¼å’Œæ ‘å½¢ç»“æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å›¾åƒç­‰å¤šç»´æ•°æ®ã€‚é€šè¿‡å¼•å…¥ç®­å¤´æŒ‡å‘å¤–æ¨çš„åˆæˆè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ŒpLSTMså±•ç¤ºäº†å…¶åœ¨é•¿è·ç¦»æ¨æ–­ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚","title":"pLSTMsï¼šè¶…è¶Šå˜æ¢å™¨çš„é•¿è·ç¦»å­¦ä¹ æ–°æ–¹æ³•"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='pLSTMsæ˜¯ä¸€ç§å¯å¹¶è¡ŒåŒ–çš„çº¿æ€§é€’å½’ç¥ç»ç½‘ç»œï¼Œä¸“ä¸ºæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨é•¿è·ç¦»ä»»åŠ¡å’ŒåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºå˜æ¢å™¨ï¼ˆTransformersï¼‰ã€‚ä¸ç°ä»£é€’å½’æ¶æ„ç›¸æ¯”ï¼ŒpLSTMsé€šè¿‡æºã€è½¬ç§»å’Œæ ‡è®°é—¨çš„è®¾è®¡ï¼Œè§£å†³äº†é•¿è·ç¦»ä¼ æ’­ä¸­çš„æ¶ˆå¤±å’Œçˆ†ç‚¸æ¢¯åº¦é—®é¢˜ã€‚è¯¥æ–¹æ³•é€‚ç”¨äºæ›´é«˜ç»“æ„çš„æ•°æ®ï¼Œå¦‚äºŒç»´ç½‘æ ¼å’Œæ ‘å½¢ç»“æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å›¾åƒç­‰å¤šç»´æ•°æ®ã€‚é€šè¿‡å¼•å…¥ç®­å¤´æŒ‡å‘å¤–æ¨çš„åˆæˆè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ŒpLSTMså±•ç¤ºäº†å…¶åœ¨é•¿è·ç¦»æ¨æ–­ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚', title='pLSTMsï¼šè¶…è¶Šå˜æ¢å™¨çš„é•¿è·ç¦»å­¦ä¹ æ–°æ–¹æ³•'))
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#optimization", "#multimodal", "#games"], "emoji": "ğŸ”„", "ru": {"title": "InterSyn: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ InterSyn - ĞºÑ€ÑƒĞ¿Ğ½Ğ¾Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ğ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. InterSyn ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ñ Ğ¸Ñ
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#benchmark", "#robotics", "#rl", "#open_source", "#games"], "emoji": "ğŸ¤–", "ru": {"title": "SkillBlender: ÑƒĞ¼Ğ½Ğ¾Ğµ ÑĞ¾Ñ‡ĞµÑ‚Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³ÑƒĞ¼Ğ°Ğ½Ğ¾Ğ¸Ğ´Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ²", "desc": "SkillBlender - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ³ÑƒĞ¼
[16.06.2025 09:15] Using data from previous issue: {"categories": ["#dataset", "#low_resource", "#ethics", "#interpretability", "#small_models", "#multimodal", "#benchmark"], "emoji": "ğŸ•µï¸", "ru": {"title": "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¸Ğ² Ğ´Ğ»Ñ Ğ²Ñ€ĞµĞ´Ğ½Ñ‹Ñ… Ğ¼ĞµĞ¼Ğ¾Ğ²", "desc": "U-CoT+ - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ñ… Ğ¼ĞµĞ¼Ğ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Ğ¸Ñ… Ğ² Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¾
[16.06.2025 09:15] Querying the API.
[16.06.2025 09:15] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks.
[16.06.2025 09:15] Response: {
  "desc": "DeepVideo-R1 - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ GRPO (Reg-GRPO) Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ GRPO Ğº Ğ²Ğ¸Ğ´ĞµĞ¾-Ğ¯Ğ‘Ğœ, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ½Ñ‹Ñ… Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ¾Ğ² Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¸ÑÑ‡ĞµĞ·Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ°. Reg-GRPO Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ GRPO ĞºĞ°Ğº Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½ÑƒÑ, Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾. Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ½Ğ° Ñ€ĞµÑˆĞ°ĞµĞ¼Ñ‹Ñ… ÑƒÑ€Ğ¾Ğ²Ğ½ÑÑ… ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸.",
  "emoji": "ğŸ¥",
  "title": "DeepVideo-R1: Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ GRPO"
}
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks."

[16.06.2025 09:15] Response: ```python
["RL", "RLHF", "VIDEO", "BENCHMARK", "TRAINING"]
```
[16.06.2025 09:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.  					AI-generated summary 				 Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks."

[16.06.2025 09:15] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[16.06.2025 09:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeepVideo-R1 is a novel approach that enhances video reasoning in large language models by utilizing a regression-based method called Reg-GRPO. This method reformulates the Group Relative Policy Optimization (GRPO) objective into a regression task, allowing for more direct policy guidance without the need for complex safeguards. Additionally, the paper introduces a difficulty-aware data augmentation strategy that adjusts training samples based on their solvable difficulty, which helps in generating diverse and informative reward signals. The results demonstrate that DeepVideo-R1 significantly boosts performance on various video reasoning benchmarks, showcasing its effectiveness in the field.","title":"Enhancing Video Reasoning with Reg-GRPO and Smart Data Augmentation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DeepVideo-R1 is a novel approach that enhances video reasoning in large language models by utilizing a regression-based method called Reg-GRPO. This method reformulates the Group Relative Policy Optimization (GRPO) objective into a regression task, allowing for more direct policy guidance without the need for complex safeguards. Additionally, the paper introduces a difficulty-aware data augmentation strategy that adjusts training samples based on their solvable difficulty, which helps in generating diverse and informative reward signals. The results demonstrate that DeepVideo-R1 significantly boosts performance on various video reasoning benchmarks, showcasing its effectiveness in the field.', title='Enhancing Video Reasoning with Reg-GRPO and Smart Data Augmentation'))
[16.06.2025 09:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DeepVideo-R1 æ˜¯ä¸€ç§å¢å¼ºè§†é¢‘æ¨ç†æ€§èƒ½çš„æ¨¡å‹ï¼Œé‡‡ç”¨äº†å›å½’å‹çš„ GRPO æ–¹æ³•å’Œéš¾åº¦æ„ŸçŸ¥çš„æ•°æ®å¢å¼ºç­–ç•¥ã€‚è¯¥ç ”ç©¶æ¢è®¨äº† GRPO åœ¨è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨ï¼Œå¹¶è¯†åˆ«å‡ºå½±å“æœ‰æ•ˆå­¦ä¹ çš„ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¾èµ–ä¿æŠ¤æªæ–½å’Œä¼˜åŠ¿æ¶ˆå¤±é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒDeepVideo-R1 é€šè¿‡å›å½’ GRPO é‡æ–°æ„å»ºäº† GRPO ç›®æ ‡ï¼Œç›´æ¥é¢„æµ‹ä¼˜åŠ¿å€¼ï¼Œä»è€Œç®€åŒ–äº†æ”¿ç­–æŒ‡å¯¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepVideo-R1 åœ¨å¤šä¸ªè§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†è§†é¢‘æ¨ç†æ€§èƒ½ã€‚","title":"DeepVideo-R1ï¼šæå‡è§†é¢‘æ¨ç†çš„æ–°æ–¹æ³•"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DeepVideo-R1 æ˜¯ä¸€ç§å¢å¼ºè§†é¢‘æ¨ç†æ€§èƒ½çš„æ¨¡å‹ï¼Œé‡‡ç”¨äº†å›å½’å‹çš„ GRPO æ–¹æ³•å’Œéš¾åº¦æ„ŸçŸ¥çš„æ•°æ®å¢å¼ºç­–ç•¥ã€‚è¯¥ç ”ç©¶æ¢è®¨äº† GRPO åœ¨è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨ï¼Œå¹¶è¯†åˆ«å‡ºå½±å“æœ‰æ•ˆå­¦ä¹ çš„ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¾èµ–ä¿æŠ¤æªæ–½å’Œä¼˜åŠ¿æ¶ˆå¤±é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒDeepVideo-R1 é€šè¿‡å›å½’ GRPO é‡æ–°æ„å»ºäº† GRPO ç›®æ ‡ï¼Œç›´æ¥é¢„æµ‹ä¼˜åŠ¿å€¼ï¼Œä»è€Œç®€åŒ–äº†æ”¿ç­–æŒ‡å¯¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepVideo-R1 åœ¨å¤šä¸ªè§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†è§†é¢‘æ¨ç†æ€§èƒ½ã€‚', title='DeepVideo-R1ï¼šæå‡è§†é¢‘æ¨ç†çš„æ–°æ–¹æ³•'))
[16.06.2025 09:16] Using data from previous issue: {"categories": ["#rlhf", "#synthetic", "#training", "#dataset", "#alignment", "#open_source"], "emoji": "ğŸ›ï¸", "ru": {"title": "Ğ“Ğ¸Ğ±ĞºĞ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾Ğ´ Ğ¼ĞµĞ½ÑÑÑ‰Ğ¸ĞµÑÑ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Configurable Preference Tuning (CPT
[16.06.2025 09:16] Querying the API.
[16.06.2025 09:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings.
[16.06.2025 09:16] Response: {
  "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑĞ°Ğ¼Ğ¾ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²ÑƒÑÑ‰Ğ°ÑÑÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑ‡Ğ¸ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½ĞµĞ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞŸÑ€Ğ¾Ñ†ĞµÑÑ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ÑĞµĞ²Ğ´Ğ¾-Ğ¼ĞµÑ‚Ğ¾Ğº ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ ĞĞ¡Ğ , ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ñ€ĞµÑ‡Ğ¸. Ğ—Ğ°Ñ‚ĞµĞ¼ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ñ‹ Ñ€ĞµÑ‡ÑŒ-Ñ‚ĞµĞºÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ĞĞ¡Ğ , Ğ·Ğ°Ğ¼Ñ‹ĞºĞ°Ñ Ñ†Ğ¸ĞºĞ» ÑĞ°Ğ¼Ğ¾ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ½Ğ° Ñ‚Ğ°Ğ¹Ğ²Ğ°Ğ½ÑŒÑĞºĞ¾Ğ¼ Ğ¼Ğ°Ğ½Ğ´Ğ°Ñ€Ğ¸Ğ½ÑĞºĞ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ»ĞµĞºÑ‚Ğµ, Ğ³Ğ´Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Twister, Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¸Ğ· Whisper-large-v2, Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ° Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ.",
  "emoji": "ğŸ”",
  "title": "Ğ¡Ğ°Ğ¼Ğ¾ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²ÑƒÑÑ‰Ğ°ÑÑÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ĞĞ¡Ğ : Ğ¾Ñ‚ Ğ¿ÑĞµĞ²Ğ´Ğ¾-Ğ¼ĞµÑ‚Ğ¾Ğº Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ¼Ñƒ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ"
}
[16.06.2025 09:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings."

[16.06.2025 09:16] Response: ```python
["DATASET", "DATA", "BENCHMARK", "AUDIO"]
```
[16.06.2025 09:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.  					AI-generated summary 				 We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings."

[16.06.2025 09:16] Response: ```python
['TRANSFER_LEARNING', 'SYNTHETIC', 'LOW_RESOURCE']
```
[16.06.2025 09:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a self-refining framework designed to improve Automatic Speech Recognition (ASR) performance using only unlabeled datasets. The framework begins with an existing ASR model that generates pseudo-labels from unannotated speech data, which are then utilized to train a high-fidelity Text-to-Speech (TTS) system. Synthesized speech and text pairs are incorporated back into the original ASR model, creating a closed-loop system that enhances its accuracy. The proposed method, tested on Taiwanese Mandarin, shows significant error rate reductions, demonstrating its effectiveness in low-resource environments.","title":"Enhancing ASR with Unlabeled Data: The Twister Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a self-refining framework designed to improve Automatic Speech Recognition (ASR) performance using only unlabeled datasets. The framework begins with an existing ASR model that generates pseudo-labels from unannotated speech data, which are then utilized to train a high-fidelity Text-to-Speech (TTS) system. Synthesized speech and text pairs are incorporated back into the original ASR model, creating a closed-loop system that enhances its accuracy. The proposed method, tested on Taiwanese Mandarin, shows significant error rate reductions, demonstrating its effectiveness in low-resource environments.', title='Enhancing ASR with Unlabeled Data: The Twister Framework'))
[16.06.2025 09:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªæˆ‘ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡ä½¿ç”¨æœªæ ‡æ³¨çš„æ•°æ®é›†æ¥æå‡è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨ç°æœ‰çš„ASRæ¨¡å‹ä¸ºæœªæ ‡æ³¨çš„è¯­éŸ³ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªé«˜ä¿çœŸçš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿã€‚æ¥ç€ï¼Œå°†åˆæˆçš„è¯­éŸ³æ–‡æœ¬å¯¹å¼•å…¥åŸå§‹çš„ASRç³»ç»Ÿï¼Œå½¢æˆä¸€ä¸ªé—­ç¯çš„è‡ªæˆ‘æ”¹è¿›å¾ªç¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å°æ¹¾æ™®é€šè¯è¯­éŸ³ä¸Šæœ‰æ•ˆï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½é”™è¯¯ç‡ï¼Œå°¤å…¶åœ¨ä½èµ„æºæˆ–ç‰¹å®šé¢†åŸŸçš„åº”ç”¨ä¸­å…·æœ‰å®é™…æ„ä¹‰ã€‚","title":"è‡ªæˆ‘ä¼˜åŒ–æ¡†æ¶æå‡ASRæ€§èƒ½çš„åˆ›æ–°ä¹‹è·¯"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªæˆ‘ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡ä½¿ç”¨æœªæ ‡æ³¨çš„æ•°æ®é›†æ¥æå‡è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨ç°æœ‰çš„ASRæ¨¡å‹ä¸ºæœªæ ‡æ³¨çš„è¯­éŸ³ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªé«˜ä¿çœŸçš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿã€‚æ¥ç€ï¼Œå°†åˆæˆçš„è¯­éŸ³æ–‡æœ¬å¯¹å¼•å…¥åŸå§‹çš„ASRç³»ç»Ÿï¼Œå½¢æˆä¸€ä¸ªé—­ç¯çš„è‡ªæˆ‘æ”¹è¿›å¾ªç¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å°æ¹¾æ™®é€šè¯è¯­éŸ³ä¸Šæœ‰æ•ˆï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½é”™è¯¯ç‡ï¼Œå°¤å…¶åœ¨ä½èµ„æºæˆ–ç‰¹å®šé¢†åŸŸçš„åº”ç”¨ä¸­å…·æœ‰å®é™…æ„ä¹‰ã€‚', title='è‡ªæˆ‘ä¼˜åŒ–æ¡†æ¶æå‡ASRæ€§èƒ½çš„åˆ›æ–°ä¹‹è·¯'))
[16.06.2025 09:16] Using data from previous issue: {"categories": ["#data", "#transfer_learning", "#training", "#open_source", "#dataset"], "emoji": "ğŸ”", "ru": {"title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ´ĞµÑ‚Ğ°Ğ»ÑÑ…: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ²", "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ CapRetrieval Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ² Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ»ĞºĞ¸Ğµ
[16.06.2025 09:16] Renaming data file.
[16.06.2025 09:16] Renaming previous data. hf_papers.json to ./d/2025-06-16.json
[16.06.2025 09:16] Saving new data file.
[16.06.2025 09:16] Generating page.
[16.06.2025 09:16] Renaming previous page.
[16.06.2025 09:16] Renaming previous data. index.html to ./d/2025-06-16.html
[16.06.2025 09:16] Writing result.
[16.06.2025 09:16] Renaming log file.
[16.06.2025 09:16] Renaming previous data. log.txt to ./logs/2025-06-16_last_log.txt
