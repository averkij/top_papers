[20.05.2025 23:10] Read previous papers.
[20.05.2025 23:10] Generating top page (month).
[20.05.2025 23:10] Writing top page (month).
[21.05.2025 00:55] Read previous papers.
[21.05.2025 00:55] Get feed.
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11820
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13417
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11896
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11254
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13227
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13389
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13379
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13308
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12082
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13427
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13215
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12805
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12504
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12992
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13444
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11932
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12346
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12081
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07704
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13180
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11855
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12849
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13388
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12058
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13437
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.10238
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12996
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12120
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11497
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11484
[21.05.2025 00:55] Extract page data from URL. URL: https://huggingface.co/papers/2505.13840
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12872
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11733
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11475
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.10420
[21.05.2025 00:55] Extract page data from URL. URL: https://huggingface.co/papers/2505.13181
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12781
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12257
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11988
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.10831
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.03332
[21.05.2025 00:55] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12973
[21.05.2025 00:55] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[21.05.2025 00:55] No deleted papers detected.
[21.05.2025 00:55] Downloading and parsing papers (pdf, html). Total: 42.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11820.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11820.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11820.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13417.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13417.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13417.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11896.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11896.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11896.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11254.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11254.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11254.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13227.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13227.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13227.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13389.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13389.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13389.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13379.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13379.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13379.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13308.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13308.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13308.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12082.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12082.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12082.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13427.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13427.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13427.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13215.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13215.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13215.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12805.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12805.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12805.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12504.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12504.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12504.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12992.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12992.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12992.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13444.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13444.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13444.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11932.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11932.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11932.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12346.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12346.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12346.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12081.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12081.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12081.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.07704.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.07704.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.07704.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13180.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13180.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13180.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11855.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11855.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11855.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12849.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12849.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12849.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13388.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13388.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13388.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12058.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12058.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12058.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13437.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.13437.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.13437.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.10238.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.10238.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.10238.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12996.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12996.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12996.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12120.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12120.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12120.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11497.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11497.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11497.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11484.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11484.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11484.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13840.
[21.05.2025 00:55] Downloading paper 2505.13840 from http://arxiv.org/pdf/2505.13840v1...
[21.05.2025 00:55] Extracting affiliations from text.
[21.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"EFFICIENTLLM: EFFICIENCY IN LARGE LANGUAGE MODELS EVALUATION ON ARCHITECTURE PRETRAINING, FINE-TUNING, AND BIT-WIDTH QUANTIZATION 5 2 0 2 0 2 ] . [ 1 0 4 8 3 1 . 5 0 5 2 : r Zhengqing Yuan1 Weixiang Sun1 Yixin Liu2 Huichi Zhou3 Rong Zhou2 Yiyang Li1 Zheyuan Zhang1 Wei Song1 Yue Huang1 Haolong Jia4 Keerthiram Murugesan Yu Wang6 Lifang He2 Jianfeng Gao7 Lichao Sun2 Yanfang Ye1 1University of Notre Dame 2Lehigh University 3Imperial College London 4Rutgers University 5International Business Machines Corporation (IBM) 6University of Illinois Chicago 7Microsoft Research https://dlyuangod.github.io/EfficientLLM/ (cid:18) https://huggingface.co/Tyrannosaurus/EfficientLLM "
[21.05.2025 00:55] Response: ```python
[
    "University of Notre Dame",
    "Lehigh University",
    "Imperial College London",
    "Rutgers University",
    "International Business Machines Corporation (IBM)",
    "University of Illinois Chicago",
    "Microsoft Research"
]
```
[21.05.2025 00:55] Deleting PDF ./assets/pdf/2505.13840.pdf.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12872.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12872.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12872.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11733.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11733.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11733.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11475.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11475.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11475.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.10420.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.10420.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.10420.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.13181.
[21.05.2025 00:55] Downloading paper 2505.13181 from http://arxiv.org/pdf/2505.13181v1...
[21.05.2025 00:55] Extracting affiliations from text.
[21.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 1 ] . [ 1 1 8 1 3 1 . 5 0 5 2 : r a Zhengrui Ma 1,2,3, Yang Feng 1,2 * , Chenze Shao 3, Fandong Meng 3, Jie Zhou 3, Min Zhang 4 1 Key Laboratory of Intelligent Information Processing Institute of Computing Technology, Chinese Academy of Sciences 2 University of Chinese Academy of Sciences 3 Pattern Recognition Center, WeChat AI, Tencent Inc 4 School of Future Science and Engineering, Soochow University *: Corresponding author {mazhengrui21b,fengyang}@ict.ac.cn "
[21.05.2025 00:55] Response: ```python
[
    "Key Laboratory of Intelligent Information Processing Institute of Computing Technology, Chinese Academy of Sciences",
    "University of Chinese Academy of Sciences",
    "Pattern Recognition Center, WeChat AI, Tencent Inc",
    "School of Future Science and Engineering, Soochow University"
]
```
[21.05.2025 00:55] Deleting PDF ./assets/pdf/2505.13181.pdf.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12781.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12781.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12781.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12257.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12257.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12257.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.11988.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.11988.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.11988.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.10831.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.10831.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.10831.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.03332.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.03332.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.03332.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Downloading and parsing paper https://huggingface.co/papers/2505.12973.
[21.05.2025 00:55] Extra JSON file exists (./assets/json/2505.12973.json), skip PDF parsing.
[21.05.2025 00:55] Paper image links file exists (./assets/img_data/2505.12973.json), skip HTML parsing.
[21.05.2025 00:55] Success.
[21.05.2025 00:55] Enriching papers with extra data.
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 0. In this paper, we propose a novel learning paradigm, termed Chain-of-Model (CoM), which incorporates the causal relationship into the hidden states of each layer as a chain style, thereby introducing great scaling efficiency in model training and inference flexibility in deployment. We introduce the...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 1. Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking,...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 2. Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to su...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 3. The attention mechanism of a transformer has a quadratic complexity, leading to high inference costs and latency for long sequences. However, attention matrices are mostly sparse, which implies that many entries may be omitted from computation for efficient inference. Sparse attention inference meth...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 4. Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to cap...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 5. Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D attention, even though most of the attention mass concentrates on a small subset of positions. We turn this observation into VSA, a trainable, hardware-efficient sparse attention that replaces full attention at both trainin...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 6. Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many pr...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 7. Reasoning ability, a core component of human intelligence, continues to pose a significant challenge for Large Language Models (LLMs) in the pursuit of AGI. Although model performance has improved under the training scaling law, significant challenges remain, particularly with respect to training al...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 8. Model merging has emerged as a promising technique for enhancing large language models, though its application in large-scale pre-training remains relatively unexplored. In this paper, we present a comprehensive investigation of model merging techniques during the pre-training process. Through exten...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 9. While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervisi...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 10. Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 11. Low-Rank Adaptation (LoRA), which introduces a product of two trainable low-rank matrices into frozen pre-trained weights, is widely used for efficient fine-tuning of language models in federated learning (FL). However, when combined with differentially private stochastic gradient descent (DP-SGD), ...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 12. Recent advances in rule-based reinforcement learning (RL) have significantly improved the reasoning capability of language models (LMs) with rule-based rewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO -- often suffer from training instability, where large policy updates a...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 13. Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by genera...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 14. Chart understanding presents a unique challenge for large vision-language models (LVLMs), as it requires the integration of sophisticated textual and visual reasoning capabilities. However, current LVLMs exhibit a notable imbalance between these skills, falling short on visual reasoning that is diff...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 15. Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic gra...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 16. Large language models (LLMs) exhibit varying levels of confidence across input prompts (questions): some lead to consistent, semantically similar answers, while others yield diverse or contradictory outputs. This variation reflects LLM's uncertainty about the input prompt, a signal of how confidentl...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 17. Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 18. Measuring how real images look is a complex task in artificial intelligence research. For example, an image of a boy with a vacuum cleaner in a desert violates common sense. We introduce a novel method, which we call Through the Looking Glass (TLG), to assess image common sense consistency using Lar...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 19. Integrating Large Language Models with symbolic planners is a promising direction for obtaining verifiable and grounded plans compared to planning in natural language, with recent works extending this idea to visual domains using Vision-Language Models (VLMs). However, rigorous comparison between VL...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 20. Recent advances in large language models (LLMs) have fueled the vision of automated scientific discovery, often called AI Co-Scientists. To date, prior work casts these systems as generative co-authors responsible for crafting hypotheses, synthesizing code, or drafting manuscripts. In this work, we ...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 21. Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computatio...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 22. Reward models are essential for aligning language model outputs with human preferences, yet existing approaches often lack both controllability and interpretability. These models are typically optimized for narrow objectives, limiting their generalizability to broader downstream tasks. Moreover, the...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 23. Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual smoke-test suite designed to give large-language-model (LLM) pipelines a unit-test style safety net dataset that runs in seconds with minimal cost. Born out of the tight feedback-loop demands building the Comet Opik prompt-optim...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 24. Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as "switch leap with 0.5 turn" poses subs...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 25. Human image animation has gained increasing attention and developed rapidly due to its broad applications in digital humans. However, existing methods rely largely on 2D-rendered pose images for motion guidance, which limits generalization and discards essential 3D information for open-world animati...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 26. In recent years, the emergence of large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex problems, e.g., mathematics and coding. Some pioneering studies attempt to bring the success of LRMs in neural machine translation (MT). They try to build ...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 27. Recent advancements in Digital Pathology (DP), particularly through artificial intelligence and Foundation Models, have underscored the importance of large-scale, diverse, and richly annotated datasets. Despite their critical role, publicly available Whole Slide Image (WSI) datasets often lack suffi...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 28. Video diffusion models (DMs) have enabled high-quality video synthesis. Yet, their substantial computational and memory demands pose serious challenges to real-world deployment, even on high-end GPUs. As a commonly adopted solution, quantization has proven notable success in reducing cost for image ...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 29. Test-Time Scaling (TTS) refers to approaches that improve reasoning performance by allocating extra computation during inference, without altering the model's parameters. While existing TTS methods operate in a discrete token space by generating more intermediate steps, recent studies in Coconut and...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 30. Large Language Models (LLMs) have driven significant progress, yet their growing parameter counts and context windows incur prohibitive compute, energy, and monetary costs. We introduce EfficientLLM, a novel benchmark and the first comprehensive empirical study evaluating efficiency techniques for L...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 31. Early cavemen relied on gestures, vocalizations, and simple signals to coordinate, plan, avoid predators, and share resources. Today, humans collaborate using complex languages to achieve remarkable results. What drives this evolution in communication? How does language emerge, adapt, and become vit...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 32. Doctors and patients alike increasingly use Large Language Models (LLMs) to diagnose clinical cases. However, unlike domains such as math or coding, where correctness can be objectively defined by the final answer, medical diagnosis requires both the outcome and the reasoning process to be accurate....
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 33. Preference datasets are essential for training general-domain, instruction-following language models with Reinforcement Learning from Human Feedback (RLHF). Each subsequent data release raises expectations for future data collection, meaning there is a constant need to advance the quality and divers...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 34. The Image Signal Processor (ISP) is a fundamental component in modern smartphone cameras responsible for conversion of RAW sensor image data to RGB images with a strong focus on perceptual quality. Recent work highlights the potential of deep learning approaches and their ability to capture details ...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 35. We introduce SLED, an alternative approach to speech language modeling by encoding speech waveforms into sequences of continuous latent representations and modeling them autoregressively using an energy distance objective. The energy distance offers an analytical measure of the distributional gap by...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 36. Training high-performing Small Language Models (SLMs) remains costly, even with knowledge distillation and pruning from larger teacher models. Existing work often faces three key challenges: (1) information loss from hard pruning, (2) inefficient alignment of representations, and (3) underutilizatio...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 37. Identifying subtle technical errors within complex scientific and technical documents, especially those requiring multimodal interpretation (e.g., formulas in images), presents a significant hurdle for Large Language Models (LLMs) whose inherent error-correction tendencies can mask inaccuracies. Thi...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 38. Accurately identifying adversarial techniques in security texts is critical for effective cyber defense. However, existing methods face a fundamental trade-off: they either rely on generic models with limited domain precision or require resource-intensive pipelines that depend on large labeled datas...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 39. Human-computer interaction has long imagined technology that understands us-from our preferences and habits, to the timing and purpose of our everyday actions. Yet current user models remain fragmented, narrowly tailored to specific apps, and incapable of the flexible reasoning required to fulfill t...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 40. Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering met...
[21.05.2025 00:55] ********************************************************************************
[21.05.2025 00:55] Abstract 41. Homograph disambiguation remains a significant challenge in grapheme-to-phoneme (G2P) conversion, especially for low-resource languages. This challenge is twofold: (1) creating balanced and comprehensive homograph datasets is labor-intensive and costly, and (2) specific disambiguation strategies int...
[21.05.2025 00:55] Read previous papers.
[21.05.2025 00:55] Generating reviews via LLM API.
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#open_source", "#inference", "#agi", "#architecture", "#optimization"], "emoji": "🔗", "ru": {"title": "Цепная революция в языковых моделях: гибкость и эффективность", "desc": "В этой статье представлена новая парадигма обучения под названием Chain-of-Model (CoM), котора
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#math", "#reasoning", "#inference", "#training", "#optimization", "#rl"], "emoji": "🧠", "ru": {"title": "Адаптивное мышление для оптимизации рассуждений ИИ", "desc": "Исследователи представили новый алгоритм AdaptThink, который учит модели рассуждения адаптивно выбирать оптимальный 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rlhf", "#rl", "#training"], "emoji": "🧠", "ru": {"title": "AdaCoT: Умное рассуждение для языковых моделей", "desc": "AdaCoT - это новый фреймворк, позволяющий крупным языковым моделям (LLM) адаптивно решать, когда использовать метод цепочки рассуждени
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#architecture", "#inference", "#benchmark"], "emoji": "🔍", "ru": {"title": "Коррекция распределения для эффективного разреженного внимания", "desc": "Статья предлагает новый метод для повышения эффективности разреженного внимания в трансформерах. Ав
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#data", "#dataset", "#graphs", "#agents", "#benchmark", "#open_source"], "emoji": "🖥️", "ru": {"title": "Революция в обучении ИИ работе с компьютерными интерфейсами", "desc": "Статья представляет новый бенчмарк OSWorld-G для оценки способности моделей машинного обучения к интерпрета
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#diffusion", "#training", "#open_source", "#video"], "emoji": "🎥", "ru": {"title": "Эффективное разреженное внимание для масштабирования видео-диффузионных моделей", "desc": "Статья представляет новый метод разреженного внимания (VSA) для масштабиро
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#benchmark", "#training"], "emoji": "🧠", "ru": {"title": "Умное переключение между кратким и развернутым мышлением в языковых моделях", "desc": "Статья представляет Thinkless - обучаемую систему, позволяющую языковым моделям адаптивно выбирать м
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#architecture", "#reasoning", "#training", "#agi"], "emoji": "🧠", "ru": {"title": "LatentSeek: Повышение способности рассуждать у ИИ через адаптацию в латентном пространстве", "desc": "Статья представляет LatentSeek - новый фреймворк для улучшения спос
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#architecture", "#training"], "emoji": "🔀", "ru": {"title": "Слияние моделей: путь к эффективному предобучению больших языковых моделей", "desc": "Статья исследует применение техники слияния моделей в процессе предварительного обучения больших языков
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#multimodal", "#math", "#training", "#open_source", "#benchmark", "#data", "#dataset"], "emoji": "🧠", "ru": {"title": "Автоматизированное обучение мультимодальных моделей пошаговым рассуждениям", "desc": "В статье представлена модель MM-PRM, обучающаяс
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#3d"], "emoji": "🎥", "ru": {"title": "Гибридный 3D-4D подход для эффективной реконструкции динамических сцен", "desc": "Статья представляет новый метод 3D-4DGS для реконструкции динамических 3D-сцен. Он комбинирует 3D гауссианы для статичных областей и 4D гауссианы для динамических 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#data", "#benchmark", "#security", "#optimization"], "emoji": "🔒", "ru": {"title": "FedSVD: Защищенное федеративное обучение языковых моделей с сохранением эффективности", "desc": "Статья представляет новый метод FedSVD для эффективного федеративного обучения языковых м
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "Стабильное обучение с подкреплением для языковых моделей", "desc": "Статья представляет новый алгоритм CPGD для стабилизации обучения с подкреплением языковых моделей. CPGD вводит ограничение на дрейф 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#benchmark", "#inference"], "emoji": "🧠", "ru": {"title": "Эффективное масштабирование рассуждений языковых моделей без переобучения", "desc": "Эта статья представляет новый метод под названием Fractured Sampling для улучшения рассуждений 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#open_source", "#interpretability", "#cv", "#benchmark", "#synthetic", "#reasoning", "#dataset"], "emoji": "📊", "ru": {"title": "Раскрывая пробелы в визуальном мышлении ИИ при анализе диаграмм", "desc": "Статья представляет новый тестовый набор данных ChartMuseum для оценки понимани
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rag", "#multimodal"], "emoji": "🧠", "ru": {"title": "Компиляция запросов для точного поиска в RAG-системах", "desc": "QCompiler - это нейро-символическая система для улучшения понимания сложных запросов в RAG-системах. Она использует минимальную грамм
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#math", "#benchmark", "#rl", "#hallucinations"], "emoji": "🧠", "ru": {"title": "Умное обучение ИИ: учитываем неуверенность модели", "desc": "Статья представляет новый метод обучения больших языковых моделей под названием SEED-GRPO. Этот по
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#benchmark", "#reasoning"], "emoji": "🧠", "ru": {"title": "Единая модель для многозадачного визуального восприятия", "desc": "В статье представлен VisionReasoner - унифицированная модель для решения различных задач визуального восприятия. Модель использует новы
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#training", "#dataset", "#interpretability", "#cv", "#architecture", "#optimization"], "emoji": "🔍", "ru": {"title": "Новый взгляд на здравый смысл в компьютерном зрении", "desc": "Исследователи представили новый метод оценки здравого смысла в изображениях под названием Through the 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#benchmark", "#video", "#cv", "#games", "#reasoning", "#agents", "#open_source"], "emoji": "🤖", "ru": {"title": "ViPlan: новый бенчмарк для сравнения символьного и прямого визуального планирования", "desc": "Статья представляет ViPlan - первый открытый бенчмарк для визуального плани
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#data", "#science", "#dataset", "#benchmark"], "emoji": "🔍", "ru": {"title": "Большие языковые модели пока не готовы быть научными рецензентами", "desc": "Статья представляет SPOT - набор данных из 83 опубликованных научных работ с 91 значительной ошибкой, приведшей к опечаткам или 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#open_source", "#cv", "#training"], "emoji": "🚀", "ru": {"title": "Ускорение генерации изображений в TarFlow с помощью оптимизированных итераций", "desc": "Данная статья представляет метод ускорения процесса сэмплирования в модели TarFlow для генера
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#open_source", "#data", "#optimization", "#benchmark", "#alignment", "#interpretability", "#rlhf"], "emoji": "🎯", "ru": {"title": "R3: Прозрачное и гибкое моделирование наград для языковых моделей", "desc": "R3 - это новая система моделирования наград для языковых моделей. Она обесп
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#multilingual", "#dataset", "#synthetic", "#open_source", "#benchmark"], "emoji": "🚀", "ru": {"title": "Молниеносное тестирование языковых моделей для всех", "desc": "TQB++ представляет собой легковесный многоязычный набор тестов для быстрой проверки языковых моделей. Он включает в 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#3d", "#optimization", "#diffusion", "#video"], "emoji": "🤸", "ru": {"title": "Точная генерация движений человека с помощью физического моделирования", "desc": "Статья представляет FinePhys - фреймворк для генерации точных движений человека с использованием физических моделей. Систе
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#3d", "#video"], "emoji": "🕺", "ru": {"title": "Революция в анимации человека: от 2D к 4D движению", "desc": "MTVCrafter - это новый подход к анимации изображений человека, использующий токенизацию 4D движения вместо 2D-изображений поз. Метод вводит 4DMoT для квантования 3D последов
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#reasoning", "#multilingual", "#rl", "#low_resource", "#machine_translation"], "emoji": "🌐", "ru": {"title": "Революция в машинном переводе: от одноязычного к многоязычному совершенству", "desc": "Статья описывает новый метод моделирования вознаграждения для обучения с подкреплением
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#multimodal", "#healthcare", "#dataset", "#data"], "emoji": "🔬", "ru": {"title": "HISTAI: Крупномасштабный набор данных для прорыва в цифровой патологии", "desc": "Статья представляет новый набор данных HISTAI для цифровой патологии. Он содержит более 60 000 изображений срезов ткане
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#inference", "#video"], "emoji": "🎬", "ru": {"title": "Революция в квантовании видео-диффузионных моделей", "desc": "QVGen - это новая система обучения с учетом квантования для высокопроизводительных и эффективных при выводе видео-диффузионных моделей 
[21.05.2025 00:55] Using data from previous issue: {"categories": ["#optimization", "#inference", "#benchmark", "#reasoning", "#training"], "emoji": "🧠", "ru": {"title": "Улучшение рассуждений ИИ через разнообразные латентные мысли", "desc": "Статья представляет метод SoftCoT++, улучшающий рассуждения языковых моделей в непрерывном латентном простра
[21.05.2025 00:55] Querying the API.
[21.05.2025 00:55] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Language Models (LLMs) have driven significant progress, yet their growing parameter counts and context windows incur prohibitive compute, energy, and monetary costs. We introduce EfficientLLM, a novel benchmark and the first comprehensive empirical study evaluating efficiency techniques for LLMs at scale. Conducted on a production-class cluster (48xGH200, 8xH200 GPUs), our study systematically explores three key axes: (1) architecture pretraining (efficient attention variants: MQA, GQA, MLA, NSA; sparse Mixture-of-Experts (MoE)), (2) fine-tuning (parameter-efficient methods: LoRA, RSLoRA, DoRA), and (3) inference (quantization methods: int4, float16). We define six fine-grained metrics (Memory Utilization, Compute Utilization, Latency, Throughput, Energy Consumption, Compression Rate) to capture hardware saturation, latency-throughput balance, and carbon cost. Evaluating over 100 model-technique pairs (0.5B-72B parameters), we derive three core insights: (i) Efficiency involves quantifiable trade-offs: no single method is universally optimal; e.g., MoE reduces FLOPs and improves accuracy but increases VRAM by 40%, while int4 quantization cuts memory/energy by up to 3.9x at a 3-5% accuracy drop. (ii) Optima are task- and scale-dependent: MQA offers optimal memory-latency trade-offs for constrained devices, MLA achieves lowest perplexity for quality-critical tasks, and RSLoRA surpasses LoRA efficiency only beyond 14B parameters. (iii) Techniques generalize across modalities: we extend evaluations to Large Vision Models (Stable Diffusion 3.5, Wan 2.1) and Vision-Language Models (Qwen2.5-VL), confirming effective transferability. By open-sourcing datasets, evaluation pipelines, and leaderboards, EfficientLLM provides essential guidance for researchers and engineers navigating the efficiency-performance landscape of next-generation foundation models.
[21.05.2025 00:55] Response: {
  "desc": "Статья представляет EfficientLLM - новый бенчмарк и первое комплексное эмпирическое исследование методов повышения эффективности больших языковых моделей (LLM) в масштабе. Исследование систематически изучает три ключевых направления: архитектуру предобучения, тонкую настройку и инференс, используя шесть метрик для оценки аппаратной утилизации, баланса латентности и пропускной способности, а также углеродных затрат. Оценивая более 100 пар модель-метод, авторы выявляют количественные компромиссы эффективности, зависимость оптимумов от задачи и масштаба, а также обобщаемость техник на другие модальности. EfficientLLM предоставляет важные рекомендации для исследователей и инженеров в области эффективности и производительности моделей нового поколения.",
  "emoji": "🚀",
  "title": "EfficientLLM: Компромиссы эффективности в мире больших языковых моделей"
}
[21.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have driven significant progress, yet their growing parameter counts and context windows incur prohibitive compute, energy, and monetary costs. We introduce EfficientLLM, a novel benchmark and the first comprehensive empirical study evaluating efficiency techniques for LLMs at scale. Conducted on a production-class cluster (48xGH200, 8xH200 GPUs), our study systematically explores three key axes: (1) architecture pretraining (efficient attention variants: MQA, GQA, MLA, NSA; sparse Mixture-of-Experts (MoE)), (2) fine-tuning (parameter-efficient methods: LoRA, RSLoRA, DoRA), and (3) inference (quantization methods: int4, float16). We define six fine-grained metrics (Memory Utilization, Compute Utilization, Latency, Throughput, Energy Consumption, Compression Rate) to capture hardware saturation, latency-throughput balance, and carbon cost. Evaluating over 100 model-technique pairs (0.5B-72B parameters), we derive three core insights: (i) Efficiency involves quantifiable trade-offs: no single method is universally optimal; e.g., MoE reduces FLOPs and improves accuracy but increases VRAM by 40%, while int4 quantization cuts memory/energy by up to 3.9x at a 3-5% accuracy drop. (ii) Optima are task- and scale-dependent: MQA offers optimal memory-latency trade-offs for constrained devices, MLA achieves lowest perplexity for quality-critical tasks, and RSLoRA surpasses LoRA efficiency only beyond 14B parameters. (iii) Techniques generalize across modalities: we extend evaluations to Large Vision Models (Stable Diffusion 3.5, Wan 2.1) and Vision-Language Models (Qwen2.5-VL), confirming effective transferability. By open-sourcing datasets, evaluation pipelines, and leaderboards, EfficientLLM provides essential guidance for researchers and engineers navigating the efficiency-performance landscape of next-generation foundation models."

[21.05.2025 00:55] Response: ```python
['BENCHMARK', 'INFERENCE', 'ARCHITECTURE', 'TRAINING', 'MULTIMODAL']
```
[21.05.2025 00:55] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have driven significant progress, yet their growing parameter counts and context windows incur prohibitive compute, energy, and monetary costs. We introduce EfficientLLM, a novel benchmark and the first comprehensive empirical study evaluating efficiency techniques for LLMs at scale. Conducted on a production-class cluster (48xGH200, 8xH200 GPUs), our study systematically explores three key axes: (1) architecture pretraining (efficient attention variants: MQA, GQA, MLA, NSA; sparse Mixture-of-Experts (MoE)), (2) fine-tuning (parameter-efficient methods: LoRA, RSLoRA, DoRA), and (3) inference (quantization methods: int4, float16). We define six fine-grained metrics (Memory Utilization, Compute Utilization, Latency, Throughput, Energy Consumption, Compression Rate) to capture hardware saturation, latency-throughput balance, and carbon cost. Evaluating over 100 model-technique pairs (0.5B-72B parameters), we derive three core insights: (i) Efficiency involves quantifiable trade-offs: no single method is universally optimal; e.g., MoE reduces FLOPs and improves accuracy but increases VRAM by 40%, while int4 quantization cuts memory/energy by up to 3.9x at a 3-5% accuracy drop. (ii) Optima are task- and scale-dependent: MQA offers optimal memory-latency trade-offs for constrained devices, MLA achieves lowest perplexity for quality-critical tasks, and RSLoRA surpasses LoRA efficiency only beyond 14B parameters. (iii) Techniques generalize across modalities: we extend evaluations to Large Vision Models (Stable Diffusion 3.5, Wan 2.1) and Vision-Language Models (Qwen2.5-VL), confirming effective transferability. By open-sourcing datasets, evaluation pipelines, and leaderboards, EfficientLLM provides essential guidance for researchers and engineers navigating the efficiency-performance landscape of next-generation foundation models."

[21.05.2025 00:55] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE', 'TRANSFER_LEARNING']
```
[21.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents EfficientLLM, a benchmark designed to evaluate the efficiency of Large Language Models (LLMs) at scale. It systematically investigates various techniques across architecture pretraining, fine-tuning, and inference, using a comprehensive set of metrics to assess performance. The study reveals that efficiency techniques involve trade-offs that vary by task and model size, highlighting that no single method is best for all scenarios. Additionally, the findings indicate that these efficiency techniques can be applied across different model types, including vision and vision-language models, providing valuable resources for future research.","title":"Optimizing Efficiency in Large Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents EfficientLLM, a benchmark designed to evaluate the efficiency of Large Language Models (LLMs) at scale. It systematically investigates various techniques across architecture pretraining, fine-tuning, and inference, using a comprehensive set of metrics to assess performance. The study reveals that efficiency techniques involve trade-offs that vary by task and model size, highlighting that no single method is best for all scenarios. Additionally, the findings indicate that these efficiency techniques can be applied across different model types, including vision and vision-language models, providing valuable resources for future research.', title='Optimizing Efficiency in Large Language Models'))
[21.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型语言模型（LLMs）在技术上取得了显著进展，但其不断增长的参数数量和上下文窗口导致了高昂的计算、能源和经济成本。我们提出了EfficientLLM，这是一个新的基准，首次全面评估了大规模LLMs的效率技术。研究系统地探讨了架构预训练、微调和推理等三个关键方面，并定义了六个细致的指标来捕捉硬件饱和度、延迟-吞吐量平衡和碳成本。通过对100多个模型-技术对的评估，我们得出了效率涉及可量化权衡、最优解依赖于任务和规模以及技术在不同模态间的通用性等三大核心见解。","title":"高效模型，节能降耗！"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='大型语言模型（LLMs）在技术上取得了显著进展，但其不断增长的参数数量和上下文窗口导致了高昂的计算、能源和经济成本。我们提出了EfficientLLM，这是一个新的基准，首次全面评估了大规模LLMs的效率技术。研究系统地探讨了架构预训练、微调和推理等三个关键方面，并定义了六个细致的指标来捕捉硬件饱和度、延迟-吞吐量平衡和碳成本。通过对100多个模型-技术对的评估，我们得出了效率涉及可量化权衡、最优解依赖于任务和规模以及技术在不同模态间的通用性等三大核心见解。', title='高效模型，节能降耗！'))
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#agents", "#reasoning", "#open_source", "#multimodal", "#games"], "emoji": "🗣️", "ru": {"title": "Эволюция языка через призму искусственного интеллекта", "desc": "Статья исследует эволюцию языка в контексте многоагентных игр по добыче ресурсов, используя глубокое обу
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#training", "#benchmark", "#alignment", "#data", "#healthcare", "#reasoning"], "emoji": "🩺", "ru": {"title": "Новый стандарт оценки ИИ в медицинской диагностике", "desc": "Представлен новый датасет MedCaseReasoning для оценки способности языковых моделей 
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#alignment", "#rlhf", "#multilingual", "#open_source", "#dataset"], "emoji": "🤖", "ru": {"title": "HelpSteer3-Preference: новый стандарт данных для RLHF", "desc": "Статья представляет HelpSteer3-Preference - высококачественный набор данных предпочтений для обучения языковых моделей 
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#architecture", "#cv", "#training", "#dataset"], "emoji": "📱", "ru": {"title": "Умная обработка фото без парных данных", "desc": "Статья описывает новый метод обучения Image Signal Processor (ISP) для смартфонов без использования парных данных. Авторы предлагают подход с несколькими
[21.05.2025 00:56] Querying the API.
[21.05.2025 00:56] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We introduce SLED, an alternative approach to speech language modeling by encoding speech waveforms into sequences of continuous latent representations and modeling them autoregressively using an energy distance objective. The energy distance offers an analytical measure of the distributional gap by contrasting simulated and target samples, enabling efficient training to capture the underlying continuous autoregressive distribution. By bypassing reliance on residual vector quantization, SLED avoids discretization errors and eliminates the need for the complicated hierarchical architectures common in existing speech language models. It simplifies the overall modeling pipeline while preserving the richness of speech information and maintaining inference efficiency. Empirical results demonstrate that SLED achieves strong performance in both zero-shot and streaming speech synthesis, showing its potential for broader applications in general-purpose speech language models.
[21.05.2025 00:56] Response: {
  "desc": "SLED - это новый подход к моделированию речи, кодирующий звуковые волны в последовательности непрерывных латентных представлений и моделирующий их авторегрессивно с использованием целевой функции энергетического расстояния. Метод позволяет избежать ошибок дискретизации и упрощает архитектуру модели по сравнению с существующими языковыми моделями речи. SLED сохраняет богатство речевой информации и обеспечивает эффективный вывод. Эмпирические результаты показывают высокую производительность SLED в задачах синтеза речи без предварительного обучения и в потоковом режиме.",
  "emoji": "🗣️",
  "title": "SLED: Непрерывное моделирование речи без дискретизации"
}
[21.05.2025 00:56] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce SLED, an alternative approach to speech language modeling by encoding speech waveforms into sequences of continuous latent representations and modeling them autoregressively using an energy distance objective. The energy distance offers an analytical measure of the distributional gap by contrasting simulated and target samples, enabling efficient training to capture the underlying continuous autoregressive distribution. By bypassing reliance on residual vector quantization, SLED avoids discretization errors and eliminates the need for the complicated hierarchical architectures common in existing speech language models. It simplifies the overall modeling pipeline while preserving the richness of speech information and maintaining inference efficiency. Empirical results demonstrate that SLED achieves strong performance in both zero-shot and streaming speech synthesis, showing its potential for broader applications in general-purpose speech language models."

[21.05.2025 00:56] Response: ```python
["AUDIO"]
```
[21.05.2025 00:56] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce SLED, an alternative approach to speech language modeling by encoding speech waveforms into sequences of continuous latent representations and modeling them autoregressively using an energy distance objective. The energy distance offers an analytical measure of the distributional gap by contrasting simulated and target samples, enabling efficient training to capture the underlying continuous autoregressive distribution. By bypassing reliance on residual vector quantization, SLED avoids discretization errors and eliminates the need for the complicated hierarchical architectures common in existing speech language models. It simplifies the overall modeling pipeline while preserving the richness of speech information and maintaining inference efficiency. Empirical results demonstrate that SLED achieves strong performance in both zero-shot and streaming speech synthesis, showing its potential for broader applications in general-purpose speech language models."

[21.05.2025 00:56] Response: ```python
[]
```
[21.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SLED is a new method for speech language modeling that transforms speech waveforms into continuous latent representations. It uses an autoregressive approach combined with an energy distance objective to effectively measure and minimize the differences between simulated and actual speech samples. This method avoids common issues found in traditional models, such as discretization errors and complex architectures, leading to a simpler and more efficient modeling process. The results show that SLED performs well in generating speech, even in zero-shot and streaming scenarios, indicating its versatility for various speech applications.","title":"SLED: Simplifying Speech Modeling with Continuous Representations"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SLED is a new method for speech language modeling that transforms speech waveforms into continuous latent representations. It uses an autoregressive approach combined with an energy distance objective to effectively measure and minimize the differences between simulated and actual speech samples. This method avoids common issues found in traditional models, such as discretization errors and complex architectures, leading to a simpler and more efficient modeling process. The results show that SLED performs well in generating speech, even in zero-shot and streaming scenarios, indicating its versatility for various speech applications.', title='SLED: Simplifying Speech Modeling with Continuous Representations'))
[21.05.2025 00:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"我们介绍了一种名为SLED的语音语言建模新方法，它通过将语音波形编码为连续潜在表示序列，并使用能量距离目标进行自回归建模。能量距离提供了一种分析性度量，用于对比模拟样本和目标样本之间的分布差异，从而实现高效训练，捕捉潜在的连续自回归分布。SLED避免了对残差向量量化的依赖，消除了离散化误差，并简化了现有语音语言模型中常见的复杂层次结构。实证结果表明，SLED在零样本和流式语音合成中表现出色，显示出其在通用语音语言模型中的广泛应用潜力。","title":"SLED：简化语音建模的新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='我们介绍了一种名为SLED的语音语言建模新方法，它通过将语音波形编码为连续潜在表示序列，并使用能量距离目标进行自回归建模。能量距离提供了一种分析性度量，用于对比模拟样本和目标样本之间的分布差异，从而实现高效训练，捕捉潜在的连续自回归分布。SLED避免了对残差向量量化的依赖，消除了离散化误差，并简化了现有语音语言模型中常见的复杂层次结构。实证结果表明，SLED在零样本和流式语音合成中表现出色，显示出其在通用语音语言模型中的广泛应用潜力。', title='SLED：简化语音建模的新方法'))
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#open_source", "#transfer_learning", "#training", "#small_models"], "emoji": "🧠", "ru": {"title": "Эффективное обучение малых языковых моделей с помощью низкоранговых проекций", "desc": "Статья представляет новый метод предобучения малых языковых моделей (SLM) под названием Low-Rank
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#science", "#multimodal", "#interpretability", "#inference"], "emoji": "🔍", "ru": {"title": "Повышение точности LLM в обнаружении ошибок через структурированную настройку контекста", "desc": "Это исследование изучает структурированный подход к настройке контекста больших языковых мо
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#security", "#data", "#hallucinations", "#rag", "#benchmark"], "emoji": "🛡️", "ru": {"title": "Точное распознавание техник злоумышленников с минимумом данных", "desc": "TechniqueRAG - это новая система для идентификации техник противников в текстах по кибербезопасности. Она использу
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#interpretability", "#agents", "#multimodal", "#agi", "#architecture", "#reasoning"], "emoji": "🧠", "ru": {"title": "GUM: универсальная модель пользователя для создания интуитивных интерфейсов будущего", "desc": "Статья представляет архитектуру общей модели пользователя (GUM), котор
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#reasoning", "#data", "#science", "#multimodal", "#interpretability", "#architecture"], "emoji": "🔬", "ru": {"title": "PWP: Новый подход к критическому анализу научных работ с помощью LLM", "desc": "Статья представляет новый метод инженерии промптов под названием Persistent Workflow
[21.05.2025 00:56] Using data from previous issue: {"categories": ["#data", "#healthcare", "#low_resource", "#dataset"], "emoji": "🗣️", "ru": {"title": "Эффективное разрешение омографов для G2P конверсии в малоресурсных языках", "desc": "Статья посвящена проблеме разрешения омографов в задаче преобразования графем в фонемы (G2P) для малоресурсных яз
[21.05.2025 00:56] Loading Chinese text from previous data.
[21.05.2025 00:56] Renaming data file.
[21.05.2025 00:56] Renaming previous data. hf_papers.json to ./d/2025-05-21.json
[21.05.2025 00:56] Saving new data file.
[21.05.2025 00:56] Generating page.
[21.05.2025 00:56] Renaming previous page.
[21.05.2025 00:56] Renaming previous data. index.html to ./d/2025-05-21.html
[21.05.2025 00:56] [Experimental] Generating Chinese page for reading.
[21.05.2025 00:56] Chinese vocab [{'word': '范式', 'pinyin': 'fàn shì', 'trans': 'paradigm'}, {'word': 'Chain-of-Model', 'pinyin': 'Chèin-òf-Módel', 'trans': 'Chain-of-Model'}, {'word': '因果关系', 'pinyin': 'yīn guǒ guān xì', 'trans': 'causal relationship'}, {'word': '隐藏状态', 'pinyin': 'yǐn cáng zhuàng tài', 'trans': 'hidden state'}, {'word': '链式结构', 'pinyin': 'liàn shì jiégòu', 'trans': 'chain structure'}, {'word': '扩展效率', 'pinyin': 'kuò zhǎn xiào lǜ', 'trans': 'scalability'}, {'word': '部署', 'pinyin': 'bù shǔ', 'trans': 'deployment'}, {'word': '灵活性', 'pinyin': 'líng huó xìng', 'trans': 'flexibility'}, {'word': 'Chain-of-Representation', 'pinyin': 'Chèin-òf-Rěprizen téi shēn', 'trans': 'Chain-of-Representation'}, {'word': '子表示', 'pinyin': 'zǐ biǎo shì', 'trans': 'sub-representation'}, {'word': '组合', 'pinyin': 'zǔ hé', 'trans': 'combination'}, {'word': '前序链', 'pinyin': 'qián xù liàn', 'trans': 'preceding chain'}, {'word': '弹性推理', 'pinyin': 'tán xìng tuī lǐ', 'trans': 'elastic inference'}, {'word': 'Chain-of-Language-Model', 'pinyin': 'Chèin-òf-Lánggù Módel', 'trans': 'Chain-of-Language-Model'}, {'word': 'KV共享机制', 'pinyin': 'KV gòng xiǎng jī zhì', 'trans': 'KV sharing mechanism'}, {'word': 'CoLM-Air', 'pinyin': 'CoLM-Éir', 'trans': 'CoLM-Air'}, {'word': '扩展功能', 'pinyin': 'kuò zhǎn gōng néng', 'trans': 'extended functionality'}, {'word': 'Transformer', 'pinyin': 'Tèinshèin fōměi', 'trans': 'Transformer'}]
[21.05.2025 00:56] Renaming previous Chinese page.
[21.05.2025 00:56] Renaming previous data. zh.html to ./d/2025-05-20_zh_reading_task.html
[21.05.2025 00:56] Writing Chinese reading task.
[21.05.2025 00:56] Writing result.
[21.05.2025 00:56] Renaming log file.
[21.05.2025 00:56] Renaming previous data. log.txt to ./logs/2025-05-21_last_log.txt
