[14.10.2024 04:15] Get feed.
[14.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08565
[14.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.08261
[14.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07133
[14.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.06456
[14.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.09008
[14.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.09009
[14.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.07035
[14.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.08391
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 0. The salient multimodal capabilities and interactive experience of GPT-4o highlight its critical role in practical applications, yet it lacks a high-performing open-source counterpart. In this paper, we introduce Baichuan-Omni, the first open-source 7B Multimodal Large Language Model (MLLM) adept at ...
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 1. Diffusion models, such as Stable Diffusion, have made significant strides in visual generation, yet their paradigm remains fundamentally different from autoregressive language models, complicating the development of unified language-vision models. Recent efforts like LlamaGen have attempted autoregr...
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 2. Recent advancements in generation models have showcased remarkable capabilities in generating fantastic content. However, most of them are trained on proprietary high-quality data, and some models withhold their parameters and only provide accessible application programming interfaces (APIs), limiti...
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 3. Large vision language models (VLMs) combine large language models with vision encoders, demonstrating promise across various tasks. However, they often underperform in task-specific applications due to domain gaps between pre-training and fine-tuning. We introduce VITask, a novel framework that enha...
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 4. Large language models (LLMs) like GPT-4, PaLM, and LLaMA have shown significant improvements in various reasoning tasks. However, smaller models such as Llama-3-8B and DeepSeekMath-Base still struggle with complex mathematical reasoning because they fail to effectively identify and correct reasoning...
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 5. Generating high-quality 3D assets from textual descriptions remains a pivotal challenge in computer graphics and vision research. Due to the scarcity of 3D data, state-of-the-art approaches utilize pre-trained 2D diffusion priors, optimized through Score Distillation Sampling (SDS). Despite progress...
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 6. Large Language Models (LLMs) demonstrate impressive capabilities across various domains, including role-playing, creative writing, mathematical reasoning, and coding. Despite these advancements, LLMs still encounter challenges with length control, frequently failing to adhere to specific length cons...
[14.10.2024 04:15] ********************************************************************************
[14.10.2024 04:15] Abstract 7. Inference with transformer-based language models begins with a prompt processing step. In this step, the model generates the first output token and stores the KV cache needed for future generation steps. This prompt processing step can be computationally expensive, taking 10s of seconds or more for ...
[14.10.2024 04:15] Read previous papers.
[14.10.2024 04:15] Generating reviews via LLM API.
[14.10.2024 04:15] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Baichuan-Omni - –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã—Ç—É—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ 7 –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ú–æ–¥–µ–ª—å —Å–ø–æ—Å–æ–±–Ω–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ, –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –æ–ø—ã—Ç. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Å—Ö–µ–º—É –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á
[14.10.2024 04:15] Querying the API.
[14.10.2024 04:15] Got response. {
  "desc": "Meissonic - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –ø–æ–¥—Ö–æ–¥–µ masked image modeling (MIM). –û–Ω–∞ —Å–æ—á–µ—Ç–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Å–ª–æ–≤–∏—è —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ MIM. Meissonic –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ, –º–∏–∫—Ä–æ-—É—Å–ª–æ–≤–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–æ–∫ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π —á–µ–ª–æ–≤–µ–∫–∞ –∏ —Å–ª–æ–∏ —Å–∂–∞—Ç–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ú–æ–¥–µ–ª—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ –∏–ª–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤—Ä–æ–¥–µ SDXL.",
  "tags": [
    "#masked_image_modeling",
    "#text_to_image",
    "#high_resolution_generation"
  ],
  "categories": [
    "#cv",
    "#multimodal",
    "#generative",
    "#benchmark",
    "#code"
  ],
  "emoji": "üé®",
  "title": "Meissonic: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å MIM"
}
[14.10.2024 04:15] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç EvolveDirector - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É, —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ–π —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã. –ê–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç API —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ä —Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –î–ª—è
[14.10.2024 04:15] Querying the API.
[14.10.2024 04:15] Got response. {
  "desc": "VITask - –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (VLM) –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∑–∞–¥–∞—á–∞–º. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –æ—Ç–≤–µ—Ç–æ–≤. VITask –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–¥–∞—á, —á—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å VLM. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ 12 –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ VITask –Ω–∞–¥ –æ–±—ã—á–Ω—ã–º–∏ VLM –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.",
  "tags": ["#VITask", "#–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è_–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "#–∞–¥–∞–ø—Ç–∞—Ü–∏—è_–º–æ–¥–µ–ª–µ–π"],
  "categories": ["#multimodal", "#nlp", "#cv", "#benchmark", "#code"],
  "emoji": "üî¨",
  "title": "VITask: –ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ —Ä–∞–∑—Ä—ã–≤–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ–º –∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö"
}
[14.10.2024 04:15] Using data from previous issue: {"desc": "SuperCorrect - —ç—Ç–æ –Ω–æ–≤—ã–π –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –º–∞–ª–µ–Ω—å–∫–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å-—É—á–∏—Ç–µ–ª—è –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –º–µ–Ω—å—à–µ–π –º–æ–¥–µ–ª–∏-—É—á–µ–Ω–∏–∫–∞. –ù–∞ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–ø–µ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ —à–∞–±–ª–æ–Ω—ã –º
[14.10.2024 04:15] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π - Semantic Score Distillation Sampling (SemanticSDS). –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤. SemanticSDS —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —ç
[14.10.2024 04:15] Querying the API.
[14.10.2024 04:15] Got response. {
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM). –û–Ω–∏ –≤–≤–æ–¥—è—Ç PositionID Prompting –∏ PositionID Fine-Tuning –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–π –æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π. –¢–∞–∫–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –º–µ—Ç–æ–¥ PositionID CP Prompting –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—Å—Ç–∞–≤–∫–∏. –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –¥–≤–∞ –Ω–æ–≤—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–ª–∏–Ω—ã –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è-–≤—Å—Ç–∞–≤–∫–∏.",
  "tags": ["#–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ_–≤–Ω–µ–¥—Ä–µ–Ω–∏–µ", "#–∫–æ–Ω—Ç—Ä–æ–ª—å_–¥–ª–∏–Ω—ã_—Ç–µ–∫—Å—Ç–∞", "#–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ_–≤—Å—Ç–∞–≤–∫–∞_–≤_LLM"],
  "categories": ["#nlp", "#benchmark", "#rlhf"],
  "emoji": "üìè",
  "title": "–¢–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –≤ LLM —Å –ø–æ–º–æ—â—å—é –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–π –æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω–æ—Å—Ç–∏"
}
[14.10.2024 04:15] Querying the API.
[14.10.2024 04:15] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º KV Prediction –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ KV-–∫—ç—à–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ (TTFT). –ê–≤—Ç–æ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ 15-50% –Ω–∞ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö TriviaQA –∏ –¥–æ 30% –Ω–∞ HumanEval –ø—Ä–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –±—é–¥–∂–µ—Ç–µ FLOPS –¥–ª—è TTFT. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ CPU Apple M2 Pro –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç —É—Å–∫–æ—Ä–µ–Ω–∏–µ TTFT –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏.",
  "tags": ["#KVPrediction", "#TimeToFirstToken", "#EdgeInference"],
  "categories": ["#nlp", "#benchmark", "#code", "#rag", "#dataset"],
  "emoji": "‚ö°",
  "title": "KV Prediction: –º–æ–ª–Ω–∏–µ–Ω–æ—Å–Ω—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"
}
[14.10.2024 04:15] Renaming data file.
[14.10.2024 04:15] Renaming previous data. hf_papers.json to 2024-10-13_hf_papers.json
[14.10.2024 04:15] Saving new data file.
[14.10.2024 04:15] Generating page.
[14.10.2024 04:15] Renaming previous page.
[14.10.2024 04:15] Renaming previous data. index.html to 2024-10-13_hf_papers.html
[14.10.2024 04:15] Writing result.
[14.10.2024 04:15] Renaming log file.
[14.10.2024 04:15] Renaming previous data. log.txt to 2024-10-13_last_log.txt
