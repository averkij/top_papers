[14.10.2024 07:10] Get feed.
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08565
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08261
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.06456
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07133
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.09008
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.07035
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.09009
[14.10.2024 07:10] Extract page data from URL. URL: https://huggingface.co/papers/2410.08102
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08815
[14.10.2024 07:10] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08391
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 0. The salient multimodal capabilities and interactive experience of GPT-4o highlight its critical role in practical applications, yet it lacks a high-performing open-source counterpart. In this paper, we introduce Baichuan-Omni, the first open-source 7B Multimodal Large Language Model (MLLM) adept at ...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 1. Diffusion models, such as Stable Diffusion, have made significant strides in visual generation, yet their paradigm remains fundamentally different from autoregressive language models, complicating the development of unified language-vision models. Recent efforts like LlamaGen have attempted autoregr...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 2. Large vision language models (VLMs) combine large language models with vision encoders, demonstrating promise across various tasks. However, they often underperform in task-specific applications due to domain gaps between pre-training and fine-tuning. We introduce VITask, a novel framework that enha...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 3. Recent advancements in generation models have showcased remarkable capabilities in generating fantastic content. However, most of them are trained on proprietary high-quality data, and some models withhold their parameters and only provide accessible application programming interfaces (APIs), limiti...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 4. Large language models (LLMs) like GPT-4, PaLM, and LLaMA have shown significant improvements in various reasoning tasks. However, smaller models such as Llama-3-8B and DeepSeekMath-Base still struggle with complex mathematical reasoning because they fail to effectively identify and correct reasoning...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 5. Large Language Models (LLMs) demonstrate impressive capabilities across various domains, including role-playing, creative writing, mathematical reasoning, and coding. Despite these advancements, LLMs still encounter challenges with length control, frequently failing to adhere to specific length cons...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 6. Generating high-quality 3D assets from textual descriptions remains a pivotal challenge in computer graphics and vision research. Due to the scarcity of 3D data, state-of-the-art approaches utilize pre-trained 2D diffusion priors, optimized through Score Distillation Sampling (SDS). Despite progress...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 7. Efficient data selection is crucial to accelerate the pretraining of large language models (LLMs). While various methods have been proposed to enhance data efficiency, limited research has addressed the inherent conflicts between these approaches to achieve optimal data selection for LLM pretraining...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 8. Retrieval-augmented generation (RAG) is a key means to effectively enhance large language models (LLMs) in many knowledge-based tasks. However, existing RAG methods struggle with knowledge-intensive reasoning tasks, because useful information required to these tasks are badly scattered. This charact...
[14.10.2024 07:10] ********************************************************************************
[14.10.2024 07:10] Abstract 9. Inference with transformer-based language models begins with a prompt processing step. In this step, the model generates the first output token and stores the KV cache needed for future generation steps. This prompt processing step can be computationally expensive, taking 10s of seconds or more for ...
[14.10.2024 07:10] Read previous papers.
[14.10.2024 07:10] Generating reviews via LLM API.
[14.10.2024 07:10] Using data from previous issue: {"desc": "Статья представляет Baichuan-Omni - первую открытую мультимодальную языковую модель на 7 миллиардов параметров. Модель способна одновременно обрабатывать изображения, видео, аудио и текст, обеспечивая продвинутый интерактивный опыт. Авторы предлагают эффективную схему мультимодального обуч
[14.10.2024 07:10] Using data from previous issue: {"desc": "Meissonic - это новая модель для генерации изображений по текстовому описанию, основанная на подходе masked image modeling (MIM). Она сочетает архитектурные инновации, продвинутые стратегии позиционного кодирования и оптимизированные условия сэмплирования для улучшения производительности и
[14.10.2024 07:10] Using data from previous issue: {"desc": "VITask - новый фреймворк для улучшения адаптации крупных визуально-языковых моделей (VLM) к конкретным задачам. Он использует три стратегии: примерное подсказывание, выравнивание распределения ответов и контрастную настройку ответов. VITask интегрирует специализированные модели для конкрет
[14.10.2024 07:10] Using data from previous issue: {"desc": "Статья представляет EvolveDirector - фреймворк для обучения модели генерации изображений по тексту, сопоставимой с продвинутыми моделями, но используя только общедоступные ресурсы. Авторы используют API существующих моделей для получения пар текст-изображение и обучения базовой модели. Для
[14.10.2024 07:10] Using data from previous issue: {"desc": "SuperCorrect - это новый двухэтапный фреймворк для улучшения математических рассуждений маленьких языковых моделей. Он использует большую модель-учителя для руководства и коррекции процессов рассуждения и рефлексии меньшей модели-ученика. На первом этапе извлекаются иерархические шаблоны м
[14.10.2024 07:10] Using data from previous issue: {"desc": "Исследователи предлагают новые методы для улучшения контроля длины текста в больших языковых моделях (LLM). Они вводят PositionID Prompting и PositionID Fine-Tuning для повышения позиционной осведомленности моделей. Также представлен метод PositionID CP Prompting для выполнения операций ко
[14.10.2024 07:10] Using data from previous issue: {"desc": "В статье представлен новый подход к генерации 3D-контента на основе текстовых описаний - Semantic Score Distillation Sampling (SemanticSDS). Метод использует семантические эмбеддинги для улучшения выразительности и точности композиционной генерации 3D-объектов. SemanticSDS трансформирует э
[14.10.2024 07:10] Querying the API.
[14.10.2024 07:10] Got response. {
  "desc": "Представлен новый механизм многоагентного совместного отбора данных для предобучения больших языковых моделей (LLM). Каждый метод отбора данных выступает в роли независимого агента, а консоль агентов динамически интегрирует информацию от всех агентов в процессе обучения LLM. Экспериментальные результаты показывают значительное повышение эффективности использования данных и ускорение сходимости при обучении LLM. Предложенный подход достигает среднего прироста производительности в 10.5% по сравнению с современными методами на нескольких эталонных тестах языковых моделей.",
  "tags": ["#многоагентный_отбор_данных", "#эффективность_предобучения", "#оптимизация_LLM"],
  "categories": ["#nlp", "#dataset", "#benchmark"],
  "emoji": "🤖",
  "title": "Многоагентный подход к оптимизации данных для LLM"
}
[14.10.2024 07:10] Using data from previous issue: {"desc": "StructRAG - новый фреймворк для улучшения работы больших языковых моделей в задачах, требующих интенсивного использования знаний. Он преодолевает ограничения существующих методов RAG, структурируя исходную информацию оптимальным для конкретной задачи образом. StructRAG идентифицирует наибо
[14.10.2024 07:10] Using data from previous issue: {"desc": "Статья представляет новый метод под названием KV Prediction для ускорения вывода трансформерных языковых моделей. Метод использует вспомогательную модель для аппроксимации KV-кэша основной модели, что значительно сокращает время до первого токена (TTFT). Авторы демонстрируют улучшение точн
[14.10.2024 07:10] Renaming data file.
[14.10.2024 07:10] Renaming previous data. hf_papers.json to 2024-10-13_hf_papers.json
[14.10.2024 07:10] Saving new data file.
[14.10.2024 07:10] Generating page.
[14.10.2024 07:10] Renaming previous page.
[14.10.2024 07:10] Renaming previous data. index.html to 2024-10-13_hf_papers.html
[14.10.2024 07:10] Writing result.
[14.10.2024 07:10] Renaming log file.
[14.10.2024 07:10] Renaming previous data. log.txt to 2024-10-13_last_log.txt
