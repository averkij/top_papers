[11.02.2026 08:41] Read previous papers.
[11.02.2026 08:41] Generating top page (month).
[11.02.2026 08:41] Writing top page (month).
[11.02.2026 09:45] Read previous papers.
[11.02.2026 09:45] Get feed.
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05400
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09856
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09082
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10063
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08234
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09443
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10090
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08426
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07035
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10104
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09084
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04208
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07022
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10102
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08847
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06820
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09849
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10098
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09823
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07153
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10116
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09024
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08382
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08344
[11.02.2026 09:45] Extract page data from URL. URL: https://huggingface.co/papers/2602.09662
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09439
[11.02.2026 09:45] Extract page data from URL. URL: https://huggingface.co/papers/2602.09268
[11.02.2026 09:45] Extract page data from URL. URL: https://huggingface.co/papers/2602.06161
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05435
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02464
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08503
[11.02.2026 09:45] Extract page data from URL. URL: https://huggingface.co/papers/2602.09924
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07839
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07276
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01725
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2601.21235
[11.02.2026 09:45] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04908
[11.02.2026 09:45] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.02.2026 09:45] No deleted papers detected.
[11.02.2026 09:45] Downloading and parsing papers (pdf, html). Total: 37.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.05400.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.05400.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.05400.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09856.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09856.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09856.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09082.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09082.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09082.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.10063.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.10063.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.10063.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.08234.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.08234.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.08234.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09443.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09443.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09443.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.10090.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.10090.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.10090.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.08426.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.08426.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.08426.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.07035.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.07035.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.07035.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.10104.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.10104.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.10104.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09084.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09084.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09084.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.04208.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.04208.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.04208.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.07022.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.07022.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.07022.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.10102.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.10102.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.10102.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.08847.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.08847.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.08847.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.06820.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.06820.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.06820.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09849.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09849.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09849.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.10098.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.10098.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.10098.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09823.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09823.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09823.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.07153.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.07153.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.07153.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.10116.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.10116.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.10116.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09024.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09024.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09024.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.08382.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.08382.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.08382.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.08344.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.08344.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.08344.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09662.
[11.02.2026 09:45] Downloading paper 2602.09662 from https://arxiv.org/pdf/2602.09662v1...
[11.02.2026 09:45] Extracting affiliations from text.
[11.02.2026 09:45] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution Deyang Jiang * 1 Jing Huang * 1 Xuanle Zhao * 1 Lei Chen 1 Liming Zheng 1 Fanfan Liu 1 Haibo Qiu 1 Peng Shi 1 Zhixiong Zeng (cid:66) "
[11.02.2026 09:45] Response: ```python
[]
```
[11.02.2026 09:45] Extracting affiliations from text.
[11.02.2026 09:45] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution Deyang Jiang * 1 Jing Huang * 1 Xuanle Zhao * 1 Lei Chen 1 Liming Zheng 1 Fanfan Liu 1 Haibo Qiu 1 Peng Shi 1 Zhixiong Zeng (cid:66)1. Introduction 6 2 0 2 0 1 ] . [ 1 2 6 6 9 0 . 2 0 6 2 : r Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning, which requires more sophisticated data collection. In reality, the exploration process of CUA across apps/desktops/web pages typically follows tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (i.e., trajectory difficulty) and breadth (i.e., trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUADPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA. *Equal contribution 1Meituan, Beijing, China. Correspondence to: Zhixiong Zeng <zengzhixiong@meituan.com>. Preprint. February 11, 2026. 1 Computer-Use Agents (CUAs) represent paradigm shift towards general-purpose digital agents, capable of perceiving and interacting with Graphical User Interfaces (GUIs) in human-like manner (OpenAI, 2025). Leveraging the emergent capabilities of large Vision-Language Models (VLMs) (Bai et al., 2025; Comanici et al., 2025), these agents process high-resolution visual inputs to execute intricate instructionfollowing tasks. The field has been significantly shaped by proprietary frontier models such as Gemini (Comanici et al., 2025) and Claude (Anthropic, 2025), which have demonstrated exceptional proficiency in complex agentic workflows. Concurrently, open-source initiatives are accelerating efforts to scale CUA models and data pipelines to bridge the gap with proprietary systems. Representative models (Qin et al., 2025; Ye et al., 2025; Zeng et al., 2025; Sun et al., 2024) have successfully scaled capabilities across desktop, mobile, and web platforms, underscoring the immense potential for generalized digital intelligence. However, distinct from the rapid scaling of model parameters, scaling high-quality training data incurs significantly higher costs and complexity. Although recent works (Cheng et al., 2024a; Xie et al., 2025; Chai et al., 2024; Huang et al., 2025) have successfully scaled GUI grounding datasets, these efforts focus primarily on static element recognition. In contrast, efficiently scaling long-horizon planning trajectories necessitates temporal reasoning and dynamic interaction, remaining largely unexplored challenge. To address this challenge, recent CUA methods like OpenCUA (Wang et al., 2025) and ScaleCUA (Liu et al., 2025) collect human computer-use demonstrations or human expert annotations to construct GUI trajectories. Unfortunately, existing methods often rely on necessary human annotations, making it difficult to scale effectively to large-scale trajectory synthesis. As result, open-source trajectories currently available in this field remain very scarce. Efficiently scaling GUI trajectory requires addressing two key challenges: step redundancy and trajectory diversity. Step redundancy intensifies with increasing trajectory scale, as different app/desktop/webpage trajectories inevitably repeat the exploration of early functional entry points. TrajecTreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution tory diversity depends primarily on the distillation model in automated trajectory synthesis, as the models inherent bias favors high-frequency exploration behaviors, potentially leading to insufficiently diverse and long-tail trajectories. In this paper, we devise an efficient way to scale GUI automation by eliminating step redundancy through organizing large-scale trajectories into tree structure and improving trajectory diversity through world knowledge guidance. Thus we propose TreeCUA, novel data synthesis framework of tree-structured verifiable evolution, and design training recipe of two-stage SFT protocol for establishing foundational and cognitive capabilities. To this end, we develop an automated multi-agent collaborative framework to collect tree-structured verifiable synthesis trajectories, including an exploration agent, verification agent, summary agent and an evaluation agent to explore the environment, verify actions, summarize trajectories, and evaluate quality. To achieve efficiency and scalability, we devise novel tree-based topology to store and reuse intermediate exploration nodes. Moreover, we design an adaptive exploration algorithm to balance trajectory depth (difficulty) and breadth (diversity) within the tree exploration, augmented by world knowledge guidance and global memory backtracking to strictly filter low-quality generations. In particular, leveraging the rich tree-structured data, we naturally extended TreeCUA to TreeCUA-DPO through reinforcement learning. By utilizing the branching information from adjacent trajectories as distinct preference pairs, this method significantly enhances the model planning capabilities. Experimental results on OSWorld (Xie et al., 2024) and out-of-distribution (OOD) tasks demonstrate that both TreeCUA and TreeCUADPO significantly improve task success rates in online environments, while also exhibiting strong generalization capabilities. In conclusion, our contributions are listed as follows We introduce tree"
[11.02.2026 09:45] Mistral response. {"id": "87e1d49f53ab4c0e8487fe105ca32d4e", "created": 1770803151, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1376, "total_tokens": 1390, "completion_tokens": 14, "prompt_tokens_details": {"cached_tokens": 0}}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Meituan, Beijing, China\"]\n```"}}]}
[11.02.2026 09:45] Response: ```python
["Meituan, Beijing, China"]
```
[11.02.2026 09:45] Deleting PDF ./assets/pdf/2602.09662.pdf.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09439.
[11.02.2026 09:45] Extra JSON file exists (./assets/json/2602.09439.json), skip PDF parsing.
[11.02.2026 09:45] Paper image links file exists (./assets/img_data/2602.09439.json), skip HTML parsing.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.09268.
[11.02.2026 09:45] Downloading paper 2602.09268 from https://arxiv.org/pdf/2602.09268v1...
[11.02.2026 09:45] Extracting affiliations from text.
[11.02.2026 09:45] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Published as conference paper at ICLR Nikita Starodubcev1 Daniil Pakhomov2 Zongze Wu2 Yuchen Liu2 Zhonghao Wang2 Yuqian Zhou2 Zhe Lin2 Dmitry Baranchuk1 Ilya Drobyshevskiy1 6 2 0 2 9 ] . [ 1 8 6 2 9 0 . 2 0 6 2 : r 1Yandex Research, 2Adobe Research https://github.com/quickjkee/modulation-guidance "
[11.02.2026 09:45] Response: ```python
['Yandex Research', 'Adobe Research']
```
[11.02.2026 09:45] Deleting PDF ./assets/pdf/2602.09268.pdf.
[11.02.2026 09:45] Success.
[11.02.2026 09:45] Downloading and parsing paper https://huggingface.co/papers/2602.06161.
[11.02.2026 09:45] Downloading paper 2602.06161 from https://arxiv.org/pdf/2602.06161v1...
[11.02.2026 09:46] Extracting affiliations from text.
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding Yanzheng Xiang * 1 Lan Wei * 2 Yizhen Yao 1 Qinglin Zhu 1 Hanqi Yan 1 Chen Jin 3 Philip Alexander Teare 3 Dandan Zhang 2 Lin Gui 1 Amrutha Saseendran 3 Yulan He 1 4 6 2 0 2 5 ] . [ 1 1 6 1 6 0 . 2 0 6 2 : r a "
[11.02.2026 09:46] Response: ```python
[]
```
[11.02.2026 09:46] Extracting affiliations from text.
[11.02.2026 09:46] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding Yanzheng Xiang * 1 Lan Wei * 2 Yizhen Yao 1 Qinglin Zhu 1 Hanqi Yan 1 Chen Jin 3 Philip Alexander Teare 3 Dandan Zhang 2 Lin Gui 1 Amrutha Saseendran 3 Yulan He 1 4 6 2 0 2 5 ] . [ 1 1 6 1 6 0 . 2 0 6 2 : r aParallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality. 1. Introduction Autoregressive language models (Abhimanyu Dubey et al., 2024; Brown et al., 2020; Radford et al., 2019; Radford & *Equal contribution 1Kings College London, UK 2Imperial College London, UK 3Centre for AI, Data Science & Artificial Intelligence, BioPharmaceuticals R&D, AstraZeneca, UK 4The Alan Turing Institute, UK. Correspondence to: Yulan He <yulan.he@kcl.ac.uk>. Preprint. February 9, 2026. Figure 1. Flip-flop behaviour on HumanEval for Dream-Instruct7B and LLaDA-Instruct-8B under two revocable baselines (Saber, WINO) and ours (COVER). Unlike baselines that repeatedly ReMask, COVER uses context-preserving in-place verification to reduce oscillatory revisions while maintaining generation quality. Narasimhan, 2018) generate text token by token and remain the dominant paradigm for high quality generation. Yet this sequential decoding is persistent inference bottleneck, and early errors can propagate through the remainder of the output (Valmeekam et al., 2023; Stechly et al., 2023). Diffusion large language models (dLLMs) offer an appealing alternative: they denoise an initially masked sequence and can, in principle, update many positions in parallel (Li et al., 2022b). In practice, however, aggressive parallel unmasking often harms generation quality (Hong et al., 2025; Dong et al., 2025), so dLLMs frequently revert to conservative decoding that unmasks only one position per step, largely sacrificing the promised speed gains (Nie et al., 2025; Ye et al., 2025; Xie et al., 2025). Recent work attempts to bridge this gap with revocable parallel diffusion decoding. These methods draft multiple tokens in parallel and then revisit subset of previously unmasked positions using the newly available context, optionally revoking them by resetting to [MASK]. WINO (Hong et al., 2025) performs verification through an auxiliary shadow block, whereas Saber (Dong et al., 2025) triggers remasking based on confidence drops. Although revocation imStop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding proves robustness, existing verification mechanisms introduce substantial overhead. WINO increases effective sequence length and memory footprint, and both methods depend on explicit remasking, which replaces content tokens with [MASK] for all queries and can destabilise subsequent drafts, leading to slower net denoising progress. In this work, we highlight an inefficiency of revocable decoding that standard accuracy metrics do not capture. We observe flip-flop oscillations, where position is remasked and later re-unmasked to exactly the same token. Figure 1 shows that such oscillations occur frequently under existing revocable baselines across dLLMs, indicating that many verification actions consume iterations without producing correction. This creates two coupled inefficiencies. First, remasking replaces content bearing embedding with [MASK], weakening the conditioning context used by other positions during parallel drafting. Second, each ineffective remask spends future unmask budget merely to restore the same token, reducing net denoising progress under any fixed step or unmask budget. To solve this, we propose COVER (Cache Override Verification for Efficient Revision), context-preserving single-pass verification mechanism for revocable parallel diffusion decoding. At each step, COVER rechecks small seed set by masking these positions in the input while overriding their KV states with cached values from the previous step. This dual view computation keeps the drafting context for all non seed queries unchanged, yet enables faithful leave one out verification on the seeds via diagonal correction that removes self leakage. To make cache reuse reliable, COVER chooses seeds using stability aware score that trades off uncertainty against estimated influence on the remaining masked positions, adapts the verification token number per step, and updates verified positions by KEEP, REPLACE, or REMASK to avoid ineffective remasking cycles. Our contributions are as follows: We identify flip-flop oscillations as dominant inefficiency in revocable diffusion decoding and show how explicit remasking weakens drafting context and wastes the revision budget. We introduce an in place KV cache override verification mechanism with diagonal correction, enabling faithful leave-one-out checks and stable parallel drafting within single forward pass. We propose stability aware and adaptive seed selection that prioritises uncertain and influential positions while avoiding unstable cache reuse, enabling efficient multitoken verification. We show that COVER improves accuracy while substantially reducing decoding steps, yielding consis2 tent end-to-end speedups of up to 11.64 (Dream-Ins7B), which supports reliable multi-token drafting via context-preserving in-place v"
[11.02.2026 09:46] Mistral response. {"id": "454b2497d3f741a5af756aa840687119", "created": 1770803163, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1459, "total_tokens": 1519, "completion_tokens": 60, "prompt_tokens_details": {"cached_tokens": 0}}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Kings College London, UK\",\n    \"Imperial College London, UK\",\n    \"Centre for AI, Data Science & Artificial Intelligence, BioPharmaceuticals R&D, AstraZeneca, UK\",\n    \"The Alan Turing Institute, UK\"\n]\n```"}}]}
[11.02.2026 09:46] Response: ```python
[
    "Kings College London, UK",
    "Imperial College London, UK",
    "Centre for AI, Data Science & Artificial Intelligence, BioPharmaceuticals R&D, AstraZeneca, UK",
    "The Alan Turing Institute, UK"
]
```
[11.02.2026 09:46] Deleting PDF ./assets/pdf/2602.06161.pdf.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.05435.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2602.05435.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2602.05435.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.02464.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2602.02464.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2602.02464.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.08503.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2602.08503.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2602.08503.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.09924.
[11.02.2026 09:46] Downloading paper 2602.09924 from https://arxiv.org/pdf/2602.09924v1...
[11.02.2026 09:46] Extracting affiliations from text.
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 1 ] . [ 1 4 2 9 9 0 . 2 0 6 2 : r Preprint. Work in Progress LLMS ENCODE THEIR FAILURES: PREDICTING SUCCESS FROM PRE-GENERATION ACTIVATIONS William Lugoloobi1,, Thomas Foster2, William Bankes3, Chris Russell1 1 Oxford Internet Institute, University of Oxford 2 FLAIR, University of Oxford 3 Department of Computer Science, University College London "
[11.02.2026 09:46] Response: ```python
[
    "Oxford Internet Institute, University of Oxford",
    "FLAIR, University of Oxford",
    "Department of Computer Science, University College London"
]
```
[11.02.2026 09:46] Deleting PDF ./assets/pdf/2602.09924.pdf.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.07839.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2602.07839.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2602.07839.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.07276.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2602.07276.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2602.07276.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.01725.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2602.01725.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2602.01725.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2601.21235.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2601.21235.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2601.21235.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Downloading and parsing paper https://huggingface.co/papers/2602.04908.
[11.02.2026 09:46] Extra JSON file exists (./assets/json/2602.04908.json), skip PDF parsing.
[11.02.2026 09:46] Paper image links file exists (./assets/img_data/2602.04908.json), skip HTML parsing.
[11.02.2026 09:46] Success.
[11.02.2026 09:46] Enriching papers with extra data.
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 0. OPUS is a dynamic data selection framework that improves pre-training efficiency by scoring data candidates based on optimizer-induced update projections in a stable proxy-derived target space, achieving superior performance with reduced computational overhead.  					AI-generated summary 				 As hig...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 1. Code2World enables autonomous GUI agents to predict next visual states through renderable code generation, achieving high visual fidelity and structural controllability while improving navigation performance.  					AI-generated summary 				 Autonomous GUI agents interact with environments by perceiv...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 2. UI-Venus-1.5 is a unified GUI agent with improved performance through mid-training stages, online reinforcement learning, and model merging techniques.  					AI-generated summary 				 GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving bo...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 3. A novel training-free framework called Chain of Mindset enables step-level adaptive mindset orchestration for large language models by integrating spatial, convergent, divergent, and algorithmic reasoning approaches.  					AI-generated summary 				 Human problem-solving is never the repetition of a ...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 4. SkillRL enables LLM agents to improve through hierarchical skill discovery and recursive policy evolution, achieving superior performance on complex tasks while reducing computational overhead.  					AI-generated summary 				 Large Language Model (LLM) agents have shown stunning results in complex t...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 5. Physics-oriented vision-language models leverage curriculum reinforcement learning and agentic augmentation to achieve state-of-the-art scientific reasoning performance while maintaining physical consistency through multimodal perception.  					AI-generated summary 				 The transition from symbolic ...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 6. Large language model agents trained in synthetic environments with code-driven simulations and database-backed state transitions demonstrate superior out-of-distribution generalization compared to traditional benchmark-specific approaches.  					AI-generated summary 				 Recent advances in large lan...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 7. Prism addresses inefficiencies in block-sparse attention for long-context LLM pre-filling by using a spectral-aware approach that improves block selection accuracy through energy-based temperature calibration.  					AI-generated summary 				 Block-sparse attention is promising for accelerating long-...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 8. Diffusion Large Language Models are optimized for search agents through enhanced reasoning capabilities and reduced latency via a parallel reasoning paradigm.  					AI-generated summary 				 Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by ...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 9. Sequence-level control-effect alignment enables structured latent action space learning for zero-shot action transfer in video world models.  					AI-generated summary 				 Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to ...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 10. Agent Banana addresses challenges in instruction-based image editing through a hierarchical framework with context folding and image layer decomposition for high-fidelity, multi-turn editing at ultra-high resolution.  					AI-generated summary 				 We study instruction-based image editing under prof...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 11. SCALE is a novel inference strategy for Vision-Language-Action models that jointly modulates visual perception and action based on self-uncertainty, improving robustness without additional training or multiple forward passes.  					AI-generated summary 				 Vision-Language-Action (VLA) models have e...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 12. Autoregressive models with diffusion loss outperform traditional diffusion models by effectively mitigating condition errors through patch denoising optimization and condition refinement using Optimal Transport theory.  					AI-generated summary 				 Recent studies have explored autoregressive model...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 13. VideoWorld 2 enables transferable knowledge learning from raw videos through a dynamic-enhanced Latent Dynamics Model that decouples action dynamics from visual appearance, achieving improved task performance and long-horizon reasoning in real-world applications.  					AI-generated summary 				 Lear...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 14. Multi-agent large language model systems face training instability in reinforcement learning due to global normalization mismatches, which is addressed by Dr. MAS through agent-specific advantage normalization and enhanced training stability.  					AI-generated summary 				 Multi-agent LLM systems e...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 15. ScaleEnv framework generates interactive environments from scratch to improve agent generalization through diverse domain scaling and verified task completion.  					AI-generated summary 				 Training generalist agents capable of adapting to diverse scenarios requires interactive environments for se...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 16. BagelVLA is a unified Vision-Language-Action model that integrates linguistic planning, visual forecasting, and action generation through residual flow guidance for improved manipulation tasks.  					AI-generated summary 				 Equipping embodied agents with the ability to reason about tasks, foresee ...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 17. VLA-JEPA is a JEPA-style pretraining framework that improves vision-language-action policy learning by using leakage-free state prediction in latent space, enhancing generalization and robustness in manipulation tasks.  					AI-generated summary 				 Pretraining Vision-Language-Action (VLA) policies...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 18. Covo-Audio is a 7B-parameter end-to-end large audio language model that processes continuous audio inputs and generates audio outputs, achieving state-of-the-art performance across speech-text modeling, spoken dialogue, and full-duplex voice interaction tasks through large-scale pretraining and post...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 19. A trajectory expansion framework called Anchor bootstraps scalable desktop supervision from seed demonstrations by identifying branch points and generating new trajectories through state-grounded task variants.  					AI-generated summary 				 End-to-end GUI agents for real desktop environments requi...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 20. SAGE is an agentic framework that automatically generates simulation-ready 3D environments for embodied AI by combining layout and object composition generators with evaluative critics for semantic plausibility and physical stability.  					AI-generated summary 				 Real-world data collection for em...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 21. Discrete tokenizers can match or exceed continuous methods when properly scaled, and a new masked Bit AutoRegressive modeling approach achieves state-of-the-art results with reduced computational costs.  					AI-generated summary 				 This paper challenges the dominance of continuous pipelines in vi...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 22. A cognitive-inspired framework for long-context language modeling uses chunk-wise compression and selective memory recall to improve efficiency and performance over traditional approaches.  					AI-generated summary 				 Large Language Models (LLMs) face significant challenges in long-context proces...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 23. Reinforcement learning with verifiable rewards is used to enhance parallel thinking in large reasoning models through outline-guided path exploration that reduces information redundancy and improves solution discovery.  					AI-generated summary 				 Parallel thinking has emerged as a new paradigm f...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 24. TreeCUA enables efficient GUI automation scaling through tree-structured trajectory organization and multi-agent collaboration, improving GUI planning capabilities via adaptive exploration and trajectory verification.  					AI-generated summary 				 Effectively scaling GUI automation is essential fo...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 25. A large-scale, high-quality, and fully open dataset for text-to-image fine-tuning is presented, featuring over 6 million text-image pairs with rigorous filtering for alignment and quality across multiple task combinations and visual styles.  					AI-generated summary 				 High-quality and open datas...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 26. Modulation-based text conditioning in diffusion transformers provides performance benefits when used as guidance for controllable generation rather than just as attention mechanisms.  					AI-generated summary 				 Diffusion transformers typically incorporate textual information via attention layers...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 27. COVER enables efficient parallel decoding for diffusion language models by implementing cache override verification that reduces unnecessary revisions and maintains output quality through stable drafting and attention view construction.  					AI-generated summary 				 Parallel diffusion decoding can...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 28. Stable Velocity framework addresses high-variance training in flow matching by identifying low-variance regimes and proposing variance-reduction techniques for improved training efficiency and sampling speed.  					AI-generated summary 				 While flow matching is elegant, its reliance on single-samp...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 29. Mixture of Factor Analyzers (MFA) provides a scalable, unsupervised approach for discovering complex, nonlinear structures in language model activation spaces by modeling local geometric structures through Gaussian regions and their covariance properties.  					AI-generated summary 				 Activation d...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 30. Octopus, an RL rollout augmentation framework, enables efficient self-correction learning in vision-language models through synthetic example generation and response masking strategies.  					AI-generated summary 				 Self-correction is essential for solving complex reasoning problems in vision-lang...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 31. LLMs' internal representations can predict problem difficulty and enable efficient inference routing that reduces costs while maintaining performance.  					AI-generated summary 				 Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require add...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 32. TodoEvolve enables autonomous synthesis and revision of task-specific planning architectures through a modular design space and multi-objective reinforcement learning optimization.  					AI-generated summary 				 Planning has become a central capability for contemporary agent systems in navigating c...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 33. STEER2ADAPT is a lightweight framework that adapts large language models by composing steering vectors from reusable semantic prior subspaces, enabling efficient and flexible task adaptation through linear combinations of basis vectors.  					AI-generated summary 				 Activation steering has emerged...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 34. SafePred is a predictive guardrail framework for computer-using agents that uses risk prediction and decision optimization to prevent both immediate and delayed high-risk consequences in complex environments.  					AI-generated summary 				 With the widespread deployment of Computer-using Agents (CU...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 35. Large language models exhibit varying levels of social risk across multiple dimensions, with significant differences in worst-case behavior that cannot be captured by traditional scalar evaluation metrics.  					AI-generated summary 				 Large language models (LLMs) are increasingly deployed in high...
[11.02.2026 09:46] ********************************************************************************
[11.02.2026 09:46] Abstract 36. Temporal Pair Consistency reduces variance in continuous-time generative models by coupling velocity predictions at paired timesteps, improving sample quality and efficiency without altering model architecture or training procedures.  					AI-generated summary 				 Continuous-time generative models,...
[11.02.2026 09:46] Read previous papers.
[11.02.2026 09:46] Generating reviews via LLM API.
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#data", "#training"], "emoji": "", "ru": {"title": "     ", "desc": "OPUS           ,         
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#agents", "#dataset", "#rlhf", "#multimodal", "#training"], "emoji": "", "ru": {"title": "      ", "desc": "Code2World      vision-language,      GUI  
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#rl", "#agents", "#benchmark", "#multimodal", "#training"], "emoji": "", "ru": {"title": "            ", "desc": "UI-Venus-1.5       
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#training", "#agents", "#architecture"], "emoji": "", "ru": {"title": "         LLM", "desc": "   Chain of Mindset,         
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#rl", "#open_source", "#agents", "#training", "#reasoning"], "emoji": "", "ru": {"title": "   :    ", "desc": "SkillRL   ,      LLM        
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#rl", "#agents", "#multimodal", "#training", "#open_source", "#cv", "#science", "#optimization"], "emoji": "", "ru": {"title": "    : VLM   ", "desc": "    
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#synthetic", "#rl", "#agents", "#benchmark"], "emoji": "", "ru": {"title": "     ", "desc": "   Agent World Model (AWM)       , 
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#optimization", "#inference", "#long_context", "#architecture", "#training"], "emoji": "", "ru": {"title": "   :  Prism  LLM    ", "desc": "   -   
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#open_source", "#agents", "#optimization", "#inference", "#architecture", "#training", "#reasoning", "#diffusion"], "emoji": "", "ru": {"title": "     ", "desc": "    DLLM-Searcher   
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#training", "#video", "#architecture"], "emoji": "", "ru": {"title": "           -", "desc": "         
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#agents", "#dataset", "#cv", "#benchmark", "#multimodal"], "emoji": "", "ru": {"title": "          ", "desc": "Agent Banana      
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#inference", "#robotics", "#benchmark", "#multimodal"], "emoji": "", "ru": {"title": "        ", "desc": "    SCALE    Vision-Language-Action ,   
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#diffusion", "#optimization"], "emoji": "", "ru": {"title": "       ", "desc": "   ,          .  
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#open_source", "#agents", "#reasoning", "#video", "#robotics", "#training", "#transfer_learning", "#diffusion"], "emoji": "", "ru": {"title": "   :        ", "desc": "VideoWorld 2      
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#reasoning", "#alignment", "#training", "#rl", "#agents", "#math", "#optimization"], "emoji": "", "ru": {"title": "   LLM  - ", "desc": "        
[11.02.2026 09:46] Using data from previous issue: {"categories": [], "emoji": "", "ru": {"title": "     ", "desc": "ScaleEnv        ,         .  
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#robotics", "#architecture", "#multimodal", "#training", "#reasoning"], "emoji": "", "ru": {"title": " ,       ", "desc": "BagelVLA     Vision-Language-Action,    , 
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#training", "#robotics", "#architecture", "#cv"], "emoji": "", "ru": {"title": "  :      ", "desc": "VLA-JEPA    ,    JEPA,     
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#open_source", "#audio", "#benchmark", "#multimodal", "#training", "#reasoning"], "emoji": "", "ru": {"title": "  :     ", "desc": " Covo-Audio        7  
[11.02.2026 09:46] Using data from previous issue: {"categories": [], "emoji": "", "ru": {"title": "       ", "desc": "   Anchor             
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#open_source", "#agents", "#dataset", "#synthetic", "#robotics", "#3d", "#reasoning"], "emoji": "", "ru": {"title": "   3D     ", "desc": "SAGE         , 
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#training", "#architecture", "#cv"], "emoji": "", "ru": {"title": "        ", "desc": "       ,    , 
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#inference", "#rl", "#reasoning", "#optimization", "#rag"], "emoji": "", "ru": {"title": "    :       ", "desc": "   -
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#reasoning", "#math"], "emoji": "", "ru": {"title": "      ", "desc": "           
[11.02.2026 09:46] Querying the API.
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

TreeCUA enables efficient GUI automation scaling through tree-structured trajectory organization and multi-agent collaboration, improving GUI planning capabilities via adaptive exploration and trajectory verification.  					AI-generated summary 				 Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning, which requires more sophisticated data collection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose a multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (i.e., trajectory difficulty) and breadth (i.e., trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA.
[11.02.2026 09:46] Response: ```json
{
  "desc": "TreeCUA        ,           .       ,      ,    .          ,     .  TreeCUA-DPO              GUI.",
  "emoji": "",
  "title": "       "
}
```
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TreeCUA enables efficient GUI automation scaling through tree-structured trajectory organization and multi-agent collaboration, improving GUI planning capabilities via adaptive exploration and trajectory verification.  					AI-generated summary 				 Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning, which requires more sophisticated data collection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose a multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (i.e., trajectory difficulty) and breadth (i.e., trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA."

[11.02.2026 09:46] Response: ```python
['AGENTS', 'DATASET', 'RLHF']
```
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TreeCUA enables efficient GUI automation scaling through tree-structured trajectory organization and multi-agent collaboration, improving GUI planning capabilities via adaptive exploration and trajectory verification.  					AI-generated summary 				 Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning, which requires more sophisticated data collection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose a multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (i.e., trajectory difficulty) and breadth (i.e., trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA."

[11.02.2026 09:46] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **OPTIMIZATION**: The paper focuses on efficiently scaling GUI automation through optimized data collection and organization methods, including adaptive exploration algorithms, tree-based topology for efficient storage/replay, and methods to improve training efficiency (TreeCUA-DPO).

- **OPEN_SOURCE**: The paper explicitly states "All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA," indicating the authors are releasing their models, datasets, and code to the public.
[11.02.2026 09:46] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **OPTIMIZATION**: The paper focuses on efficiently scaling GUI automation through optimized data collection and organization methods, including adaptive exploration algorithms, tree-based topology for efficient storage/replay, and methods to improve training efficiency (TreeCUA-DPO).

- **OPEN_SOURCE**: The paper explicitly states "All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA," indicating the authors are releasing their models, datasets, and code to the public.
[11.02.2026 09:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TreeCUA is a novel framework designed to enhance the efficiency of GUI automation by organizing exploration trajectories into tree structures. This approach allows for better data management and reduces costs associated with GUI planning, which is often overlooked in existing methods. By employing a multi-agent system, TreeCUA facilitates collaborative exploration and verification of actions, leading to the generation of high-quality trajectories. Additionally, the framework incorporates adaptive exploration techniques and memory backtracking to ensure diverse and effective trajectory generation, demonstrating strong performance in experimental evaluations.","title":"TreeCUA: Scaling GUI Automation with Tree Structures and Collaboration"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TreeCUA is a novel framework designed to enhance the efficiency of GUI automation by organizing exploration trajectories into tree structures. This approach allows for better data management and reduces costs associated with GUI planning, which is often overlooked in existing methods. By employing a multi-agent system, TreeCUA facilitates collaborative exploration and verification of actions, leading to the generation of high-quality trajectories. Additionally, the framework incorporates adaptive exploration techniques and memory backtracking to ensure diverse and effective trajectory generation, demonstrating strong performance in experimental evaluations.', title='TreeCUA: Scaling GUI Automation with Tree Structures and Collaboration'))
[11.02.2026 09:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TreeCUAGUIGUITreeCUAGUITreeCUA","title":"TreeCUAGUI"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TreeCUAGUIGUITreeCUAGUITreeCUA', title='TreeCUAGUI'))
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#diffusion", "#open_source", "#synthetic"], "emoji": "", "ru": {"title": "    -  --", "desc": "   Fine-T2I    6   -    -
[11.02.2026 09:46] Querying the API.
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Modulation-based text conditioning in diffusion transformers provides performance benefits when used as guidance for controllable generation rather than just as attention mechanisms.  					AI-generated summary 				 Diffusion transformers typically incorporate textual information via attention layers and a modulation mechanism using a pooled text embedding. Nevertheless, recent approaches discard modulation-based text conditioning and rely exclusively on attention. In this paper, we address whether modulation-based text conditioning is necessary and whether it can provide any performance advantage. Our analysis shows that, in its conventional usage, the pooled embedding contributes little to overall performance, suggesting that attention alone is generally sufficient for faithfully propagating prompt information. However, we reveal that the pooled embedding can provide significant gains when used from a different perspective-serving as guidance and enabling controllable shifts toward more desirable properties. This approach is training-free, simple to implement, incurs negligible runtime overhead, and can be applied to various diffusion models, bringing improvements across diverse tasks, including text-to-image/video generation and image editing.
[11.02.2026 09:46] Response: ```json
{
  "desc": " ,      embedding         ,       .  ,      embedding     ,          . ,       guidance   ,        .      ,            ,   .",
  "emoji": "",
  "title": " :      "
}
```
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Modulation-based text conditioning in diffusion transformers provides performance benefits when used as guidance for controllable generation rather than just as attention mechanisms.  					AI-generated summary 				 Diffusion transformers typically incorporate textual information via attention layers and a modulation mechanism using a pooled text embedding. Nevertheless, recent approaches discard modulation-based text conditioning and rely exclusively on attention. In this paper, we address whether modulation-based text conditioning is necessary and whether it can provide any performance advantage. Our analysis shows that, in its conventional usage, the pooled embedding contributes little to overall performance, suggesting that attention alone is generally sufficient for faithfully propagating prompt information. However, we reveal that the pooled embedding can provide significant gains when used from a different perspective-serving as guidance and enabling controllable shifts toward more desirable properties. This approach is training-free, simple to implement, incurs negligible runtime overhead, and can be applied to various diffusion models, bringing improvements across diverse tasks, including text-to-image/video generation and image editing."

[11.02.2026 09:46] Response: ```python
["ARCHITECTURE", "TRAINING", "MULTIMODAL"]
```
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Modulation-based text conditioning in diffusion transformers provides performance benefits when used as guidance for controllable generation rather than just as attention mechanisms.  					AI-generated summary 				 Diffusion transformers typically incorporate textual information via attention layers and a modulation mechanism using a pooled text embedding. Nevertheless, recent approaches discard modulation-based text conditioning and rely exclusively on attention. In this paper, we address whether modulation-based text conditioning is necessary and whether it can provide any performance advantage. Our analysis shows that, in its conventional usage, the pooled embedding contributes little to overall performance, suggesting that attention alone is generally sufficient for faithfully propagating prompt information. However, we reveal that the pooled embedding can provide significant gains when used from a different perspective-serving as guidance and enabling controllable shifts toward more desirable properties. This approach is training-free, simple to implement, incurs negligible runtime overhead, and can be applied to various diffusion models, bringing improvements across diverse tasks, including text-to-image/video generation and image editing."

[11.02.2026 09:46] Response: ```python
["DIFFUSION"]
```
[11.02.2026 09:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the role of modulation-based text conditioning in diffusion transformers, which are models used for generating content. It finds that while traditional methods rely heavily on attention mechanisms, the pooled text embedding can actually enhance performance when used as guidance for generating specific outputs. The authors demonstrate that this approach is not only effective but also easy to implement and does not significantly slow down the model. Overall, the study suggests that using modulation for controllable generation can lead to better results in tasks like text-to-image generation and image editing.","title":"Enhancing Generation Control with Modulation in Diffusion Transformers"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores the role of modulation-based text conditioning in diffusion transformers, which are models used for generating content. It finds that while traditional methods rely heavily on attention mechanisms, the pooled text embedding can actually enhance performance when used as guidance for generating specific outputs. The authors demonstrate that this approach is not only effective but also easy to implement and does not significantly slow down the model. Overall, the study suggests that using modulation for controllable generation can lead to better results in tasks like text-to-image generation and image editing.', title='Enhancing Generation Control with Modulation in Diffusion Transformers'))
[11.02.2026 09:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"/","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='/', title=''))
[11.02.2026 09:46] Querying the API.
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

COVER enables efficient parallel decoding for diffusion language models by implementing cache override verification that reduces unnecessary revisions and maintains output quality through stable drafting and attention view construction.  					AI-generated summary 				 Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality.
[11.02.2026 09:46] Response: ```json
{
  "desc": "    COVER       .     ,       ,      ,    . COVER    KV-          forward pass,        .       ,       ,             .",
  "emoji": "",
  "title": "      "
}
```
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"COVER enables efficient parallel decoding for diffusion language models by implementing cache override verification that reduces unnecessary revisions and maintains output quality through stable drafting and attention view construction.  					AI-generated summary 				 Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality."

[11.02.2026 09:46] Response: ```python
["INFERENCE", "TRAINING"]
```

**Justification:**

- **INFERENCE**: The paper is explicitly focused on optimizing model deployment and inference efficiency. It addresses parallel decoding for diffusion language models, proposes techniques to reduce computational overhead (unnecessary revisions), and aims to accelerate inference speed while maintaining quality.

- **TRAINING**: The paper discusses training-related optimization techniques including attention mechanisms, cache management strategies, and scoring methods that influence how the model processes information during the decoding process, which relates to improving model training/inference efficiency.
[11.02.2026 09:46] Error. Failed to parse JSON from LLM. ["INFERENCE", "TRAINING"]


**Justification:**

- **INFERENCE**: The paper is explicitly focused on optimizing model deployment and inference efficiency. It addresses parallel decoding for diffusion language models, proposes techniques to reduce computational overhead (unnecessary revisions), and aims to accelerate inference speed while maintaining quality.

- **TRAINING**: The paper discusses training-related optimization techniques including attention mechanisms, cache management strategies, and scoring methods that influence how the model processes information during the decoding process, which relates to improving model training/inference efficiency.
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"COVER enables efficient parallel decoding for diffusion language models by implementing cache override verification that reduces unnecessary revisions and maintains output quality through stable drafting and attention view construction.  					AI-generated summary 				 Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality."

[11.02.2026 09:46] Response: ```python
['DIFFUSION', 'OPTIMIZATION']
```
[11.02.2026 09:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces COVER, a method designed to enhance the efficiency of parallel decoding in diffusion language models. It addresses the issue of quality degradation caused by aggressive parallelism, which can lead to unnecessary remasking of tokens. By implementing cache override verification, COVER allows for stable drafting and effective verification of tokens in a single forward pass. The method improves inference speed while maintaining high output quality by optimizing the selection and verification of tokens based on their stability and contextual relevance.","title":"COVER: Efficient Parallel Decoding with Quality Preservation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces COVER, a method designed to enhance the efficiency of parallel decoding in diffusion language models. It addresses the issue of quality degradation caused by aggressive parallelism, which can lead to unnecessary remasking of tokens. By implementing cache override verification, COVER allows for stable drafting and effective verification of tokens in a single forward pass. The method improves inference speed while maintaining high output quality by optimizing the selection and verification of tokens based on their stability and contextual relevance.', title='COVER: Efficient Parallel Decoding with Quality Preservation'))
[11.02.2026 09:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"COVERCOVER","title":"COVER"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='COVERCOVER', title='COVER'))
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#training", "#multimodal", "#diffusion", "#open_source", "#video", "#optimization"], "emoji": "", "ru": {"title": "  flow matching     ", "desc": "   Stable Velocity     
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#training", "#architecture"], "emoji": "", "ru": {"title": "  :      ", "desc": "  Mixture of Factor Analyzers (MFA)     
[11.02.2026 09:46] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#training", "#multimodal", "#open_source", "#cv", "#synthetic", "#optimization"], "emoji": "", "ru": {"title": "   vision-language    ", "desc": "    Octopus    
[11.02.2026 09:46] Querying the API.
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

LLMs' internal representations can predict problem difficulty and enable efficient inference routing that reduces costs while maintaining performance.  					AI-generated summary 				 Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require additional compute remains challenging. We investigate whether their own likelihood of success is recoverable from their internal representations before generation, and if this signal can guide more efficient inference. We train linear probes on pre-generation activations to predict policy-specific success on math and coding tasks, substantially outperforming surface features such as question length and TF-IDF. Using E2H-AMC, which provides both human and model performance on identical problems, we show that models encode a model-specific notion of difficulty that is distinct from human difficulty, and that this distinction increases with extended reasoning. Leveraging these probes, we demonstrate that routing queries across a pool of models can exceed the best-performing model whilst reducing inference cost by up to 70\% on MATH, showing that internal representations enable practical efficiency gains even when they diverge from human intuitions about difficulty. Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty
[11.02.2026 09:46] Response: ```json
{
  "desc": " ,  LLM           ,    .                  ,        .  ,      ,  ,       .         ,      70%    .",
  "emoji": "",
  "title": "  ,     "
}
```
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LLMs' internal representations can predict problem difficulty and enable efficient inference routing that reduces costs while maintaining performance.  					AI-generated summary 				 Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require additional compute remains challenging. We investigate whether their own likelihood of success is recoverable from their internal representations before generation, and if this signal can guide more efficient inference. We train linear probes on pre-generation activations to predict policy-specific success on math and coding tasks, substantially outperforming surface features such as question length and TF-IDF. Using E2H-AMC, which provides both human and model performance on identical problems, we show that models encode a model-specific notion of difficulty that is distinct from human difficulty, and that this distinction increases with extended reasoning. Leveraging these probes, we demonstrate that routing queries across a pool of models can exceed the best-performing model whilst reducing inference cost by up to 70\% on MATH, showing that internal representations enable practical efficiency gains even when they diverge from human intuitions about difficulty. Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty"

[11.02.2026 09:46] Response: ```python
["INFERENCE", "BENCHMARK", "MATH"]
```
[11.02.2026 09:46] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"LLMs' internal representations can predict problem difficulty and enable efficient inference routing that reduces costs while maintaining performance.  					AI-generated summary 				 Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require additional compute remains challenging. We investigate whether their own likelihood of success is recoverable from their internal representations before generation, and if this signal can guide more efficient inference. We train linear probes on pre-generation activations to predict policy-specific success on math and coding tasks, substantially outperforming surface features such as question length and TF-IDF. Using E2H-AMC, which provides both human and model performance on identical problems, we show that models encode a model-specific notion of difficulty that is distinct from human difficulty, and that this distinction increases with extended reasoning. Leveraging these probes, we demonstrate that routing queries across a pool of models can exceed the best-performing model whilst reducing inference cost by up to 70\% on MATH, showing that internal representations enable practical efficiency gains even when they diverge from human intuitions about difficulty. Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty"

[11.02.2026 09:46] Response: ```python
["INTERPRETABILITY", "OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **INTERPRETABILITY**: The paper analyzes LLM internal representations and what they encode about problem difficulty, investigating model behavior through linear probes on pre-generation activations.

- **OPTIMIZATION**: The paper focuses on efficient inference routing that reduces computational costs while maintaining performance, which is a core optimization concern.

- **OPEN_SOURCE**: The paper explicitly states "Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty", indicating the authors are releasing code publicly.
[11.02.2026 09:46] Error. Failed to parse JSON from LLM. ["INTERPRETABILITY", "OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **INTERPRETABILITY**: The paper analyzes LLM internal representations and what they encode about problem difficulty, investigating model behavior through linear probes on pre-generation activations.

- **OPTIMIZATION**: The paper focuses on efficient inference routing that reduces computational costs while maintaining performance, which is a core optimization concern.

- **OPEN_SOURCE**: The paper explicitly states "Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty", indicating the authors are releasing code publicly.
[11.02.2026 09:46] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how the internal representations of large language models (LLMs) can predict the difficulty of problems, allowing for more efficient use of computational resources. By training linear probes on the models\' pre-generation activations, the authors demonstrate that these internal signals can outperform traditional features like question length in predicting success on math and coding tasks. The study reveals that LLMs have a unique understanding of problem difficulty that differs from human perceptions, especially when extended reasoning is involved. Ultimately, the research shows that intelligently routing queries based on these internal representations can significantly reduce inference costs while maintaining or even improving performance.","title":"Unlocking Efficiency: Predicting Problem Difficulty with LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper explores how the internal representations of large language models (LLMs) can predict the difficulty of problems, allowing for more efficient use of computational resources. By training linear probes on the models' pre-generation activations, the authors demonstrate that these internal signals can outperform traditional features like question length in predicting success on math and coding tasks. The study reveals that LLMs have a unique understanding of problem difficulty that differs from human perceptions, especially when extended reasoning is involved. Ultimately, the research shows that intelligently routing queries based on these internal representations can significantly reduce inference costs while maintaining or even improving performance.", title='Unlocking Efficiency: Predicting Problem Difficulty with LLMs'))
[11.02.2026 09:47] Response: ParsedChatCompletionMessage[Article](content='{"desc":"LLMs","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='LLMs', title=''))
[11.02.2026 09:47] Using data from previous issue: {"categories": ["#benchmark", "#training", "#agents", "#architecture", "#rl"], "emoji": "", "ru": {"title": "        ", "desc": "TodoEvolve   -      
[11.02.2026 09:47] Using data from previous issue: {"categories": ["#architecture", "#training"], "emoji": "", "ru": {"title": "  LLM    ", "desc": "STEER2ADAPT                 
[11.02.2026 09:47] Using data from previous issue: {"categories": ["#security", "#alignment"], "emoji": "", "ru": {"title": "     ", "desc": "SafePred         ,       
[11.02.2026 09:47] Using data from previous issue: {"categories": ["#interpretability", "#ethics", "#benchmark"], "emoji": "", "ru": {"title": "      :      ", "desc": "     SHARP       
[11.02.2026 09:47] Using data from previous issue: {"categories": ["#diffusion", "#training", "#optimization", "#architecture"], "emoji": "", "ru": {"title": "      ", "desc": "    Temporal Pair Consistency       , 
[11.02.2026 09:47] Renaming data file.
[11.02.2026 09:47] Renaming previous data. hf_papers.json to ./d/2026-02-11.json
[11.02.2026 09:47] Saving new data file.
[11.02.2026 09:47] Generating page.
[11.02.2026 09:47] Renaming previous page.
[11.02.2026 09:47] Renaming previous data. index.html to ./d/2026-02-11.html
[11.02.2026 09:47] Writing result.
[11.02.2026 09:47] Renaming log file.
[11.02.2026 09:47] Renaming previous data. log.txt to ./logs/2026-02-11_last_log.txt
