[11.02.2026 14:15] Read previous papers.
[11.02.2026 14:15] Generating top page (month).
[11.02.2026 14:15] Writing top page (month).
[11.02.2026 15:55] Read previous papers.
[11.02.2026 15:55] Get feed.
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05400
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09856
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09082
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10063
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08234
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09443
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10090
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08426
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07035
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10104
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07022
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09084
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04208
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09849
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10098
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.00268
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08847
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10102
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06820
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01244
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08382
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.00462
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09268
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09439
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07276
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09823
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09662
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07153
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10116
[11.02.2026 15:55] Extract page data from URL. URL: https://huggingface.co/papers/2602.09276
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09024
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08344
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07839
[11.02.2026 15:55] Extract page data from URL. URL: https://huggingface.co/papers/2602.09017
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06161
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05435
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02464
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09591
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08503
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07755
[11.02.2026 15:55] Extract page data from URL. URL: https://huggingface.co/papers/2602.05892
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.10099
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09924
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08519
[11.02.2026 15:55] Extract page data from URL. URL: https://huggingface.co/papers/2602.07670
[11.02.2026 15:55] Extract page data from URL. URL: https://huggingface.co/papers/2602.07422
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04802
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04521
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.04908
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01725
[11.02.2026 15:55] Get page data from previous paper. URL: https://huggingface.co/papers/2601.21235
[11.02.2026 15:55] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.02.2026 15:55] No deleted papers detected.
[11.02.2026 15:55] Downloading and parsing papers (pdf, html). Total: 51.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.05400.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.05400.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.05400.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09856.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09856.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09856.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09082.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09082.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09082.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.10063.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.10063.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.10063.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.08234.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.08234.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.08234.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09443.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09443.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09443.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.10090.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.10090.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.10090.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.08426.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.08426.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.08426.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07035.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.07035.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.07035.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.10104.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.10104.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.10104.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07022.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.07022.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.07022.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09084.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09084.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09084.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.04208.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.04208.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.04208.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09849.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09849.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09849.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.10098.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.10098.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.10098.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.00268.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.00268.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.00268.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.08847.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.08847.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.08847.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.10102.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.10102.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.10102.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.06820.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.06820.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.06820.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.01244.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.01244.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.01244.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.08382.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.08382.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.08382.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.00462.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.00462.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.00462.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09268.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09268.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09268.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09439.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09439.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09439.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07276.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.07276.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.07276.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09823.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09823.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09823.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09662.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09662.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09662.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07153.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.07153.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.07153.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.10116.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.10116.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.10116.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09276.
[11.02.2026 15:55] Downloading paper 2602.09276 from https://arxiv.org/pdf/2602.09276v1...
[11.02.2026 15:55] Extracting affiliations from text.
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Archiki Prasad* 1 Mandar Joshi 2 Kenton Lee 2 Mohit Bansal 1 Peter Shaw "
[11.02.2026 15:55] Response: ```python
[]
```
[11.02.2026 15:55] Extracting affiliations from text.
[11.02.2026 15:55] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Archiki Prasad* 1 Mandar Joshi 2 Kenton Lee 2 Mohit Bansal 1 Peter ShawChain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach given accuracy threshold on given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies, we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe strong inverse correlation between the intrinsic dimensionality of reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering new quantitative metric for analyzing reasoning processes. 6 2 0 2 9 ] . [ 1 6 7 2 9 0 . 2 0 6 2 : r 1. Introduction Chain-of-thought reasoning (CoT) whether through fewshot prompting (Wei et al., 2022), zero-shot prompting (Kojima et al., 2022), or various post-training methods (Zelikman et al., 2022; Chung et al., 2024) has substantially improved the performance of large language models (LLMs) on reasoning tasks by generating textual rationales before 1UNC Chapel Hill 2Google DeepMind. *Work partially done during an internship at Google DeepMind. Correspondence to: Archiki Prasad <archiki@cs.unc.edu>. Preprint. February 11, 2026. 1 final answers. Subsequent work has proposed numerous variations with different stylistic and strategic features, including code-based solutions (Gao et al., 2023; Chen et al., 2023), decomposition strategies (Zhou et al., 2023; Khot et al., 2023; Wang et al., 2023b), and extended reasoning with verification loops (Snell et al., 2024; Muennighoff et al., 2025). These variations represent different ways of communicating problem-solving strategies and structuring solutions analogous to how humans adapt their communication style to their interlocutor in dialogue (Pickering & Garrod, 2004; Giles et al., 1991). Empirical evidence shows different reasoning strategies yield varying performance across tasks (Zhou et al., 2024), consistent with the intuition that different solution approaches suit different problems or learners. Further, not all problems benefit from generating rationales prior to the answer (Sprague et al., 2025). This motivates an important research question: when and why is reasoning effective, and given different reasoning strategies, which is most effective for improving model performance? Existing explanations in prior work suffer from notable limitations. First, qualitative hypotheses about the importance of structure or relevance of reasoning chains are not quantifiable (Wang et al., 2023a; Li et al., 2025). Consequently, these hypotheses are subject to interpretation, limiting both their predictive capacity and the ability to offer theoretically grounded explanation for what makes reasoning effective. On the other hand, prevalent quantitative measures are often associated with conflicting evidence. For example, the relationship between the length of reasoning trajectories and the subsequent increased inference-time computational capacity remains unclear; while some works find clear gains (Muennighoff et al., 2025; Li et al., 2025), other work reports that shorter chains can be more effective and that continuing to extend reasoning (e.g., via wait tokens) can yield degradation in performance (Wu et al., 2025; Marjanovic et al., 2025). Current approaches such as process reward models or correctness-based classifiers also require subjective specifications of desirable properties and do not provide principled measure of effectiveness. reliable quantitative measure would have significant practical implications: it could inform how to annotate or collect reasoning data, how to align reasoning strategies to particular student models, and how to design better regularizers that avoid limiting exploration or reward models grounded Effective Reasoning Chains Reduce Intrinsic Dimensionality in generalization principles rather than subjective criteria. To address this gap, we draw on the long-standing literature that uses information-theoretic perspectives to explain the efficacy of neural networks. Foundational concepts such as the minimum description length principle (Rissanen, 1978; Grunwald, 2007) posit an inverse relationship between the capacity required to represent solution and its expected generalization. Building on this, the notion of intrinsic dimensionality (Li et al., 2018; Aghajanyan et al., 2021) applies these insights for overparameterized models, measuring the effective number of parameters needed to fit given task objective. Specifically, intrinsic dimensionality is function of both the model and the task. While prior work has typically fixed the data to analyze how different models vary in their intrinsic dimensionality, we instead fix the model and vary the training data by changing the reasoning strategy used to generate solutions. Although the underlying capability required (e.g., solving math problems) remains constant, different reasoning strategies change the supervision provided to the model during training. In this context, one might intuitively expect that requiring model to generate long reasoning chains alongside final answers would increase the complexity of the outputs, making the task harder to fit. However, we hypothesize the opposite for effective reasoning: if reasoning strategy effectively bridges the logical gap between input and answer, it should render the underlying mapping more compressible, requiring fewer degrees of freedom to learn, thereby resulting in lower intrinsic dimensionality. We demonstrate strong inverse correlation between intrinsic dimensionality and generalization performance across multiple chain-of-thought variants on GSM8K (C"
[11.02.2026 15:55] Mistral response. {"id": "71953cb5a57a4fb99a4dbad1c63b4e39", "created": 1770825316, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1365, "total_tokens": 1380, "completion_tokens": 15, "prompt_tokens_details": {"cached_tokens": 0}}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"UNC Chapel Hill\", \"Google DeepMind\"]\n```"}}]}
[11.02.2026 15:55] Response: ```python
["UNC Chapel Hill", "Google DeepMind"]
```
[11.02.2026 15:55] Deleting PDF ./assets/pdf/2602.09276.pdf.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09024.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09024.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09024.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.08344.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.08344.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.08344.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07839.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.07839.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.07839.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09017.
[11.02.2026 15:55] Downloading paper 2602.09017 from https://arxiv.org/pdf/2602.09017v1...
[11.02.2026 15:55] Extracting affiliations from text.
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models Zichen Jeff Cui1, Omar Rayyan3, Haritheja Etukuru2, Bowen Tan1, Zavier Andrianarivo1, Zicheng Teng1, Yihang Zhou1, Krish Mehta6, Nicholas Wojno1, Kevin Yuanbo Wu1, Manan Anjaria1, Ziyuan Wu1, Manrong Mao1, Guangxun Zhang1, Binit Shah4, Yejin Kim5, Soumith Chintala1, Lerrel Pinto1, Nur Muhammad Mahi Shafiullah2 1New York University, 2University of California, Berkeley, 3University of California, Los Angeles 4Hello Robot Inc., 5Ai2, 6University of Waterloo Project page: cap-policy.github.io The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as library of modular utility models rather than monolithic generalist policy. This factorization allows us to implement real-to-sim iteration cycle: we build EgoGym, lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. 6 2 0 F 9 ] . [ 1 7 1 0 9 0 . 2 0 6 2 : r Figure 1: We introduce Contact-Anchored Policies (CAP), method to conditioning multimodal policies with physical contact information. Such policies are able to generalize zero-shot to novel objects and scenes with or"
[11.02.2026 15:55] Response: ```python
[
    "New York University",
    "University of California, Berkeley",
    "University of California, Los Angeles",
    "Hello Robot Inc.",
    "Ai2",
    "University of Waterloo"
]
```
[11.02.2026 15:55] Deleting PDF ./assets/pdf/2602.09017.pdf.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.06161.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.06161.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.06161.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.05435.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.05435.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.05435.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.02464.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.02464.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.02464.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09591.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09591.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09591.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.08503.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.08503.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.08503.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07755.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.07755.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.07755.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.05892.
[11.02.2026 15:55] Downloading paper 2602.05892 from https://arxiv.org/pdf/2602.05892v2...
[11.02.2026 15:55] Extracting affiliations from text.
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 1 ] . [ 2 2 9 8 5 0 . 2 0 6 2 : r CONTEXTBENCH: Benchmark for Context Retrieval in Coding Agents Han Li1 Letian Zhu1 Bohan Zhang1 Rili Feng1 Jiaming Wang1 Yue Pan2 Earl T. Barr2 Federica Sarro2 Zhaoyang Chu2 He Ye2 1Nanjing University 2University College London https://contextbench.github.io/ "
[11.02.2026 15:55] Response: ```python
["Nanjing University", "University College London"]
```
[11.02.2026 15:55] Deleting PDF ./assets/pdf/2602.05892.pdf.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.10099.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.10099.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.10099.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.09924.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.09924.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.09924.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.08519.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.08519.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.08519.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07670.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.07670.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.07670.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.07422.
[11.02.2026 15:55] Downloading paper 2602.07422 from https://arxiv.org/pdf/2602.07422v1...
[11.02.2026 15:55] Extracting affiliations from text.
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Tianyi Wu 1 Mingzhe Du 1 2 Yue Liu 1 Chengran Yang 3 Yue Zhuo 4 5 Jiaheng Zhang 1 See-Kiong Ng 1 6 2 0 2 7 ] . [ 1 2 2 4 7 0 . 2 0 6 2 : r Abstract Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains major barrier to real-world deployment. Existing secure code alignment methods often suffer from functionalitysecurity paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionalitypreserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https: //github.com/AndrewWTY/SecCoderX. 1. Introduction Large Language Models (LLMs) have become central to modern software development (Jin et al., 2024), supporting tasks ranging from function implementation (Roziere et al., 2023; Chaudhary, 2023; Lozhkov et al., 2024b) to large-scale repository refactoring (Anthropic, 2024; OpenAI, 2024). However, this rapid adoption has outpaced our 1National University of Singapore 2Nanyang Technological University 3Singapore Management University 4Monash University 5CSIROs Data61. Correspondence to: Tianyi Wu <tianyi wu@u.nus.edu>. Preprint. February 10, 2026. Figure 1. Average Effective Safety Rate (ESR) of secure c"
[11.02.2026 15:55] Response: ```python
[
    "National University of Singapore",
    "Nanyang Technological University",
    "Singapore Management University",
    "Monash University",
    "CSIROs Data61"
]
```
[11.02.2026 15:55] Deleting PDF ./assets/pdf/2602.07422.pdf.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.04802.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.04802.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.04802.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.04521.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.04521.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.04521.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.04908.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.04908.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.04908.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2602.01725.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2602.01725.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2602.01725.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Downloading and parsing paper https://huggingface.co/papers/2601.21235.
[11.02.2026 15:55] Extra JSON file exists (./assets/json/2601.21235.json), skip PDF parsing.
[11.02.2026 15:55] Paper image links file exists (./assets/img_data/2601.21235.json), skip HTML parsing.
[11.02.2026 15:55] Success.
[11.02.2026 15:55] Enriching papers with extra data.
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 0. OPUS is a dynamic data selection framework that improves pre-training efficiency by scoring data candidates based on optimizer-induced update projections in a stable proxy-derived target space, achieving superior performance with reduced computational overhead.  					AI-generated summary 				 As hig...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 1. Code2World enables autonomous GUI agents to predict next visual states through renderable code generation, achieving high visual fidelity and structural controllability while improving navigation performance.  					AI-generated summary 				 Autonomous GUI agents interact with environments by perceiv...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 2. UI-Venus-1.5 is a unified GUI agent with improved performance through mid-training stages, online reinforcement learning, and model merging techniques.  					AI-generated summary 				 GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving bo...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 3. A novel training-free framework called Chain of Mindset enables step-level adaptive mindset orchestration for large language models by integrating spatial, convergent, divergent, and algorithmic reasoning approaches.  					AI-generated summary 				 Human problem-solving is never the repetition of a ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 4. SkillRL enables LLM agents to improve through hierarchical skill discovery and recursive policy evolution, achieving superior performance on complex tasks while reducing computational overhead.  					AI-generated summary 				 Large Language Model (LLM) agents have shown stunning results in complex t...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 5. Physics-oriented vision-language models leverage curriculum reinforcement learning and agentic augmentation to achieve state-of-the-art scientific reasoning performance while maintaining physical consistency through multimodal perception.  					AI-generated summary 				 The transition from symbolic ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 6. Large language model agents trained in synthetic environments with code-driven simulations and database-backed state transitions demonstrate superior out-of-distribution generalization compared to traditional benchmark-specific approaches.  					AI-generated summary 				 Recent advances in large lan...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 7. Prism addresses inefficiencies in block-sparse attention for long-context LLM pre-filling by using a spectral-aware approach that improves block selection accuracy through energy-based temperature calibration.  					AI-generated summary 				 Block-sparse attention is promising for accelerating long-...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 8. Diffusion Large Language Models are optimized for search agents through enhanced reasoning capabilities and reduced latency via a parallel reasoning paradigm.  					AI-generated summary 				 Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 9. Sequence-level control-effect alignment enables structured latent action space learning for zero-shot action transfer in video world models.  					AI-generated summary 				 Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 10. Autoregressive models with diffusion loss outperform traditional diffusion models by effectively mitigating condition errors through patch denoising optimization and condition refinement using Optimal Transport theory.  					AI-generated summary 				 Recent studies have explored autoregressive model...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 11. Agent Banana addresses challenges in instruction-based image editing through a hierarchical framework with context folding and image layer decomposition for high-fidelity, multi-turn editing at ultra-high resolution.  					AI-generated summary 				 We study instruction-based image editing under prof...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 12. SCALE is a novel inference strategy for Vision-Language-Action models that jointly modulates visual perception and action based on self-uncertainty, improving robustness without additional training or multiple forward passes.  					AI-generated summary 				 Vision-Language-Action (VLA) models have e...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 13. BagelVLA is a unified Vision-Language-Action model that integrates linguistic planning, visual forecasting, and action generation through residual flow guidance for improved manipulation tasks.  					AI-generated summary 				 Equipping embodied agents with the ability to reason about tasks, foresee ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 14. VLA-JEPA is a JEPA-style pretraining framework that improves vision-language-action policy learning by using leakage-free state prediction in latent space, enhancing generalization and robustness in manipulation tasks.  					AI-generated summary 				 Pretraining Vision-Language-Action (VLA) policies...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 15. Auto-regressive video generation suffers from temporal drift due to error accumulation in latent conditioning tokens, which is addressed by identifying and removing unstable tokens during inference to improve long-horizon consistency.  					AI-generated summary 				 Auto-regressive video generation ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 16. Multi-agent large language model systems face training instability in reinforcement learning due to global normalization mismatches, which is addressed by Dr. MAS through agent-specific advantage normalization and enhanced training stability.  					AI-generated summary 				 Multi-agent LLM systems e...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 17. VideoWorld 2 enables transferable knowledge learning from raw videos through a dynamic-enhanced Latent Dynamics Model that decouples action dynamics from visual appearance, achieving improved task performance and long-horizon reasoning in real-world applications.  					AI-generated summary 				 Lear...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 18. ScaleEnv framework generates interactive environments from scratch to improve agent generalization through diverse domain scaling and verified task completion.  					AI-generated summary 				 Training generalist agents capable of adapting to diverse scenarios requires interactive environments for se...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 19. A scalable pipeline called TerminalTraj addresses challenges in creating high-quality terminal trajectories for training agentic models by filtering repositories, generating Docker-aligned task instances, and synthesizing executable agent trajectories across multiple domains.  					AI-generated summ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 20. A cognitive-inspired framework for long-context language modeling uses chunk-wise compression and selective memory recall to improve efficiency and performance over traditional approaches.  					AI-generated summary 				 Large Language Models (LLMs) face significant challenges in long-context proces...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 21. LatentLens enables interpretation of visual token representations in vision-language models by comparing them to contextualized textual representations, revealing that visual tokens are more interpretable than previously thought.  					AI-generated summary 				 Transforming a large language model (L...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 22. Modulation-based text conditioning in diffusion transformers provides performance benefits when used as guidance for controllable generation rather than just as attention mechanisms.  					AI-generated summary 				 Diffusion transformers typically incorporate textual information via attention layers...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 23. A large-scale, high-quality, and fully open dataset for text-to-image fine-tuning is presented, featuring over 6 million text-image pairs with rigorous filtering for alignment and quality across multiple task combinations and visual styles.  					AI-generated summary 				 High-quality and open datas...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 24. STEER2ADAPT is a lightweight framework that adapts large language models by composing steering vectors from reusable semantic prior subspaces, enabling efficient and flexible task adaptation through linear combinations of basis vectors.  					AI-generated summary 				 Activation steering has emerged...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 25. Covo-Audio is a 7B-parameter end-to-end large audio language model that processes continuous audio inputs and generates audio outputs, achieving state-of-the-art performance across speech-text modeling, spoken dialogue, and full-duplex voice interaction tasks through large-scale pretraining and post...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 26. TreeCUA enables efficient GUI automation scaling through tree-structured trajectory organization and multi-agent collaboration, improving GUI planning capabilities via adaptive exploration and trajectory verification.  					AI-generated summary 				 Effectively scaling GUI automation is essential fo...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 27. A trajectory expansion framework called Anchor bootstraps scalable desktop supervision from seed demonstrations by identifying branch points and generating new trajectories through state-grounded task variants.  					AI-generated summary 				 End-to-end GUI agents for real desktop environments requi...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 28. SAGE is an agentic framework that automatically generates simulation-ready 3D environments for embodied AI by combining layout and object composition generators with evaluative critics for semantic plausibility and physical stability.  					AI-generated summary 				 Real-world data collection for em...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 29. Effective chain-of-thought reasoning strategies reduce intrinsic dimensionality, leading to better generalization by requiring fewer model parameters to achieve given accuracy thresholds.  					AI-generated summary 				 Chain-of-thought (CoT) reasoning and its variants have substantially improved th...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 30. Discrete tokenizers can match or exceed continuous methods when properly scaled, and a new masked Bit AutoRegressive modeling approach achieves state-of-the-art results with reduced computational costs.  					AI-generated summary 				 This paper challenges the dominance of continuous pipelines in vi...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 31. Reinforcement learning with verifiable rewards is used to enhance parallel thinking in large reasoning models through outline-guided path exploration that reduces information redundancy and improves solution discovery.  					AI-generated summary 				 Parallel thinking has emerged as a new paradigm f...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 32. TodoEvolve enables autonomous synthesis and revision of task-specific planning architectures through a modular design space and multi-objective reinforcement learning optimization.  					AI-generated summary 				 Planning has become a central capability for contemporary agent systems in navigating c...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 33. Contact-Anchored Policies replace language conditioning with physical contact points and use modular utility models for robust manipulation, achieving superior zero-shot performance with minimal demonstration data through real-to-sim iteration cycles.  					AI-generated summary 				 The prevalent pa...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 34. COVER enables efficient parallel decoding for diffusion language models by implementing cache override verification that reduces unnecessary revisions and maintains output quality through stable drafting and attention view construction.  					AI-generated summary 				 Parallel diffusion decoding can...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 35. Stable Velocity framework addresses high-variance training in flow matching by identifying low-variance regimes and proposing variance-reduction techniques for improved training efficiency and sampling speed.  					AI-generated summary 				 While flow matching is elegant, its reliance on single-samp...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 36. Mixture of Factor Analyzers (MFA) provides a scalable, unsupervised approach for discovering complex, nonlinear structures in language model activation spaces by modeling local geometric structures through Gaussian regions and their covariance properties.  					AI-generated summary 				 Activation d...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 37. Length control methods in reinforcement learning-trained language models affect reasoning performance and computational efficiency, with optimal output lengths balancing these factors.  					AI-generated summary 				 Reinforcement learning substantially improves reasoning in large language models, b...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 38. Octopus, an RL rollout augmentation framework, enables efficient self-correction learning in vision-language models through synthetic example generation and response masking strategies.  					AI-generated summary 				 Self-correction is essential for solving complex reasoning problems in vision-lang...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 39. ALMA is a framework that uses meta-learning to automatically discover memory designs for agentic systems, enabling continual learning without human engineering across diverse domains.  					AI-generated summary 				 The statelessness of foundation models bottlenecks agentic systems' ability to conti...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 40. ContextBench evaluates context retrieval in coding agents through detailed process analysis, revealing that advanced agent designs provide limited improvements in context usage while highlighting gaps between explored and utilized information.  					AI-generated summary 				 LLM-based coding agents ...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 41. Geometric interference in standard diffusion transformers prevents convergence on representation encoders, which is resolved through Riemannian flow matching with jacobi regularization enabling effective training without width scaling.  					AI-generated summary 				 Leveraging representation encode...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 42. LLMs' internal representations can predict problem difficulty and enable efficient inference routing that reduces costs while maintaining performance.  					AI-generated summary 				 Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require add...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 43. PyAGC presents a production-ready benchmark and library for attributed graph clustering that addresses limitations of current research through scalable, memory-efficient implementations and comprehensive evaluation protocols.  					AI-generated summary 				 Attributed Graph Clustering (AGC) is a fun...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 44. Test-time training fails in verification-grounded tasks due to over-sharpening, while surprisal-guided selection improves performance by favoring diverse, low-confidence samples.  					AI-generated summary 				 Test-time training (TTT) adapts language models through gradient-based updates at inferen...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 45. SecCoderX uses online reinforcement learning to align large language models for secure code generation while preserving functionality, addressing the functionality-security trade-off through vulnerability detection integration and reward modeling.  					AI-generated summary 				 Large language model...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 46. VISTA-Bench evaluates vision-language models' ability to understand visualized text versus pure-text queries, revealing significant performance gaps and sensitivity to rendering variations.  					AI-generated summary 				 Vision-Language Models (VLMs) have achieved impressive performance in cross-mo...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 47. Offline selective refusal in large language models is achieved through circuit-restricted weight updates that eliminate runtime intervention costs while maintaining performance.  					AI-generated summary 				 Modern deployments require LLMs to enforce safety policies at scale, yet many controls rel...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 48. Temporal Pair Consistency reduces variance in continuous-time generative models by coupling velocity predictions at paired timesteps, improving sample quality and efficiency without altering model architecture or training procedures.  					AI-generated summary 				 Continuous-time generative models,...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 49. SafePred is a predictive guardrail framework for computer-using agents that uses risk prediction and decision optimization to prevent both immediate and delayed high-risk consequences in complex environments.  					AI-generated summary 				 With the widespread deployment of Computer-using Agents (CU...
[11.02.2026 15:55] ********************************************************************************
[11.02.2026 15:55] Abstract 50. Large language models exhibit varying levels of social risk across multiple dimensions, with significant differences in worst-case behavior that cannot be captured by traditional scalar evaluation metrics.  					AI-generated summary 				 Large language models (LLMs) are increasingly deployed in high...
[11.02.2026 15:55] Read previous papers.
[11.02.2026 15:55] Generating reviews via LLM API.
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#data", "#training"], "emoji": "", "ru": {"title": "     ", "desc": "OPUS           ,         
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#agents", "#dataset", "#rlhf", "#multimodal", "#training"], "emoji": "", "ru": {"title": "      ", "desc": "Code2World      vision-language,      GUI  
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#rl", "#agents", "#benchmark", "#multimodal", "#training"], "emoji": "", "ru": {"title": "            ", "desc": "UI-Venus-1.5       
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#training", "#agents", "#architecture"], "emoji": "", "ru": {"title": "         LLM", "desc": "   Chain of Mindset,         
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#rl", "#open_source", "#agents", "#training", "#reasoning"], "emoji": "", "ru": {"title": "   :    ", "desc": "SkillRL   ,      LLM        
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#rl", "#agents", "#multimodal", "#training", "#open_source", "#cv", "#science", "#optimization"], "emoji": "", "ru": {"title": "    : VLM   ", "desc": "    
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#synthetic", "#rl", "#agents", "#benchmark"], "emoji": "", "ru": {"title": "     ", "desc": "   Agent World Model (AWM)       , 
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#optimization", "#inference", "#long_context", "#architecture", "#training"], "emoji": "", "ru": {"title": "   :  Prism  LLM    ", "desc": "   -   
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#open_source", "#agents", "#optimization", "#inference", "#architecture", "#training", "#reasoning", "#diffusion"], "emoji": "", "ru": {"title": "     ", "desc": "    DLLM-Searcher   
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#training", "#video", "#architecture"], "emoji": "", "ru": {"title": "           -", "desc": "         
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#diffusion", "#optimization"], "emoji": "", "ru": {"title": "       ", "desc": "   ,          .  
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#agents", "#dataset", "#cv", "#benchmark", "#multimodal"], "emoji": "", "ru": {"title": "          ", "desc": "Agent Banana      
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#inference", "#robotics", "#benchmark", "#multimodal"], "emoji": "", "ru": {"title": "        ", "desc": "    SCALE    Vision-Language-Action ,   
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#robotics", "#architecture", "#multimodal", "#training", "#reasoning"], "emoji": "", "ru": {"title": " ,       ", "desc": "BagelVLA     Vision-Language-Action,    , 
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#training", "#robotics", "#architecture", "#cv"], "emoji": "", "ru": {"title": "  :      ", "desc": "VLA-JEPA    ,    JEPA,     
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#video", "#inference"], "emoji": "", "ru": {"title": "       ", "desc": "         ,   -    
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#reasoning", "#alignment", "#training", "#rl", "#agents", "#math", "#optimization"], "emoji": "", "ru": {"title": "   LLM  - ", "desc": "        
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#open_source", "#agents", "#reasoning", "#video", "#robotics", "#training", "#transfer_learning", "#diffusion"], "emoji": "", "ru": {"title": "   :        ", "desc": "VideoWorld 2      
[11.02.2026 15:55] Using data from previous issue: {"categories": [], "emoji": "", "ru": {"title": "     ", "desc": "ScaleEnv        ,         .  
[11.02.2026 15:55] Using data from previous issue: {"categories": [], "emoji": "", "ru": {"title": "    :     ", "desc": "TerminalTraj            ,   
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#inference", "#rl", "#reasoning", "#optimization", "#rag"], "emoji": "", "ru": {"title": "    :       ", "desc": "   -
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#multimodal"], "emoji": "", "ru": {"title": "      ", "desc": "  LatentLens             
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#diffusion", "#architecture", "#multimodal", "#training"], "emoji": "", "ru": {"title": " :      ", "desc": " ,      embedding      
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#diffusion", "#open_source", "#synthetic"], "emoji": "", "ru": {"title": "    -  --", "desc": "   Fine-T2I    6   -    -
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#architecture", "#training"], "emoji": "", "ru": {"title": "  LLM    ", "desc": "STEER2ADAPT                 
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#open_source", "#audio", "#benchmark", "#multimodal", "#training", "#reasoning"], "emoji": "", "ru": {"title": "  :     ", "desc": " Covo-Audio        7  
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#dataset", "#rlhf", "#agents"], "emoji": "", "ru": {"title": "       ", "desc": "TreeCUA        ,    
[11.02.2026 15:55] Using data from previous issue: {"categories": [], "emoji": "", "ru": {"title": "       ", "desc": "   Anchor             
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#open_source", "#agents", "#dataset", "#synthetic", "#robotics", "#3d", "#reasoning"], "emoji": "", "ru": {"title": "   3D     ", "desc": "SAGE         , 
[11.02.2026 15:55] Querying the API.
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Effective chain-of-thought reasoning strategies reduce intrinsic dimensionality, leading to better generalization by requiring fewer model parameters to achieve given accuracy thresholds.  					AI-generated summary 				 Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as a quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach a given accuracy threshold on a given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies, we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe a strong inverse correlation between the intrinsic dimensionality of a reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering a new quantitative metric for analyzing reasoning processes.
[11.02.2026 15:55] Response: ```json
{
  "desc": "       (Chain-of-Thought)        .  ,       ,      ,     .      (GSM8K)             ,     .            .",
  "emoji": "",
  "title": "   :  ,  "
}
```
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Effective chain-of-thought reasoning strategies reduce intrinsic dimensionality, leading to better generalization by requiring fewer model parameters to achieve given accuracy thresholds.  					AI-generated summary 				 Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as a quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach a given accuracy threshold on a given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies, we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe a strong inverse correlation between the intrinsic dimensionality of a reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering a new quantitative metric for analyzing reasoning processes."

[11.02.2026 15:55] Response: ```python
["MATH", "TRAINING", "SMALL_MODELS"]
```
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Effective chain-of-thought reasoning strategies reduce intrinsic dimensionality, leading to better generalization by requiring fewer model parameters to achieve given accuracy thresholds.  					AI-generated summary 				 Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as a quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach a given accuracy threshold on a given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies, we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe a strong inverse correlation between the intrinsic dimensionality of a reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering a new quantitative metric for analyzing reasoning processes."

[11.02.2026 15:55] Response: ```python
['REASONING', 'INTERPRETABILITY']
```
[11.02.2026 15:55] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how effective chain-of-thought (CoT) reasoning strategies can improve the performance of language models by reducing intrinsic dimensionality. Intrinsic dimensionality measures the minimum number of dimensions needed for a model to achieve a certain level of accuracy on a task. The authors show that by using different reasoning strategies while keeping the model architecture constant, the intrinsic dimensionality decreases, leading to better generalization. Their findings indicate that effective reasoning chains allow models to learn more efficiently, requiring fewer parameters to perform well on various tasks.","title":"Reducing Dimensionality for Better Generalization in Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how effective chain-of-thought (CoT) reasoning strategies can improve the performance of language models by reducing intrinsic dimensionality. Intrinsic dimensionality measures the minimum number of dimensions needed for a model to achieve a certain level of accuracy on a task. The authors show that by using different reasoning strategies while keeping the model architecture constant, the intrinsic dimensionality decreases, leading to better generalization. Their findings indicate that effective reasoning chains allow models to learn more efficiently, requiring fewer parameters to perform well on various tasks.', title='Reducing Dimensionality for Better Generalization in Language Models'))
[11.02.2026 15:55] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CoT","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CoT', title=''))
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#training", "#architecture", "#cv"], "emoji": "", "ru": {"title": "        ", "desc": "       ,    , 
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#reasoning", "#math"], "emoji": "", "ru": {"title": "      ", "desc": "           
[11.02.2026 15:55] Using data from previous issue: {"categories": ["#benchmark", "#training", "#agents", "#architecture", "#rl"], "emoji": "", "ru": {"title": "        ", "desc": "TodoEvolve   -      
[11.02.2026 15:55] Querying the API.
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Contact-Anchored Policies replace language conditioning with physical contact points and use modular utility models for robust manipulation, achieving superior zero-shot performance with minimal demonstration data through real-to-sim iteration cycles.  					AI-generated summary 				 The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/
[11.02.2026 15:55] Response: ```json
{
  "desc": "  Contact-Anchored Policies (CAP)      ,          .       CAP    -,      .      EgoGym          .       ,   23       VLA-  56%        .",
  "emoji": "",
  "title": "   :      "
}
```
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Contact-Anchored Policies replace language conditioning with physical contact points and use modular utility models for robust manipulation, achieving superior zero-shot performance with minimal demonstration data through real-to-sim iteration cycles.  					AI-generated summary 				 The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/"

[11.02.2026 15:55] Response: ```python
['ROBOTICS', 'DATASET', 'BENCHMARK', 'MULTIMODAL']
```
[11.02.2026 15:55] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Contact-Anchored Policies replace language conditioning with physical contact points and use modular utility models for robust manipulation, achieving superior zero-shot performance with minimal demonstration data through real-to-sim iteration cycles.  					AI-generated summary 				 The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/"

[11.02.2026 15:56] Response: ```python
['OPEN_SOURCE']
```
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents Contact-Anchored Policies (CAP), a new approach to robot learning that uses physical contact points instead of language prompts for guiding manipulation tasks. By structuring CAP as a collection of modular utility models, the authors enable more effective generalization across different environments and tasks. The method incorporates a real-to-sim iteration cycle using a simulation benchmark called EgoGym, which helps identify and address failure modes before real-world application. The results demonstrate that CAP achieves superior performance in zero-shot scenarios with minimal demonstration data, outperforming existing state-of-the-art models significantly.","title":"Revolutionizing Robot Learning with Contact Points"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents Contact-Anchored Policies (CAP), a new approach to robot learning that uses physical contact points instead of language prompts for guiding manipulation tasks. By structuring CAP as a collection of modular utility models, the authors enable more effective generalization across different environments and tasks. The method incorporates a real-to-sim iteration cycle using a simulation benchmark called EgoGym, which helps identify and address failure modes before real-world application. The results demonstrate that CAP achieves superior performance in zero-shot scenarios with minimal demonstration data, outperforming existing state-of-the-art models significantly.', title='Revolutionizing Robot Learning with Contact Points'))
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Contact-Anchored PoliciesCAPCAP23-shot","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Contact-Anchored PoliciesCAPCAP23-shot', title=''))
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#diffusion", "#optimization"], "emoji": "", "ru": {"title": "      ", "desc": "    COVER       .     , 
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#training", "#multimodal", "#diffusion", "#open_source", "#video", "#optimization"], "emoji": "", "ru": {"title": "  flow matching     ", "desc": "   Stable Velocity     
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#training", "#architecture"], "emoji": "", "ru": {"title": "  :      ", "desc": "  Mixture of Factor Analyzers (MFA)     
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#small_models", "#rl", "#optimization", "#training", "#reasoning"], "emoji": "", "ru": {"title": " :       ", "desc": "           
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#training", "#multimodal", "#open_source", "#cv", "#synthetic", "#optimization"], "emoji": "", "ru": {"title": "   vision-language    ", "desc": "    Octopus    
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#training", "#reasoning", "#agents", "#optimization"], "emoji": "", "ru": {"title": " :      ", "desc": "ALMA   ,          
[11.02.2026 15:56] Querying the API.
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ContextBench evaluates context retrieval in coding agents through detailed process analysis, revealing that advanced agent designs provide limited improvements in context usage while highlighting gaps between explored and utilized information.  					AI-generated summary 				 LLM-based coding agents have shown strong performance on automated issue resolution benchmarks, yet existing evaluations largely focus on final task success, providing limited insight into how agents retrieve and use code context during problem solving. We introduce ContextBench, a process-oriented evaluation of context retrieval in coding agents. ContextBench consists of 1,136 issue-resolution tasks from 66 repositories across eight programming languages, each augmented with human-annotated gold contexts. We further implement an automated evaluation framework that tracks agent trajectories and measures context recall, precision, and efficiency throughout issue resolution. Using ContextBench, we evaluate four frontier LLMs and five coding agents. Our results show that sophisticated agent scaffolding yields only marginal gains in context retrieval ("The Bitter Lesson" of coding agents), LLMs consistently favor recall over precision, and substantial gaps exist between explored and utilized context. ContextBench augments existing end-to-end benchmarks with intermediate gold-context metrics that unbox the issue-resolution process. These contexts offer valuable intermediate signals for guiding LLM reasoning in software tasks.
[11.02.2026 15:56] Response: ```json
{
  "desc": "   ContextBench        ,     LLM           .        1136   66 ,      .  ,            ,       .      ,   ,  ,       .",
  "emoji": "",
  "title": "     :     "
}
```
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ContextBench evaluates context retrieval in coding agents through detailed process analysis, revealing that advanced agent designs provide limited improvements in context usage while highlighting gaps between explored and utilized information.  					AI-generated summary 				 LLM-based coding agents have shown strong performance on automated issue resolution benchmarks, yet existing evaluations largely focus on final task success, providing limited insight into how agents retrieve and use code context during problem solving. We introduce ContextBench, a process-oriented evaluation of context retrieval in coding agents. ContextBench consists of 1,136 issue-resolution tasks from 66 repositories across eight programming languages, each augmented with human-annotated gold contexts. We further implement an automated evaluation framework that tracks agent trajectories and measures context recall, precision, and efficiency throughout issue resolution. Using ContextBench, we evaluate four frontier LLMs and five coding agents. Our results show that sophisticated agent scaffolding yields only marginal gains in context retrieval ("The Bitter Lesson" of coding agents), LLMs consistently favor recall over precision, and substantial gaps exist between explored and utilized context. ContextBench augments existing end-to-end benchmarks with intermediate gold-context metrics that unbox the issue-resolution process. These contexts offer valuable intermediate signals for guiding LLM reasoning in software tasks."

[11.02.2026 15:56] Response: ```python
["BENCHMARK", "DATASET", "AGENTS", "PLP"]
```
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ContextBench evaluates context retrieval in coding agents through detailed process analysis, revealing that advanced agent designs provide limited improvements in context usage while highlighting gaps between explored and utilized information.  					AI-generated summary 				 LLM-based coding agents have shown strong performance on automated issue resolution benchmarks, yet existing evaluations largely focus on final task success, providing limited insight into how agents retrieve and use code context during problem solving. We introduce ContextBench, a process-oriented evaluation of context retrieval in coding agents. ContextBench consists of 1,136 issue-resolution tasks from 66 repositories across eight programming languages, each augmented with human-annotated gold contexts. We further implement an automated evaluation framework that tracks agent trajectories and measures context recall, precision, and efficiency throughout issue resolution. Using ContextBench, we evaluate four frontier LLMs and five coding agents. Our results show that sophisticated agent scaffolding yields only marginal gains in context retrieval ("The Bitter Lesson" of coding agents), LLMs consistently favor recall over precision, and substantial gaps exist between explored and utilized context. ContextBench augments existing end-to-end benchmarks with intermediate gold-context metrics that unbox the issue-resolution process. These contexts offer valuable intermediate signals for guiding LLM reasoning in software tasks."

[11.02.2026 15:56] Response: ```python
['INTERPRETABILITY', 'REASONING']
```

**Justification:**

- **INTERPRETABILITY**: The paper focuses on analyzing and explaining how coding agents retrieve and use context during problem-solving. It provides detailed process analysis and intermediate metrics to "unbox the issue-resolution process," which directly relates to understanding model behavior and explanations.

- **REASONING**: The paper discusses guiding LLM reasoning in software tasks and evaluates how agents reason through code context retrieval and utilization during problem-solving.
[11.02.2026 15:56] Error. Failed to parse JSON from LLM. ["INTERPRETABILITY", "REASONING"]


**Justification:**

- **INTERPRETABILITY**: The paper focuses on analyzing and explaining how coding agents retrieve and use context during problem-solving. It provides detailed process analysis and intermediate metrics to "unbox the issue-resolution process," which directly relates to understanding model behavior and explanations.

- **REASONING**: The paper discusses guiding LLM reasoning in software tasks and evaluates how agents reason through code context retrieval and utilization during problem-solving.
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces ContextBench, a new evaluation framework for assessing how coding agents retrieve and utilize context during problem-solving tasks. It analyzes 1,136 issue-resolution tasks across various programming languages, providing insights into the effectiveness of different coding agents and large language models (LLMs). The findings reveal that while advanced agent designs show slight improvements in context usage, there are significant gaps between the context that agents explore and what they actually utilize. ContextBench enhances traditional evaluations by focusing on intermediate metrics, which can help improve LLM reasoning in software development tasks.","title":"ContextBench: Unpacking Context Retrieval in Coding Agents"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces ContextBench, a new evaluation framework for assessing how coding agents retrieve and utilize context during problem-solving tasks. It analyzes 1,136 issue-resolution tasks across various programming languages, providing insights into the effectiveness of different coding agents and large language models (LLMs). The findings reveal that while advanced agent designs show slight improvements in context usage, there are significant gaps between the context that agents explore and what they actually utilize. ContextBench enhances traditional evaluations by focusing on intermediate metrics, which can help improve LLM reasoning in software development tasks.', title='ContextBench: Unpacking Context Retrieval in Coding Agents'))
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ContextBench LLM ","title":"ContextBench"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ContextBench LLM ', title='ContextBench'))
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#training", "#math", "#optimization", "#open_source", "#diffusion", "#architecture"], "emoji": "", "ru": {"title": " :      ", "desc": "       , 
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#benchmark", "#math", "#inference"], "emoji": "", "ru": {"title": "  ,     ", "desc": " ,  LLM           ,    .  
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#benchmark", "#open_source", "#graphs"], "emoji": "", "ru": {"title": "   :      ", "desc": "PyAGC       
[11.02.2026 15:56] Querying the API.
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Test-time training fails in verification-grounded tasks due to over-sharpening, while surprisal-guided selection improves performance by favoring diverse, low-confidence samples.  					AI-generated summary 				 Test-time training (TTT) adapts language models through gradient-based updates at inference. But is adaptation the right strategy? We study compute-optimal test-time strategies for verifiable execution-grounded (VEG) tasks, domains like GPU kernel optimization where a deterministic evaluator provides dense, continuous reward signals. Using KernelBench as our testbed and a 120B-parameter model (GPT-OSS-120B with LoRA adaptation), we find that search outperforms minimal adaptation (1-5 gradient steps): Best-of-N sampling achieves 90% task success (18/20 tasks) at K=64 across the full KernelBench L1 eval set while TTT's best checkpoint reaches only 30.6% (3-seed mean), with TTT's "equivalent K" falling below 1, worse than single-sample inference. The failure mode is over-sharpening: gradient updates collapse diversity toward mediocre solutions rather than discovering optimal ones. Our main contribution is surprisal-guided selection: selecting the highest-surprisal (lowest-confidence) correct sample yields 80% success vs. 50% for most-confident selection, a 30% improvement. Extending to surprisal-guided-top3 matches oracle performance at 100%. This zero-cost strategy, validated through length-controlled analysis, recovers oracle performance. For dense-reward VEG tasks, compute should be allocated to sample diversity and intelligent selection rather than gradient adaptation. The surprisal-guided selection principle may generalize to other execution-grounded domains where optimal solutions occupy the distribution tail.
[11.02.2026 15:56] Response: ```json
{
  "desc": "           ,      .  ,       (TTT)           .   surprisal-guided selection         ,     30%    .  ,                 ,     .",
  "emoji": "",
  "title": "   : surprisal-guided selection  "
}
```
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Test-time training fails in verification-grounded tasks due to over-sharpening, while surprisal-guided selection improves performance by favoring diverse, low-confidence samples.  					AI-generated summary 				 Test-time training (TTT) adapts language models through gradient-based updates at inference. But is adaptation the right strategy? We study compute-optimal test-time strategies for verifiable execution-grounded (VEG) tasks, domains like GPU kernel optimization where a deterministic evaluator provides dense, continuous reward signals. Using KernelBench as our testbed and a 120B-parameter model (GPT-OSS-120B with LoRA adaptation), we find that search outperforms minimal adaptation (1-5 gradient steps): Best-of-N sampling achieves 90% task success (18/20 tasks) at K=64 across the full KernelBench L1 eval set while TTT's best checkpoint reaches only 30.6% (3-seed mean), with TTT's "equivalent K" falling below 1, worse than single-sample inference. The failure mode is over-sharpening: gradient updates collapse diversity toward mediocre solutions rather than discovering optimal ones. Our main contribution is surprisal-guided selection: selecting the highest-surprisal (lowest-confidence) correct sample yields 80% success vs. 50% for most-confident selection, a 30% improvement. Extending to surprisal-guided-top3 matches oracle performance at 100%. This zero-cost strategy, validated through length-controlled analysis, recovers oracle performance. For dense-reward VEG tasks, compute should be allocated to sample diversity and intelligent selection rather than gradient adaptation. The surprisal-guided selection principle may generalize to other execution-grounded domains where optimal solutions occupy the distribution tail."

[11.02.2026 15:56] Response: ```python
["INFERENCE", "TRAINING"]
```
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Test-time training fails in verification-grounded tasks due to over-sharpening, while surprisal-guided selection improves performance by favoring diverse, low-confidence samples.  					AI-generated summary 				 Test-time training (TTT) adapts language models through gradient-based updates at inference. But is adaptation the right strategy? We study compute-optimal test-time strategies for verifiable execution-grounded (VEG) tasks, domains like GPU kernel optimization where a deterministic evaluator provides dense, continuous reward signals. Using KernelBench as our testbed and a 120B-parameter model (GPT-OSS-120B with LoRA adaptation), we find that search outperforms minimal adaptation (1-5 gradient steps): Best-of-N sampling achieves 90% task success (18/20 tasks) at K=64 across the full KernelBench L1 eval set while TTT's best checkpoint reaches only 30.6% (3-seed mean), with TTT's "equivalent K" falling below 1, worse than single-sample inference. The failure mode is over-sharpening: gradient updates collapse diversity toward mediocre solutions rather than discovering optimal ones. Our main contribution is surprisal-guided selection: selecting the highest-surprisal (lowest-confidence) correct sample yields 80% success vs. 50% for most-confident selection, a 30% improvement. Extending to surprisal-guided-top3 matches oracle performance at 100%. This zero-cost strategy, validated through length-controlled analysis, recovers oracle performance. For dense-reward VEG tasks, compute should be allocated to sample diversity and intelligent selection rather than gradient adaptation. The surprisal-guided selection principle may generalize to other execution-grounded domains where optimal solutions occupy the distribution tail."

[11.02.2026 15:56] Response: ```python
["OPTIMIZATION", "REASONING"]
```

**Justification:**

- **OPTIMIZATION**: The paper directly addresses training optimization methods, specifically comparing test-time training (TTT) strategies with search-based approaches and proposing surprisal-guided selection as a compute-optimal strategy for inference-time adaptation.

- **REASONING**: The paper focuses on verification-grounded execution tasks (GPU kernel optimization) where models must produce correct solutions, which relates to enhancing logical reasoning and problem-solving capabilities in language models.
[11.02.2026 15:56] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "REASONING"]


**Justification:**

- **OPTIMIZATION**: The paper directly addresses training optimization methods, specifically comparing test-time training (TTT) strategies with search-based approaches and proposing surprisal-guided selection as a compute-optimal strategy for inference-time adaptation.

- **REASONING**: The paper focuses on verification-grounded execution tasks (GPU kernel optimization) where models must produce correct solutions, which relates to enhancing logical reasoning and problem-solving capabilities in language models.
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the effectiveness of test-time training (TTT) in verification-grounded tasks, particularly in scenarios where a deterministic evaluator provides continuous rewards. The authors find that TTT often leads to over-sharpening, which reduces diversity and results in suboptimal solutions. Instead, they propose a method called surprisal-guided selection, which focuses on choosing low-confidence samples to improve performance significantly. Their experiments show that this approach can achieve near-optimal results in dense-reward tasks, suggesting that prioritizing sample diversity over gradient updates is more beneficial for these types of problems.","title":"Surprisal-Guided Selection: A Better Approach for Test-Time Training"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the effectiveness of test-time training (TTT) in verification-grounded tasks, particularly in scenarios where a deterministic evaluator provides continuous rewards. The authors find that TTT often leads to over-sharpening, which reduces diversity and results in suboptimal solutions. Instead, they propose a method called surprisal-guided selection, which focuses on choosing low-confidence samples to improve performance significantly. Their experiments show that this approach can achieve near-optimal results in dense-reward tasks, suggesting that prioritizing sample diversity over gradient updates is more beneficial for these types of problems.', title='Surprisal-Guided Selection: A Better Approach for Test-Time Training'))
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TTTGPU1-580%50%","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TTTGPU1-580%50%', title=''))
[11.02.2026 15:56] Querying the API.
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SecCoderX uses online reinforcement learning to align large language models for secure code generation while preserving functionality, addressing the functionality-security trade-off through vulnerability detection integration and reward modeling.  					AI-generated summary 				 Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.
[11.02.2026 15:56] Response: ```json
{
  "desc": "SecCoderX      -  ,           .        :               .    -,           .   ,  SecCoderX     10%     ,         14-54%.",
  "emoji": "",
  "title": "   :     LLM-"
}
```
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SecCoderX uses online reinforcement learning to align large language models for secure code generation while preserving functionality, addressing the functionality-security trade-off through vulnerability detection integration and reward modeling.  					AI-generated summary 				 Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX."

[11.02.2026 15:56] Response: ```python
["RL", "TRAINING", "PLP"]
```
[11.02.2026 15:56] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SecCoderX uses online reinforcement learning to align large language models for secure code generation while preserving functionality, addressing the functionality-security trade-off through vulnerability detection integration and reward modeling.  					AI-generated summary 				 Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX."

[11.02.2026 15:56] Response: ```python
['ALIGNMENT', 'SECURITY', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SecCoderX is a novel framework that utilizes online reinforcement learning to enhance the security of code generated by large language models (LLMs) while maintaining their functionality. It addresses the common issue where improving code security often leads to a loss in utility, known as the functionality-security trade-off. By integrating vulnerability detection with secure code generation, SecCoderX employs a reasoning-based reward model to guide the learning process effectively. Experimental results show that SecCoderX significantly improves the Effective Safety Rate (ESR) of generated code compared to previous methods, making it a promising solution for secure software development.","title":"SecCoderX: Balancing Security and Functionality in Code Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SecCoderX is a novel framework that utilizes online reinforcement learning to enhance the security of code generated by large language models (LLMs) while maintaining their functionality. It addresses the common issue where improving code security often leads to a loss in utility, known as the functionality-security trade-off. By integrating vulnerability detection with secure code generation, SecCoderX employs a reasoning-based reward model to guide the learning process effectively. Experimental results show that SecCoderX significantly improves the Effective Safety Rate (ESR) of generated code compared to previous methods, making it a promising solution for secure software development.', title='SecCoderX: Balancing Security and Functionality in Code Generation'))
[11.02.2026 15:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SecCoderX SecCoderX ESR 10%","title":"SecCoderX"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SecCoderX SecCoderX ESR 10%', title='SecCoderX'))
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#benchmark", "#dataset"], "emoji": "", "ru": {"title": " :  -      ", "desc": "   VISTA-Bench       -  
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#training", "#inference"], "emoji": "", "ru": {"title": "  : -     ", "desc": "    offline-          
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#diffusion", "#training", "#optimization", "#architecture"], "emoji": "", "ru": {"title": "      ", "desc": "    Temporal Pair Consistency       , 
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#security", "#alignment"], "emoji": "", "ru": {"title": "     ", "desc": "SafePred         ,       
[11.02.2026 15:56] Using data from previous issue: {"categories": ["#interpretability", "#ethics", "#benchmark"], "emoji": "", "ru": {"title": "      :      ", "desc": "     SHARP       
[11.02.2026 15:56] Renaming data file.
[11.02.2026 15:56] Renaming previous data. hf_papers.json to ./d/2026-02-11.json
[11.02.2026 15:56] Saving new data file.
[11.02.2026 15:56] Generating page.
[11.02.2026 15:56] Renaming previous page.
[11.02.2026 15:56] Renaming previous data. index.html to ./d/2026-02-11.html
[11.02.2026 15:56] Writing result.
[11.02.2026 15:56] Renaming log file.
[11.02.2026 15:56] Renaming previous data. log.txt to ./logs/2026-02-11_last_log.txt
