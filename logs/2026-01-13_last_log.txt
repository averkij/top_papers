[13.01.2026 19:22] Read previous papers.
[13.01.2026 19:22] Generating top page (month).
[13.01.2026 19:22] Writing top page (month).
[13.01.2026 20:29] Read previous papers.
[13.01.2026 20:29] Get feed.
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06943
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06521
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05593
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06953
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07832
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05110
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07779
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07226
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07351
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05107
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.01528
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07526
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05823
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06165
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06860
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06803
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04698
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07055
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07376
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07767
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06411
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03666
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07786
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07181
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07033
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04577
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06993
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06944
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06747
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06463
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06423
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.05747
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.07790
[13.01.2026 20:29] Extract page data from URL. URL: https://huggingface.co/papers/2601.07239
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06966
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06496
[13.01.2026 20:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.06329
[13.01.2026 20:29] Extract page data from URL. URL: https://huggingface.co/papers/2601.06307
[13.01.2026 20:29] Extract page data from URL. URL: https://huggingface.co/papers/2601.06238
[13.01.2026 20:29] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[13.01.2026 20:29] No deleted papers detected.
[13.01.2026 20:29] Downloading and parsing papers (pdf, html). Total: 39.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06943.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06943.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06943.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06521.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06521.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06521.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.05593.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.05593.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.05593.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06953.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06953.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06953.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07832.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07832.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07832.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.05110.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.05110.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.05110.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07779.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07779.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07779.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07226.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07226.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07226.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07351.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07351.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07351.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.05107.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.05107.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.05107.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.01528.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.01528.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.01528.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07526.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07526.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07526.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.05823.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.05823.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.05823.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06165.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06165.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06165.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06860.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06860.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06860.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06803.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06803.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06803.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.04698.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.04698.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.04698.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07055.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07055.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07055.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07376.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07376.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07376.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07767.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07767.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07767.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06411.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06411.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06411.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.03666.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.03666.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.03666.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07786.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07786.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07786.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07181.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07181.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07181.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07033.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07033.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07033.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.04577.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.04577.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.04577.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06993.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06993.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06993.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06944.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06944.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06944.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06747.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06747.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06747.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06463.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06463.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06463.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06423.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06423.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06423.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.05747.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.05747.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.05747.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07790.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.07790.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.07790.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.07239.
[13.01.2026 20:29] Downloading paper 2601.07239 from https://arxiv.org/pdf/2601.07239v1...
[13.01.2026 20:29] Extracting affiliations from text.
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 1 ] . [ 1 9 3 2 7 0 . 1 0 6 2 : r Tanmay Joshi1, Shourya Aggarwal1, Anusa Saha1, Aadi Pandey1, Shreyash Dhoot1, Vighnesh Rai1, Raxit Goswami2, Aman Chadha3, Vinija Jain4, Amitava Das 2Raapid Lab, USA 3Apple, USA 4Google, USA, 1Pragya Lab, BITS Pilani Goa, India Abstract Deterministic inference is comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models (LLMs) move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented detailed analysis of nondeterminism in LLM inference, showing in widely discussed blog post how batch-invariant kernels and deterministic attention can be used to enforce bitwise-identical outputs for given prompt, effectively positioning deterministic inference as prerequisite for reproducibility, onpolicy RL, and enterprise reliability. In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills: it kills the ability to model uncertainty, makes emergent abilities vanish, disrupts reasoning abilities by killing multiple reasoning paths, and renders safety alignment brittle so that we lose honest generalization. LLMs implement conditional distributions pŒ∏(y x), not fixed functions (x); collapsing these distributions to single canonical output per prompt may feel reassuring, but it systematically hides the very properties that matter for artificial cognition. We instead advocate Stochastic CHAOSand claim that distributional variability is the heart of artificial cognition. We begin by disentangling algorithmic stochasticityintentional sampling in decoding (temperature, top-k/top-p, self-consistency, tree-of-thought)from numerical and systems nondeterminism (batching and floating-point artifacts even at temperature 0), and introduce three distinct stability goals for LLM inference: bitwise determinism (same bits, any load), distributio"
[13.01.2026 20:29] Response: ```python
[
    "Pragya Lab, BITS Pilani Goa, India",
    "Raapid Lab, USA",
    "Apple, USA",
    "Google, USA"
]
```
[13.01.2026 20:29] Deleting PDF ./assets/pdf/2601.07239.pdf.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06966.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06966.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06966.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06496.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06496.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06496.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06329.
[13.01.2026 20:29] Extra JSON file exists (./assets/json/2601.06329.json), skip PDF parsing.
[13.01.2026 20:29] Paper image links file exists (./assets/img_data/2601.06329.json), skip HTML parsing.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06307.
[13.01.2026 20:29] Downloading paper 2601.06307 from https://arxiv.org/pdf/2601.06307v1...
[13.01.2026 20:29] Extracting affiliations from text.
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality Ishika Agarwal*1, Zhenlin He*1, Dhruva Patil2, Dilek Hakkani-Tur1 1UIUC, 2Independent ishikaa2, zhenlin5, dilek@illinois.edu, dhruvakpatil@gmail.com 6 2 0 2 9 ] . [ 1 7 0 3 6 0 . 1 0 6 2 : r a "
[13.01.2026 20:29] Response: ```python
["UIUC"]
```
[13.01.2026 20:29] Deleting PDF ./assets/pdf/2601.06307.pdf.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Downloading and parsing paper https://huggingface.co/papers/2601.06238.
[13.01.2026 20:29] Downloading paper 2601.06238 from https://arxiv.org/pdf/2601.06238v1...
[13.01.2026 20:29] Extracting affiliations from text.
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 8 ] . [ 1 8 3 2 6 0 . 1 0 6 2 : r Arion Das1 Partha Pratim Saha4 Aman Chadha2 Vinija Jain3 Amitava Das4 1IIIT Ranchi 2Apple (USA) 3Google (USA) 4Pragya Lab, BITS Pilani, Goa "
[13.01.2026 20:29] Response: ```python
[
    "IIIT Ranchi",
    "Apple (USA)",
    "Google (USA)",
    "Pragya Lab, BITS Pilani, Goa"
]
```
[13.01.2026 20:29] Deleting PDF ./assets/pdf/2601.06238.pdf.
[13.01.2026 20:29] Success.
[13.01.2026 20:29] Enriching papers with extra data.
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 0. VideoDR benchmark enables video question answering by combining cross-frame visual extraction, web retrieval, and multi-hop reasoning in open-domain settings.  					AI-generated summary 				 In real-world video question answering scenarios, videos often provide only localized visual cues, while veri...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 1. Current multimodal large language models exhibit significant gaps in fundamental visual understanding compared to human children, as demonstrated by the BabyVision benchmark.  					AI-generated summary 				 While humans develop core visual skills long before acquiring language, contemporary Multimod...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 2. Parallel Coordinated Reasoning enables large-scale test-time compute scaling beyond sequential reasoning limitations through parallel exploration and message-passing architecture.  					AI-generated summary 				 We introduce Parallel Coordinated Reasoning (PaCoRe), a training-and-inference framework...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 3. Code LLMs trained on fully synthetic data using a feature-based synthesis pipeline achieve superior performance on competitive programming benchmarks while reducing dependence on real-world coding datasets.  					AI-generated summary 				 Competitive programming presents great challenges for Code LL...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 4. Multi-Head Linear Attention addresses the performance degradation in linear attention by preserving representational diversity through head-wise token dimension computation, maintaining linear complexity while recovering softmax attention's expressive power across multiple domains.  					AI-generate...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 5. Large reasoning models' inference latency can be reduced by routing reasoning steps to larger models based on the entropy of their first token, enabling efficient collaborative inference without additional training.  					AI-generated summary 				 Large Reasoning Models (LRMs) achieve remarkable per...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 6. OS-Symphony presents a comprehensive framework for computer-using agents that enhances robustness in long-horizon tasks through reflection-memory and multimodal search capabilities.  					AI-generated summary 				 While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents ...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 7. NoisyBench benchmark reveals significant performance degradation in state-of-the-art models when exposed to noisy contextual information, with agentic workflows amplifying errors and attention mechanisms disproportionately focusing on distractor tokens.  					AI-generated summary 				 Recent advance...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 8. EvoToken-DLM introduces a diffusion-based language modeling approach that uses soft token distributions and continuous trajectory supervision to enable revisable decoding and outperforms existing baselines.  					AI-generated summary 				 Diffusion Language Models (DLMs) offer a promising alternativ...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 9. A framework is presented that enables dynamic regulation of memory reliance in LLM-based agents, allowing users to control the balance between innovation and historical fidelity in long-term interactions.  					AI-generated summary 				 As LLM-based agents are increasingly used in long-term interact...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 10. DrivingGen presents the first comprehensive benchmark for generative driving world models, addressing limitations in existing evaluations through diverse datasets and metrics that assess visual realism, trajectory plausibility, temporal coherence, and controllability.  					AI-generated summary 				...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 11. MegaFlow is a distributed orchestration system that enables large-scale training and evaluation of agents on complex tasks by providing efficient scheduling, resource allocation, and task management through modular services.  					AI-generated summary 				 The rapid development of interactive and au...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 12. Latent Diffusion Models generate high-quality images by operating in compressed latent space, typically obtained through image tokenizers such as Variational Autoencoders (VAEs). In pursuit of a generation-friendly VAE, recent studies have explored leveraging Vision Foundation Models (VFMs) as repre...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 13. Real-world vision-language benchmarks reveal that under-specified user queries pose significant challenges for current models, with explicit query rewriting leading to substantial performance improvements.  					AI-generated summary 				 Current vision-language benchmarks predominantly feature well-...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 14. ET-Agent is a training framework that calibrates tool-use behavior in large language models through self-evolving data flywheels and behavior calibration training to improve task execution effectiveness.  					AI-generated summary 				 Large Language Models (LLMs) can extend their parameter knowledg...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 15. Laser introduces a new visual reasoning paradigm using dynamic windowed alignment learning to maintain global features during latent deduction while achieving superior performance with reduced computational overhead.  					AI-generated summary 				 While Chain-of-Thought empowers Large Vision-Langua...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 16. TourPlanner addresses travel planning challenges through multi-path reasoning and constraint-gated reinforcement learning to optimize both hard and soft constraints effectively.  					AI-generated summary 				 Travel planning is a sophisticated decision-making process that requires synthesizing mult...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 17. A data-free self-evolution framework enables large language models to autonomously improve reasoning capabilities through iterative question generation and solving, achieving performance comparable to supervised methods.  					AI-generated summary 				 As high-quality data becomes increasingly diffi...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 18. OpenTinker provides a modular infrastructure for reinforcement learning of large language model agents with separated components and managed execution runtime.  					AI-generated summary 				 We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) age...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 19. Large language models exhibit a disconnect between their expressed uncertainty and strategic decision-making under varying penalty conditions, failing to adjust abstention policies even when optimal.  					AI-generated summary 				 Large Language Models (LLMs) can produce surprisingly sophisticated ...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 20. Structured Episodic Event Memory (SEEM) enhances LLMs with hierarchical memory architecture combining graph and episodic layers for improved narrative coherence and reasoning.  					AI-generated summary 				 Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Re...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 21. Omni-modal embedding models face challenges with modality-dependent similarity scaling, ineffective in-batch negatives, and mismatched statistics across modalities, which are addressed through explicit alignment techniques including temperature calibration, controlled negative curriculum, and batch ...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 22. Analysis of AI-referencing code comments reveals that developers explicitly acknowledge technical debt in AI-assisted code, identifying patterns of postponed testing, incomplete adaptation, and limited understanding as key factors in AI-induced technical debt emergence.  					AI-generated summary 		...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 23. ShowUI-Aloha presents a pipeline that converts unstructured human screen recordings into structured GUI tasks through recording, semantic interpretation, planning, and execution components.  					AI-generated summary 				 Graphical User Interfaces (GUIs) are central to human-computer interaction, ye...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 24. Large language models struggle with maintaining long-range narrative dependencies, but a new framework called CFPG addresses this by structuring narrative continuity through executable causal predicates to ensure proper fulfillment of foreshadowed events.  					AI-generated summary 				 Foreshadowin...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 25. Sci-Reasoning dataset captures intellectual synthesis patterns in AI research through structured reasoning links from key papers to their predecessors, identifying 15 thinking patterns that drive breakthrough innovations.  					AI-generated summary 				 While AI innovation accelerates rapidly, the i...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 26. Multi-modal large language models struggle with fine-grained visual classification, and chain-of-thought reasoning harms performance due to increased reasoning length; a new framework called ReFine-RFT is proposed to address this issue through normalized multi-reward optimization.  					AI-generated...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 27. SketchJudge benchmark evaluates multimodal large language models' ability to grade hand-drawn STEM diagrams, revealing significant limitations in visual understanding compared to human performance.  					AI-generated summary 				 While Multimodal Large Language Models (MLLMs) have achieved remarkabl...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 28. FinForge presents a scalable semi-synthetic pipeline for creating domain-specific financial evaluation benchmarks using expert curation and language model synthesis, demonstrating significant variations in financial reasoning capabilities among state-of-the-art models.  					AI-generated summary 			...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 29. Gecko is a neural architecture that improves long-range dependency capture through exponential moving average with gated attention and additional components like timestep decay normalization and sliding chunk attention, achieving efficient processing of arbitrary-length sequential data with superior...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 30. Self-consistency improves reasoning accuracy for some models while potentially sacrificing faithfulness, with varying effects across different language models and problem difficulties.  					AI-generated summary 				 Self-consistency has emerged as a popular technique for improving large language mo...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 31. A lightweight aerial human pose estimation system achieves improved accuracy and real-time performance through multi-dataset training and deployment on UAV platforms.  					AI-generated summary 				 Unmanned Aerial Vehicles (UAVs) are increasingly deployed in close proximity to humans for applicatio...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 32. Severity classification in system logs serves as a benchmark for evaluating model comprehension and deployability, with retrieval-augmented generation improving performance across small language models while efficiency varies significantly.  					AI-generated summary 				 System logs are crucial for...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 33. Deterministic inference in large language models suppresses uncertainty modeling, emergent abilities, and safety awareness by enforcing single-output predictions instead of maintaining distributional variability.  					AI-generated summary 				 Deterministic inference is a comforting ideal in classi...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 34. RealMem benchmark evaluates memory systems for long-term project-oriented interactions in large language models, revealing challenges in managing dynamic context dependencies.  					AI-generated summary 				 As Large Language Models (LLMs) evolve from static dialogue interfaces to autonomous general...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 35. 3D CoCa v2 enhances 3D captioning by combining contrastive vision-language learning with spatially-aware 3D scene encoding and test-time search for improved generalization across diverse environments.  					AI-generated summary 				 Spatial intelligence refers to the ability to perceive, reason abou...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 36. Speech models trained on raw audio can generate appropriate content while maintaining speaker and emotion attributes, but traditional text-based evaluation methods underestimate speech characteristics; new evaluation approaches better correlate with human perception.  					AI-generated summary 				 ...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 37. GRPO-style fine-tuning with MTQE models as rewards improves idiom translation by 14 points while enhancing general translation and cross-lingual capabilities.  					AI-generated summary 				 Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural ...
[13.01.2026 20:29] ********************************************************************************
[13.01.2026 20:29] Abstract 38. SPINAL diagnoses how DPO alignment reshapes representations layer by layer, revealing geometric localization of preference gradients in final decoder blocks and enabling practical auditing of alignment progress.  					AI-generated summary 				 Direct Preference Optimization (DPO) is a principled, sc...
[13.01.2026 20:29] Read previous papers.
[13.01.2026 20:29] Generating reviews via LLM API.
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#rag", "#video", "#agents", "#benchmark", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–û—Ç –≤–∏–¥–µ–æ –∫ –∑–Ω–∞–Ω–∏—è–º: –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–π –ø–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ –≤–µ–±", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ VideoDR –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –≤–∏–¥–µ–æ –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –≤–µ–±-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ. –ú–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#cv", "#dataset"], "emoji": "üë∂", "ru": {"title": "–î–µ—Ç–∏ –≤–∏–¥—è—Ç –ª—É—á—à–µ: –ø–æ—á–µ–º—É —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Å–ª–µ–ø—ã –∫ –±–∞–∑–æ–≤–æ–º—É –∑—Ä–µ–Ω–∏—é", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –±–µ–Ω—á–º–∞—Ä–∫ BabyVision –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–∞–∑–æ–≤—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –Ω–µ
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#training", "#long_context", "#open_source", "#benchmark", "#math", "#reasoning", "#rl", "#inference"], "emoji": "üîÄ", "ru": {"title": "–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω Parallel Coordinated Reasonin
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#dataset", "#training", "#synthetic", "#small_models", "#benchmark", "#plp", "#data"], "emoji": "ü§ñ", "ru": {"title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –≤–º–µ—Å—Ç–æ —Ä–µ–∞–ª—å–Ω—ã—Ö: –∫–∞–∫ –Ω–∞—É—á–∏—Ç—å LLM –ø–∏—Å–∞—Ç—å –∫–æ–¥ –±–µ–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∞–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "‚ö°", "ru": {"title": "–õ–∏–Ω–µ–π–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —á–µ—Ä–µ–∑ –º–Ω–æ–≥–æ–≥–æ–ª–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç Multi-Head Linear Attention (MHLA) ‚Äî –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –¥–µ–≥—Ä–∞–¥–∞
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization", "#reasoning", "#inference"], "emoji": "‚ö°", "ru": {"title": "–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —à–∞–≥–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø–æ –ø–µ—Ä–≤–æ–º—É —Ç–æ–∫–µ–Ω—É –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ GlimpRouter –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#agents", "#multimodal", "#long_context", "#reasoning"], "emoji": "üéº", "ru": {"title": "–û—Ä–∫–µ—Å—Ç—Ä–æ–≤–∫–∞ –ø–∞–º—è—Ç–∏ –∏ –ø–æ–∏—Å–∫–∞ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º", "desc": "OS-Symphony ‚Äî —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤, —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º, 
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#security", "#rag", "#alignment", "#agents", "#benchmark"], "emoji": "üîß", "ru": {"title": "–ö–∞–∫ –Ω–∞—É—á–∏—Ç—å AI-–º–æ–¥–µ–ª–∏ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —à—É–º –≤ –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –±–µ–Ω—á–º–∞—Ä–∫ NoisyBench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ —à—É–º–Ω—ã–º –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º –≤
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#diffusion"], "emoji": "üåä", "ru": {"title": "–ú—è–≥–∫–∏–µ —Ç–æ–∫–µ–Ω—ã –≤–º–µ—Å—Ç–æ –∂—ë—Å—Ç–∫–∏—Ö –º–∞—Å–æ–∫: –ø—É—Ç—å –∫ –≥–∏–±–∫–æ–º—É –ø–µ—Ä–µ—Å–º–æ—Ç—Ä—É —Ä–µ—à–µ–Ω–∏–π –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "EvoToken-DLM –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —è–∑—ã–∫–æ–≤–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º—è–≥–∫–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç
[13.01.2026 20:29] Using data from previous issue: {"categories": [], "emoji": "üéöÔ∏è", "ru": {"title": "–£–ø—Ä–∞–≤–ª—è–µ–º–∞—è –ø–∞–º—è—Ç—å: –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∏–Ω–Ω–æ–≤–∞—Ü–∏–µ–π –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é –≤ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ SteeM –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–∞–º—è—Ç–∏ –≤ LLM-–∞–≥–µ–Ω—Ç–∞—Ö, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –±–∞–ª–∞–Ω
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#survey", "#diffusion", "#synthetic"], "emoji": "üöó", "ru": {"title": "–ï–¥–∏–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–∏–º—É–ª—è—Ü–∏–∏ –≤–æ–∂–¥–µ–Ω–∏—è", "desc": "DrivingGen –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∏—Ä–∞ –≤–æ–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#open_source", "#training", "#agents"], "emoji": "üîÑ", "ru": {"title": "–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤", "desc": "MegaFlow ‚Äî —ç—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö. –°–∏—Å—Ç–µ
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization", "#diffusion", "#cv"], "emoji": "üé®", "ru": {"title": "–î–∏sentangled –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: VAE –ø–µ—Ä–µ—É—á–∏–≤–∞–µ—Ç—Å—è –ø–æ-–Ω–æ–≤–æ–º—É", "desc": "–†–∞–±–æ—Ç–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç Send-VAE ‚Äî –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–π –∞–≤—Ç–æ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –¥–∏sent
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#dataset", "#low_resource", "#cv"], "emoji": "üîç", "ru": {"title": "–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –Ω–µ—è—Å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Äî –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é –∑—Ä–∏—Ç–µ–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç HAERAE-Vision, –±–µ–Ω—á–º–∞—Ä–∫ –∏–∑ 653 —Ä–µ–∞–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –∫–æ—Ä–µ–π—Å–∫–∏—Ö –æ–Ω–ª
[13.01.2026 20:29] Using data from previous issue: {"categories": [], "emoji": "üîß", "ru": {"title": "–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "desc": "ET-Agent ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –∫–∞–ª–∏–±—Ä—É–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ —á–µ—Ä–µ–∑ —Å–∞–º–æ—ç–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä—É—é—â
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#multimodal", "#architecture", "#inference", "#reasoning", "#interpretability"], "emoji": "üå≥", "ru": {"title": "–õ–µ—Å –ø—Ä–µ–∂–¥–µ –¥–µ—Ä–µ–≤—å–µ–≤: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º", "desc": "Laser ‚Äî —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#rl", "#benchmark"], "emoji": "‚úàÔ∏è", "ru": {"title": "–ú–Ω–æ–≥–æ–ø—É—Ç–µ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–π", "desc": "TourPlanner —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–π, –∏—Å–ø–æ–ª—å–∑—É—è –º–Ω–æ–≥–æ–ø—É—Ç–µ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –≥–µ–π—Ç–∏–Ω–≥–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π. –°–∏—Å—Ç–µ–º–∞ —Å–Ω–∞—á–∞–ª–∞ –ø
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#optimization", "#training", "#agents", "#synthetic"], "emoji": "üîÑ", "ru": {"title": "–°–∞–º–æ—ç–≤–æ–ª—é—Ü–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏ —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Dr. Zero, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª—å—à–∏–º —è–∑—ã–∫–æ–≤—ã–º 
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#training", "#agents", "#rl", "#architecture"], "emoji": "üîß", "ru": {"title": "–ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –≥–∏–±–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è LLM-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "OpenTinker ‚Äî —ç—Ç–æ –º–æ–¥—É–ª—å–Ω–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º LLM-–∞–≥–µ–Ω—Ç–æ–≤, —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π –¥–∏–∑–∞–π–Ω, –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –∏ –≤–∑–∞–∏–º
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#reasoning"], "emoji": "‚öñÔ∏è", "ru": {"title": "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: –ø–æ—á–µ–º—É LLM –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç —Ä–∏—Å–∫ –≤ —Ä–µ—à–µ–Ω–∏—è—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –Ω–µ –º–æ–≥—É—Ç –∞–¥–µ–∫–≤–∞—Ç–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ –æ—Ü–µ–Ω–∫–∏ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –ø—Ä–∏
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#reasoning", "#rag", "#long_context", "#agents", "#graphs", "#benchmark"], "emoji": "üß†", "ru": {"title": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ SEEM (Structured Episodic Event Memory), –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#training", "#open_source", "#multimodal", "#optimization", "#benchmark"], "emoji": "üåà", "ru": {"title": "–Ø–≤–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –¥–ª—è –Ω–∞–¥—ë–∂–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –≤–ª–æ–∂–µ–Ω–∏–π", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ e5-omni –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–ª–æ–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã
[13.01.2026 20:29] Using data from previous issue: {"categories": [], "emoji": "‚öôÔ∏è", "ru": {"title": "–ö–æ–≥–¥–∞ AI –ø–æ–º–æ–≥–∞–µ—Ç, –Ω–æ —Å–æ–∑–¥–∞—ë—Ç –¥–æ–ª–≥–∏: –ø—Ä–∏–∑–Ω–∞–Ω–Ω–∞—è –Ω–µ–ø–æ–ª–Ω–æ—Ç–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –∫–æ–¥–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –∫–æ–¥–µ, –≥–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –ø—Ä–∏–∑–Ω–∞—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –Ω–∞–ª–∏—á–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞. –£—á—ë–Ω—ã–µ –∏–∑—É—á–∏–ª–∏ 6540 –∫–æ–º–º–µ
[13.01.2026 20:29] Using data from previous issue: {"categories": [], "emoji": "üñ•Ô∏è", "ru": {"title": "–û—Ç –∑–∞–ø–∏—Å–µ–π –∫ –¥–µ–π—Å—Ç–≤–∏—è–º: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è GUI-–∑–∞–¥–∞—á —á–µ—Ä–µ–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é", "desc": "ShowUI-Aloha –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π pipeline –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–µ–π –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —á–µ–ª–æ–≤–µ–∫–∞ —Å —ç–∫—Ä–∞–Ω–æ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–¥
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#long_context", "#story_generation", "#reasoning"], "emoji": "üî´", "ru": {"title": "–û—Ç –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω–æ–π –±–µ–≥–ª–æ—Å—Ç–∏ –∫ –ø–æ–¥–ª–∏–Ω–Ω–æ–π –Ω–∞—Ä—Ä–∞—Ç–∏–≤–Ω–æ–π –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –∫–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—é –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ CFPG –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#reasoning", "#science", "#synthetic"], "emoji": "üß†", "ru": {"title": "–ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞—É—á–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ –≤ AI-Á†îÁ©∂", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –¥–∞—Ç–∞—Å–µ—Ç Sci-Reasoning, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã, –ª–µ–∂–∞—â–∏–µ –≤ –æ—Å–Ω–æ–≤–µ
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#rlhf", "#optimization", "#cv", "#benchmark", "#multimodal"], "emoji": "üîç", "ru": {"title": "–ú–µ–Ω—å—à–µ –¥—É–º–∞—Ç—å, –ª—É—á—à–µ –≤–∏–¥–µ—Ç—å: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", "desc": "–ú–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω—ã–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –ø–ª–æ—Ö–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å 
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#cv", "#dataset"], "emoji": "‚úèÔ∏è", "ru": {"title": "–ö–æ–≥–¥–∞ –¥–∞–∂–µ —É–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ –º–æ–≥—É—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —à–∫–æ–ª—å–Ω—ã–π —Ä–∏—Å—É–Ω–æ–∫", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –±–µ–Ω—á–º–∞—Ä–∫ SketchJudge –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≤–µ—Ä—è—Ç—å –∏ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å —Ä—É–∫–æ
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#synthetic", "#open_source", "#science"], "emoji": "üí∞", "ru": {"title": "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —É–º–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –∏–∑–º–µ—Ä–µ–Ω–∏–µ –∏ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏–µ", "desc": "FinForge –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –ø–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º, –∫–æ–º–±–∏–Ω–∏—Ä—É—è —Ä—É
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#open_source", "#architecture", "#optimization", "#long_context", "#training"], "emoji": "ü¶é", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –±–µ–∑ –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏", "desc": "Gecko ‚Äî —ç—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –∑–∞—Ö–≤–∞—Ç –¥–∞–ª—å–Ω–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–≤–∏—Å–∏–º
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#interpretability", "#math", "#benchmark", "#training", "#reasoning"], "emoji": "üéØ", "ru": {"title": "Self-consistency —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∂–∞—Ç—å –≤–µ—Ä–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Ç–µ—Ö–Ω–∏–∫–∞ self-consistency, –∫–æ—Ç–æ—Ä–∞—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ü–µ–ø–æ
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#open_source", "#small_models", "#robotics", "#inference", "#cv", "#dataset"], "emoji": "üöÅ", "ru": {"title": "–õ–µ–≥–∫–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–æ–∑—ã —á–µ–ª–æ–≤–µ–∫–∞ —Å –¥—Ä–æ–Ω–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –æ–±–ª–µ–≥—á–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ FlyPose –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–∑—ã —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#benchmark", "#small_models", "#inference", "#rag"], "emoji": "üìä", "ru": {"title": "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –ª–æ–≥–æ–≤ –∫–∞–∫ —Ç–µ—Å—Ç –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º –¥–ª—è –º–∞–ª—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Ä–æ–≤–Ω–µ–π —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ª–æ–≥–∞—Ö Linux –∫–∞–∫ —ç—Ç–∞–ª–æ–Ω –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
[13.01.2026 20:29] Querying the API.
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Deterministic inference in large language models suppresses uncertainty modeling, emergent abilities, and safety awareness by enforcing single-output predictions instead of maintaining distributional variability.  					AI-generated summary 				 Deterministic inference is a comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented a detailed analysis of nondeterminism in LLM inference, showing how batch-invariant kernels and deterministic attention can enforce bitwise-identical outputs, positioning deterministic inference as a prerequisite for reproducibility and enterprise reliability.   In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills. It kills the ability to model uncertainty, suppresses emergent abilities, collapses reasoning into a single brittle path, and weakens safety alignment by hiding tail risks. LLMs implement conditional distributions over outputs, not fixed functions. Collapsing these distributions to a single canonical completion may appear reassuring, but it systematically conceals properties central to artificial cognition. We instead advocate Stochastic CHAOS, treating distributional variability as a signal to be measured and controlled.   Empirically, we show that deterministic inference is systematically misleading. Single-sample deterministic evaluation underestimates both capability and fragility, masking failure probability under paraphrases and noise. Phase-like transitions associated with emergent abilities disappear under greedy decoding. Multi-path reasoning degrades when forced onto deterministic backbones, reducing accuracy and diagnostic insight. Finally, deterministic evaluation underestimates safety risk by hiding rare but dangerous behaviors that appear only under multi-sample evaluation.
[13.01.2026 20:29] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –∞–≤—Ç–æ—Ä—ã –¥–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –≤—Ä–µ–¥–∏—Ç –∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º. –û–Ω–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –≤—ã—Ö–æ–¥–∞ —Å–∫—Ä—ã–≤–∞–µ—Ç –∏—Å—Ç–∏–Ω–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –∏ –ø–æ–¥–∞–≤–ª—è–µ—Ç –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø–æ–¥—Ö–æ–¥ Stochastic CHAOS, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∫–∞–∫ –≤–∞–∂–Ω—ã–π —Å–∏–≥–Ω–∞–ª, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏–∑–º–µ—Ä—è—Ç—å –∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å. –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç, —á—Ç–æ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–¥–æ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏, —Ç–∞–∫ –∏ –µ—ë —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.",
  "emoji": "üé≤",
  "title": "–°—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å —Å–ø–∞—Å–∞–µ—Ç: –ø–æ—á–µ–º—É —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –≤ LLM –∫—Ä–∏—Ç–∏—á–Ω–∞"
}
```
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Deterministic inference in large language models suppresses uncertainty modeling, emergent abilities, and safety awareness by enforcing single-output predictions instead of maintaining distributional variability.  					AI-generated summary 				 Deterministic inference is a comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented a detailed analysis of nondeterminism in LLM inference, showing how batch-invariant kernels and deterministic attention can enforce bitwise-identical outputs, positioning deterministic inference as a prerequisite for reproducibility and enterprise reliability.   In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills. It kills the ability to model uncertainty, suppresses emergent abilities, collapses reasoning into a single brittle path, and weakens safety alignment by hiding tail risks. LLMs implement conditional distributions over outputs, not fixed functions. Collapsing these distributions to a single canonical completion may appear reassuring, but it systematically conceals properties central to artificial cognition. We instead advocate Stochastic CHAOS, treating distributional variability as a signal to be measured and controlled.   Empirically, we show that deterministic inference is systematically misleading. Single-sample deterministic evaluation underestimates both capability and fragility, masking failure probability under paraphrases and noise. Phase-like transitions associated with emergent abilities disappear under greedy decoding. Multi-path reasoning degrades when forced onto deterministic backbones, reducing accuracy and diagnostic insight. Finally, deterministic evaluation underestimates safety risk by hiding rare but dangerous behaviors that appear only under multi-sample evaluation."

[13.01.2026 20:29] Response: ```python
["INFERENCE", "TRAINING"]
```
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Deterministic inference in large language models suppresses uncertainty modeling, emergent abilities, and safety awareness by enforcing single-output predictions instead of maintaining distributional variability.  					AI-generated summary 				 Deterministic inference is a comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented a detailed analysis of nondeterminism in LLM inference, showing how batch-invariant kernels and deterministic attention can enforce bitwise-identical outputs, positioning deterministic inference as a prerequisite for reproducibility and enterprise reliability.   In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills. It kills the ability to model uncertainty, suppresses emergent abilities, collapses reasoning into a single brittle path, and weakens safety alignment by hiding tail risks. LLMs implement conditional distributions over outputs, not fixed functions. Collapsing these distributions to a single canonical completion may appear reassuring, but it systematically conceals properties central to artificial cognition. We instead advocate Stochastic CHAOS, treating distributional variability as a signal to be measured and controlled.   Empirically, we show that deterministic inference is systematically misleading. Single-sample deterministic evaluation underestimates both capability and fragility, masking failure probability under paraphrases and noise. Phase-like transitions associated with emergent abilities disappear under greedy decoding. Multi-path reasoning degrades when forced onto deterministic backbones, reducing accuracy and diagnostic insight. Finally, deterministic evaluation underestimates safety risk by hiding rare but dangerous behaviors that appear only under multi-sample evaluation."

[13.01.2026 20:29] Response: ```python
['REASONING', 'ALIGNMENT', 'SECURITY', 'INTERPRETABILITY']
```
[13.01.2026 20:29] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper critiques the use of deterministic inference in large language models (LLMs), arguing that it limits their ability to model uncertainty and emergent capabilities. The authors highlight that enforcing single-output predictions can lead to brittle reasoning and increased safety risks by masking potential failures. They propose an alternative approach called Stochastic CHAOS, which embraces distributional variability as a valuable aspect of LLMs. Empirical evidence is presented to show that deterministic methods can misrepresent the true capabilities and risks associated with LLMs, advocating for a more nuanced evaluation strategy.","title":"Embrace Uncertainty: The Case Against Deterministic Inference in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper critiques the use of deterministic inference in large language models (LLMs), arguing that it limits their ability to model uncertainty and emergent capabilities. The authors highlight that enforcing single-output predictions can lead to brittle reasoning and increased safety risks by masking potential failures. They propose an alternative approach called Stochastic CHAOS, which embraces distributional variability as a valuable aspect of LLMs. Empirical evidence is presented to show that deterministic methods can misrepresent the true capabilities and risks associated with LLMs, advocating for a more nuanced evaluation strategy.', title='Embrace Uncertainty: The Case Against Deterministic Inference in LLMs'))
[13.01.2026 20:29] Response: ParsedChatCompletionMessage[Article](content='{"desc":"ËøôÁØáËÆ∫ÊñáÊé¢ËÆ®‰∫ÜÂú®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏≠ÔºåÁ°ÆÂÆöÊÄßÊé®ÁêÜÂ¶Ç‰ΩïÊäëÂà∂‰∏çÁ°ÆÂÆöÊÄßÂª∫Ê®°ÂíåÊñ∞ÂÖ¥ËÉΩÂäõ„ÄÇ‰ΩúËÄÖËÆ§‰∏∫ÔºåÂº∫Âà∂Âçï‰∏ÄËæìÂá∫È¢ÑÊµã‰ºöÂØºËá¥Êé®ÁêÜËøáÁ®ãÂèòÂæóËÑÜÂº±ÔºåÂπ∂ÂâäÂº±ÂÆâÂÖ®ÊÄßÊÑèËØÜ„ÄÇÁõ∏ÂèçÔºåËÆ∫ÊñáÊèêÂÄ°‰ΩøÁî®ÈöèÊú∫Ê∑∑Ê≤åÔºàStochastic CHAOSÔºâÔºåÂ∞ÜÂàÜÂ∏ÉÂèòÂºÇÊÄßËßÜ‰∏∫ÈúÄË¶ÅÊµãÈáèÂíåÊéßÂà∂ÁöÑ‰ø°Âè∑„ÄÇÈÄöËøáÂÆûËØÅÁ†îÁ©∂Ôºå‰ΩúËÄÖÂ±ïÁ§∫‰∫ÜÁ°ÆÂÆöÊÄßÊé®ÁêÜÂú®ËØÑ‰º∞ËÉΩÂäõÂíåËÑÜÂº±ÊÄßÊó∂ÁöÑÁ≥ªÁªüÊÄßËØØÂØº„ÄÇ","title":"ÈöèÊú∫Ê∑∑Ê≤åÔºöËß£ÊîæÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊΩúÂäõ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='ËøôÁØáËÆ∫ÊñáÊé¢ËÆ®‰∫ÜÂú®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏≠ÔºåÁ°ÆÂÆöÊÄßÊé®ÁêÜÂ¶Ç‰ΩïÊäëÂà∂‰∏çÁ°ÆÂÆöÊÄßÂª∫Ê®°ÂíåÊñ∞ÂÖ¥ËÉΩÂäõ„ÄÇ‰ΩúËÄÖËÆ§‰∏∫ÔºåÂº∫Âà∂Âçï‰∏ÄËæìÂá∫È¢ÑÊµã‰ºöÂØºËá¥Êé®ÁêÜËøáÁ®ãÂèòÂæóËÑÜÂº±ÔºåÂπ∂ÂâäÂº±ÂÆâÂÖ®ÊÄßÊÑèËØÜ„ÄÇÁõ∏ÂèçÔºåËÆ∫ÊñáÊèêÂÄ°‰ΩøÁî®ÈöèÊú∫Ê∑∑Ê≤åÔºàStochastic CHAOSÔºâÔºåÂ∞ÜÂàÜÂ∏ÉÂèòÂºÇÊÄßËßÜ‰∏∫ÈúÄË¶ÅÊµãÈáèÂíåÊéßÂà∂ÁöÑ‰ø°Âè∑„ÄÇÈÄöËøáÂÆûËØÅÁ†îÁ©∂Ôºå‰ΩúËÄÖÂ±ïÁ§∫‰∫ÜÁ°ÆÂÆöÊÄßÊé®ÁêÜÂú®ËØÑ‰º∞ËÉΩÂäõÂíåËÑÜÂº±ÊÄßÊó∂ÁöÑÁ≥ªÁªüÊÄßËØØÂØº„ÄÇ', title='ÈöèÊú∫Ê∑∑Ê≤åÔºöËß£ÊîæÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊΩúÂäõ'))
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#open_source", "#long_context"], "emoji": "üß†", "ru": {"title": "–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–≥–æ—Å–µ–∞–Ω—Å–æ–≤—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –±–µ–Ω—á–º–∞—Ä–∫ RealMem –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º –ø–∞–º—è—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –ø—Ä–∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#open_source"], "emoji": "üé¨", "ru": {"title": "–¢—Ä—ë—Ö–º–µ—Ä–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –±–µ–∑ –≥—Ä–∞–Ω–∏—Ü: –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞", "desc": "3D CoCa v2 ‚Äî —ç—Ç–æ —É–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö —Å—Ü–µ–Ω –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤–∏–¥–µ–Ω–∏—è –∏ —è–∑—ã–∫
[13.01.2026 20:29] Using data from previous issue: {"categories": ["#audio", "#benchmark"], "emoji": "üé§", "ru": {"title": "–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–µ—á–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫, –∞ –Ω–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤", "desc": "–í —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É—é—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω—ã–µ –Ω–∞ —Å—ã—Ä–æ–º –∞—É–¥–∏–æ, –∫–æ—Ç–æ—Ä—ã–µ —Å–ø–æ—Å–æ–±–Ω—ã –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–µ—á–µ–≤—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, 
[13.01.2026 20:29] Querying the API.
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

GRPO-style fine-tuning with MTQE models as rewards improves idiom translation by 14 points while enhancing general translation and cross-lingual capabilities.  					AI-generated summary 				 Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by ~14 points, general, non-idiomatic translation implicitly improves by ~8 points, and cross-lingual translation abilities (trained on one language, evaluated on another) improves by ~6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding.
[13.01.2026 20:29] Response: ```json
{
  "desc": "–í —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–¥–∏–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–ª–æ—Ö–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –Ω–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ —Ñ—Ä–∞–∑–∞–º–∏, –∫–æ–¥–∏—Ä—É—é—â–∏–º–∏ –∫—É–ª—å—Ç—É—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç GRPO-style fine-tuning —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ (MTQE) –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–æ–≤ –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–¥–∏–æ–º–∞–º–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º –∏ —Ö–∏–Ω–¥–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –ø–æ–∫–∞–∑–∞–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–¥–∏–æ–º –Ω–∞ 14 –ø—É–Ω–∫—Ç–æ–≤, –∞ —Ç–∞–∫–∂–µ –∫–æ—Å–≤–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ 8 –ø—É–Ω–∫—Ç–æ–≤ –∏ –∫—Ä–æ—Å—Å—è–∑—ã—á–Ω—ã—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ 6 –ø—É–Ω–∫—Ç–æ–≤. –†–∞–±–æ—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑—Ä—ã–≤ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ –Ω–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø–æ–¥—Ö–æ–¥ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è LLM —Å –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫—Ä–æ—Å—Å-–∫—É–ª—å—Ç—É—Ä–Ω–æ–≥–æ –∏ —Ñ–∏–≥—É—Ä–∞–ª—å–Ω–æ–≥–æ —è–∑—ã–∫–∞.",
  "emoji": "üåâ",
  "title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ –∫—É–ª—å—Ç—É—Ä–Ω–æ–≥–æ —Ä–∞–∑—Ä—ã–≤–∞: –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–¥–∏–æ–º"
}
```
[13.01.2026 20:29] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"GRPO-style fine-tuning with MTQE models as rewards improves idiom translation by 14 points while enhancing general translation and cross-lingual capabilities.  					AI-generated summary 				 Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by ~14 points, general, non-idiomatic translation implicitly improves by ~8 points, and cross-lingual translation abilities (trained on one language, evaluated on another) improves by ~6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding."

[13.01.2026 20:30] Response: ```python
['RLHF', 'MULTILINGUAL', 'TRAINING']
```
[13.01.2026 20:30] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"GRPO-style fine-tuning with MTQE models as rewards improves idiom translation by 14 points while enhancing general translation and cross-lingual capabilities.  					AI-generated summary 				 Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by ~14 points, general, non-idiomatic translation implicitly improves by ~8 points, and cross-lingual translation abilities (trained on one language, evaluated on another) improves by ~6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding."

[13.01.2026 20:30] Response: ```python
['TRANSLATION', 'OPTIMIZATION', 'TRANSFER_LEARNING']
```
[13.01.2026 20:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of translating idioms and other non-compositional expressions in neural machine translation. It proposes a method called GRPO-style fine-tuning, which utilizes Machine Translation Quality Estimation (MTQE) models as reward functions to enhance translation accuracy. The study shows that this approach improves idiom translation by approximately 14 points, while also boosting general translation and cross-lingual capabilities. The findings highlight the importance of understanding cultural nuances in language and provide a pathway for developing more effective language models.","title":"Enhancing Idiom Translation with GRPO and MTQE"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenge of translating idioms and other non-compositional expressions in neural machine translation. It proposes a method called GRPO-style fine-tuning, which utilizes Machine Translation Quality Estimation (MTQE) models as reward functions to enhance translation accuracy. The study shows that this approach improves idiom translation by approximately 14 points, while also boosting general translation and cross-lingual capabilities. The findings highlight the importance of understanding cultural nuances in language and provide a pathway for developing more effective language models.', title='Enhancing Idiom Translation with GRPO and MTQE'))
[13.01.2026 20:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ËÆ∫ÊñáÊé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÈÄöËøáGRPOÈ£éÊ†ºÁöÑÂæÆË∞ÉÂíåÊú∫Âô®ÁøªËØëË¥®ÈáèËØÑ‰º∞ÔºàMTQEÔºâÊ®°Âûã‰Ωú‰∏∫Â•ñÂä±ÂáΩÊï∞ÔºåÊù•ÊîπÂñÑÊàêËØ≠ÁøªËØëÁöÑÊïàÊûú„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºå‰ΩøÁî®ËøôÁßçÊñπÊ≥ïÔºåÊàêËØ≠ÁøªËØëÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜÁ∫¶14‰∏™ÁôæÂàÜÁÇπÔºåÂêåÊó∂‰∏ÄËà¨ÁøªËØëÂíåË∑®ËØ≠Ë®ÄËÉΩÂäõ‰πüÂæóÂà∞‰∫ÜÊèêÂçá„ÄÇÈÄöËøáÂØπ‰∏≠ÊñáÂíåÂç∞Âú∞ËØ≠ÊàêËØ≠Êï∞ÊçÆÈõÜÁöÑÂÆûÈ™åÔºåÂèëÁé∞ÈùûÊàêËØ≠ÁøªËØëÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜÁ∫¶8‰∏™ÁôæÂàÜÁÇπÔºåË∑®ËØ≠Ë®ÄÁøªËØëËÉΩÂäõÊèêÈ´ò‰∫ÜÁ∫¶6‰∏™ÁôæÂàÜÁÇπ„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåËøôÈ°πÁ†îÁ©∂ÈáèÂåñ‰∫ÜÈùûÁªÑÂêàÁøªËØëÁöÑÂ∑ÆË∑ùÔºåÂπ∂‰∏∫ÂºÄÂèëÂÖ∑ÊúâÊõ¥Âº∫Ë∑®ÊñáÂåñÂíåÊØîÂñªËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõ‰∫ÜËßÅËß£„ÄÇ","title":"ÊèêÂçáÊàêËØ≠ÁøªËØëÁöÑÊô∫ËÉΩÊñπÊ≥ï"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ËÆ∫ÊñáÊé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÈÄöËøáGRPOÈ£éÊ†ºÁöÑÂæÆË∞ÉÂíåÊú∫Âô®ÁøªËØëË¥®ÈáèËØÑ‰º∞ÔºàMTQEÔºâÊ®°Âûã‰Ωú‰∏∫Â•ñÂä±ÂáΩÊï∞ÔºåÊù•ÊîπÂñÑÊàêËØ≠ÁøªËØëÁöÑÊïàÊûú„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºå‰ΩøÁî®ËøôÁßçÊñπÊ≥ïÔºåÊàêËØ≠ÁøªËØëÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜÁ∫¶14‰∏™ÁôæÂàÜÁÇπÔºåÂêåÊó∂‰∏ÄËà¨ÁøªËØëÂíåË∑®ËØ≠Ë®ÄËÉΩÂäõ‰πüÂæóÂà∞‰∫ÜÊèêÂçá„ÄÇÈÄöËøáÂØπ‰∏≠ÊñáÂíåÂç∞Âú∞ËØ≠ÊàêËØ≠Êï∞ÊçÆÈõÜÁöÑÂÆûÈ™åÔºåÂèëÁé∞ÈùûÊàêËØ≠ÁøªËØëÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜÁ∫¶8‰∏™ÁôæÂàÜÁÇπÔºåË∑®ËØ≠Ë®ÄÁøªËØëËÉΩÂäõÊèêÈ´ò‰∫ÜÁ∫¶6‰∏™ÁôæÂàÜÁÇπ„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåËøôÈ°πÁ†îÁ©∂ÈáèÂåñ‰∫ÜÈùûÁªÑÂêàÁøªËØëÁöÑÂ∑ÆË∑ùÔºåÂπ∂‰∏∫ÂºÄÂèëÂÖ∑ÊúâÊõ¥Âº∫Ë∑®ÊñáÂåñÂíåÊØîÂñªËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõ‰∫ÜËßÅËß£„ÄÇ', title='ÊèêÂçáÊàêËØ≠ÁøªËØëÁöÑÊô∫ËÉΩÊñπÊ≥ï'))
[13.01.2026 20:30] Querying the API.
[13.01.2026 20:30] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SPINAL diagnoses how DPO alignment reshapes representations layer by layer, revealing geometric localization of preference gradients in final decoder blocks and enabling practical auditing of alignment progress.  					AI-generated summary 				 Direct Preference Optimization (DPO) is a principled, scalable alternative to RLHF for aligning large language models from pairwise preferences, but its internal geometric footprint remains undercharacterized, limiting audits, checkpoint comparisons, and failure prediction. We introduce SPINAL (Scaling-law and Preference Integration in Neural Alignment Layers), a diagnostic that measures how alignment reshapes representations across depth by tracing localized structural change layer by layer. Across model families, DPO produces a layerwise calibration effect concentrated in the final decoder blocks (often layers 21-30), where preference gradients most directly affect the next-token distribution. SPINAL encodes each checkpoint as a depth trace over (layer index, contraction score, transport score). The contraction score summarizes how quickly the tail of a layer's spectrum decays (how fast small modes vanish); higher values indicate stronger contraction into fewer effective directions. The transport score summarizes how much the token distribution shifts between adjacent layers using a bounded overlap measure; lower values indicate shorter, smoother steps through representation space. Aligned checkpoints show a late-layer ramp-up in contraction and a smooth reduction in transport, consistent with tightened and stabilized policy mass, while unaligned models trace higher-curvature, more entropic, and geometrically incoherent depth paths. Overall, alignment is geometrically localized: the final layers encode the dominant preference-induced corrections. SPINAL turns this localization into a practical audit signal, quantifying where alignment concentrates, how strongly it manifests, and when it begins to destabilize during training.
[13.01.2026 20:30] Response: ```json
{
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SPINAL ‚Äî –º–µ—Ç–æ–¥ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç, –∫–∞–∫ Direct Preference Optimization (DPO) –ø–µ—Ä–µ—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å–ª–æ–π –∑–∞ —Å–ª–æ–µ–º. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–µ–Ω–æ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏ –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –±–ª–æ–∫–∞—Ö –¥–µ–∫–æ–¥–µ—Ä–∞, –≥–¥–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞. SPINAL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤–µ –º–µ—Ç—Ä–∏–∫–∏ ‚Äî –∫–æ–Ω—Ç—Ä–∞–∫—Ü–∏—é —Å–ø–µ–∫—Ç—Ä–∞ (–∫–∞–∫ –±—ã—Å—Ç—Ä–æ –∏—Å—á–µ–∑–∞—é—Ç –º–∞–ª—ã–µ –º–æ–¥—ã) –∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –º–µ–∂–¥—É —Å–ª–æ—è–º–∏) ‚Äî –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ –≤—Å–µ–π –≥–ª—É–±–∏–Ω–µ –º–æ–¥–µ–ª–∏. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∞—É–¥–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è.",
  "emoji": "üî¨",
  "title": "–í–∏–¥–∏–º–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –≤ –≥–ª—É–±–∏–Ω–µ –º–æ–¥–µ–ª–∏"
}
```
[13.01.2026 20:30] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SPINAL diagnoses how DPO alignment reshapes representations layer by layer, revealing geometric localization of preference gradients in final decoder blocks and enabling practical auditing of alignment progress.  					AI-generated summary 				 Direct Preference Optimization (DPO) is a principled, scalable alternative to RLHF for aligning large language models from pairwise preferences, but its internal geometric footprint remains undercharacterized, limiting audits, checkpoint comparisons, and failure prediction. We introduce SPINAL (Scaling-law and Preference Integration in Neural Alignment Layers), a diagnostic that measures how alignment reshapes representations across depth by tracing localized structural change layer by layer. Across model families, DPO produces a layerwise calibration effect concentrated in the final decoder blocks (often layers 21-30), where preference gradients most directly affect the next-token distribution. SPINAL encodes each checkpoint as a depth trace over (layer index, contraction score, transport score). The contraction score summarizes how quickly the tail of a layer's spectrum decays (how fast small modes vanish); higher values indicate stronger contraction into fewer effective directions. The transport score summarizes how much the token distribution shifts between adjacent layers using a bounded overlap measure; lower values indicate shorter, smoother steps through representation space. Aligned checkpoints show a late-layer ramp-up in contraction and a smooth reduction in transport, consistent with tightened and stabilized policy mass, while unaligned models trace higher-curvature, more entropic, and geometrically incoherent depth paths. Overall, alignment is geometrically localized: the final layers encode the dominant preference-induced corrections. SPINAL turns this localization into a practical audit signal, quantifying where alignment concentrates, how strongly it manifests, and when it begins to destabilize during training."

[13.01.2026 20:30] Response: ```python
['RLHF', 'TRAINING', 'ARCHITECTURE']
```
[13.01.2026 20:30] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SPINAL diagnoses how DPO alignment reshapes representations layer by layer, revealing geometric localization of preference gradients in final decoder blocks and enabling practical auditing of alignment progress.  					AI-generated summary 				 Direct Preference Optimization (DPO) is a principled, scalable alternative to RLHF for aligning large language models from pairwise preferences, but its internal geometric footprint remains undercharacterized, limiting audits, checkpoint comparisons, and failure prediction. We introduce SPINAL (Scaling-law and Preference Integration in Neural Alignment Layers), a diagnostic that measures how alignment reshapes representations across depth by tracing localized structural change layer by layer. Across model families, DPO produces a layerwise calibration effect concentrated in the final decoder blocks (often layers 21-30), where preference gradients most directly affect the next-token distribution. SPINAL encodes each checkpoint as a depth trace over (layer index, contraction score, transport score). The contraction score summarizes how quickly the tail of a layer's spectrum decays (how fast small modes vanish); higher values indicate stronger contraction into fewer effective directions. The transport score summarizes how much the token distribution shifts between adjacent layers using a bounded overlap measure; lower values indicate shorter, smoother steps through representation space. Aligned checkpoints show a late-layer ramp-up in contraction and a smooth reduction in transport, consistent with tightened and stabilized policy mass, while unaligned models trace higher-curvature, more entropic, and geometrically incoherent depth paths. Overall, alignment is geometrically localized: the final layers encode the dominant preference-induced corrections. SPINAL turns this localization into a practical audit signal, quantifying where alignment concentrates, how strongly it manifests, and when it begins to destabilize during training."

[13.01.2026 20:30] Response: ```python
["ALIGNMENT", "INTERPRETABILITY"]
```
[13.01.2026 20:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces SPINAL, a diagnostic tool that analyzes how Direct Preference Optimization (DPO) aligns large language models by reshaping their internal representations layer by layer. It focuses on the final decoder blocks, where preference gradients significantly influence the model\'s output. SPINAL measures two key metrics: contraction score, which indicates how effectively a layer compresses its representation, and transport score, which assesses the smoothness of transitions between layers. This allows for practical auditing of alignment progress, revealing that alignment effects are concentrated in the later layers of the model, providing insights into the stability and effectiveness of the alignment process during training.","title":"SPINAL: Unraveling Layerwise Alignment in Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces SPINAL, a diagnostic tool that analyzes how Direct Preference Optimization (DPO) aligns large language models by reshaping their internal representations layer by layer. It focuses on the final decoder blocks, where preference gradients significantly influence the model's output. SPINAL measures two key metrics: contraction score, which indicates how effectively a layer compresses its representation, and transport score, which assesses the smoothness of transitions between layers. This allows for practical auditing of alignment progress, revealing that alignment effects are concentrated in the later layers of the model, providing insights into the stability and effectiveness of the alignment process during training.", title='SPINAL: Unraveling Layerwise Alignment in Language Models'))
[13.01.2026 20:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SPINAL ÊòØ‰∏ÄÁßçËØäÊñ≠Â∑•ÂÖ∑ÔºåÁî®‰∫éÂàÜÊûê DPOÔºàÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºâÂ¶Ç‰ΩïÈÄêÂ±ÇÈáçÂ°ëË°®Á§∫ÔºåÊè≠Á§∫ÊúÄÁªàËß£Á†ÅÂô®Âùó‰∏≠ÂÅèÂ•ΩÊ¢ØÂ∫¶ÁöÑÂá†‰ΩïÂÆö‰Ωç„ÄÇÈÄöËøáËøΩË∏™ÊØè‰∏ÄÂ±ÇÁöÑÂ±ÄÈÉ®ÁªìÊûÑÂèòÂåñÔºåSPINAL ËÉΩÂ§üÈáèÂåñÂØπÈΩêËøáÁ®ãÁöÑËøõÂ±ï„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåDPO Âú®Ê®°ÂûãÁöÑÊúÄÂêéËß£Á†ÅÂô®Â±ÇÔºàÈÄöÂ∏∏ÊòØÁ¨¨21Âà∞30Â±ÇÔºâ‰∫ßÁîü‰∫ÜÊòæËëóÁöÑÂ±ÇÁ∫ßÊ†°ÂáÜÊïàÂ∫îÔºåÂÅèÂ•ΩÊ¢ØÂ∫¶Áõ¥Êé•ÂΩ±Âìç‰∏ã‰∏Ä‰∏™Ê†áËÆ∞ÁöÑÂàÜÂ∏É„ÄÇSPINAL ËøòÊèê‰æõ‰∫ÜÂØπÈΩêÊ£ÄÊü•ÁÇπÁöÑÂÆ°ËÆ°‰ø°Âè∑ÔºåÂ∏ÆÂä©ÁêÜËß£ÂØπÈΩêÈõÜ‰∏≠Âú®Âì™Èáå„ÄÅÂº∫Â∫¶Â¶Ç‰Ωï‰ª•ÂèäÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠‰ΩïÊó∂ÂºÄÂßã‰∏çÁ®≥ÂÆö„ÄÇ","title":"SPINALÔºöÊè≠Á§∫ÂØπÈΩêËøáÁ®ãÁöÑÂá†‰ΩïÁâπÂæÅ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SPINAL ÊòØ‰∏ÄÁßçËØäÊñ≠Â∑•ÂÖ∑ÔºåÁî®‰∫éÂàÜÊûê DPOÔºàÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºâÂ¶Ç‰ΩïÈÄêÂ±ÇÈáçÂ°ëË°®Á§∫ÔºåÊè≠Á§∫ÊúÄÁªàËß£Á†ÅÂô®Âùó‰∏≠ÂÅèÂ•ΩÊ¢ØÂ∫¶ÁöÑÂá†‰ΩïÂÆö‰Ωç„ÄÇÈÄöËøáËøΩË∏™ÊØè‰∏ÄÂ±ÇÁöÑÂ±ÄÈÉ®ÁªìÊûÑÂèòÂåñÔºåSPINAL ËÉΩÂ§üÈáèÂåñÂØπÈΩêËøáÁ®ãÁöÑËøõÂ±ï„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåDPO Âú®Ê®°ÂûãÁöÑÊúÄÂêéËß£Á†ÅÂô®Â±ÇÔºàÈÄöÂ∏∏ÊòØÁ¨¨21Âà∞30Â±ÇÔºâ‰∫ßÁîü‰∫ÜÊòæËëóÁöÑÂ±ÇÁ∫ßÊ†°ÂáÜÊïàÂ∫îÔºåÂÅèÂ•ΩÊ¢ØÂ∫¶Áõ¥Êé•ÂΩ±Âìç‰∏ã‰∏Ä‰∏™Ê†áËÆ∞ÁöÑÂàÜÂ∏É„ÄÇSPINAL ËøòÊèê‰æõ‰∫ÜÂØπÈΩêÊ£ÄÊü•ÁÇπÁöÑÂÆ°ËÆ°‰ø°Âè∑ÔºåÂ∏ÆÂä©ÁêÜËß£ÂØπÈΩêÈõÜ‰∏≠Âú®Âì™Èáå„ÄÅÂº∫Â∫¶Â¶Ç‰Ωï‰ª•ÂèäÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠‰ΩïÊó∂ÂºÄÂßã‰∏çÁ®≥ÂÆö„ÄÇ', title='SPINALÔºöÊè≠Á§∫ÂØπÈΩêËøáÁ®ãÁöÑÂá†‰ΩïÁâπÂæÅ'))
[13.01.2026 20:30] Renaming data file.
[13.01.2026 20:30] Renaming previous data. hf_papers.json to ./d/2026-01-13.json
[13.01.2026 20:30] Saving new data file.
[13.01.2026 20:30] Generating page.
[13.01.2026 20:30] Renaming previous page.
[13.01.2026 20:30] Renaming previous data. index.html to ./d/2026-01-13.html
[13.01.2026 20:30] Writing result.
[13.01.2026 20:30] Renaming log file.
[13.01.2026 20:30] Renaming previous data. log.txt to ./logs/2026-01-13_last_log.txt
