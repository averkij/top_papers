[10.07.2025 19:10] Read previous papers.
[10.07.2025 19:10] Generating top page (month).
[10.07.2025 19:10] Writing top page (month).
[10.07.2025 20:13] Read previous papers.
[10.07.2025 20:13] Get feed.
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.07105
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.07095
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06448
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06920
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06457
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.07017
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.05687
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06804
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.24044
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06853
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.05455
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06485
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06260
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.10251
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.07106
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.06415
[10.07.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2507.01702
[10.07.2025 20:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[10.07.2025 20:13] No deleted papers detected.
[10.07.2025 20:13] Downloading and parsing papers (pdf, html). Total: 17.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.07105.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.07105.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.07105.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.07095.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.07095.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.07095.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06448.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06448.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06448.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06920.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06920.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06920.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06457.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06457.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06457.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.07017.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.07017.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.07017.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.05687.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.05687.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.05687.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06804.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06804.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06804.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2506.24044.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2506.24044.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2506.24044.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06853.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06853.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06853.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.05455.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.05455.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.05455.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06485.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06485.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06485.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06260.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06260.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06260.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2505.10251.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2505.10251.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2505.10251.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.07106.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.07106.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.07106.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.06415.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.06415.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.06415.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2507.01702.
[10.07.2025 20:13] Extra JSON file exists (./assets/json/2507.01702.json), skip PDF parsing.
[10.07.2025 20:13] Paper image links file exists (./assets/img_data/2507.01702.json), skip HTML parsing.
[10.07.2025 20:13] Success.
[10.07.2025 20:13] Enriching papers with extra data.
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 0. 4KAgent, a unified agentic super-resolution system, enhances low-resolution images to 4K using profiling, perception, and restoration agents, achieving state-of-the-art performance across various imaging domains.  					AI-generated summary 				 We present 4KAgent, a unified agentic super-resolution ...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 1. A new dataset and evaluation framework improve zero-shot text-to-motion generation through a large-scale, high-quality dataset and a scalable model architecture.  					AI-generated summary 				 Generating diverse and natural human motion sequences based on textual descriptions constitutes a fundamen...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 2. Perception-Aware Policy Optimization (PAPO) enhances reinforcement learning with verifiable rewards for multimodal reasoning by integrating implicit perception loss, improving visual perception and reasoning.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has p...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 3. A human-LLM collaborative method enhances code generation test case generation, improving reliability and detection rates in code evaluation benchmarks.  					AI-generated summary 				 Large language models (LLMs) have recently achieved notable success in code-generation benchmarks such as HumanEval...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 4. Research evaluates various linear attention models and their integration with full attention in Transformers, identifying key mechanisms like selective gating and hierarchical recurrence for enhanced recall performance.  					AI-generated summary 				 Transformers face quadratic complexity and memor...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 5. FR3E enhances LLM reasoning by providing structured exploration through targeted rollouts at high-uncertainty points, leading to more stable training and accurate responses.  					AI-generated summary 				 Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning abilities of Larg...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 6. Kernel development in deep learning requires optimizing computational units across hardware while balancing memory management, parallelism, and hardware-specific optimizations through extensive empirical tuning. Although domain-specific languages like Triton simplify GPU programming by abstracting l...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 7. A novel framework decouples reasoning and proving in ATP to improve formal proving performance, achieving success on challenging IMO problems.  					AI-generated summary 				 Automated Theorem Proving (ATP) in formal languages is a foundational challenge for AI. While Large Language Models (LLMs) ha...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 8. This survey provides a comprehensive overview of Vision-Language-Action (VLA) paradigms and their adaptation for autonomous driving, detailing architectural components, evolution of models, datasets, and future challenges.  					AI-generated summary 				 The rapid progress of multimodal large langua...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 9. DiffSpectra uses diffusion models with SE(3)-equivariant architecture and SpecFormer spectral encoder to accurately infer both 2D and 3D molecular structures from multi-modal spectral data.  					AI-generated summary 				 Molecular structure elucidation from spectra is a foundational problem in chem...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 10. A new dataset and models for toxic language detection incorporate diverse community perspectives and conversational context, improving accuracy over existing tools.  					AI-generated summary 				 Automatic toxic language detection is critical for creating safe, inclusive online spaces. However, it ...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 11. Video-RTS enhances video reasoning efficiency and accuracy through pure RL training and adaptive test-time scaling, reducing data and computational costs.  					AI-generated summary 				 Despite advances in reinforcement learning (RL)-based video reasoning with large language models (LLMs), data col...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 12. Nova Premier is Amazon's most capable multimodal foundation model and teacher for model distillation. It processes text, images, and video with a one-million-token context window, enabling analysis of large codebases, 400-page documents, and 90-minute videos in a single prompt. We present the first ...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 13. A hierarchical framework combining high-level task planning and low-level trajectory generation enables autonomous surgical procedures with high success rates in ex vivo experiments.  					AI-generated summary 				 Research on autonomous surgery has largely focused on simple task automation in contr...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 14. Text-to-image diffusion models enhance image-based question-answering by providing semantically rich and instruction-aware visual encodings, complementing CLIP and improving spatial and compositional reasoning.  					AI-generated summary 				 Recent advances in multimodal large language models (MLLM...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 15. PERK, a scalable approach using parameter-efficient adapters, enhances long-context reasoning by encoding contexts into a lightweight model at test time, achieving significant performance improvements over prompt-based methods.  					AI-generated summary 				 Long-context reasoning requires accurate...
[10.07.2025 20:13] ********************************************************************************
[10.07.2025 20:13] Abstract 16. AdamMeme, an adaptive agent-based framework, evaluates multimodal Large Language Models' understanding of harmful memes through iterative updates and multi-agent collaboration, revealing model-specific weaknesses.  					AI-generated summary 				 The proliferation of multimodal memes in the social me...
[10.07.2025 20:13] Read previous papers.
[10.07.2025 20:13] Generating reviews via LLM API.
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#low_resource", "#cv", "#open_source", "#benchmark", "#agents", "#healthcare"], "emoji": "üî¨", "ru": {"title": "4KAgent: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —É–ª—É—á—à–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "4KAgent - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–≤–µ—Ä—Ö–≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∏–∑
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#transfer_learning", "#cv", "#benchmark", "#dataset", "#robotics", "#games"], "emoji": "ü§ñ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–≤–∏–∂–µ–Ω–∏–π: –æ—Ç —Ç–µ–∫—Å—Ç–∞ –∫ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö MotionMillion –∏ —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏ MotionMillion-Eval –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#multimodal", "#training", "#reasoning", "#rl", "#rlhf", "#optimization"], "emoji": "üëÅÔ∏è", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Perception-Aware Policy Optimization (PAPO) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#optimization", "#rl", "#benchmark", "#dataset", "#training", "#games"], "emoji": "üß™", "ru": {"title": "–ß–µ–ª–æ–≤–µ–∫ –∏ –ò–ò –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–¥–µ–∂–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ –∫–æ–¥–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ SAGA –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª—É—á–∞–µ–≤, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –∏ –≤–æ–∑–º–æ–∂
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#dataset", "#training", "#open_source", "#benchmark", "#architecture", "#optimization"], "emoji": "üß†", "ru": {"title": "–ì–∏–±—Ä–∏–¥–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤–Ω–∏–º–∞–Ω–∏—è: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ª–∏–Ω–µ–π–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –∏ –∏—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#reasoning", "#training"], "emoji": "üß†", "ru": {"title": "FR3E: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò", "desc": "FR3E - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization", "#rl"], "emoji": "üöÄ", "ru": {"title": "AutoTriton: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —è–¥–µ—Ä –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é RL", "desc": "AutoTriton - —ç—Ç–æ –ø–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL), –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ Triton. –û–Ω–∞ –∏
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#dataset", "#training", "#math"], "emoji": "üß†", "ru": {"title": "–†–∞–∑–¥–µ–ª—è–π –∏ –≤–ª–∞—Å—Ç–≤—É–π: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤—É —Ç–µ–æ—Ä–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤—É —Ç–µ–æ—Ä–µ–º, —Ä–∞–∑–¥–µ–ª—è—é—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å—ã —Ä–∞—Å—Å—É–∂–¥–µ
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#architecture", "#benchmark", "#survey", "#dataset", "#multimodal", "#alignment", "#interpretability"], "emoji": "üöó", "ru": {"title": "VLA: –ù–æ–≤—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã—Ö –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π", "desc": "–≠—Ç–æ –æ–±–∑–æ—Ä –ø–∞—Ä–∞–¥–∏–≥–º 
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#architecture", "#science", "#multimodal", "#data", "#diffusion", "#3d"], "emoji": "üß™", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–ª–µ–∫—É–ª —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "DiffSpectra - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è 2D –∏ 3D —Å—Ç—Ä—É–∫—Ç—É—Ä –º–æ–ª–µ–∫—É–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —Å–ø–µ–∫—Ç—Ä–∞
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#data", "#open_source", "#ethics", "#dataset", "#training"], "emoji": "üó®Ô∏è", "ru": {"title": "–ò–Ω–∫–ª—é–∑–∏–≤–Ω–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞: —É—á–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç MODELCITIZENS –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ —è–∑—ã–∫–∞, —É—á–∏—Ç—ã–≤–∞—é—â–∏–π —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#video", "#rl", "#reasoning", "#benchmark"], "emoji": "üé¨", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –æ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é RL –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "Video-RTS - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–∞—Ç—å –æ –≤–∏–¥–µ–æ —Å drastically –ø–æ–≤—ã—à
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#healthcare", "#benchmark", "#multimodal", "#alignment", "#security"], "emoji": "üî¨", "ru": {"title": "Nova Premier: –º–æ—â–Ω–∞—è –∏ –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –ò–ò –æ—Ç Amazon", "desc": "Amazon –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ Nova Premier - –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å, —Å–ø–æ—Å–æ–±–Ω—É—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–µ–∫
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#robotics", "#agents", "#optimization", "#science", "#agi"], "emoji": "ü§ñ", "ru": {"title": "–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è —Ö–∏—Ä—É—Ä–≥–∏—è: –æ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∫ —Ç–æ—á–Ω—ã–º –¥–≤–∏–∂–µ–Ω–∏—è–º", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö —Ö–∏—Ä—É—Ä–≥–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Ä–æ–±–æ—Ç–æ–º. –°–∏—Å—Ç–µ–º–∞ —Å–æ—á–µ—Ç–∞–µ—Ç –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –ø–ª–∞
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#cv", "#benchmark", "#leakage", "#reasoning"], "emoji": "üñºÔ∏è", "ru": {"title": "–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–∞–∫ –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –ò–ò", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –º–æ–¥–µ–ª–∏ –¥–∏—Ñ—Ñ—É–∑–∏–∏ —Ç–µ–∫—Å—Ç–∞ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–æ–≥—É—Ç —É–ª—É—á—à–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#long_context", "#training", "#small_models", "#reasoning", "#architecture", "#optimization"], "emoji": "üß†", "ru": {"title": "PERK: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –Ω–∞ –¥–ª–∏–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ", "desc": "PERK - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã–π –ø–æ–¥—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏-—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–¥–∞–ø—Ç–µ—Ä—ã –¥–ª
[10.07.2025 20:13] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#benchmark", "#reasoning", "#interpretability", "#alignment"], "emoji": "üïµÔ∏è", "ru": {"title": "AdamMeme: –£–º–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–∏–≤ –≤ –º–∏—Ä–µ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã—Ö –º–µ–º–æ–≤", "desc": "AdamMeme - —ç—Ç–æ –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã—Ö –º–µ–º
[10.07.2025 20:13] Renaming data file.
[10.07.2025 20:13] Renaming previous data. hf_papers.json to ./d/2025-07-10.json
[10.07.2025 20:13] Saving new data file.
[10.07.2025 20:13] Generating page.
[10.07.2025 20:13] Renaming previous page.
[10.07.2025 20:13] Renaming previous data. index.html to ./d/2025-07-10.html
[10.07.2025 20:13] Writing result.
[10.07.2025 20:13] Renaming log file.
[10.07.2025 20:13] Renaming previous data. log.txt to ./logs/2025-07-10_last_log.txt
