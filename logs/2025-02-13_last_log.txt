[13.02.2025 05:13] Read previous papers.
[13.02.2025 05:13] Generating top page (month).
[13.02.2025 05:13] Writing top page (month).
[13.02.2025 06:14] Read previous papers.
[13.02.2025 06:14] Get feed.
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.08590
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.08639
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.07870
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.08127
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.08168
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.07864
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.07737
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.06872
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.05167
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.07563
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.08524
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.08606
[13.02.2025 06:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.07599
[13.02.2025 06:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[13.02.2025 06:14] No deleted papers detected.
[13.02.2025 06:14] Downloading and parsing papers (pdf, html). Total: 13.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.08590.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.08590.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.08590.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.08639.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.08639.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.08639.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.07870.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.07870.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.07870.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.08127.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.08127.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.08127.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.08168.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.08168.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.08168.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.07864.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.07864.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.07864.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.07737.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.07737.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.07737.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.06872.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.06872.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.06872.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.05167.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.05167.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.05167.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.07563.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.07563.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.07563.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.08524.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.08524.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.08524.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.08606.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.08606.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.08606.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Downloading and parsing paper https://huggingface.co/papers/2502.07599.
[13.02.2025 06:14] Extra JSON file exists (./assets/json/2502.07599.json), skip PDF parsing.
[13.02.2025 06:14] Paper image links file exists (./assets/img_data/2502.07599.json), skip HTML parsing.
[13.02.2025 06:14] Success.
[13.02.2025 06:14] Enriching papers with extra data.
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 0. Recent advancements in image relighting models, driven by large-scale datasets and pre-trained diffusion models, have enabled the imposition of consistent lighting. However, video relighting still lags, primarily due to the excessive training costs and the scarcity of diverse, high-quality video rel...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 1. In this work, we present CineMaster, a novel framework for 3D-aware and controllable text-to-video generation. Our goal is to empower users with comparable controllability as professional film directors: precise placement of objects within the scene, flexible manipulation of both objects and camera ...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 2. Text-conditioned image generation has gained significant attention in recent years and are processing increasingly longer and comprehensive text prompt. In everyday life, dense and intricate text appears in contexts like advertisements, infographics, and signage, where the integration of both text a...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 3. Recent advancements in large language models (LLMs) have shown strong general reasoning abilities, yet their effectiveness in financial reasoning remains underexplored. In this study, we comprehensively evaluate 16 powerful reasoning and general LLMs on three complex financial tasks involving financ...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 4. In the field of synthetic aperture radar (SAR) remote sensing image interpretation, although Vision language models (VLMs) have made remarkable progress in natural language processing and image understanding, their applications remain limited in professional domains due to insufficient domain expert...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 5. Modern large language models (LLMs) often encounter communication bottlenecks on current hardware, rather than purely computational constraints. Multi-head Latent Attention (MLA) tackles this challenge by using low-rank matrices in the key-value (KV) layers, thereby allowing compressed latent KV sta...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 6. Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR) video generation, but it suffers from suboptimal unidirectional dependencies and slow inference speed. In this work, we propose a semi-autoregressive (semi-AR) framework, called Next-Block Prediction (NBP), for video generati...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 7. Retrieval-Augmented Generation (RAG) is an advanced technique designed to address the challenges of Artificial Intelligence-Generated Content (AIGC). By integrating context retrieval into content generation, RAG provides reliable and up-to-date external knowledge, reduces hallucinations, and ensures...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 8. Recent large language models (LLMs) support long contexts ranging from 128K to 1M tokens. A popular method for evaluating these capabilities is the needle-in-a-haystack (NIAH) test, which involves retrieving a "needle" (relevant information) from a "haystack" (long irrelevant context). Extensions of...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 9. Linear sequence modeling approaches, such as linear attention, provide advantages like linear-time training and constant-memory inference over sequence lengths. However, existing sequence parallelism (SP) methods are either not optimized for the right-product-first feature of linear attention or use...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 10. Next token prediction has been the standard training objective used in large language model pretraining. Representations are learned as a result of optimizing for token-level perplexity. We propose Continuous Concept Mixing (CoCoMix), a novel pretraining framework that combines discrete next token p...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 11. We provide a distillation scaling law that estimates distilled model performance based on a compute budget and its allocation between the student and teacher. Our findings reduce the risks associated with using distillation at scale; compute allocation for both the teacher and student models can now...
[13.02.2025 06:14] ********************************************************************************
[13.02.2025 06:14] Abstract 12. Direct Preference Optimization (DPO) and its variants have become increasingly popular for aligning language models with human preferences. These methods aim to teach models to better distinguish between chosen (or preferred) and rejected (or dispreferred) responses. However, prior research has iden...
[13.02.2025 06:14] Read previous papers.
[13.02.2025 06:14] Generating reviews via LLM API.
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#video", "#diffusion", "#cv"], "emoji": "💡", "ru": {"title": "Плавное переосвещение видео без обучения", "desc": "Эта статья представляет Light-A-Video - подход к переосвещению видео без дополнительного обучения. Авторы предлагают два ключевых метода для улучшения согласованности ос
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#dataset", "#video", "#diffusion", "#3d", "#games"], "emoji": "🎬", "ru": {"title": "CineMaster: Режиссируйте свое видео в 3D", "desc": "CineMaster - это новая система для создания 3D-ориентированного и контролируемого видео на основе текста. Она позволяет пользователям точно размеща
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#long_context", "#benchmark", "#cv"], "emoji": "📚", "ru": {"title": "TextAtlas5M: Новый горизонт в генерации изображений с длинным текстом", "desc": "Статья представляет новый датасет TextAtlas5M для оценки генерации изображений с длинным текстом. Датасет
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#benchmark", "#rl", "#open_source", "#training", "#long_context"], "emoji": "💹", "ru": {"title": "Специализация языковых моделей - ключ к успеху в финансовом анализе", "desc": "В этом исследовании оценивается эффективность 16 мощных языковых моделей в решен
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#dataset", "#open_source", "#synthetic"], "emoji": "🛰️", "ru": {"title": "SARChat-2M: Революция в интерпретации изображений SAR с помощью мультимодальных диалоговых моделей", "desc": "Статья представляет первый крупномасштабный мультимодальный диалоговый
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#inference", "#training", "#long_context"], "emoji": "🚀", "ru": {"title": "Революция в архитектуре внимания: MLA для эффективных языковых моделей", "desc": "Статья представляет новый метод под названием Multi-head Latent Attention (MLA), который реш
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#video", "#inference", "#training"], "emoji": "🎬", "ru": {"title": "NBP: Быстрая и качественная генерация видео блоками", "desc": "Статья представляет новый подход к генерации видео под названием Next-Block Prediction (NBP). В отличие от традиционно
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#hallucinations", "#interpretability", "#security", "#survey", "#rag", "#ethics"], "emoji": "🧠", "ru": {"title": "Путь к надёжному ИИ: Преодоление рисков в генерации с дополнением извлечённой информацией", "desc": "Статья посвящена методу генерации с дополнением извлечённой информац
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#benchmark", "#long_context"], "emoji": "🔍", "ru": {"title": "NoLiMa: Новый вызов для больших языковых моделей в работе с длинным контекстом", "desc": "Статья представляет новый бенчмарк NoLiMa для оценки способности больших языковых моделей (LLM) работать с длинным контекстом. В от
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#training", "#architecture", "#optimization"], "emoji": "🚀", "ru": {"title": "Ускорение обучения трансформеров с линейным вниманием на сверхдлинных последовательностях", "desc": "Статья представляет новый метод параллелизма последовательностей LASP-2 для обучения моделей трансформер
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#interpretability", "#training", "#architecture", "#benchmark"], "emoji": "🧠", "ru": {"title": "CoCoMix: смешивание концепций для улучшения языковых моделей", "desc": "В этой статье представлен новый метод предобучения языковых моделей под названием Co
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#training", "#optimization"], "emoji": "🔬", "ru": {"title": "Масштабируемая дистилляция: оптимизация обучения моделей", "desc": "Эта статья представляет закон масштабирования дистилляции, который оценивает производительность дистиллированной модели на основе вычислительного бюджета 
[13.02.2025 06:14] Using data from previous issue: {"categories": ["#alignment", "#training", "#rlhf"], "emoji": "🔀", "ru": {"title": "Контролируемое смещение вероятностей для улучшения обучения языковых моделей", "desc": "Статья представляет новый метод под названием DPO-Shift для улучшения обучения языковых моделей с учетом человеческих предпочтен
[13.02.2025 06:14] Loading Chinese text from previous data.
[13.02.2025 06:14] Renaming data file.
[13.02.2025 06:14] Renaming previous data. hf_papers.json to ./d/2025-02-13.json
[13.02.2025 06:14] Saving new data file.
[13.02.2025 06:14] Generating page.
[13.02.2025 06:14] Renaming previous page.
[13.02.2025 06:14] Renaming previous data. index.html to ./d/2025-02-13.html
[13.02.2025 06:14] [Experimental] Generating Chinese page for reading.
[13.02.2025 06:14] Chinese vocab [{'word': '展示', 'pinyin': 'zhǎnshì', 'trans': 'display'}, {'word': '强化学习', 'pinyin': 'qiáng\u200bhuà\u200bxué\u200bxí', 'trans': 'reinforcement learning'}, {'word': '应用于', 'pinyin': 'yìng\u200byòng\u200byú', 'trans': 'apply to'}, {'word': '大型语言模型', 'pinyin': 'dà\u200bxíng\u200byǔ\u200byán\u200bmó\u200bxíng', 'trans': 'large language model'}, {'word': '显著', 'pinyin': 'xiǎn\u200bzhù', 'trans': 'significant'}, {'word': '提升', 'pinyin': 'tí\u200bshēng', 'trans': 'improve'}, {'word': '复杂', 'pinyin': 'fù\u200bzá', 'trans': 'complex'}, {'word': '编程', 'pinyin': 'biān\u200bchéng', 'trans': 'programming'}, {'word': '推理', 'pinyin': 'tuī\u200blǐ', 'trans': 'reasoning'}, {'word': '表现', 'pinyin': 'biǎo\u200bxiàn', 'trans': 'performance'}, {'word': '比较', 'pinyin': 'bǐ\u200bjiào', 'trans': 'compare'}, {'word': '通用', 'pinyin': 'tōng\u200byòng', 'trans': 'general-purpose'}, {'word': '针对', 'pinyin': 'zhēn\u200bduì', 'trans': 'target'}, {'word': '特定领域', 'pinyin': 'tè\u200bdìng\u200blǐng\u200byù', 'trans': 'specific domain'}, {'word': '系统', 'pinyin': 'xì\u200btǒng', 'trans': 'system'}, {'word': '国际信息学奥林匹克', 'pinyin': 'guó\u200bjì\u200bxìn\u200bxī\u200bxué\u200bào\u200blín\u200bpǐ\u200bkè', 'trans': 'International Olympiad in Informatics'}, {'word': '设计', 'pinyin': 'shè\u200bjì', 'trans': 'design'}, {'word': '参赛', 'pinyin': 'cān\u200bsài', 'trans': 'compete'}, {'word': '放宽', 'pinyin': 'fàng\u200bkuān', 'trans': 'relax'}, {'word': '约束', 'pinyin': 'yuē\u200bshù', 'trans': 'constraint'}, {'word': '获得', 'pinyin': 'huò\u200bdé', 'trans': 'obtain'}, {'word': '金牌', 'pinyin': 'jīn\u200bpái', 'trans': 'gold medal'}, {'word': '后续', 'pinyin': 'hòu\u200bxù', 'trans': 'subsequent'}, {'word': '手工制定', 'pinyin': 'shǒu\u200bgōng\u200bzhì\u200bdìng', 'trans': 'manually specified'}, {'word': '策略', 'pinyin': 'cè\u200blüè', 'trans': 'strategy'}, {'word': '启发式', 'pinyin': 'qǐ\u200bfā\u200bshì', 'trans': 'heuristic'}, {'word': '依赖', 'pinyin': 'yī\u200blài', 'trans': 'rely on'}, {'word': '扩展', 'pinyin': 'kuò\u200bzhǎn', 'trans': 'extend'}, {'word': '超越', 'pinyin': 'chāo\u200byuè', 'trans': 'surpass'}, {'word': '结果', 'pinyin': 'jié\u200bguǒ', 'trans': 'result'}]
[13.02.2025 06:14] Renaming previous Chinese page.
[13.02.2025 06:14] Renaming previous data. zh.html to ./d/2025-02-12_zh_reading_task.html
[13.02.2025 06:14] Writing Chinese reading task.
[13.02.2025 06:14] Writing result.
[13.02.2025 06:14] Renaming log file.
[13.02.2025 06:14] Renaming previous data. log.txt to ./logs/2025-02-13_last_log.txt
