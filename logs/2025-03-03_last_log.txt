[03.03.2025 04:14] Read previous papers.
[03.03.2025 04:14] Generating top page (month).
[03.03.2025 04:14] Writing top page (month).
[03.03.2025 05:11] Read previous papers.
[03.03.2025 05:11] Get feed.
[03.03.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20730
[03.03.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18017
[03.03.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20811
[03.03.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20545
[03.03.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20583
[03.03.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20396
[03.03.2025 05:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.03.2025 05:11] No deleted papers detected.
[03.03.2025 05:11] Downloading and parsing papers (pdf, html). Total: 6.
[03.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.20730.
[03.03.2025 05:11] Extra JSON file exists (./assets/json/2502.20730.json), skip PDF parsing.
[03.03.2025 05:11] Paper image links file exists (./assets/img_data/2502.20730.json), skip HTML parsing.
[03.03.2025 05:11] Success.
[03.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.18017.
[03.03.2025 05:11] Extra JSON file exists (./assets/json/2502.18017.json), skip PDF parsing.
[03.03.2025 05:11] Paper image links file exists (./assets/img_data/2502.18017.json), skip HTML parsing.
[03.03.2025 05:11] Success.
[03.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.20811.
[03.03.2025 05:11] Extra JSON file exists (./assets/json/2502.20811.json), skip PDF parsing.
[03.03.2025 05:11] Paper image links file exists (./assets/img_data/2502.20811.json), skip HTML parsing.
[03.03.2025 05:11] Success.
[03.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.20545.
[03.03.2025 05:11] Extra JSON file exists (./assets/json/2502.20545.json), skip PDF parsing.
[03.03.2025 05:11] Paper image links file exists (./assets/img_data/2502.20545.json), skip HTML parsing.
[03.03.2025 05:11] Success.
[03.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.20583.
[03.03.2025 05:11] Extra JSON file exists (./assets/json/2502.20583.json), skip PDF parsing.
[03.03.2025 05:11] Paper image links file exists (./assets/img_data/2502.20583.json), skip HTML parsing.
[03.03.2025 05:11] Success.
[03.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2502.20396.
[03.03.2025 05:11] Extra JSON file exists (./assets/json/2502.20396.json), skip PDF parsing.
[03.03.2025 05:11] Paper image links file exists (./assets/img_data/2502.20396.json), skip HTML parsing.
[03.03.2025 05:11] Success.
[03.03.2025 05:11] Enriching papers with extra data.
[03.03.2025 05:11] ********************************************************************************
[03.03.2025 05:11] Abstract 0. Designing solutions for complex engineering challenges is crucial in human production activities. However, previous research in the retrieval-augmented generation (RAG) field has not sufficiently addressed tasks related to the design of complex engineering solutions. To fill this gap, we introduce a...
[03.03.2025 05:11] ********************************************************************************
[03.03.2025 05:11] Abstract 1. Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehe...
[03.03.2025 05:11] ********************************************************************************
[03.03.2025 05:11] Abstract 2. Recent Multi-modal Large Language Models (MLLMs) have made great progress in video understanding. However, their performance on videos involving human actions is still limited by the lack of high-quality data. To address this, we introduce a two-stage data annotation pipeline. First, we design strat...
[03.03.2025 05:11] ********************************************************************************
[03.03.2025 05:11] Abstract 3. Large Language Models (LLMs) have achieved human-level proficiency across diverse tasks, but their ability to perform rigorous mathematical problem solving remains an open challenge. In this work, we investigate a fundamental yet computationally intractable problem: determining whether a given multi...
[03.03.2025 05:11] ********************************************************************************
[03.03.2025 05:11] Abstract 4. Modern automatic speech recognition (ASR) models, such as OpenAI's Whisper, rely on deep encoder-decoder architectures, and their encoders are a critical bottleneck for efficient deployment due to high computational intensity. We introduce LiteASR, a low-rank compression scheme for ASR encoders that...
[03.03.2025 05:11] ********************************************************************************
[03.03.2025 05:11] Abstract 5. Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited. This work investigates the key challenges in applying reinforcement learning to solve a collec...
[03.03.2025 05:11] Read previous papers.
[03.03.2025 05:11] Generating reviews via LLM API.
[03.03.2025 05:11] Using data from previous issue: {"categories": ["#rag", "#benchmark"], "emoji": "üîß", "ru": {"title": "–£–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ SolutionBench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ
[03.03.2025 05:11] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#rag", "#games", "#benchmark", "#multimodal", "#dataset"], "emoji": "üîç", "ru": {"title": "ViDoRAG: –ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ViDoSeek –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–≤ –∏–∑–≤–ª–µ
[03.03.2025 05:11] Using data from previous issue: {"categories": ["#dataset", "#data", "#video", "#multimodal", "#benchmark", "#synthetic"], "emoji": "üé¨", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –≤ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º–∏ –¥–µ–π—Å—Ç–≤–∏—è
[03.03.2025 05:11] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#training", "#math", "#reasoning"], "emoji": "üßÆ", "ru": {"title": "–ë–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—é—Ç –≥—Ä–∞–Ω–∏—Ü—ã –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Ä–µ—à–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏,
[03.03.2025 05:11] Using data from previous issue: {"categories": ["#inference", "#optimization", "#audio"], "emoji": "üéôÔ∏è", "ru": {"title": "LiteASR: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ ASR –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "LiteASR - —ç—Ç–æ –º–µ—Ç–æ–¥ —Å–∂–∞—Ç–∏—è —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (ASR), –∫–æ—Ç–æ—Ä—ã–π –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞
[03.03.2025 05:11] Using data from previous issue: {"categories": ["#robotics", "#rl", "#games", "#optimization"], "emoji": "ü§ñ", "ru": {"title": "–õ–æ–≤–∫–æ—Å—Ç—å —Ä–æ–±–æ—Ç–∞: –æ—Ç —Å–∏–º—É–ª—è—Ü–∏–∏ –∫ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ —Å –ø–æ–º–æ—â—å—é —á–µ–ª–æ–≤–µ–∫–æ–ø–æ–¥–æ–±–Ω–æ–≥–æ —Ä–æ–±–æ—Ç–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–æ
[03.03.2025 05:11] Loading Chinese text from previous data.
[03.03.2025 05:11] Renaming data file.
[03.03.2025 05:11] Renaming previous data. hf_papers.json to ./d/2025-03-03.json
[03.03.2025 05:11] Saving new data file.
[03.03.2025 05:11] Generating page.
[03.03.2025 05:11] Renaming previous page.
[03.03.2025 05:11] Renaming previous data. index.html to ./d/2025-03-03.html
[03.03.2025 05:11] [Experimental] Generating Chinese page for reading.
[03.03.2025 05:11] Chinese vocab [{'word': 'Ëá™ÊàëÂ•ñÂä±Êé®ÁêÜ', 'pinyin': 'z√¨ w«í ji«éng l√¨ tuƒ´ l«ê', 'trans': 'self-rewarding reasoning'}, {'word': 'Â§ßËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'd√† y«î y√°n m√≥ x√≠ng', 'trans': 'large language model'}, {'word': 'ÈÄêÊ≠•Êé®ÁêÜ', 'pinyin': 'zh√∫ b√π tuƒ´ l«ê', 'trans': 'step-by-step reasoning'}, {'word': 'Ëá™ÊàëÁ∫†Ê≠£', 'pinyin': 'z√¨ w«í ji≈´ zh√®ng', 'trans': 'self-correction'}, {'word': 'Ëá™‰∏ªÊ£ÄÊµã', 'pinyin': 'z√¨ zh«î ji«én c√®', 'trans': 'autonomous detection'}, {'word': 'Ëø≠‰ª£‰øÆÊ≠£', 'pinyin': 'di√© d√†i xi≈´ zh√®ng', 'trans': 'iterative correction'}, {'word': 'ÁÆóÊ≥ïÊ°ÜÊû∂', 'pinyin': 'su√†n f«é ku√†ng ji√†', 'trans': 'algorithmic framework'}, {'word': 'Ëá™ÊàëÁîüÊàê', 'pinyin': 'z√¨ w«í shƒìng ch√©ng', 'trans': 'self-generation'}, {'word': 'ÂÜÖÂú®Ëá™ÊàëÁ∫†Ê≠£', 'pinyin': 'n√®i z√†i z√¨ w«í ji≈´ zh√®ng', 'trans': 'intrinsic self-correction'}, {'word': '‰æùËµñÂ§ñÈÉ®Â•ñÂä±', 'pinyin': 'yƒ´ l√†i w√†i b√π ji«éng l√¨', 'trans': 'reliant on external rewards'}]
[03.03.2025 05:11] Renaming previous Chinese page.
[03.03.2025 05:11] Renaming previous data. zh.html to ./d/2025-03-02_zh_reading_task.html
[03.03.2025 05:11] Writing Chinese reading task.
[03.03.2025 05:11] Writing result.
[03.03.2025 05:11] Renaming log file.
[03.03.2025 05:11] Renaming previous data. log.txt to ./logs/2025-03-03_last_log.txt
