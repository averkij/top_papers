[03.03.2025 10:12] Read previous papers.
[03.03.2025 10:12] Generating top page (month).
[03.03.2025 10:12] Writing top page (month).
[03.03.2025 11:09] Read previous papers.
[03.03.2025 11:09] Get feed.
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20730
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18600
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18017
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20545
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20396
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20811
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20583
[03.03.2025 11:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19577
[03.03.2025 11:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.03.2025 11:09] No deleted papers detected.
[03.03.2025 11:09] Downloading and parsing papers (pdf, html). Total: 8.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.20730.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.20730.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.20730.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.18600.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.18600.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.18600.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.18017.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.18017.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.18017.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.20545.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.20545.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.20545.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.20396.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.20396.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.20396.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.20811.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.20811.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.20811.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.20583.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.20583.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.20583.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Downloading and parsing paper https://huggingface.co/papers/2502.19577.
[03.03.2025 11:09] Extra JSON file exists (./assets/json/2502.19577.json), skip PDF parsing.
[03.03.2025 11:09] Paper image links file exists (./assets/img_data/2502.19577.json), skip HTML parsing.
[03.03.2025 11:09] Success.
[03.03.2025 11:09] Enriching papers with extra data.
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 0. Designing solutions for complex engineering challenges is crucial in human production activities. However, previous research in the retrieval-augmented generation (RAG) field has not sufficiently addressed tasks related to the design of complex engineering solutions. To fill this gap, we introduce a...
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 1. Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning. However, humans typically employ a more efficient strategy: drafting concise intermedia...
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 2. Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehe...
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 3. Large Language Models (LLMs) have achieved human-level proficiency across diverse tasks, but their ability to perform rigorous mathematical problem solving remains an open challenge. In this work, we investigate a fundamental yet computationally intractable problem: determining whether a given multi...
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 4. Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited. This work investigates the key challenges in applying reinforcement learning to solve a collec...
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 5. Recent Multi-modal Large Language Models (MLLMs) have made great progress in video understanding. However, their performance on videos involving human actions is still limited by the lack of high-quality data. To address this, we introduce a two-stage data annotation pipeline. First, we design strat...
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 6. Modern automatic speech recognition (ASR) models, such as OpenAI's Whisper, rely on deep encoder-decoder architectures, and their encoders are a critical bottleneck for efficient deployment due to high computational intensity. We introduce LiteASR, a low-rank compression scheme for ASR encoders that...
[03.03.2025 11:09] ********************************************************************************
[03.03.2025 11:09] Abstract 7. Visual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, self-explainable models (SEM) aim to provide interpretable classifiers that decompose predictions into a wei...
[03.03.2025 11:09] Read previous papers.
[03.03.2025 11:09] Generating reviews via LLM API.
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#rag", "#benchmark"], "emoji": "üîß", "ru": {"title": "–£–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ SolutionBench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#reasoning", "#training", "#rl"], "emoji": "‚úçÔ∏è", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ: –∫—Ä–∞—Ç–∫–æ—Å—Ç—å - —Å–µ—Å—Ç—Ä–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á —Å –ø–æ–º–æ—â—å—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π - Chain of Draft (CoD). –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –º–µ—Ç–æ–¥–∞ Chain-of-Thought 
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#rag", "#games", "#benchmark", "#multimodal", "#dataset"], "emoji": "üîç", "ru": {"title": "ViDoRAG: –ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ViDoSeek –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–≤ –∏–∑–≤–ª–µ
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#training", "#math", "#reasoning"], "emoji": "üßÆ", "ru": {"title": "–ë–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—é—Ç –≥—Ä–∞–Ω–∏—Ü—ã –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Ä–µ—à–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏,
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#robotics", "#rl", "#games", "#optimization"], "emoji": "ü§ñ", "ru": {"title": "–õ–æ–≤–∫–æ—Å—Ç—å —Ä–æ–±–æ—Ç–∞: –æ—Ç —Å–∏–º—É–ª—è—Ü–∏–∏ –∫ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ —Å –ø–æ–º–æ—â—å—é —á–µ–ª–æ–≤–µ–∫–æ–ø–æ–¥–æ–±–Ω–æ–≥–æ —Ä–æ–±–æ—Ç–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–æ
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#dataset", "#data", "#video", "#multimodal", "#benchmark", "#synthetic"], "emoji": "üé¨", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –≤ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º–∏ –¥–µ–π—Å—Ç–≤–∏—è
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#inference", "#optimization", "#audio"], "emoji": "üéôÔ∏è", "ru": {"title": "LiteASR: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ ASR –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "LiteASR - —ç—Ç–æ –º–µ—Ç–æ–¥ —Å–∂–∞—Ç–∏—è —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (ASR), –∫–æ—Ç–æ—Ä—ã–π –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞
[03.03.2025 11:09] Using data from previous issue: {"categories": ["#cv", "#small_models", "#architecture", "#interpretability", "#open_source", "#training", "#optimization"], "emoji": "üîç", "ru": {"title": "ProtoFM: –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ
[03.03.2025 11:09] Loading Chinese text from previous data.
[03.03.2025 11:09] Renaming data file.
[03.03.2025 11:09] Renaming previous data. hf_papers.json to ./d/2025-03-03.json
[03.03.2025 11:09] Saving new data file.
[03.03.2025 11:09] Generating page.
[03.03.2025 11:09] Renaming previous page.
[03.03.2025 11:09] Renaming previous data. index.html to ./d/2025-03-03.html
[03.03.2025 11:09] [Experimental] Generating Chinese page for reading.
[03.03.2025 11:09] Chinese vocab [{'word': 'ËÆæËÆ°', 'pinyin': 'sh√®j√¨', 'trans': 'design'}, {'word': 'Â§çÊùÇ', 'pinyin': 'f√πz√°', 'trans': 'complex'}, {'word': 'Â∑•Á®ã', 'pinyin': 'g≈çngch√©ng', 'trans': 'engineering'}, {'word': 'ÊåëÊàò', 'pinyin': 'ti«éozh√†n', 'trans': 'challenge'}, {'word': 'Ëß£ÂÜ≥ÊñπÊ°à', 'pinyin': 'jiƒõju√© fƒÅng√†n', 'trans': 'solution'}, {'word': 'Ëá≥ÂÖ≥ÈáçË¶Å', 'pinyin': 'zh√¨guƒÅn zh√≤ngy√†o', 'trans': 'crucial'}, {'word': 'Ê£ÄÁ¥¢', 'pinyin': 'ji«énsu«í', 'trans': 'retrieval'}, {'word': 'Â¢ûÂº∫', 'pinyin': 'zƒìngqi√°ng', 'trans': 'enhanced'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìngch√©ng', 'trans': 'generation'}, {'word': 'Á†îÁ©∂', 'pinyin': 'y√°nji≈´', 'trans': 'research'}, {'word': 'Êú™ËÉΩ', 'pinyin': 'w√®in√©ng', 'trans': 'failed to'}, {'word': 'ÂÖÖÂàÜ', 'pinyin': 'ch≈çngf√®n', 'trans': 'adequately'}, {'word': 'Áõ∏ÂÖ≥', 'pinyin': 'xiƒÅngguƒÅn', 'trans': 'related'}, {'word': '‰ªªÂä°', 'pinyin': 'r√®nw√π', 'trans': 'task'}, {'word': 'ÂºïÂÖ•', 'pinyin': 'y«ênr√π', 'trans': 'introduce'}, {'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´zh«în', 'trans': 'benchmark'}, {'word': 'ËØÑ‰º∞', 'pinyin': 'p√≠ngg≈´', 'trans': 'evaluate'}, {'word': 'Á≥ªÁªü', 'pinyin': 'x√¨t«íng', 'trans': 'system'}, {'word': 'ÂÆåÊï¥', 'pinyin': 'w√°nzhƒõng', 'trans': 'complete'}, {'word': 'ÂèØË°å', 'pinyin': 'kƒõx√≠ng', 'trans': 'feasible'}, {'word': 'Â∑•Á®ãÈóÆÈ¢ò', 'pinyin': 'g≈çngch√©ng w√®nt√≠', 'trans': 'engineering problem'}, {'word': 'Ëß£ÂÜ≥ÊñπÊ°à', 'pinyin': 'jiƒõju√© fƒÅng√†n', 'trans': 'solution'}, {'word': 'ËÉΩÂäõ', 'pinyin': 'n√©ngl√¨', 'trans': 'capability'}, {'word': 'ÊèêÂá∫', 'pinyin': 't√≠ch≈´', 'trans': 'propose'}, {'word': 'Êñ∞Á≥ªÁªü', 'pinyin': 'xƒ´n x√¨t«íng', 'trans': 'new system'}, {'word': 'Âà©Áî®', 'pinyin': 'l√¨y√≤ng', 'trans': 'utilize'}, {'word': 'Âü∫‰∫é', 'pinyin': 'jƒ´y√∫', 'trans': 'based on'}, {'word': 'Ê†ë', 'pinyin': 'sh√π', 'trans': 'tree'}, {'word': 'Êé¢Á¥¢', 'pinyin': 't√†nsu«í', 'trans': 'exploration'}, {'word': 'ÂèåÁÇπÊÄùÁª¥', 'pinyin': 'shuƒÅngdi«én sƒ´w√©i', 'trans': 'dual-point thinking'}, {'word': 'Êú∫Âà∂', 'pinyin': 'jƒ´zh√¨', 'trans': 'mechanism'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìngch√©ng', 'trans': 'generate'}, {'word': 'ÂèØÈù†', 'pinyin': 'kƒõk√†o', 'trans': 'reliable'}, {'word': 'ÂÆûÈ™å', 'pinyin': 'sh√≠y√†n', 'trans': 'experiment'}, {'word': 'ÁªìÊûú', 'pinyin': 'ji√©gu«í', 'trans': 'result'}, {'word': 'ÊòæÁ§∫', 'pinyin': 'xi«énsh√¨', 'trans': 'show'}, {'word': 'ËææÂà∞', 'pinyin': 'd√°d√†o', 'trans': 'achieve'}, {'word': 'ÊúÄÂÖàËøõ', 'pinyin': 'zu√¨ xiƒÅnj√¨n', 'trans': 'state-of-the-art'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ngn√©ng', 'trans': 'performance'}, {'word': 'Á™ÅÊòæ', 'pinyin': 't≈´xi«én', 'trans': 'highlight'}, {'word': 'ÊΩúÂäõ', 'pinyin': 'qi√°nl√¨', 'trans': 'potential'}, {'word': 'ÂÆûÈôÖ', 'pinyin': 'sh√≠j√¨', 'trans': 'practical'}, {'word': 'Â∫îÁî®', 'pinyin': 'y√¨ngy√≤ng', 'trans': 'application'}, {'word': 'Â¢ûÂº∫', 'pinyin': 'zƒìngqi√°ng', 'trans': 'enhance'}, {'word': 'Ëá™Âä®Âåñ', 'pinyin': 'z√¨d√≤nghu√†', 'trans': 'automation'}]
[03.03.2025 11:09] Renaming previous Chinese page.
[03.03.2025 11:09] Renaming previous data. zh.html to ./d/2025-03-02_zh_reading_task.html
[03.03.2025 11:09] Writing Chinese reading task.
[03.03.2025 11:09] Writing result.
[03.03.2025 11:09] Renaming log file.
[03.03.2025 11:09] Renaming previous data. log.txt to ./logs/2025-03-03_last_log.txt
