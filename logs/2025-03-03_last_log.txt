[03.03.2025 09:13] Read previous papers.
[03.03.2025 09:13] Generating top page (month).
[03.03.2025 09:13] Writing top page (month).
[03.03.2025 10:12] Read previous papers.
[03.03.2025 10:12] Get feed.
[03.03.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20730
[03.03.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18600
[03.03.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18017
[03.03.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20545
[03.03.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20396
[03.03.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20811
[03.03.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20583
[03.03.2025 10:12] Extract page data from URL. URL: https://huggingface.co/papers/2502.19577
[03.03.2025 10:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.03.2025 10:12] No deleted papers detected.
[03.03.2025 10:12] Downloading and parsing papers (pdf, html). Total: 8.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.20730.
[03.03.2025 10:12] Extra JSON file exists (./assets/json/2502.20730.json), skip PDF parsing.
[03.03.2025 10:12] Paper image links file exists (./assets/img_data/2502.20730.json), skip HTML parsing.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.18600.
[03.03.2025 10:12] Extra JSON file exists (./assets/json/2502.18600.json), skip PDF parsing.
[03.03.2025 10:12] Paper image links file exists (./assets/img_data/2502.18600.json), skip HTML parsing.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.18017.
[03.03.2025 10:12] Extra JSON file exists (./assets/json/2502.18017.json), skip PDF parsing.
[03.03.2025 10:12] Paper image links file exists (./assets/img_data/2502.18017.json), skip HTML parsing.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.20545.
[03.03.2025 10:12] Extra JSON file exists (./assets/json/2502.20545.json), skip PDF parsing.
[03.03.2025 10:12] Paper image links file exists (./assets/img_data/2502.20545.json), skip HTML parsing.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.20396.
[03.03.2025 10:12] Extra JSON file exists (./assets/json/2502.20396.json), skip PDF parsing.
[03.03.2025 10:12] Paper image links file exists (./assets/img_data/2502.20396.json), skip HTML parsing.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.20811.
[03.03.2025 10:12] Extra JSON file exists (./assets/json/2502.20811.json), skip PDF parsing.
[03.03.2025 10:12] Paper image links file exists (./assets/img_data/2502.20811.json), skip HTML parsing.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.20583.
[03.03.2025 10:12] Extra JSON file exists (./assets/json/2502.20583.json), skip PDF parsing.
[03.03.2025 10:12] Paper image links file exists (./assets/img_data/2502.20583.json), skip HTML parsing.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2502.19577.
[03.03.2025 10:12] Downloading paper 2502.19577 from http://arxiv.org/pdf/2502.19577v1...
[03.03.2025 10:12] Extracting affiliations from text.
[03.03.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Tell me why: Visual foundation models as self-explainable classifiers Hugues Turbe 1 2 Mina Bjelogrlic 1 2 Gianmarco Mengaldo 3 Christian Lovis 1 2 5 2 0 2 6 2 ] . [ 1 7 7 5 9 1 . 2 0 5 2 : r a "
[03.03.2025 10:12] Response: []
[03.03.2025 10:12] Extracting affiliations from text.
[03.03.2025 10:12] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Tell me why: Visual foundation models as self-explainable classifiers Hugues Turbe 1 2 Mina Bjelogrlic 1 2 Gianmarco Mengaldo 3 Christian Lovis 1 2 5 2 0 2 6 2 ] . [ 1 7 7 5 9 1 . 2 0 5 2 : r aVisual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, selfexplainable models (SEM) aim to provide interpretable classifiers that decompose predictions into weighted sum of interpretable concepts. Despite their promise, recent studies have shown that these explanations often lack faithfulness. In this work, we combine VFMs with novel prototypical architecture and specialized training objectives. By training only lightweight head (approximately 1M parameters) on top of frozen VFMs, our approach (ProtoFM) offers an efficient and interpretable solution. Evaluations demonstrate that our approach achieves competitive classification performance while outperforming existing models across range of interpretability metrics derived from the literature. Code is available at https: //github.com/hturbe/proto-fm. 1. Introduction Deep neural networks have shown impressive results in vision tasks, including segmentation and classification. Recent progress has been largely driven by the development of visual foundation models (VFMs), that is, models trained on vast image datasets that serve various downstream tasks. As VFMs are increasingly applied in diverse domains, interpretability is becoming crucial for critical fields like medicine and remote sensing. Given the ambiguity around what interpretability means (Lipton, 2018), in this work we focus on the ability to reflect the influence of the input fea1Department of Radiology and Medical Informatics, University of Geneva, Geneva, Switzerland 2Division of Medical Information Sciences, Geneva University Hospitals, Geneva, Switzerland 3Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore, Singapore. Correspondence to: Hugues Turbe <hugues.turbe@unige.ch>. Preliminary work currently under review. tures on the models prediction. Besides legal requirements (Metikoˇs & Ausloos, 2024), the absence of interpretability has often been pointed out as barrier to the adoption of deep learning models in various domains, such as the healthcare sector (Reddy, 2022). Beyond the adoption challenges, interpretability may allow for scientific discovery where model might have discovered some rules in the data unknown to the scientific community that can be uncovered through explaining the models predictions (Mengaldo, 2025). Methods for model interpretability can be broadly categorized into two paradigms based on the stage of model development where interpretability is incorporated: (i) the intrinsic paradigm, and (ii) the post-hoc paradigm (Madsen et al., 2024). Post-hoc methods aim to provide explanations for already trained models. These methods are often modelagnostic (e.g., SHAP (Lundberg & Lee, 2017)), and do not interfere with model training or performance. However, these methods are often criticized for their lack of faithfulness (Adebayo et al., 2018; Hooker et al., 2019a; Turbe et al., 2023; Wei et al., 2024), raising significant concerns about their reliability in critical applications. This has led to growing advocacy for the intrinsic paradigm (Rudin, 2019), which involves models designed to be interpretable by design, which are also referred to as self-explainable models (SEM). notable direction within SEM is the development of partprototype models, which aim to decompose predictions into weighted sum of interpretable concepts. Although these models are theoretically designed to provide consistent explanations, recent findings indicate that the explanations they generate often lack faithfulness. Specifically, these models tend to mislocalize critical regions of the input that are important for classification (Sacha et al., 2024; Carmichael et al., 2024a) and fail to represent coherent concepts in the input space (Hoffmann et al., 2021), aspects that undermine their interpretability. Another general criticism of the intrinsic paradigm is that previous approaches are not designed to leverage pre-trained models, such as vision foundation models (VFMs) (Madsen et al., 2024). In this work, we aim to address the challenges just described that affect SEMs . We achieve this goal by designing new Tell me why: Visual foundation models as self-explainable classifiers architecture, ProtoFM, depicted in Figure 1, that (i) significantly improves the quality of the explanations provided, and (ii) allows using frozen VFMs. One of the key motivations behind using existing VFMs, such as Dinov2 (Oquab et al., 2024), AMRADIO (Ranzinger et al., 2024), and SAM (Kirillov et al., 2023), is their state-of-the-art performance on variety of downstream tasks, including classification and segmentation in general image domains (Oquab et al., 2024; Ranzinger et al., 2024), and specialized tasks e.g., RADDINO (Perez-Garcıa et al., 2025) for chest radiography, and SkySense (Guo et al., 2024) for remote sensing. We argue that using frozen VFMs enables efficient training on diverse classification tasks with minimal number of parameters trained. Furthermore, VFMs trained with patchlevel objectives, yield strong local representations, as evidenced by their high performance in segmentation (Oquab et al., 2024; Perez-Garcıa et al., 2025). This property is important to addresses the critical issue of spatial alignment in prototypical models. Contributions 1. Introduce novel architecture which allows to leverage frozen VFMs providing lightweight approach ( 1M trained parameter). The evaluation demonstrates that the architecture is competitive in terms of classification performance achieves SOTA performance across the range of interpretability desiderata derived from the literature. 2. We extensively evaluate number of prototypical models from the literature, highlighting important issues regarding the correctness and contrastivity of the explanations obtained with these models, justifying the introduction of the novel architecture. 2. Related work The development of Prototypical Part Network research was initiated by the ProtoPNet architecture (Chen et al., 2019). ProtoPNet works by comparing parts of an image to learned prototypes, which are meant to represent semantically coherent concepts. This approach allows t"
[03.03.2025 10:12] Mistral response. {"id": "d67fe6b34e1c48cf9e246862597b6fb3", "object": "chat.completion", "created": 1740996739, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Department of Radiology and Medical Informatics, University of Geneva, Geneva, Switzerland\",\n    \"Division of Medical Information Sciences, Geneva University Hospitals, Geneva, Switzerland\",\n    \"Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore, Singapore\"\n]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1614, "total_tokens": 1693, "completion_tokens": 79}}
[03.03.2025 10:12] Response: ```python
[
    "Department of Radiology and Medical Informatics, University of Geneva, Geneva, Switzerland",
    "Division of Medical Information Sciences, Geneva University Hospitals, Geneva, Switzerland",
    "Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore, Singapore"
]
```
[03.03.2025 10:12] Deleting PDF ./assets/pdf/2502.19577.pdf.
[03.03.2025 10:12] Success.
[03.03.2025 10:12] Enriching papers with extra data.
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 0. Designing solutions for complex engineering challenges is crucial in human production activities. However, previous research in the retrieval-augmented generation (RAG) field has not sufficiently addressed tasks related to the design of complex engineering solutions. To fill this gap, we introduce a...
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 1. Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning. However, humans typically employ a more efficient strategy: drafting concise intermedia...
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 2. Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehe...
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 3. Large Language Models (LLMs) have achieved human-level proficiency across diverse tasks, but their ability to perform rigorous mathematical problem solving remains an open challenge. In this work, we investigate a fundamental yet computationally intractable problem: determining whether a given multi...
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 4. Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited. This work investigates the key challenges in applying reinforcement learning to solve a collec...
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 5. Recent Multi-modal Large Language Models (MLLMs) have made great progress in video understanding. However, their performance on videos involving human actions is still limited by the lack of high-quality data. To address this, we introduce a two-stage data annotation pipeline. First, we design strat...
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 6. Modern automatic speech recognition (ASR) models, such as OpenAI's Whisper, rely on deep encoder-decoder architectures, and their encoders are a critical bottleneck for efficient deployment due to high computational intensity. We introduce LiteASR, a low-rank compression scheme for ASR encoders that...
[03.03.2025 10:12] ********************************************************************************
[03.03.2025 10:12] Abstract 7. Visual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, self-explainable models (SEM) aim to provide interpretable classifiers that decompose predictions into a wei...
[03.03.2025 10:12] Read previous papers.
[03.03.2025 10:12] Generating reviews via LLM API.
[03.03.2025 10:12] Using data from previous issue: {"categories": ["#rag", "#benchmark"], "emoji": "🔧", "ru": {"title": "Умная система для проектирования сложных инженерных решений", "desc": "Статья представляет новый бенчмарк SolutionBench для оценки способности систем генерировать решения инженерных задач с множественными ограничениями. Авторы пре
[03.03.2025 10:12] Using data from previous issue: {"categories": ["#reasoning", "#training", "#rl"], "emoji": "✍️", "ru": {"title": "Эффективное рассуждение: краткость - сестра точности", "desc": "Статья представляет новый подход к решению сложных задач с помощью больших языковых моделей - Chain of Draft (CoD). В отличие от метода Chain-of-Thought 
[03.03.2025 10:12] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#rag", "#games", "#benchmark", "#multimodal", "#dataset"], "emoji": "🔍", "ru": {"title": "ViDoRAG: Новый подход к извлечению информации из визуальных документов", "desc": "Статья представляет новый набор данных ViDoSeek для оценки эффективности методов извле
[03.03.2025 10:12] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#training", "#math", "#reasoning"], "emoji": "🧮", "ru": {"title": "Большие языковые модели преодолевают границы математического мышления", "desc": "В этой статье исследуется способность больших языковых моделей (LLM) решать сложные математические задачи,
[03.03.2025 10:12] Using data from previous issue: {"categories": ["#robotics", "#rl", "#games", "#optimization"], "emoji": "🤖", "ru": {"title": "Ловкость робота: от симуляции к реальности", "desc": "Статья описывает применение обучения с подкреплением для решения задач манипуляции объектами с помощью человекоподобного робота. Авторы представляют но
[03.03.2025 10:12] Using data from previous issue: {"categories": ["#dataset", "#data", "#video", "#multimodal", "#benchmark", "#synthetic"], "emoji": "🎬", "ru": {"title": "Улучшение понимания человеческих действий в видео с помощью аннотированных данных", "desc": "Статья представляет новый подход к улучшению понимания видео с человеческими действия
[03.03.2025 10:12] Using data from previous issue: {"categories": ["#inference", "#optimization", "#audio"], "emoji": "🎙️", "ru": {"title": "LiteASR: Эффективное сжатие энкодеров ASR без потери точности", "desc": "LiteASR - это метод сжатия энкодеров для систем автоматического распознавания речи (ASR), который значительно уменьшает вычислительные за
[03.03.2025 10:12] Querying the API.
[03.03.2025 10:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Visual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, self-explainable models (SEM) aim to provide interpretable classifiers that decompose predictions into a weighted sum of interpretable concepts. Despite their promise, recent studies have shown that these explanations often lack faithfulness. In this work, we combine VFMs with a novel prototypical architecture and specialized training objectives. By training only a lightweight head (approximately 1M parameters) on top of frozen VFMs, our approach (ProtoFM) offers an efficient and interpretable solution. Evaluations demonstrate that our approach achieves competitive classification performance while outperforming existing models across a range of interpretability metrics derived from the literature. Code is available at https://github.com/hturbe/proto-fm.
[03.03.2025 10:12] Response: {
  "desc": "Статья описывает новый подход к интерпретируемости визуальных моделей-основ (VFM). Авторы предлагают комбинацию VFM с прототипической архитектурой и специализированными целями обучения, названную ProtoFM. Этот метод обучает только легковесную верхушку поверх замороженных VFM, что обеспечивает эффективное и интерпретируемое решение. Эксперименты показывают, что ProtoFM достигает конкурентоспособной точности классификации, превосходя существующие модели по ряду метрик интерпретируемости.",
  "emoji": "🔍",
  "title": "ProtoFM: Интерпретируемость визуальных моделей без потери точности"
}
[03.03.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, self-explainable models (SEM) aim to provide interpretable classifiers that decompose predictions into a weighted sum of interpretable concepts. Despite their promise, recent studies have shown that these explanations often lack faithfulness. In this work, we combine VFMs with a novel prototypical architecture and specialized training objectives. By training only a lightweight head (approximately 1M parameters) on top of frozen VFMs, our approach (ProtoFM) offers an efficient and interpretable solution. Evaluations demonstrate that our approach achieves competitive classification performance while outperforming existing models across a range of interpretability metrics derived from the literature. Code is available at https://github.com/hturbe/proto-fm."

[03.03.2025 10:12] Response: ```python
['CV', 'ARCHITECTURE', 'TRAINING', 'SMALL_MODELS']
```
[03.03.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Visual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, self-explainable models (SEM) aim to provide interpretable classifiers that decompose predictions into a weighted sum of interpretable concepts. Despite their promise, recent studies have shown that these explanations often lack faithfulness. In this work, we combine VFMs with a novel prototypical architecture and specialized training objectives. By training only a lightweight head (approximately 1M parameters) on top of frozen VFMs, our approach (ProtoFM) offers an efficient and interpretable solution. Evaluations demonstrate that our approach achieves competitive classification performance while outperforming existing models across a range of interpretability metrics derived from the literature. Code is available at https://github.com/hturbe/proto-fm."

[03.03.2025 10:12] Response: ```python
['INTERPRETABILITY', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[03.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces ProtoFM, a new approach that combines visual foundation models (VFMs) with a prototypical architecture to enhance interpretability in machine learning. The method focuses on creating self-explainable models (SEMs) that break down predictions into understandable components, addressing the issue of faithfulness in explanations. By training a lightweight head on top of frozen VFMs, ProtoFM maintains high classification performance while improving interpretability metrics. The results show that ProtoFM outperforms existing models, making it a promising solution for applications requiring both accuracy and clarity.","title":"ProtoFM: Interpretable and Efficient Visual Foundation Models"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces ProtoFM, a new approach that combines visual foundation models (VFMs) with a prototypical architecture to enhance interpretability in machine learning. The method focuses on creating self-explainable models (SEMs) that break down predictions into understandable components, addressing the issue of faithfulness in explanations. By training a lightweight head on top of frozen VFMs, ProtoFM maintains high classification performance while improving interpretability metrics. The results show that ProtoFM outperforms existing models, making it a promising solution for applications requiring both accuracy and clarity.', title='ProtoFM: Interpretable and Efficient Visual Foundation Models'))
[03.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"视觉基础模型（VFM）因其卓越的性能而受到广泛关注，但在关键应用中可解释性仍然至关重要。自解释模型（SEM）旨在提供可解释的分类器，将预测分解为可解释概念的加权和。尽管有潜力，近期研究表明这些解释往往缺乏可信度。我们提出了一种结合VFM和新型原型架构的方案（ProtoFM），通过在冻结的VFM上训练一个轻量级的头部模型，提供了一种高效且可解释的解决方案。","title":"高效可解释的视觉基础模型"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='视觉基础模型（VFM）因其卓越的性能而受到广泛关注，但在关键应用中可解释性仍然至关重要。自解释模型（SEM）旨在提供可解释的分类器，将预测分解为可解释概念的加权和。尽管有潜力，近期研究表明这些解释往往缺乏可信度。我们提出了一种结合VFM和新型原型架构的方案（ProtoFM），通过在冻结的VFM上训练一个轻量级的头部模型，提供了一种高效且可解释的解决方案。', title='高效可解释的视觉基础模型'))
[03.03.2025 10:12] Loading Chinese text from previous data.
[03.03.2025 10:12] Renaming data file.
[03.03.2025 10:12] Renaming previous data. hf_papers.json to ./d/2025-03-03.json
[03.03.2025 10:12] Saving new data file.
[03.03.2025 10:12] Generating page.
[03.03.2025 10:12] Renaming previous page.
[03.03.2025 10:12] Renaming previous data. index.html to ./d/2025-03-03.html
[03.03.2025 10:12] [Experimental] Generating Chinese page for reading.
[03.03.2025 10:12] Chinese vocab [{'word': '设计', 'pinyin': 'shèjì', 'trans': 'design'}, {'word': '复杂', 'pinyin': 'fùzá', 'trans': 'complex'}, {'word': '工程', 'pinyin': 'gōngchéng', 'trans': 'engineering'}, {'word': '挑战', 'pinyin': 'tiǎozhàn', 'trans': 'challenge'}, {'word': '解决方案', 'pinyin': 'jiějué fāngàn', 'trans': 'solution'}, {'word': '至关重要', 'pinyin': 'zhìguān zhòngyào', 'trans': 'crucial'}, {'word': '检索', 'pinyin': 'jiǎnsuǒ', 'trans': 'retrieval'}, {'word': '增强', 'pinyin': 'zēngqiáng', 'trans': 'enhanced'}, {'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generation'}, {'word': '研究', 'pinyin': 'yánjiū', 'trans': 'research'}, {'word': '未能', 'pinyin': 'wèinéng', 'trans': 'failed to'}, {'word': '充分', 'pinyin': 'chōngfèn', 'trans': 'adequately'}, {'word': '相关', 'pinyin': 'xiāngguān', 'trans': 'related'}, {'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'}, {'word': '引入', 'pinyin': 'yǐnrù', 'trans': 'introduce'}, {'word': '基准', 'pinyin': 'jīzhǔn', 'trans': 'benchmark'}, {'word': '评估', 'pinyin': 'pínggū', 'trans': 'evaluate'}, {'word': '系统', 'pinyin': 'xìtǒng', 'trans': 'system'}, {'word': '完整', 'pinyin': 'wánzhěng', 'trans': 'complete'}, {'word': '可行', 'pinyin': 'kěxíng', 'trans': 'feasible'}, {'word': '工程问题', 'pinyin': 'gōngchéng wèntí', 'trans': 'engineering problem'}, {'word': '解决方案', 'pinyin': 'jiějué fāngàn', 'trans': 'solution'}, {'word': '能力', 'pinyin': 'nénglì', 'trans': 'capability'}, {'word': '提出', 'pinyin': 'tíchū', 'trans': 'propose'}, {'word': '新系统', 'pinyin': 'xīn xìtǒng', 'trans': 'new system'}, {'word': '利用', 'pinyin': 'lìyòng', 'trans': 'utilize'}, {'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'}, {'word': '树', 'pinyin': 'shù', 'trans': 'tree'}, {'word': '探索', 'pinyin': 'tànsuǒ', 'trans': 'exploration'}, {'word': '双点思维', 'pinyin': 'shuāngdiǎn sīwéi', 'trans': 'dual-point thinking'}, {'word': '机制', 'pinyin': 'jīzhì', 'trans': 'mechanism'}, {'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generate'}, {'word': '可靠', 'pinyin': 'kěkào', 'trans': 'reliable'}, {'word': '实验', 'pinyin': 'shíyàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jiéguǒ', 'trans': 'result'}, {'word': '显示', 'pinyin': 'xiǎnshì', 'trans': 'show'}, {'word': '达到', 'pinyin': 'dádào', 'trans': 'achieve'}, {'word': '最先进', 'pinyin': 'zuì xiānjìn', 'trans': 'state-of-the-art'}, {'word': '性能', 'pinyin': 'xìngnéng', 'trans': 'performance'}, {'word': '突显', 'pinyin': 'tūxiǎn', 'trans': 'highlight'}, {'word': '潜力', 'pinyin': 'qiánlì', 'trans': 'potential'}, {'word': '实际', 'pinyin': 'shíjì', 'trans': 'practical'}, {'word': '应用', 'pinyin': 'yìngyòng', 'trans': 'application'}, {'word': '增强', 'pinyin': 'zēngqiáng', 'trans': 'enhance'}, {'word': '自动化', 'pinyin': 'zìdònghuà', 'trans': 'automation'}]
[03.03.2025 10:12] Renaming previous Chinese page.
[03.03.2025 10:12] Renaming previous data. zh.html to ./d/2025-03-02_zh_reading_task.html
[03.03.2025 10:12] Writing Chinese reading task.
[03.03.2025 10:12] Writing result.
[03.03.2025 10:12] Renaming log file.
[03.03.2025 10:12] Renaming previous data. log.txt to ./logs/2025-03-03_last_log.txt
