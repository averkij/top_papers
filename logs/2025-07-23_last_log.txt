[23.07.2025 04:01] Read previous papers.
[23.07.2025 04:01] Generating top page (month).
[23.07.2025 04:01] Writing top page (month).
[23.07.2025 04:43] Read previous papers.
[23.07.2025 04:43] Get feed.
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16632
[23.07.2025 04:43] Extract page data from URL. URL: https://huggingface.co/papers/2507.16784
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16815
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16812
[23.07.2025 04:43] Extract page data from URL. URL: https://huggingface.co/papers/2507.16814
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16746
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.15024
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16813
[23.07.2025 04:43] Extract page data from URL. URL: https://huggingface.co/papers/2507.15974
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.15454
[23.07.2025 04:43] Get page data from previous paper. URL: https://huggingface.co/papers/2507.15245
[23.07.2025 04:43] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.07.2025 04:43] No deleted papers detected.
[23.07.2025 04:43] Downloading and parsing papers (pdf, html). Total: 11.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.16632.
[23.07.2025 04:43] Extra JSON file exists (./assets/json/2507.16632.json), skip PDF parsing.
[23.07.2025 04:43] Paper image links file exists (./assets/img_data/2507.16632.json), skip HTML parsing.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.16784.
[23.07.2025 04:43] Downloading paper 2507.16784 from http://arxiv.org/pdf/2507.16784v1...
[23.07.2025 04:43] Extracting affiliations from text.
[23.07.2025 04:43] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 2 ] . [ 1 4 8 7 6 1 . 7 0 5 2 : r Research Preview BEYOND CONTEXT LIMITS: SUBCONSCIOUS THREADS FOR LONG-HORIZON REASONING Hongyin Luo1,2, Nathaniel Morgan1, Tina Li1, Derek Zhao1, Ai Vy Ngo1, Philip Schroeder1, Lijie Yang3, Assaf Ben-Kish4, Jack OBrien2, James Glass1 1 MIT CSAIL 2 Subconscious Systems Technologies, Inc. 3 Princeton University 4 Tel Aviv University hyluo@mit.edu, {hongyin,jack}@subconscious.dev "
[23.07.2025 04:43] Response: ```python
["MIT CSAIL", "Subconscious Systems Technologies, Inc.", "Princeton University", "Tel Aviv University"]
```
[23.07.2025 04:43] Deleting PDF ./assets/pdf/2507.16784.pdf.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.16815.
[23.07.2025 04:43] Extra JSON file exists (./assets/json/2507.16815.json), skip PDF parsing.
[23.07.2025 04:43] Paper image links file exists (./assets/img_data/2507.16815.json), skip HTML parsing.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.16812.
[23.07.2025 04:43] Extra JSON file exists (./assets/json/2507.16812.json), skip PDF parsing.
[23.07.2025 04:43] Paper image links file exists (./assets/img_data/2507.16812.json), skip HTML parsing.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.16814.
[23.07.2025 04:43] Downloading paper 2507.16814 from http://arxiv.org/pdf/2507.16814v1...
[23.07.2025 04:43] Extracting affiliations from text.
[23.07.2025 04:43] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 2 ] . [ 1 4 1 8 6 1 . 7 0 5 2 : r Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning Junhao Shen1,2 Haiteng Zhao1 Yuzhe Gu1,2 Songyang Gao1 Kuikun Liu1 Haian Huang1 Jianfei Gao1 Dahua Lin1,3 Wenwei Zhang1 Kai Chen1 1Shanghai AI Laboratory 2Shanghai Jiao Tong University 3MMLab, The Chinese University of Hong Kong {shenjunhao,zhangwenwei,chenkai}@pjlab.org.cn "
[23.07.2025 04:43] Response: ```python
["Shanghai AI Laboratory", "Shanghai Jiao Tong University", "MMLab, The Chinese University of Hong Kong"]
```
[23.07.2025 04:43] Deleting PDF ./assets/pdf/2507.16814.pdf.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.16746.
[23.07.2025 04:43] Extra JSON file exists (./assets/json/2507.16746.json), skip PDF parsing.
[23.07.2025 04:43] Paper image links file exists (./assets/img_data/2507.16746.json), skip HTML parsing.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.15024.
[23.07.2025 04:43] Extra JSON file exists (./assets/json/2507.15024.json), skip PDF parsing.
[23.07.2025 04:43] Paper image links file exists (./assets/img_data/2507.15024.json), skip HTML parsing.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.16813.
[23.07.2025 04:43] Extra JSON file exists (./assets/json/2507.16813.json), skip PDF parsing.
[23.07.2025 04:43] Paper image links file exists (./assets/img_data/2507.16813.json), skip HTML parsing.
[23.07.2025 04:43] Success.
[23.07.2025 04:43] Downloading and parsing paper https://huggingface.co/papers/2507.15974.
[23.07.2025 04:43] Downloading paper 2507.15974 from http://arxiv.org/pdf/2507.15974v1...
[23.07.2025 04:44] Extracting affiliations from text.
[23.07.2025 04:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 2 ] . [ 1 4 7 9 5 1 . 7 0 5 2 : r Preprint. Under review. Does More Inference-Time Compute Really Help Robustness? Tong Wu1, Chong Xiang2, Jiachen T. Wang1, Weichen Yu3, Chawin Sitawarin4, Vikash Sehwag4, Prateek Mittal1 1Princeton University, 2NVIDIA, 3Carnegie Mellon University, 4Google DeepMind tongwu@princeton.edu "
[23.07.2025 04:44] Response: ```python
["Princeton University", "NVIDIA", "Carnegie Mellon University", "Google DeepMind"]
```
[23.07.2025 04:44] Deleting PDF ./assets/pdf/2507.15974.pdf.
[23.07.2025 04:44] Success.
[23.07.2025 04:44] Downloading and parsing paper https://huggingface.co/papers/2507.15454.
[23.07.2025 04:44] Extra JSON file exists (./assets/json/2507.15454.json), skip PDF parsing.
[23.07.2025 04:44] Paper image links file exists (./assets/img_data/2507.15454.json), skip HTML parsing.
[23.07.2025 04:44] Success.
[23.07.2025 04:44] Downloading and parsing paper https://huggingface.co/papers/2507.15245.
[23.07.2025 04:44] Extra JSON file exists (./assets/json/2507.15245.json), skip PDF parsing.
[23.07.2025 04:44] Paper image links file exists (./assets/img_data/2507.15245.json), skip HTML parsing.
[23.07.2025 04:44] Success.
[23.07.2025 04:44] Enriching papers with extra data.
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 0. This paper presents Step-Audio~2, an end-to-end multi-modal large language model designed for industry-strength audio understanding and speech conversation. By integrating a latent audio encoder and reasoning-centric reinforcement learning (RL), Step-Audio 2 achieves promising performance in automat...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 1. A Thread Inference Model (TIM) and its runtime (TIMRUN) enable long-horizon reasoning in LLMs by using reasoning trees and key-value state retention, overcoming context and memory limitations.  					AI-generated summary 				 To break the context limits of large language models (LLMs) that bottleneck...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 2. ThinkAct, a dual-system framework, uses reinforced visual latent planning to enable high-level reasoning and robust action execution in vision-language-action tasks.  					AI-generated summary 				 Vision-language-action (VLA) reasoning tasks require agents to interpret multimodal instructions, perf...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 3. MegaScience, a large-scale dataset of scientific reasoning questions, enhances the performance and training efficiency of AI models compared to existing datasets.  					AI-generated summary 				 Scientific reasoning is critical for developing AI scientists and supporting human researchers in advanci...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 4. Enhancing large vision-language models (LVLMs) with visual slow-thinking reasoning is crucial for solving complex multimodal tasks. However, since LVLMs are mainly trained with vision-language alignment, it is difficult to adopt on-policy reinforcement learning (RL) to develop the slow thinking abil...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 5. Humans often use visual aids, for example diagrams or sketches, when solving complex problems. Training multimodal models to do the same, known as Visual Chain of Thought (Visual CoT), is challenging due to: (1) poor off-the-shelf visual CoT performance, which hinders reinforcement learning, and (2)...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 6. With the rapid advancement of Large Language Models (LLMs), developing effective critic modules for precise guidance has become crucial yet challenging. In this paper, we initially demonstrate that supervised fine-tuning for building critic modules (which is widely adopted in current solutions) fail...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 7. HOComp uses MLLMs and attention mechanisms to achieve seamless human-object interactions with consistent appearances in image compositing.  					AI-generated summary 				 While existing image-guided composition methods may help insert a foreground object onto a user-specified region of a background ...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 8. Recently, Zaremba et al. demonstrated that increasing inference-time computation improves robustness in large proprietary reasoning LLMs. In this paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1, Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 9. ObjectGS combines 3D scene reconstruction with semantic understanding by modeling individual objects as neural Gaussians, achieving superior performance in segmentation and integration with applications like mesh extraction and scene editing.  					AI-generated summary 				 3D Gaussian Splatting is ...
[23.07.2025 04:44] ********************************************************************************
[23.07.2025 04:44] Abstract 10. Recent advances in large language models (LLMs) have opened new opportunities for academic literature retrieval. However, existing systems often rely on rigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR, a multi-agent framework that incorporates RefChain-based query decom...
[23.07.2025 04:44] Read previous papers.
[23.07.2025 04:44] Generating reviews via LLM API.
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#agi", "#hallucinations", "#reasoning", "#rl", "#audio", "#open_source", "#rag"], "emoji": "🎙️", "ru": {"title": "Интеллектуальное понимание аудио и речи с помощью мультимодальной языковой модели", "desc": "Step-Audio 2 - это мультимодальная языковая мод
[23.07.2025 04:44] Querying the API.
[23.07.2025 04:44] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A Thread Inference Model (TIM) and its runtime (TIMRUN) enable long-horizon reasoning in LLMs by using reasoning trees and key-value state retention, overcoming context and memory limitations.  					AI-generated summary 				 To break the context limits of large language models (LLMs) that bottleneck reasoning accuracy and efficiency, we propose the Thread Inference Model (TIM), a family of LLMs trained for recursive and decompositional problem solving, and TIMRUN, an inference runtime enabling long-horizon structured reasoning beyond context limits. Together, TIM hosted on TIMRUN supports virtually unlimited working memory and multi-hop tool calls within a single language model inference, overcoming output limits, positional-embedding constraints, and GPU-memory bottlenecks. Performance is achieved by modeling natural language as reasoning trees measured by both length and depth instead of linear sequences. The reasoning trees consist of tasks with thoughts, recursive subtasks, and conclusions based on the concept we proposed in Schroeder et al, 2025. During generation, we maintain a working memory that retains only the key-value states of the most relevant context tokens, selected by a rule-based subtask-pruning mechanism, enabling reuse of positional embeddings and GPU memory pages throughout reasoning. Experimental results show that our system sustains high inference throughput, even when manipulating up to 90% of the KV cache in GPU memory. It also delivers accurate reasoning on mathematical tasks and handles information retrieval challenges that require long-horizon reasoning and multi-hop tool use.
[23.07.2025 04:44] Response: {
  "desc": "Эта статья представляет Thread Inference Model (TIM) и его среду выполнения TIMRUN, которые позволяют большим языковым моделям (LLM) осуществлять долгосрочные рассуждения. TIM использует деревья рассуждений и сохранение ключевых состояний для преодоления ограничений контекста и памяти. Система поддерживает практически неограниченную рабочую память и многоэтапные вызовы инструментов в рамках одного вывода языковой модели. Экспериментальные результаты показывают высокую пропускную способность вывода и точные рассуждения для задач, требующих долгосрочного анализа.",

  "emoji": "🧠",

  "title": "Преодоление ограничений контекста в LLM с помощью древовидных рассуждений"
}
[23.07.2025 04:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A Thread Inference Model (TIM) and its runtime (TIMRUN) enable long-horizon reasoning in LLMs by using reasoning trees and key-value state retention, overcoming context and memory limitations.  					AI-generated summary 				 To break the context limits of large language models (LLMs) that bottleneck reasoning accuracy and efficiency, we propose the Thread Inference Model (TIM), a family of LLMs trained for recursive and decompositional problem solving, and TIMRUN, an inference runtime enabling long-horizon structured reasoning beyond context limits. Together, TIM hosted on TIMRUN supports virtually unlimited working memory and multi-hop tool calls within a single language model inference, overcoming output limits, positional-embedding constraints, and GPU-memory bottlenecks. Performance is achieved by modeling natural language as reasoning trees measured by both length and depth instead of linear sequences. The reasoning trees consist of tasks with thoughts, recursive subtasks, and conclusions based on the concept we proposed in Schroeder et al, 2025. During generation, we maintain a working memory that retains only the key-value states of the most relevant context tokens, selected by a rule-based subtask-pruning mechanism, enabling reuse of positional embeddings and GPU memory pages throughout reasoning. Experimental results show that our system sustains high inference throughput, even when manipulating up to 90% of the KV cache in GPU memory. It also delivers accurate reasoning on mathematical tasks and handles information retrieval challenges that require long-horizon reasoning and multi-hop tool use."

[23.07.2025 04:44] Response: ```python
['INFERENCE', 'ARCHITECTURE', 'MATH']
```
[23.07.2025 04:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A Thread Inference Model (TIM) and its runtime (TIMRUN) enable long-horizon reasoning in LLMs by using reasoning trees and key-value state retention, overcoming context and memory limitations.  					AI-generated summary 				 To break the context limits of large language models (LLMs) that bottleneck reasoning accuracy and efficiency, we propose the Thread Inference Model (TIM), a family of LLMs trained for recursive and decompositional problem solving, and TIMRUN, an inference runtime enabling long-horizon structured reasoning beyond context limits. Together, TIM hosted on TIMRUN supports virtually unlimited working memory and multi-hop tool calls within a single language model inference, overcoming output limits, positional-embedding constraints, and GPU-memory bottlenecks. Performance is achieved by modeling natural language as reasoning trees measured by both length and depth instead of linear sequences. The reasoning trees consist of tasks with thoughts, recursive subtasks, and conclusions based on the concept we proposed in Schroeder et al, 2025. During generation, we maintain a working memory that retains only the key-value states of the most relevant context tokens, selected by a rule-based subtask-pruning mechanism, enabling reuse of positional embeddings and GPU memory pages throughout reasoning. Experimental results show that our system sustains high inference throughput, even when manipulating up to 90% of the KV cache in GPU memory. It also delivers accurate reasoning on mathematical tasks and handles information retrieval challenges that require long-horizon reasoning and multi-hop tool use."

[23.07.2025 04:44] Response: ```python
["REASONING", "LONG_CONTEXT"]
```
[23.07.2025 04:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Thread Inference Model (TIM) introduces a new approach for large language models (LLMs) to enhance their reasoning capabilities over extended contexts. By utilizing reasoning trees and a key-value state retention mechanism, TIM allows for recursive problem solving and efficient management of memory during inference. This model overcomes traditional limitations of LLMs, such as output constraints and GPU memory bottlenecks, enabling complex multi-hop reasoning tasks. Experimental results demonstrate that TIM can maintain high throughput while accurately performing mathematical reasoning and information retrieval tasks that require long-horizon thinking.","title":"Unlocking Long-Horizon Reasoning in LLMs with TIM"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Thread Inference Model (TIM) introduces a new approach for large language models (LLMs) to enhance their reasoning capabilities over extended contexts. By utilizing reasoning trees and a key-value state retention mechanism, TIM allows for recursive problem solving and efficient management of memory during inference. This model overcomes traditional limitations of LLMs, such as output constraints and GPU memory bottlenecks, enabling complex multi-hop reasoning tasks. Experimental results demonstrate that TIM can maintain high throughput while accurately performing mathematical reasoning and information retrieval tasks that require long-horizon thinking.', title='Unlocking Long-Horizon Reasoning in LLMs with TIM'))
[23.07.2025 04:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种线程推理模型（TIM）及其运行时（TIMRUN），旨在解决大型语言模型（LLMs）在推理准确性和效率上的上下文限制。TIM通过使用推理树和关键值状态保留，支持递归和分解问题的解决，从而实现长时间跨度的推理。该模型能够在单次推理中支持几乎无限的工作记忆和多跳工具调用，克服了输出限制和GPU内存瓶颈。实验结果表明，该系统在处理数学任务和信息检索挑战时，能够保持高推理吞吐量，并提供准确的推理能力。","title":"突破上下文限制，实现长远推理"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种线程推理模型（TIM）及其运行时（TIMRUN），旨在解决大型语言模型（LLMs）在推理准确性和效率上的上下文限制。TIM通过使用推理树和关键值状态保留，支持递归和分解问题的解决，从而实现长时间跨度的推理。该模型能够在单次推理中支持几乎无限的工作记忆和多跳工具调用，克服了输出限制和GPU内存瓶颈。实验结果表明，该系统在处理数学任务和信息检索挑战时，能够保持高推理吞吐量，并提供准确的推理能力。', title='突破上下文限制，实现长远推理'))
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#agents", "#optimization", "#robotics", "#training", "#multimodal", "#reasoning"], "emoji": "🤖", "ru": {"title": "Думай и действуй: интеллектуальное планирование для воплощенного ИИ", "desc": "ThinkAct - это двухсистемная архитектура для задач визуально-языкового взаимодействия. Она
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#benchmark", "#science", "#data", "#open_source", "#reasoning", "#dataset"], "emoji": "🧠", "ru": {"title": "MegaScience: прорыв в научном мышлении ИИ", "desc": "MegaScience - это крупномасштабный набор данных научных рассуждений, улучшающий производительность и эффективность обучени
[23.07.2025 04:44] Querying the API.
[23.07.2025 04:44] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Enhancing large vision-language models (LVLMs) with visual slow-thinking reasoning is crucial for solving complex multimodal tasks. However, since LVLMs are mainly trained with vision-language alignment, it is difficult to adopt on-policy reinforcement learning (RL) to develop the slow thinking ability because the rollout space is restricted by its initial abilities. Off-policy RL offers a way to go beyond the current policy, but directly distilling trajectories from external models may cause visual hallucinations due to mismatched visual perception abilities across models. To address these issues, this paper proposes SOPHIA, a simple and scalable Semi-Off-Policy RL for vision-language slow-tHInking reAsoning. SOPHIA builds a semi-off-policy behavior model by combining on-policy visual understanding from a trainable LVLM with off-policy slow-thinking reasoning from a language model, assigns outcome-based rewards to reasoning, and propagates visual rewards backward. Then LVLM learns slow-thinking reasoning ability from the obtained reasoning trajectories using propagated rewards via off-policy RL algorithms. Extensive experiments with InternVL2.5 and InternVL3.0 with 8B and 38B sizes show the effectiveness of SOPHIA. Notably, SOPHIA improves InternVL3.0-38B by 8.50% in average, reaching state-of-the-art performance among open-source LVLMs on multiple multimodal reasoning benchmarks, and even outperforms some closed-source models (e.g., GPT-4.1) on the challenging MathVision and OlympiadBench, achieving 49.08% and 49.95% pass@1 accuracy, respectively. Analysis shows SOPHIA outperforms supervised fine-tuning and direct on-policy RL methods, offering a better policy initialization for further on-policy training.
[23.07.2025 04:44] Response: {
  "desc": "Статья представляет SOPHIA - новый метод обучения с подкреплением для улучшения способностей крупных мультимодальных моделей к визуальному рассуждению. SOPHIA сочетает в себе визуальное понимание из обучаемой модели LVLM с медленным рассуждением из языковой модели, используя полу-офф-полисный подход. Метод показал значительное улучшение производительности на различных тестах мультимодального рассуждения, превзойдя некоторые закрытые модели. Анализ демонстрирует преимущества SOPHIA перед обучением с учителем и прямыми он-полисными методами обучения с подкреплением.",
  "emoji": "🧠",
  "title": "SOPHIA: Революция в визуальном мышлении искусственного интеллекта"
}
[23.07.2025 04:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Enhancing large vision-language models (LVLMs) with visual slow-thinking reasoning is crucial for solving complex multimodal tasks. However, since LVLMs are mainly trained with vision-language alignment, it is difficult to adopt on-policy reinforcement learning (RL) to develop the slow thinking ability because the rollout space is restricted by its initial abilities. Off-policy RL offers a way to go beyond the current policy, but directly distilling trajectories from external models may cause visual hallucinations due to mismatched visual perception abilities across models. To address these issues, this paper proposes SOPHIA, a simple and scalable Semi-Off-Policy RL for vision-language slow-tHInking reAsoning. SOPHIA builds a semi-off-policy behavior model by combining on-policy visual understanding from a trainable LVLM with off-policy slow-thinking reasoning from a language model, assigns outcome-based rewards to reasoning, and propagates visual rewards backward. Then LVLM learns slow-thinking reasoning ability from the obtained reasoning trajectories using propagated rewards via off-policy RL algorithms. Extensive experiments with InternVL2.5 and InternVL3.0 with 8B and 38B sizes show the effectiveness of SOPHIA. Notably, SOPHIA improves InternVL3.0-38B by 8.50% in average, reaching state-of-the-art performance among open-source LVLMs on multiple multimodal reasoning benchmarks, and even outperforms some closed-source models (e.g., GPT-4.1) on the challenging MathVision and OlympiadBench, achieving 49.08% and 49.95% pass@1 accuracy, respectively. Analysis shows SOPHIA outperforms supervised fine-tuning and direct on-policy RL methods, offering a better policy initialization for further on-policy training."

[23.07.2025 04:44] Response: ```python
['RL', 'MULTIMODAL', 'BENCHMARK', 'TRAINING']
```
[23.07.2025 04:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Enhancing large vision-language models (LVLMs) with visual slow-thinking reasoning is crucial for solving complex multimodal tasks. However, since LVLMs are mainly trained with vision-language alignment, it is difficult to adopt on-policy reinforcement learning (RL) to develop the slow thinking ability because the rollout space is restricted by its initial abilities. Off-policy RL offers a way to go beyond the current policy, but directly distilling trajectories from external models may cause visual hallucinations due to mismatched visual perception abilities across models. To address these issues, this paper proposes SOPHIA, a simple and scalable Semi-Off-Policy RL for vision-language slow-tHInking reAsoning. SOPHIA builds a semi-off-policy behavior model by combining on-policy visual understanding from a trainable LVLM with off-policy slow-thinking reasoning from a language model, assigns outcome-based rewards to reasoning, and propagates visual rewards backward. Then LVLM learns slow-thinking reasoning ability from the obtained reasoning trajectories using propagated rewards via off-policy RL algorithms. Extensive experiments with InternVL2.5 and InternVL3.0 with 8B and 38B sizes show the effectiveness of SOPHIA. Notably, SOPHIA improves InternVL3.0-38B by 8.50% in average, reaching state-of-the-art performance among open-source LVLMs on multiple multimodal reasoning benchmarks, and even outperforms some closed-source models (e.g., GPT-4.1) on the challenging MathVision and OlympiadBench, achieving 49.08% and 49.95% pass@1 accuracy, respectively. Analysis shows SOPHIA outperforms supervised fine-tuning and direct on-policy RL methods, offering a better policy initialization for further on-policy training."

[23.07.2025 04:44] Response: ```python
['REASONING', 'OPTIMIZATION', 'OPEN_SOURCE']
```
[23.07.2025 04:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces SOPHIA, a novel Semi-Off-Policy Reinforcement Learning (RL) approach designed to enhance large vision-language models (LVLMs) by incorporating slow-thinking reasoning capabilities. The challenge with traditional on-policy RL is that it limits the model\'s ability to explore beyond its initial training, while off-policy RL can lead to visual inconsistencies when using external models. SOPHIA effectively combines on-policy visual understanding from LVLMs with off-policy reasoning from language models, allowing for better learning through outcome-based rewards. Experimental results demonstrate that SOPHIA significantly improves performance on multimodal reasoning tasks, surpassing both open-source and some closed-source models.","title":"SOPHIA: Elevating LVLMs with Semi-Off-Policy Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces SOPHIA, a novel Semi-Off-Policy Reinforcement Learning (RL) approach designed to enhance large vision-language models (LVLMs) by incorporating slow-thinking reasoning capabilities. The challenge with traditional on-policy RL is that it limits the model's ability to explore beyond its initial training, while off-policy RL can lead to visual inconsistencies when using external models. SOPHIA effectively combines on-policy visual understanding from LVLMs with off-policy reasoning from language models, allowing for better learning through outcome-based rewards. Experimental results demonstrate that SOPHIA significantly improves performance on multimodal reasoning tasks, surpassing both open-source and some closed-source models.", title='SOPHIA: Elevating LVLMs with Semi-Off-Policy Reasoning'))
[23.07.2025 04:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为SOPHIA的半离线强化学习方法，用于增强大型视觉语言模型（LVLM）的慢思维推理能力。SOPHIA结合了来自可训练LVLM的在线视觉理解和来自语言模型的离线慢思维推理，利用结果导向的奖励来促进推理过程。通过这种方法，LVLM能够从获得的推理轨迹中学习慢思维推理能力，并通过离线强化学习算法传播奖励。实验结果表明，SOPHIA在多个多模态推理基准上显著提高了模型性能，超越了许多现有的开源和闭源模型。","title":"SOPHIA：提升视觉语言模型的慢思维推理能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为SOPHIA的半离线强化学习方法，用于增强大型视觉语言模型（LVLM）的慢思维推理能力。SOPHIA结合了来自可训练LVLM的在线视觉理解和来自语言模型的离线慢思维推理，利用结果导向的奖励来促进推理过程。通过这种方法，LVLM能够从获得的推理轨迹中学习慢思维推理能力，并通过离线强化学习算法传播奖励。实验结果表明，SOPHIA在多个多模态推理基准上显著提高了模型性能，超越了许多现有的开源和闭源模型。', title='SOPHIA：提升视觉语言模型的慢思维推理能力'))
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#games", "#optimization", "#multimodal", "#open_source", "#cv", "#dataset"], "emoji": "🦓", "ru": {"title": "Zebra-CoT: Прорыв в обучении ИИ визуальному мышлению", "desc": "Статья представляет Zebra-CoT - крупномасштабный набор данных для обучения мультимодальных
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#training", "#reasoning", "#rl", "#rlhf"], "emoji": "🔍", "ru": {"title": "RefCritic: Революция в критике и улучшении языковых моделей", "desc": "В статье представлен новый подход к разработке критических модулей для больших языковых моделей (LLM) - Ref
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#cv", "#synthetic", "#games", "#dataset"], "emoji": "🖼️", "ru": {"title": "Гармоничная композиция человека и объекта с помощью искусственного интеллекта", "desc": "HOComp - это новый подход к композиции изображений, обеспечивающий гармоничное взаимодействие между объектом переднего 
[23.07.2025 04:44] Querying the API.
[23.07.2025 04:44] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recently, Zaremba et al. demonstrated that increasing inference-time computation improves robustness in large proprietary reasoning LLMs. In this paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1, Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a simple budget forcing strategy. More importantly, we reveal and critically examine an implicit assumption in prior work: intermediate reasoning steps are hidden from adversaries. By relaxing this assumption, we identify an important security risk, intuitively motivated and empirically verified as an inverse scaling law: if intermediate reasoning steps become explicitly accessible, increased inference-time computation consistently reduces model robustness. Finally, we discuss practical scenarios where models with hidden reasoning chains are still vulnerable to attacks, such as models with tool-integrated reasoning and advanced reasoning extraction attacks. Our findings collectively demonstrate that the robustness benefits of inference-time scaling depend heavily on the adversarial setting and deployment context. We urge practitioners to carefully weigh these subtle trade-offs before applying inference-time scaling in security-sensitive, real-world applications.
[23.07.2025 04:44] Response: {
  "desc": "Исследование показывает, что увеличение вычислений во время вывода улучшает устойчивость не только крупных проприетарных языковых моделей, но и небольших моделей с открытым исходным кодом. Однако авторы обнаружили, что если промежуточные шаги рассуждений становятся доступными, увеличение вычислений снижает устойчивость модели. Это создает риски безопасности для моделей с интегрированными инструментами рассуждений и при атаках на извлечение рассуждений. Исследователи призывают тщательно оценивать компромиссы перед применением масштабирования вывода в чувствительных к безопасности приложениях.",

  "emoji": "🛡️",

  "title": "Масштабирование вывода: палка о двух концах для безопасности ИИ"
}
[23.07.2025 04:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recently, Zaremba et al. demonstrated that increasing inference-time computation improves robustness in large proprietary reasoning LLMs. In this paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1, Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a simple budget forcing strategy. More importantly, we reveal and critically examine an implicit assumption in prior work: intermediate reasoning steps are hidden from adversaries. By relaxing this assumption, we identify an important security risk, intuitively motivated and empirically verified as an inverse scaling law: if intermediate reasoning steps become explicitly accessible, increased inference-time computation consistently reduces model robustness. Finally, we discuss practical scenarios where models with hidden reasoning chains are still vulnerable to attacks, such as models with tool-integrated reasoning and advanced reasoning extraction attacks. Our findings collectively demonstrate that the robustness benefits of inference-time scaling depend heavily on the adversarial setting and deployment context. We urge practitioners to carefully weigh these subtle trade-offs before applying inference-time scaling in security-sensitive, real-world applications."

[23.07.2025 04:44] Response: ```python
["INFERENCE"]
```
[23.07.2025 04:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recently, Zaremba et al. demonstrated that increasing inference-time computation improves robustness in large proprietary reasoning LLMs. In this paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1, Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a simple budget forcing strategy. More importantly, we reveal and critically examine an implicit assumption in prior work: intermediate reasoning steps are hidden from adversaries. By relaxing this assumption, we identify an important security risk, intuitively motivated and empirically verified as an inverse scaling law: if intermediate reasoning steps become explicitly accessible, increased inference-time computation consistently reduces model robustness. Finally, we discuss practical scenarios where models with hidden reasoning chains are still vulnerable to attacks, such as models with tool-integrated reasoning and advanced reasoning extraction attacks. Our findings collectively demonstrate that the robustness benefits of inference-time scaling depend heavily on the adversarial setting and deployment context. We urge practitioners to carefully weigh these subtle trade-offs before applying inference-time scaling in security-sensitive, real-world applications."

[23.07.2025 04:44] Response: ```python
['SECURITY', 'REASONING']
```
[23.07.2025 04:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how increasing computation during inference can enhance the robustness of smaller, open-source language models, similar to findings in larger proprietary models. The authors challenge the assumption that intermediate reasoning steps in these models are hidden from adversaries, revealing a security risk when these steps are made accessible. They introduce the concept of an inverse scaling law, showing that more computation can actually decrease robustness if adversaries can see the reasoning process. The paper emphasizes the need for careful consideration of these trade-offs in security-sensitive applications, especially when models are integrated with tools or face advanced attack methods.","title":"Inference-Time Scaling: A Double-Edged Sword for Model Robustness"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how increasing computation during inference can enhance the robustness of smaller, open-source language models, similar to findings in larger proprietary models. The authors challenge the assumption that intermediate reasoning steps in these models are hidden from adversaries, revealing a security risk when these steps are made accessible. They introduce the concept of an inverse scaling law, showing that more computation can actually decrease robustness if adversaries can see the reasoning process. The paper emphasizes the need for careful consideration of these trade-offs in security-sensitive applications, especially when models are integrated with tools or face advanced attack methods.', title='Inference-Time Scaling: A Double-Edged Sword for Model Robustness'))
[23.07.2025 04:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"最近，Zaremba等人展示了增加推理时间计算可以提高大型专有推理大语言模型的鲁棒性。本文首先表明，小规模的开源模型（如DeepSeek R1、Qwen3、Phi-reasoning）也可以通过简单的预算强制策略受益于推理时间的扩展。更重要的是，我们揭示并批判性地审视了先前工作的一个隐含假设：中间推理步骤对对手是隐藏的。通过放宽这一假设，我们识别出一个重要的安全风险，即反向缩放法则：如果中间推理步骤变得显式可访问，增加的推理时间计算会持续降低模型的鲁棒性。","title":"推理时间扩展的鲁棒性与安全风险"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='最近，Zaremba等人展示了增加推理时间计算可以提高大型专有推理大语言模型的鲁棒性。本文首先表明，小规模的开源模型（如DeepSeek R1、Qwen3、Phi-reasoning）也可以通过简单的预算强制策略受益于推理时间的扩展。更重要的是，我们揭示并批判性地审视了先前工作的一个隐含假设：中间推理步骤对对手是隐藏的。通过放宽这一假设，我们识别出一个重要的安全风险，即反向缩放法则：如果中间推理步骤变得显式可访问，增加的推理时间计算会持续降低模型的鲁棒性。', title='推理时间扩展的鲁棒性与安全风险'))
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#3d", "#games", "#optimization", "#cv"], "emoji": "🧠", "ru": {"title": "Объектно-ориентированная 3D-реконструкция с семантическим пониманием", "desc": "ObjectGS - это новый подход к 3D-реконструкции сцен, объединяющий геометрическое моделирование с семантическим пониманием. Метод ис
[23.07.2025 04:44] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#survey", "#interpretability", "#reasoning"], "emoji": "🔍", "ru": {"title": "SPAR: Умный поиск научной литературы с помощью ИИ", "desc": "SPAR - это мультиагентная система для поиска научной литературы, использующая большие языковые модели. Она применяет дек
[23.07.2025 04:44] Renaming data file.
[23.07.2025 04:44] Renaming previous data. hf_papers.json to ./d/2025-07-23.json
[23.07.2025 04:44] Saving new data file.
[23.07.2025 04:44] Generating page.
[23.07.2025 04:44] Renaming previous page.
[23.07.2025 04:44] Renaming previous data. index.html to ./d/2025-07-23.html
[23.07.2025 04:44] Writing result.
[23.07.2025 04:44] Renaming log file.
[23.07.2025 04:44] Renaming previous data. log.txt to ./logs/2025-07-23_last_log.txt
