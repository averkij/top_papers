[05.03.2025 07:10] Read previous papers.
[05.03.2025 07:10] Generating top page (month).
[05.03.2025 07:10] Writing top page (month).
[05.03.2025 08:14] Read previous papers.
[05.03.2025 08:14] Get feed.
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02682
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02846
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02879
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01935
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01328
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.14856
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.00955
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02197
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02878
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01342
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02268
[05.03.2025 08:14] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02876
[05.03.2025 08:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.03.2025 08:14] No deleted papers detected.
[05.03.2025 08:14] Downloading and parsing papers (pdf, html). Total: 12.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.02682.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.02682.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.02682.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.02846.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.02846.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.02846.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.02879.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.02879.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.02879.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.01935.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.01935.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.01935.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.01328.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.01328.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.01328.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2502.14856.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2502.14856.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2502.14856.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.00955.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.00955.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.00955.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.02197.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.02197.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.02197.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.02878.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.02878.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.02878.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.01342.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.01342.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.01342.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.02268.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.02268.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.02268.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Downloading and parsing paper https://huggingface.co/papers/2503.02876.
[05.03.2025 08:14] Extra JSON file exists (./assets/json/2503.02876.json), skip PDF parsing.
[05.03.2025 08:14] Paper image links file exists (./assets/img_data/2503.02876.json), skip HTML parsing.
[05.03.2025 08:14] Success.
[05.03.2025 08:14] Enriching papers with extra data.
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 0. Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges,...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 1. Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains. Since hallucinations always come with truthful content in the LLM responses, previous factuality alignment methods that conduct response-level preferenc...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 2. In this paper, we present a thorough analysis of the impact of Large Language Models (LLMs) on Wikipedia, examining the evolution of Wikipedia through existing data and using simulations to explore potential risks. We begin by analyzing page views and article content to study Wikipedia's recent chan...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 3. Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 4. Pipeline parallelism (PP) is widely used for training large language models (LLMs), yet its scalability is often constrained by high activation memory consumption as the number of in-flight microbatches grows with the degree of PP. In this paper, we focus on addressing this challenge by leveraging t...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 5. Speculative sampling has emerged as an important technique for accelerating the auto-regressive generation process of large language models (LLMs) by utilizing a draft-then-verify mechanism to produce multiple tokens per forward pass. While state-of-the-art speculative sampling methods use only a si...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 6. The rise of misinformation, exacerbated by Large Language Models (LLMs) like GPT and Gemini, demands robust fact-checking solutions, especially for low-resource languages like Vietnamese. Existing methods struggle with semantic ambiguity, homonyms, and complex linguistic structures, often trading ac...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 7. Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks. Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories. However, behavior-cloning of full trajectories can introduce expert bias and we...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 8. Collecting ground truth task completion rewards or human demonstrations for multi-step reasoning tasks is often cost-prohibitive and time-consuming, especially in interactive domains like web tasks. To address this bottleneck, we present self-taught lookahead, a self-supervised method that leverages...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 9. Generalist models have achieved remarkable success in both language and vision-language tasks, showcasing the potential of unified modeling. However, effectively integrating fine-grained perception tasks like detection and segmentation into these models remains a significant challenge. This is prima...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 10. Recent advancements in Large Language Models (LLMs) have led to the development of intelligent LLM-based agents capable of interacting with graphical user interfaces (GUIs). These agents demonstrate strong reasoning and adaptability, enabling them to perform complex tasks that traditionally required...
[05.03.2025 08:14] ********************************************************************************
[05.03.2025 08:14] Abstract 11. Advancing AI in computational pathology requires large, high-quality, and diverse datasets, yet existing public datasets are often limited in organ diversity, class coverage, or annotation quality. To bridge this gap, we introduce SPIDER (Supervised Pathology Image-DEscription Repository), the large...
[05.03.2025 08:14] Read previous papers.
[05.03.2025 08:14] Generating reviews via LLM API.
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#rl", "#training", "#optimization", "#hallucinations", "#agents"], "emoji": "🧠", "ru": {"title": "Метапланы для умных агентов: эффективнее, универсальнее, без галлюцинаций", "desc": "Статья представляет новый подход к улучшению планирования задач агентами на основе больших языковых 
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#hallucinations", "#training", "#rlhf", "#alignment"], "emoji": "🎭", "ru": {"title": "Mask-DPO: точная настройка фактов в ответах языковых моделей", "desc": "Эта статья представляет метод Mask-DPO для улучшения фактической точности больших языковых моделей (LLM). Метод основан на оп
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#rag", "#benchmark", "#machine_translation", "#dataset", "#multimodal", "#science", "#data"], "emoji": "🧠", "ru": {"title": "Большие языковые модели меняют лицо Википедии: анализ влияния и потенциальных рисков", "desc": "Эта статья представляет анализ влияния больших языковых моделе
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#games", "#optimization", "#open_source", "#benchmark", "#agents"], "emoji": "🤖", "ru": {"title": "MultiAgentBench: новый стандарт для оценки мультиагентных LLM-систем", "desc": "Статья представляет MultiAgentBench - комплексный бенчмарк для оценки мультиагентных систем на основе бо
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#open_source", "#inference", "#optimization", "#training"], "emoji": "🚀", "ru": {"title": "Оптимизация памяти для масштабирования больших языковых моделей", "desc": "Статья посвящена улучшению масштабируемости конвейерного параллелизма при обучении больших языковых моделей. Авторы п
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization"], "emoji": "🚀", "ru": {"title": "Быстрее и эффективнее: оптимизация спекулятивной выборки для LLM", "desc": "Статья представляет FR-Spec - новый метод спекулятивной выборки для ускорения работы больших языковых моделей (LLM). Метод оптимизир
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#multilingual", "#inference", "#benchmark", "#low_resource", "#dataset", "#science", "#data"], "emoji": "🕵️", "ru": {"title": "SemViQA: Передовая система проверки фактов для борьбы с дезинформацией на вьетнамском языке", "desc": "SemViQA - это новая система проверки фактов на вьетна
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#training", "#agents", "#agi"], "emoji": "🎯", "ru": {"title": "ATLaS: точечная настройка LLM-агентов для улучшения обобщения", "desc": "ATLaS - это новый метод настройки агентов на основе больших языковых моделей (LLM). Он фокусируется на обучении толь
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Самообучение для эффективного поиска без дорогостоящих демонстраций", "desc": "Статья представляет метод 'self-taught lookahead' для обучения модели оценки, способной эффективно направлять поиск, управ
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#cv", "#training", "#optimization", "#agi", "#open_source", "#multimodal", "#architecture"], "emoji": "🔬", "ru": {"title": "Унификация задач компьютерного зрения через языковой интерфейс", "desc": "Статья представляет новый фреймворк для унификации задач тонкой визуальной перцепции 
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#optimization", "#agents", "#benchmark", "#reasoning", "#open_source", "#training"], "emoji": "🧠", "ru": {"title": "Эволюционное обучение агентов GUI: баланс эффективности и гибкости", "desc": "Эта статья представляет новый эволюционный подход для агентов, работающих с графическим и
[05.03.2025 08:14] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#multimodal", "#science", "#benchmark"], "emoji": "🕷️", "ru": {"title": "SPIDER: Новый стандарт данных для ИИ в патологии", "desc": "Статья представляет SPIDER - крупнейший общедоступный набор данных для вычислительной патологии, охватывающий множество ти
[05.03.2025 08:14] Loading Chinese text from previous data.
[05.03.2025 08:14] Renaming data file.
[05.03.2025 08:14] Renaming previous data. hf_papers.json to ./d/2025-03-05.json
[05.03.2025 08:14] Saving new data file.
[05.03.2025 08:14] Generating page.
[05.03.2025 08:14] Renaming previous page.
[05.03.2025 08:14] Renaming previous data. index.html to ./d/2025-03-05.html
[05.03.2025 08:14] [Experimental] Generating Chinese page for reading.
[05.03.2025 08:14] Chinese vocab [{'word': '视觉强化微调', 'pinyin': 'shìjué qiángzhù wēitiáo', 'trans': 'visual reinforcement fine-tuning'}, {'word': '大型视觉-语言模型', 'pinyin': 'dàxíng shìjué-yǔyán móxíng', 'trans': 'large vision-language models'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generate'}, {'word': '可验证的', 'pinyin': 'kě yànzhèng de', 'trans': 'verifiable'}, {'word': '奖励函数', 'pinyin': 'jiǎnglì hánshù', 'trans': 'reward function'}, {'word': '更新', 'pinyin': 'gēngxīn', 'trans': 'update'}, {'word': '实验结果', 'pinyin': 'shíyàn jiéguǒ', 'trans': 'experimental results'}, {'word': '出色', 'pinyin': 'chūsè', 'trans': 'outstanding'}, {'word': '优于', 'pinyin': 'yōu yú', 'trans': 'superior to'}, {'word': '监督微调', 'pinyin': 'jiàndū wēitiáo', 'trans': 'supervised fine-tuning'}, {'word': '细粒度', 'pinyin': 'xì lìdù', 'trans': 'fine-grained'}, {'word': '图像分类', 'pinyin': 'túxiàng fēnlèi', 'trans': 'image classification'}, {'word': '准确率', 'pinyin': 'zhǔnquèlǜ', 'trans': 'accuracy'}]
[05.03.2025 08:14] Renaming previous Chinese page.
[05.03.2025 08:14] Renaming previous data. zh.html to ./d/2025-03-04_zh_reading_task.html
[05.03.2025 08:14] Writing Chinese reading task.
[05.03.2025 08:14] Writing result.
[05.03.2025 08:14] Renaming log file.
[05.03.2025 08:14] Renaming previous data. log.txt to ./logs/2025-03-05_last_log.txt
