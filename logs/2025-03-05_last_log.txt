[05.03.2025 00:48] Read previous papers.
[05.03.2025 00:48] Generating top page (month).
[05.03.2025 00:48] Writing top page (month).
[05.03.2025 02:16] Read previous papers.
[05.03.2025 02:16] Get feed.
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01785
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01743
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01774
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01183
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18965
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01688
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18890
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01307
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01496
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.00714
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.00501
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.00031
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.00784
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01506
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01370
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.00455
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01714
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01295
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01807
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19402
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01063
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01739
[05.03.2025 02:16] Extract page data from URL. URL: https://huggingface.co/papers/2503.01820
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01103
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16779
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2503.00729
[05.03.2025 02:16] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20383
[05.03.2025 02:16] Extract page data from URL. URL: https://huggingface.co/papers/2503.02379
[05.03.2025 02:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.03.2025 02:16] No deleted papers detected.
[05.03.2025 02:16] Downloading and parsing papers (pdf, html). Total: 28.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01785.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01785.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01785.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01743.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01743.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01743.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01774.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01774.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01774.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01183.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01183.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01183.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2502.18965.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2502.18965.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2502.18965.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01688.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01688.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01688.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2502.18890.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2502.18890.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2502.18890.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01307.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01307.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01307.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01496.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01496.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01496.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.00714.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.00714.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.00714.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.00501.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.00501.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.00501.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.00031.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.00031.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.00031.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.00784.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.00784.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.00784.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01506.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01506.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01506.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01370.
[05.03.2025 02:16] Downloading paper 2503.01370 from http://arxiv.org/pdf/2503.01370v1...
[05.03.2025 02:16] Failed to download and parse paper https://huggingface.co/papers/2503.01370: max() arg is an empty sequence
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.00455.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.00455.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.00455.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01714.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01714.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01714.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01295.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01295.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01295.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01807.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01807.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01807.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2502.19402.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2502.19402.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2502.19402.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01063.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01063.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01063.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01739.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01739.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01739.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01820.
[05.03.2025 02:16] Downloading paper 2503.01820 from http://arxiv.org/pdf/2503.01820v1...
[05.03.2025 02:16] Extracting affiliations from text.
[05.03.2025 02:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RSQ: Learning from Important Tokens Leads to Better Quantized LLMs Yi-Lin Sung 1 Prateek Yadav 1 Jialu Li 1 Jaehong Yoon 1 Mohit Bansal 1 5 2 0 2 3 ] . [ 1 0 2 8 1 0 . 3 0 5 2 : r a "
[05.03.2025 02:16] Response: []
[05.03.2025 02:16] Extracting affiliations from text.
[05.03.2025 02:16] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RSQ: Learning from Important Tokens Leads to Better Quantized LLMs Yi-Lin Sung 1 Prateek Yadav 1 Jialu Li 1 Jaehong Yoon 1 Mohit Bansal 1 5 2 0 2 3 ] . [ 1 0 2 8 1 0 . 3 0 5 2 : r aLayer-wise quantization is key technique for efficiently compressing large models without expensive retraining. Previous methods typically quantize the weights of each layer by uniformly optimizing the layer reconstruction loss across all output tokens. However, in this paper, we demonstrate that better-quantized models can be obtained by prioritizing learning from important tokens (e.g. which have large attention scores). Building on this finding, we propose RSQ (Rotate, Scale, then Quantize), which (1) applies rotations (orthogonal transformation) to the model to mitigate outliers (those with exceptionally large magnitude), (2) scales the token feature based on its importance, and (3) quantizes the model using the GPTQ framework with the second-order statistics computed by scaled tokens. To compute token importance, we explore both heuristic and dynamic strategies. Based on thorough analysis of all approaches, we adopt attention concentration, which uses attention scores of each token as its importance, as the best approach. We demonstrate that RSQ consistently outperforms baseline methods across multiple downstream tasks and three model families: LLaMA3, Mistral, and Qwen2.5. Additionally, models quantized with RSQ achieve superior performance on long-context tasks, further highlighting its effectiveness. Lastly, RSQ demonstrates generalizability across various setups, including different model sizes, calibration datasets, bit precisions, and quantization methods. Our code is available at https://github.com/ylsung/rsq. 1. Introduction Large language models (LLMs) (Georgiev et al., 2024; Achiam et al., 2023) have recently achieved great success and have transformed the landscape of artificial intelligence. 1Department of Computer Science, UNC at Chapel Hill. Correspondence to: Yi-Lin Sung <ylsung@cs.unc.edu>. However, the substantial computational demands associated with these models pose significant challenges to their usage and deployment, especially in resource-constrained scenarios. Weight quantization (Han et al., 2016; Wu et al., 2016) is widely used technique for reducing the computational costs of LLMs by representing weight values with fewer bits. Among various approaches, post-training quantization (PTQ) (Frantar & Alistarh, 2022; Liu et al., 2021) is particularly favored by practitioners, as it enables the quantization of pre-trained LLMs using only small calibration dataset, eliminating the need for expensive retraining. We focus on the layer-wise post-training quantization scheme (Hubara et al., 2020; Li et al., 2021; Frantar et al., 2023) that has been demonstrated to be both effective and efficient for quantizing large models. Layer-wise quantization methods quantize an LLMs weights one layer at time by minimizing the token-level feature distance between the outputs of the original and quantized weights (i.e., the layer reconstruction loss, WX WX2 2). Several advancements have been made to improve layer-wise quantization techniques in the past few years. For example, GPTQ (Frantar et al., 2023) improves the efficiency and stability to compute second-order statistics and their inverses. QuIP# (Tseng et al., 2024) and AQLM (Egiazarian et al., 2024) represent quantized weights with vectors rather than fixed scalars. Additionally, QuIP (Chee et al., 2023) and QuaRot (Ashkboos et al., 2024b) demonstrate through empirical studies that weight outliersparameters with unusually large magnitudescan be effectively mitigated by applying orthogonal transformations. Previous methods commonly perform layer-wise weight quantization by optimizing the layer reconstruction loss across all input tokens uniformly. However, research has shown that LLMs do not treat all tokens equally: (1) StreamingLLM (Xiao et al., 2024) shows that initial tokens often have strong attention scores, (2) H2O (Zhang et al., 2023) reveals that some tokens in KV cache contribute most of the attention values while decoding, and (3) RHO-1 (Lin et al., 2024c) demonstrates not all tokens are equal in training LLMs. Since quantized models inherently lose information due to the reduced capacity of lower bit representations, we argue that it should be particularly crucial RSQ: Learning from Important Tokens Leads to Better Quantized LLMs for them to focus on learning and preserving the most critical information during the quantization process to maximize their performance. Inspired by these insights, we reconsider the conventional approach in quantization methods by optimizing the layer reconstruction loss over only subset of important input tokens (i.e., using only the first 1/4 of the tokens). Our findings reveal that this strategy improves the quantized models accuracy across ten downstream tasks by up to 2.2%. Building on our findings and previous approaches, we propose RSQ to quantize the model in three steps: (1) rotate (orthogonally transform) the model to mitigate weight outliers, (2) scale the token feature based on its importance, and (3) quantize the weights using the GPTQ mechanism while leveraging token importance. We note that the token importance integrates seamlessly into the GPTQ framework in the third step, ensuring both compatibility and efficiency. Fig. 1 illustrates the three steps in RSQ. In this paper, we explore two categories of approaches for obtaining token importance: (1) heuristic approaches and (2) dynamic approaches. Within the heuristic category, we investigate methods such as First-N and First&Last-N, which prioritize initial tokens and combination of initial and final tokens for quantization, respectively. These approaches outperform the conventional quantization method of optimizing across all tokens, achieving peak performance when is roughly 510% of the total tokens. It is important to note that the initial or final tokens do not inherently contain more meaningful semantic information. Instead, their importance likely stems from their positional characteristics and their tendency to receive stronger attention scores (Xiao et al., 2024; Sun et al., 2024a). In this aforementioned approach, token importance was determined solely based on heuristics (e.g., token positions). To further improve performance beyond heuristic methods, we also explore several dynamic approaches for computing token importanc"
[05.03.2025 02:16] Mistral response. {"id": "cb789d0105954f899eb4aec5426d77df", "object": "chat.completion", "created": 1741141006, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Department of Computer Science, UNC at Chapel Hill\"]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1617, "total_tokens": 1637, "completion_tokens": 20}}
[05.03.2025 02:16] Response: ```python
["Department of Computer Science, UNC at Chapel Hill"]
```
[05.03.2025 02:16] Deleting PDF ./assets/pdf/2503.01820.pdf.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.01103.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.01103.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.01103.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2502.16779.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2502.16779.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2502.16779.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.00729.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2503.00729.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2503.00729.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2502.20383.
[05.03.2025 02:16] Extra JSON file exists (./assets/json/2502.20383.json), skip PDF parsing.
[05.03.2025 02:16] Paper image links file exists (./assets/img_data/2502.20383.json), skip HTML parsing.
[05.03.2025 02:16] Success.
[05.03.2025 02:16] Downloading and parsing paper https://huggingface.co/papers/2503.02379.
[05.03.2025 02:16] Downloading paper 2503.02379 from http://arxiv.org/pdf/2503.02379v1...
[05.03.2025 02:16] Extracting affiliations from text.
[05.03.2025 02:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Jiwan Chung Saejin Kim Yongrae Jo Jaewoo Park Dongjun Min Youngjae Yu Yonsei University LG AI Research jiwan.chung.research@gmail.com 5 2 0 2 M 4 ] . [ 1 9 7 3 2 0 . 3 0 5 2 : r a "
[05.03.2025 02:16] Response: ```python
["Yonsei University", "LG AI Research"]
```
[05.03.2025 02:16] Deleting PDF ./assets/pdf/2503.02379.pdf.
[05.03.2025 02:17] Success.
[05.03.2025 02:17] Enriching papers with extra data.
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 0. Reinforcement Fine-Tuning (RFT) in Large Reasoning Models like OpenAI o1 learns from feedback on its answers, which is especially useful in applications when fine-tuning data is scarce. Recent open-source work like DeepSeek-R1 demonstrates that reinforcement learning with verifiable reward is one ke...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 1. We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality web and synthetic data, significantly outperforming recent open-source models of similar size and matching the perform...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 2. Neural Radiance Fields and 3D Gaussian Splatting have revolutionized 3D reconstruction and novel-view synthesis task. However, achieving photorealistic rendering from extreme novel viewpoints remains challenging, as artifacts persist across representations. In this work, we introduce Difix3D+, a nov...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 3. Recent advancements in music generation have garnered significant attention, yet existing approaches face critical limitations. Some current generative models can only synthesize either the vocal track or the accompaniment track. While some models can generate combined vocal and accompaniment, they ...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 4. Recently, generative retrieval-based recommendation systems have emerged as a promising paradigm. However, most modern recommender systems adopt a retrieve-and-rank strategy, where the generative model functions only as a selector during the retrieval stage. In this paper, we propose OneRec, which r...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 5. Uncertainty estimation is crucial for evaluating Large Language Models (LLMs), particularly in high-stakes domains where incorrect answers result in significant consequences. Numerous approaches consider this problem, while focusing on a specific type of uncertainty, ignoring others. We investigate ...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 6. Generating ultra-long sequences with large language models (LLMs) has become increasingly crucial but remains a highly time-intensive task, particularly for sequences up to 100K tokens. While traditional speculative decoding methods exist, simply extending their generation limits fails to accelerate...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 7. Test-time inference has emerged as a powerful paradigm for enabling language models to ``think'' longer and more carefully about complex challenges, much like skilled human experts. While reinforcement learning (RL) can drive self-improvement in language models on verifiable tasks, some models exhib...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 8. Transformers with linear recurrent modeling offer linear-time training and constant-memory inference. Despite their demonstrated efficiency and performance, pretraining such non-standard architectures from scratch remains costly and risky. The linearization of large language models (LLMs) transforms...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 9. Analyzing large datasets requires responsive query execution, but executing SQL queries on massive datasets can be slow. This paper explores whether query execution can begin even before the user has finished typing, allowing results to appear almost instantly. We propose SpeQL, a system that levera...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 10. User-generated content (UGC) communities, especially those featuring multimodal content, improve user experiences by integrating visual and textual information into results (or items). The challenge of improving user experiences in complex systems with search and recommendation (S\&R) services has d...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 11. Increasing test-time computation is a straightforward approach to enhancing the quality of responses in Large Language Models (LLMs). While Best-of-N sampling and Self-Consistency with majority voting are simple and effective, they require a fixed number of sampling responses for each query, regardl...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 12. Large language models (LLMs) exhibit exceptional performance across a wide range of tasks; however, their token-by-token autoregressive generation process significantly hinders inference speed. Speculative decoding presents a promising draft-then-verify framework that reduces generation latency whil...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 13. Existing pretraining data mixing methods for large language models (LLMs) typically follow a domain-wise methodology, a top-down process that first determines domain weights and then performs uniform data sampling across each domain. However, these approaches neglect significant inter-domain overlap...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 14. Diffusion models have achieved great success in generating 2D images. However, the quality and generalizability of 3D content generation remain limited. State-of-the-art methods often require large-scale 3D assets for training, which are challenging to collect. In this work, we introduce Kiss3DGen (...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 15. Existing Existing automatic audio generation methods struggle to generate podcast-like audio programs effectively. The key challenges lie in in-depth content generation, appropriate and expressive voice production. This paper proposed PodAgent, a comprehensive framework for creating audio programs. ...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 16. Human readers can efficiently comprehend scrambled words, a phenomenon known as Typoglycemia, primarily by relying on word form; if word form alone is insufficient, they further utilize contextual cues for interpretation. While advanced large language models (LLMs) exhibit similar abilities, the und...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 17. Large Language Models (LLMs) have reshaped code generation by synergizing their exceptional comprehension of natural language and programming syntax, thereby substantially boosting developer productivity. These advancements have prompted numerous efforts to quantitatively evaluate their coding capab...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 18. Selecting high-quality training data from a larger pool is a crucial step when instruction-tuning language models, as carefully curated datasets often produce models that outperform those trained on much larger, noisier datasets. Automated data selection approaches for instruction-tuning are typical...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 19. Large Language Models (LLMs) have demonstrated impressive real-world utility, exemplifying artificial useful intelligence (AUI). However, their ability to reason adaptively and robustly -- the hallmarks of artificial general intelligence (AGI) -- remains fragile. While LLMs seemingly succeed in comm...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 20. This paper investigates the potential for large language models (LLMs) to develop private tonal languages for machine-to-machine (M2M) communication. Inspired by cryptophasia in human twins (affecting up to 50% of twin births) and natural tonal languages like Mandarin and Vietnamese, we implement a ...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 21. Text-to-video generative models convert textual prompts into dynamic visual content, offering wide-ranging applications in film production, gaming, and education. However, their real-world performance often falls short of user expectations. One key reason is that these models have not been trained o...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 22. Layer-wise quantization is a key technique for efficiently compressing large models without expensive retraining. Previous methods typically quantize the weights of each layer by "uniformly" optimizing the layer reconstruction loss across all output tokens. However, in this paper, we demonstrate tha...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 23. While likelihood-based generative models, particularly diffusion and autoregressive models, have achieved remarkable fidelity in visual generation, the maximum likelihood estimation (MLE) objective inherently suffers from a mode-covering tendency that limits the generation quality under limited mode...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 24. Room layout estimation from multiple-perspective images is poorly investigated due to the complexities that emerge from multi-view geometry, which requires muti-step solutions such as camera intrinsic and extrinsic estimation, image matching, and triangulation. However, in 3D reconstruction, the adv...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 25. Large Language Models (LLMs) exhibit remarkable capabilities in the hierarchical decomposition of complex tasks through semantic reasoning. However, their application in embodied systems faces challenges in ensuring reliable execution of subtask sequences and achieving one-shot success in long-term ...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 26. Recent advancements in Web AI agents have demonstrated remarkable capabilities in addressing complex web navigation tasks. However, emerging research shows that these agents exhibit greater vulnerability compared to standalone Large Language Models (LLMs), despite both being built upon the same safe...
[05.03.2025 02:17] ********************************************************************************
[05.03.2025 02:17] Abstract 27. As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregr...
[05.03.2025 02:17] Read previous papers.
[05.03.2025 02:17] Generating reviews via LLM API.
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#multimodal", "#open_source", "#cv", "#optimization", "#rlhf", "#reasoning", "#training", "#rl"], "emoji": "🔬", "ru": {"title": "Visual-RFT: Революция в тонкой настройке визуально-языковых моделей", "desc": "Статья представляет Visual Reinforcement Fine-Tuning (Visual-RFT) - метод, 
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#multimodal", "#small_models", "#data", "#agi", "#synthetic", "#long_context", "#optimization", "#dataset", "#training"], "emoji": "🧠", "ru": {"title": "Компактные модели с большими возможностями: прорыв в эффективности ИИ", "desc": "Представлены две новые модели: Phi-4-Mini и Phi-4
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#3d", "#diffusion"], "emoji": "🖼️", "ru": {"title": "Одношаговая диффузия для фотореалистичной 3D-реконструкции", "desc": "Difix3D+ - это новый подход к улучшению 3D-реконструкции и синтеза изображений с новых ракурсов. В его основе лежит Difix - одношаговая модель диффузии изображе
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#diffusion", "#inference", "#dataset", "#open_source", "#audio"], "emoji": "🎵", "ru": {"title": "DiffRhythm: Быстрая генерация полных песен с помощью латентной диффузии", "desc": "DiffRhythm - это первая модель генерации песен на основе латентной диффузии, способная синтезировать по
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#alignment", "#rlhf", "#rag", "#games", "#training", "#optimization"], "emoji": "🎥", "ru": {"title": "OneRec: Единая генеративная модель для революции в рекомендательных системах", "desc": "OneRec - это новая система рекомендаций, использующая единую генеративную модель вместо каска
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#ethics", "#hallucinations", "#benchmark", "#reasoning", "#data", "#multilingual"], "emoji": "🤖", "ru": {"title": "Энтропия ответов как индикатор неопределенности LLM в задачах с множественным выбором", "desc": "Исследование посвящено оценке неопределенности в крупных языковых модел
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#training", "#architecture", "#long_context", "#inference", "#optimization"], "emoji": "⚡", "ru": {"title": "TOKENSWIFT: революция в скорости генерации сверхдлинных текстов", "desc": "Исследователи представили TOKENSWIFT - новую систему для ускорения генерации сверхдлинных последова
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "Когнитивные навыки - ключ к самосовершенствованию языковых моделей", "desc": "Исследование показывает, что способность языковых моделей к самосовершенствованию зависит от наличия у них определенных ког
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization", "#benchmark"], "emoji": "🔢", "ru": {"title": "Эффективная линеаризация больших языковых моделей", "desc": "Данная статья представляет новый метод Liger для линеаризации больших языковых моделей (LLM) в гейтированные линейно-рекуррентные 
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#dataset", "#data", "#benchmark"], "emoji": "⚡", "ru": {"title": "Молниеносные SQL-запросы с помощью предиктивной аналитики", "desc": "Статья представляет систему SpeQL, использующую большие языковые модели для предсказания SQL-запросов пользователя. SpeQL предугадывает структуру за
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#multimodal", "#dataset", "#rag"], "emoji": "🔍", "ru": {"title": "Qilin: мультимодальный датасет для улучшения поиска и рекомендаций", "desc": "Представлен новый набор данных Qilin для мультимодального информационного поиска, собранный на платформе Xiaohongshu. Датасет включает поль
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "🎯", "ru": {"title": "Повышение эффективности LLM через калибровку уверенности", "desc": "Это исследование предлагает метод Self-Calibration для улучшения эффективности крупных языковых моделей (LLM) при тестировании. Метод основа
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#inference", "#training", "#optimization"], "emoji": "🚀", "ru": {"title": "DuoDecoding: Параллельное ускорение языковых моделей", "desc": "Статья представляет новый метод ускорения генерации текста большими языковыми моделями (LLM) под названием DuoDecoding. Этот подход использует п
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#transfer_learning", "#training", "#optimization", "#data"], "emoji": "🔀", "ru": {"title": "SampleMix: революция в смешивании данных для LLM", "desc": "В статье представлен новый подход к смешиванию предобучающих данных для больших языковых моделей (LLM), названный SampleMix. В отли
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#3d"], "emoji": "🎨", "ru": {"title": "Простая и эффективная 3D-генерация на основе 2D-диффузии", "desc": "Статья представляет Kiss3DGen - эффективный фреймворк для генерации, редактирования и улучшения 3D-объектов с использованием предобученной модели диффузии д
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#games", "#audio", "#interpretability", "#benchmark", "#optimization", "#multimodal"], "emoji": "🎙️", "ru": {"title": "PodAgent: ИИ-ведущий для подкастов нового поколения", "desc": "PodAgent - это новая система для автоматического создания аудиопрограмм в стиле подкастов. Она исполь
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#training", "#interpretability", "#data", "#multimodal", "#alignment"], "emoji": "🔀", "ru": {"title": "Форма слова - ключ к пониманию перемешанного текста для ИИ", "desc": "Исследование посвящено способности больших языковых моделей (LLM) понимать перемешанные слова, подобно людям. 
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#leakage", "#open_source"], "emoji": "🏟️", "ru": {"title": "CodeArena: Справедливая арена для оценки LLM в генерации кода", "desc": "CodeArena - это новая онлайн-платформа для оценки генерации кода большими языковыми моделями (LLM). Она использует коллектив
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#data", "#open_source", "#optimization", "#dataset", "#training"], "emoji": "🔍", "ru": {"title": "Эффективный отбор данных для обучения языковых моделей: меньше значит больше", "desc": "Эта статья исследует методы автоматического отбора данных для инструктивной настройки языковых мо
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#agi", "#transfer_learning", "#architecture", "#rl", "#synthetic", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Отделяя рассуждения от знаний: путь к AGI", "desc": "Статья рассматривает ограничения больших языковых моделей (LLM) в области обобщенного рассуждения, несмо
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#security", "#ethics", "#audio", "#multimodal"], "emoji": "🎵", "ru": {"title": "Тональные языки: секретный код машин будущего", "desc": "Это исследование изучает потенциал больших языковых моделей (LLM) для разработки приватных тональных языков для коммуникации между машинами. Автор
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#video", "#dataset", "#data", "#games", "#open_source"], "emoji": "🎬", "ru": {"title": "VideoUFO: Новый эталонный датасет для генерации видео по запросу", "desc": "Статья представляет VideoUFO - новый набор данных для обучения моделей генерации видео по текстовому описанию. Этот дат
[05.03.2025 02:17] Querying the API.
[05.03.2025 02:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Layer-wise quantization is a key technique for efficiently compressing large models without expensive retraining. Previous methods typically quantize the weights of each layer by "uniformly" optimizing the layer reconstruction loss across all output tokens. However, in this paper, we demonstrate that better-quantized models can be obtained by prioritizing learning from important tokens (e.g. which have large attention scores). Building on this finding, we propose RSQ (Rotate, Scale, then Quantize), which (1) applies rotations (orthogonal transformation) to the model to mitigate outliers (those with exceptionally large magnitude), (2) scales the token feature based on its importance, and (3) quantizes the model using the GPTQ framework with the second-order statistics computed by scaled tokens. To compute token importance, we explore both heuristic and dynamic strategies. Based on a thorough analysis of all approaches, we adopt attention concentration, which uses attention scores of each token as its importance, as the best approach. We demonstrate that RSQ consistently outperforms baseline methods across multiple downstream tasks and three model families: LLaMA3, Mistral, and Qwen2.5. Additionally, models quantized with RSQ achieve superior performance on long-context tasks, further highlighting its effectiveness. Lastly, RSQ demonstrates generalizability across various setups, including different model sizes, calibration datasets, bit precisions, and quantization methods.
[05.03.2025 02:17] Response: {
  "desc": "Статья представляет новый метод квантования нейронных сетей под названием RSQ (Rotate, Scale, then Quantize). Метод применяет ортогональные преобразования для уменьшения выбросов, масштабирует признаки токенов на основе их важности и использует фреймворк GPTQ для квантования. RSQ показывает лучшие результаты по сравнению с базовыми методами на различных задачах и моделях, включая LLaMA3, Mistral и Qwen2.5. Метод также демонстрирует эффективность на задачах с длинным контекстом и обобщаемость на разные конфигурации.",
  "emoji": "🔢",
  "title": "RSQ: Умное квантование для эффективного сжатия больших языковых моделей"
}
[05.03.2025 02:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Layer-wise quantization is a key technique for efficiently compressing large models without expensive retraining. Previous methods typically quantize the weights of each layer by "uniformly" optimizing the layer reconstruction loss across all output tokens. However, in this paper, we demonstrate that better-quantized models can be obtained by prioritizing learning from important tokens (e.g. which have large attention scores). Building on this finding, we propose RSQ (Rotate, Scale, then Quantize), which (1) applies rotations (orthogonal transformation) to the model to mitigate outliers (those with exceptionally large magnitude), (2) scales the token feature based on its importance, and (3) quantizes the model using the GPTQ framework with the second-order statistics computed by scaled tokens. To compute token importance, we explore both heuristic and dynamic strategies. Based on a thorough analysis of all approaches, we adopt attention concentration, which uses attention scores of each token as its importance, as the best approach. We demonstrate that RSQ consistently outperforms baseline methods across multiple downstream tasks and three model families: LLaMA3, Mistral, and Qwen2.5. Additionally, models quantized with RSQ achieve superior performance on long-context tasks, further highlighting its effectiveness. Lastly, RSQ demonstrates generalizability across various setups, including different model sizes, calibration datasets, bit precisions, and quantization methods."

[05.03.2025 02:17] Response: ```python
["INFERENCE", "TRAINING"]
```
[05.03.2025 02:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Layer-wise quantization is a key technique for efficiently compressing large models without expensive retraining. Previous methods typically quantize the weights of each layer by "uniformly" optimizing the layer reconstruction loss across all output tokens. However, in this paper, we demonstrate that better-quantized models can be obtained by prioritizing learning from important tokens (e.g. which have large attention scores). Building on this finding, we propose RSQ (Rotate, Scale, then Quantize), which (1) applies rotations (orthogonal transformation) to the model to mitigate outliers (those with exceptionally large magnitude), (2) scales the token feature based on its importance, and (3) quantizes the model using the GPTQ framework with the second-order statistics computed by scaled tokens. To compute token importance, we explore both heuristic and dynamic strategies. Based on a thorough analysis of all approaches, we adopt attention concentration, which uses attention scores of each token as its importance, as the best approach. We demonstrate that RSQ consistently outperforms baseline methods across multiple downstream tasks and three model families: LLaMA3, Mistral, and Qwen2.5. Additionally, models quantized with RSQ achieve superior performance on long-context tasks, further highlighting its effectiveness. Lastly, RSQ demonstrates generalizability across various setups, including different model sizes, calibration datasets, bit precisions, and quantization methods."

[05.03.2025 02:17] Response: ```python
["OPTIMIZATION", "LONG_CONTEXT"]
```
[05.03.2025 02:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a novel method called RSQ for quantizing large machine learning models efficiently. Unlike traditional methods that optimize layer reconstruction loss uniformly, RSQ focuses on important tokens identified by their attention scores to improve model performance. The process involves rotating the model to handle outliers, scaling token features based on their importance, and applying quantization using the GPTQ framework. The results show that RSQ outperforms existing methods across various tasks and model families, especially in long-context scenarios, demonstrating its versatility and effectiveness.","title":"Prioritizing Important Tokens for Better Model Quantization"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a novel method called RSQ for quantizing large machine learning models efficiently. Unlike traditional methods that optimize layer reconstruction loss uniformly, RSQ focuses on important tokens identified by their attention scores to improve model performance. The process involves rotating the model to handle outliers, scaling token features based on their importance, and applying quantization using the GPTQ framework. The results show that RSQ outperforms existing methods across various tasks and model families, especially in long-context scenarios, demonstrating its versatility and effectiveness.', title='Prioritizing Important Tokens for Better Model Quantization'))
[05.03.2025 02:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"层级量化是一种有效压缩大型模型的技术，无需昂贵的重新训练。以往的方法通常通过均匀优化层重建损失来量化每层的权重，但我们发现优先学习重要的标记（例如，具有较大注意力分数的标记）可以获得更好的量化模型。我们提出的RSQ方法通过旋转、缩放和量化的步骤，改善了模型的量化效果，并在多个下游任务中超越了基线方法。RSQ在长上下文任务中表现优异，且在不同模型规模和量化方法中具有良好的通用性。","title":"优先学习重要标记，实现高效量化"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='层级量化是一种有效压缩大型模型的技术，无需昂贵的重新训练。以往的方法通常通过均匀优化层重建损失来量化每层的权重，但我们发现优先学习重要的标记（例如，具有较大注意力分数的标记）可以获得更好的量化模型。我们提出的RSQ方法通过旋转、缩放和量化的步骤，改善了模型的量化效果，并在多个下游任务中超越了基线方法。RSQ在长上下文任务中表现优异，且在不同模型规模和量化方法中具有良好的通用性。', title='优先学习重要标记，实现高效量化'))
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#training", "#diffusion", "#cv", "#optimization"], "emoji": "🚀", "ru": {"title": "DDO: Прорыв в обучении генеративных моделей без ограничений MLE", "desc": "Авторы статьи предлагают новый метод обучения генеративных моделей под названием Direct Discriminative Optimization (DDO). Это
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#3d", "#optimization", "#cv", "#synthetic"], "emoji": "🏠", "ru": {"title": "Революция в оценке планировки помещений: от множества шагов к единому решению", "desc": "Статья представляет Plane-DUSt3R - новый метод для оценки планировки помещений по множественным ракурсам изображений. 
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#open_source", "#robotics", "#agents", "#optimization"], "emoji": "🤖", "ru": {"title": "CLEA: Повышение надежности выполнения задач роботами с помощью языковых моделей", "desc": "Статья представляет новую архитектуру под названием CLEA (Closed-Loop Emb
[05.03.2025 02:17] Using data from previous issue: {"categories": ["#benchmark", "#security", "#agents"], "emoji": "🕸️", "ru": {"title": "Раскрытие уязвимостей веб-агентов ИИ: путь к более безопасным системам", "desc": "Исследование показывает, что веб-агенты на основе искусственного интеллекта более уязвимы, чем автономные большие языковые модели (
[05.03.2025 02:17] Querying the API.
[05.03.2025 02:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregressive discrete models by leveraging predefined distance relationships among output tokens. At its core, DIST2Loss transforms continuous exponential family distributions derived from inherent distance metrics into discrete, categorical optimization targets compatible with the models' architectures. This approach enables the models to learn and preserve meaningful distance relationships during token generation while maintaining compatibility with existing architectures. Empirical evaluations show consistent performance gains in diverse multimodal applications, including visual grounding, robotic manipulation, generative reward modeling, and image generation using vector-quantized features. These improvements are pronounced in cases of limited training data, highlighting DIST2Loss's effectiveness in resource-constrained settings.
[05.03.2025 02:17] Response: {
  "desc": "Статья представляет DIST2Loss - новый подход к обучению авторегрессионных дискретных моделей, учитывающий метрические отношения между токенами. DIST2Loss преобразует непрерывные распределения экспоненциального семейства в дискретные оптимизационные цели, совместимые с архитектурами моделей. Этот метод позволяет моделям сохранять значимые метрические отношения при генерации токенов. Эмпирические оценки показывают улучшение производительности в различных мультимодальных задачах, особенно при ограниченных обучающих данных.",
  "emoji": "📏",
  "title": "DIST2Loss: Сохраняя метрику в дискретном пространстве"
}
[05.03.2025 02:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregressive discrete models by leveraging predefined distance relationships among output tokens. At its core, DIST2Loss transforms continuous exponential family distributions derived from inherent distance metrics into discrete, categorical optimization targets compatible with the models' architectures. This approach enables the models to learn and preserve meaningful distance relationships during token generation while maintaining compatibility with existing architectures. Empirical evaluations show consistent performance gains in diverse multimodal applications, including visual grounding, robotic manipulation, generative reward modeling, and image generation using vector-quantized features. These improvements are pronounced in cases of limited training data, highlighting DIST2Loss's effectiveness in resource-constrained settings."

[05.03.2025 02:17] Response: ```python
["MULTIMODAL", "AGENTS", "CV", "ROBOTICS", "TRAINING"]
```
[05.03.2025 02:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregressive discrete models by leveraging predefined distance relationships among output tokens. At its core, DIST2Loss transforms continuous exponential family distributions derived from inherent distance metrics into discrete, categorical optimization targets compatible with the models' architectures. This approach enables the models to learn and preserve meaningful distance relationships during token generation while maintaining compatibility with existing architectures. Empirical evaluations show consistent performance gains in diverse multimodal applications, including visual grounding, robotic manipulation, generative reward modeling, and image generation using vector-quantized features. These improvements are pronounced in cases of limited training data, highlighting DIST2Loss's effectiveness in resource-constrained settings."

[05.03.2025 02:17] Response: ```python
["OPTIMIZATION", "LOW_RESOURCE"]
```
[05.03.2025 02:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents DIST2Loss, a novel framework that enhances the training of autoregressive discrete models by incorporating distance relationships among output tokens. By transforming continuous distributions based on these distances into discrete targets, the framework allows models to generate tokens that maintain meaningful metric relationships. This method is particularly beneficial in multimodal applications, such as visual grounding and robotic manipulation, where understanding the spatial or contextual distance between elements is crucial. The results demonstrate that DIST2Loss significantly improves model performance, especially when training data is limited, making it a valuable tool in resource-constrained environments.","title":"Enhancing Token Generation with Distance Awareness"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents DIST2Loss, a novel framework that enhances the training of autoregressive discrete models by incorporating distance relationships among output tokens. By transforming continuous distributions based on these distances into discrete targets, the framework allows models to generate tokens that maintain meaningful metric relationships. This method is particularly beneficial in multimodal applications, such as visual grounding and robotic manipulation, where understanding the spatial or contextual distance between elements is crucial. The results demonstrate that DIST2Loss significantly improves model performance, especially when training data is limited, making it a valuable tool in resource-constrained environments.', title='Enhancing Token Generation with Distance Awareness'))
[05.03.2025 02:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"随着大型语言模型的应用扩展到数学、多模态理解和具身智能体等领域，模型中的标记越来越反映度量关系，而不仅仅是语言意义。我们提出了DIST2Loss，这是一种距离感知框架，旨在通过利用输出标记之间的预定义距离关系来训练自回归离散模型。DIST2Loss的核心是将基于固有距离度量的连续指数族分布转化为与模型架构兼容的离散分类优化目标。实证评估显示，在视觉定位、机器人操作、生成奖励建模和使用向量量化特征的图像生成等多种多模态应用中，DIST2Loss都能带来一致的性能提升，尤其在训练数据有限的情况下效果更为显著。","title":"利用距离关系提升模型性能的创新方法"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='随着大型语言模型的应用扩展到数学、多模态理解和具身智能体等领域，模型中的标记越来越反映度量关系，而不仅仅是语言意义。我们提出了DIST2Loss，这是一种距离感知框架，旨在通过利用输出标记之间的预定义距离关系来训练自回归离散模型。DIST2Loss的核心是将基于固有距离度量的连续指数族分布转化为与模型架构兼容的离散分类优化目标。实证评估显示，在视觉定位、机器人操作、生成奖励建模和使用向量量化特征的图像生成等多种多模态应用中，DIST2Loss都能带来一致的性能提升，尤其在训练数据有限的情况下效果更为显著。', title='利用距离关系提升模型性能的创新方法'))
[05.03.2025 02:17] Loading Chinese text from previous data.
[05.03.2025 02:17] Renaming data file.
[05.03.2025 02:17] Renaming previous data. hf_papers.json to ./d/2025-03-05.json
[05.03.2025 02:17] Saving new data file.
[05.03.2025 02:17] Generating page.
[05.03.2025 02:17] Renaming previous page.
[05.03.2025 02:17] Renaming previous data. index.html to ./d/2025-03-05.html
[05.03.2025 02:17] [Experimental] Generating Chinese page for reading.
[05.03.2025 02:17] Chinese vocab [{'word': '视觉强化微调', 'pinyin': 'shìjué qiángzhù wēitiáo', 'trans': 'visual reinforcement fine-tuning'}, {'word': '大型视觉-语言模型', 'pinyin': 'dàxíng shìjué-yǔyán móxíng', 'trans': 'large vision-language models'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generate'}, {'word': '可验证的', 'pinyin': 'kě yànzhèng de', 'trans': 'verifiable'}, {'word': '奖励函数', 'pinyin': 'jiǎnglì hánshù', 'trans': 'reward function'}, {'word': '更新', 'pinyin': 'gēngxīn', 'trans': 'update'}, {'word': '实验结果', 'pinyin': 'shíyàn jiéguǒ', 'trans': 'experimental results'}, {'word': '出色', 'pinyin': 'chūsè', 'trans': 'outstanding'}, {'word': '优于', 'pinyin': 'yōu yú', 'trans': 'superior to'}, {'word': '监督微调', 'pinyin': 'jiàndū wēitiáo', 'trans': 'supervised fine-tuning'}, {'word': '细粒度', 'pinyin': 'xì lìdù', 'trans': 'fine-grained'}, {'word': '图像分类', 'pinyin': 'túxiàng fēnlèi', 'trans': 'image classification'}, {'word': '准确率', 'pinyin': 'zhǔnquèlǜ', 'trans': 'accuracy'}]
[05.03.2025 02:17] Renaming previous Chinese page.
[05.03.2025 02:17] Renaming previous data. zh.html to ./d/2025-03-04_zh_reading_task.html
[05.03.2025 02:17] Writing Chinese reading task.
[05.03.2025 02:17] Writing result.
[05.03.2025 02:17] Renaming log file.
[05.03.2025 02:17] Renaming previous data. log.txt to ./logs/2025-03-05_last_log.txt
