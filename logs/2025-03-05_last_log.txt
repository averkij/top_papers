[05.03.2025 04:13] Read previous papers.
[05.03.2025 04:13] Generating top page (month).
[05.03.2025 04:13] Writing top page (month).
[05.03.2025 05:10] Read previous papers.
[05.03.2025 05:10] Get feed.
[05.03.2025 05:10] Extract page data from URL. URL: https://huggingface.co/papers/2503.02846
[05.03.2025 05:10] Extract page data from URL. URL: https://huggingface.co/papers/2503.02682
[05.03.2025 05:10] Extract page data from URL. URL: https://huggingface.co/papers/2503.02879
[05.03.2025 05:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01935
[05.03.2025 05:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01328
[05.03.2025 05:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02878
[05.03.2025 05:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02197
[05.03.2025 05:10] Extract page data from URL. URL: https://huggingface.co/papers/2503.00955
[05.03.2025 05:10] Extract page data from URL. URL: https://huggingface.co/papers/2503.01342
[05.03.2025 05:10] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02876
[05.03.2025 05:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.03.2025 05:10] No deleted papers detected.
[05.03.2025 05:10] Downloading and parsing papers (pdf, html). Total: 10.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.02846.
[05.03.2025 05:10] Extra JSON file exists (./assets/json/2503.02846.json), skip PDF parsing.
[05.03.2025 05:10] Paper image links file exists (./assets/img_data/2503.02846.json), skip HTML parsing.
[05.03.2025 05:10] Success.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.02682.
[05.03.2025 05:10] Extra JSON file exists (./assets/json/2503.02682.json), skip PDF parsing.
[05.03.2025 05:10] Paper image links file exists (./assets/img_data/2503.02682.json), skip HTML parsing.
[05.03.2025 05:10] Success.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.02879.
[05.03.2025 05:10] Extra JSON file exists (./assets/json/2503.02879.json), skip PDF parsing.
[05.03.2025 05:10] Paper image links file exists (./assets/img_data/2503.02879.json), skip HTML parsing.
[05.03.2025 05:10] Success.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.01935.
[05.03.2025 05:10] Extra JSON file exists (./assets/json/2503.01935.json), skip PDF parsing.
[05.03.2025 05:10] Paper image links file exists (./assets/img_data/2503.01935.json), skip HTML parsing.
[05.03.2025 05:10] Success.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.01328.
[05.03.2025 05:10] Extra JSON file exists (./assets/json/2503.01328.json), skip PDF parsing.
[05.03.2025 05:10] Paper image links file exists (./assets/img_data/2503.01328.json), skip HTML parsing.
[05.03.2025 05:10] Success.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.02878.
[05.03.2025 05:10] Extra JSON file exists (./assets/json/2503.02878.json), skip PDF parsing.
[05.03.2025 05:10] Paper image links file exists (./assets/img_data/2503.02878.json), skip HTML parsing.
[05.03.2025 05:10] Success.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.02197.
[05.03.2025 05:10] Extra JSON file exists (./assets/json/2503.02197.json), skip PDF parsing.
[05.03.2025 05:10] Paper image links file exists (./assets/img_data/2503.02197.json), skip HTML parsing.
[05.03.2025 05:10] Success.
[05.03.2025 05:10] Downloading and parsing paper https://huggingface.co/papers/2503.00955.
[05.03.2025 05:10] Downloading paper 2503.00955 from http://arxiv.org/pdf/2503.00955v1...
[05.03.2025 05:10] Extracting affiliations from text.
[05.03.2025 05:10] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 ] . [ 1 5 5 9 0 0 . 3 0 5 2 : r SemViQA: Semantic Question Answering System for Vietnamese Information Fact-Checking Nam V. Nguyen1,2,*, Dien X. Tran2,*, Thanh T. Tran2, Anh T. Hoang2,4, Tai V. Duong2, Di T. Le2, Phuc-Lu Le3 1FPT Software AI Center, Viet Nam 2Faculty of Information Technology, Industrial University of Ho Chi Minh City, Viet Nam 3Faculty of Information Technology, University of Science, VNU-HCM, Viet Nam 4FPT Telecom, Viet Nam Correspondence: lplu@fit.hcmus.edu.vn "
[05.03.2025 05:10] Response: ```python
[
    "FPT Software AI Center, Viet Nam",
    "Faculty of Information Technology, Industrial University of Ho Chi Minh City, Viet Nam",
    "Faculty of Information Technology, University of Science, VNU-HCM, Viet Nam",
    "FPT Telecom, Viet Nam"
]
```
[05.03.2025 05:10] Deleting PDF ./assets/pdf/2503.00955.pdf.
[05.03.2025 05:11] Success.
[05.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2503.01342.
[05.03.2025 05:11] Downloading paper 2503.01342 from http://arxiv.org/pdf/2503.01342v2...
[05.03.2025 05:11] Extracting affiliations from text.
[05.03.2025 05:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"UFO: Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface Hao Tang1,2 Chenwei Xie2 Haiyang Wang1 Xiaoyi Bao2,3 Pandeng Li2 Yun Zheng2 Liwei Wang1 Tingyu Weng2 5 2 0 2 M 4 ] . [ 2 2 4 3 1 0 . 3 0 5 2 : r 1Center for Data Science, Peking University 2Alibaba Group 3Institute of Automation, Chinese Academy of Sciences {tanghao@stu, wanghaiyang@stu, wanglw@cis}.pku.edu.cn baoxiaoyi2021@ia.ac.cn {eniac.xcw, wengtingyu.wty, lipandeng.lpd, zhengyun.zy}@alibaba-inc.com "
[05.03.2025 05:11] Response: ```python
[
    "Center for Data Science, Peking University",
    "Alibaba Group",
    "Institute of Automation, Chinese Academy of Sciences"
]
```
[05.03.2025 05:11] Deleting PDF ./assets/pdf/2503.01342.pdf.
[05.03.2025 05:11] Success.
[05.03.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2503.02876.
[05.03.2025 05:11] Extra JSON file exists (./assets/json/2503.02876.json), skip PDF parsing.
[05.03.2025 05:11] Paper image links file exists (./assets/img_data/2503.02876.json), skip HTML parsing.
[05.03.2025 05:11] Success.
[05.03.2025 05:11] Enriching papers with extra data.
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 0. Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains. Since hallucinations always come with truthful content in the LLM responses, previous factuality alignment methods that conduct response-level preferenc...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 1. Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges,...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 2. In this paper, we present a thorough analysis of the impact of Large Language Models (LLMs) on Wikipedia, examining the evolution of Wikipedia through existing data and using simulations to explore potential risks. We begin by analyzing page views and article content to study Wikipedia's recent chan...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 3. Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 4. Pipeline parallelism (PP) is widely used for training large language models (LLMs), yet its scalability is often constrained by high activation memory consumption as the number of in-flight microbatches grows with the degree of PP. In this paper, we focus on addressing this challenge by leveraging t...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 5. Collecting ground truth task completion rewards or human demonstrations for multi-step reasoning tasks is often cost-prohibitive and time-consuming, especially in interactive domains like web tasks. To address this bottleneck, we present self-taught lookahead, a self-supervised method that leverages...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 6. Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks. Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories. However, behavior-cloning of full trajectories can introduce expert bias and we...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 7. The rise of misinformation, exacerbated by Large Language Models (LLMs) like GPT and Gemini, demands robust fact-checking solutions, especially for low-resource languages like Vietnamese. Existing methods struggle with semantic ambiguity, homonyms, and complex linguistic structures, often trading ac...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 8. Generalist models have achieved remarkable success in both language and vision-language tasks, showcasing the potential of unified modeling. However, effectively integrating fine-grained perception tasks like detection and segmentation into these models remains a significant challenge. This is prima...
[05.03.2025 05:11] ********************************************************************************
[05.03.2025 05:11] Abstract 9. Advancing AI in computational pathology requires large, high-quality, and diverse datasets, yet existing public datasets are often limited in organ diversity, class coverage, or annotation quality. To bridge this gap, we introduce SPIDER (Supervised Pathology Image-DEscription Repository), the large...
[05.03.2025 05:11] Read previous papers.
[05.03.2025 05:11] Generating reviews via LLM API.
[05.03.2025 05:11] Querying the API.
[05.03.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains. Since hallucinations always come with truthful content in the LLM responses, previous factuality alignment methods that conduct response-level preference learning inevitably introduced noises during training. Therefore, this paper proposes a fine-grained factuality alignment method based on Direct Preference Optimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as mask signals, Mask-DPO only learns from factually correct sentences in the preferred samples and prevents the penalty on factual contents in the not preferred samples, which resolves the ambiguity in the preference learning. Extensive experimental results demonstrate that Mask-DPO can significantly improve the factuality of LLMs responses to questions from both in-domain and out-of-domain datasets, although these questions and their corresponding topics are unseen during training. Only trained on the ANAH train set, the score of Llama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%, even surpassing the score of Llama3.1-70B-Instruct (53.44%), while its FactScore on the out-of-domain Biography dataset is also improved from 30.29% to 39.39%. We further study the generalization property of Mask-DPO using different training sample scaling strategies and find that scaling the number of topics in the dataset is more effective than the number of questions. We provide a hypothesis of what factual alignment is doing with LLMs, on the implication of this phenomenon, and conduct proof-of-concept experiments to verify it. We hope the method and the findings pave the way for future research on scaling factuality alignment.
[05.03.2025 05:11] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[05.03.2025 05:11] Querying the API.
[05.03.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges, we propose the Meta Plan Optimization (MPO) framework, which enhances agent planning capabilities by directly incorporating explicit guidance. Unlike previous methods that rely on complex knowledge, which either require significant human effort or lack quality assurance, MPO leverages high-level general guidance through meta plans to assist agent planning and enables continuous optimization of the meta plans based on feedback from the agent's task execution. Our experiments conducted on two representative tasks demonstrate that MPO significantly outperforms existing baselines. Moreover, our analysis indicates that MPO provides a plug-and-play solution that enhances both task completion efficiency and generalization capabilities in previous unseen scenarios.
[05.03.2025 05:11] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[05.03.2025 05:11] Querying the API.
[05.03.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

In this paper, we present a thorough analysis of the impact of Large Language Models (LLMs) on Wikipedia, examining the evolution of Wikipedia through existing data and using simulations to explore potential risks. We begin by analyzing page views and article content to study Wikipedia's recent changes and assess the impact of LLMs. Subsequently, we evaluate how LLMs affect various Natural Language Processing (NLP) tasks related to Wikipedia, including machine translation and retrieval-augmented generation (RAG). Our findings and simulation results reveal that Wikipedia articles have been influenced by LLMs, with an impact of approximately 1%-2% in certain categories. If the machine translation benchmark based on Wikipedia is influenced by LLMs, the scores of the models may become inflated, and the comparative results among models might shift as well. Moreover, the effectiveness of RAG might decrease if the knowledge base becomes polluted by LLM-generated content. While LLMs have not yet fully changed Wikipedia's language and knowledge structures, we believe that our empirical findings signal the need for careful consideration of potential future risks.
[05.03.2025 05:11] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[05.03.2025 05:11] Using data from previous issue: {"categories": ["#games", "#optimization", "#open_source", "#benchmark", "#agents"], "emoji": "🤖", "ru": {"title": "MultiAgentBench: новый стандарт для оценки мультиагентных LLM-систем", "desc": "Статья представляет MultiAgentBench - комплексный бенчмарк для оценки мультиагентных систем на основе бо
[05.03.2025 05:11] Using data from previous issue: {"categories": ["#open_source", "#inference", "#optimization", "#training"], "emoji": "🚀", "ru": {"title": "Оптимизация памяти для масштабирования больших языковых моделей", "desc": "Статья посвящена улучшению масштабируемости конвейерного параллелизма при обучении больших языковых моделей. Авторы п
[05.03.2025 05:11] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Самообучение для эффективного поиска без дорогостоящих демонстраций", "desc": "Статья представляет метод 'self-taught lookahead' для обучения модели оценки, способной эффективно направлять поиск, управ
[05.03.2025 05:11] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#training", "#agents", "#agi"], "emoji": "🎯", "ru": {"title": "ATLaS: точечная настройка LLM-агентов для улучшения обобщения", "desc": "ATLaS - это новый метод настройки агентов на основе больших языковых моделей (LLM). Он фокусируется на обучении толь
[05.03.2025 05:11] Querying the API.
[05.03.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The rise of misinformation, exacerbated by Large Language Models (LLMs) like GPT and Gemini, demands robust fact-checking solutions, especially for low-resource languages like Vietnamese. Existing methods struggle with semantic ambiguity, homonyms, and complex linguistic structures, often trading accuracy for efficiency. We introduce SemViQA, a novel Vietnamese fact-checking framework integrating Semantic-based Evidence Retrieval (SER) and Two-step Verdict Classification (TVC). Our approach balances precision and speed, achieving state-of-the-art results with 78.97\% strict accuracy on ISE-DSC01 and 80.82\% on ViWikiFC, securing 1st place in the UIT Data Science Challenge. Additionally, SemViQA Faster improves inference speed 7x while maintaining competitive accuracy. SemViQA sets a new benchmark for Vietnamese fact verification, advancing the fight against misinformation. The source code is available at: https://github.com/DAVID-NGUYEN-S16/SemViQA.
[05.03.2025 05:11] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[05.03.2025 05:11] Querying the API.
[05.03.2025 05:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Generalist models have achieved remarkable success in both language and vision-language tasks, showcasing the potential of unified modeling. However, effectively integrating fine-grained perception tasks like detection and segmentation into these models remains a significant challenge. This is primarily because these tasks often rely heavily on task-specific designs and architectures that can complicate the modeling process. To address this challenge, we present \ours, a framework that Unifies Fine-grained visual perception tasks through an Open-ended language interface. By transforming all perception targets into the language space, \ours unifies object-level detection, pixel-level segmentation, and image-level vision-language tasks into a single model. Additionally, we introduce a novel embedding retrieval approach that relies solely on the language interface to support segmentation tasks. Our framework bridges the gap between fine-grained perception and vision-language tasks, significantly simplifying architectural design and training strategies while achieving comparable or superior performance to methods with intricate task-specific designs. After multi-task training on five standard visual perception datasets, \ours outperforms the previous state-of-the-art generalist models by 12.3 mAP on COCO instance segmentation and 3.3 mIoU on ADE20K semantic segmentation. Furthermore, our method seamlessly integrates with existing MLLMs, effectively combining fine-grained perception capabilities with their advanced language abilities, thereby enabling more challenging tasks such as reasoning segmentation. Code and models will be publicly available.
[05.03.2025 05:11] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[05.03.2025 05:11] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#multimodal", "#science", "#benchmark"], "emoji": "🕷️", "ru": {"title": "SPIDER: Новый стандарт данных для ИИ в патологии", "desc": "Статья представляет SPIDER - крупнейший общедоступный набор данных для вычислительной патологии, охватывающий множество ти
[05.03.2025 05:11] Loading Chinese text from previous data.
[05.03.2025 05:11] Renaming data file.
[05.03.2025 05:11] Renaming previous data. hf_papers.json to ./d/2025-03-05.json
[05.03.2025 05:11] Saving new data file.
[05.03.2025 05:11] Generating page.
[05.03.2025 05:11] Renaming previous page.
[05.03.2025 05:11] Renaming previous data. index.html to ./d/2025-03-05.html
[05.03.2025 05:11] [Experimental] Generating Chinese page for reading.
[05.03.2025 05:11] Chinese vocab [{'word': '视觉强化微调', 'pinyin': 'shìjué qiángzhù wēitiáo', 'trans': 'visual reinforcement fine-tuning'}, {'word': '大型视觉-语言模型', 'pinyin': 'dàxíng shìjué-yǔyán móxíng', 'trans': 'large vision-language models'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generate'}, {'word': '可验证的', 'pinyin': 'kě yànzhèng de', 'trans': 'verifiable'}, {'word': '奖励函数', 'pinyin': 'jiǎnglì hánshù', 'trans': 'reward function'}, {'word': '更新', 'pinyin': 'gēngxīn', 'trans': 'update'}, {'word': '实验结果', 'pinyin': 'shíyàn jiéguǒ', 'trans': 'experimental results'}, {'word': '出色', 'pinyin': 'chūsè', 'trans': 'outstanding'}, {'word': '优于', 'pinyin': 'yōu yú', 'trans': 'superior to'}, {'word': '监督微调', 'pinyin': 'jiàndū wēitiáo', 'trans': 'supervised fine-tuning'}, {'word': '细粒度', 'pinyin': 'xì lìdù', 'trans': 'fine-grained'}, {'word': '图像分类', 'pinyin': 'túxiàng fēnlèi', 'trans': 'image classification'}, {'word': '准确率', 'pinyin': 'zhǔnquèlǜ', 'trans': 'accuracy'}]
[05.03.2025 05:11] Renaming previous Chinese page.
[05.03.2025 05:11] Renaming previous data. zh.html to ./d/2025-03-04_zh_reading_task.html
[05.03.2025 05:11] Writing Chinese reading task.
[05.03.2025 05:11] Writing result.
[05.03.2025 05:11] Renaming log file.
[05.03.2025 05:11] Renaming previous data. log.txt to ./logs/2025-03-05_last_log.txt
