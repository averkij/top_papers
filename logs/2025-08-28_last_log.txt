[27.08.2025 23:11] Read previous papers.
[27.08.2025 23:11] Generating top page (month).
[27.08.2025 23:11] Writing top page (month).
[28.08.2025 00:52] Read previous papers.
[28.08.2025 00:52] Get feed.
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17445
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18124
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19205
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19247
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19209
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17661
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18756
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17437
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15774
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19242
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18621
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18579
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19188
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15804
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18773
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18672
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19026
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18271
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18370
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15213
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16697
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19202
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18192
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17621
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18921
[28.08.2025 00:52] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17234
[28.08.2025 00:52] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.08.2025 00:52] No deleted papers detected.
[28.08.2025 00:52] Downloading and parsing papers (pdf, html). Total: 26.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.17445.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.17445.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.17445.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18124.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18124.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18124.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.19205.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.19205.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.19205.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.19247.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.19247.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.19247.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.19209.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.19209.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.19209.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.17661.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.17661.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.17661.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18756.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18756.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18756.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.17437.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.17437.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.17437.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.15774.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.15774.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.15774.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.19242.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.19242.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.19242.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18621.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18621.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18621.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18579.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18579.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18579.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.19188.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.19188.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.19188.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.15804.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.15804.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.15804.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18773.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18773.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18773.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18672.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18672.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18672.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.19026.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.19026.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.19026.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18271.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18271.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18271.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18370.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18370.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18370.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.15213.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.15213.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.15213.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.16697.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.16697.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.16697.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.19202.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.19202.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.19202.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18192.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18192.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18192.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.17621.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.17621.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.17621.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.18921.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.18921.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.18921.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Downloading and parsing paper https://huggingface.co/papers/2508.17234.
[28.08.2025 00:52] Extra JSON file exists (./assets/json/2508.17234.json), skip PDF parsing.
[28.08.2025 00:52] Paper image links file exists (./assets/img_data/2508.17234.json), skip HTML parsing.
[28.08.2025 00:52] Success.
[28.08.2025 00:52] Enriching papers with extra data.
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 0. TreePO, a self-guided rollout algorithm for sequence generation, reduces computational cost and enhances exploration diversity in reinforcement learning for large language models.  					AI-generated summary 				 Recent advancements in aligning large language models via reinforcement learning have ac...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 1. CMPhysBench evaluates LLMs in condensed matter physics using calculation problems and a new SEED score for partial credit assessment, revealing significant capability gaps.  					AI-generated summary 				 We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 2. VibeVoice synthesizes long-form multi-speaker speech using next-token diffusion and a highly efficient continuous speech tokenizer, achieving superior performance and fidelity.  					AI-generated summary 				 This report presents VibeVoice, a novel model designed to synthesize long-form speech with ...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 3. VoxHammer is a training-free method that performs precise and coherent 3D editing in latent space, ensuring consistency in preserved regions and high-quality overall results.  					AI-generated summary 				 3D local editing of specified regions is crucial for game industry and robot interaction. Rec...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 4. A framework using Multimodal Large Language Models and a specialized Multimodal DiT architecture generates semantically coherent and expressive character animations from multimodal inputs.  					AI-generated summary 				 Existing video avatar models can produce fluid human animations, yet they strug...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 5. Spacer, a scientific discovery system, uses deliberate decontextualization to generate creative and factually grounded scientific concepts from keyword sets, achieving high accuracy and similarity to leading publications.  					AI-generated summary 				 Recent advances in LLMs have made automated sc...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 6. UltraMemV2, a redesigned memory-layer architecture, achieves performance parity with 8-expert MoE models while significantly reducing memory access costs.  					AI-generated summary 				 While Mixture of Experts (MoE) models achieve remarkable efficiency by activating only subsets of parameters, the...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 7. PIXIE, a neural network method, predicts physical properties of 3D scenes from visual features, enabling fast and realistic physics simulation using supervised learning and pretrained visual features.  					AI-generated summary 				 Inferring the physical properties of 3D scenes from visual informat...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 8. CineScale is a novel inference paradigm that enables high-resolution visual generation for both images and videos without extensive fine-tuning, addressing issues of repetitive patterns and high-frequency information accumulation.  					AI-generated summary 				 Visual diffusion models achieve remar...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 9. AUSM, an autoregressive universal segmentation model, unifies prompted and unprompted video segmentation by treating it as sequential mask prediction, achieving superior performance and faster training on standard benchmarks.  					AI-generated summary 				 Recent video foundation models such as SAM...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 10. Wan-S2V, an audio-driven model built on Wan, enhances expressiveness and fidelity in cinematic character animation compared to existing methods.  					AI-generated summary 				 Current state-of-the-art (SOTA) methods for audio-driven character animation demonstrate promising performance for scenario...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 11. DrugReasoner, a reasoning-based large language model fine-tuned with GRPO, predicts small-molecule approval with high accuracy and interpretability, outperforming conventional methods and enhancing transparency in drug discovery.  					AI-generated summary 				 Drug discovery is a complex and resour...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 12. A framework for efficient artistic mesh generation reduces redundancy by separating vertex and face generation, using an autoregressive model for vertices and a bidirectional transformer for faces, and includes a fidelity enhancer and post-processing to improve quality and speed.  					AI-generated ...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 13. ReportBench evaluates the content quality of research reports generated by large language models, focusing on cited literature quality and statement faithfulness, demonstrating that commercial Deep Research agents produce more comprehensive and reliable reports than standalone LLMs.  					AI-generat...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 14. ThinkDial is an open-source framework that implements controllable reasoning in large language models through discrete operational modes, achieving performance while reducing computational effort.  					AI-generated summary 				 Large language models (LLMs) with chain-of-thought reasoning have demon...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 15. MoE models introduce sparsity that affects memorization and reasoning capabilities differently in large language models, with reasoning performance potentially regressing despite increased parameters.  					AI-generated summary 				 Empirical scaling laws have driven the evolution of large language ...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 16. MovieCORE is a video question answering dataset that uses multiple large language models to generate deep cognitive questions, and introduces an agentic enhancement module to improve VQA model performance.  					AI-generated summary 				 This paper introduces MovieCORE, a novel video question answer...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 17. ObjFiller-3D uses video editing models to achieve high-quality and consistent 3D object completion, outperforming previous methods in terms of reconstruction fidelity and practical deployment.  					AI-generated summary 				 3D inpainting often relies on multi-view 2D image inpainting, where the inh...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 18. CTF-Dojo, a large-scale executable runtime with 658 CTF challenges, enables rapid training of LLM-based agents with verifiable feedback, achieving state-of-the-art performance in competitive benchmarks.  					AI-generated summary 				 Large language models (LLMs) have demonstrated exceptional capabi...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 19. Selct2Know (S2K) enhances domain-specific QA by progressively internalizing and selecting knowledge through a cost-effective framework, outperforming existing methods with lower costs.  					AI-generated summary 				 Large Language Models (LLMs) perform well in general QA but often struggle in domai...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 20. QueryBandits, a bandit framework, effectively mitigates hallucinations in LLMs by proactively rewriting queries based on linguistic features, outperforming static prompting strategies.  					AI-generated summary 				 Advanced reasoning capabilities in Large Language Models (LLMs) have caused higher ...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 21. SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for ...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 22. A network-based framework links cognitive skills, LLM architectures, and datasets, revealing unique emergent skill patterns in LLMs that benefit from dynamic, cross-regional interactions.  					AI-generated summary 				 Large Language Models (LLMs) have reshaped our world with significant advancemen...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 23. The Flexible Activation Steering with Backtracking (FASB) framework dynamically adjusts the intervention strength and necessity in large language models during generation to align with desired behaviors, outperforming existing methods.  					AI-generated summary 				 Large language models (LLMs) hav...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 24. Deep neural networks, including 1D CNNs and LSTMs, provide accurate distributional forecasts of financial returns, outperforming classical GARCH models in Value-at-Risk estimation.  					AI-generated summary 				 This study evaluates deep neural networks for forecasting probability distributions of ...
[28.08.2025 00:52] ********************************************************************************
[28.08.2025 00:52] Abstract 25. The paper addresses the generation of legal claims for non-professionals using datasets and evaluation metrics, highlighting the limitations of current models in factual precision and clarity.  					AI-generated summary 				 Legal claims refer to the plaintiff's demands in a case and are essential t...
[28.08.2025 00:52] Read previous papers.
[28.08.2025 00:52] Generating reviews via LLM API.
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#training", "#rl", "#rlhf"], "emoji": "üå≥", "ru": {"title": "TreePO: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç TreePO - –∞–ª–≥–æ—Ä–∏—Ç–º —Å–∞–º–æ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –±
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#benchmark", "#science", "#dataset"], "emoji": "üî¨", "ru": {"title": "–ù–æ–≤—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –ò–ò: —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á –ø–æ —Ñ–∏–∑–∏–∫–µ –∫–æ–Ω–¥–µ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è", "desc": "CMPhysBench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–∑–∏–∫–∏ –∫–æ–Ω–¥–µ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#diffusion", "#audio"], "emoji": "üó£Ô∏è", "ru": {"title": "VibeVoice: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–∏–Ω—Ç–µ–∑–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –º–Ω–æ–≥–æ–≥–æ–ª–æ—Å–æ–π —Ä–µ—á–∏", "desc": "VibeVoice - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –º–Ω–æ–≥–æ–≥–æ–ª–æ—Å–æ–π —Ä–µ—á–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—é —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#games", "#dataset", "#synthetic", "#3d"], "emoji": "üî®", "ru": {"title": "–¢–æ—á–Ω–æ–µ 3D-—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤", "desc": "VoxHammer - —ç—Ç–æ –º–µ—Ç–æ–¥ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è 3D-–º–æ–¥–µ–ª–µ–π –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ç–æ—á–Ω–æ–µ –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#optimization", "#games", "#multimodal", "#video"], "emoji": "üé≠", "ru": {"title": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ò–ò", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å OmniHuman-1.5 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∏–º–∞—Ü–∏–∏ –ø–µ
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#science", "#data", "#multimodal", "#dataset"], "emoji": "üß¨", "ru": {"title": "Spacer: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç–∏—è—Ö", "desc": "Spacer - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞—É—á–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –Ω–∞–º–µ—Ä–µ–Ω–Ω—É—é –¥–µ–∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã—Ö –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "UltraMemV2: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å MoE –±–µ–∑ –≤—ã—Å–æ–∫–∏—Ö –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –ø–∞–º—è—Ç—å", "desc": "UltraMemV2 - —ç—Ç–æ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–ª–æ—è –ø–∞–º—è—Ç–∏ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, –∫–æ—Ç–æ—Ä–∞—è –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ 8-—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö 
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#inference", "#synthetic", "#3d"], "emoji": "üß†", "ru": {"title": "–ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ 3D-—Å—Ü–µ–Ω —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π", "desc": "PIXIE - —ç—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ 3D-—Å—Ü–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö 
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#inference", "#cv", "#video"], "emoji": "üé¨", "ru": {"title": "CineScale: –ü—Ä–æ—Ä—ã–≤ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "CineScale - —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ –≤—ã–≤–æ–¥–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤–∏–¥–µ–æ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –±–µ–∑ 
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#training", "#video", "#optimization"], "emoji": "üé¨", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–æ–∫", "desc": "AUSM - —ç—Ç–æ –º–æ–¥–µ–ª—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤–∏–¥–µ–æ, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø–æ–¥—Ö–æ–¥—ã —Å –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏ –∏ –±–µ–∑ –Ω–∏—Ö. –û–Ω–∞ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#story_generation", "#audio", "#games", "#benchmark", "#video"], "emoji": "üé≠", "ru": {"title": "Wan-S2V: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–Ω–∏–º–∞—Ü–∏–∏ –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—É–¥–∏–æ", "desc": "–ú–æ–¥–µ–ª—å Wan-S2V, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞—É–¥–∏–æ, —É–ª—É—á—à–∞–µ—Ç –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ç–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∏–º–∞—Ü–∏–∏ –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#training", "#interpretability", "#architecture", "#healthcare", "#reasoning", "#science"], "emoji": "üíä", "ru": {"title": "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π –ò–ò –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–æ–±—Ä–µ–Ω–∏—è –ª–µ–∫–∞—Ä—Å—Ç–≤", "desc": "DrugReasoner - —ç—Ç–æ —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ LLaMA –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è —Å –ø–æ–º–æ—â—å
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "üé®", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 3D-–º–æ–¥–µ–ª–µ–π: —Ä–∞–∑–¥–µ–ª—è–π –∏ –≤–ª–∞—Å—Ç–≤—É–π", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö 3D-–º–æ–¥–µ–ª–µ–π, —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è –ø—Ä–æ—Ü–µ—Å—Å—ã —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ—Ä—à–∏–Ω –∏ –≥—Ä–∞–Ω–µ–π. –î–ª—è –≤–µ—Ä—à–∏–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#survey", "#agents", "#open_source"], "emoji": "üî¨", "ru": {"title": "ReportBench: –Ω–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ AI-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π", "desc": "ReportBench - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ 
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#training", "#optimization", "#reasoning", "#agi", "#rl"], "emoji": "üß†", "ru": {"title": "ThinkDial: –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "ThinkDial - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#architecture", "#training", "#open_source"], "emoji": "üß†", "ru": {"title": "–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å –≤ MoE: –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –º–æ–¥–µ–ª—è—Ö Mixture-of-Experts (MoE) –Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#video", "#reasoning", "#alignment", "#agents", "#benchmark", "#dataset"], "emoji": "üé¨", "ru": {"title": "MovieCORE: –ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ñ–∏–ª—å–º–æ–≤ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "MovieCORE - —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#video", "#optimization", "#3d"], "emoji": "üé®", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-–∏–Ω–ø–µ–π–Ω—Ç–∏–Ω–≥–µ: –æ—Ç –≤–∏–¥–µ–æ –∫ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º –æ–±—ä–µ–∫—Ç–∞–º", "desc": "ObjFiller-3D - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ –¥–ª
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#open_source", "#training", "#dataset", "#games", "#benchmark", "#agents"], "emoji": "üèÜ", "ru": {"title": "CTF-Dojo: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∏—Å–ø–æ–ª–Ω—è–µ–º—É—é —Å—Ä–µ–¥—É", "desc": "CTF-Dojo - —ç—Ç–æ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–∞—è –∏—Å–ø–æ–ª–Ω—è–µ–º–∞—è —Å—Ä–µ–¥–∞ —Å 658 –∑–∞–¥–∞—á–∞–º–∏ CTF, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞—Ç—å –∞–≥
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#training", "#rag", "#hallucinations", "#optimization", "#healthcare", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ò–ò: –æ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∫ —Å–ª–æ–∂–Ω—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º", "desc": "Selct2Know (S2K) - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –≤ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#training", "#hallucinations", "#multimodal", "#rl"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω–æ–µ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–±–µ–∂–¥–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –ò–ò", "desc": "QueryBandits - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–Ω–æ–≥–æ—Ä—É–∫–∏—Ö –±–∞–Ω–¥–∏—Ç–æ–≤ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö 
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#benchmark", "#multimodal", "#science"], "emoji": "üß†", "ru": {"title": "–†–∞–∑–¥–µ–ª—è–π –∏ –≤–ª–∞—Å—Ç–≤—É–π: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –Ω–∞—É—á–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –Ø–ú", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ SciReas –∏ SciReas-Pro –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–∞—É—á–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è —É —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#architecture", "#science", "#training", "#interpretability", "#dataset"], "emoji": "üß†", "ru": {"title": "–°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–µ—Ç–µ–≤—É—é –º–æ–¥–µ–ª—å, —Å–≤—è–∑—ã–≤–∞—é—â—É—é –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#training", "#inference", "#alignment"], "emoji": "üéõÔ∏è", "ru": {"title": "–ì–∏–±–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º FASB (–ì–∏–±–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π —Å –æ—Ç–∫–∞—Ç–æ–º) –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ —Ä–∞–±–æ—Ç—É –±–æ–ª—å
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#data", "#training", "#optimization", "#benchmark", "#architecture", "#science"], "emoji": "üìä", "ru": {"title": "–ì–ª—É–±–æ–∫–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç GARCH –≤ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–∏—Å–∫–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≥–ª—É–±–æ–∫–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞—Å–ø
[28.08.2025 00:52] Using data from previous issue: {"categories": ["#dataset", "#science", "#open_source", "#benchmark"], "emoji": "‚öñÔ∏è", "ru": {"title": "–ò–ò –Ω–∞ –∑–∞—â–∏—Ç–µ –ø—Ä–∞–≤: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–æ–≤ –¥–ª—è –≤—Å–µ—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–æ–≤ –¥–ª—è –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫ –æ—Ü–µ–Ω–∫–∏. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –ø–µ—Ä–≤—ã
[28.08.2025 00:52] Renaming data file.
[28.08.2025 00:52] Renaming previous data. hf_papers.json to ./d/2025-08-28.json
[28.08.2025 00:52] Saving new data file.
[28.08.2025 00:52] Generating page.
[28.08.2025 00:52] Renaming previous page.
[28.08.2025 00:52] Renaming previous data. index.html to ./d/2025-08-28.html
[28.08.2025 00:52] Writing result.
[28.08.2025 00:52] Renaming log file.
[28.08.2025 00:52] Renaming previous data. log.txt to ./logs/2025-08-28_last_log.txt
