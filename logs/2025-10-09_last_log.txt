[09.10.2025 18:16] Read previous papers.
[09.10.2025 18:16] Generating top page (month).
[09.10.2025 18:16] Writing top page (month).
[09.10.2025 19:10] Read previous papers.
[09.10.2025 19:10] Get feed.
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03215
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06590
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06308
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06917
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07310
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06710
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07315
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04678
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04204
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07318
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04212
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04230
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07019
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06751
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05862
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06557
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05644
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07238
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07143
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05057
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01954
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06783
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07313
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07307
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01982
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06953
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06855
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06673
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05491
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04999
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06261
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07041
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07037
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21842
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05891
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06475
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06426
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04910
[09.10.2025 19:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05152
[09.10.2025 19:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[09.10.2025 19:10] No deleted papers detected.
[09.10.2025 19:10] Downloading and parsing papers (pdf, html). Total: 39.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.03215.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.03215.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.03215.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06590.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06590.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06590.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06308.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06308.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06308.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06917.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06917.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06917.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07310.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07310.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07310.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06710.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06710.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06710.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07315.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07315.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07315.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.04678.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.04678.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.04678.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.04204.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.04204.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.04204.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07318.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07318.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07318.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.04212.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.04212.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.04212.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.04230.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.04230.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.04230.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07019.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07019.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07019.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06751.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06751.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06751.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.05862.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.05862.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.05862.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06557.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06557.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06557.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.05644.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.05644.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.05644.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07238.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07238.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07238.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07143.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07143.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07143.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.05057.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.05057.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.05057.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.01954.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.01954.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.01954.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06783.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06783.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06783.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07313.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07313.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07313.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07307.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07307.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07307.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.01982.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.01982.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.01982.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06953.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06953.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06953.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06855.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06855.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06855.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06673.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06673.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06673.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.05491.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.05491.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.05491.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.04999.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.04999.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.04999.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06261.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06261.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06261.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07041.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07041.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07041.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.07037.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.07037.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.07037.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2509.21842.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2509.21842.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2509.21842.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.05891.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.05891.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.05891.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06475.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06475.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06475.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.06426.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.06426.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.06426.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.04910.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.04910.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.04910.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Downloading and parsing paper https://huggingface.co/papers/2510.05152.
[09.10.2025 19:10] Extra JSON file exists (./assets/json/2510.05152.json), skip PDF parsing.
[09.10.2025 19:10] Paper image links file exists (./assets/img_data/2510.05152.json), skip HTML parsing.
[09.10.2025 19:10] Success.
[09.10.2025 19:10] Enriching papers with extra data.
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 0. Cache-to-Cache (C2C) enables direct semantic communication between LLMs using neural network projections, improving accuracy and reducing latency compared to text-based communication.  					AI-generated summary 				 Multi-LLM systems harness the complementary strengths of diverse Large Language Mode...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 1. MingTok, a continuous latent space visual tokenizer, unifies vision-language understanding and generation within an autoregressive framework, achieving state-of-the-art performance across both domains.  					AI-generated summary 				 Visual tokenization remains a core challenge in unifying visual un...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 2. Lumina-DiMOO, an open-source foundational model, uses fully discrete diffusion modeling for efficient multi-modal generation and understanding, outperforming existing models.  					AI-generated summary 				 We introduce Lumina-DiMOO, an open-source foundational model for seamless multi-modal generat...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 3. SHANKS, a general inference framework, enables spoken language models to generate unspoken reasoning while listening to user input, enhancing real-time interaction and task completion.  					AI-generated summary 				 Current large language models (LLMs) and spoken language models (SLMs) begin thinki...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 4. MATRIX-11K dataset and MATRIX regularization enhance interaction fidelity and semantic alignment in video DiTs by aligning attention with multi-instance mask tracks.  					AI-generated summary 				 Video DiTs have advanced video generation, yet they still struggle to model multi-instance or subject-...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 5. RLinf-VLA is a unified framework for scalable reinforcement learning training of vision-language-action models, offering improved performance and generalization compared to supervised fine-tuning.  					AI-generated summary 				 Recent progress in vision and language foundation models has significan...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 6. Vibe Checker evaluates LLMs by combining functional correctness and instruction following to better align with human coding preferences.  					AI-generated summary 				 Large Language Models (LLMs) have catalyzed vibe coding, where users leverage LLMs to generate and iteratively refine code through ...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 7. MATPO, a reinforcement learning method, optimizes tool-integrated multi-agent roles within a single LLM, improving performance and robustness over single-agent systems.  					AI-generated summary 				 Large language models (LLMs) increasingly rely on multi-turn tool-integrated planning for knowledge...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 8. CALM framework uses expert interventions to refine LRM reasoning for optimization tasks, achieving high accuracy with fewer modifications compared to traditional methods.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoni...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 9. A memory framework combining short-term and long-term memory in neural networks improves long-sequence modeling efficiency and performance.  					AI-generated summary 				 Long-sequence modeling faces a fundamental trade-off between the efficiency of compressive fixed-size memory in RNN-like models ...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 10. Low-precision training of transformer models with flash attention suffers from catastrophic loss explosions due to low-rank representations and biased rounding errors, which are addressed by a minimal modification to the flash attention mechanism.  					AI-generated summary 				 The pursuit of compu...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 11. A language-mixed chain-of-thought reasoning approach improves performance in Korean-specific tasks by switching between English and Korean, achieving state-of-the-art results across various benchmarks.  					AI-generated summary 				 Recent frontier models employ long chain-of-thought reasoning to e...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 12. Native Hybrid Attention (NHA) combines linear and full attention mechanisms to maintain long-term context while improving efficiency, outperforming Transformers in recall-intensive tasks and offering efficiency gains in pretrained LLMs.  					AI-generated summary 				 Transformers excel at sequence ...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 13. OBS-Diff is a novel one-shot pruning framework that compresses large-scale text-to-image diffusion models with minimal quality loss and significant inference acceleration.  					AI-generated summary 				 Large-scale text-to-image diffusion models, while powerful, suffer from prohibitive computationa...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 14. Context Denoising Training (CDT) improves long-context models' performance by mitigating contextual noise and enhancing attention on critical tokens.  					AI-generated summary 				 Long-context models (LCMs) have demonstrated great potential in processing long sequences, facilitating many real-worl...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 15. Markovian Thinking, implemented in Delethink, enables efficient and scalable reinforcement learning for long-chain-of-thought reasoning in LLMs by decoupling thinking length from context size, resulting in linear compute and constant memory usage.  					AI-generated summary 				 Reinforcement learni...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 16. The African Languages Lab addresses the underserved status of African languages in NLP by creating a large dataset and demonstrating improved model performance through fine-tuning.  					AI-generated summary 				 Despite representing nearly one-third of the world's languages, African languages remai...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 17. Research investigates the aging of factuality benchmarks and its impact on evaluating the factuality of large language models, revealing significant unreliability due to outdated samples.  					AI-generated summary 				 The rapid evolution of large language models (LLMs) and the real world has outpa...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 18. VTC-Bench is introduced to provide a fair evaluation framework for visual token compression by incorporating a data filtering mechanism to denoise existing benchmarks.  					AI-generated summary 				 Recent endeavors to accelerate inference in Multimodal Large Language Models (MLLMs) have primarily ...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 19. An unsupervised method learns a compact state representation using a lightweight encoder and Diffusion Transformer decoder, improving robotic performance and enabling latent action decoding from static images.  					AI-generated summary 				 A fundamental challenge in embodied intelligence is develo...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 20. PaDT, a unified paradigm for multimodal large language models, directly generates both textual and visual outputs, achieving state-of-the-art performance in visual perception tasks.  					AI-generated summary 				 Multimodal large language models (MLLMs) have advanced rapidly in recent years. Howeve...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 21. TTRV enhances vision language understanding through test-time reinforcement learning, improving performance on object recognition and VQA without labeled data.  					AI-generated summary 				 Existing methods for extracting reward signals in Reinforcement Learning typically rely on labeled data and ...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 22. WristWorld is a 4D world model that generates wrist-view videos from anchor views, improving video generation consistency and VLA performance.  					AI-generated summary 				 Wrist-view observations are crucial for VLA models as they capture fine-grained hand-object interactions that directly enhanc...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 23. MLE-Smith automates the creation of high-quality, diverse MLE tasks from raw datasets using a multi-agent pipeline, improving scalability and maintaining task quality.  					AI-generated summary 				 While Language Models (LMs) have made significant progress in automating machine learning engineerin...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 24. A novel Granular-GRPO framework enhances reinforcement learning in diffusion and flow models by improving reward assessment and reducing bias in denoising.  					AI-generated summary 				 The integration of online reinforcement learning (RL) into diffusion and flow models has recently emerged as a p...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 25. Step-level uniformity in information density, measured using entropy-based metrics, improves reasoning accuracy in large language models across various benchmarks.  					AI-generated summary 				 The Uniform Information Density (UID) hypothesis suggests that effective communication maintains a stabl...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 26. A novel framework for real-time event boundary detection in streaming videos uses prediction and error measurement to identify subtle event changes.  					AI-generated summary 				 Generic Event Boundary Detection (GEBD) aims to interpret long-form videos through the lens of human perception. Howeve...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 27. Heptapod, an image autoregressive model using causal attention and next 2D distribution prediction, achieves superior performance on ImageNet generation by combining sequential modeling with holistic self-supervised learning.  					AI-generated summary 				 We introduce Heptapod, an image autoregres...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 28. NorMuon, a novel optimizer combining orthogonalization with neuron-level adaptive learning rates, enhances training efficiency and balances parameter utilization in large language models.  					AI-generated summary 				 The choice of optimizer significantly impacts the training efficiency and comput...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 29. A survey of text-to-video generative models from GANs and VAEs to hybrid Diffusion-Transformer architectures, detailing their development, limitations, and future directions.  					AI-generated summary 				 Text-to-video (T2V) generation technology holds potential to transform multiple domains such ...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 30. AlphaApollo, a self-evolving reasoning system, enhances foundation model performance through tool integration and iterative refinement, achieving significant improvements in accuracy and pass rates.  					AI-generated summary 				 We present AlphaApollo, a self-evolving agentic reasoning system that...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 31. U-Bench is a comprehensive benchmark evaluating 100 U-Net variants across 28 datasets and 10 imaging modalities, focusing on statistical robustness, zero-shot generalization, and computational efficiency.  					AI-generated summary 				 Over the past decade, U-Net has been the dominant architecture ...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 32. This survey analyzes the current state of code-switching aware large language models, highlighting advancements and challenges in multilingual NLP.  					AI-generated summary 				 Code-switching (CSW), the alternation of languages and scripts within a single utterance, remains a fundamental challeng...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 33. DeepTravel is an end-to-end reinforcement learning framework for autonomous travel planning that uses a hierarchical reward system and reply-augmented learning to improve performance over existing models.  					AI-generated summary 				 Travel planning (TP) agent has recently worked as an emerging b...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 34. A novel method using Discrete Distribution Discrepancy-aware Quantization Error (D$^3$QE) detects images generated by visual autoregressive models by analyzing codebook frequency statistics and quantization errors.  					AI-generated summary 				 The emergence of visual autoregressive (AR) models ha...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 35. PuzzlePlex benchmark assesses reasoning and planning capabilities of foundation models through diverse puzzles, providing metrics and insights into their performance and scalability.  					AI-generated summary 				 This work investigates the reasoning and planning capabilities of foundation models a...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 36. FinLFQA evaluates LLMs' ability to provide reliable and nuanced attributions in long-form financial question answering through human and automatic assessments.  					AI-generated summary 				 Large Language Models (LLMs) frequently hallucinate to long-form questions, producing plausible yet factuall...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 37. A new training paradigm, Glocal Information Bottleneck, improves time series imputation by aligning latent representations to retain global structure and local details under high missingness.  					AI-generated summary 				 Time Series Imputation (TSI), which aims to recover missing values in tempor...
[09.10.2025 19:10] ********************************************************************************
[09.10.2025 19:10] Abstract 38. The choice of delimiter in formatting in-context examples significantly impacts the performance of large language models across different families and tasks.  					AI-generated summary 				 Common Large Language model (LLM) evaluations rely on demonstration examples to steer models' responses to the...
[09.10.2025 19:10] Read previous papers.
[09.10.2025 19:10] Generating reviews via LLM API.
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#multimodal", "#optimization", "#agi"], "emoji": "🔄", "ru": {"title": "Общение LLM без слов: прямая передача семантики через кэш", "desc": "Статья предлагает новый подход Cache-to-Cache (C2C) для коммуникации между несколькими LLM, который позволяет мод
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#games", "#multimodal", "#optimization", "#cv", "#architecture", "#open_source"], "emoji": "🖼️", "ru": {"title": "MingTok: революция в визуальной токенизации", "desc": "MingTok — это новый подход к визуальной токенизации, который использует непрерывное латентное пространство для объ
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#benchmark", "#diffusion", "#architecture"], "emoji": "🎭", "ru": {"title": "Дискретная диффузия для универсальной мультимодальности", "desc": "Lumina-DiMOO - это открытая foundational модель для мультимодальной генерации и понимания контента. В отличие
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#inference", "#long_context"], "emoji": "🎧", "ru": {"title": "Думай пока слушаешь: рассуждения в реальном времени для разговорных моделей", "desc": "В статье представлен SHANKS — фреймворк для spoken language models (SLM), который позволяет моделям генер
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#dataset", "#hallucinations", "#benchmark", "#video", "#interpretability"], "emoji": "🎭", "ru": {"title": "Улучшение взаимодействий в видео через выравнивание внимания по маскам объектов", "desc": "Исследователи создали датасет MATRIX-11K с видео, содержащими описания взаимодействий
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#training", "#reasoning", "#optimization", "#rl", "#robotics"], "emoji": "🤖", "ru": {"title": "Обучение роботов через взаимодействие: RL побеждает классический supervised learning", "desc": "RLinf-VLA — это унифицированный фреймворк для масштабного обучения
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#interpretability", "#alignment", "#training", "#benchmark", "#plp"], "emoji": "✨", "ru": {"title": "Vibe Check: когда код должен не только работать, но и нравиться", "desc": "Исследователи представили Vibe Checker — новый подход к оценке LLM для генерации кода, который учитывает не
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#agents", "#rl"], "emoji": "🎭", "ru": {"title": "Один LLM в роли целой команды агентов", "desc": "Исследователи представили MATPO — метод обучения с подкреплением для оптимизации мультиагентных систем внутри одной языковой модели. Традицио
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#optimization", "#training", "#reasoning", "#rl"], "emoji": "🎯", "ru": {"title": "Точечные коррекции вместо тотального файн-тюнинга", "desc": "Статья представляет CALM — фреймворк для адаптации больших reasoning-моделей (LRM) к задачам оптимизационного моде
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#benchmark", "#optimization", "#long_context"], "emoji": "🧠", "ru": {"title": "Искусственный гиппокамп для эффективной памяти нейросетей", "desc": "Исследователи предложили архитектуру памяти для нейросетей, вдохновлённую моделью многокомпонентной памят
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "💥", "ru": {"title": "Укрощение взрывов: стабильная тренировка трансформеров с низкой точностью", "desc": "Исследователи выяснили, почему обучение transformer-моделей с flash attention в низкой точности приводит к катастрофичес
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#open_source", "#reasoning", "#low_resource", "#benchmark", "#multilingual", "#dataset", "#long_context", "#training", "#data"], "emoji": "🇰🇷", "ru": {"title": "Смешанный языковой reasoning: английский как якорь для усиления корейских LLM", "desc": "Исследователи предложили метод La
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#architecture", "#long_context"], "emoji": "🔀", "ru": {"title": "Гибридное внимание: эффективность линейных моделей с точностью Transformer", "desc": "Статья представляет Native Hybrid Attention (NHA) — новую архитектуру, которая объединяе
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference", "#diffusion", "#architecture"], "emoji": "✂️", "ru": {"title": "Умное сжатие диффузионных моделей за один проход", "desc": "OBS-Diff — это новый метод одношаговой обрезки (pruning) для сжатия больших текст-в-изображение диффузионных моделей
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#training", "#long_context", "#optimization"], "emoji": "🎯", "ru": {"title": "Обучение с очисткой контекста: фокус на важном", "desc": "Исследователи предлагают метод Context Denoising Training (CDT) для улучшения работы моделей с длинным контекстом. Проблема заключается в том, что 
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#training", "#reasoning", "#rlhf", "#long_context", "#rl", "#optimization"], "emoji": "🧩", "ru": {"title": "Марковское мышление: эффективные длинные рассуждения без квадратичных затрат", "desc": "Статья представляет Markovian Thinking и систему Delethink — новый подход к обучению яз
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#dataset", "#training", "#data", "#multilingual", "#low_resource"], "emoji": "🌍", "ru": {"title": "Африканские языки выходят из тени: масштабный датасет для NLP", "desc": "Исследователи создали African Languages Lab для решения проблемы недостаточной представленности африканских язы
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#interpretability", "#hallucinations", "#benchmark"], "emoji": "⏳", "ru": {"title": "Когда бенчмарки стареют: проблема устаревших тестов для оценки фактуальности LLM", "desc": "Исследование показывает, что популярные бенчмарки для оценки фактуальности LLM устаревают со временем, что
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#dataset"], "emoji": "🔬", "ru": {"title": "VTC-Bench: честная оценка сжатия визуальных токенов в мультимодальных LLM", "desc": "Статья представляет VTC-Bench — новый фреймворк для честной оценки методов сжатия визуальных токенов в мультимодальных больш
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#interpretability", "#training", "#agents", "#optimization", "#robotics", "#diffusion"], "emoji": "🤖", "ru": {"title": "Два токена для управления роботом: компактное представление состояния и действия", "desc": "Статья предлагает метод StaMo для обучения компактного представления со
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#games", "#multimodal", "#training", "#cv", "#optimization", "#open_source"], "emoji": "🎯", "ru": {"title": "Прямая генерация визуальных результатов через токены-патчи", "desc": "В статье представлен PaDT — новый подход для мультимодальных LLM, который позволяет напрямую генерироват
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#optimization", "#rl", "#multimodal", "#rlhf", "#cv", "#transfer_learning"], "emoji": "🎯", "ru": {"title": "Обучение с подкреплением на лету: модели учатся прямо во время тестирования", "desc": "Исследователи предложили метод TTRV, который улучшает понимание изображений и текста чер
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#optimization", "#synthetic", "#cv", "#video"], "emoji": "🤖", "ru": {"title": "Генерация видео с запястья из обычных камер для роботов", "desc": "WristWorld — это 4D модель мира, которая генерирует видео с точки зрения запястья робота, используя только записи с обычных стационарных 
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#survey", "#optimization", "#dataset", "#benchmark", "#data", "#agents"], "emoji": "🏭", "ru": {"title": "Автоматическая фабрика ML-задач из сырых данных", "desc": "Статья представляет MLE-Smith — полностью автоматизированный мульти-агентный пайплайн для создания качественных задач п
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#games", "#alignment", "#rlhf", "#diffusion", "#optimization", "#training", "#rl"], "emoji": "🎯", "ru": {"title": "Точная настройка диффузионных моделей через мультимасштабное обучение с подкреплением", "desc": "Статья представляет новый фреймворк Granular-GRPO для улучшения обучени
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#training"], "emoji": "📊", "ru": {"title": "Равномерность информации — ключ к точности рассуждений LLM", "desc": "Исследователи применили гипотезу равномерной плотности информации (UID) к анализу цепочек рассуждений больших языковых моделей. Они предложил
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#interpretability", "#video", "#benchmark", "#long_context"], "emoji": "🎬", "ru": {"title": "Распознавание границ событий в видео в реальном времени через предсказание и ошибку", "desc": "Статья представляет новую задачу Online Generic Event Boundary Detection (On-GEBD) — обнаружени
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#games", "#benchmark", "#cv"], "emoji": "🐙", "ru": {"title": "Предсказание 2D распределений для авторегрессивной генерации изображений", "desc": "Heptapod — это авторегрессивная модель для генерации изображений, которая использует causal attention и
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "⚖️", "ru": {"title": "Балансировка нейронов через ортогонализацию и адаптивные шаги обучения", "desc": "Статья представляет NorMuon — новый оптимизатор для обучения больших языковых моделей, который объединяет ортогонализацию 
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#architecture", "#training", "#dataset", "#benchmark", "#video", "#diffusion", "#survey"], "emoji": "🎬", "ru": {"title": "От GAN к Diffusion: эволюция генерации видео из текста", "desc": "Статья представляет обзор моделей генерации видео из текста (text-to-video), прослеживая их раз
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#training", "#agents"], "emoji": "🔄", "ru": {"title": "Самоэволюция через инструменты: AlphaApollo поднимает потолок возможностей LLM", "desc": "AlphaApollo — это самообучающаяся система агентного рассуждения, которая решает две ключевые проблемы found
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#cv", "#open_source", "#dataset", "#benchmark", "#optimization", "#survey"], "emoji": "🏥", "ru": {"title": "U-Bench: всесторонний бенчмарк для U-Net архитектур в медицинской сегментации", "desc": "U-Bench представляет собой первый масштабный бенчмарк для систематической оценки U-Net
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#training", "#multilingual", "#architecture", "#benchmark", "#survey", "#dataset", "#low_resource"], "emoji": "🔀", "ru": {"title": "Переключение языков: вызов для современных LLM", "desc": "Статья представляет собой обзор современного состояния больших языковых моделей (LLM), способ
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#agents", "#games", "#reasoning", "#training", "#optimization", "#rl"], "emoji": "🗺️", "ru": {"title": "Автономный AI-агент для планирования путешествий превосходит frontier модели", "desc": "DeepTravel — это end-to-end фреймворк на основе reinforcement learning для автономного план
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#security", "#synthetic", "#cv", "#dataset", "#inference"], "emoji": "🔍", "ru": {"title": "Поиск искусственного через анализ квантизации", "desc": "Исследователи предложили новый метод D³QE для обнаружения изображений, сгенерированных визуальными autoregressive моделями. Метод анали
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#training", "#reasoning", "#games", "#benchmark"], "emoji": "🧩", "ru": {"title": "Головоломки как испытание для AI: проверка логики и планирования", "desc": "Исследователи представили PuzzlePlex — бенчмарк для оценки способностей foundation models к рассуждению и планированию через 
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#long_context", "#hallucinations", "#benchmark", "#reasoning", "#multimodal"], "emoji": "💰", "ru": {"title": "Проверка LLM на честность в финансовых ответах", "desc": "Статья представляет FinLFQA — бенчмарк для оценки способности LLM генерировать развёрнутые ответы на сложные финанс
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#training"], "emoji": "🌍", "ru": {"title": "Баланс между глобальным и локальным: новый подход к восстановлению временных рядов", "desc": "Статья представляет новую парадигму обучения Glocal Information Bottleneck для восстановления пропущенных значений в
[09.10.2025 19:10] Using data from previous issue: {"categories": ["#interpretability", "#training", "#data", "#benchmark", "#optimization"], "emoji": "🔗", "ru": {"title": "Один символ может изменить всё: как разделители влияют на работу LLM", "desc": "Исследование показывает, что выбор разделителя между примерами в промпте (запятая, точка с запятой
[09.10.2025 19:10] Renaming data file.
[09.10.2025 19:10] Renaming previous data. hf_papers.json to ./d/2025-10-09.json
[09.10.2025 19:10] Saving new data file.
[09.10.2025 19:10] Generating page.
[09.10.2025 19:10] Renaming previous page.
[09.10.2025 19:10] Renaming previous data. index.html to ./d/2025-10-09.html
[09.10.2025 19:10] Writing result.
[09.10.2025 19:10] Renaming log file.
[09.10.2025 19:10] Renaming previous data. log.txt to ./logs/2025-10-09_last_log.txt
