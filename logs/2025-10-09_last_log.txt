[09.10.2025 12:22] Read previous papers.
[09.10.2025 12:22] Generating top page (month).
[09.10.2025 12:22] Writing top page (month).
[09.10.2025 13:25] Read previous papers.
[09.10.2025 13:25] Get feed.
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06590
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03215
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06308
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06917
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06710
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07310
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07315
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04678
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06751
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07318
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05862
[09.10.2025 13:25] Extract page data from URL. URL: https://huggingface.co/papers/2510.04204
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07019
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04212
[09.10.2025 13:25] Extract page data from URL. URL: https://huggingface.co/papers/2510.04230
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07238
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07143
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05057
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01954
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07313
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06783
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07307
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06953
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06557
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05644
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01982
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06855
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04999
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06261
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07041
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.07037
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06673
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05491
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21842
[09.10.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05891
[09.10.2025 13:25] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[09.10.2025 13:25] No deleted papers detected.
[09.10.2025 13:25] Downloading and parsing papers (pdf, html). Total: 35.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06590.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06590.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06590.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.03215.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.03215.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.03215.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06308.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06308.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06308.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06917.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06917.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06917.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06710.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06710.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06710.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07310.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07310.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07310.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07315.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07315.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07315.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.04678.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.04678.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.04678.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06751.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06751.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06751.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07318.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07318.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07318.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.05862.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.05862.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.05862.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.04204.
[09.10.2025 13:25] Downloading paper 2510.04204 from http://arxiv.org/pdf/2510.04204v1...
[09.10.2025 13:25] Extracting affiliations from text.
[09.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Preprint. CALM < BEFORE THE STORM : UNLOCKING NATIVE REASONING FOR OPTIMIZATION MODELING Zhengyang Tang1,5, Zihan Ye1, Chenyu Huang2, Xuhan Huang1, Chengpeng Li5, Sihang Li5, Guanhua Chen3, Ming Yan1, Zizhuo Wang1, Hongyuan Zha1, Dayiheng Liu5, and Benyou Wang1,4 1The Chinese University of Hong Kong, Shenzhen 2Shanghai University of Finance and Economics 3Southern University of Science and Technology 4Shenzhen Loop Area Institute (SLAI) 5Qwen Team, Alibaba Inc. ABSTRACT Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoning, opening new opportunities for automating optimization modeling. However, existing domain adaptation methods, originally designed for earlier instruction-tuned models, often fail to exploit the advanced reasoning patterns of modern LRMs In particular, we show that direct fine-tuning on traditional non-reflective datasets leads to limited gains. To fully leverage LRMs inherent reasoning abilities, we propose CALM (Corrective Adaptation with Lightweight Modification), framework that progressively refines LRMs within their native reasoning modes for optimization modeling tasks. In CALM, an expert intervener identifies reasoning flaws and provides concise corrective hints, which the LRM incorporates to produce improved reasoning trajectories. These interventions modify fewer than 2.6% of generated tokens, but generate high-quality data for soft adaptation through supervised fine-tuning. The adapted model is then further improved through reinforcement learning. Building on CALM, we develop STORM (Smart Thinking Optimization Reasoning Model), 4B-parameter LRM that achieves new state-of-the-art average accuracy of 68.9% across five popular optimization modeling benchmarks, matching the performance of 671B LRM. These results demonstrate that dynamic, hint-based data synthesis both preserves and amplifies the native reasoning patterns of modern LRMs, offering more effective and scalable path towards expert-leve"
[09.10.2025 13:25] Response: ```python
[
    "The Chinese University of Hong Kong, Shenzhen",
    "Shanghai University of Finance and Economics",
    "Southern University of Science and Technology",
    "Shenzhen Loop Area Institute (SLAI)",
    "Qwen Team, Alibaba Inc."
]
```
[09.10.2025 13:25] Deleting PDF ./assets/pdf/2510.04204.pdf.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07019.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07019.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07019.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.04212.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.04212.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.04212.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.04230.
[09.10.2025 13:25] Downloading paper 2510.04230 from http://arxiv.org/pdf/2510.04230v1...
[09.10.2025 13:25] Extracting affiliations from text.
[09.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PUSHING ON MULTILINGUAL REASONING MODELS WITH LANGUAGE-MIXED CHAIN-OF-THOUGHT Guijin Son1,6 Donghun Yang2 Hitesh Laxmichand Patel3 Amit Agarwal3 Hyunwoo Ko1,6 Chanuk Lim2 Dasol Choi4,6 Kyong-Ha Lee2 Youngjae Yu5 Srikant Panda3 Minhyuk Kim4,6 Nikunj Drolia7 1OneLineAI 5Seoul National University 2KISTI 3Oracle AI 4Korea University 6Modulabs 7University College Dublin 5 2 0 2 5 ] . [ 1 0 3 2 4 0 . 0 1 5 2 : r spthsrbwls123@yonsei.ac.kr "
[09.10.2025 13:25] Response: ```python
[
    "OneLineAI",
    "Seoul National University",
    "KISTI",
    "Oracle AI",
    "Korea University",
    "Modulabs",
    "University College Dublin"
]
```
[09.10.2025 13:25] Deleting PDF ./assets/pdf/2510.04230.pdf.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07238.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07238.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07238.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07143.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07143.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07143.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.05057.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.05057.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.05057.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.01954.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.01954.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.01954.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07313.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07313.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07313.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06783.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06783.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06783.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07307.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07307.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07307.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06953.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06953.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06953.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06557.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06557.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06557.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.05644.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.05644.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.05644.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.01982.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.01982.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.01982.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06855.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06855.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06855.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.04999.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.04999.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.04999.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06261.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06261.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06261.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07041.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07041.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07041.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.07037.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.07037.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.07037.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.06673.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.06673.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.06673.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.05491.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.05491.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.05491.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2509.21842.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2509.21842.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2509.21842.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2510.05891.
[09.10.2025 13:25] Extra JSON file exists (./assets/json/2510.05891.json), skip PDF parsing.
[09.10.2025 13:25] Paper image links file exists (./assets/img_data/2510.05891.json), skip HTML parsing.
[09.10.2025 13:25] Success.
[09.10.2025 13:25] Enriching papers with extra data.
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 0. MingTok, a continuous latent space visual tokenizer, unifies vision-language understanding and generation within an autoregressive framework, achieving state-of-the-art performance across both domains.  					AI-generated summary 				 Visual tokenization remains a core challenge in unifying visual un...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 1. Cache-to-Cache (C2C) enables direct semantic communication between LLMs using neural network projections, improving accuracy and reducing latency compared to text-based communication.  					AI-generated summary 				 Multi-LLM systems harness the complementary strengths of diverse Large Language Mode...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 2. Lumina-DiMOO, an open-source foundational model, uses fully discrete diffusion modeling for efficient multi-modal generation and understanding, outperforming existing models.  					AI-generated summary 				 We introduce Lumina-DiMOO, an open-source foundational model for seamless multi-modal generat...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 3. SHANKS, a general inference framework, enables spoken language models to generate unspoken reasoning while listening to user input, enhancing real-time interaction and task completion.  					AI-generated summary 				 Current large language models (LLMs) and spoken language models (SLMs) begin thinki...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 4. RLinf-VLA is a unified framework for scalable reinforcement learning training of vision-language-action models, offering improved performance and generalization compared to supervised fine-tuning.  					AI-generated summary 				 Recent progress in vision and language foundation models has significan...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 5. MATRIX-11K dataset and MATRIX regularization enhance interaction fidelity and semantic alignment in video DiTs by aligning attention with multi-instance mask tracks.  					AI-generated summary 				 Video DiTs have advanced video generation, yet they still struggle to model multi-instance or subject-...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 6. Vibe Checker evaluates LLMs by combining functional correctness and instruction following to better align with human coding preferences.  					AI-generated summary 				 Large Language Models (LLMs) have catalyzed vibe coding, where users leverage LLMs to generate and iteratively refine code through ...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 7. MATPO, a reinforcement learning method, optimizes tool-integrated multi-agent roles within a single LLM, improving performance and robustness over single-agent systems.  					AI-generated summary 				 Large language models (LLMs) increasingly rely on multi-turn tool-integrated planning for knowledge...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 8. OBS-Diff is a novel one-shot pruning framework that compresses large-scale text-to-image diffusion models with minimal quality loss and significant inference acceleration.  					AI-generated summary 				 Large-scale text-to-image diffusion models, while powerful, suffer from prohibitive computationa...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 9. A memory framework combining short-term and long-term memory in neural networks improves long-sequence modeling efficiency and performance.  					AI-generated summary 				 Long-sequence modeling faces a fundamental trade-off between the efficiency of compressive fixed-size memory in RNN-like models ...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 10. Context Denoising Training (CDT) improves long-context models' performance by mitigating contextual noise and enhancing attention on critical tokens.  					AI-generated summary 				 Long-context models (LCMs) have demonstrated great potential in processing long sequences, facilitating many real-worl...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 11. CALM framework uses expert interventions to refine LRM reasoning for optimization tasks, achieving high accuracy with fewer modifications compared to traditional methods.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoni...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 12. Native Hybrid Attention (NHA) combines linear and full attention mechanisms to maintain long-term context while improving efficiency, outperforming Transformers in recall-intensive tasks and offering efficiency gains in pretrained LLMs.  					AI-generated summary 				 Transformers excel at sequence ...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 13. Low-precision training of transformer models with flash attention suffers from catastrophic loss explosions due to low-rank representations and biased rounding errors, which are addressed by a minimal modification to the flash attention mechanism.  					AI-generated summary 				 The pursuit of compu...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 14. A language-mixed chain-of-thought reasoning approach improves performance in Korean-specific tasks by switching between English and Korean, achieving state-of-the-art results across various benchmarks.  					AI-generated summary 				 Recent frontier models employ long chain-of-thought reasoning to e...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 15. Research investigates the aging of factuality benchmarks and its impact on evaluating the factuality of large language models, revealing significant unreliability due to outdated samples.  					AI-generated summary 				 The rapid evolution of large language models (LLMs) and the real world has outpa...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 16. VTC-Bench is introduced to provide a fair evaluation framework for visual token compression by incorporating a data filtering mechanism to denoise existing benchmarks.  					AI-generated summary 				 Recent endeavors to accelerate inference in Multimodal Large Language Models (MLLMs) have primarily ...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 17. An unsupervised method learns a compact state representation using a lightweight encoder and Diffusion Transformer decoder, improving robotic performance and enabling latent action decoding from static images.  					AI-generated summary 				 A fundamental challenge in embodied intelligence is develo...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 18. PaDT, a unified paradigm for multimodal large language models, directly generates both textual and visual outputs, achieving state-of-the-art performance in visual perception tasks.  					AI-generated summary 				 Multimodal large language models (MLLMs) have advanced rapidly in recent years. Howeve...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 19. WristWorld is a 4D world model that generates wrist-view videos from anchor views, improving video generation consistency and VLA performance.  					AI-generated summary 				 Wrist-view observations are crucial for VLA models as they capture fine-grained hand-object interactions that directly enhanc...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 20. TTRV enhances vision language understanding through test-time reinforcement learning, improving performance on object recognition and VQA without labeled data.  					AI-generated summary 				 Existing methods for extracting reward signals in Reinforcement Learning typically rely on labeled data and ...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 21. MLE-Smith automates the creation of high-quality, diverse MLE tasks from raw datasets using a multi-agent pipeline, improving scalability and maintaining task quality.  					AI-generated summary 				 While Language Models (LMs) have made significant progress in automating machine learning engineerin...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 22. Step-level uniformity in information density, measured using entropy-based metrics, improves reasoning accuracy in large language models across various benchmarks.  					AI-generated summary 				 The Uniform Information Density (UID) hypothesis suggests that effective communication maintains a stabl...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 23. Markovian Thinking, implemented in Delethink, enables efficient and scalable reinforcement learning for long-chain-of-thought reasoning in LLMs by decoupling thinking length from context size, resulting in linear compute and constant memory usage.  					AI-generated summary 				 Reinforcement learni...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 24. The African Languages Lab addresses the underserved status of African languages in NLP by creating a large dataset and demonstrating improved model performance through fine-tuning.  					AI-generated summary 				 Despite representing nearly one-third of the world's languages, African languages remai...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 25. A novel Granular-GRPO framework enhances reinforcement learning in diffusion and flow models by improving reward assessment and reducing bias in denoising.  					AI-generated summary 				 The integration of online reinforcement learning (RL) into diffusion and flow models has recently emerged as a p...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 26. A novel framework for real-time event boundary detection in streaming videos uses prediction and error measurement to identify subtle event changes.  					AI-generated summary 				 Generic Event Boundary Detection (GEBD) aims to interpret long-form videos through the lens of human perception. Howeve...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 27. A survey of text-to-video generative models from GANs and VAEs to hybrid Diffusion-Transformer architectures, detailing their development, limitations, and future directions.  					AI-generated summary 				 Text-to-video (T2V) generation technology holds potential to transform multiple domains such ...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 28. AlphaApollo, a self-evolving reasoning system, enhances foundation model performance through tool integration and iterative refinement, achieving significant improvements in accuracy and pass rates.  					AI-generated summary 				 We present AlphaApollo, a self-evolving agentic reasoning system that...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 29. U-Bench is a comprehensive benchmark evaluating 100 U-Net variants across 28 datasets and 10 imaging modalities, focusing on statistical robustness, zero-shot generalization, and computational efficiency.  					AI-generated summary 				 Over the past decade, U-Net has been the dominant architecture ...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 30. This survey analyzes the current state of code-switching aware large language models, highlighting advancements and challenges in multilingual NLP.  					AI-generated summary 				 Code-switching (CSW), the alternation of languages and scripts within a single utterance, remains a fundamental challeng...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 31. Heptapod, an image autoregressive model using causal attention and next 2D distribution prediction, achieves superior performance on ImageNet generation by combining sequential modeling with holistic self-supervised learning.  					AI-generated summary 				 We introduce Heptapod, an image autoregres...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 32. NorMuon, a novel optimizer combining orthogonalization with neuron-level adaptive learning rates, enhances training efficiency and balances parameter utilization in large language models.  					AI-generated summary 				 The choice of optimizer significantly impacts the training efficiency and comput...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 33. DeepTravel is an end-to-end reinforcement learning framework for autonomous travel planning that uses a hierarchical reward system and reply-augmented learning to improve performance over existing models.  					AI-generated summary 				 Travel planning (TP) agent has recently worked as an emerging b...
[09.10.2025 13:25] ********************************************************************************
[09.10.2025 13:25] Abstract 34. A novel method using Discrete Distribution Discrepancy-aware Quantization Error (D$^3$QE) detects images generated by visual autoregressive models by analyzing codebook frequency statistics and quantization errors.  					AI-generated summary 				 The emergence of visual autoregressive (AR) models ha...
[09.10.2025 13:25] Read previous papers.
[09.10.2025 13:25] Generating reviews via LLM API.
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#games", "#multimodal", "#optimization", "#cv", "#architecture", "#open_source"], "emoji": "ðŸ–¼ï¸", "ru": {"title": "MingTok: Ñ€ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð² Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸Ð¸", "desc": "MingTok â€” ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð½ÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½Ð¾Ðµ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð¾Ð±ÑŠ
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#architecture", "#training", "#multimodal", "#optimization", "#agi"], "emoji": "ðŸ”„", "ru": {"title": "ÐžÐ±Ñ‰ÐµÐ½Ð¸Ðµ LLM Ð±ÐµÐ· ÑÐ»Ð¾Ð²: Ð¿Ñ€ÑÐ¼Ð°Ñ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð° ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ¸ Ñ‡ÐµÑ€ÐµÐ· ÐºÑÑˆ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Cache-to-Cache (C2C) Ð´Ð»Ñ ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼Ð¸ LLM, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¼Ð¾Ð´
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#benchmark", "#diffusion", "#architecture"], "emoji": "ðŸŽ­", "ru": {"title": "Ð”Ð¸ÑÐºÑ€ÐµÑ‚Ð½Ð°Ñ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ñ Ð´Ð»Ñ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸", "desc": "Lumina-DiMOO - ÑÑ‚Ð¾ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð°Ñ foundational Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°. Ð’ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#inference", "#long_context"], "emoji": "ðŸŽ§", "ru": {"title": "Ð”ÑƒÐ¼Ð°Ð¹ Ð¿Ð¾ÐºÐ° ÑÐ»ÑƒÑˆÐ°ÐµÑˆÑŒ: Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð´Ð»Ñ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð’ ÑÑ‚Ð°Ñ‚ÑŒÐµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ SHANKS â€” Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ spoken language models (SLM), ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼ Ð³ÐµÐ½ÐµÑ€
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#training", "#reasoning", "#optimization", "#rl", "#robotics"], "emoji": "ðŸ¤–", "ru": {"title": "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ: RL Ð¿Ð¾Ð±ÐµÐ¶Ð´Ð°ÐµÑ‚ ÐºÐ»Ð°ÑÑÐ¸Ñ‡ÐµÑÐºÐ¸Ð¹ supervised learning", "desc": "RLinf-VLA â€” ÑÑ‚Ð¾ ÑƒÐ½Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#dataset", "#hallucinations", "#benchmark", "#video", "#interpretability"], "emoji": "ðŸŽ­", "ru": {"title": "Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹ Ð² Ð²Ð¸Ð´ÐµÐ¾ Ñ‡ÐµÑ€ÐµÐ· Ð²Ñ‹Ñ€Ð°Ð²Ð½Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð¿Ð¾ Ð¼Ð°ÑÐºÐ°Ð¼ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ ÑÐ¾Ð·Ð´Ð°Ð»Ð¸ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ MATRIX-11K Ñ Ð²Ð¸Ð´ÐµÐ¾, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰Ð¸Ð¼Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#interpretability", "#alignment", "#training", "#benchmark", "#plp"], "emoji": "âœ¨", "ru": {"title": "Vibe Check: ÐºÐ¾Ð³Ð´Ð° ÐºÐ¾Ð´ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ, Ð½Ð¾ Ð¸ Ð½Ñ€Ð°Ð²Ð¸Ñ‚ÑŒÑÑ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ Vibe Checker â€” Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð¾Ñ†ÐµÐ½ÐºÐµ LLM Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð´Ð°, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ðµ
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#agents", "#rl"], "emoji": "ðŸŽ­", "ru": {"title": "ÐžÐ´Ð¸Ð½ LLM Ð² Ñ€Ð¾Ð»Ð¸ Ñ†ÐµÐ»Ð¾Ð¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ MATPO â€” Ð¼ÐµÑ‚Ð¾Ð´ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð°Ð³ÐµÐ½Ñ‚Ð½Ñ‹Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð¾Ð´Ð½Ð¾Ð¹ ÑÐ·Ñ‹ÐºÐ¾Ð²Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸. Ð¢Ñ€Ð°Ð´Ð¸Ñ†Ð¸Ð¾
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference", "#diffusion", "#architecture"], "emoji": "âœ‚ï¸", "ru": {"title": "Ð£Ð¼Ð½Ð¾Ðµ ÑÐ¶Ð°Ñ‚Ð¸Ðµ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð·Ð° Ð¾Ð´Ð¸Ð½ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´", "desc": "OBS-Diff â€” ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð¾Ð´Ð½Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾Ð¹ Ð¾Ð±Ñ€ÐµÐ·ÐºÐ¸ (pruning) Ð´Ð»Ñ ÑÐ¶Ð°Ñ‚Ð¸Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ñ‚ÐµÐºÑÑ‚-Ð²-Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#architecture", "#training", "#benchmark", "#optimization", "#long_context"], "emoji": "ðŸ§ ", "ru": {"title": "Ð˜ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð³Ð¸Ð¿Ð¿Ð¾ÐºÐ°Ð¼Ð¿ Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚ÐµÐ¹", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð¸ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð´Ð»Ñ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚ÐµÐ¹, Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»Ñ‘Ð½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒÑŽ Ð¼Ð½Ð¾Ð³Ð¾ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð½Ð¾Ð¹ Ð¿Ð°Ð¼ÑÑ‚
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#long_context", "#optimization"], "emoji": "ðŸŽ¯", "ru": {"title": "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¾Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°: Ñ„Ð¾ÐºÑƒÑ Ð½Ð° Ð²Ð°Ð¶Ð½Ð¾Ð¼", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÑŽÑ‚ Ð¼ÐµÑ‚Ð¾Ð´ Context Denoising Training (CDT) Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼. ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð·Ð°ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ÑÑ Ð² Ñ‚Ð¾Ð¼, Ñ‡Ñ‚Ð¾ 
[09.10.2025 13:25] Querying the API.
[09.10.2025 13:25] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

CALM framework uses expert interventions to refine LRM reasoning for optimization tasks, achieving high accuracy with fewer modifications compared to traditional methods.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoning, opening new opportunities for automating optimization modeling. However, existing domain adaptation methods, originally designed for earlier instruction-tuned models, often fail to exploit the advanced reasoning patterns of modern LRMs -- In particular, we show that direct fine-tuning on traditional non-reflective datasets leads to limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose CALM (Corrective Adaptation with Lightweight Modification), a framework that progressively refines LRMs within their native reasoning modes for optimization modeling tasks. In CALM, an expert intervener identifies reasoning flaws and provides concise corrective hints, which the LRM incorporates to produce improved reasoning trajectories. These interventions modify fewer than 2.6\% of generated tokens, but generate high-quality data for soft adaptation through supervised fine-tuning. The adapted model is then further improved through reinforcement learning. Building on CALM, we develop STORM (Smart Thinking Optimization Reasoning Model), a 4B-parameter LRM that achieves a new state-of-the-art average accuracy of 68.9\% across five popular optimization modeling benchmarks, matching the performance of a 671B LRM. These results demonstrate that dynamic, hint-based data synthesis both preserves and amplifies the native reasoning patterns of modern LRMs, offering a more effective and scalable path towards expert-level performance on challenging optimization modeling tasks.
[09.10.2025 13:25] Response: ```json
{
  "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ CALM â€” Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… reasoning-Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LRM) Ðº Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ð³Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ. Ð’Ð¼ÐµÑÑ‚Ð¾ Ñ‚Ñ€Ð°Ð´Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð½-Ñ‚ÑŽÐ½Ð¸Ð½Ð³Ð° Ð°Ð²Ñ‚Ð¾Ñ€Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ðµ Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÑŽÑ‚ Ð¼ÐµÐ½ÐµÐµ 2.6% ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð², ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸. ÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ CALM ÑÐ¾Ð·Ð´Ð°Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ STORM Ñ 4 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð°Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð², ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð°ÐµÑ‚ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ 68.9% Ð½Ð° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°Ñ… Ð¿Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸, ÑÑ€Ð°Ð²Ð½ÑÐ²ÑˆÐ¸ÑÑŒ Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒÑŽ Ð² 671 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð². ÐŸÐ¾Ð´Ñ…Ð¾Ð´ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÑ‚, Ñ‡Ñ‚Ð¾ Ñ†ÐµÐ»ÐµÐ½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ð°Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ñ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½ÐµÐµ Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ð³Ð¾ Ð´Ð¾Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸.",
  "emoji": "ðŸŽ¯",
  "title": "Ð¢Ð¾Ñ‡ÐµÑ‡Ð½Ñ‹Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ð¸ Ð²Ð¼ÐµÑÑ‚Ð¾ Ñ‚Ð¾Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð½-Ñ‚ÑŽÐ½Ð¸Ð½Ð³Ð°"
}
```
[09.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CALM framework uses expert interventions to refine LRM reasoning for optimization tasks, achieving high accuracy with fewer modifications compared to traditional methods.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoning, opening new opportunities for automating optimization modeling. However, existing domain adaptation methods, originally designed for earlier instruction-tuned models, often fail to exploit the advanced reasoning patterns of modern LRMs -- In particular, we show that direct fine-tuning on traditional non-reflective datasets leads to limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose CALM (Corrective Adaptation with Lightweight Modification), a framework that progressively refines LRMs within their native reasoning modes for optimization modeling tasks. In CALM, an expert intervener identifies reasoning flaws and provides concise corrective hints, which the LRM incorporates to produce improved reasoning trajectories. These interventions modify fewer than 2.6\% of generated tokens, but generate high-quality data for soft adaptation through supervised fine-tuning. The adapted model is then further improved through reinforcement learning. Building on CALM, we develop STORM (Smart Thinking Optimization Reasoning Model), a 4B-parameter LRM that achieves a new state-of-the-art average accuracy of 68.9\% across five popular optimization modeling benchmarks, matching the performance of a 671B LRM. These results demonstrate that dynamic, hint-based data synthesis both preserves and amplifies the native reasoning patterns of modern LRMs, offering a more effective and scalable path towards expert-level performance on challenging optimization modeling tasks."

[09.10.2025 13:25] Response: ```python
['RL', 'TRAINING', 'BENCHMARK', 'DATASET']
```
[09.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CALM framework uses expert interventions to refine LRM reasoning for optimization tasks, achieving high accuracy with fewer modifications compared to traditional methods.  					AI-generated summary 				 Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoning, opening new opportunities for automating optimization modeling. However, existing domain adaptation methods, originally designed for earlier instruction-tuned models, often fail to exploit the advanced reasoning patterns of modern LRMs -- In particular, we show that direct fine-tuning on traditional non-reflective datasets leads to limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose CALM (Corrective Adaptation with Lightweight Modification), a framework that progressively refines LRMs within their native reasoning modes for optimization modeling tasks. In CALM, an expert intervener identifies reasoning flaws and provides concise corrective hints, which the LRM incorporates to produce improved reasoning trajectories. These interventions modify fewer than 2.6\% of generated tokens, but generate high-quality data for soft adaptation through supervised fine-tuning. The adapted model is then further improved through reinforcement learning. Building on CALM, we develop STORM (Smart Thinking Optimization Reasoning Model), a 4B-parameter LRM that achieves a new state-of-the-art average accuracy of 68.9\% across five popular optimization modeling benchmarks, matching the performance of a 671B LRM. These results demonstrate that dynamic, hint-based data synthesis both preserves and amplifies the native reasoning patterns of modern LRMs, offering a more effective and scalable path towards expert-level performance on challenging optimization modeling tasks."

[09.10.2025 13:25] Response: ```python
['OPTIMIZATION', 'REASONING']
```
[09.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The CALM framework enhances Large Reasoning Models (LRMs) by using expert interventions to correct reasoning errors during optimization tasks. It allows LRMs to maintain their advanced reasoning capabilities while making minimal modifications to their outputs. By incorporating concise corrective hints from experts, CALM enables the model to generate high-quality data for further training through supervised fine-tuning. This approach leads to significant improvements in accuracy, demonstrating a more effective method for adapting LRMs to complex optimization challenges.","title":"Refining Reasoning with Expert Hints for Optimization Success"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The CALM framework enhances Large Reasoning Models (LRMs) by using expert interventions to correct reasoning errors during optimization tasks. It allows LRMs to maintain their advanced reasoning capabilities while making minimal modifications to their outputs. By incorporating concise corrective hints from experts, CALM enables the model to generate high-quality data for further training through supervised fine-tuning. This approach leads to significant improvements in accuracy, demonstrating a more effective method for adapting LRMs to complex optimization challenges.', title='Refining Reasoning with Expert Hints for Optimization Success'))
[09.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CALMæ¡†æž¶é€šè¿‡ä¸“å®¶å¹²é¢„æ¥ä¼˜åŒ–å¤§åž‹æŽ¨ç†æ¨¡åž‹ï¼ˆLRMï¼‰çš„æŽ¨ç†è¿‡ç¨‹ï¼Œä»Žè€Œåœ¨ä¼˜åŒ–ä»»åŠ¡ä¸­å®žçŽ°é«˜å‡†ç¡®çŽ‡ã€‚ä¸Žä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒCALMåœ¨ä¿®æ”¹æ–¹é¢çš„éœ€æ±‚æ›´å°‘ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨LRMçš„æŽ¨ç†èƒ½åŠ›ã€‚è¯¥æ¡†æž¶é€šè¿‡è¯†åˆ«æŽ¨ç†ç¼ºé™·å¹¶æä¾›ç®€æ´çš„çº æ­£æç¤ºï¼Œå¸®åŠ©LRMç”Ÿæˆæ›´ä¼˜è´¨çš„æŽ¨ç†è½¨è¿¹ã€‚æœ€ç»ˆï¼ŒåŸºäºŽCALMçš„STORMæ¨¡åž‹åœ¨å¤šä¸ªä¼˜åŒ–å»ºæ¨¡åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æ–°çš„æœ€é«˜å¹³å‡å‡†ç¡®çŽ‡ï¼Œå±•ç¤ºäº†åŠ¨æ€æç¤ºæ•°æ®åˆæˆçš„æœ‰æ•ˆæ€§ã€‚","title":"CALMæ¡†æž¶ï¼šä¼˜åŒ–æŽ¨ç†çš„æ™ºèƒ½å¹²é¢„"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CALMæ¡†æž¶é€šè¿‡ä¸“å®¶å¹²é¢„æ¥ä¼˜åŒ–å¤§åž‹æŽ¨ç†æ¨¡åž‹ï¼ˆLRMï¼‰çš„æŽ¨ç†è¿‡ç¨‹ï¼Œä»Žè€Œåœ¨ä¼˜åŒ–ä»»åŠ¡ä¸­å®žçŽ°é«˜å‡†ç¡®çŽ‡ã€‚ä¸Žä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒCALMåœ¨ä¿®æ”¹æ–¹é¢çš„éœ€æ±‚æ›´å°‘ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨LRMçš„æŽ¨ç†èƒ½åŠ›ã€‚è¯¥æ¡†æž¶é€šè¿‡è¯†åˆ«æŽ¨ç†ç¼ºé™·å¹¶æä¾›ç®€æ´çš„çº æ­£æç¤ºï¼Œå¸®åŠ©LRMç”Ÿæˆæ›´ä¼˜è´¨çš„æŽ¨ç†è½¨è¿¹ã€‚æœ€ç»ˆï¼ŒåŸºäºŽCALMçš„STORMæ¨¡åž‹åœ¨å¤šä¸ªä¼˜åŒ–å»ºæ¨¡åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æ–°çš„æœ€é«˜å¹³å‡å‡†ç¡®çŽ‡ï¼Œå±•ç¤ºäº†åŠ¨æ€æç¤ºæ•°æ®åˆæˆçš„æœ‰æ•ˆæ€§ã€‚', title='CALMæ¡†æž¶ï¼šä¼˜åŒ–æŽ¨ç†çš„æ™ºèƒ½å¹²é¢„'))
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#architecture", "#long_context"], "emoji": "ðŸ”€", "ru": {"title": "Ð“Ð¸Ð±Ñ€Ð¸Ð´Ð½Ð¾Ðµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ: ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð»Ð¸Ð½ÐµÐ¹Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ Transformer", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Native Hybrid Attention (NHA) â€” Ð½Ð¾Ð²ÑƒÑŽ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµ
[09.10.2025 13:25] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "ðŸ’¥", "ru": {"title": "Ð£ÐºÑ€Ð¾Ñ‰ÐµÐ½Ð¸Ðµ Ð²Ð·Ñ€Ñ‹Ð²Ð¾Ð²: ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð°Ñ Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²ÐºÐ° Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ð¾Ð² Ñ Ð½Ð¸Ð·ÐºÐ¾Ð¹ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð²Ñ‹ÑÑÐ½Ð¸Ð»Ð¸, Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ transformer-Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ flash attention Ð² Ð½Ð¸Ð·ÐºÐ¾Ð¹ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸Ð²Ð¾Ð´Ð¸Ñ‚ Ðº ÐºÐ°Ñ‚Ð°ÑÑ‚Ñ€Ð¾Ñ„Ð¸Ñ‡ÐµÑ
[09.10.2025 13:25] Querying the API.
[09.10.2025 13:25] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A language-mixed chain-of-thought reasoning approach improves performance in Korean-specific tasks by switching between English and Korean, achieving state-of-the-art results across various benchmarks.  					AI-generated summary 				 Recent frontier models employ long chain-of-thought reasoning to explore solution spaces in context and achieve stonger performance. While many works study distillation to build smaller yet capable models, most focus on English and little is known about language-specific reasoning. To bridge this gap, we first introduct **Language-Mixed CoT**, a reasoning schema that switches between English and a target language, using English as an anchor to excel in reasoning while minimizing translation artificats. As a Korean case study, we curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5, Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves state-of-the-art performance, with the highest overall average score (64.0 \pm 25), ranking first on 5/9 benchmarks and second on the remainder. Samller and mid-sized models also benefit substantially, with an average improvement of +18.6 points across teh evaluated nine benchmarks. Ablations show **Language-Mixed CoT** is more effective than monolingual CoT, also resulting in cross-lingual and mult-modal performance gains. We release our data-curation pipeline, evaluation system, datasets, and models to advance research on language-specific reasoning. Data and model collection: https://huggingface.co/KOREAson.
[09.10.2025 13:26] Response: ```json
{
  "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð¸ Ð¼ÐµÑ‚Ð¾Ð´ Language-Mixed CoT, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ÑÑ Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¼ Ð¸ Ñ†ÐµÐ»ÐµÐ²Ñ‹Ð¼ ÑÐ·Ñ‹ÐºÐ¾Ð¼ (ÐºÐ¾Ñ€ÐµÐ¹ÑÐºÐ¸Ð¼) Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ reasoning ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÐµÐ¹ LLM. ÐžÐ½Ð¸ ÑÐ¾Ð·Ð´Ð°Ð»Ð¸ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Yi-Sang Ñ 5.79M ÐºÐ¾Ñ€ÐµÐ¹ÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð² Ð¸ 3.7M Ð´Ð»Ð¸Ð½Ð½Ñ‹Ñ… reasoning traces, Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð½Ð° Ð±Ð°Ð·Ðµ Qwen3-32B. Ð˜Ñ… Ð»ÑƒÑ‡ÑˆÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ KO-REAson-35B Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð° state-of-the-art Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð½Ð° ÐºÐ¾Ñ€ÐµÐ¹ÑÐºÐ¸Ñ… Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°Ñ…, Ð·Ð°Ð½ÑÐ² Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾ Ð½Ð° 5 Ð¸Ð· 9 Ñ‚ÐµÑÑ‚Ð¾Ð² ÑÐ¾ ÑÑ€ÐµÐ´Ð½Ð¸Ð¼ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÐµÐ¼ +18.6 Ð±Ð°Ð»Ð»Ð¾Ð². Ð­ÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¿Ð¾ÐºÐ°Ð·Ð°Ð»Ð¸, Ñ‡Ñ‚Ð¾ ÑÐ¼ÐµÑˆÐ°Ð½Ð½Ñ‹Ð¹ ÑÐ·Ñ‹ÐºÐ¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ð¿Ñ€ÐµÐ²Ð¾ÑÑ…Ð¾Ð´Ð¸Ñ‚ Ð¼Ð¾Ð½Ð¾Ð»Ð¸Ð½Ð³Ð²Ð°Ð»ÑŒÐ½Ñ‹Ð¹ CoT Ð¸ Ð´Ð°Ð¶Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ cross-lingual Ð¸ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.",
  "emoji": "ðŸ‡°ðŸ‡·",
  "title": "Ð¡Ð¼ÐµÑˆÐ°Ð½Ð½Ñ‹Ð¹ ÑÐ·Ñ‹ÐºÐ¾Ð²Ð¾Ð¹ reasoning: Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÐºÐ°Ðº ÑÐºÐ¾Ñ€ÑŒ Ð´Ð»Ñ ÑƒÑÐ¸Ð»ÐµÐ½Ð¸Ñ ÐºÐ¾Ñ€ÐµÐ¹ÑÐºÐ¸Ñ… LLM"
}
```
[09.10.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A language-mixed chain-of-thought reasoning approach improves performance in Korean-specific tasks by switching between English and Korean, achieving state-of-the-art results across various benchmarks.  					AI-generated summary 				 Recent frontier models employ long chain-of-thought reasoning to explore solution spaces in context and achieve stonger performance. While many works study distillation to build smaller yet capable models, most focus on English and little is known about language-specific reasoning. To bridge this gap, we first introduct **Language-Mixed CoT**, a reasoning schema that switches between English and a target language, using English as an anchor to excel in reasoning while minimizing translation artificats. As a Korean case study, we curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5, Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves state-of-the-art performance, with the highest overall average score (64.0 \pm 25), ranking first on 5/9 benchmarks and second on the remainder. Samller and mid-sized models also benefit substantially, with an average improvement of +18.6 points across teh evaluated nine benchmarks. Ablations show **Language-Mixed CoT** is more effective than monolingual CoT, also resulting in cross-lingual and mult-modal performance gains. We release our data-curation pipeline, evaluation system, datasets, and models to advance research on language-specific reasoning. Data and model collection: https://huggingface.co/KOREAson."

[09.10.2025 13:26] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'MULTILINGUAL', 'TRAINING']
```
[09.10.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A language-mixed chain-of-thought reasoning approach improves performance in Korean-specific tasks by switching between English and Korean, achieving state-of-the-art results across various benchmarks.  					AI-generated summary 				 Recent frontier models employ long chain-of-thought reasoning to explore solution spaces in context and achieve stonger performance. While many works study distillation to build smaller yet capable models, most focus on English and little is known about language-specific reasoning. To bridge this gap, we first introduct **Language-Mixed CoT**, a reasoning schema that switches between English and a target language, using English as an anchor to excel in reasoning while minimizing translation artificats. As a Korean case study, we curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5, Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves state-of-the-art performance, with the highest overall average score (64.0 \pm 25), ranking first on 5/9 benchmarks and second on the remainder. Samller and mid-sized models also benefit substantially, with an average improvement of +18.6 points across teh evaluated nine benchmarks. Ablations show **Language-Mixed CoT** is more effective than monolingual CoT, also resulting in cross-lingual and mult-modal performance gains. We release our data-curation pipeline, evaluation system, datasets, and models to advance research on language-specific reasoning. Data and model collection: https://huggingface.co/KOREAson."

[09.10.2025 13:26] Response: ```python
["REASONING", "LONG_CONTEXT", "OPEN_SOURCE", "LOW_RESOURCE"]
```
[09.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a novel reasoning approach called Language-Mixed Chain-of-Thought (CoT) that enhances performance on Korean-specific tasks by alternating between English and Korean. By using English as a reference point, the method minimizes translation errors and improves reasoning capabilities. The authors present a comprehensive dataset, Yi-Sang, consisting of millions of Korean prompts and reasoning traces, which supports the training of various models. The best-performing model, KO-REAson-35B, achieves state-of-the-art results across multiple benchmarks, demonstrating significant improvements for both large and smaller models.","title":"Bridging Languages for Better Reasoning in Korean Tasks"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a novel reasoning approach called Language-Mixed Chain-of-Thought (CoT) that enhances performance on Korean-specific tasks by alternating between English and Korean. By using English as a reference point, the method minimizes translation errors and improves reasoning capabilities. The authors present a comprehensive dataset, Yi-Sang, consisting of millions of Korean prompts and reasoning traces, which supports the training of various models. The best-performing model, KO-REAson-35B, achieves state-of-the-art results across multiple benchmarks, demonstrating significant improvements for both large and smaller models.', title='Bridging Languages for Better Reasoning in Korean Tasks'))
[09.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§è¯­è¨€æ··åˆçš„æ€ç»´é“¾æŽ¨ç†æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜éŸ©è¯­ç‰¹å®šä»»åŠ¡çš„è¡¨çŽ°ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨è‹±è¯­å’ŒéŸ©è¯­ä¹‹é—´åˆ‡æ¢ï¼Œåˆ©ç”¨è‹±è¯­ä½œä¸ºé”šç‚¹æ¥å¢žå¼ºæŽ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶å‡å°‘ç¿»è¯‘å¸¦æ¥çš„å¹²æ‰°ã€‚ç ”ç©¶ä¸­ä½¿ç”¨äº†åä¸ºYi-Sangçš„éŸ©è¯­æ•°æ®é›†ï¼Œå¹¶è®­ç»ƒäº†å¤šä¸ªæ¨¡åž‹ï¼Œå…¶ä¸­æœ€å¥½çš„æ¨¡åž‹KO-REAson-35Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æˆç»©ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯­è¨€æ··åˆçš„æ€ç»´é“¾æŽ¨ç†æ–¹æ³•æ¯”å•è¯­æŽ¨ç†æ–¹æ³•æ›´æœ‰æ•ˆï¼Œä¸”å¯¹ä¸­å°åž‹æ¨¡åž‹ä¹Ÿæœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚","title":"è¯­è¨€æ··åˆæŽ¨ç†ï¼Œæå‡éŸ©è¯­ä»»åŠ¡è¡¨çŽ°ï¼"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§è¯­è¨€æ··åˆçš„æ€ç»´é“¾æŽ¨ç†æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜éŸ©è¯­ç‰¹å®šä»»åŠ¡çš„è¡¨çŽ°ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨è‹±è¯­å’ŒéŸ©è¯­ä¹‹é—´åˆ‡æ¢ï¼Œåˆ©ç”¨è‹±è¯­ä½œä¸ºé”šç‚¹æ¥å¢žå¼ºæŽ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶å‡å°‘ç¿»è¯‘å¸¦æ¥çš„å¹²æ‰°ã€‚ç ”ç©¶ä¸­ä½¿ç”¨äº†åä¸ºYi-Sangçš„éŸ©è¯­æ•°æ®é›†ï¼Œå¹¶è®­ç»ƒäº†å¤šä¸ªæ¨¡åž‹ï¼Œå…¶ä¸­æœ€å¥½çš„æ¨¡åž‹KO-REAson-35Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æˆç»©ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯­è¨€æ··åˆçš„æ€ç»´é“¾æŽ¨ç†æ–¹æ³•æ¯”å•è¯­æŽ¨ç†æ–¹æ³•æ›´æœ‰æ•ˆï¼Œä¸”å¯¹ä¸­å°åž‹æ¨¡åž‹ä¹Ÿæœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚', title='è¯­è¨€æ··åˆæŽ¨ç†ï¼Œæå‡éŸ©è¯­ä»»åŠ¡è¡¨çŽ°ï¼'))
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#interpretability", "#hallucinations", "#benchmark"], "emoji": "â³", "ru": {"title": "ÐšÐ¾Ð³Ð´Ð° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸ ÑÑ‚Ð°Ñ€ÐµÑŽÑ‚: Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° ÑƒÑÑ‚Ð°Ñ€ÐµÐ²ÑˆÐ¸Ñ… Ñ‚ÐµÑÑ‚Ð¾Ð² Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ñ„Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ LLM", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ðµ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ñ„Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ LLM ÑƒÑÑ‚Ð°Ñ€ÐµÐ²Ð°ÑŽÑ‚ ÑÐ¾ Ð²Ñ€ÐµÐ¼ÐµÐ½ÐµÐ¼, Ñ‡Ñ‚Ð¾
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#dataset"], "emoji": "ðŸ”¬", "ru": {"title": "VTC-Bench: Ñ‡ÐµÑÑ‚Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° ÑÐ¶Ð°Ñ‚Ð¸Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ñ… LLM", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ VTC-Bench â€” Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ñ‡ÐµÑÑ‚Ð½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð² ÑÐ¶Ð°Ñ‚Ð¸Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð±Ð¾Ð»ÑŒÑˆ
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#interpretability", "#training", "#agents", "#optimization", "#robotics", "#diffusion"], "emoji": "ðŸ¤–", "ru": {"title": "Ð”Ð²Ð° Ñ‚Ð¾ÐºÐµÐ½Ð° Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¾Ð¼: ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð¼ÐµÑ‚Ð¾Ð´ StaMo Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ð¾Ð³Ð¾ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐ¾
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#games", "#multimodal", "#training", "#cv", "#optimization", "#open_source"], "emoji": "ðŸŽ¯", "ru": {"title": "ÐŸÑ€ÑÐ¼Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ñ‚Ð¾ÐºÐµÐ½Ñ‹-Ð¿Ð°Ñ‚Ñ‡Ð¸", "desc": "Ð’ ÑÑ‚Ð°Ñ‚ÑŒÐµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ PaDT â€” Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ð´Ð»Ñ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ñ… LLM, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#optimization", "#synthetic", "#cv", "#video"], "emoji": "ðŸ¤–", "ru": {"title": "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð·Ð°Ð¿ÑÑÑ‚ÑŒÑ Ð¸Ð· Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… ÐºÐ°Ð¼ÐµÑ€ Ð´Ð»Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¾Ð²", "desc": "WristWorld â€” ÑÑ‚Ð¾ 4D Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¼Ð¸Ñ€Ð°, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð¸Ð´ÐµÐ¾ Ñ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð·Ñ€ÐµÐ½Ð¸Ñ Ð·Ð°Ð¿ÑÑÑ‚ÑŒÑ Ñ€Ð¾Ð±Ð¾Ñ‚Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ñ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… ÑÑ‚Ð°Ñ†Ð¸Ð¾Ð½Ð°Ñ€Ð½Ñ‹Ñ… 
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#optimization", "#rl", "#multimodal", "#rlhf", "#cv", "#transfer_learning"], "emoji": "ðŸŽ¯", "ru": {"title": "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð½Ð° Ð»ÐµÑ‚Ñƒ: Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑƒÑ‡Ð°Ñ‚ÑÑ Ð¿Ñ€ÑÐ¼Ð¾ Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð¸ Ð¼ÐµÑ‚Ð¾Ð´ TTRV, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° Ñ‡ÐµÑ€
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#survey", "#optimization", "#dataset", "#benchmark", "#data", "#agents"], "emoji": "ðŸ­", "ru": {"title": "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ„Ð°Ð±Ñ€Ð¸ÐºÐ° ML-Ð·Ð°Ð´Ð°Ñ‡ Ð¸Ð· ÑÑ‹Ñ€Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ MLE-Smith â€” Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸-Ð°Ð³ÐµÐ½Ñ‚Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð¿
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#training"], "emoji": "ðŸ“Š", "ru": {"title": "Ð Ð°Ð²Ð½Ð¾Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ â€” ÐºÐ»ÑŽÑ‡ Ðº Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ LLM", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ð»Ð¸ Ð³Ð¸Ð¿Ð¾Ñ‚ÐµÐ·Ñƒ Ñ€Ð°Ð²Ð½Ð¾Ð¼ÐµÑ€Ð½Ð¾Ð¹ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ (UID) Ðº Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ Ñ†ÐµÐ¿Ð¾Ñ‡ÐµÐº Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹. ÐžÐ½Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#training", "#reasoning", "#rlhf", "#long_context", "#rl", "#optimization"], "emoji": "ðŸ§©", "ru": {"title": "ÐœÐ°Ñ€ÐºÐ¾Ð²ÑÐºÐ¾Ðµ Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸Ðµ: ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð±ÐµÐ· ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð·Ð°Ñ‚Ñ€Ð°Ñ‚", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Markovian Thinking Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Delethink â€” Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÑŽ ÑÐ·
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#dataset", "#training", "#data", "#multilingual", "#low_resource"], "emoji": "ðŸŒ", "ru": {"title": "ÐÑ„Ñ€Ð¸ÐºÐ°Ð½ÑÐºÐ¸Ðµ ÑÐ·Ñ‹ÐºÐ¸ Ð²Ñ‹Ñ…Ð¾Ð´ÑÑ‚ Ð¸Ð· Ñ‚ÐµÐ½Ð¸: Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð´Ð»Ñ NLP", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ ÑÐ¾Ð·Ð´Ð°Ð»Ð¸ African Languages Lab Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð°Ñ„Ñ€Ð¸ÐºÐ°Ð½ÑÐºÐ¸Ñ… ÑÐ·Ñ‹
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#games", "#alignment", "#rlhf", "#diffusion", "#optimization", "#training", "#rl"], "emoji": "ðŸŽ¯", "ru": {"title": "Ð¢Ð¾Ñ‡Ð½Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ‡ÐµÑ€ÐµÐ· Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Granular-GRPO Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#interpretability", "#video", "#benchmark", "#long_context"], "emoji": "ðŸŽ¬", "ru": {"title": "Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ð³Ñ€Ð°Ð½Ð¸Ñ† ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð² Ð²Ð¸Ð´ÐµÐ¾ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÑƒ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²ÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Online Generic Event Boundary Detection (On-GEBD) â€” Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#architecture", "#training", "#dataset", "#benchmark", "#video", "#diffusion", "#survey"], "emoji": "ðŸŽ¬", "ru": {"title": "ÐžÑ‚ GAN Ðº Diffusion: ÑÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¾Ð±Ð·Ð¾Ñ€ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° (text-to-video), Ð¿Ñ€Ð¾ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ñ Ð¸Ñ… Ñ€Ð°Ð·
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#training", "#agents"], "emoji": "ðŸ”„", "ru": {"title": "Ð¡Ð°Ð¼Ð¾ÑÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹: AlphaApollo Ð¿Ð¾Ð´Ð½Ð¸Ð¼Ð°ÐµÑ‚ Ð¿Ð¾Ñ‚Ð¾Ð»Ð¾Ðº Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÐµÐ¹ LLM", "desc": "AlphaApollo â€” ÑÑ‚Ð¾ ÑÐ°Ð¼Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð°ÑÑÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð³ÐµÐ½Ñ‚Ð½Ð¾Ð³Ð¾ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð´Ð²Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ found
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#cv", "#open_source", "#dataset", "#benchmark", "#optimization", "#survey"], "emoji": "ðŸ¥", "ru": {"title": "U-Bench: Ð²ÑÐµÑÑ‚Ð¾Ñ€Ð¾Ð½Ð½Ð¸Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ U-Net Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€ Ð² Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¾Ð¹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸", "desc": "U-Bench Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ÑÐ¾Ð±Ð¾Ð¹ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð½Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ U-Net
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#training", "#multilingual", "#architecture", "#benchmark", "#survey", "#dataset", "#low_resource"], "emoji": "ðŸ”€", "ru": {"title": "ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÑÐ·Ñ‹ÐºÐ¾Ð²: Ð²Ñ‹Ð·Ð¾Ð² Ð´Ð»Ñ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… LLM", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ÑÐ¾Ð±Ð¾Ð¹ Ð¾Ð±Ð·Ð¾Ñ€ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM), ÑÐ¿Ð¾ÑÐ¾Ð±
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#games", "#benchmark", "#cv"], "emoji": "ðŸ™", "ru": {"title": "ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ 2D Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð²Ð½Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹", "desc": "Heptapod â€” ÑÑ‚Ð¾ Ð°Ð²Ñ‚Ð¾Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð²Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ causal attention Ð¸
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "âš–ï¸", "ru": {"title": "Ð‘Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð¾Ñ€Ñ‚Ð¾Ð³Ð¾Ð½Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð¸ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑˆÐ°Ð³Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ NorMuon â€” Ð½Ð¾Ð²Ñ‹Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ð¾Ñ€Ñ‚Ð¾Ð³Ð¾Ð½Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ 
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#agents", "#games", "#reasoning", "#training", "#optimization", "#rl"], "emoji": "ðŸ—ºï¸", "ru": {"title": "ÐÐ²Ñ‚Ð¾Ð½Ð¾Ð¼Ð½Ñ‹Ð¹ AI-Ð°Ð³ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿ÑƒÑ‚ÐµÑˆÐµÑÑ‚Ð²Ð¸Ð¹ Ð¿Ñ€ÐµÐ²Ð¾ÑÑ…Ð¾Ð´Ð¸Ñ‚ frontier Ð¼Ð¾Ð´ÐµÐ»Ð¸", "desc": "DeepTravel â€” ÑÑ‚Ð¾ end-to-end Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ reinforcement learning Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð½Ð¾Ð¼Ð½Ð¾Ð³Ð¾ Ð¿Ð»Ð°Ð½
[09.10.2025 13:26] Using data from previous issue: {"categories": ["#security", "#synthetic", "#cv", "#dataset", "#inference"], "emoji": "ðŸ”", "ru": {"title": "ÐŸÐ¾Ð¸ÑÐº Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ‡ÐµÑ€ÐµÐ· Ð°Ð½Ð°Ð»Ð¸Ð· ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð¸ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ DÂ³QE Ð´Ð»Ñ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹, ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ autoregressive Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸. ÐœÐµÑ‚Ð¾Ð´ Ð°Ð½Ð°Ð»Ð¸
[09.10.2025 13:26] Renaming data file.
[09.10.2025 13:26] Renaming previous data. hf_papers.json to ./d/2025-10-09.json
[09.10.2025 13:26] Saving new data file.
[09.10.2025 13:26] Generating page.
[09.10.2025 13:26] Renaming previous page.
[09.10.2025 13:26] Renaming previous data. index.html to ./d/2025-10-09.html
[09.10.2025 13:26] Writing result.
[09.10.2025 13:26] Renaming log file.
[09.10.2025 13:26] Renaming previous data. log.txt to ./logs/2025-10-09_last_log.txt
