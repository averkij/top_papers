[21.07.2025 17:14] Read previous papers.
[21.07.2025 17:14] Generating top page (month).
[21.07.2025 17:14] Writing top page (month).
[21.07.2025 18:18] Read previous papers.
[21.07.2025 18:18] Get feed.
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.11097
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13563
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.14137
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.12566
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13984
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13158
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.10605
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.12455
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13302
[21.07.2025 18:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13391
[21.07.2025 18:18] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[21.07.2025 18:18] No deleted papers detected.
[21.07.2025 18:18] Downloading and parsing papers (pdf, html). Total: 10.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.11097.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.11097.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.11097.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.13563.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.13563.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.13563.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.14137.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.14137.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.14137.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.12566.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.12566.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.12566.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.13984.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.13984.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.13984.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.13158.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.13158.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.13158.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.10605.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.10605.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.10605.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.12455.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.12455.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.12455.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.13302.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.13302.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.13302.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Downloading and parsing paper https://huggingface.co/papers/2507.13391.
[21.07.2025 18:18] Extra JSON file exists (./assets/json/2507.13391.json), skip PDF parsing.
[21.07.2025 18:18] Paper image links file exists (./assets/img_data/2507.13391.json), skip HTML parsing.
[21.07.2025 18:18] Success.
[21.07.2025 18:18] Enriching papers with extra data.
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 0. DIJA is a framework that exploits safety weaknesses in diffusion-based large language models by constructing adversarial prompts, demonstrating significant vulnerabilities in their alignment mechanisms.  					AI-generated summary 				 Diffusion-based large language models (dLLMs) have recently emerg...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 1. Balalaika, a large Russian speech dataset with detailed annotations, improves performance in speech synthesis and enhancement tasks.  					AI-generated summary 				 Russian speech synthesis presents distinctive challenges, including vowel reduction, consonant devoicing, variable stress patterns, hom...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 2. Franca, an open-source vision foundation model, achieves high performance using a transparent training pipeline and novel clustering and disentanglement techniques.  					AI-generated summary 				 We present Franca (pronounced Fran-ka): free one; the first fully open-source (data, code, weights) vis...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 3. Mono-InternVL, an advanced monolithic Multimodal Large Language Model, integrates visual experts and improved pre-training strategies to enhance visual learning and reduce computational costs while maintaining competitive performance.  					AI-generated summary 				 This paper focuses on monolithic ...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 4. CSD-VAR, a Visual Autoregressive Modeling approach, enhances content-style decomposition by introducing scale-aware optimization, SVD-based rectification, and augmented K-V memory, outperforming diffusion models in content preservation and stylization.  					AI-generated summary 				 Disentangling c...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 5. A review of advancements in aligning large language models using inverse reinforcement learning, emphasizing challenges and opportunities in neural reward modeling and sparse-reward reinforcement learning.  					AI-generated summary 				 In the era of Large Language Models (LLMs), alignment has emer...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 6. RedOne, a domain-specific LLM, enhances performance across multiple SNS tasks through a three-stage training strategy, improving generalization and reducing harmful content exposure.  					AI-generated summary 				 As a primary medium for modern information dissemination, social networking services ...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 7. SENTINEL reduces hallucinations in multimodal large language models by iteratively generating and validating sentence-level outputs using in-domain preference learning and context-aware preference loss.  					AI-generated summary 				 Multimodal large language models (MLLMs) have revolutionized cros...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 8. GEA, a public arena that includes energy consumption data, shows that users often prefer smaller, more energy-efficient language models over larger, more complex ones.  					AI-generated summary 				 The evaluation of large language models is a complex task, in which several approaches have been pro...
[21.07.2025 18:18] ********************************************************************************
[21.07.2025 18:18] Abstract 9. This research presents a framework for quantitative risk management in volatile markets, specifically focusing on expectile-based methodologies applied to the FTSE 100 index. Traditional risk measures such as Value-at-Risk (VaR) have demonstrated significant limitations during periods of market stre...
[21.07.2025 18:18] Read previous papers.
[21.07.2025 18:18] Generating reviews via LLM API.
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#training", "#architecture", "#diffusion", "#alignment", "#security"], "emoji": "üïµÔ∏è", "ru": {"title": "–£—è–∑–≤–∏–º–æ—Å—Ç–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –Ω–æ–≤—ã–π —Ñ—Ä–æ–Ω—Ç –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ò–ò", "desc": "DIJA - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –≤ –º–µ—Ö–∞–Ω–∏
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#data", "#low_resource", "#dataset", "#audio", "#synthetic"], "emoji": "üéª", "ru": {"title": "Balalaika: –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —Ä–µ—á–µ–≤–æ–≥–æ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Balalaika. –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ 2000 —á
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#training", "#cv", "#optimization", "#dataset", "#architecture", "#open_source"], "emoji": "üëÅÔ∏è", "ru": {"title": "–û—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "Franca - —ç—Ç–æ –ø–µ—Ä–≤–∞—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#multimodal", "#training", "#architecture", "#agi", "#optimization", "#benchmark"], "emoji": "üß†", "ru": {"title": "Mono-InternVL: –ú–æ–Ω–æ–ª–∏—Ç–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –≤–∏–∑—É–∞–ª—å–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º", "desc": "Mono-InternVL - —ç—Ç–æ —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω–∞—è –º–æ–Ω–æ–ª–∏—Ç–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –±–æ–ª—å—à–∞—è
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#benchmark", "#synthetic", "#cv"], "emoji": "üé®", "ru": {"title": "CSD-VAR: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ —Å—Ç–∏–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "CSD-VAR - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≤–∏–∑—É–∞–ª—å–Ω–æ–º—É –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é –¥–ª—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ —Å—Ç–∏–ª—è –∏–∑–æ–±—Ä–∞–∂–µ
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#rlhf", "#training", "#rl", "#survey", "#benchmark", "#alignment"], "emoji": "üß†", "ru": {"title": "–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –ø—Ä–∏–∑–º—É –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±–∑–æ—Ä –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π 
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#training", "#alignment", "#optimization", "#dataset", "#multilingual", "#science"], "emoji": "üöÄ", "ru": {"title": "RedOne: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä–µ–≤–æ–ª—é—Ü–∏–∏ –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö", "desc": "RedOne - —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è —Å
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#hallucinations", "#multimodal", "#open_source", "#benchmark", "#data", "#training"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ó–∞—â–∏—Ç–∞ –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª—è—Ö", "desc": "SENTINEL - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. –û–Ω –∏—Å–ø–æ
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#ethics", "#dataset", "#benchmark", "#small_models", "#optimization"], "emoji": "üåø", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–µ–µ —Ä–∞–∑–º–µ—Ä–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –≤—ã–±–∏—Ä–∞—é—Ç —ç–Ω–µ—Ä–≥–æ—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ GEA (Generative Energy Arena) - –ø—É–±–ª–∏—á–Ω–∞—è –∞—Ä–µ–Ω–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã
[21.07.2025 18:18] Using data from previous issue: {"categories": ["#dataset", "#math"], "emoji": "üìä", "ru": {"title": "–≠–∫—Å–ø–µ–∫—Ç–∏–ª—å-–±–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏: –Ω–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Ä—ã–Ω–∫–æ–≤", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–∏—Å–∫–∞–º–∏ –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Ä—ã–Ω–∫–∞—Ö, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ —ç–∫—Å–ø–µ–∫—Ç–∏–ª–µ–π, –ø—Ä–∏–º–µ–Ω—è–µ–º–æ–π 
[21.07.2025 18:18] Renaming data file.
[21.07.2025 18:18] Renaming previous data. hf_papers.json to ./d/2025-07-21.json
[21.07.2025 18:18] Saving new data file.
[21.07.2025 18:18] Generating page.
[21.07.2025 18:18] Renaming previous page.
[21.07.2025 18:18] Renaming previous data. index.html to ./d/2025-07-21.html
[21.07.2025 18:18] Writing result.
[21.07.2025 18:18] Renaming log file.
[21.07.2025 18:18] Renaming previous data. log.txt to ./logs/2025-07-21_last_log.txt
