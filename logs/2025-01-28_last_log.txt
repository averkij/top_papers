[28.01.2025 08:13] Read previous papers.
[28.01.2025 08:13] Generating top page (month).
[28.01.2025 08:13] Writing top page (month).
[28.01.2025 09:10] Read previous papers.
[28.01.2025 09:10] Get feed.
[28.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.15368
[28.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.15383
[28.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.15570
[28.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.16142
[28.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.15369
[28.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.16295
[28.01.2025 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.14912
[28.01.2025 09:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.01.2025 09:10] No deleted papers detected.
[28.01.2025 09:10] Downloading and parsing papers (pdf, html). Total: 7.
[28.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.15368.
[28.01.2025 09:10] Extra JSON file exists (./assets/json/2501.15368.json), skip PDF parsing.
[28.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.15368.json), skip HTML parsing.
[28.01.2025 09:10] Success.
[28.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.15383.
[28.01.2025 09:10] Extra JSON file exists (./assets/json/2501.15383.json), skip PDF parsing.
[28.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.15383.json), skip HTML parsing.
[28.01.2025 09:10] Success.
[28.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.15570.
[28.01.2025 09:10] Extra JSON file exists (./assets/json/2501.15570.json), skip PDF parsing.
[28.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.15570.json), skip HTML parsing.
[28.01.2025 09:10] Success.
[28.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.16142.
[28.01.2025 09:10] Extra JSON file exists (./assets/json/2501.16142.json), skip PDF parsing.
[28.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.16142.json), skip HTML parsing.
[28.01.2025 09:10] Success.
[28.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.15369.
[28.01.2025 09:10] Extra JSON file exists (./assets/json/2501.15369.json), skip PDF parsing.
[28.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.15369.json), skip HTML parsing.
[28.01.2025 09:10] Success.
[28.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.16295.
[28.01.2025 09:10] Extra JSON file exists (./assets/json/2501.16295.json), skip PDF parsing.
[28.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.16295.json), skip HTML parsing.
[28.01.2025 09:10] Success.
[28.01.2025 09:10] Downloading and parsing paper https://huggingface.co/papers/2501.14912.
[28.01.2025 09:10] Extra JSON file exists (./assets/json/2501.14912.json), skip PDF parsing.
[28.01.2025 09:10] Paper image links file exists (./assets/img_data/2501.14912.json), skip HTML parsing.
[28.01.2025 09:10] Success.
[28.01.2025 09:10] Enriching papers with extra data.
[28.01.2025 09:10] ********************************************************************************
[28.01.2025 09:10] Abstract 0. We introduce Baichuan-Omni-1.5, an omni-modal model that not only has omni-modal understanding capabilities but also provides end-to-end audio generation capabilities. To achieve fluent and high-quality interaction across modalities without compromising the capabilities of any modality, we prioritiz...
[28.01.2025 09:10] ********************************************************************************
[28.01.2025 09:10] Abstract 1. We introduce Qwen2.5-1M, a series of models that extend the context length to 1 million tokens. Compared to the previous 128K version, the Qwen2.5-1M series have significantly enhanced long-context capabilities through long-context pre-training and post-training. Key techniques such as long data syn...
[28.01.2025 09:10] ********************************************************************************
[28.01.2025 09:10] Abstract 2. As is known, hybrid quadratic and subquadratic attention models in multi-head architectures have surpassed both Transformer and Linear RNN models , with these works primarily focusing on reducing KV complexity and improving efficiency. For further research on expressiveness, we introduce our series ...
[28.01.2025 09:10] ********************************************************************************
[28.01.2025 09:10] Abstract 3. Reinforcement learning (RL) promises a framework for near-universal problem-solving. In practice however, RL algorithms are often tailored to specific benchmarks, relying on carefully tuned hyperparameters and algorithmic choices. Recently, powerful model-based RL methods have shown impressive gener...
[28.01.2025 09:10] ********************************************************************************
[28.01.2025 09:10] Abstract 4. We present a new family of mobile hybrid vision networks, called iFormer, with a focus on optimizing latency and accuracy on mobile applications. iFormer effectively integrates the fast local representation capacity of convolution with the efficient global modeling ability of self-attention. The loc...
[28.01.2025 09:10] ********************************************************************************
[28.01.2025 09:10] Abstract 5. State Space Models (SSMs) have emerged as efficient alternatives to Transformers for sequential modeling, but their inability to leverage modality-specific features limits their performance in multi-modal pretraining. Here, we propose Mixture-of-Mamba, a novel SSM architecture that introduces modali...
[28.01.2025 09:10] ********************************************************************************
[28.01.2025 09:10] Abstract 6. We introduce Feasible Learning (FL), a sample-centric learning paradigm where models are trained by solving a feasibility problem that bounds the loss for each training sample. In contrast to the ubiquitous Empirical Risk Minimization (ERM) framework, which optimizes for average performance, FL dema...
[28.01.2025 09:10] Read previous papers.
[28.01.2025 09:10] Generating reviews via LLM API.
[28.01.2025 09:10] Using data from previous issue: {"categories": ["#data", "#optimization", "#dataset", "#training", "#audio", "#multimodal"], "emoji": "üé≠", "ru": {"title": "Baichuan-Omni-1.5: –ü—Ä–æ—Ä—ã–≤ –≤ –æ–º–Ω–∏–º–æ–¥–∞–ª—å–Ω–æ–º –ò–ò", "desc": "Baichuan-Omni-1.5 - —ç—Ç–æ –æ–º–Ω–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, –æ–±–ª–∞–¥–∞—é—â–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ. –î–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∫–∞—á–µ—Å
[28.01.2025 09:10] Using data from previous issue: {"categories": ["#architecture", "#inference", "#long_context", "#training", "#open_source"], "emoji": "üöÄ", "ru": {"title": "–ú–∏–ª–ª–∏–æ–Ω —Ç–æ–∫–µ–Ω–æ–≤: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–µ—Ä–∏—é –º–æ–¥–µ–ª–µ–π Qwen2.5-1M —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –æ–∫–Ω–æ–º –≤ 1 –º–∏–ª–ª–∏–æ–Ω —Ç–æ–∫–µ–Ω–æ–≤. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω–∏–ª–∏ —Ç–µ—Ö–Ω–∏–∫–∏ —Å–∏–Ω
[28.01.2025 09:10] Using data from previous issue: {"categories": ["#transfer_learning", "#training", "#architecture", "#small_models", "#optimization", "#open_source"], "emoji": "üß†", "ru": {"title": "–ü–æ–≤—ã—à–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RNN —á–µ—Ä–µ–∑ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—é –∑–Ω–∞–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ —á–∏—Å—Ç–æ–º –Ω–∞—Ç–∏–≤–Ω–æ–º –≤–Ω–∏–º
[28.01.2025 09:10] Using data from previous issue: {"categories": ["#optimization", "#rl", "#benchmark", "#training", "#games"], "emoji": "ü§ñ", "ru": {"title": "MR.Q: –ù–∞ –ø—É—Ç–∏ –∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º MR.Q. –≠—Ç–æ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª—å
[28.01.2025 09:10] Using data from previous issue: {"categories": ["#optimization", "#training", "#cv", "#architecture"], "emoji": "üì±", "ru": {"title": "iFormer: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è", "desc": "iFormer - —ç—Ç–æ –Ω–æ–≤–æ–µ —Å–µ–º–µ–π—Å—Ç–≤–æ –º–æ–±–∏–ª—å–Ω—ã—Ö –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Å–µ—Ç–µ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.
[28.01.2025 09:10] Using data from previous issue: {"categories": ["#multimodal", "#architecture", "#benchmark"], "emoji": "üß†", "ru": {"title": "Mixture-of-Mamba: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å-—Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–æ–π —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å—é", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–π (SSM) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Mixture-of-Mamb
[28.01.2025 09:10] Using data from previous issue: {"categories": ["#training", "#optimization"], "emoji": "üéØ", "ru": {"title": "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–∞–∂–¥–æ–º—É –æ–±—Ä–∞–∑—Ü—É –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è - Feasible Learning (FL). –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–≥–æ —Ä–∏—Å
[28.01.2025 09:10] Trying to get texts in Chinese.
[28.01.2025 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

We introduce Baichuan-Omni-1.5, an omni-modal model that not only has omni-modal understanding capabilities but also provides end-to-end audio generation capabilities. To achieve fluent and high-quality interaction across modalities without compromising the capabilities of any modality, we prioritized optimizing three key aspects. First, we establish a comprehensive data cleaning and synthesis pipeline for multimodal data, obtaining about 500B high-quality data (text, audio, and vision). Second, an audio-tokenizer (Baichuan-Audio-Tokenizer) has been designed to capture both semantic and acoustic information from audio, enabling seamless integration and enhanced compatibility with MLLM. Lastly, we designed a multi-stage training strategy that progressively integrates multimodal alignment and multitask fine-tuning, ensuring effective synergy across all modalities. Baichuan-Omni-1.5 leads contemporary models (including GPT4o-mini and MiniCPM-o 2.6) in terms of comprehensive omni-modal capabilities. Notably, it achieves results comparable to leading models such as Qwen2-VL-72B across various multimodal medical benchmarks.
[28.01.2025 09:10] Mistral response. {"id": "cc1e7b95ccf140b38f6558e1f96e2591", "object": "chat.completion", "created": 1738055454, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u6211\u4eec\u4ecb\u7ecd\u4e86 Baichuan-Omni-1.5\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709\u5168\u6a21\u6001\u7406\u89e3\u548c\u7aef\u5230\u7aef\u97f3\u9891\u751f\u6210\u80fd\u529b\u7684\u6a21\u578b\u3002\u4e3a\u4e86\u5b9e\u73b0\u6d41\u7545\u7684\u9ad8\u8d28\u91cf\u8de8\u6a21\u6001\u4ea4\u4e92\uff0c\u6211\u4eec\u4f18\u5316\u4e86\u4e09\u4e2a\u5173\u952e\u65b9\u9762\u3002\u9996\u5148\uff0c\u6211\u4eec\u5efa\u7acb\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6570\u636e\u6e05\u6d17\u548c\u5408\u6210\u7ba1\u9053\uff0c\u83b7\u5f97\u4e86\u5927\u7ea6 500B \u7684\u9ad8\u8d28\u91cf\u6570\u636e\uff08\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u89c9\uff09\u3002\u5176\u6b21\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u97f3\u9891\u5206\u8bcd\u5668\uff0c\u6355\u6349\u97f3\u9891\u7684\u8bed\u4e49\u548c\u58f0\u5b66\u4fe1\u606f\u3002\u6700\u540e\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u786e\u4fdd\u6240\u6709\u6a21\u6001\u7684\u6709\u6548\u534f\u540c\u3002Baichuan-Omni-1.5 \u5728\u5168\u6a21\u6001\u80fd\u529b\u65b9\u9762\u9886\u5148\u4e8e\u5f53\u524d\u6a21\u578b\uff0c\u5e76\u5728\u591a\u4e2a\u591a\u6a21\u6001\u533b\u7597\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u53ef\u6bd4\u7684\u7ed3\u679c\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 299, "total_tokens": 532, "completion_tokens": 233}}
[28.01.2025 09:10] Response: Êàë‰ª¨‰ªãÁªç‰∫Ü Baichuan-Omni-1.5ÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÂÖ®Ê®°ÊÄÅÁêÜËß£ÂíåÁ´ØÂà∞Á´ØÈü≥È¢ëÁîüÊàêËÉΩÂäõÁöÑÊ®°Âûã„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞ÊµÅÁïÖÁöÑÈ´òË¥®ÈáèË∑®Ê®°ÊÄÅ‰∫§‰∫íÔºåÊàë‰ª¨‰ºòÂåñ‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÊï∞ÊçÆÊ∏ÖÊ¥óÂíåÂêàÊàêÁÆ°ÈÅìÔºåËé∑Âæó‰∫ÜÂ§ßÁ∫¶ 500B ÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÔºàÊñáÊú¨„ÄÅÈü≥È¢ëÂíåËßÜËßâÔºâ„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Èü≥È¢ëÂàÜËØçÂô®ÔºåÊçïÊçâÈü≥È¢ëÁöÑËØ≠‰πâÂíåÂ£∞Â≠¶‰ø°ÊÅØ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â§öÈò∂ÊÆµËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁ°Æ‰øùÊâÄÊúâÊ®°ÊÄÅÁöÑÊúâÊïàÂçèÂêå„ÄÇBaichuan-Omni-1.5 Âú®ÂÖ®Ê®°ÊÄÅËÉΩÂäõÊñπÈù¢È¢ÜÂÖà‰∫éÂΩìÂâçÊ®°ÂûãÔºåÂπ∂Âú®Â§ö‰∏™Â§öÊ®°ÊÄÅÂåªÁñóÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÂèØÊØîÁöÑÁªìÊûú„ÄÇ
[28.01.2025 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

Êàë‰ª¨‰ªãÁªç‰∫Ü Baichuan-Omni-1.5ÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÂÖ®Ê®°ÊÄÅÁêÜËß£ÂíåÁ´ØÂà∞Á´ØÈü≥È¢ëÁîüÊàêËÉΩÂäõÁöÑÊ®°Âûã„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞ÊµÅÁïÖÁöÑÈ´òË¥®ÈáèË∑®Ê®°ÊÄÅ‰∫§‰∫íÔºåÊàë‰ª¨‰ºòÂåñ‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÊï∞ÊçÆÊ∏ÖÊ¥óÂíåÂêàÊàêÁÆ°ÈÅìÔºåËé∑Âæó‰∫ÜÂ§ßÁ∫¶ 500B ÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÔºàÊñáÊú¨„ÄÅÈü≥È¢ëÂíåËßÜËßâÔºâ„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Èü≥È¢ëÂàÜËØçÂô®ÔºåÊçïÊçâÈü≥È¢ëÁöÑËØ≠‰πâÂíåÂ£∞Â≠¶‰ø°ÊÅØ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â§öÈò∂ÊÆµËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁ°Æ‰øùÊâÄÊúâÊ®°ÊÄÅÁöÑÊúâÊïàÂçèÂêå„ÄÇBaichuan-Omni-1.5 Âú®ÂÖ®Ê®°ÊÄÅËÉΩÂäõÊñπÈù¢È¢ÜÂÖà‰∫éÂΩìÂâçÊ®°ÂûãÔºåÂπ∂Âú®Â§ö‰∏™Â§öÊ®°ÊÄÅÂåªÁñóÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÂèØÊØîÁöÑÁªìÊûú„ÄÇ
[28.01.2025 09:11] Mistral response. {"id": "cbe29afbc9d644c0aefd7819930d70ae", "object": "chat.completion", "created": 1738055459, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "W\u01d2men ji\u00e8sh\u00e0o le Baichuan-Omni-1.5, zh\u00e8 sh\u00ec y\u012bg\u00e8 j\u00f9y\u01d2u qu\u00e1n m\u00f3sh\u00ec l\u01d0ji\u011b h\u00e9 du\u0101n d\u00e0o du\u0101n y\u012bnpi\u00e0n sh\u0113ngch\u00e9ng n\u00e9ngl\u00ec de m\u00f3x\u00edng. W\u00e8ile sh\u00edxi\u00e0n li\u00fach\u00e0ng de g\u0101o zh\u00ecli\u00e0ng ku\u00e0 m\u00f3sh\u00ec ji\u0101oh\u00f9, w\u01d2men y\u014duhu\u00e0 le s\u0101n g\u00e8 gu\u01cenji\u00e0n f\u0101ngc\u00e8. Sh\u01d2uxi\u0101n, w\u01d2men ji\u00e0nl\u00ec le y\u012bg\u00e8 qu\u00e1nmi\u00e0n de sh\u00f9j\u00f9 q\u012bngx\u012b h\u00e9 h\u00e9ch\u00e9ng gu\u01cend\u01ceo, hu\u00f2d\u00e9 le d\u00e0yu\u0113 500B de g\u0101o zh\u00ecli\u00e0ng sh\u00f9j\u00f9 (w\u00e9nb\u011bn, y\u012bnpi\u00e0n h\u00e9 sh\u00ecju\u00e9). Q\u00edc\u00ec, w\u01d2men sh\u00e8j\u00ec le y\u012bg\u00e8 y\u012bnpi\u00e0n f\u0113nc\u00edq\u00ec, b\u012bngzhu\u014d y\u012bnpi\u00e0n de y\u01d4y\u00ec h\u00e9 sh\u0113ngxu\u00e9 x\u00ecnx\u012b. Zu\u00ech\u00f2u, w\u01d2men sh\u00e8j\u00ec le y\u012bg\u00e8 du\u014d ji\u0113du\u00e0n x\u00f9nli\u00e0n c\u00e8l\u00fc\u00e8, qu\u00e8b\u01ceo su\u01d2y\u01d2u m\u00f3sh\u00ec de y\u01d2uxi\u00e0o xi\u00e9t\u00f3ng. Baichuan-Omni-1.5 z\u00e0i qu\u00e1n m\u00f3sh\u00ec n\u00e9ngl\u00ec f\u0101ngmi\u00e0n l\u01d0ngxi\u0101n y\u00fa d\u0101ngqi\u00e1n m\u00f3x\u00edng, b\u00ecng z\u00e0i du\u014d g\u00e8 du\u014d m\u00f3sh\u00ec y\u012bli\u00e1o j\u012bzh\u01d4n sh\u00e0ng qud\u00e9 le k\u011bb\u01d0 de ji\u00e9gu\u01d2."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 248, "total_tokens": 698, "completion_tokens": 450}}
[28.01.2025 09:11] Response: W«ímen ji√®sh√†o le Baichuan-Omni-1.5, zh√® sh√¨ yƒ´g√® j√πy«íu qu√°n m√≥sh√¨ l«êjiƒõ h√© duƒÅn d√†o duƒÅn yƒ´npi√†n shƒìngch√©ng n√©ngl√¨ de m√≥x√≠ng. W√®ile sh√≠xi√†n li√∫ch√†ng de gƒÅo zh√¨li√†ng ku√† m√≥sh√¨ jiƒÅoh√π, w«ímen y≈çuhu√† le sƒÅn g√® gu«énji√†n fƒÅngc√®. Sh«íuxiƒÅn, w«ímen ji√†nl√¨ le yƒ´g√® qu√°nmi√†n de sh√πj√π qƒ´ngxƒ´ h√© h√©ch√©ng gu«énd«éo, hu√≤d√© le d√†yuƒì 500B de gƒÅo zh√¨li√†ng sh√πj√π (w√©nbƒõn, yƒ´npi√†n h√© sh√¨ju√©). Q√≠c√¨, w«ímen sh√®j√¨ le yƒ´g√® yƒ´npi√†n fƒìnc√≠q√¨, bƒ´ngzhu≈ç yƒ´npi√†n de y«îy√¨ h√© shƒìngxu√© x√¨nxƒ´. Zu√¨h√≤u, w«ímen sh√®j√¨ le yƒ´g√® du≈ç jiƒìdu√†n x√πnli√†n c√®l√º√®, qu√®b«éo su«íy«íu m√≥sh√¨ de y«íuxi√†o xi√©t√≥ng. Baichuan-Omni-1.5 z√†i qu√°n m√≥sh√¨ n√©ngl√¨ fƒÅngmi√†n l«êngxiƒÅn y√∫ dƒÅngqi√°n m√≥x√≠ng, b√¨ng z√†i du≈ç g√® du≈ç m√≥sh√¨ yƒ´li√°o jƒ´zh«în sh√†ng qud√© le kƒõb«ê de ji√©gu«í.
[28.01.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

Êàë‰ª¨‰ªãÁªç‰∫Ü Baichuan-Omni-1.5ÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÂÖ®Ê®°ÊÄÅÁêÜËß£ÂíåÁ´ØÂà∞Á´ØÈü≥È¢ëÁîüÊàêËÉΩÂäõÁöÑÊ®°Âûã„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞ÊµÅÁïÖÁöÑÈ´òË¥®ÈáèË∑®Ê®°ÊÄÅ‰∫§‰∫íÔºåÊàë‰ª¨‰ºòÂåñ‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÊï∞ÊçÆÊ∏ÖÊ¥óÂíåÂêàÊàêÁÆ°ÈÅìÔºåËé∑Âæó‰∫ÜÂ§ßÁ∫¶ 500B ÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÔºàÊñáÊú¨„ÄÅÈü≥È¢ëÂíåËßÜËßâÔºâ„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Èü≥È¢ëÂàÜËØçÂô®ÔºåÊçïÊçâÈü≥È¢ëÁöÑËØ≠‰πâÂíåÂ£∞Â≠¶‰ø°ÊÅØ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â§öÈò∂ÊÆµËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁ°Æ‰øùÊâÄÊúâÊ®°ÊÄÅÁöÑÊúâÊïàÂçèÂêå„ÄÇBaichuan-Omni-1.5 Âú®ÂÖ®Ê®°ÊÄÅËÉΩÂäõÊñπÈù¢È¢ÜÂÖà‰∫éÂΩìÂâçÊ®°ÂûãÔºåÂπ∂Âú®Â§ö‰∏™Â§öÊ®°ÊÄÅÂåªÁñóÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÂèØÊØîÁöÑÁªìÊûú„ÄÇ
[28.01.2025 09:11] Mistral response. {"id": "a1e5cdddd6494f0785c60e1494f78080", "object": "chat.completion", "created": 1738055468, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[{'word': '\u4ecb\u7ecd', 'pinyin': 'ji\u00e8 sh\u00e0o', 'trans': 'introduce'},\n{'word': 'Baichuan-Omni-1.5', 'pinyin': 'B\u00e0i chu\u0101n-\u014cu m\u00ed-1.5', 'trans': 'Baichuan-Omni-1.5'},\n{'word': '\u5177\u6709', 'pinyin': 'j\u00f9 y\u01d2u', 'trans': 'have'},\n{'word': '\u5168\u6a21\u6001', 'pinyin': 'qu\u00e1n m\u00f3 sh\u00ec', 'trans': 'full modality'},\n{'word': '\u7406\u89e3', 'pinyin': 'l\u01d0 ji\u011b', 'trans': 'understanding'},\n{'word': '\u7aef\u5230\u7aef', 'pinyin': 'du\u0101n d\u00e0o du\u0101n', 'trans': 'end-to-end'},\n{'word': '\u97f3\u9891', 'pinyin': 'y\u012bn p\u00edn', 'trans': 'audio'},\n{'word': '\u751f\u6210', 'pinyin': 'sh\u0113ng ch\u00e9ng', 'trans': 'generate'},\n{'word': '\u80fd\u529b', 'pinyin': 'n\u00e9ng l\u00ec', 'trans': 'ability'},\n{'word': '\u5b9e\u73b0', 'pinyin': 'sh\u00ed xi\u00e0n', 'trans': 'achieve'},\n{'word': '\u6d41\u7545', 'pinyin': 'li\u00fa ch\u00e0ng', 'trans': 'smooth'},\n{'word': '\u9ad8\u8d28\u91cf', 'pinyin': 'g\u0101o zh\u00ec li\u00e0ng', 'trans': 'high quality'},\n{'word': '\u8de8\u6a21\u6001', 'pinyin': 'ku\u00e0 m\u00f3 sh\u00ec', 'trans': 'cross-modality'},\n{'word': '\u4ea4\u4e92', 'pinyin': 'ji\u0101o h\u00f9', 'trans': 'interaction'},\n{'word': '\u4f18\u5316', 'pinyin': 'y\u014du hu\u00e0', 'trans': 'optimize'},\n{'word': '\u5173\u952e', 'pinyin': 'gu\u01cen ji\u00e0n', 'trans': 'key'},\n{'word': '\u65b9\u9762', 'pinyin': 'f\u0101ng mi\u00e0n', 'trans': 'aspect'},\n{'word': '\u5efa\u7acb', 'pinyin': 'ji\u00e0n l\u00ec', 'trans': 'establish'},\n{'word': '\u5168\u9762', 'pinyin': 'qu\u00e1n mi\u00e0n', 'trans': 'comprehensive'},\n{'word': '\u6570\u636e', 'pinyin': 'sh\u00f9 j\u00f9', 'trans': 'data'},\n{'word': '\u6e05\u6d17', 'pinyin': 'q\u012bng x\u01d0', 'trans': 'clean'},\n{'word': '\u5408\u6210', 'pinyin': 'h\u00e9 ch\u00e9ng', 'trans': 'synthesize'},\n{'word': '\u7ba1\u9053', 'pinyin': 'gu\u01cen d\u00e0o', 'trans': 'pipeline'},\n{'word': '\u83b7\u5f97', 'pinyin': 'hu\u00f2 d\u00e9', 'trans': 'obtain'},\n{'word': '\u5927\u7ea6', 'pinyin': 'd\u00e0 yu\u0113', 'trans': 'about'},\n{'word': '\u6587\u672c', 'pinyin': 'w\u00e9n b\u011bn', 'trans': 'text'},\n{'word': '\u89c6\u89c9', 'pinyin': 'sh\u00ec ju\u00e9', 'trans': 'visual'},\n{'word': '\u8bbe\u8ba1', 'pinyin': 'sh\u00e8 j\u00ec', 'trans': 'design'},\n{'word': '\u5206\u8bcd\u5668', 'pinyin': 'f\u0113n c\u00ed q\u00ec', 'trans': 'tokenizer'},\n{'word': '\u6355\u6349', 'pinyin': 'b\u01d4 zhu\u014d', 'trans': 'capture'},\n{'word': '\u8bed\u4e49', 'pinyin': 'y\u01d4 y\u00ec', 'trans': 'semantics'},\n{'word': '\u58f0\u5b66', 'pinyin': 'sh\u0113ng xu\u00e9', 'trans': 'acoustics'},\n{'word': '\u4fe1\u606f', 'pinyin': 'x\u00ecn x\u012b', 'trans': 'information'},\n{'word': '\u591a\u9636\u6bb5', 'pinyin': 'du\u014d ji\u0113 du\u00e0n', 'trans': 'multi-stage'},\n{'word': '\u8bad\u7ec3', 'pinyin': 'x\u00f9n li\u00e0n', 'trans': 'training'},\n{'word': '\u7b56\u7565', 'pinyin': 'c\u00e8 l\u00fc\u00e8', 'trans': 'strategy'},\n{'word': '\u786e\u4fdd', 'pinyin': 'qu\u00e8 b\u01ceo', 'trans': 'ensure'},\n{'word': '\u6709\u6548', 'pinyin': 'y\u01d2u xi\u00e0o', 'trans': 'effective'},\n{'word': '\u534f\u540c', 'pinyin': 'xi\u00e9 t\u00f3ng', 'trans': 'coordination'},\n{'word': '\u9886\u5148', 'pinyin': 'l\u01d0ng xi\u0101n', 'trans': 'lead'},\n{'word': '\u5f53\u524d', 'pinyin': 'd\u0101ng qi\u00e1n', 'trans': 'current'},\n{'word': '\u57fa\u51c6', 'pinyin': 'j\u012b zh\u01d4n', 'trans': 'benchmark'},\n{'word': '\u53d6\u5f97', 'pinyin': 'q\u01d4 d\u00e9', 'trans': 'achieve'},\n{'word': '\u53ef\u6bd4', 'pinyin': 'k\u011b b\u01d0', 'trans': 'comparable'},\n{'word': '\u7ed3\u679c', 'pinyin': 'ji\u00e9 gu\u01d2', 'trans': 'result'}]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 280, "total_tokens": 1550, "completion_tokens": 1270}}
[28.01.2025 09:11] Response: [{'word': '‰ªãÁªç', 'pinyin': 'ji√® sh√†o', 'trans': 'introduce'},
{'word': 'Baichuan-Omni-1.5', 'pinyin': 'B√†i chuƒÅn-≈åu m√≠-1.5', 'trans': 'Baichuan-Omni-1.5'},
{'word': 'ÂÖ∑Êúâ', 'pinyin': 'j√π y«íu', 'trans': 'have'},
{'word': 'ÂÖ®Ê®°ÊÄÅ', 'pinyin': 'qu√°n m√≥ sh√¨', 'trans': 'full modality'},
{'word': 'ÁêÜËß£', 'pinyin': 'l«ê jiƒõ', 'trans': 'understanding'},
{'word': 'Á´ØÂà∞Á´Ø', 'pinyin': 'duƒÅn d√†o duƒÅn', 'trans': 'end-to-end'},
{'word': 'Èü≥È¢ë', 'pinyin': 'yƒ´n p√≠n', 'trans': 'audio'},
{'word': 'ÁîüÊàê', 'pinyin': 'shƒìng ch√©ng', 'trans': 'generate'},
{'word': 'ËÉΩÂäõ', 'pinyin': 'n√©ng l√¨', 'trans': 'ability'},
{'word': 'ÂÆûÁé∞', 'pinyin': 'sh√≠ xi√†n', 'trans': 'achieve'},
{'word': 'ÊµÅÁïÖ', 'pinyin': 'li√∫ ch√†ng', 'trans': 'smooth'},
{'word': 'È´òË¥®Èáè', 'pinyin': 'gƒÅo zh√¨ li√†ng', 'trans': 'high quality'},
{'word': 'Ë∑®Ê®°ÊÄÅ', 'pinyin': 'ku√† m√≥ sh√¨', 'trans': 'cross-modality'},
{'word': '‰∫§‰∫í', 'pinyin': 'jiƒÅo h√π', 'trans': 'interaction'},
{'word': '‰ºòÂåñ', 'pinyin': 'y≈çu hu√†', 'trans': 'optimize'},
{'word': 'ÂÖ≥ÈîÆ', 'pinyin': 'gu«én ji√†n', 'trans': 'key'},
{'word': 'ÊñπÈù¢', 'pinyin': 'fƒÅng mi√†n', 'trans': 'aspect'},
{'word': 'Âª∫Á´ã', 'pinyin': 'ji√†n l√¨', 'trans': 'establish'},
{'word': 'ÂÖ®Èù¢', 'pinyin': 'qu√°n mi√†n', 'trans': 'comprehensive'},
{'word': 'Êï∞ÊçÆ', 'pinyin': 'sh√π j√π', 'trans': 'data'},
{'word': 'Ê∏ÖÊ¥ó', 'pinyin': 'qƒ´ng x«ê', 'trans': 'clean'},
{'word': 'ÂêàÊàê', 'pinyin': 'h√© ch√©ng', 'trans': 'synthesize'},
{'word': 'ÁÆ°ÈÅì', 'pinyin': 'gu«én d√†o', 'trans': 'pipeline'},
{'word': 'Ëé∑Âæó', 'pinyin': 'hu√≤ d√©', 'trans': 'obtain'},
{'word': 'Â§ßÁ∫¶', 'pinyin': 'd√† yuƒì', 'trans': 'about'},
{'word': 'ÊñáÊú¨', 'pinyin': 'w√©n bƒõn', 'trans': 'text'},
{'word': 'ËßÜËßâ', 'pinyin': 'sh√¨ ju√©', 'trans': 'visual'},
{'word': 'ËÆæËÆ°', 'pinyin': 'sh√® j√¨', 'trans': 'design'},
{'word': 'ÂàÜËØçÂô®', 'pinyin': 'fƒìn c√≠ q√¨', 'trans': 'tokenizer'},
{'word': 'ÊçïÊçâ', 'pinyin': 'b«î zhu≈ç', 'trans': 'capture'},
{'word': 'ËØ≠‰πâ', 'pinyin': 'y«î y√¨', 'trans': 'semantics'},
{'word': 'Â£∞Â≠¶', 'pinyin': 'shƒìng xu√©', 'trans': 'acoustics'},
{'word': '‰ø°ÊÅØ', 'pinyin': 'x√¨n xƒ´', 'trans': 'information'},
{'word': 'Â§öÈò∂ÊÆµ', 'pinyin': 'du≈ç jiƒì du√†n', 'trans': 'multi-stage'},
{'word': 'ËÆ≠ÁªÉ', 'pinyin': 'x√πn li√†n', 'trans': 'training'},
{'word': 'Á≠ñÁï•', 'pinyin': 'c√® l√º√®', 'trans': 'strategy'},
{'word': 'Á°Æ‰øù', 'pinyin': 'qu√® b«éo', 'trans': 'ensure'},
{'word': 'ÊúâÊïà', 'pinyin': 'y«íu xi√†o', 'trans': 'effective'},
{'word': 'ÂçèÂêå', 'pinyin': 'xi√© t√≥ng', 'trans': 'coordination'},
{'word': 'È¢ÜÂÖà', 'pinyin': 'l«êng xiƒÅn', 'trans': 'lead'},
{'word': 'ÂΩìÂâç', 'pinyin': 'dƒÅng qi√°n', 'trans': 'current'},
{'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´ zh«în', 'trans': 'benchmark'},
{'word': 'ÂèñÂæó', 'pinyin': 'q«î d√©', 'trans': 'achieve'},
{'word': 'ÂèØÊØî', 'pinyin': 'kƒõ b«ê', 'trans': 'comparable'},
{'word': 'ÁªìÊûú', 'pinyin': 'ji√© gu«í', 'trans': 'result'}]
[28.01.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

Êàë‰ª¨‰ªãÁªç‰∫Ü Baichuan-Omni-1.5ÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÂÖ®Ê®°ÊÄÅÁêÜËß£ÂíåÁ´ØÂà∞Á´ØÈü≥È¢ëÁîüÊàêËÉΩÂäõÁöÑÊ®°Âûã„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞ÊµÅÁïÖÁöÑÈ´òË¥®ÈáèË∑®Ê®°ÊÄÅ‰∫§‰∫íÔºåÊàë‰ª¨‰ºòÂåñ‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÊï∞ÊçÆÊ∏ÖÊ¥óÂíåÂêàÊàêÁÆ°ÈÅìÔºåËé∑Âæó‰∫ÜÂ§ßÁ∫¶ 500B ÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÔºàÊñáÊú¨„ÄÅÈü≥È¢ëÂíåËßÜËßâÔºâ„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Èü≥È¢ëÂàÜËØçÂô®ÔºåÊçïÊçâÈü≥È¢ëÁöÑËØ≠‰πâÂíåÂ£∞Â≠¶‰ø°ÊÅØ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â§öÈò∂ÊÆµËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁ°Æ‰øùÊâÄÊúâÊ®°ÊÄÅÁöÑÊúâÊïàÂçèÂêå„ÄÇBaichuan-Omni-1.5 Âú®ÂÖ®Ê®°ÊÄÅËÉΩÂäõÊñπÈù¢È¢ÜÂÖà‰∫éÂΩìÂâçÊ®°ÂûãÔºåÂπ∂Âú®Â§ö‰∏™Â§öÊ®°ÊÄÅÂåªÁñóÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÂèØÊØîÁöÑÁªìÊûú„ÄÇ
[28.01.2025 09:11] Mistral response. {"id": "2e66fcee79264c809fe1ed322e85502a", "object": "chat.completion", "created": 1738055498, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "We introduce Baichuan-Omni-1.5, a model with full-modal understanding and end-to-end audio generation capabilities. To achieve smooth, high-quality cross-modal interaction, we optimized three key aspects. First, we established a comprehensive data cleaning and synthesis pipeline, obtaining approximately 500B high-quality data (text, audio, and visual). Second, we designed an audio tokenizer to capture the semantic and acoustic information of audio. Lastly, we designed a multi-stage training strategy to ensure effective collaboration across all modalities. Baichuan-Omni-1.5 leads in full-modal capabilities and achieves comparable results on multiple multimodal medical benchmarks."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 246, "total_tokens": 398, "completion_tokens": 152}}
[28.01.2025 09:11] Response: We introduce Baichuan-Omni-1.5, a model with full-modal understanding and end-to-end audio generation capabilities. To achieve smooth, high-quality cross-modal interaction, we optimized three key aspects. First, we established a comprehensive data cleaning and synthesis pipeline, obtaining approximately 500B high-quality data (text, audio, and visual). Second, we designed an audio tokenizer to capture the semantic and acoustic information of audio. Lastly, we designed a multi-stage training strategy to ensure effective collaboration across all modalities. Baichuan-Omni-1.5 leads in full-modal capabilities and achieves comparable results on multiple multimodal medical benchmarks.
[28.01.2025 09:11] Renaming data file.
[28.01.2025 09:11] Renaming previous data. hf_papers.json to ./d/2025-01-28.json
[28.01.2025 09:11] Saving new data file.
[28.01.2025 09:11] Generating page.
[28.01.2025 09:11] Renaming previous page.
[28.01.2025 09:11] Renaming previous data. index.html to ./d/2025-01-28.html
[28.01.2025 09:11] [Experimental] Generating Chinese page for reading.
[28.01.2025 09:11] Chinese vocab [{'word': '‰ªãÁªç', 'pinyin': 'ji√® sh√†o', 'trans': 'introduce'}, {'word': 'Baichuan-Omni-1.5', 'pinyin': 'B√†i chuƒÅn-≈åu m√≠-1.5', 'trans': 'Baichuan-Omni-1.5'}, {'word': 'ÂÖ∑Êúâ', 'pinyin': 'j√π y«íu', 'trans': 'have'}, {'word': 'ÂÖ®Ê®°ÊÄÅ', 'pinyin': 'qu√°n m√≥ sh√¨', 'trans': 'full modality'}, {'word': 'ÁêÜËß£', 'pinyin': 'l«ê jiƒõ', 'trans': 'understanding'}, {'word': 'Á´ØÂà∞Á´Ø', 'pinyin': 'duƒÅn d√†o duƒÅn', 'trans': 'end-to-end'}, {'word': 'Èü≥È¢ë', 'pinyin': 'yƒ´n p√≠n', 'trans': 'audio'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìng ch√©ng', 'trans': 'generate'}, {'word': 'ËÉΩÂäõ', 'pinyin': 'n√©ng l√¨', 'trans': 'ability'}, {'word': 'ÂÆûÁé∞', 'pinyin': 'sh√≠ xi√†n', 'trans': 'achieve'}, {'word': 'ÊµÅÁïÖ', 'pinyin': 'li√∫ ch√†ng', 'trans': 'smooth'}, {'word': 'È´òË¥®Èáè', 'pinyin': 'gƒÅo zh√¨ li√†ng', 'trans': 'high quality'}, {'word': 'Ë∑®Ê®°ÊÄÅ', 'pinyin': 'ku√† m√≥ sh√¨', 'trans': 'cross-modality'}, {'word': '‰∫§‰∫í', 'pinyin': 'jiƒÅo h√π', 'trans': 'interaction'}, {'word': '‰ºòÂåñ', 'pinyin': 'y≈çu hu√†', 'trans': 'optimize'}, {'word': 'ÂÖ≥ÈîÆ', 'pinyin': 'gu«én ji√†n', 'trans': 'key'}, {'word': 'ÊñπÈù¢', 'pinyin': 'fƒÅng mi√†n', 'trans': 'aspect'}, {'word': 'Âª∫Á´ã', 'pinyin': 'ji√†n l√¨', 'trans': 'establish'}, {'word': 'ÂÖ®Èù¢', 'pinyin': 'qu√°n mi√†n', 'trans': 'comprehensive'}, {'word': 'Êï∞ÊçÆ', 'pinyin': 'sh√π j√π', 'trans': 'data'}, {'word': 'Ê∏ÖÊ¥ó', 'pinyin': 'qƒ´ng x«ê', 'trans': 'clean'}, {'word': 'ÂêàÊàê', 'pinyin': 'h√© ch√©ng', 'trans': 'synthesize'}, {'word': 'ÁÆ°ÈÅì', 'pinyin': 'gu«én d√†o', 'trans': 'pipeline'}, {'word': 'Ëé∑Âæó', 'pinyin': 'hu√≤ d√©', 'trans': 'obtain'}, {'word': 'Â§ßÁ∫¶', 'pinyin': 'd√† yuƒì', 'trans': 'about'}, {'word': 'ÊñáÊú¨', 'pinyin': 'w√©n bƒõn', 'trans': 'text'}, {'word': 'ËßÜËßâ', 'pinyin': 'sh√¨ ju√©', 'trans': 'visual'}, {'word': 'ËÆæËÆ°', 'pinyin': 'sh√® j√¨', 'trans': 'design'}, {'word': 'ÂàÜËØçÂô®', 'pinyin': 'fƒìn c√≠ q√¨', 'trans': 'tokenizer'}, {'word': 'ÊçïÊçâ', 'pinyin': 'b«î zhu≈ç', 'trans': 'capture'}, {'word': 'ËØ≠‰πâ', 'pinyin': 'y«î y√¨', 'trans': 'semantics'}, {'word': 'Â£∞Â≠¶', 'pinyin': 'shƒìng xu√©', 'trans': 'acoustics'}, {'word': '‰ø°ÊÅØ', 'pinyin': 'x√¨n xƒ´', 'trans': 'information'}, {'word': 'Â§öÈò∂ÊÆµ', 'pinyin': 'du≈ç jiƒì du√†n', 'trans': 'multi-stage'}, {'word': 'ËÆ≠ÁªÉ', 'pinyin': 'x√πn li√†n', 'trans': 'training'}, {'word': 'Á≠ñÁï•', 'pinyin': 'c√® l√º√®', 'trans': 'strategy'}, {'word': 'Á°Æ‰øù', 'pinyin': 'qu√® b«éo', 'trans': 'ensure'}, {'word': 'ÊúâÊïà', 'pinyin': 'y«íu xi√†o', 'trans': 'effective'}, {'word': 'ÂçèÂêå', 'pinyin': 'xi√© t√≥ng', 'trans': 'coordination'}, {'word': 'È¢ÜÂÖà', 'pinyin': 'l«êng xiƒÅn', 'trans': 'lead'}, {'word': 'ÂΩìÂâç', 'pinyin': 'dƒÅng qi√°n', 'trans': 'current'}, {'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´ zh«în', 'trans': 'benchmark'}, {'word': 'ÂèñÂæó', 'pinyin': 'q«î d√©', 'trans': 'achieve'}, {'word': 'ÂèØÊØî', 'pinyin': 'kƒõ b«ê', 'trans': 'comparable'}, {'word': 'ÁªìÊûú', 'pinyin': 'ji√© gu«í', 'trans': 'result'}]
[28.01.2025 09:11] Renaming previous Chinese page.
[28.01.2025 09:11] Renaming previous data. zh.html to ./d/2025-01-27_zh_reading_task.html
[28.01.2025 09:11] Writing Chinese reading task.
[28.01.2025 09:11] Writing result.
[28.01.2025 09:11] Renaming log file.
[28.01.2025 09:11] Renaming previous data. log.txt to ./logs/2025-01-28_last_log.txt
