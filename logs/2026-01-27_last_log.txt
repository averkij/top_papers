[27.01.2026 06:39] Read previous papers.
[27.01.2026 06:39] Generating top page (month).
[27.01.2026 06:39] Writing top page (month).
[27.01.2026 07:29] Read previous papers.
[27.01.2026 07:29] Get feed.
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17058
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18418
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17737
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17367
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17027
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17124
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18577
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18184
[27.01.2026 07:29] Extract page data from URL. URL: https://huggingface.co/papers/2601.18217
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18778
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18202
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18157
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17323
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17111
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.17761
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.15849
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18759
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18731
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18130
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.18081
[27.01.2026 07:29] Get page data from previous paper. URL: https://huggingface.co/papers/2601.16207
[27.01.2026 07:29] Extract page data from URL. URL: https://huggingface.co/papers/2601.13599
[27.01.2026 07:29] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.01.2026 07:29] No deleted papers detected.
[27.01.2026 07:29] Downloading and parsing papers (pdf, html). Total: 22.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.17058.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.17058.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.17058.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.18418.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.18418.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.18418.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.17737.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.17737.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.17737.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.17367.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.17367.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.17367.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.17027.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.17027.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.17027.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.17124.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.17124.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.17124.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.18577.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.18577.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.18577.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.18184.
[27.01.2026 07:29] Extra JSON file exists (./assets/json/2601.18184.json), skip PDF parsing.
[27.01.2026 07:29] Paper image links file exists (./assets/img_data/2601.18184.json), skip HTML parsing.
[27.01.2026 07:29] Success.
[27.01.2026 07:29] Downloading and parsing paper https://huggingface.co/papers/2601.18217.
[27.01.2026 07:29] Downloading paper 2601.18217 from https://arxiv.org/pdf/2601.18217v1...
[27.01.2026 07:30] Extracting affiliations from text.
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 6 2 ] . [ 1 7 1 2 8 1 . 1 0 6 2 : r Paying Less Generalization Tax: Cross-Domain Generalization Study of RL Training for LLM Agents Zhihan Liu1,3,,, Lin Guan1,, Yixin Nie1, Kai Zhang1,4,, Zhuoqun Hao1,5,, Lin Chen1, Asli Celikyilmaz 2, Zhaoran Wang3,, Na Zhang1, 1Meta Superintelligence Labs, 2FAIR at Meta, 3Northwestern University, 4The Ohio State University, 5University of Pennsylvania Work done at Meta, Joint First Author, Joint Last Author Generalist LLM agents are often post-trained on narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the midtraining datamix; and (b) turning on step-by-"
[27.01.2026 07:30] Response: ```python
[
    "Meta Superintelligence Labs",
    "FAIR at Meta",
    "Northwestern University",
    "The Ohio State University",
    "University of Pennsylvania"
]
```
[27.01.2026 07:30] Deleting PDF ./assets/pdf/2601.18217.pdf.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.18778.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.18778.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.18778.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.18202.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.18202.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.18202.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.18157.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.18157.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.18157.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.17323.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.17323.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.17323.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.17111.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.17111.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.17111.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.17761.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.17761.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.17761.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.15849.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.15849.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.15849.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.18759.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.18759.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.18759.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.18731.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.18731.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.18731.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.18130.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.18130.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.18130.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.18081.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.18081.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.18081.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.16207.
[27.01.2026 07:30] Extra JSON file exists (./assets/json/2601.16207.json), skip PDF parsing.
[27.01.2026 07:30] Paper image links file exists (./assets/img_data/2601.16207.json), skip HTML parsing.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Downloading and parsing paper https://huggingface.co/papers/2601.13599.
[27.01.2026 07:30] Downloading paper 2601.13599 from https://arxiv.org/pdf/2601.13599v2...
[27.01.2026 07:30] Extracting affiliations from text.
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 1 2 ] . [ 2 9 9 5 3 1 . 1 0 6 2 : r Preprint. Under review. Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion Linrui Ma, Yufei Cui, Kai Han& Yunhe Wang Noahs Ark Lab, Huawei Montreal, Canada & Beijing, China {kai.han, yunhe.wang}@huawei.com "
[27.01.2026 07:30] Response: ```python
["Noahs Ark Lab, Huawei", "Montreal, Canada", "Beijing, China"]
```
[27.01.2026 07:30] Deleting PDF ./assets/pdf/2601.13599.pdf.
[27.01.2026 07:30] Success.
[27.01.2026 07:30] Enriching papers with extra data.
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 0. LLM-enhanced data preparation methods are transforming data-centric workflows from rule-based pipelines to prompt-driven, context-aware approaches, organized into data cleaning, integration, and enrichment tasks.  					AI-generated summary 				 Data preparation aims to denoise raw datasets, uncover ...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 1. Agentic mid-training enables large language models to develop autonomous software engineering capabilities through specialized data synthesis techniques that bridge the gap between static training data and dynamic development environments.  					AI-generated summary 				 Recently, the frontier of La...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 2. A novel end-to-end agentic framework translates dialogue into cinematic videos through specialized agents that generate and orchestrate video content while maintaining narrative coherence.  					AI-generated summary 				 Recent advances in video generation have produced models capable of synthesizin...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 3. Elastic Attention enables dynamic adjustment of attention sparsity during inference by integrating a lightweight Attention Router into pretrained models, achieving efficient long-context processing.  					AI-generated summary 				 The quadratic complexity of standard attention mechanisms poses a sig...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 4. Scientific image synthesis using logic-driven frameworks like ImgCoder improves multimodal reasoning by addressing visual-logic divergence through structured generation and evaluation benchmarks.  					AI-generated summary 				 While synthetic data has proven effective for improving scientific reaso...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 5. Finite Scalar Quantization with improved activation mapping enables unified modeling of discrete and continuous image generation approaches, revealing optimal representation balance and performance characteristics.  					AI-generated summary 				 The field of image generation is currently bifurcated...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 6. Self-refining video sampling improves motion coherence and physics alignment by using a pre-trained video generator as its own denoising autoencoder for iterative refinement with uncertainty-aware region selection.  					AI-generated summary 				 Modern video generators still struggle with complex p...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 7. VibeVoice-ASR is a unified end-to-end speech understanding framework that processes long-form audio in a single pass while supporting multilingual, code-switching, and domain-specific context injection.  					AI-generated summary 				 This report presents VibeVoice-ASR, a general-purpose speech unde...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 8. Research examines factors influencing out-of-domain performance in reinforcement learning agents, identifying state information richness and planning complexity as key determinants, while proposing a randomization technique to enhance cross-domain robustness.  					AI-generated summary 				 Generali...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 9. A self-improvement framework enables pretrained language models to generate automated curricula for solving previously unsolvable problems by leveraging latent knowledge and meta-reinforcement learning.  					AI-generated summary 				 Can a model learn to escape its own learning plateau? Reinforceme...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 10. Deep search agents trained on synthetic question-answer pairs generated through an iterative agent-based pipeline demonstrate improved performance and adaptability across different search environments.  					AI-generated summary 				 Deep search agents, which aim to answer complex questions requirin...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 11. An agentic framework using entity scene graphs enables long-horizon video understanding with structured search, temporal reasoning, and cross-modal capabilities for extended visual and audio interpretation.  					AI-generated summary 				 The advent of always-on personal AI assistants, enabled by al...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 12. SkyReels-V3 is a unified multimodal video generation model that supports reference image-to-video, video-to-video extension, and audio-guided video generation through diffusion Transformers and in-context learning frameworks.  					AI-generated summary 				 Video generation serves as a cornerstone f...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 13. Imbalanced expert routing in Mixture-of-Experts models leads to computational inefficiencies in expert parallelism, which are addressed by a dynamic rerouting algorithm that balances workload and reduces memory usage.  					AI-generated summary 				 Mixture-of-Experts (MoE) models are typically pre-...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 14. AR-Omni is a unified autoregressive model that supports multimodal input and output generation through a single Transformer decoder, addressing modality balance, visual fidelity, and stability-creativity trade-offs.  					AI-generated summary 				 Real-world perception and interaction are inherently...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 15. CGPT improves table retrieval by using LLM-generated synthetic queries for contrastive fine-tuning of embedding models through semantically diverse partial table construction.  					AI-generated summary 				 General-purpose embedding models have demonstrated strong performance in text retrieval but ...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 16. UI Remix is an interactive system that supports mobile UI design through example-driven workflows using a multimodal retrieval-augmented generation model, enabling iterative design adaptation with source transparency cues.  					AI-generated summary 				 Designing user interfaces (UIs) is a critical...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 17. Meta Reward Modeling reformulates personalized reward modeling as a meta-learning problem to enable efficient adaptation to individual users with limited feedback.  					AI-generated summary 				 Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 18. RouteMoA reduces computational costs and latency in mixture-of-agents frameworks by using dynamic routing with lightweight scoring and judgment mechanisms.  					AI-generated summary 				 Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises co...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 19. An agentic framework for automatic academic rebuttal generation that decomposes reviews, retrieves evidence, plans rebuttal strategies, and generates persuasive responses with human-level performance using an 8B model.  					AI-generated summary 				 Despite the growing adoption of large language mo...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 20. IVRA enhances spatial understanding in vision-language-action models by injecting affinity signals into language-model layers without retraining or external encoders.  					AI-generated summary 				 Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening th...
[27.01.2026 07:30] ********************************************************************************
[27.01.2026 07:30] Abstract 21. A 'draft-then-refine' framework for discrete diffusion language models that recovers global contextual understanding while maintaining semi-autoregressive efficiency through block diffusion and global bidirectional processing.  					AI-generated summary 				 One of the most compelling features of gl...
[27.01.2026 07:30] Read previous papers.
[27.01.2026 07:30] Generating reviews via LLM API.
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#benchmark", "#survey", "#hallucinations", "#data", "#agents"], "emoji": "üßπ", "ru": {"title": "–û—Ç –ø—Ä–∞–≤–∏–ª –∫ –ø–æ–¥—Å–∫–∞–∑–∫–∞–º: LLM-—Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–º–µ–Ω—è—é—Ç
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#agents", "#training", "#synthetic", "#optimization", "#plp", "#data"], "emoji": "ü§ñ", "ru": {"title": "–°–∏–Ω—Ç–µ–∑ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ü–û –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#benchmark", "#video", "#open_source", "#dataset", "#agents", "#story_generation", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–û—Ç –¥–∏–∞–ª–æ–≥–∞ –∫ –∫–∏–Ω–æ: –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–¥–µ–æ—Ñ–∏–ª—å–º–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –ø—Ä–µ
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#long_context", "#optimization"], "emoji": "‚ö°", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –º–µ—Ç–æ–¥ Elastic Attention, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è –≤ –±
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#diffusion", "#benchmark", "#cv", "#dataset", "#synthetic", "#science", "#multimodal"], "emoji": "üî¨", "ru": {"title": "–û—Ç –ª–æ–≥–∏–∫–∏ –∫ –ø–∏–∫—Å–µ–ª—è–º: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –Ω–∞—É—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —Å–∏–Ω—Ç–µ–∑—É –Ω–∞—É—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#optimization", "#diffusion", "#architecture", "#inference", "#open_source"], "emoji": "‚öñÔ∏è", "ru": {"title": "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ: –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ Finite Scalar Q
[27.01.2026 07:30] Using data from previous issue: {"categories": [], "emoji": "üé¨", "ru": {"title": "–°–∞–º–æ—É–ª—É—á—à–∞—é—â–∞—è—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ —Å —É—á—ë—Ç–æ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –º–µ—Ç–æ–¥ —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–¥–µ–æ –∫–∞–∫ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–≤—Ç–æ–∫–æ–¥–µ—Ä —à—É–º–æ–ø–æ–¥
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#long_context", "#multilingual", "#low_resource", "#open_source", "#architecture", "#audio"], "emoji": "üéôÔ∏è", "ru": {"title": "–ï–¥–∏–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –ª—é–±—É—é —Ä–µ—á—å: –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –±–µ–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏", "desc": "VibeVoice-ASR ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∫–≤–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ—á
[27.01.2026 07:30] Querying the API.
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Research examines factors influencing out-of-domain performance in reinforcement learning agents, identifying state information richness and planning complexity as key determinants, while proposing a randomization technique to enhance cross-domain robustness.  					AI-generated summary 				 Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.
[27.01.2026 07:30] Response: ```json
{
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—ã—è–≤–ª—è–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –æ–±–æ–±—â–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã. –ê–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —è–≤–ª—è—é—Ç—Å—è –≥–ª–∞–≤–Ω—ã–º–∏ –¥–µ—Ç–µ—Ä–º–∏–Ω–∞–Ω—Ç–∞–º–∏ –∫—Ä–æ—Å—Å-–¥–æ–º–µ–Ω–Ω–æ–π —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å –¥–æ–º–µ–Ω–∞ –∏–º–µ–µ—Ç –º–µ–Ω—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏–∏: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–∑–Ω–∞—á–∏–º—ã—Ö –¥–ª—è –∑–∞–¥–∞—á–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –µ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏. –¢–∞–∫–∂–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –≤–ª–∏—è–Ω–∏–µ supervised fine-tuning –∏ –ø–æ—à–∞–≥–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –æ–±–æ–±—â–∞—Ç—å—Å—è –Ω–∞ –Ω–æ–≤—ã–µ –¥–æ–º–µ–Ω—ã.",
  "emoji": "üß©",
  "title": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è - –∫–ª—é—á –∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤"
}
```
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research examines factors influencing out-of-domain performance in reinforcement learning agents, identifying state information richness and planning complexity as key determinants, while proposing a randomization technique to enhance cross-domain robustness.  					AI-generated summary 				 Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization."

[27.01.2026 07:30] Response: ```python
['AGENTS', 'RL', 'TRAINING']
```
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research examines factors influencing out-of-domain performance in reinforcement learning agents, identifying state information richness and planning complexity as key determinants, while proposing a randomization technique to enhance cross-domain robustness.  					AI-generated summary 				 Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization."

[27.01.2026 07:30] Response: ```python
["TRANSFER_LEARNING", "REASONING"]
```

**Justification:**

- **TRANSFER_LEARNING**: The paper directly addresses cross-domain generalization and out-of-domain performance in RL agents. It investigates how agents trained on narrow environments can generalize to unseen domains, which is a core transfer learning problem.

- **REASONING**: The paper examines step-by-step thinking during RL training and its role in generalization, which relates to enhancing reasoning capabilities in agents.
[27.01.2026 07:30] Error. Failed to parse JSON from LLM. ["TRANSFER_LEARNING", "REASONING"]


**Justification:**

- **TRANSFER_LEARNING**: The paper directly addresses cross-domain generalization and out-of-domain performance in RL agents. It investigates how agents trained on narrow environments can generalize to unseen domains, which is a core transfer learning problem.

- **REASONING**: The paper examines step-by-step thinking during RL training and its role in generalization, which relates to enhancing reasoning capabilities in agents.
[27.01.2026 07:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This research focuses on improving the performance of reinforcement learning (RL) agents when they encounter new, unseen environments. It identifies two main factors that affect how well these agents generalize: the richness of state information and the complexity of planning required to achieve goals. The study finds that enhancing state information can significantly boost an agent\'s ability to adapt to different domains. Additionally, a new randomization technique is proposed, which involves adding irrelevant features to the state to improve robustness without changing the core task.","title":"Enhancing RL Agents\' Cross-Domain Performance through State Richness and Randomization"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This research focuses on improving the performance of reinforcement learning (RL) agents when they encounter new, unseen environments. It identifies two main factors that affect how well these agents generalize: the richness of state information and the complexity of planning required to achieve goals. The study finds that enhancing state information can significantly boost an agent's ability to adapt to different domains. Additionally, a new randomization technique is proposed, which involves adding irrelevant features to the state to improve robustness without changing the core task.", title="Enhancing RL Agents' Cross-Domain Performance through State Richness and Randomization"))
[27.01.2026 07:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂΩ±ÂìçÂº∫ÂåñÂ≠¶‰π†‰ª£ÁêÜÂú®Êú™Áü•È¢ÜÂüüË°®Áé∞ÁöÑÂõ†Á¥†ÔºåÂèëÁé∞Áä∂ÊÄÅ‰ø°ÊÅØ‰∏∞ÂØåÊÄßÂíåËßÑÂàíÂ§çÊùÇÊÄßÊòØÂÖ≥ÈîÆÂÜ≥ÂÆöÂõ†Á¥†„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂ¢ûÂä†Áä∂ÊÄÅ‰ø°ÊÅØ‰∏∞ÂØåÊÄßÂèØ‰ª•ÊúâÊïàÊèêÈ´òË∑®È¢ÜÂüüÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÈöèÊú∫ÂåñÊäÄÊúØÔºåÈÄöËøáÂú®Áä∂ÊÄÅ‰∏≠Ê∑ªÂä†Â∞ëÈáè‰∏éÁõÆÊ†áÊó†ÂÖ≥ÁöÑÂπ≤Êâ∞ÁâπÂæÅÊù•Â¢ûÂº∫‰ø°ÊÅØ‰∏∞ÂØåÊÄßÔºåËÄå‰∏çÊîπÂèò‰ªªÂä°Êú¨Ë∫´„ÄÇÊ≠§Â§ñÔºåÁ†îÁ©∂ËøòÂàÜÊûê‰∫ÜÊ®°ÂûãÈÄâÊã©ÂØπË∑®È¢ÜÂüüË°®Áé∞ÁöÑÂΩ±ÂìçÔºåÂº∫Ë∞É‰∫ÜÈÄêÊ≠•ÊÄùËÄÉÂú®‰øùÊåÅÊ≥õÂåñËÉΩÂäõ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ","title":"ÊèêÂçáÂº∫ÂåñÂ≠¶‰π†‰ª£ÁêÜÁöÑË∑®È¢ÜÂüüÈ≤ÅÊ£íÊÄß"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂΩ±ÂìçÂº∫ÂåñÂ≠¶‰π†‰ª£ÁêÜÂú®Êú™Áü•È¢ÜÂüüË°®Áé∞ÁöÑÂõ†Á¥†ÔºåÂèëÁé∞Áä∂ÊÄÅ‰ø°ÊÅØ‰∏∞ÂØåÊÄßÂíåËßÑÂàíÂ§çÊùÇÊÄßÊòØÂÖ≥ÈîÆÂÜ≥ÂÆöÂõ†Á¥†„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂ¢ûÂä†Áä∂ÊÄÅ‰ø°ÊÅØ‰∏∞ÂØåÊÄßÂèØ‰ª•ÊúâÊïàÊèêÈ´òË∑®È¢ÜÂüüÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÈöèÊú∫ÂåñÊäÄÊúØÔºåÈÄöËøáÂú®Áä∂ÊÄÅ‰∏≠Ê∑ªÂä†Â∞ëÈáè‰∏éÁõÆÊ†áÊó†ÂÖ≥ÁöÑÂπ≤Êâ∞ÁâπÂæÅÊù•Â¢ûÂº∫‰ø°ÊÅØ‰∏∞ÂØåÊÄßÔºåËÄå‰∏çÊîπÂèò‰ªªÂä°Êú¨Ë∫´„ÄÇÊ≠§Â§ñÔºåÁ†îÁ©∂ËøòÂàÜÊûê‰∫ÜÊ®°ÂûãÈÄâÊã©ÂØπË∑®È¢ÜÂüüË°®Áé∞ÁöÑÂΩ±ÂìçÔºåÂº∫Ë∞É‰∫ÜÈÄêÊ≠•ÊÄùËÄÉÂú®‰øùÊåÅÊ≥õÂåñËÉΩÂäõ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ', title='ÊèêÂçáÂº∫ÂåñÂ≠¶‰π†‰ª£ÁêÜÁöÑË∑®È¢ÜÂüüÈ≤ÅÊ£íÊÄß'))
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#rl", "#training", "#synthetic", "#reasoning", "#optimization", "#math"], "emoji": "ü™ú", "ru": {"title": "–°–∞–º–æ—É–ª—É—á—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ SOAR –¥–ª—è —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–µ–æ–¥–æ–ª–µ—Ç—å –ø–ª–∞—Ç–æ –æ–±—É
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#reasoning", "#synthetic", "#data", "#agents", "#open_source"], "emoji": "üîÑ", "ru": {"title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª—É—á—à–∏—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω SAGE ‚Äî –∞–≥–µ–Ω—Ç—Å–∫–∏–π –∫–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∏–Ω—Ç–µ—Ç–∏
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#graphs", "#audio", "#agents", "#rag", "#long_context", "#video"], "emoji": "üìπ", "ru": {"title": "–ì—Ä–∞—Ñ—ã —Å—Ü–µ–Ω –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ –±–µ–∑ –≥—Ä–∞–Ω–∏—Ü –≤—Ä–µ–º–µ–Ω–∏", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç EGAgent ‚Äî –∞–≥–µ–Ω—Ç–∏–≤–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–µ
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#training", "#data", "#diffusion", "#multimodal", "#architecture", "#video", "#open_source"], "emoji": "üé¨", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –ª—é–±–æ–≥–æ —Ç–∏–ø–∞", "desc": "SkyReels-V3 ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#inference", "#training"], "emoji": "‚öñÔ∏è", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è MoE-–º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –º–æ–¥–µ–ª—è—Ö Mixture-of
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#training", "#multimodal"], "emoji": "üé≠", "ru": {"title": "–û–¥–∏–Ω –¥–µ–∫–æ–¥–µ—Ä –¥–ª—è –≤—Å–µ—Ö: —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ –≤ –µ–¥–∏–Ω–æ–º –ø–æ—Ç–æ–∫–µ —Ç–æ–∫–µ–Ω–æ–≤", "desc": "AR-Omni ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–≤—Ç—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#benchmark", "#training", "#synthetic", "#rag", "#open_source"], "emoji": "üìä", "ru": {"title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö", "desc": "CGPT ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º —á–µ—Ä–µ–∑ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ –±–æ–ª—å—à–∏–º–∏ —è–∑
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#rag", "#multimodal"], "emoji": "üé®", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –¥–∏–∑–∞–π–Ω –º–æ–±–∏–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–∏–º–µ—Ä—ã —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤", "desc": "UI Remix ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–±–∏–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º–æ–¥–µ–ª—å multimodal retrieval-augmented generatio
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#alignment", "#optimization"], "emoji": "üéØ", "ru": {"title": "–ú–µ—Ç–∞–æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –Ω–∞–≥—Ä–∞–¥—ã –∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç Meta Reward Modeling ‚Äî –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–≤ –∑–∞–¥–∞—á—É –º–æ–¥–µ–ª–∏—Ä
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#inference", "#optimization", "#architecture", "#agents"], "emoji": "üõ£Ô∏è", "ru": {"title": "–£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å–º–µ—Å–∏ –∞–≥–µ–Ω—Ç–æ–≤", "desc": "RouteMoA ‚Äî —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–º–µ—Å–∏ –∞–≥–µ–Ω—Ç–æ–≤ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π, –∫–æ—Ç–æ—Ä–∞—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã 
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#science", "#reasoning"], "emoji": "ü§ñ", "ru": {"title": "–ê–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è DRPG ‚Äî –∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ —Ä–µ—Ü–µ–Ω–∑–∏–∏ –Ω–∞—É—á
[27.01.2026 07:30] Using data from previous issue: {"categories": ["#3d", "#inference", "#robotics", "#multimodal"], "emoji": "ü§ñ", "ru": {"title": "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –º–µ—Ç–æ–¥ IVRA, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤ –º–æ–¥–µ–ª—è—Ö Vision-Language-Action –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.
[27.01.2026 07:30] Querying the API.
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A 'draft-then-refine' framework for discrete diffusion language models that recovers global contextual understanding while maintaining semi-autoregressive efficiency through block diffusion and global bidirectional processing.  					AI-generated summary 				 One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.
[27.01.2026 07:30] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ 'Diffusion in Diffusion', –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –±–ª–æ—á–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏ –∏ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–∏. –ü–æ–¥—Ö–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—É—é —Å—Ö–µ–º—É: —Å–Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –±—ã—Å—Ç—Ä—ã–µ —á–µ—Ä–Ω–æ–≤–∏–∫–∏ —Å –ø–æ–º–æ—â—å—é –±–ª–æ—á–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏ –Ω–∞ –º–∞–ª—ã—Ö –±–ª–æ–∫–∞—Ö, –∑–∞—Ç–µ–º –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≥–ª–æ–±–∞–ª—å–Ω—É—é –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –¥–∏—Ñ—Ñ—É–∑–∏—é —Å –±–æ–ª—å—à–∏–º —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω—ã–º –ø–æ–ª–µ–º. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç —Ç–µ—Ö–Ω–∏–∫—É –ø–µ—Ä–µ—Ä–∞–∑–º–µ—Ç–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å–Ω–∏–º–∫–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏, –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –º–Ω–æ–≥–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–ª—å–∫–æ 26% –æ—Ç –±—é–¥–∂–µ—Ç–∞ –æ–±—É—á–µ–Ω–∏—è –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è —Å–Ω–∏–∂–∞–µ—Ç—Å—è —Å 25,7 –¥–æ 21,9, –∑–∞–º–µ—Ç–Ω–æ —Å–æ–∫—Ä–∞—â–∞—è —Ä–∞–∑—Ä—ã–≤ —Å –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.",
  "emoji": "üîÑ",
  "title": "–ß–µ—Ä–Ω–æ–≤–∏–∫ –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ: –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –±–ª–æ—á–Ω—É—é –¥–∏—Ñ—Ñ—É–∑–∏—é"
}
```
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A 'draft-then-refine' framework for discrete diffusion language models that recovers global contextual understanding while maintaining semi-autoregressive efficiency through block diffusion and global bidirectional processing.  					AI-generated summary 				 One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models."

[27.01.2026 07:30] Response: ```python
["ARCHITECTURE", "TRAINING", "BENCHMARK"]
```
[27.01.2026 07:30] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A 'draft-then-refine' framework for discrete diffusion language models that recovers global contextual understanding while maintaining semi-autoregressive efficiency through block diffusion and global bidirectional processing.  					AI-generated summary 				 One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models."

[27.01.2026 07:30] Response: ```python
['DIFFUSION', 'OPTIMIZATION']
```
[27.01.2026 07:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new framework called \'Diffusion in Diffusion\' for discrete diffusion language models, which aims to enhance global contextual understanding while maintaining efficiency. The framework operates in two stages: first, it generates quick drafts using block diffusion, and then it refines these drafts through global bidirectional processing. By employing snapshot confidence remasking, the model identifies key tokens that need adjustments, and mix-scale training is used to improve its global capabilities. The results show that this approach significantly reduces generative perplexity and sets a new benchmark for performance in discrete diffusion models.","title":"Enhancing Contextual Understanding in Language Models with Draft-Then-Refine"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces a new framework called 'Diffusion in Diffusion' for discrete diffusion language models, which aims to enhance global contextual understanding while maintaining efficiency. The framework operates in two stages: first, it generates quick drafts using block diffusion, and then it refines these drafts through global bidirectional processing. By employing snapshot confidence remasking, the model identifies key tokens that need adjustments, and mix-scale training is used to improve its global capabilities. The results show that this approach significantly reduces generative perplexity and sets a new benchmark for performance in discrete diffusion models.", title='Enhancing Contextual Understanding in Language Models with Draft-Then-Refine'))
[27.01.2026 07:30] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫‚ÄúËçâÁ®ø-ÂÜçÁ≤æÁÇº‚ÄùÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÁ¶ªÊï£Êâ©Êï£ËØ≠Ë®ÄÊ®°ÂûãÔºåÊó®Âú®ÊÅ¢Â§çÂÖ®ÁêÉ‰∏ä‰∏ãÊñáÁêÜËß£ÔºåÂêåÊó∂‰øùÊåÅÂçäËá™ÂõûÂΩíÁöÑÊïàÁéá„ÄÇËØ•ÊñπÊ≥ïÈ¶ñÂÖàÈÄöËøáÂ∞èÂùóËøõË°åÂø´ÈÄüËçâÁ®øÁîüÊàêÔºåÁÑ∂ÂêéÈÄöËøáÂÖ®ÁêÉÂèåÂêëÊâ©Êï£ÂØπËøô‰∫õËçâÁ®øËøõË°åÁ≤æÁÇºÔºå‰ª•ÂÖãÊúçÂùóÊâ©Êï£Ê®°Âûã‰∏≠ÁöÑ‰∏çÂèØÈÄÜÊÄßÂíåÁü≠ËßÜÈóÆÈ¢ò„ÄÇÊàë‰ª¨ËøòÂà©Áî®Âø´ÁÖßÁΩÆ‰ø°ÈáçÊé©ËîΩÊäÄÊúØÊù•ËØÜÂà´ÈúÄË¶Å‰øÆÊîπÁöÑÂÖ≥ÈîÆÊ†áËÆ∞ÔºåÂπ∂Â∫îÁî®Ê∑∑ÂêàËßÑÊ®°ËÆ≠ÁªÉÊù•Êâ©Â±ïÂùóÊâ©Êï£Ê®°ÂûãÁöÑÂÖ®ÁêÉËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®OpenWebTextÊï∞ÊçÆÈõÜ‰∏äËÆæÂÆö‰∫ÜÁ¶ªÊï£Êâ©Êï£Ê®°ÂûãÁöÑÊñ∞Âü∫ÂáÜ„ÄÇ","title":"ËçâÁ®ø-ÂÜçÁ≤æÁÇºÔºöÊèêÂçáÁ¶ªÊï£Êâ©Êï£Ê®°ÂûãÁöÑÂÖ®ÁêÉÁêÜËß£ËÉΩÂäõ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫‚ÄúËçâÁ®ø-ÂÜçÁ≤æÁÇº‚ÄùÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÁ¶ªÊï£Êâ©Êï£ËØ≠Ë®ÄÊ®°ÂûãÔºåÊó®Âú®ÊÅ¢Â§çÂÖ®ÁêÉ‰∏ä‰∏ãÊñáÁêÜËß£ÔºåÂêåÊó∂‰øùÊåÅÂçäËá™ÂõûÂΩíÁöÑÊïàÁéá„ÄÇËØ•ÊñπÊ≥ïÈ¶ñÂÖàÈÄöËøáÂ∞èÂùóËøõË°åÂø´ÈÄüËçâÁ®øÁîüÊàêÔºåÁÑ∂ÂêéÈÄöËøáÂÖ®ÁêÉÂèåÂêëÊâ©Êï£ÂØπËøô‰∫õËçâÁ®øËøõË°åÁ≤æÁÇºÔºå‰ª•ÂÖãÊúçÂùóÊâ©Êï£Ê®°Âûã‰∏≠ÁöÑ‰∏çÂèØÈÄÜÊÄßÂíåÁü≠ËßÜÈóÆÈ¢ò„ÄÇÊàë‰ª¨ËøòÂà©Áî®Âø´ÁÖßÁΩÆ‰ø°ÈáçÊé©ËîΩÊäÄÊúØÊù•ËØÜÂà´ÈúÄË¶Å‰øÆÊîπÁöÑÂÖ≥ÈîÆÊ†áËÆ∞ÔºåÂπ∂Â∫îÁî®Ê∑∑ÂêàËßÑÊ®°ËÆ≠ÁªÉÊù•Êâ©Â±ïÂùóÊâ©Êï£Ê®°ÂûãÁöÑÂÖ®ÁêÉËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®OpenWebTextÊï∞ÊçÆÈõÜ‰∏äËÆæÂÆö‰∫ÜÁ¶ªÊï£Êâ©Êï£Ê®°ÂûãÁöÑÊñ∞Âü∫ÂáÜ„ÄÇ', title='ËçâÁ®ø-ÂÜçÁ≤æÁÇºÔºöÊèêÂçáÁ¶ªÊï£Êâ©Êï£Ê®°ÂûãÁöÑÂÖ®ÁêÉÁêÜËß£ËÉΩÂäõ'))
[27.01.2026 07:30] Renaming data file.
[27.01.2026 07:30] Renaming previous data. hf_papers.json to ./d/2026-01-27.json
[27.01.2026 07:30] Saving new data file.
[27.01.2026 07:30] Generating page.
[27.01.2026 07:30] Renaming previous page.
[27.01.2026 07:30] Renaming previous data. index.html to ./d/2026-01-27.html
[27.01.2026 07:30] Writing result.
[27.01.2026 07:30] Renaming log file.
[27.01.2026 07:30] Renaming previous data. log.txt to ./logs/2026-01-27_last_log.txt
