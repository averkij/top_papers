[07.10.2024 22:11] Get feed.
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.00907
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02613
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02703
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.01699
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03017
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2409.19989
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02362
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02760
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02241
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.01273
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03535
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03103
[07.10.2024 22:11] Extract page data from URL. URL: https://huggingface.co/papers/2410.03051
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.01999
[07.10.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03645
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 0. Large neural networks spend most computation on floating point tensor multiplications. In this work, we find that a floating point multiplier can be approximated by one integer adder with high precision. We propose the linear-complexity multiplication L-Mul algorithm that approximates floating point...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 1. Will a Visual Language Model (VLM)-based bot warn us about slipping if it detects a wet floor? Recent VLMs have demonstrated impressive capabilities, yet their ability to infer outcomes and causes remains underexplored. To address this, we introduce NL-Eye, a benchmark designed to assess VLMs' visua...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 2. Unneeded elements in the attention's context degrade performance. We introduce Selective Attention, a simple parameter-free change to the standard attention mechanism which reduces attention to unneeded elements. Selective attention improves language modeling performance in a variety of model sizes ...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 3. The current large auto-regressive models can generate high-quality, high-resolution images, but these models require hundreds or even thousands of steps of next-token prediction during inference, resulting in substantial time consumption. In existing studies, Jacobi decoding, an iterative parallel d...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 4. Generative AI, particularly Language Models (LMs), has the potential to transform real-world domains with societal impact, particularly where access to experts is limited. For example, in education, training novice educators with expert guidance is important for effectiveness but expensive, creating...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 5. Text-to-texture generation has recently attracted increasing attention, but existing methods often suffer from the problems of view inconsistencies, apparent seams, and misalignment between textures and the underlying mesh. In this paper, we propose a robust text-to-texture method for generating con...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 6. Mamba, a special case of the State Space Model, is gaining popularity as an alternative to template-based deep learning approaches in medical image analysis. While transformers are powerful architectures, they have drawbacks, including quadratic computational complexity and an inability to address l...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 7. Concept erasure in language models has traditionally lacked a comprehensive evaluation framework, leading to incomplete assessments of effectiveness of erasure methods. We propose an evaluation paradigm centered on three critical criteria: innocence (complete knowledge removal), seamlessness (mainta...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 8. Stock market prediction has remained an extremely challenging problem for many decades owing to its inherent high volatility and low information noisy ratio. Existing solutions based on machine learning or deep learning demonstrate superior performance by employing a single model trained on the enti...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 9. Real-life robot navigation involves more than just reaching a destination; it requires optimizing movements while addressing scenario-specific goals. An intuitive way for humans to express these goals is through abstract cues like verbal commands or rough sketches. Such human guidance may lack detai...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 10. Despite the rise to dominance of deep learning in unstructured data domains, tree-based methods such as Random Forests (RF) and Gradient Boosted Decision Trees (GBDT) are still the workhorses for handling discriminative tasks on tabular data. We explore generative extensions of these popular algorit...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 11. Fill-in-the-Middle (FIM) has become integral to code language models, enabling generation of missing code given both left and right contexts. However, the current FIM training paradigm, which reorders original training sequences and then performs regular next-token prediction (NTP), often leads to m...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 12. Video detailed captioning is a key task which aims to generate comprehensive and coherent textual descriptions of video content, benefiting both video understanding and generation. In this paper, we propose AuroraCap, a video captioner based on a large multimodal model. We follow the simplest archit...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 13. Recent advancements in Code Large Language Models (CodeLLMs) have predominantly focused on open-ended code generation tasks, often neglecting the critical aspect of code understanding and comprehension. To bridge this gap, we present CodeMMLU, a comprehensive multiple-choice question-answer benchmar...
[07.10.2024 22:11] ********************************************************************************
[07.10.2024 22:11] Abstract 14. Robotic simulation today remains challenging to scale up due to the human efforts required to create diverse simulation tasks and scenes. Simulation-trained policies also face scalability issues as many sim-to-real methods focus on a single task. To address these challenges, this work proposes GenSi...
[07.10.2024 22:11] Read previous papers.
[07.10.2024 22:11] Generating reviews via LLM API.
[07.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º L-Mul –¥–ª—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ —É–º–Ω–æ–∂–µ–Ω–∏—è —á–∏—Å–µ–ª —Å –ø–ª–∞–≤–∞—é—â–µ–π –∑–∞–ø—è—Ç–æ–π —Å –ø–æ–º–æ—â—å—é –æ–ø–µ—Ä–∞—Ü–∏–π —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–∂–µ–Ω–∏—è. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –ø–æ—Ç—Ä–µ–±–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤, —á–µ–º 8-–±–∏—Ç–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ —Å –ø–ª–∞–≤–∞—é—â–µ–π –∑–∞–ø—è—Ç–æ–π, –Ω–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å. –ü
[07.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç NL-Eye - –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (VLM) –∫ –∞–±–¥—É–∫—Ç–∏–≤–Ω–æ–º—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é. NL-Eye –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á—É –∞–±–¥—É–∫—Ç–∏–≤–Ω–æ–≥–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ-—è–∑—ã–∫–æ–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ –∫ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏, —Ç—Ä–µ–±—É—è –æ—Ç –º–æ–¥–µ–ª–µ–π –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ—Å—Ç—å –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
[07.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è (Selective Attention) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞—Ö. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ —É–º–µ–Ω—å—à–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ –∫ –Ω–µ–Ω—É–∂–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–∞–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è. –ò–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è
[07.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è - Speculative Jacobi Decoding (SJD) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É. SJD –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –ø—Ä–∏ –≤—ã–±–æ—Ä–∫–µ —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –≥–µ–Ω–µ—Ä–∏
[07.10.2024 22:11] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º—É Tutor CoPilot, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –í —Ä–∞–Ω–¥–æ–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ —Å —É—á–∞—Å—Ç–∏–µ–º 900 —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–æ–≤ –∏ 1800 —É—á–µ–Ω–∏–∫–æ–≤ –∏–∑ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—Å–ª—É–∂–∏–≤–∞–µ–º—ã—Ö —Å–æ–æ–±—â–µ—Å—Ç–≤ –±—ã–ª–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ, —á—Ç–æ —É—á–µ–Ω–∏–∫–∏,
[07.10.2024 22:11] Using data from previous issue: {"desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç—É—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π, —Ä–µ—à–∞—é—â–∏–π –ø—Ä–æ–±–ª–µ–º—ã –Ω–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –≤–∏–¥–æ–≤, –≤–∏–¥–∏–º—ã—Ö —à–≤–æ–≤ –∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–µ–∫—Å—Ç—É—Ä –∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ 2D –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏, –≤–∫–ª—é—á–∞—è SDXL –∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ ControlNet, –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –æ—Å–æ
[07.10.2024 22:11] Using data from previous issue: {"desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Mamba –≤ –∞–Ω–∞–ª–∏–∑–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. Mamba, —è–≤–ª—è—è—Å—å —á–∞—Å—Ç–Ω—ã–º —Å–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π (State Space Model), –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –±–µ–∑ –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è. –í –æ—Ç–ª–∏—á
[07.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å—Ç–∏—Ä–∞–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö - Erasure of Language Memory (ELM). –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å—Ç–∏—Ä–∞–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ —Ç—Ä–µ—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è—Ö: –ø–æ–ª–Ω–æ—Ç–∞ —É–¥–∞–ª–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ª–æ–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç—å. ELM –∏—Å–ø–æ–ª—å–∑—É–µ
[07.10.2024 22:11] Using data from previous issue: {"desc": "MIGA - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–æ–Ω–¥–æ–≤–æ–≥–æ —Ä—ã–Ω–∫–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Å–º–µ—Å–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —Å –≥—Ä—É–ø–ø–æ–≤–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π, MIGA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∏–ª–µ–π –∞–∫—Ü–∏–π, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ü–µ–Ω
[07.10.2024 22:11] Using data from previous issue: {"desc": "CANVAS - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ —Ä–æ–±–æ—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∏ —è–∑—ã–∫–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. –û–Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –∏–º–∏—Ç–∞—Ü–∏–æ–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏, –ø–æ–∑–≤–æ–ª—è—é—â–µ–º —Ä–æ–±–æ—Ç—É —É—á–∏—Ç—å—Å—è –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç COMMAND —Å –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —á–µ–ª–æ–≤–µ–∫–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á
[07.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –¥—Ä–µ–≤–æ–≤–∏–¥–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ Random Forests –∏ Gradient Boosted Decision Trees, –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–∞–±–ª–∏—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –±—É—Å—Ç–∏–Ω–≥–∞, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥—É –≤—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –≤ XGBoost. –ù–æ–≤—ã–π –º–µ
[07.10.2024 22:11] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–æ–¥–µ - Horizon-Length Prediction (HLP). –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ Fill-in-the-Middle (FIM), HLP —É—á–∏—Ç –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ–∫–µ–Ω–æ–≤, —á—Ç–æ —É–ª—É—á—à–∞–µ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å –∫–æ–Ω—Ç–µ–∫—Å
[07.10.2024 22:11] Querying the API.
[07.10.2024 22:11] Got response. {
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ AuroraCap - —Å–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–æ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω–∏–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞. AuroraCap –ø—Ä–µ–≤–∑–æ—à–ª–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é –≤–∏–¥–µ–æ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –¢–∞–∫–∂–µ –∞–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç VDC –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –≤–∏–¥–µ–æ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –º–µ—Ç—Ä–∏–∫—É VDCscore, –∏—Å–ø–æ–ª—å–∑—É—é—â—É—é LLM –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π.",
  "tags": ["#–≤–∏–¥–µ–æ–∫–∞–ø—Ç–∏–æ–Ω–∏–Ω–≥", "#—Ç–æ–∫–µ–Ω–º–µ—Ä–¥–∂–∏–Ω–≥", "#–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ–º–æ–¥–µ–ª–∏"],
  "emoji": "üé•",
  "title": "AuroraCap: –ø—Ä–æ—Ä—ã–≤ –≤ –¥–µ—Ç–∞–ª—å–Ω–æ–º –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∏–¥–µ–æ"
}
[07.10.2024 22:11] Using data from previous issue: {"desc": "CodeMMLU - –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–¥–∞ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏. –û–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ 10 000 –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ–º –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤, CodeMMLU –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–∞—Ç—å –æ –∫–æ–¥–µ, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
[07.10.2024 22:11] Using data from previous issue: {"desc": "GenSim2 - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π —Ä–æ–±–æ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏ —Å—Ü–µ–Ω—ã, –≤–∫–ª—é—á–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π —Å —à–∞—Ä–Ω–∏—Ä–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∏ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –æ–±—É—á–µ
[07.10.2024 22:11] Renaming data file.
[07.10.2024 22:11] Renaming previous data. hf_papers.json to 2024-10-06_hf_papers.json
[07.10.2024 22:11] Saving new data file.
[07.10.2024 22:11] Generating page.
[07.10.2024 22:11] Renaming previous page.
[07.10.2024 22:11] Renaming previous data. index.html to 2024-10-06_hf_papers.html
[07.10.2024 22:11] Writing result.
[07.10.2024 22:11] Renaming log file.
[07.10.2024 22:11] Renaming previous data. log.txt to 2024-10-06_last_log.txt
