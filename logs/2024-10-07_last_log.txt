[08.10.2024 08:18] Get feed.
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05258
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04364
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02675
[08.10.2024 08:18] Extract page data from URL. URL: https://huggingface.co/papers/2410.02707
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05167
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04932
[08.10.2024 08:18] Extract page data from URL. URL: https://huggingface.co/papers/2410.04698
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04734
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03959
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03825
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04534
[08.10.2024 08:18] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05262
[08.10.2024 08:18] Extract page data from URL. URL: https://huggingface.co/papers/2410.03187
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 0. Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separa...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 1. Text-to-image (T2I) diffusion models have revolutionized visual content creation, but extending these capabilities to text-to-video (T2V) generation remains a challenge, particularly in preserving temporal consistency. Existing methods that aim to improve consistency often cause trade-offs such as r...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 2. Despite the remarkable success achieved by neural networks, particularly those represented by MLP and Transformer, we reveal that they exhibit potential flaws in the modeling and reasoning of periodicity, i.e., they tend to memorize the periodic data rather than genuinely understanding the underlyin...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 3. Large language models (LLMs) often produce errors, including factual inaccuracies, biases, and reasoning failures, collectively referred to as "hallucinations". Recent studies have demonstrated that LLMs' internal states encode information regarding the truthfulness of their outputs, and that this i...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 4. Despite advances in diffusion-based text-to-music (TTM) methods, efficient, high-quality generation remains a challenge. We introduce Presto!, an approach to inference acceleration for score-based diffusion transformers via reducing both sampling steps and cost per step. To reduce steps, we develop ...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 5. We present OmniBooth, an image generation framework that enables spatial control with instance-level multi-modal customization. For all instances, the multimodal instruction can be described through text prompts or image references. Given a set of user-defined masks and associated text or image guid...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 6. Recent large language models (LLMs) have demonstrated versatile capabilities in long-context scenarios. Although some recent benchmarks have been developed to evaluate the long-context capabilities of LLMs, there is a lack of benchmarks evaluating the mathematical reasoning abilities of LLMs over lo...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 7. Although reward models have been successful in improving multimodal large language models, the reward models themselves remain brutal and contain minimal information. Notably, existing reward models only mimic human annotations by assigning only one binary feedback to any text, no matter how long th...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 8. We introduce a task and dataset for referring expression generation and comprehension in multi-agent embodied environments. In this task, two agents in a shared scene must take into account one another's visual perspective, which may be different from their own, to both produce and understand refere...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 9. Estimating geometry from dynamic scenes, where objects move and deform over time, remains a core challenge in computer vision. Current approaches often rely on multi-stage pipelines or global optimizations that decompose the problem into subtasks, like depth and flow, leading to complex systems pron...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 10. We introduce UniMuMo, a unified multimodal model capable of taking arbitrary text, music, and motion data as input conditions to generate outputs across all three modalities. To address the lack of time-synchronized data, we align unpaired music and motion data based on rhythmic patterns to leverage...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 11. As the application of Large Language Models (LLMs) expands, the demand for reliable evaluations increases. Existing LLM evaluation benchmarks primarily rely on static datasets, making it challenging to assess model performance in dynamic interactions with users. Moreover, these benchmarks often depe...
[08.10.2024 08:18] ********************************************************************************
[08.10.2024 08:18] Abstract 12. Synthesizing human motions in 3D environments, particularly those with complex activities such as locomotion, hand-reaching, and human-object interaction, presents substantial demands for user-defined waypoints and stage transitions. These requirements pose challenges for current models, leading to ...
[08.10.2024 08:18] Read previous papers.
[08.10.2024 08:18] Generating reviews via LLM API.
[08.10.2024 08:18] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Diff Transformer, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ –∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∏ –ø–æ–¥–∞–≤–ª—è–µ—Ç —à—É–º. –ú–µ—Ö–∞–Ω–∏–∑–º –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –≤—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è –∫–∞–∫ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –¥–≤—É–º—è –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è softmax. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ Diff Transform
[08.10.2024 08:18] Using data from previous issue: {"desc": "VideoGuide - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –ø–æ —Ç–µ–∫—Å—Ç—É –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–∏—Ñ—Ñ—É–∑–∏–∏ –≤–∏–¥–µ–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≥–∏–¥–∞ –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —ç—Ç–∞–ø–∞—Ö –≤—ã–≤–æ–¥–∞, –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É—è –µ–µ –æ–±—Ä–∞–∑—Ü—ã –≤ –ø—Ä–æ—Ü–µ—Å—Å —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ
[08.10.2024 08:18] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º FAN, –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –§—É—Ä—å–µ. FAN —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –º–æ–¥–µ–ª–∏—Ä—É–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —è–≤–ª–µ–Ω–∏—è, –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏. –ê–≤—Ç–æ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ FAN –Ω–∞–¥ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–º 
[08.10.2024 08:18] Querying the API.
[08.10.2024 08:18] Got response. {
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å–æ–¥–µ—Ä–∂–∞—Ç –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á–µ–º —Å—á–∏—Ç–∞–ª–æ—Å—å —Ä–∞–Ω–µ–µ. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ —ç—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞—Ö, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ—à–∏–±–æ–∫. –û–¥–Ω–∞–∫–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä—ã –æ—à–∏–±–æ–∫ –Ω–µ –æ–±–æ–±—â–∞—é—Ç—Å—è –º–µ–∂–¥—É –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏, —á—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ç–∞–∫–∂–µ –≤—ã—è–≤–∏–ª–æ, —á—Ç–æ LLM –º–æ–≥—É—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–≤–µ—Ä–Ω—ã–π.",
  "tags": ["#hallucinations", "#errorDetection", "#internalRepresentations"],
  "emoji": "üîç",
  "title": "–†–∞—Å–∫—Ä—ã—Ç–∏–µ —Ç–∞–π–Ω –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π LLM –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ—à–∏–±–æ–∫"
}
[08.10.2024 08:18] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Presto! - –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É—Å–∫–æ—Ä–µ–Ω–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–µ—Ç–æ–¥ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (DMD) –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —à–∞–≥–æ–≤ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è. –û–Ω–∏ —Ç–∞–∫–∂–µ —É–ª—É—á—à–∏–ª–∏ –º–µ—Ç–æ–¥ –ø–æ—Å–ª
[08.10.2024 08:18] Using data from previous issue: {"desc": "OmniBooth - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–µ–π –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –°–∏—Å—Ç–µ–º–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–¥–∞–≤–∞—Ç—å —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π-–æ–±—Ä–∞–∑—Ü–æ–≤. –ö–ª—é—á–µ–≤—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–¥
[08.10.2024 08:18] Querying the API.
[08.10.2024 08:18] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ MathHay –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤, MathHay —Ç—Ä–µ–±—É–µ—Ç –æ—Ç –º–æ–¥–µ–ª–µ–π –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –∏ —Å–ª–æ–∂–Ω—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –≤–æ—Å–µ–º—å—é –≤–µ–¥—É—â–∏–º–∏ LLM –ø–æ–∫–∞–∑–∞–ª–∏, —á—Ç–æ –¥–∞–∂–µ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å Gemini-1.5-Pro-002 –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤—Å–µ–≥–æ 51.26% –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö –¥–ª–∏–Ω–æ–π 128 —Ç—ã—Å—è—á —Ç–æ–∫–µ–Ω–æ–≤. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π LLM –≤ –æ–±–ª–∞—Å—Ç–∏ –¥–ª–∏–Ω–Ω—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.",

  "tags": ["#LongContextMathReasoning", "#MathHayBenchmark", "#LLMEvaluation"],

  "emoji": "üßÆ",

  "title": "MathHay: –ù–æ–≤—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"
}
[08.10.2024 08:18] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ (TLDR) –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. TLDR –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª—É—á—à–µ —É—á–∏—Ç—ã–≤–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—É—é, —Ç–∞–∫ –∏ –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ '—Å–ª–æ–∂–Ω—ã–µ –æ—Ç—Ä–∏
[08.10.2024 08:18] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö. –î–≤–∞ –∞–≥–µ–Ω—Ç–∞ –≤ –æ–±—â–µ–π —Å—Ü–µ–Ω–µ –¥–æ–ª–∂–Ω—ã —É—á–∏—Ç—ã–≤–∞—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—É—é –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—É –¥—Ä—É–≥ –¥—Ä—É–≥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä–µ–∫—Ç—ã –∏ –∏—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Å–æ–±—Ä–∞–ª–∏
[08.10.2024 08:18] Using data from previous issue: {"desc": "MonST3R - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏. –í–º–µ—Å—Ç–æ —Å–ª–æ–∂–Ω—ã—Ö –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã—Ö —Å–∏—Å—Ç–µ–º, –æ–Ω –Ω–∞–ø—Ä—è–º—É—é –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞, –∞–¥–∞–ø—Ç–∏—Ä—É—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ DUST3R –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Ö–≤–∞—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –∞–≤—Ç–æ—Ä—ã 
[08.10.2024 08:18] Using data from previous issue: {"desc": "UniMuMo - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, —Å–ø–æ—Å–æ–±–Ω–∞—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –º—É–∑—ã–∫—É –∏ –¥–≤–∏–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–∏—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è—Ö. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–µ—Å–ø–∞—Ä–µ–Ω–Ω—ã—Ö –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö –∏ –¥–≤–∏–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∏—Ç–º–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ UniMuMo –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ 
[08.10.2024 08:18] Using data from previous issue: {"desc": "TurtleBench - –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–æ–≥–∞–¥–∫–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –∏–≥—Ä–µ Turtle Soup Puzzle. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏, —Å–Ω–∏–∂–∞—è —Ä–∏—Å–∫ –æ–±–º–∞–Ω–∞ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –º–æ–¥–µ–ª–µ–π –∏ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤
[08.10.2024 08:18] Querying the API.
[08.10.2024 08:18] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Å–ª–æ–∂–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π —á–µ–ª–æ–≤–µ–∫–∞ –≤ 3D-—Å—Ä–µ–¥–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ —Ü–µ–ª–µ–≤–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–≤–∏–∂–µ–Ω–∏—è –∏ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏ –¥–µ–π—Å—Ç–≤–∏–π. –î–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–≤–∏–∂–µ–Ω–∏–π —Å –æ–∫—Ä—É–∂–µ–Ω–∏–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ü–µ–Ω—ã, —É—á–∏—Ç—ã–≤–∞—é—â–µ–µ –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ. –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞–Ω –æ–±—à–∏—Ä–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ 16 —á–∞—Å–æ–≤ –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π –≤ 120 indoor-—Å—Ü–µ–Ω–∞—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.",
  "tags": ["#—Å–∏–Ω—Ç–µ–∑_–¥–≤–∏–∂–µ–Ω–∏–π", "#–¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ_–º–æ–¥–µ–ª–∏", "#3D_–∞–Ω–∏–º–∞—Ü–∏—è"],
  "emoji": "ü§ñ",
  "title": "–ò–ò –æ–∂–∏–≤–ª—è–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ 3D –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∫–æ–º–∞–Ω–¥–∞–º"
}
[08.10.2024 08:18] Renaming data file.
[08.10.2024 08:18] Renaming previous data. hf_papers.json to 2024-10-07_hf_papers.json
[08.10.2024 08:18] Saving new data file.
[08.10.2024 08:18] Generating page.
[08.10.2024 08:18] Renaming previous page.
[08.10.2024 08:18] Renaming previous data. index.html to 2024-10-07_hf_papers.html
[08.10.2024 08:18] Writing result.
[08.10.2024 08:18] Renaming log file.
[08.10.2024 08:18] Renaming previous data. log.txt to 2024-10-07_last_log.txt
