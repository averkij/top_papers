[08.10.2024 14:49] Get feed.
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05258
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02707
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04364
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02675
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05046
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05167
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04534
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04734
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04932
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03825
[08.10.2024 14:49] Extract page data from URL. URL: https://huggingface.co/papers/2410.05080
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04698
[08.10.2024 14:49] Extract page data from URL. URL: https://huggingface.co/papers/2410.05243
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02884
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03187
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05262
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03959
[08.10.2024 14:49] Extract page data from URL. URL: https://huggingface.co/papers/2410.05255
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03617
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05229
[08.10.2024 14:49] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05057
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 0. Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separa...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 1. Large language models (LLMs) often produce errors, including factual inaccuracies, biases, and reasoning failures, collectively referred to as "hallucinations". Recent studies have demonstrated that LLMs' internal states encode information regarding the truthfulness of their outputs, and that this i...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 2. Text-to-image (T2I) diffusion models have revolutionized visual content creation, but extending these capabilities to text-to-video (T2V) generation remains a challenge, particularly in preserving temporal consistency. Existing methods that aim to improve consistency often cause trade-offs such as r...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 3. Despite the remarkable success achieved by neural networks, particularly those represented by MLP and Transformer, we reveal that they exhibit potential flaws in the modeling and reasoning of periodicity, i.e., they tend to memorize the periodic data rather than genuinely understanding the underlyin...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 4. This technical report introduces a Named Clinical Entity Recognition Benchmark for evaluating language models in healthcare, addressing the crucial natural language processing (NLP) task of extracting structured information from clinical narratives to support applications like automated coding, clin...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 5. Despite advances in diffusion-based text-to-music (TTM) methods, efficient, high-quality generation remains a challenge. We introduce Presto!, an approach to inference acceleration for score-based diffusion transformers via reducing both sampling steps and cost per step. To reduce steps, we develop ...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 6. We introduce UniMuMo, a unified multimodal model capable of taking arbitrary text, music, and motion data as input conditions to generate outputs across all three modalities. To address the lack of time-synchronized data, we align unpaired music and motion data based on rhythmic patterns to leverage...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 7. Although reward models have been successful in improving multimodal large language models, the reward models themselves remain brutal and contain minimal information. Notably, existing reward models only mimic human annotations by assigning only one binary feedback to any text, no matter how long th...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 8. We present OmniBooth, an image generation framework that enables spatial control with instance-level multi-modal customization. For all instances, the multimodal instruction can be described through text prompts or image references. Given a set of user-defined masks and associated text or image guid...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 9. Estimating geometry from dynamic scenes, where objects move and deform over time, remains a core challenge in computer vision. Current approaches often rely on multi-stage pipelines or global optimizations that decompose the problem into subtasks, like depth and flow, leading to complex systems pron...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 10. The advancements of language language models (LLMs) have piqued growing interest in developing LLM-based language agents to automate scientific discovery end-to-end, which has sparked both excitement and skepticism about the true capabilities of such agents. In this work, we argue that for an agent ...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 11. Recent large language models (LLMs) have demonstrated versatile capabilities in long-context scenarios. Although some recent benchmarks have been developed to evaluate the long-context capabilities of LLMs, there is a lack of benchmarks evaluating the mathematical reasoning abilities of LLMs over lo...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 12. Multimodal large language models (MLLMs) are transforming the capabilities of graphical user interface (GUI) agents, facilitating their transition from controlled simulations to complex, real-world applications across various platforms. However, the effectiveness of these agents hinges on the robust...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 13. This paper presents an advanced mathematical problem-solving framework, LLaMA-Berry, for enhancing the mathematical reasoning ability of Large Language Models (LLMs). The framework combines Monte Carlo Tree Search (MCTS) with iterative Self-Refine to optimize the reasoning path and utilizes a pairwi...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 14. Synthesizing human motions in 3D environments, particularly those with complex activities such as locomotion, hand-reaching, and human-object interaction, presents substantial demands for user-defined waypoints and stage transitions. These requirements pose challenges for current models, leading to ...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 15. As the application of Large Language Models (LLMs) expands, the demand for reliable evaluations increases. Existing LLM evaluation benchmarks primarily rely on static datasets, making it challenging to assess model performance in dynamic interactions with users. Moreover, these benchmarks often depe...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 16. We introduce a task and dataset for referring expression generation and comprehension in multi-agent embodied environments. In this task, two agents in a shared scene must take into account one another's visual perspective, which may be different from their own, to both produce and understand refere...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 17. Reinforcement learning from human feedback (RLHF) methods are emerging as a way to fine-tune diffusion models (DMs) for visual generation. However, commonly used on-policy strategies are limited by the generalization capability of the reward model, while off-policy approaches require large amounts o...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 18. Model merging aims to combine multiple expert models into a more capable single model, offering benefits such as reduced storage and serving costs, improved generalization, and support for decentralized model development. Despite its promise, previous studies have primarily focused on merging a few ...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 19. Recent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has...
[08.10.2024 14:49] ********************************************************************************
[08.10.2024 14:49] Abstract 20. Data curation is the problem of how to collect and organize samples into a dataset that supports efficient learning. Despite the centrality of the task, little work has been devoted towards a large-scale, systematic comparison of various curation methods. In this work, we take steps towards a formal...
[08.10.2024 14:49] Read previous papers.
[08.10.2024 14:49] Generating reviews via LLM API.
[08.10.2024 14:49] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Diff Transformer, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ –∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∏ –ø–æ–¥–∞–≤–ª—è–µ—Ç —à—É–º. –ú–µ—Ö–∞–Ω–∏–∑–º –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –≤—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è –∫–∞–∫ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –¥–≤—É–º—è –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è softmax. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ Diff Transform
[08.10.2024 14:49] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å–æ–¥–µ—Ä–∂–∞—Ç –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á–µ–º —Å—á–∏—Ç–∞–ª–æ—Å—å —Ä–∞–Ω–µ–µ. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ —ç—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞—Ö, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å –æ–±–Ω–∞—Ä—É
[08.10.2024 14:49] Using data from previous issue: {"desc": "VideoGuide - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –ø–æ —Ç–µ–∫—Å—Ç—É –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–∏—Ñ—Ñ—É–∑–∏–∏ –≤–∏–¥–µ–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≥–∏–¥–∞ –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —ç—Ç–∞–ø–∞—Ö –≤—ã–≤–æ–¥–∞, –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É—è –µ–µ –æ–±—Ä–∞–∑—Ü—ã –≤ –ø—Ä–æ—Ü–µ—Å—Å —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ
[08.10.2024 14:49] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º FAN, –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –§—É—Ä—å–µ. FAN —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –º–æ–¥–µ–ª–∏—Ä—É–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —è–≤–ª–µ–Ω–∏—è, –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏. –ê–≤—Ç–æ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ FAN –Ω–∞–¥ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–º 
[08.10.2024 14:49] Using data from previous issue: {"desc": "–≠—Ç–æ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π. –ë–µ–Ω—á–º–∞—Ä–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ–¥–∏—Ü–∏
[08.10.2024 14:49] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Presto! - –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É—Å–∫–æ—Ä–µ–Ω–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–µ—Ç–æ–¥ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (DMD) –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —à–∞–≥–æ–≤ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è. –û–Ω–∏ —Ç–∞–∫–∂–µ —É–ª—É—á—à–∏–ª–∏ –º–µ—Ç–æ–¥ –ø–æ—Å–ª
[08.10.2024 14:49] Using data from previous issue: {"desc": "UniMuMo - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, —Å–ø–æ—Å–æ–±–Ω–∞—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –º—É–∑—ã–∫—É –∏ –¥–≤–∏–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–∏—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è—Ö. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–µ—Å–ø–∞—Ä–µ–Ω–Ω—ã—Ö –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö –∏ –¥–≤–∏–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∏—Ç–º–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ UniMuMo –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ 
[08.10.2024 14:49] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ (TLDR) –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. TLDR –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª—É—á—à–µ —É—á–∏—Ç—ã–≤–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—É—é, —Ç–∞–∫ –∏ –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ '—Å–ª–æ–∂–Ω—ã–µ –æ—Ç—Ä–∏
[08.10.2024 14:49] Using data from previous issue: {"desc": "OmniBooth - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–µ–π –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –°–∏—Å—Ç–µ–º–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–¥–∞–≤–∞—Ç—å —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π-–æ–±—Ä–∞–∑—Ü–æ–≤. –ö–ª—é—á–µ–≤—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–¥
[08.10.2024 14:49] Using data from previous issue: {"desc": "MonST3R - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏. –í–º–µ—Å—Ç–æ —Å–ª–æ–∂–Ω—ã—Ö –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã—Ö —Å–∏—Å—Ç–µ–º, –æ–Ω –Ω–∞–ø—Ä—è–º—É—é –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞, –∞–¥–∞–ø—Ç–∏—Ä—É—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ DUST3R –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Ö–≤–∞—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –∞–≤—Ç–æ—Ä—ã 
[08.10.2024 14:49] Querying the API.
[08.10.2024 14:50] Got response. {
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ ScienceAgentBench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤ –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö. –ê–≤—Ç–æ—Ä—ã –∏–∑–≤–ª–µ–∫–ª–∏ 102 –∑–∞–¥–∞—á–∏ –∏–∑ 44 —Ä–µ—Ü–µ–Ω–∑–∏—Ä—É–µ–º—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π –≤ —á–µ—Ç—ã—Ä–µ—Ö –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ö –∏ –ø—Ä–∏–≤–ª–µ–∫–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –∏—Ö –≤–∞–ª–∏–¥–∞—Ü–∏–∏. –ë–µ–Ω—á–º–∞—Ä–∫ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Python-–∫–æ–¥ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö –∑–∞–¥–∞—á. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –¥–∞–∂–µ –ª—É—á—à–∏–π –∞–≥–µ–Ω—Ç —Ä–µ—à–∞–µ—Ç —Ç–æ–ª—å–∫–æ 32.4% –∑–∞–¥–∞—á —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ, —á—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –Ω–∞—É—á–Ω–æ–π —Å—Ñ–µ—Ä–µ.",
  "tags": ["#languageAgents", "#scientificDiscovery", "#codeGeneration"],
  "emoji": "üß™",
  "title": "–†–µ–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –≤ –Ω–∞—É–∫–µ"
}
[08.10.2024 14:50] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ MathHay –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤, MathHay —Ç—Ä–µ–±—É–µ—Ç –æ—Ç –º–æ–¥–µ–ª–µ–π –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –∏ —Å–ª–æ–∂–Ω—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.
[08.10.2024 14:50] Querying the API.
[08.10.2024 14:50] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∞–≥–µ–Ω—Ç–æ–≤ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (GUI) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–æ–¥–µ–ª—å UGround, –∫–æ—Ç–æ—Ä–∞—è –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–º –≤–æ—Å–ø—Ä–∏—è—Ç–∏–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ UGround –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–≤—è–∑–∫–∏ –¥–ª—è GUI-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ 20%. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤, –Ω–∞–≤–∏–≥–∏—Ä—É—é—â–∏—Ö –≤ —Ü–∏—Ñ—Ä–æ–≤–æ–º –º–∏—Ä–µ –ø–æ–¥–æ–±–Ω–æ –ª—é–¥—è–º.",
  "tags": ["#–≤–∏–∑—É–∞–ª—å–Ω–∞—è_–ø—Ä–∏–≤—è–∑–∫–∞", "#GUI_–∞–≥–µ–Ω—Ç—ã", "#UGround"],
  "emoji": "üëÅÔ∏è",
  "title": "–í–∏–∑—É–∞–ª—å–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ - –∫–ª—é—á –∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º GUI-–∞–≥–µ–Ω—Ç–∞–º"
}
[08.10.2024 14:50] Using data from previous issue: {"desc": "LLaMA-Berry - —ç—Ç–æ –ø–µ—Ä–µ–¥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á, —É–ª—É—á—à–∞—é—â–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º. –û–Ω–∞ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–µ—Ç–æ–¥ –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –¥–µ—Ä–µ–≤—É (MCTS) —Å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–º —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏–µ–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—É—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ
[08.10.2024 14:50] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Å–ª–æ–∂–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π —á–µ–ª–æ–≤–µ–∫–∞ –≤ 3D-—Å—Ä–µ–¥–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ —Ü–µ–ª–µ–≤–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–≤–∏–∂–µ–Ω–∏—è –∏ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–µ—Ä–µ—Ö
[08.10.2024 14:50] Using data from previous issue: {"desc": "TurtleBench - –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–æ–≥–∞–¥–∫–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –∏–≥—Ä–µ Turtle Soup Puzzle. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏, —Å–Ω–∏–∂–∞—è —Ä–∏—Å–∫ –æ–±–º–∞–Ω–∞ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –º–æ–¥–µ–ª–µ–π –∏ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤
[08.10.2024 14:50] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö. –î–≤–∞ –∞–≥–µ–Ω—Ç–∞ –≤ –æ–±—â–µ–π —Å—Ü–µ–Ω–µ –¥–æ–ª–∂–Ω—ã —É—á–∏—Ç—ã–≤–∞—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—É—é –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—É –¥—Ä—É–≥ –¥—Ä—É–≥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä–µ–∫—Ç—ã –∏ –∏—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Å–æ–±—Ä–∞–ª–∏
[08.10.2024 14:50] Querying the API.
[08.10.2024 14:50] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –¥–ª—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞—á–∞—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ. –ú–µ—Ç–æ–¥ SePPO (Semi-Policy Preference Optimization) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –º–æ–¥–µ–ª–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∑–∞–º–µ–Ω—ã '–ø—Ä–æ–∏–≥—Ä—ã—à–Ω—ã—Ö' –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞—Ä–∞—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –∫—Ä–∏—Ç–µ—Ä–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —è–∫–æ—Ä–µ–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤. SePPO –ø—Ä–µ–≤–∑–æ—à–µ–ª —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–¥—Ö–æ–¥—ã –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö text-to-image –∏ text-to-video.",
  "tags": ["#diffusion_models", "#preference_optimization", "#text_to_image_generation"],
  "emoji": "üñºÔ∏è",
  "title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –±–µ–∑ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
}
[08.10.2024 14:50] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—è –≤–ª–∏—è–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏, –∫–∞—á–µ—Å—Ç–≤–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ä–∞–∑–º–µ—Ä–æ–º –æ
[08.10.2024 14:50] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –æ—Ü–µ–Ω–∫–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ GSM-Symbolic, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏—Ö —à–∞–±–ª–æ–Ω–æ–≤ –¥–ª—è –±–æ–ª–µ–µ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–π –æ—Ü–µ–Ω–∫–∏. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å LLM –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–Ω
[08.10.2024 14:50] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç SELECT –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∫—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –∑–∞–¥–∞—á–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ImageNet++, –≤–∫–ª—é—á–∞—é—â–∏–π 5 –Ω–æ–≤—ã—Ö —Å–¥–≤–∏–≥–æ–≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ–¥–µ–Ω–∞ –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∫—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è, –≤–∫–ª—é—á–∞—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å
[08.10.2024 14:50] Renaming data file.
[08.10.2024 14:50] Renaming previous data. hf_papers.json to 2024-10-07_hf_papers.json
[08.10.2024 14:50] Saving new data file.
[08.10.2024 14:50] Generating page.
[08.10.2024 14:50] Renaming previous page.
[08.10.2024 14:50] Renaming previous data. index.html to 2024-10-07_hf_papers.html
[08.10.2024 14:50] Writing result.
[08.10.2024 14:50] Renaming log file.
[08.10.2024 14:50] Renaming previous data. log.txt to 2024-10-07_last_log.txt
