[23.06.2025 00:59] Read previous papers.
[23.06.2025 00:59] Generating top page (month).
[23.06.2025 00:59] Writing top page (month).
[23.06.2025 02:55] Read previous papers.
[23.06.2025 02:55] Get feed.
[23.06.2025 02:55] Extract page data from URL. URL: https://huggingface.co/papers/2506.16504
[23.06.2025 02:55] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.06.2025 02:55] Downloading and parsing papers (pdf, html). Total: 1.
[23.06.2025 02:55] Downloading and parsing paper https://huggingface.co/papers/2506.16504.
[23.06.2025 02:55] Downloading paper 2506.16504 from http://arxiv.org/pdf/2506.16504v1...
[23.06.2025 02:55] Extracting affiliations from text.
[23.06.2025 02:55] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Tencent Hunyuan Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details Tencent Hunyuan3D https://3d.hunyuan.tencent.com https://github.com/Tencent/Hunyuan3D- "
[23.06.2025 02:55] Response: []
[23.06.2025 02:55] Extracting affiliations from text.
[23.06.2025 02:55] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Tencent Hunyuan Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details Tencent Hunyuan3D https://3d.hunyuan.tencent.com https://github.com/Tencent/Hunyuan3D-In this report, we present Hunyuan3D 2.5, robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce new shape foundation model LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation. 5 2 0 2 9 1 ] . [ 1 4 0 5 6 1 . 6 0 5 2 : r Figure 1: High quality 3D assets generated by Hunyuan3D 2.5.3D generation has rapidly developed in recent years, becoming core driver of innovation and growth across various industries. From game development to embodied AI, from film special effects to virtual reality, the application scenarios of 3D models continue to expand, demonstrating their immense potential and value. With advancements in artificial intelligence, 3D generation has become more efficient and powerful, particularly in areas such as automated modeling and texturing, further simplifying the creative process and enhancing production efficiency. Notably, recent 3D shape diffusion models based on 3dshape2vecset (Zhang et al., 2023) have pioneered revolution in the 3D shape generation pipeline, as demonstrated by works such as CLAY (Zhang et al., 2024b), Hunyuan3D 2.0 (Zhao et al., 2025), and TripoSG (Li et al., 2025). Direct3D (Wu et al., 2024b),from another aspect, shown the potential of compressing and generating the shape via triplane. More recently, Trellis (Xiang et al., 2024) has emerged as promising pipeline for high-quality textured 3D generation, leveraging its invented structured 3D latents as representations. Nevertheless, existing models are still limited for generating complex objects with finegrained details as demonstrated in figure 2. It remains an open problem how we could generate high-fidelity and detailed shape while maintaining smooth surface and sharp edges. High-quality textures play crucial role in enhancing the visual realism and detail representation of 3D assets. Recently, Numerous texture generation methods based on multiview diffusion (Zhao et al., 2025; Huang et al., 2024b; Vainer et al., 2024b; Li et al., 2024a; Tang et al., 2025; Long et al., 2024; Wang & Shi, 2023; Shi et al., 2023b;a) have emerged, alleviating global consistency issue of inpaintingbased methods (Huang et al., 2024a; Wu et al., 2024a; Zhang et al., 2024c; Ceylan et al., 2024; Zeng et al., 2024a; Chen et al., 2023a; Richardson et al., 2023) and synchronization techniques (Liu et al., 2025; Gao et al., 2024; Liu et al., 2024a; Zhang et al., 2024a). However, challenges remain in generating highly consistent multiview images, which can lead to artifacts and seams during the fusion and baking stages. Moreover, traditional RGB textures can no longer meet the demands for photorealistic 3D asset generation, while PBR material generation solution is not available in open source community. This report presents Hunyuan3D 2.5, robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 builds upon the twostage pipeline of its predecessor Hunyuan3D 2.0 (Zhao et al., 2025) and 2.1 (Hunyuan3D et al., 2025), while showcasing significant advancements in both shape generation and texture synthesis. Figure 2: Drawbacks of existing methods: failure at detail generation and incorrect PBR. In the first stage of shape generation, we introduce new shape foundation model LATTICE, which has been trained on large-scale, high-quality datasets with increased model size and computational resources. We found that this new model exhibits stable improvement when scaling up the model. Benifit from these characteristics, our largest model generates detailed and sharp 3D shape with precise alignment to corresponding images while maintaining clean and smooth surfaces, significantly closing the gap between generated and handcrafted 3D shapes. In the second stage of texture generation, we extend the Hunyuan3D 2.0 (Zhao et al., 2025) and 2.1 (Hunyuan3D et al., 2025) texture generation model into high-fidelity material generation framework. Adhering to the principled BRDF model, our approach produces multi-view albedo, roughness, and metallic maps simultaneously. This aims to precisely describe the surface reflection properties of generated 3D assets and accurately simulate geometric microsurface distributions, 2 Figure 3: Overview of Hunyuan3D 2.5 pipeline. It separates the 3D asset generation into two stages: first, it generates the shape, and then it creates the texture based on that shape. thereby achieving more realistic and detailed rendering results. Furthermore, we introduce dual-phase resolution enhancement strategy to strengthen texture-geometry coordination, thereby improving end-to-end visual quality. We perform extensive quantitative and qualitative evaluations as well as user studies in terms of shape generation and end-to-end texture generation, across diverse range of in-the-wild input images. The results demonstrate that Hunyuan3D 2.5 outperforms state-of-the-art open-source and closed-source commercial models.Hunyuan3D 2.5 is an image-to-3D generation model, which follows the same overall architecture of Hunyuan3D 2.0 (Zhao et al., 2025), as shown in figure 3. In nutshell, the input image is first processed by an image processor to remove the background and perform proper resizing. Then, shape generation model is conditioned on the input image and generates the 3D mesh without texture. The mesh is further processed to extract normal, UV map, and etc. After that, texture generation model is called to generate the texture with previous outputs. 2.1 Detailed Shape Generation Hunyu"
[23.06.2025 02:55] Mistral response. {"id": "3f645d790e2b4981ade6aa5f0e9cab3b", "object": "chat.completion", "created": 1750647351, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Tencent\"]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1792, "total_tokens": 1804, "completion_tokens": 12}}
[23.06.2025 02:55] Response: ```python
["Tencent"]
```
[23.06.2025 02:55] Deleting PDF ./assets/pdf/2506.16504.pdf.
[23.06.2025 02:55] Success.
[23.06.2025 02:55] Enriching papers with extra data.
[23.06.2025 02:55] ********************************************************************************
[23.06.2025 02:55] Abstract 0. Hunyuan3D 2.5, a suite of 3D diffusion models, advances shape and texture generation with a new LATTICE model and physical-based rendering in a multi-view architecture.  					AI-generated summary 				 In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating...
[23.06.2025 02:55] Read previous papers.
[23.06.2025 02:55] Generating reviews via LLM API.
[23.06.2025 02:55] Querying the API.
[23.06.2025 02:55] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Hunyuan3D 2.5, a suite of 3D diffusion models, advances shape and texture generation with a new LATTICE model and physical-based rendering in a multi-view architecture.  					AI-generated summary 				 In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.
[23.06.2025 02:55] Response: {
  "desc": "Hunyuan3D 2.5 Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ğ´Ğ»Ñ 3D-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸, ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ¸Ğ¹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ¾Ñ€Ğ¼ Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€. ĞšĞ»ÑÑ‡ĞµĞ²Ğ¾Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ - Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ LATTICE Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ„Ğ¾Ñ€Ğ¼, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ñ… Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ…. Ğ”Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ½Ğ´ĞµÑ€Ğ¸Ğ½Ğ³ (PBR) Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ€Ğ°ĞºÑƒÑ€ÑĞ½Ğ¾Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ. Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼, Hunyuan3D 2.5 Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ°Ğº Ñ„Ğ¾Ñ€Ğ¼, Ñ‚Ğ°Ğº Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€.",
  "emoji": "ğŸ§Š",
  "title": "ĞĞ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ 3D-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸: Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ñ‹ Ğ¸ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ñ‹"
}
[23.06.2025 02:55] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hunyuan3D 2.5, a suite of 3D diffusion models, advances shape and texture generation with a new LATTICE model and physical-based rendering in a multi-view architecture.  					AI-generated summary 				 In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation."

[23.06.2025 02:55] Response: ```python
['3D']
```
[23.06.2025 02:55] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Hunyuan3D 2.5, a suite of 3D diffusion models, advances shape and texture generation with a new LATTICE model and physical-based rendering in a multi-view architecture.  					AI-generated summary 				 In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation."

[23.06.2025 02:55] Response: ```python
["DIFFUSION"]
```
[23.06.2025 02:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Hunyuan3D 2.5 is a suite of advanced 3D diffusion models designed to enhance the generation of high-quality 3D shapes and textures. It introduces the LATTICE model, a new foundation for shape generation that utilizes large, high-quality datasets and boasts a model size of up to 10 billion parameters. This model produces sharp and detailed 3D shapes while maintaining clean mesh surfaces, bridging the gap between generated and handcrafted designs. Additionally, the suite incorporates physical-based rendering in a multi-view architecture to improve texture generation, demonstrating significant improvements over previous versions.","title":"Revolutionizing 3D Asset Generation with Hunyuan3D 2.5"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Hunyuan3D 2.5 is a suite of advanced 3D diffusion models designed to enhance the generation of high-quality 3D shapes and textures. It introduces the LATTICE model, a new foundation for shape generation that utilizes large, high-quality datasets and boasts a model size of up to 10 billion parameters. This model produces sharp and detailed 3D shapes while maintaining clean mesh surfaces, bridging the gap between generated and handcrafted designs. Additionally, the suite incorporates physical-based rendering in a multi-view architecture to improve texture generation, demonstrating significant improvements over previous versions.', title='Revolutionizing 3D Asset Generation with Hunyuan3D 2.5'))
[23.06.2025 02:56] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Hunyuan3D 2.5 æ˜¯ä¸€å¥—å…ˆè¿›çš„ 3D æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨ç”Ÿæˆé«˜ä¿çœŸå’Œç»†è‡´çš„çº¹ç† 3D èµ„äº§ã€‚å®ƒåœ¨å½¢çŠ¶ç”Ÿæˆæ–¹é¢å¼•å…¥äº†æ–°çš„åŸºç¡€æ¨¡å‹ LATTICEï¼Œç»è¿‡å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†çš„è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆæ¸…æ™°ä¸”ç»†è‡´çš„ 3D å½¢çŠ¶ã€‚çº¹ç†ç”Ÿæˆæ–¹é¢ï¼Œé‡‡ç”¨äº†åŸºäºç‰©ç†çš„æ¸²æŸ“ï¼ˆPBRï¼‰æŠ€æœ¯ï¼Œç»“åˆäº†å¤šè§†è§’æ¶æ„ï¼Œæ˜¾è‘—æå‡äº†çº¹ç†è´¨é‡ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒHunyuan3D 2.5 åœ¨å½¢çŠ¶å’Œçº¹ç†ç”Ÿæˆæ–¹é¢å‡ä¼˜äºä¹‹å‰çš„æ–¹æ³•ã€‚","title":"Hunyuan3D 2.5ï¼šå½¢çŠ¶ä¸çº¹ç†ç”Ÿæˆçš„æ–°çªç ´"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Hunyuan3D 2.5 æ˜¯ä¸€å¥—å…ˆè¿›çš„ 3D æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨ç”Ÿæˆé«˜ä¿çœŸå’Œç»†è‡´çš„çº¹ç† 3D èµ„äº§ã€‚å®ƒåœ¨å½¢çŠ¶ç”Ÿæˆæ–¹é¢å¼•å…¥äº†æ–°çš„åŸºç¡€æ¨¡å‹ LATTICEï¼Œç»è¿‡å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†çš„è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆæ¸…æ™°ä¸”ç»†è‡´çš„ 3D å½¢çŠ¶ã€‚çº¹ç†ç”Ÿæˆæ–¹é¢ï¼Œé‡‡ç”¨äº†åŸºäºç‰©ç†çš„æ¸²æŸ“ï¼ˆPBRï¼‰æŠ€æœ¯ï¼Œç»“åˆäº†å¤šè§†è§’æ¶æ„ï¼Œæ˜¾è‘—æå‡äº†çº¹ç†è´¨é‡ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒHunyuan3D 2.5 åœ¨å½¢çŠ¶å’Œçº¹ç†ç”Ÿæˆæ–¹é¢å‡ä¼˜äºä¹‹å‰çš„æ–¹æ³•ã€‚', title='Hunyuan3D 2.5ï¼šå½¢çŠ¶ä¸çº¹ç†ç”Ÿæˆçš„æ–°çªç ´'))
[23.06.2025 02:56] Renaming data file.
[23.06.2025 02:56] Renaming previous data. hf_papers.json to ./d/2025-06-23.json
[23.06.2025 02:56] Saving new data file.
[23.06.2025 02:56] Generating page.
[23.06.2025 02:56] Renaming previous page.
[23.06.2025 02:56] Renaming previous data. index.html to ./d/2025-06-23.html
[23.06.2025 02:56] Writing result.
[23.06.2025 02:56] Renaming log file.
[23.06.2025 02:56] Renaming previous data. log.txt to ./logs/2025-06-23_last_log.txt
