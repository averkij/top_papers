[23.06.2025 22:11] Read previous papers.
[23.06.2025 22:11] Generating top page (month).
[23.06.2025 22:11] Writing top page (month).
[23.06.2025 23:09] Read previous papers.
[23.06.2025 23:09] Get feed.
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16406
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16035
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16054
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09049
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17201
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16310
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17206
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16504
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17218
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15745
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15442
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17202
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17213
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15925
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09930
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17113
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17090
[23.06.2025 23:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16349
[23.06.2025 23:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.06.2025 23:09] No deleted papers detected.
[23.06.2025 23:09] Downloading and parsing papers (pdf, html). Total: 18.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.16406.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.16406.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.16406.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.16035.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.16035.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.16035.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.16054.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.16054.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.16054.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.09049.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.09049.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.09049.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.17201.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.17201.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.17201.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.16310.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.16310.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.16310.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.17206.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.17206.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.17206.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.16504.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.16504.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.16504.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.17218.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.17218.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.17218.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.15745.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.15745.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.15745.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.15442.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.15442.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.15442.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.17202.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.17202.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.17202.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.17213.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.17213.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.17213.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.15925.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.15925.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.15925.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.09930.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.09930.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.09930.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.17113.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.17113.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.17113.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.17090.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.17090.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.17090.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Downloading and parsing paper https://huggingface.co/papers/2506.16349.
[23.06.2025 23:09] Extra JSON file exists (./assets/json/2506.16349.json), skip PDF parsing.
[23.06.2025 23:09] Paper image links file exists (./assets/img_data/2506.16349.json), skip HTML parsing.
[23.06.2025 23:09] Success.
[23.06.2025 23:09] Enriching papers with extra data.
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 0. Drag-and-Drop LLMs generate task-specific parameters through prompt-conditioned parameter generation, achieving significant efficiency gains and cross-domain generalization without per-task training.  					AI-generated summary 				 Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-ra...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 1. A novel multimodal document chunking approach using Large Multimodal Models (LMMs) enhances RAG performance by accurately processing complex PDF documents, including multi-page tables and embedded visuals.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) systems have revolutioniz...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 2. PAROAttention reorganizes visual attention patterns to enable efficient sparsification and quantization, reducing memory and computational costs with minimal impact on performance.  					AI-generated summary 				 In visual generation, the quadratic complexity of attention mechanisms results in high ...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 3. VIKI-Bench and VIKI-R provide a benchmark and framework for evaluating and improving visual-driven cooperation among diverse embodied agents using vision-language models and reinforcement learning.  					AI-generated summary 				 Coordinating multiple embodied agents in dynamic environments remains ...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 4. Hunyuan-GameCraft is a novel framework for high-dynamic interactive video generation in game environments that addresses limitations in dynamics, generality, and efficiency through unified input representation, hybrid history-conditioned training, and model distillation.  					AI-generated summary 	...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 5. A new TTS architecture improves accent accuracy and emotion recognition for Hindi and Indian English by integrating phoneme alignment, culture-sensitive emotion embeddings, and dynamic accent code switching.  					AI-generated summary 				 State-of-the-art text-to-speech (TTS) systems realize high n...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 6. Multi-plane synchronization extends 2D foundation models to 3D panorama generation, introducing DreamCube to achieve diverse appearances and accurate geometry.  					AI-generated summary 				 3D panorama synthesis is a promising yet challenging task that demands high-quality and diverse visual appea...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 7. Hunyuan3D 2.5, a suite of 3D diffusion models, advances shape and texture generation with a new LATTICE model and physical-based rendering in a multi-view architecture.  					AI-generated summary 				 In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 8. Mirage enhances vision-language models by integrating latent visual tokens into text decoding to improve multimodal reasoning without generating explicit images.  					AI-generated summary 				 Vision-language models (VLMs) excel at multimodal understanding, yet their text-only decoding forces them ...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 9. InfiniPot-V is a training-free, query-agnostic framework that compresses the key-value cache during video encoding to maintain a fixed memory cap for streaming video understanding, enhancing real-time performance and accuracy.  					AI-generated summary 				 Modern multimodal large language models (...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 10. The tutorial provides a comprehensive guide on using Hunyuan3D 2.1 for generating high-resolution, textured 3D models, covering data preparation, model architecture, training, evaluation, and deployment.  					AI-generated summary 				 3D AI-generated content (AIGC) is a passionate field that has si...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 11. A Y-shaped architecture, UniFork, balances shared learning and task specialization for unified image understanding and generation, outperforming conventional fully shared Transformer models.  					AI-generated summary 				 Unified image understanding and generation has emerged as a promising paradig...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 12. InfGen, a unified next-token prediction model, enables stable long-term traffic simulation by interleaving closed-loop motion simulation and scene generation.  					AI-generated summary 				 An ideal traffic simulator replicates the realistic long-term point-to-point trip that a self-driving system ...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 13. Reranking and preference tuning improve the quality of perspective summaries generated by LLMs, as measured by language model-based metrics that outperform traditional ones.  					AI-generated summary 				 Generating unbiased summaries in real-world settings such as political perspective summarizati...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 14. A unified benchmark suite evaluates Vision-Language-Action models' generalization and motor execution capabilities, highlighting the disparity between perceptual understanding and precise action execution.  					AI-generated summary 				 One promise that Vision-Language-Action (VLA) models hold over...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 15. MEXA is a training-free framework that aggregates outputs from specialized expert models using a Large Reasoning Model for effective multimodal reasoning across various domains.  					AI-generated summary 				 Combining pre-trained expert models offers substantial potential for scalable multimodal r...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 16. A new method called Prompt Inversion from Logprob Sequences (PILS) recovers hidden prompts in language models by analyzing the low-dimensional subspace of the model's next-token probabilities, achieving higher recovery rates and better generalization than previous methods.  					AI-generated summary...
[23.06.2025 23:09] ********************************************************************************
[23.06.2025 23:09] Abstract 17. A novel watermarking technique for autoregressive image generation models achieves reliable detection through improved reverse cycle-consistency and synchronization layers.  					AI-generated summary 				 Watermarking the outputs of generative models has emerged as a promising approach for tracking ...
[23.06.2025 23:09] Read previous papers.
[23.06.2025 23:09] Generating reviews via LLM API.
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal", "#training", "#optimization"], "emoji": "üé≠", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –Ø–ú: –±—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ Drag-and-Drop LLMs (DnD) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#dataset", "#long_context", "#optimization", "#rag", "#multimodal"], "emoji": "üìÑ", "ru": {"title": "–£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è RAG-—Å–∏—Å—Ç–µ–º", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑–±–∏–µ–Ω–∏—é —Å–ª–æ–∂–Ω—ã—Ö PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#optimization", "#cv", "#inference", "#architecture", "#video"], "emoji": "üî¨", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –º–µ–Ω—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, —Ç–∞ –∂–µ —Ç–æ—á–Ω–æ—Å—Ç—å", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ PAROAttention –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è –≤ –∑–∞–¥–∞—á–∞—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#games", "#rl", "#benchmark", "#cv"], "emoji": "ü§ñ", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–∞—è –∫–æ–æ–ø–µ—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "VIKI-Bench –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–æ–æ–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É –≤–æ–ø–ª–æ—â–µ–Ω–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#inference", "#video", "#diffusion", "#synthetic", "#dataset", "#games", "#training"], "emoji": "üéÆ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏–≥—Ä–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ", "desc": "Hunyuan-GameCraft - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–∏–¥–µ–æ –≤ –∏–≥—Ä–æ–≤—ã—Ö —Å—Ä–µ–¥–∞—Ö —Å –≤—ã—Å–æ–∫–æ–π –¥–∏
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#low_resource", "#machine_translation", "#multilingual", "#audio"], "emoji": "üó£Ô∏è", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ –¥–ª—è –∏–Ω–¥–∏–π—Å–∫–∏—Ö —è–∑—ã–∫–æ–≤ —Å —É—á–µ—Ç–æ–º –∞–∫—Ü–µ–Ω—Ç–∞ –∏ —ç–º–æ—Ü–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ (TTS) –¥–ª—è —Ö–∏–Ω–¥–∏ –∏ –∏–Ω–¥–∏–π—Å–∫–æ–≥–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ. –°–∏—Å—Ç–µ–º–∞ –∏
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#3d", "#cv"], "emoji": "üåê", "ru": {"title": "–ú–Ω–æ–≥–æ–ø–ª–æ—Å–∫–æ—Å—Ç–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: –º–æ—Å—Ç –º–µ–∂–¥—É 2D –∏ 3D –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞–Ω–æ—Ä–∞–º", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –ø–∞–Ω–æ—Ä–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–≥–æ–ø–ª–æ—Å–∫–æ—Å—Ç–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –¥–≤—É–º–µ—Ä–Ω—ã—Ö
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#diffusion", "#3d"], "emoji": "üßä", "ru": {"title": "–ù–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å 3D-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—ã –∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ç–µ–∫—Å—Ç—É—Ä—ã", "desc": "Hunyuan3D 2.5 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏ –¥–ª—è 3D-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —É–ª—É—á—à–∞—é—â–∏–π —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–æ—Ä–º –∏ —Ç–µ–∫—Å—Ç—É—Ä. –ö–ª—é—á–µ–≤–æ–µ –Ω–æ–≤–æ–≤–≤–µ–¥–µ–Ω–∏–µ - –º–æ–¥–µ–ª—å LATTICE –¥–ª—è –≥–µ
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#multimodal", "#rl", "#reasoning", "#games"], "emoji": "üß†", "ru": {"title": "–ú–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–∑—ã –¥–ª—è –ò–ò: —É–ª—É—á—à–µ–Ω–∏–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –±–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Mirage –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. Mirag
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#training", "#multimodal", "#optimization", "#long_context", "#video"], "emoji": "üé•", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –∫—ç—à–∞ –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "InfiniPot-V - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–∂–∞—Ç–∏—è –∫—ç—à–∞ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤–∏–¥–µ–æ, –Ω–µ —Ç—Ä–µ–±—É—é—â–∏–π –æ–±
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#training", "#3d", "#architecture", "#synthetic", "#games", "#data"], "emoji": "üé®", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏: –¥–æ—Å—Ç—É–ø–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ Hunyuan3D 2.1", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é Hunyuan3D 2.1 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–æ–∫–∞—á
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#multimodal"], "emoji": "üç¥", "ru": {"title": "UniFork: –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –æ–±—â–∏–º –æ–±—É—á–µ–Ω–∏–µ–º –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π –∑–∞–¥–∞—á", "desc": "UniFork - —ç—Ç–æ –Ω–æ–≤–∞—è Y-–æ–±—Ä–∞–∑–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω–∞ —Å–æ—á–µ—Ç–∞–µ—Ç –æ–±—â–∏–µ —Å–ª–æ–∏
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#training", "#optimization", "#agents", "#open_source", "#video"], "emoji": "üöó", "ru": {"title": "InfGen: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–º –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–æ—Ä–æ–∂–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è", "desc": "InfGen - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–æ–≤–æ–¥–∏—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –¥
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#dataset", "#interpretability", "#alignment", "#training", "#benchmark"], "emoji": "üîç", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±–∑–æ—Ä–æ–≤ —Å —Ä–∞–∑–Ω—ã—Ö —Ç–æ—á–µ–∫ –∑—Ä–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#cv", "#agi", "#optimization", "#survey", "#robotics", "#agents", "#benchmark", "#games"], "emoji": "ü§ñ", "ru": {"title": "–†–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É –Ω–∞–º–µ—Ä–µ–Ω–∏–µ–º –∏ –¥–µ–π—Å—Ç–≤–∏–µ–º: –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π VLA –≤ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–µ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π Vision-Lan
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark"], "emoji": "üß†", "ru": {"title": "MEXA: –£–º–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ò–ò", "desc": "MEXA - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#security", "#rlhf", "#hallucinations", "#data", "#transfer_learning", "#architecture"], "emoji": "üîç", "ru": {"title": "PILS: –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ PILS (Prompt Inversion from Logprob Sequences) –ø–æ–∑–≤–æ–ª—è
[23.06.2025 23:09] Using data from previous issue: {"categories": ["#security", "#multimodal", "#cv", "#training"], "emoji": "üñºÔ∏è", "ru": {"title": "–ù–∞–¥–µ–∂–Ω–∞—è –∑–∞—â–∏—Ç–∞ –∞–≤—Ç–æ—Ä—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Ç–µ—Ö–Ω–∏–∫—É –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ –∑–∞–∫–ª—é—á–∞–ª–∞—Å—å –≤ –æ—Ç—Å
[23.06.2025 23:09] Renaming data file.
[23.06.2025 23:09] Renaming previous data. hf_papers.json to ./d/2025-06-23.json
[23.06.2025 23:09] Saving new data file.
[23.06.2025 23:09] Generating page.
[23.06.2025 23:09] Renaming previous page.
[23.06.2025 23:09] Renaming previous data. index.html to ./d/2025-06-23.html
[23.06.2025 23:09] Writing result.
[23.06.2025 23:09] Renaming log file.
[23.06.2025 23:09] Renaming previous data. log.txt to ./logs/2025-06-23_last_log.txt
