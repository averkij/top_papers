[23.06.2025 03:53] Read previous papers.
[23.06.2025 03:53] Generating top page (month).
[23.06.2025 03:53] Writing top page (month).
[23.06.2025 04:27] Read previous papers.
[23.06.2025 04:27] Get feed.
[23.06.2025 04:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09049
[23.06.2025 04:27] Extract page data from URL. URL: https://huggingface.co/papers/2506.16406
[23.06.2025 04:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17206
[23.06.2025 04:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16504
[23.06.2025 04:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17201
[23.06.2025 04:27] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15925
[23.06.2025 04:27] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.06.2025 04:27] No deleted papers detected.
[23.06.2025 04:27] Downloading and parsing papers (pdf, html). Total: 6.
[23.06.2025 04:27] Downloading and parsing paper https://huggingface.co/papers/2506.09049.
[23.06.2025 04:27] Extra JSON file exists (./assets/json/2506.09049.json), skip PDF parsing.
[23.06.2025 04:27] Paper image links file exists (./assets/img_data/2506.09049.json), skip HTML parsing.
[23.06.2025 04:27] Success.
[23.06.2025 04:27] Downloading and parsing paper https://huggingface.co/papers/2506.16406.
[23.06.2025 04:27] Downloading paper 2506.16406 from http://arxiv.org/pdf/2506.16406v1...
[23.06.2025 04:27] Extracting affiliations from text.
[23.06.2025 04:27] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 1 ] . [ 1 6 0 4 6 1 . 6 0 5 2 : r Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights Zhiyuan Liang1 Dongwen Tang1 Yuhao Zhou1 Xuanlei Zhao1 Mingjia Shi1 Wangbo Zhao1 Zekai Li1 Peihao Wang2 Konstantin Sch√ºrholt3 Damian Borth3 Michael M. Bronstein4 Yang You1 Zhangyang Wang2 Kai Wang1 1National University of Singapore, 2UT Austin, 3University of St. Gallen, 4Oxford University "
[23.06.2025 04:27] Response: ```python
["National University of Singapore", "UT Austin", "University of St. Gallen", "Oxford University"]
```
[23.06.2025 04:27] Deleting PDF ./assets/pdf/2506.16406.pdf.
[23.06.2025 04:27] Success.
[23.06.2025 04:27] Downloading and parsing paper https://huggingface.co/papers/2506.17206.
[23.06.2025 04:27] Extra JSON file exists (./assets/json/2506.17206.json), skip PDF parsing.
[23.06.2025 04:27] Paper image links file exists (./assets/img_data/2506.17206.json), skip HTML parsing.
[23.06.2025 04:27] Success.
[23.06.2025 04:27] Downloading and parsing paper https://huggingface.co/papers/2506.16504.
[23.06.2025 04:27] Extra JSON file exists (./assets/json/2506.16504.json), skip PDF parsing.
[23.06.2025 04:27] Paper image links file exists (./assets/img_data/2506.16504.json), skip HTML parsing.
[23.06.2025 04:27] Success.
[23.06.2025 04:27] Downloading and parsing paper https://huggingface.co/papers/2506.17201.
[23.06.2025 04:27] Extra JSON file exists (./assets/json/2506.17201.json), skip PDF parsing.
[23.06.2025 04:27] Paper image links file exists (./assets/img_data/2506.17201.json), skip HTML parsing.
[23.06.2025 04:27] Success.
[23.06.2025 04:27] Downloading and parsing paper https://huggingface.co/papers/2506.15925.
[23.06.2025 04:27] Extra JSON file exists (./assets/json/2506.15925.json), skip PDF parsing.
[23.06.2025 04:27] Paper image links file exists (./assets/img_data/2506.15925.json), skip HTML parsing.
[23.06.2025 04:27] Success.
[23.06.2025 04:27] Enriching papers with extra data.
[23.06.2025 04:27] ********************************************************************************
[23.06.2025 04:27] Abstract 0. VIKI-Bench and VIKI-R provide a benchmark and framework for evaluating and improving visual-driven cooperation among diverse embodied agents using vision-language models and reinforcement learning.  					AI-generated summary 				 Coordinating multiple embodied agents in dynamic environments remains ...
[23.06.2025 04:27] ********************************************************************************
[23.06.2025 04:27] Abstract 1. Drag-and-Drop LLMs generate task-specific parameters through prompt-conditioned parameter generation, achieving significant efficiency gains and cross-domain generalization without per-task training.  					AI-generated summary 				 Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-ra...
[23.06.2025 04:27] ********************************************************************************
[23.06.2025 04:27] Abstract 2. Multi-plane synchronization extends 2D foundation models to 3D panorama generation, introducing DreamCube to achieve diverse appearances and accurate geometry.  					AI-generated summary 				 3D panorama synthesis is a promising yet challenging task that demands high-quality and diverse visual appea...
[23.06.2025 04:27] ********************************************************************************
[23.06.2025 04:27] Abstract 3. Hunyuan3D 2.5, a suite of 3D diffusion models, advances shape and texture generation with a new LATTICE model and physical-based rendering in a multi-view architecture.  					AI-generated summary 				 In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating...
[23.06.2025 04:27] ********************************************************************************
[23.06.2025 04:27] Abstract 4. Hunyuan-GameCraft is a novel framework for high-dynamic interactive video generation in game environments that addresses limitations in dynamics, generality, and efficiency through unified input representation, hybrid history-conditioned training, and model distillation.  					AI-generated summary 	...
[23.06.2025 04:27] ********************************************************************************
[23.06.2025 04:27] Abstract 5. Reranking and preference tuning improve the quality of perspective summaries generated by LLMs, as measured by language model-based metrics that outperform traditional ones.  					AI-generated summary 				 Generating unbiased summaries in real-world settings such as political perspective summarizati...
[23.06.2025 04:27] Read previous papers.
[23.06.2025 04:27] Generating reviews via LLM API.
[23.06.2025 04:27] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#games", "#rl", "#benchmark", "#cv"], "emoji": "ü§ñ", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω–∞—è –∫–æ–æ–ø–µ—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "VIKI-Bench –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–æ–æ–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É –≤–æ–ø–ª–æ—â–µ–Ω–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
[23.06.2025 04:27] Querying the API.
[23.06.2025 04:27] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Drag-and-Drop LLMs generate task-specific parameters through prompt-conditioned parameter generation, achieving significant efficiency gains and cross-domain generalization without per-task training.  					AI-generated summary 				 Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce Drag-and-Drop LLMs (\textit{DnD)}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to 12,000times lower overhead than full fine-tuning, ii) average gains up to 30\% in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at https://jerryliang24.github.io/DnD{https://jerryliang24.github.io/DnD}.
[23.06.2025 04:27] Response: {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ Drag-and-Drop LLMs (DnD) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. DnD –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç–∞–º–∏, –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤–µ—Å–æ–≤ LoRA –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç –∏ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏. DnD —Ç–∞–∫–∂–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞–¥–µ–∂–Ω—É—é –º–µ–∂–ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—é –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ü–µ–ª–µ–≤—ã–º –¥–∞–Ω–Ω—ã–º –∏–ª–∏ –º–µ—Ç–∫–∞–º.",
  "emoji": "üé≠",
  "title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –Ø–ú: –±—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
}
[23.06.2025 04:27] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Drag-and-Drop LLMs generate task-specific parameters through prompt-conditioned parameter generation, achieving significant efficiency gains and cross-domain generalization without per-task training.  					AI-generated summary 				 Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce Drag-and-Drop LLMs (\textit{DnD)}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to 12,000times lower overhead than full fine-tuning, ii) average gains up to 30\% in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at https://jerryliang24.github.io/DnD{https://jerryliang24.github.io/DnD}."

[23.06.2025 04:27] Response: ```python
['TRAINING', 'MULTIMODAL']
```
[23.06.2025 04:27] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Drag-and-Drop LLMs generate task-specific parameters through prompt-conditioned parameter generation, achieving significant efficiency gains and cross-domain generalization without per-task training.  					AI-generated summary 				 Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce Drag-and-Drop LLMs (\textit{DnD)}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to 12,000times lower overhead than full fine-tuning, ii) average gains up to 30\% in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at https://jerryliang24.github.io/DnD{https://jerryliang24.github.io/DnD}."

[23.06.2025 04:27] Response: ```python
["TRANSFER_LEARNING", "OPTIMIZATION"]
```
[23.06.2025 04:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Drag-and-Drop LLMs (DnD), a novel approach that generates task-specific parameters without the need for separate training on each task. By using prompt-conditioned parameter generation, DnD maps unlabeled task prompts directly to updates for low-rank adaptation (LoRA) weights. This method significantly reduces the computational overhead, achieving up to 12,000 times less than traditional fine-tuning while improving performance by an average of 30% on various benchmarks. DnD demonstrates strong cross-domain generalization, effectively adapting to new tasks without prior exposure to their data or labels.","title":"Efficient Task-Specific Adaptation with Drag-and-Drop LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces Drag-and-Drop LLMs (DnD), a novel approach that generates task-specific parameters without the need for separate training on each task. By using prompt-conditioned parameter generation, DnD maps unlabeled task prompts directly to updates for low-rank adaptation (LoRA) weights. This method significantly reduces the computational overhead, achieving up to 12,000 times less than traditional fine-tuning while improving performance by an average of 30% on various benchmarks. DnD demonstrates strong cross-domain generalization, effectively adapting to new tasks without prior exposure to their data or labels.', title='Efficient Task-Specific Adaptation with Drag-and-Drop LLMs'))
[23.06.2025 04:27] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÔºåÁß∞‰∏∫ÊãñÊîæÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàDnDÔºâÔºåÂÆÉÈÄöËøáÊèêÁ§∫Êù°‰ª∂ÁîüÊàêÂèÇÊï∞ÔºåÊ∂àÈô§‰∫ÜÊØè‰∏™‰ªªÂä°ÁöÑËÆ≠ÁªÉÈúÄÊ±Ç„ÄÇDnD‰ΩøÁî®ËΩªÈáèÁ∫ßÊñáÊú¨ÁºñÁ†ÅÂô®Â∞ÜÊèêÁ§∫ÊâπÊ¨°ÊèêÁÇº‰∏∫Êù°‰ª∂ÂµåÂÖ•ÔºåÂπ∂ÈÄöËøáÁ∫ßËÅîË∂ÖÂç∑ÁßØËß£Á†ÅÂô®ËΩ¨Êç¢‰∏∫ÂÆåÊï¥ÁöÑLoRAÁü©Èòµ„ÄÇ‰∏é‰º†ÁªüÁöÑÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÁõ∏ÊØîÔºåDnDÂú®ÊÄßËÉΩ‰∏äÊúâÊòæËëóÊèêÂçáÔºåÂπ∂‰∏îÂú®Êú™ËßÅËøáÁöÑ‰ªªÂä°‰∏ä‰πüËÉΩ‰øùÊåÅËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåËØÅÊòé‰∫ÜÊèêÁ§∫Êù°‰ª∂ÂèÇÊï∞ÁîüÊàêÊòØÂø´ÈÄü‰∏ìÈó®ÂåñÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊúâÊïàÊõø‰ª£ÊñπÊ°à„ÄÇ","title":"ÊãñÊîæÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºöÈ´òÊïàÁöÑ‰ªªÂä°ÁâπÂÆöÂèÇÊï∞ÁîüÊàê"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÔºåÁß∞‰∏∫ÊãñÊîæÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàDnDÔºâÔºåÂÆÉÈÄöËøáÊèêÁ§∫Êù°‰ª∂ÁîüÊàêÂèÇÊï∞ÔºåÊ∂àÈô§‰∫ÜÊØè‰∏™‰ªªÂä°ÁöÑËÆ≠ÁªÉÈúÄÊ±Ç„ÄÇDnD‰ΩøÁî®ËΩªÈáèÁ∫ßÊñáÊú¨ÁºñÁ†ÅÂô®Â∞ÜÊèêÁ§∫ÊâπÊ¨°ÊèêÁÇº‰∏∫Êù°‰ª∂ÂµåÂÖ•ÔºåÂπ∂ÈÄöËøáÁ∫ßËÅîË∂ÖÂç∑ÁßØËß£Á†ÅÂô®ËΩ¨Êç¢‰∏∫ÂÆåÊï¥ÁöÑLoRAÁü©Èòµ„ÄÇ‰∏é‰º†ÁªüÁöÑÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÁõ∏ÊØîÔºåDnDÂú®ÊÄßËÉΩ‰∏äÊúâÊòæËëóÊèêÂçáÔºåÂπ∂‰∏îÂú®Êú™ËßÅËøáÁöÑ‰ªªÂä°‰∏ä‰πüËÉΩ‰øùÊåÅËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåËØÅÊòé‰∫ÜÊèêÁ§∫Êù°‰ª∂ÂèÇÊï∞ÁîüÊàêÊòØÂø´ÈÄü‰∏ìÈó®ÂåñÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊúâÊïàÊõø‰ª£ÊñπÊ°à„ÄÇ', title='ÊãñÊîæÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºöÈ´òÊïàÁöÑ‰ªªÂä°ÁâπÂÆöÂèÇÊï∞ÁîüÊàê'))
[23.06.2025 04:27] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#3d", "#cv"], "emoji": "üåê", "ru": {"title": "–ú–Ω–æ–≥–æ–ø–ª–æ—Å–∫–æ—Å—Ç–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: –º–æ—Å—Ç –º–µ–∂–¥—É 2D –∏ 3D –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞–Ω–æ—Ä–∞–º", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –ø–∞–Ω–æ—Ä–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–≥–æ–ø–ª–æ—Å–∫–æ—Å—Ç–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –¥–≤—É–º–µ—Ä–Ω—ã—Ö
[23.06.2025 04:27] Using data from previous issue: {"categories": ["#diffusion", "#3d"], "emoji": "üßä", "ru": {"title": "–ù–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å 3D-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—ã –∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ç–µ–∫—Å—Ç—É—Ä—ã", "desc": "Hunyuan3D 2.5 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏ –¥–ª—è 3D-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —É–ª—É—á—à–∞—é—â–∏–π —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–æ—Ä–º –∏ —Ç–µ–∫—Å—Ç—É—Ä. –ö–ª—é—á–µ–≤–æ–µ –Ω–æ–≤–æ–≤–≤–µ–¥–µ–Ω–∏–µ - –º–æ–¥–µ–ª—å LATTICE –¥–ª—è –≥–µ
[23.06.2025 04:27] Using data from previous issue: {"categories": ["#inference", "#video", "#diffusion", "#synthetic", "#dataset", "#games", "#training"], "emoji": "üéÆ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏–≥—Ä–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ", "desc": "Hunyuan-GameCraft - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–∏–¥–µ–æ –≤ –∏–≥—Ä–æ–≤—ã—Ö —Å—Ä–µ–¥–∞—Ö —Å –≤—ã—Å–æ–∫–æ–π –¥–∏
[23.06.2025 04:27] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#dataset", "#interpretability", "#alignment", "#training", "#benchmark"], "emoji": "üîç", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±–∑–æ—Ä–æ–≤ —Å —Ä–∞–∑–Ω—ã—Ö —Ç–æ—á–µ–∫ –∑—Ä–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü
[23.06.2025 04:27] Renaming data file.
[23.06.2025 04:27] Renaming previous data. hf_papers.json to ./d/2025-06-23.json
[23.06.2025 04:27] Saving new data file.
[23.06.2025 04:27] Generating page.
[23.06.2025 04:27] Renaming previous page.
[23.06.2025 04:27] Renaming previous data. index.html to ./d/2025-06-23.html
[23.06.2025 04:27] Writing result.
[23.06.2025 04:27] Renaming log file.
[23.06.2025 04:27] Renaming previous data. log.txt to ./logs/2025-06-23_last_log.txt
