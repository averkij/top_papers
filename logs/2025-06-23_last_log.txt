[23.06.2025 18:16] Read previous papers.
[23.06.2025 18:16] Generating top page (month).
[23.06.2025 18:16] Writing top page (month).
[23.06.2025 19:09] Read previous papers.
[23.06.2025 19:09] Get feed.
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16406
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16035
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16054
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09049
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17201
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16310
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17206
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.16504
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17218
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15745
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15442
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17213
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17202
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.15925
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.09930
[23.06.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2506.17113
[23.06.2025 19:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.06.2025 19:09] No deleted papers detected.
[23.06.2025 19:09] Downloading and parsing papers (pdf, html). Total: 16.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.16406.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.16406.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.16406.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.16035.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.16035.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.16035.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.16054.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.16054.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.16054.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.09049.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.09049.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.09049.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.17201.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.17201.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.17201.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.16310.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.16310.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.16310.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.17206.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.17206.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.17206.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.16504.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.16504.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.16504.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.17218.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.17218.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.17218.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.15745.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.15745.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.15745.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.15442.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.15442.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.15442.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.17213.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.17213.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.17213.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.17202.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.17202.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.17202.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.15925.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.15925.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.15925.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.09930.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.09930.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.09930.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2506.17113.
[23.06.2025 19:09] Extra JSON file exists (./assets/json/2506.17113.json), skip PDF parsing.
[23.06.2025 19:09] Paper image links file exists (./assets/img_data/2506.17113.json), skip HTML parsing.
[23.06.2025 19:09] Success.
[23.06.2025 19:09] Enriching papers with extra data.
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 0. Drag-and-Drop LLMs generate task-specific parameters through prompt-conditioned parameter generation, achieving significant efficiency gains and cross-domain generalization without per-task training.  					AI-generated summary 				 Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-ra...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 1. A novel multimodal document chunking approach using Large Multimodal Models (LMMs) enhances RAG performance by accurately processing complex PDF documents, including multi-page tables and embedded visuals.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) systems have revolutioniz...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 2. PAROAttention reorganizes visual attention patterns to enable efficient sparsification and quantization, reducing memory and computational costs with minimal impact on performance.  					AI-generated summary 				 In visual generation, the quadratic complexity of attention mechanisms results in high ...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 3. VIKI-Bench and VIKI-R provide a benchmark and framework for evaluating and improving visual-driven cooperation among diverse embodied agents using vision-language models and reinforcement learning.  					AI-generated summary 				 Coordinating multiple embodied agents in dynamic environments remains ...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 4. Hunyuan-GameCraft is a novel framework for high-dynamic interactive video generation in game environments that addresses limitations in dynamics, generality, and efficiency through unified input representation, hybrid history-conditioned training, and model distillation.  					AI-generated summary 	...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 5. A new TTS architecture improves accent accuracy and emotion recognition for Hindi and Indian English by integrating phoneme alignment, culture-sensitive emotion embeddings, and dynamic accent code switching.  					AI-generated summary 				 State-of-the-art text-to-speech (TTS) systems realize high n...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 6. Multi-plane synchronization extends 2D foundation models to 3D panorama generation, introducing DreamCube to achieve diverse appearances and accurate geometry.  					AI-generated summary 				 3D panorama synthesis is a promising yet challenging task that demands high-quality and diverse visual appea...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 7. Hunyuan3D 2.5, a suite of 3D diffusion models, advances shape and texture generation with a new LATTICE model and physical-based rendering in a multi-view architecture.  					AI-generated summary 				 In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 8. Mirage enhances vision-language models by integrating latent visual tokens into text decoding to improve multimodal reasoning without generating explicit images.  					AI-generated summary 				 Vision-language models (VLMs) excel at multimodal understanding, yet their text-only decoding forces them ...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 9. InfiniPot-V is a training-free, query-agnostic framework that compresses the key-value cache during video encoding to maintain a fixed memory cap for streaming video understanding, enhancing real-time performance and accuracy.  					AI-generated summary 				 Modern multimodal large language models (...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 10. The tutorial provides a comprehensive guide on using Hunyuan3D 2.1 for generating high-resolution, textured 3D models, covering data preparation, model architecture, training, evaluation, and deployment.  					AI-generated summary 				 3D AI-generated content (AIGC) is a passionate field that has si...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 11. InfGen, a unified next-token prediction model, enables stable long-term traffic simulation by interleaving closed-loop motion simulation and scene generation.  					AI-generated summary 				 An ideal traffic simulator replicates the realistic long-term point-to-point trip that a self-driving system ...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 12. A Y-shaped architecture, UniFork, balances shared learning and task specialization for unified image understanding and generation, outperforming conventional fully shared Transformer models.  					AI-generated summary 				 Unified image understanding and generation has emerged as a promising paradig...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 13. Reranking and preference tuning improve the quality of perspective summaries generated by LLMs, as measured by language model-based metrics that outperform traditional ones.  					AI-generated summary 				 Generating unbiased summaries in real-world settings such as political perspective summarizati...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 14. A unified benchmark suite evaluates Vision-Language-Action models' generalization and motor execution capabilities, highlighting the disparity between perceptual understanding and precise action execution.  					AI-generated summary 				 One promise that Vision-Language-Action (VLA) models hold over...
[23.06.2025 19:09] ********************************************************************************
[23.06.2025 19:09] Abstract 15. MEXA is a training-free framework that aggregates outputs from specialized expert models using a Large Reasoning Model for effective multimodal reasoning across various domains.  					AI-generated summary 				 Combining pre-trained expert models offers substantial potential for scalable multimodal r...
[23.06.2025 19:09] Read previous papers.
[23.06.2025 19:09] Generating reviews via LLM API.
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal", "#training", "#optimization"], "emoji": "🎭", "ru": {"title": "Революция в настройке ЯМ: быстрая адаптация без дополнительного обучения", "desc": "Статья представляет новый метод Drag-and-Drop LLMs (DnD) для эффективной настройки больших языковых м
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#dataset", "#long_context", "#optimization", "#rag", "#multimodal"], "emoji": "📄", "ru": {"title": "Умное разбиение документов для улучшения RAG-систем", "desc": "Предложен новый подход к разбиению сложных PDF-документов на фрагменты с использованием мультимодальных языковых моделей
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#optimization", "#cv", "#inference", "#architecture", "#video"], "emoji": "🔬", "ru": {"title": "Эффективное внимание: меньше вычислений, та же точность", "desc": "Статья представляет новый метод PAROAttention для оптимизации механизмов внимания в задачах генерации изображений и виде
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#games", "#rl", "#benchmark", "#cv"], "emoji": "🤖", "ru": {"title": "Визуальная кооперация агентов с помощью глубокого обучения", "desc": "VIKI-Bench представляет собой иерархический бенчмарк для оценки кооперации между воплощенными агентами с использованием
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#inference", "#video", "#diffusion", "#synthetic", "#dataset", "#games", "#training"], "emoji": "🎮", "ru": {"title": "Революция в генерации интерактивного игрового видео", "desc": "Hunyuan-GameCraft - это новая система для генерации интерактивного видео в игровых средах с высокой ди
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#low_resource", "#machine_translation", "#multilingual", "#audio"], "emoji": "🗣️", "ru": {"title": "Улучшение синтеза речи для индийских языков с учетом акцента и эмоций", "desc": "Статья представляет новую архитектуру синтеза речи (TTS) для хинди и индийского английского. Система и
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#3d", "#cv"], "emoji": "🌐", "ru": {"title": "Многоплоскостная синхронизация: мост между 2D и 3D в генерации панорам", "desc": "Эта статья представляет новый подход к генерации трехмерных панорам с использованием многоплоскостной синхронизации двумерных
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#diffusion", "#3d"], "emoji": "🧊", "ru": {"title": "Новый уровень 3D-генерации: точные формы и реалистичные текстуры", "desc": "Hunyuan3D 2.5 представляет собой набор моделей диффузии для 3D-генерации, улучшающий создание форм и текстур. Ключевое нововведение - модель LATTICE для ге
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#multimodal", "#rl", "#reasoning", "#games"], "emoji": "🧠", "ru": {"title": "Ментальные образы для ИИ: улучшение мультимодального мышления без генерации изображений", "desc": "Статья представляет новый подход под названием Mirage для улучшения мультимодальных языковых моделей. Mirag
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#training", "#multimodal", "#optimization", "#long_context", "#video"], "emoji": "🎥", "ru": {"title": "Эффективное сжатие кэша для потокового анализа видео без потери точности", "desc": "InfiniPot-V - это фреймворк для сжатия кэша ключ-значение при кодировании видео, не требующий об
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#training", "#3d", "#architecture", "#synthetic", "#games", "#data"], "emoji": "🎨", "ru": {"title": "Революция в 3D-моделировании: доступное руководство по Hunyuan3D 2.1", "desc": "Статья представляет собой подробное руководство по использованию Hunyuan3D 2.1 для генерации высококач
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#training", "#optimization", "#agents", "#open_source", "#video"], "emoji": "🚗", "ru": {"title": "InfGen: Революция в долгосрочном моделировании дорожного движения", "desc": "InfGen - это унифицированная модель предсказания следующего токена, которая позволяет проводить стабильное д
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#multimodal"], "emoji": "🍴", "ru": {"title": "UniFork: оптимальный баланс между общим обучением и специализацией задач", "desc": "UniFork - это новая Y-образная архитектура для объединенного понимания и генерации изображений. Она сочетает общие слои
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#dataset", "#interpretability", "#alignment", "#training", "#benchmark"], "emoji": "🔍", "ru": {"title": "Улучшение генерации обзоров с разных точек зрения с помощью ранжирования и настройки LLM", "desc": "Исследование посвящено улучшению качества генерац
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#cv", "#agi", "#optimization", "#survey", "#robotics", "#agents", "#benchmark", "#games"], "emoji": "🤖", "ru": {"title": "Разрыв между намерением и действием: оценка моделей VLA в робототехнике", "desc": "Статья представляет унифицированный набор тестов для оценки моделей Vision-Lan
[23.06.2025 19:09] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark"], "emoji": "🧠", "ru": {"title": "MEXA: Умное объединение экспертов для мультимодального ИИ", "desc": "MEXA - это фреймворк для мультимодального рассуждения, который не требует дополнительного обучения. Он агрегирует выходные данные специализи
[23.06.2025 19:09] Renaming data file.
[23.06.2025 19:09] Renaming previous data. hf_papers.json to ./d/2025-06-23.json
[23.06.2025 19:09] Saving new data file.
[23.06.2025 19:09] Generating page.
[23.06.2025 19:09] Renaming previous page.
[23.06.2025 19:09] Renaming previous data. index.html to ./d/2025-06-23.html
[23.06.2025 19:09] Writing result.
[23.06.2025 19:09] Renaming log file.
[23.06.2025 19:09] Renaming previous data. log.txt to ./logs/2025-06-23_last_log.txt
