[30.05.2025 06:17] Read previous papers.
[30.05.2025 06:17] Generating top page (month).
[30.05.2025 06:17] Writing top page (month).
[30.05.2025 07:12] Read previous papers.
[30.05.2025 07:12] Get feed.
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22653
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23762
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23693
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23747
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23604
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23716
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23621
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23380
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23419
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23660
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20088
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23359
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23606
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23585
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23559
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23416
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22961
[30.05.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.22914
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22421
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23735
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23758
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22618
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20755
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23754
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23742
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17818
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23745
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23625
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23253
[30.05.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.22765
[30.05.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.21114
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20282
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19286
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18087
[30.05.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.23761
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22943
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22126
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19360
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19236
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23646
[30.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20199
[30.05.2025 07:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[30.05.2025 07:12] No deleted papers detected.
[30.05.2025 07:12] Downloading and parsing papers (pdf, html). Total: 41.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22653.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22653.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22653.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23762.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23762.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23762.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23693.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23693.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23693.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23747.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23747.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23747.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23604.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23604.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23604.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23716.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23716.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23716.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23621.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23621.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23621.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23380.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23380.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23380.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23419.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23419.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23419.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23660.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23660.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23660.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.20088.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.20088.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.20088.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23359.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23359.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23359.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23606.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23606.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23606.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23585.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23585.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23585.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23559.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23559.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23559.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23416.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23416.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23416.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22961.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22961.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22961.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22914.
[30.05.2025 07:12] Downloading paper 2505.22914 from http://arxiv.org/pdf/2505.22914v1...
[30.05.2025 07:12] Extracting affiliations from text.
[30.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 2 ] . [ 1 4 1 9 2 2 . 5 0 5 2 : r cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning Maksim Kolodiazhnyi12* kolodiazhnyi@airi.net Denis Tarasov13* tarasov@airi.net Dmitrii Zhemchuzhnikov12 zhemchuzhnikov@airi.net Alexander Nikulin12 nikulin@airi.net Ilya Zisman1 zisman@airi.net Anna Vorontsova Anton Konushin12 konushin@airi.net Vladislav Kurenkov14 kurenkov@airi.net Danila Rukhovich 1AIRI Institute; 2Lomonosov Moscow State University; 3ETH Zurich; 4Innopolis University "
[30.05.2025 07:12] Response: ```python
["AIRI Institute", "Lomonosov Moscow State University", "ETH Zurich", "Innopolis University"]
```
[30.05.2025 07:12] Deleting PDF ./assets/pdf/2505.22914.pdf.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22421.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22421.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22421.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23735.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23735.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23735.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23758.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23758.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23758.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22618.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22618.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22618.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.20755.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.20755.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.20755.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23754.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23754.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23754.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23742.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23742.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23742.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.17818.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.17818.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.17818.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23745.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23745.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23745.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23625.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23625.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23625.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23253.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23253.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23253.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22765.
[30.05.2025 07:12] Downloading paper 2505.22765 from http://arxiv.org/pdf/2505.22765v1...
[30.05.2025 07:12] Extracting affiliations from text.
[30.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 2 ] . [ 1 5 6 7 2 2 . 5 0 5 2 : r StressTest: Can YOUR Speech LM Handle the Stress? Iddo Yosha Gallil Maimon Yossi Adi iddo.yosha@mail.huji.ac.il "
[30.05.2025 07:12] Response: []
[30.05.2025 07:12] Extracting affiliations from text.
[30.05.2025 07:12] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 2 ] . [ 1 5 6 7 2 2 . 5 0 5 2 : r StressTest: Can YOUR Speech LM Handle the Stress? Iddo Yosha Gallil Maimon Yossi Adiiddo.yosha@mail.huji.ac.ilSentence stress refers to emphasis, placed on specific words within spoken utterance to highlight or contrast an idea, or to introduce new information. It is often used to imply an underlying intention that is not explicitly stated. Recent advances in speech-aware language models (SLMs) have enabled direct processing of audio, allowing models to bypass transcription and access the full richness of the speech signal and perform audio reasoning tasks such as spoken question answering. Despite the crucial role of sentence stress in shaping meaning and speaker intent, it remains largely overlooked in evaluation and development of such models. In this work, we address this gap by introducing StressTest, benchmark specifically designed to evaluate models ability to distinguish between interpretations of spoken sentences based on the stress pattern. We assess the performance of several leading SLMs and find that, despite their overall capabilities, they perform poorly on such tasks. To overcome this limitation, we propose novel synthetic data generation pipeline, and create Stress-17k, training set that simulates change of meaning implied by stress variation. Then, we empirically show that optimizing models with this synthetic dataset aligns well with real-world recordings and enables effective finetuning of SLMs. Results suggest, that our finetuned model, StresSLM, significantly outperforms existing models on both sentence stress reasoning and detection tasks. Code, models, data, and audio samples - https://pages.cs.huji.ac.il/adiyoss-lab/stresstest.Large language models (LLMs) have revolutionized language processing, enabling new forms of human-computer interaction [Minaee et al., 2025; Grattafiori et al., 2024]. As the field advanced, researchers have started exploring the integration of other modalities into LLMs, aiming to enrich their understanding of the world [Carolan et al., 2024; Liu et al., 2023]. In particular, the incorporation of speech and audio into LLMs has gained notable traction, equipping models with the ability to listen, speak, and reason about audio [Arora et al., 2025; Ghosh et al., 2025; Maimon et al., 2025a]. An elementary approach of integrating speech into LLMs follows cascade paradigm [Ji et al., 2024], where audio is first transcribed by an automatic speech recognition (ASR) system, and the resulting text is then processed by language model. While effective to some extent, this approach falls short of capturing the full expressive range of spoken language. Speech carries rich paralinguistic cues such as emotion, speaker identity, and prosodic characteristics including pitch (f0), loudness, duration, timbre and rhythm, that are often lost in transcription [Wilson and Wharton, 2006; Van Heuven, 2018]. One key aspect of prosody is sentence stress, which refers to the emphasis placed on particular words or phrases within sentence to highlight an idea or to contrast another [Bolinger, 1972]. For example, Preprint. Under review. Figure 1: StressTest provides samples that can be understood differently based on different stress patterns. We consider both sentence stress detection (SSD) and sentence stress reasoning (SSR). StresSLM detects the stress and reasons about the intended meaning. consider the sentence didnt say she stole the money. Depending on which word is stressed, the sentence can express dramatically different meanings, despite its written-form remaining unchanged. Recent developments in Speech-aware LMs (SLMs) aim to address these limitations by enabling models to process audio directly, bypassing the need for explicit transcription and allowing them to access the full range of acoustic information [Arora et al., 2025]. State-of-the-art models in this space have demonstrated impressive performance across wide range of tasks, including audio question answering, automatic speech recognition, and emotion recognition [Chu et al., 2024; Tang et al., 2024]. Nevertheless, sentence stress has received limited attention in the evaluation and development of these models, despite its vital role in expressing the speakers intent and meaning. We argue that interpreting sentence stress requires the listener to reason about the intended meaning based on stress placement, which can often be inferred even without explicit context. In this work, we address this gap by introducing StressTest, comprehensive benchmark designed to evaluate models ability to distinguish spoken sentence meanings based on different stress patterns. We then evaluate leading SLMs on our benchmark to quantify their capacity for stress based reasoning. Additionally, we introduce novel synthetic dataset generation pipeline, which produces the Stress-17k dataset. We empirically show that finetuning model using Stress-17k leads to enhanced ability to detect and model sentence stress on real-world recordings. Through extensive empirical evaluation and ablation studies, we demonstrate that our finetuned model, StresSLM, significantly outperforms existing models in both stress detection and sentence stress reasoning, with minimal performance degradation on its original tasks. Our contributions: (i) We propose StressTest, novel benchmark for evaluating sentence stress understanding in SLMs; (ii) We analyze the performance of several leading models on this benchmark, and show that they fail to detect sentence stress and to reason about the underlying meaning, based on the stress pattern; (iii) Lastly, we propose synthetic data generation pipeline and demonstrate its effectiveness by finetuning leading SLM.Theoretical views of sentence stress. As described by Ladd [2008], theoretical accounts of sentence stress, can be broadly divided into two main perspectives. The first is the phonological view, which defines the notion of normal stress as the default prosodic pattern in an utterance. This view is formalized in the Nuclear Stress Rule [Chomsky and Halle, 1968], which assumes that sentence stress is determined by syntactic structure and does not necessarily convey special semantic intent. The second, views stress as semantic phenomenon that conveys the speakers intention. According to this perspective, stress can be flexibly assigned to any word in sentence to highlight its relative importance in the discourse. Such stress can signal new information,"
[30.05.2025 07:12] Mistral response. {"id": "5ae0742ee3424070b3046b8cefa10517", "object": "chat.completion", "created": 1748589133, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"The Hebrew University of Jerusalem\"]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1512, "total_tokens": 1527, "completion_tokens": 15}}
[30.05.2025 07:12] Response: ```python
["The Hebrew University of Jerusalem"]
```
[30.05.2025 07:12] Deleting PDF ./assets/pdf/2505.22765.pdf.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21114.
[30.05.2025 07:12] Downloading paper 2505.21114 from http://arxiv.org/pdf/2505.21114v1...
[30.05.2025 07:12] Extracting affiliations from text.
[30.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Shuai Wang 1 Zexian Li 2 Qipeng Zhang 2 Tianhui Song 1 Xubin Li 2 Tiezheng Ge 2 Bo Zheng 2 Limin Wang 1 3 5 2 0 2 7 2 ] . [ 1 4 1 1 1 2 . 5 0 5 2 : r Figure 1: Visualization of searched Solver Parameters of DDPM/VP and Rectified Flow. We limited the order of solver coefficients of the last two steps for 5/6 NFE. The left images show the absolute value of searched coefficients {cj }. The right image shows the searched timesteps of different NFE and fitted curves. "
[30.05.2025 07:12] Response: []
[30.05.2025 07:12] Extracting affiliations from text.
[30.05.2025 07:12] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Shuai Wang 1 Zexian Li 2 Qipeng Zhang 2 Tianhui Song 1 Xubin Li 2 Tiezheng Ge 2 Bo Zheng 2 Limin Wang 1 3 5 2 0 2 7 2 ] . [ 1 4 1 1 1 2 . 5 0 5 2 : r Figure 1: Visualization of searched Solver Parameters of DDPM/VP and Rectified Flow. We limited the order of solver coefficients of the last two steps for 5/6 NFE. The left images show the absolute value of searched coefficients {cj }. The right image shows the searched timesteps of different NFE and fitted curves.Diffusion models have demonstrated remarkable generation quality, but at the cost of numerous function evaluations. Advanced ODE-based solvers have recently been developed to mitigate the substantial computational demands of reverse-diffusion solving under limited sampling steps. However, these solvers, heavily inspired by Adams-like multistep methods, rely solely on t-related Lagrange interpolation. We show that t-related Lagrange interpolation is suboptimal for diffusion models and reveal compact search space comprised of time steps and solver coefficients. Building on our analysis, we propose novel differentiable solver search algorithm to identify more optimal solver. Equipped with the searched solver, rectified-flow models, e.g., SiT-XL/2 and FlowDCN-XL/2, achieve FID scores of 2.40 and 2.35, respectively, on ImageNet-256 256 with only 10 steps. Meanwhile, DDPM model, DiT-XL/2, reaches FID 1State Key Lab of Novel Software Technology, Nanjing Uni2Taobao & Tmall Group of Alibaba, versity, Nanjing, China. Hangzhou, China. 3Shanghai AI Lab, Shanghai, China.. Correspondence to: Limin Wang <lmwang@nju.edu.cn>. Proceedings of the 42 nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025 by the author(s). 1 score of 2.33 with only 10 steps. Notably, our searched solver significantly outperforms traditional solvers(even some distillation methods). Moreover, our searched solver demonstrates generality across various model architectures, resolutions, and model sizes. 1. Introduction Image generation is fundamental task in computer vision research, which aims at capturing the inherent data distribution of original image datasets and generating high-quality synthetic images through distribution sampling. Diffusion models (Ho et al., 2020; Song et al., 2020b; Karras et al., 2022; Liu et al., 2022; Lipman et al., 2022; Wang et al., 2025) have recently emerged as highly promising solutions to learn the underlying data distribution in image generation, outperforming GAN-based models (Brock et al., 2018; Sauer et al., 2022) and Auto-Regressive models (Chang et al., 2022) by significant margin. However, diffusion models necessitate numerous denoising steps during inference, which incur substantial computational cost, thereby limiting the widespread deployment of pre-trained diffusion models. To achieve fast diffusion sampling, the existing studies have explored two distinct approaches. Training-based techniques by distilling the fast ODE trajectory into the model parameters, thereby circumIn addition, solverventing redundant refinement steps. Differentiable Solver Search for Fast Diffusion Sampling based methods (Lu et al., 2023; Zhang & Chen, 2023; Song et al., 2020a) tackle the fast sampling problem by designing high-order numerical ODE solvers. For training-based acceleration, (Salimans & Ho, 2022) aligns the single-step student denoiser with the multi-step teacher output, thereby reducing inference burdens. The consistency model concept, introduced by (Song et al., 2023), directly teaches the model to produce consistent predictions at any arbitrary timesteps. Building upon (Song et al., 2023), subsequent works (Zheng et al., 2024; Kim et al., 2023; Wang et al., 2024a; Song et al., 2025) propose improved techniques to mitigate discreet errors in LCM training. Furthermore, (Lin et al., 2024; Kang et al., 2024; Yin et al., 2024; Zhou et al., 2024; Wang et al., 2023) leverage adversarial training and distribution matching to enhance the quality of generated samples. To improve the training efficiency of distribution matching. However, training-based methods introduce changes to the model parameters, resulting in an inability to fully exploit the pre-training performance. Solver-based methods rely heavily on the ODE formulation in the reverse-diffusion dynamics and hand-crafted multi-step solvers. (Lu et al., 2023; 2022) and (Zhang & Chen, 2023) point out the semi-linear structure of the diffusion ODE and propose an exponential integrator to tackle faster sampling in diffusion models. (Zhao et al., 2023) further enhances the sampling quality by borrowing the predictor-corrector structure. Thanks to the multistep-based ODE solver methods, high-quality samples can be generated within as few as 10 steps. To further improve efficiency, (Gao et al., 2023) tracks the backward error and determines the adaptive step. Moreover, (Karras et al., 2022; Lu et al., 2022) propose handcrafted timesteps scheduler to sample respaced timesteps. (Xue et al., 2024) argues that timesteps sampled in (Karras et al., 2022; Lu et al., 2022) are suboptimal, thus proposing an online optimization algorithm to find the optimal sampling timesteps for generation. Apart from timesteps optimization, (Shaul et al., 2023) learns specific path transition to improve the sampling efficiency. In contrast to training-based acceleration methods, solverbased approaches do not necessitate parameter adjustments and preserve the optimal performance of the pre-trained model. Moreover, solvers can be seamlessly applied to any arbitrary diffusion model trained with similar noise scheduler, offering high degree of flexibility and adaptability. This motivates us to investigate the generative capabilities of pre-trained diffusion models within limited steps from diffusion solver perspective. Current state-of-the-art diffusion solvers (Lu et al., 2023; Zhao et al., 2023) adopt Adams-like multi-step methods that use the Lagrange interpolation function to minimize integral errors. We argue that an optimal solver should be tailored to specific pre-trained denoising functions and their corresponding noise schedulers. In this paper, we explore solver-based methods for fast diffusion sampling by improving diffusion solvers using data-driven approaches without destroying the pre-training internality in diffusion models. Inspired by (Xue et al., 2024), we investigate the sources of error in the diffusion ODE and discover that the interpolation function"
[30.05.2025 07:12] Mistral response. {"id": "41e833f57c43482e88f70911cc56c778", "object": "chat.completion", "created": 1748589148, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"State Key Lab of Novel Software Technology, Nanjing University, Nanjing, China\",\n    \"Taobao & Tmall Group of Alibaba, Hangzhou, China\",\n    \"Shanghai AI Lab, Shanghai, China\"\n]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1780, "total_tokens": 1850, "completion_tokens": 70}}
[30.05.2025 07:12] Response: ```python
[
    "State Key Lab of Novel Software Technology, Nanjing University, Nanjing, China",
    "Taobao & Tmall Group of Alibaba, Hangzhou, China",
    "Shanghai AI Lab, Shanghai, China"
]
```
[30.05.2025 07:12] Deleting PDF ./assets/pdf/2505.21114.pdf.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.20282.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.20282.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.20282.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.19286.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.19286.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.19286.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.18087.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.18087.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.18087.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23761.
[30.05.2025 07:12] Downloading paper 2505.23761 from http://arxiv.org/pdf/2505.23761v1...
[30.05.2025 07:12] Failed to download and parse paper https://huggingface.co/papers/2505.23761: 'LTChar' object is not iterable
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22943.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22943.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22943.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22126.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22126.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22126.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.19360.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.19360.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.19360.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.19236.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.19236.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.19236.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.23646.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.23646.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.23646.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.20199.
[30.05.2025 07:12] Extra JSON file exists (./assets/json/2505.20199.json), skip PDF parsing.
[30.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.20199.json), skip HTML parsing.
[30.05.2025 07:12] Success.
[30.05.2025 07:12] Enriching papers with extra data.
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 0. LLMs exhibit robustness to reward noise during post-training and achieve high performance using reasoning pattern rewards (RPR) in conjunction with noisy reward models.  					AI-generated summary 				 Recent studies on post-training large language models (LLMs) for reasoning through reinforcement le...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 1. ZeroGUI is an online learning framework that uses Vision-Language Models for task generation and reward estimation, enhancing GUI Agents' performance with minimal human intervention.  					AI-generated summary 				 The rapid advancement of large Vision-Language Models (VLMs) has propelled the develo...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 2. A new benchmark, VF-Eval, evaluates the capabilities of MLLMs in interpreting AI-generated content videos across four tasks, highlighting challenges and demonstrating benefits in video generation through human feedback alignment.  					AI-generated summary 				 MLLMs have been widely studied for vid...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 3. Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced performance on 2D visual tasks. However, improving their spatial intelligence remains a challenge. Existing 3D MLLMs always rely on additional 3D or 2.5D data to incorporate spatial awareness, restricting the...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 4. EvoScale, an evolutionary and reinforcement learning-based method, enhances small language models' performance on real-world software engineering tasks by iteratively improving and refining outputs.  					AI-generated summary 				 Language models (LMs) perform well on standardized coding benchmarks ...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 5. AnySplat is a feed forward network that performs novel view synthesis without camera poses, using 3D Gaussian primitives and unified design for efficiency and quality across sparse and dense datasets.  					AI-generated summary 				 We introduce AnySplat, a feed forward network for novel view synthe...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 6. Two post-training strategies, distillation and RLVR, enable inference-time scaling in table reasoning tasks, resulting in a model (Table-R1-Zero) that matches GPT-4.1's performance using fewer parameters and shows strong generalization.  					AI-generated summary 				 In this work, we present the fi...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 7. UniRL is a self-improving post-training method for unified multimodal large language models that uses generated images as training data, enhancing both generation and understanding tasks without external data.  					AI-generated summary 				 Unified multimodal large language models such as Show-o an...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 8. The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 9. Diffusion via Autoregressive models (D-AR) recasts the image diffusion process as a standard autoregressive task, achieving high-quality image generation with consistent previews and layout control using a large language model backbone.  					AI-generated summary 				 This paper presents Diffusion v...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 10. A new automated method using concept-based vectors and a Hierarchical Multi-Domain Regression model improves preference explanations and predictions for large language models.  					AI-generated summary 				 Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and reward models, a...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 11. A new benchmark, VideoReasonBench, evaluates complex vision-centric video reasoning, finding that extended thinking budgets are crucial for improved performance compared to existing benchmarks.  					AI-generated summary 				 Recent studies have shown that long chain-of-thought (CoT) reasoning can s...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 12. Muddit, a unified discrete diffusion transformer, achieves fast and high-quality generation across text and image modalities by integrating pretrained visual priors with a lightweight text decoder.  					AI-generated summary 				 Unified generation models aim to handle diverse tasks across modalitie...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 13. Reinforcement learning algorithms are fundamental to align large language models with human preferences and to enhance their reasoning capabilities. However, current reinforcement learning algorithms often suffer from training instability due to loose on-policy constraints and computational ineffici...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 14. SafeScientist is an AI framework that enhances safety in AI-driven scientific research through multiple defensive mechanisms and is validated using the SciSafetyBench benchmark.  					AI-generated summary 				 Recent advancements in large language model (LLM) agents have significantly accelerated sc...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 15. Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces KVzip, a query-agnostic KV cache eviction method enabli...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 16. ToMAP enhances LLM persuaders with Theory of Mind modules, improving opponent awareness and argument quality.  					AI-generated summary 				 Large language models (LLMs) have shown promising potential in persuasion, but existing works on training LLM persuaders are still preliminary. Notably, while...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 17. A multi-modal CAD reconstruction model leveraging vision-language models and reinforcement learning achieves state-of-the-art performance across various datasets, including real-world ones.  					AI-generated summary 				 Computer-Aided Design (CAD) plays a central role in engineering and manufactur...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 18. GeoDrive integrates robust 3D geometry into driving world models to improve spatial understanding and action controllability in autonomous navigation, enhancing safety and reliability.  					AI-generated summary 				 Recent advancements in world models have revolutionized dynamic environment simulat...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 19. Transformers have been established as the most popular backbones in sequence modeling, mainly due to their effectiveness in in-context retrieval tasks and the ability to learn at scale. Their quadratic memory and time complexity, however, bound their applicability in longer sequences and so has moti...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 20. LoRAShop, a framework for multi-concept image editing with LoRA models, leverages spatially coherent feature activation in Flux-style diffusion transformers to achieve seamless integration of multiple subjects or styles while preserving global context and identity.  					AI-generated summary 				 We...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 21. A novel block-wise approximate KV Cache and confidence-aware parallel decoding strategy improve the inference speed of diffusion-based large language models without significant quality loss.  					AI-generated summary 				 Diffusion-based large language models (Diffusion LLMs) have shown promise for...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 22. Uni-Instruct unifies and enhances one-step diffusion distillation methods through a novel diffusion expansion theory, achieving state-of-the-art performance in unconditional and conditional image generation and text-to-3D generation.  					AI-generated summary 				 In this paper, we unify more than ...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 23. DeepTheorem enhances LLM theorem-proving through a large-scale natural language dataset and a tailored reinforcement learning strategy, achieving state-of-the-art results in informal theorem proving.  					AI-generated summary 				 Theorem proving serves as a major testbed for evaluating complex rea...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 24. Video generation has made substantial strides with the emergence of deep generative models, especially diffusion-based approaches. However, video generation based on multiple reference subjects still faces significant challenges in maintaining multi-subject consistency and ensuring high generation q...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 25. PatientSim generates diverse and realistic patient personas using clinical data to evaluate LLMs in medical dialogue settings.  					AI-generated summary 				 Doctor-patient consultations require multi-turn, context-aware communication tailored to diverse patient personas. Training or evaluating doc...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 26. TrustVLM enhances the reliability of Vision-Language Models by estimating prediction trustworthiness without retraining, improving misclassification detection in multimodal tasks.  					AI-generated summary 				 Vision-Language Models (VLMs) have demonstrated strong capabilities in aligning visual a...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 27. ZeroSep, a text-guided audio diffusion model, achieves zero-shot source separation through pre-trained models and text conditioning, outperforming supervised methods on various benchmarks.  					AI-generated summary 				 Audio source separation is fundamental for machines to understand complex acous...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 28. UniTEX generates high-quality, consistent 3D textures by using Texture Functions and adapting Diffusion Transformers directly from images and geometry without UV mapping.  					AI-generated summary 				 We present UniTEX, a novel two-stage 3D texture generation framework to create high-quality, cons...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 29. A StressTest benchmark and synthetic Stress17k dataset are introduced to improve speech-aware language models' ability to interpret sentence stress in spoken language.  					AI-generated summary 				 Sentence stress refers to emphasis, placed on specific words within a spoken utterance to highlight ...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 30. Researchers propose a novel differentiable solver search algorithm that optimizes the computational efficiency and quality of diffusion models for image generation tasks.  					AI-generated summary 				 Diffusion models have demonstrated remarkable generation quality but at the cost of numerous func...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 31. Entropy minimization with one sample and minimal optimization achieves significant performance improvements for large language models.  					AI-generated summary 				 We trained 13,440 large language models and found that entropy minimization requires only a single unlabeled data and 10 steps optimi...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 32. The study explores the structural patterns of knowledge in large language models from a graph perspective, uncovering knowledge homophily and developing models for graph machine learning to estimate entity knowledge.  					AI-generated summary 				 Large language models have been extensively studied...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 33. CheXStruct and CXReasonBench evaluate Large Vision-Language Models in clinical diagnosis by assessing structured reasoning, visual grounding, and generalization using the MIMIC-CXR-JPG dataset.  					AI-generated summary 				 Recent progress in Large Vision-Language Models (LVLMs) has enabled promis...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 34. Theoretical analysis of Direct Preference Optimization (DPO) reveals that log-ratio reward parameterization is optimal for learning target policy via preference optimization, linked to log-margin ordered policies, and explains policy reinforcement and smoothing based on differential information entr...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 35. A benchmark using deceptive text samples to evaluate compositional vulnerabilities in multimodal representations is introduced, and a self-training approach improves zero-shot methods by enhancing attack success and sample diversity.  					AI-generated summary 				 While pre-trained multimodal repre...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 36. The introduction of SridBench, a benchmark for scientific figure generation, reveals that current top-tier models, such as GPT-4o-image, fall short in semantic and structural accuracy compared to human performance, underscoring the need for more advanced multimodal reasoning-driven visual generation...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 37. ChartLens enhances multimodal language models with fine-grained visual attributions, improving the accuracy of chart understanding by 26-66%.  					AI-generated summary 				 The growing capabilities of multimodal large language models (MLLMs) have advanced tasks like chart understanding. However, th...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 38. A novel pairwise-comparison framework using CreataSet dataset trains CrEval, an LLM-based evaluator that significantly improves the assessment of textual creativity aligned with human judgments.  					AI-generated summary 				 Creativity evaluation remains a challenging frontier for large language m...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 39. Large reasoning models exhibit varying susceptibility to hallucination depending on post-training pipelines, revealing critical cognitive behaviors and uncertainty misalignment as contributing factors.  					AI-generated summary 				 Recently evolved large reasoning models (LRMs) show powerful perfo...
[30.05.2025 07:12] ********************************************************************************
[30.05.2025 07:12] Abstract 40. Adaptive Classifier-Free Guidance (A-CFG) dynamically adjusts the guidance in masked diffusion language models by focusing on areas of low model confidence, leading to significant improvements in language generation performance.  					AI-generated summary 				 Classifier-Free Guidance (CFG) signific...
[30.05.2025 07:12] Read previous papers.
[30.05.2025 07:12] Generating reviews via LLM API.
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#rl", "#optimization", "#reasoning", "#training", "#rlhf"], "emoji": "", "ru": {"title": "LLM   :     ", "desc": " ,     (LLM)       
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#agents", "#rl", "#optimization", "#games", "#rlhf"], "emoji": "", "ru": {"title": "  -   ", "desc": "ZeroGUI -   -,  -       ,  
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#video", "#games", "#interpretability", "#benchmark", "#reasoning", "#alignment", "#rlhf"], "emoji": "", "ru": {"title": "VF-Eval:     -  ", "desc": "  VF-Eval      (MLLM)
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#3d", "#dataset", "#multimodal", "#architecture", "#reasoning", "#training"], "emoji": "", "ru": {"title": "   2D ", "desc": "  Spatial-MLLM -         2D   . 
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#small_models", "#rl", "#optimization", "#open_source", "#training"], "emoji": "", "ru": {"title": "       ", "desc": "EvoScale -  ,         
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "", "ru": {"title": "     ", "desc": "AnySplat -              .   3D  ,  
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#inference", "#rl", "#reasoning", "#dataset", "#training"], "emoji": "", "ru": {"title": "     ", "desc": "             
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#synthetic", "#open_source", "#multimodal", "#training", "#optimization"], "emoji": "", "ru": {"title": "  -   ", "desc": "UniRL -   -     ,  
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#benchmark", "#survey"], "emoji": "", "ru": {"title": "SWE-bench-Live:         ", "desc": "  SWE-bench-Live -           
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#open_source", "#multimodal", "#diffusion", "#cv", "#benchmark"], "emoji": "", "ru": {"title": "D-AR:    ", "desc": "      ,  Diffusion via Autoregres
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#dataset", "#data", "#interpretability", "#alignment", "#rlhf", "#training"], "emoji": "", "ru": {"title": "      ", "desc": "           
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#reasoning", "#video", "#multimodal", "#benchmark"], "emoji": "", "ru": {"title": "  -      ", "desc": "VideoReasonBench -           .     
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#architecture"], "emoji": "", "ru": {"title": "      ", "desc": "Muddit -     ,      
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#math", "#reasoning", "#alignment", "#rlhf"], "emoji": "", "ru": {"title": "OPO:        ", "desc": "         OPO (On-Poli
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#agents", "#healthcare", "#ethics", "#science", "#benchmark", "#open_source", "#security"], "emoji": "", "ru": {"title": " -:    ", "desc": "SafeScientist -    ,    
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#training", "#inference", "#long_context", "#optimization", "#reasoning"], "emoji": "", "ru": {"title": "KVzip:       ", "desc": "  KVzip -    - (KV)      
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#agents", "#rl", "#training", "#reasoning", "#alignment"], "emoji": "", "ru": {"title": "ToMAP: -   ", "desc": "  ToMAP -       -     . ToMAP 
[30.05.2025 07:12] Querying the API.
[30.05.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A multi-modal CAD reconstruction model leveraging vision-language models and reinforcement learning achieves state-of-the-art performance across various datasets, including real-world ones.  					AI-generated summary 				 Computer-Aided Design (CAD) plays a central role in engineering and manufacturing, making it possible to create precise and editable 3D models. Using a variety of sensor or user-provided data as inputs for CAD reconstruction can democratize access to design applications. However, existing methods typically focus on a single input modality, such as point clouds, images, or text, which limits their generalizability and robustness. Leveraging recent advances in vision-language models (VLM), we propose a multi-modal CAD reconstruction model that simultaneously processes all three input modalities. Inspired by large language model (LLM) training paradigms, we adopt a two-stage pipeline: supervised fine-tuning (SFT) on large-scale procedurally generated data, followed by reinforcement learning (RL) fine-tuning using online feedback, obtained programatically. Furthermore, we are the first to explore RL fine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such as Group Relative Preference Optimization (GRPO) outperform offline alternatives. In the DeepCAD benchmark, our SFT model outperforms existing single-modal approaches in all three input modalities simultaneously. More importantly, after RL fine-tuning, cadrille sets new state-of-the-art on three challenging datasets, including a real-world one.
[30.05.2025 07:12] Response: {
  "desc": "        CAD-,  -     .     ,   ,      .    :       ,      -   .  ,           ,  .",

  "emoji": "",

  "title": "  CAD:  ,     "
}
[30.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A multi-modal CAD reconstruction model leveraging vision-language models and reinforcement learning achieves state-of-the-art performance across various datasets, including real-world ones.  					AI-generated summary 				 Computer-Aided Design (CAD) plays a central role in engineering and manufacturing, making it possible to create precise and editable 3D models. Using a variety of sensor or user-provided data as inputs for CAD reconstruction can democratize access to design applications. However, existing methods typically focus on a single input modality, such as point clouds, images, or text, which limits their generalizability and robustness. Leveraging recent advances in vision-language models (VLM), we propose a multi-modal CAD reconstruction model that simultaneously processes all three input modalities. Inspired by large language model (LLM) training paradigms, we adopt a two-stage pipeline: supervised fine-tuning (SFT) on large-scale procedurally generated data, followed by reinforcement learning (RL) fine-tuning using online feedback, obtained programatically. Furthermore, we are the first to explore RL fine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such as Group Relative Preference Optimization (GRPO) outperform offline alternatives. In the DeepCAD benchmark, our SFT model outperforms existing single-modal approaches in all three input modalities simultaneously. More importantly, after RL fine-tuning, cadrille sets new state-of-the-art on three challenging datasets, including a real-world one."

[30.05.2025 07:12] Response: ```python
['MULTIMODAL', 'RL', 'BENCHMARK', '3D', 'TRAINING']
```
[30.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A multi-modal CAD reconstruction model leveraging vision-language models and reinforcement learning achieves state-of-the-art performance across various datasets, including real-world ones.  					AI-generated summary 				 Computer-Aided Design (CAD) plays a central role in engineering and manufacturing, making it possible to create precise and editable 3D models. Using a variety of sensor or user-provided data as inputs for CAD reconstruction can democratize access to design applications. However, existing methods typically focus on a single input modality, such as point clouds, images, or text, which limits their generalizability and robustness. Leveraging recent advances in vision-language models (VLM), we propose a multi-modal CAD reconstruction model that simultaneously processes all three input modalities. Inspired by large language model (LLM) training paradigms, we adopt a two-stage pipeline: supervised fine-tuning (SFT) on large-scale procedurally generated data, followed by reinforcement learning (RL) fine-tuning using online feedback, obtained programatically. Furthermore, we are the first to explore RL fine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such as Group Relative Preference Optimization (GRPO) outperform offline alternatives. In the DeepCAD benchmark, our SFT model outperforms existing single-modal approaches in all three input modalities simultaneously. More importantly, after RL fine-tuning, cadrille sets new state-of-the-art on three challenging datasets, including a real-world one."

[30.05.2025 07:12] Response: ```python
["OPTIMIZATION", "GAMES"]
```
[30.05.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a multi-modal Computer-Aided Design (CAD) reconstruction model that integrates vision-language models and reinforcement learning to enhance performance across various datasets. Unlike traditional methods that rely on a single input type, this model processes point clouds, images, and text simultaneously, improving its versatility and robustness. The authors employ a two-stage training approach, starting with supervised fine-tuning on large datasets, followed by reinforcement learning to refine the model using real-time feedback. Their results show that this innovative approach achieves state-of-the-art performance, particularly in challenging real-world scenarios, surpassing existing single-modal techniques.","title":"Revolutionizing CAD with Multi-Modal Learning and Reinforcement Techniques"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a multi-modal Computer-Aided Design (CAD) reconstruction model that integrates vision-language models and reinforcement learning to enhance performance across various datasets. Unlike traditional methods that rely on a single input type, this model processes point clouds, images, and text simultaneously, improving its versatility and robustness. The authors employ a two-stage training approach, starting with supervised fine-tuning on large datasets, followed by reinforcement learning to refine the model using real-time feedback. Their results show that this innovative approach achieves state-of-the-art performance, particularly in challenging real-world scenarios, surpassing existing single-modal techniques.', title='Revolutionizing CAD with Multi-Modal Learning and Reinforcement Techniques'))
[30.05.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CAD-DeepCAD","title":"CAD"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CAD-DeepCAD', title='CAD'))
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#games", "#agents", "#3d", "#training"], "emoji": "", "ru": {"title": "GeoDrive: 3D-    ", "desc": "GeoDrive -         ,    3D-  
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#long_context", "#benchmark"], "emoji": "", "ru": {"title": "ATLAS:     ", "desc": "  ATLAS -       . ATLAS    
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#story_generation", "#diffusion"], "emoji": "", "ru": {"title": "     ", "desc": "LoRAShop -              LoRA.   
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization", "#diffusion"], "emoji": "", "ru": {"title": "     ", "desc": "          .     KV-
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#3d", "#transfer_learning", "#cv", "#diffusion", "#dataset", "#math", "#optimization", "#benchmark"], "emoji": "", "ru": {"title": "Uni-Instruct:      ", "desc": "  Uni-Instruct -     
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#math", "#rl", "#training", "#reasoning", "#benchmark", "#dataset"], "emoji": "", "ru": {"title": "        ", "desc": "DeepTheorem -          
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#video", "#diffusion", "#benchmark", "#open_source"], "emoji": "", "ru": {"title": "MAGREF:       ", "desc": "  MAGREF -             
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#open_source", "#training", "#healthcare", "#dataset", "#science"], "emoji": "", "ru": {"title": "       ", "desc": "PatientSim -  ,          
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal", "#interpretability", "#benchmark", "#architecture", "#security"], "emoji": "", "ru": {"title": "     ", "desc": "TrustVLM -         
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#transfer_learning", "#audio", "#benchmark", "#diffusion"], "emoji": "", "ru": {"title": "       ", "desc": "ZeroSep -       ,  .   
[30.05.2025 07:12] Using data from previous issue: {"categories": ["#3d", "#open_source", "#diffusion"], "emoji": "", "ru": {"title": "  3D-: UniTEX     ", "desc": "UniTEX -          3D-.  
[30.05.2025 07:12] Querying the API.
[30.05.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A StressTest benchmark and synthetic Stress17k dataset are introduced to improve speech-aware language models' ability to interpret sentence stress in spoken language.  					AI-generated summary 				 Sentence stress refers to emphasis, placed on specific words within a spoken utterance to highlight or contrast an idea, or to introduce new information. It is often used to imply an underlying intention that is not explicitly stated. Recent advances in speech-aware language models (SLMs) have enabled direct processing of audio, allowing models to bypass transcription and access the full richness of the speech signal and perform audio reasoning tasks such as spoken question answering. Despite the crucial role of sentence stress in shaping meaning and speaker intent, it remains largely overlooked in evaluation and development of such models. In this work, we address this gap by introducing StressTest, a benchmark specifically designed to evaluate a model's ability to distinguish between interpretations of spoken sentences based on the stress pattern. We assess the performance of several leading SLMs and find that, despite their overall capabilities, they perform poorly on such tasks. To overcome this limitation, we propose a novel synthetic data generation pipeline, and create Stress17k, a training set that simulates change of meaning implied by stress variation. Then, we empirically show that optimizing models with this synthetic dataset aligns well with real-world recordings and enables effective finetuning of SLMs. Results suggest, that our finetuned model, StresSLM, significantly outperforms existing models on both sentence stress reasoning and detection tasks. Code, models, data, and audio samples - pages.cs.huji.ac.il/adiyoss-lab/stresstest.
[30.05.2025 07:12] Response: {
  "desc": "  StressTest     Stress17k            .  ,       ,    ,     .              Stress17k,      .   StresSLM           .",
  "emoji": "",
  "title": "        -"
}
[30.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A StressTest benchmark and synthetic Stress17k dataset are introduced to improve speech-aware language models' ability to interpret sentence stress in spoken language.  					AI-generated summary 				 Sentence stress refers to emphasis, placed on specific words within a spoken utterance to highlight or contrast an idea, or to introduce new information. It is often used to imply an underlying intention that is not explicitly stated. Recent advances in speech-aware language models (SLMs) have enabled direct processing of audio, allowing models to bypass transcription and access the full richness of the speech signal and perform audio reasoning tasks such as spoken question answering. Despite the crucial role of sentence stress in shaping meaning and speaker intent, it remains largely overlooked in evaluation and development of such models. In this work, we address this gap by introducing StressTest, a benchmark specifically designed to evaluate a model's ability to distinguish between interpretations of spoken sentences based on the stress pattern. We assess the performance of several leading SLMs and find that, despite their overall capabilities, they perform poorly on such tasks. To overcome this limitation, we propose a novel synthetic data generation pipeline, and create Stress17k, a training set that simulates change of meaning implied by stress variation. Then, we empirically show that optimizing models with this synthetic dataset aligns well with real-world recordings and enables effective finetuning of SLMs. Results suggest, that our finetuned model, StresSLM, significantly outperforms existing models on both sentence stress reasoning and detection tasks. Code, models, data, and audio samples - pages.cs.huji.ac.il/adiyoss-lab/stresstest."

[30.05.2025 07:12] Response: ```python
['DATASET', 'BENCHMARK', 'AUDIO', 'TRAINING']
```
[30.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A StressTest benchmark and synthetic Stress17k dataset are introduced to improve speech-aware language models' ability to interpret sentence stress in spoken language.  					AI-generated summary 				 Sentence stress refers to emphasis, placed on specific words within a spoken utterance to highlight or contrast an idea, or to introduce new information. It is often used to imply an underlying intention that is not explicitly stated. Recent advances in speech-aware language models (SLMs) have enabled direct processing of audio, allowing models to bypass transcription and access the full richness of the speech signal and perform audio reasoning tasks such as spoken question answering. Despite the crucial role of sentence stress in shaping meaning and speaker intent, it remains largely overlooked in evaluation and development of such models. In this work, we address this gap by introducing StressTest, a benchmark specifically designed to evaluate a model's ability to distinguish between interpretations of spoken sentences based on the stress pattern. We assess the performance of several leading SLMs and find that, despite their overall capabilities, they perform poorly on such tasks. To overcome this limitation, we propose a novel synthetic data generation pipeline, and create Stress17k, a training set that simulates change of meaning implied by stress variation. Then, we empirically show that optimizing models with this synthetic dataset aligns well with real-world recordings and enables effective finetuning of SLMs. Results suggest, that our finetuned model, StresSLM, significantly outperforms existing models on both sentence stress reasoning and detection tasks. Code, models, data, and audio samples - pages.cs.huji.ac.il/adiyoss-lab/stresstest."

[30.05.2025 07:12] Response: ```python
['SYNTHETIC', 'OPTIMIZATION']
```
[30.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces the StressTest benchmark and the synthetic Stress17k dataset to enhance speech-aware language models\' understanding of sentence stress in spoken language. Sentence stress is crucial for conveying meaning and speaker intent, yet it has been largely ignored in the evaluation of these models. The authors evaluate several leading speech-aware language models and find that they struggle with tasks involving sentence stress interpretation. By training a model called StresSLM on the new dataset, the authors demonstrate significant improvements in both reasoning and detection of sentence stress, showcasing the importance of this feature in natural language processing.","title":"Enhancing Speech Models with Sentence Stress Understanding"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces the StressTest benchmark and the synthetic Stress17k dataset to enhance speech-aware language models' understanding of sentence stress in spoken language. Sentence stress is crucial for conveying meaning and speaker intent, yet it has been largely ignored in the evaluation of these models. The authors evaluate several leading speech-aware language models and find that they struggle with tasks involving sentence stress interpretation. By training a model called StresSLM on the new dataset, the authors demonstrate significant improvements in both reasoning and detection of sentence stress, showcasing the importance of this feature in natural language processing.", title='Enhancing Speech Models with Sentence Stress Understanding'))
[30.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"StressTestStress17kStressTestStress17k","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='StressTestStress17kStressTestStress17k', title=''))
[30.05.2025 07:13] Querying the API.
[30.05.2025 07:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Researchers propose a novel differentiable solver search algorithm that optimizes the computational efficiency and quality of diffusion models for image generation tasks.  					AI-generated summary 				 Diffusion models have demonstrated remarkable generation quality but at the cost of numerous function evaluations. Recently, advanced ODE-based solvers have been developed to mitigate the substantial computational demands of reverse-diffusion solving under limited sampling steps. However, these solvers, heavily inspired by Adams-like multistep methods, rely solely on t-related Lagrange interpolation. We show that t-related Lagrange interpolation is suboptimal for diffusion model and reveal a compact search space comprised of time steps and solver coefficients. Building on our analysis, we propose a novel differentiable solver search algorithm to identify more optimal solver. Equipped with the searched solver, rectified-flow models, e.g., SiT-XL/2 and FlowDCN-XL/2, achieve FID scores of 2.40 and 2.35, respectively, on ImageNet256 with only 10 steps. Meanwhile, DDPM model, DiT-XL/2, reaches a FID score of 2.33 with only 10 steps. Notably, our searched solver outperforms traditional solvers by a significant margin. Moreover, our searched solver demonstrates generality across various model architectures, resolutions, and model sizes.
[30.05.2025 07:13] Response: {
  "desc": "                  .  ,   ,   ,    ,     ,       .       ,     .        ,    .",
  "emoji": "",
  "title": "      "
}
[30.05.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers propose a novel differentiable solver search algorithm that optimizes the computational efficiency and quality of diffusion models for image generation tasks.  					AI-generated summary 				 Diffusion models have demonstrated remarkable generation quality but at the cost of numerous function evaluations. Recently, advanced ODE-based solvers have been developed to mitigate the substantial computational demands of reverse-diffusion solving under limited sampling steps. However, these solvers, heavily inspired by Adams-like multistep methods, rely solely on t-related Lagrange interpolation. We show that t-related Lagrange interpolation is suboptimal for diffusion model and reveal a compact search space comprised of time steps and solver coefficients. Building on our analysis, we propose a novel differentiable solver search algorithm to identify more optimal solver. Equipped with the searched solver, rectified-flow models, e.g., SiT-XL/2 and FlowDCN-XL/2, achieve FID scores of 2.40 and 2.35, respectively, on ImageNet256 with only 10 steps. Meanwhile, DDPM model, DiT-XL/2, reaches a FID score of 2.33 with only 10 steps. Notably, our searched solver outperforms traditional solvers by a significant margin. Moreover, our searched solver demonstrates generality across various model architectures, resolutions, and model sizes."

[30.05.2025 07:13] Response: ```python
['DATA', 'CV', 'ARCHITECTURE', 'TRAINING']
```
[30.05.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers propose a novel differentiable solver search algorithm that optimizes the computational efficiency and quality of diffusion models for image generation tasks.  					AI-generated summary 				 Diffusion models have demonstrated remarkable generation quality but at the cost of numerous function evaluations. Recently, advanced ODE-based solvers have been developed to mitigate the substantial computational demands of reverse-diffusion solving under limited sampling steps. However, these solvers, heavily inspired by Adams-like multistep methods, rely solely on t-related Lagrange interpolation. We show that t-related Lagrange interpolation is suboptimal for diffusion model and reveal a compact search space comprised of time steps and solver coefficients. Building on our analysis, we propose a novel differentiable solver search algorithm to identify more optimal solver. Equipped with the searched solver, rectified-flow models, e.g., SiT-XL/2 and FlowDCN-XL/2, achieve FID scores of 2.40 and 2.35, respectively, on ImageNet256 with only 10 steps. Meanwhile, DDPM model, DiT-XL/2, reaches a FID score of 2.33 with only 10 steps. Notably, our searched solver outperforms traditional solvers by a significant margin. Moreover, our searched solver demonstrates generality across various model architectures, resolutions, and model sizes."

[30.05.2025 07:13] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[30.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new algorithm for optimizing solver efficiency in diffusion models used for generating images. The authors identify that traditional t-related Lagrange interpolation methods are not the best choice for these models, leading to a compact search space for time steps and solver coefficients. They propose a differentiable solver search algorithm that finds more effective solvers, resulting in improved image generation quality with fewer computational steps. The new solvers significantly enhance performance across different model architectures and sizes, achieving lower FID scores compared to conventional methods.","title":"Optimizing Diffusion Models with a Smart Solver Search"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a new algorithm for optimizing solver efficiency in diffusion models used for generating images. The authors identify that traditional t-related Lagrange interpolation methods are not the best choice for these models, leading to a compact search space for time steps and solver coefficients. They propose a differentiable solver search algorithm that finds more effective solvers, resulting in improved image generation quality with fewer computational steps. The new solvers significantly enhance performance across different model architectures and sizes, achieving lower FID scores compared to conventional methods.', title='Optimizing Diffusion Models with a Smart Solver Search'))
[30.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='', title=''))
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training"], "emoji": "", "ru": {"title": "    :     ", "desc": " ,            
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#data", "#interpretability", "#graphs", "#architecture", "#dataset", "#reasoning", "#benchmark", "#training"], "emoji": "", "ru": {"title": "       ", "desc": "       
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#healthcare", "#dataset", "#science", "#multimodal", "#cv", "#benchmark", "#interpretability", "#reasoning"], "emoji": "", "ru": {"title": "    :    ", "desc": "CheXStruct  CXReasonBench -     
[30.05.2025 07:13] Querying the API.
[30.05.2025 07:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Theoretical analysis of Direct Preference Optimization (DPO) reveals that log-ratio reward parameterization is optimal for learning target policy via preference optimization, linked to log-margin ordered policies, and explains policy reinforcement and smoothing based on differential information entropy.  					AI-generated summary 				 Direct Preference Optimization (DPO) has become a standard technique for aligning language models with human preferences in a supervised manner. Despite its empirical success, the theoretical justification behind its log-ratio reward parameterization remains incomplete. In this work, we address this gap by utilizing the Differential Information Distribution (DID): a distribution over token sequences that captures the information gained during policy updates. First, we show that when preference labels encode the differential information required to transform a reference policy into a target policy, the log-ratio reward in DPO emerges as the uniquely optimal form for learning the target policy via preference optimization. This result naturally yields a closed-form expression for the optimal sampling distribution over rejected responses. Second, we find that the condition for preferences to encode differential information is fundamentally linked to an implicit assumption regarding log-margin ordered policies-an inductive bias widely used in preference optimization yet previously unrecognized. Finally, by analyzing the entropy of the DID, we characterize how learning low-entropy differential information reinforces the policy distribution, while high-entropy differential information induces a smoothing effect, which explains the log-likelihood displacement phenomenon. We validate our theoretical findings in synthetic experiments and extend them to real-world instruction-following datasets. Our results suggest that learning high-entropy differential information is crucial for general instruction-following, while learning low-entropy differential information benefits knowledge-intensive question answering. Overall, our work presents a unifying perspective on the DPO objective, the structure of preference data, and resulting policy behaviors through the lens of differential information.
[30.05.2025 07:13] Response: {
  "desc": "      Direct Preference Optimization (DPO)    .  ,               .   DPO  ,    ,            .     ,         .",
  "emoji": "",
  "title": "  DPO    "
}
[30.05.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Theoretical analysis of Direct Preference Optimization (DPO) reveals that log-ratio reward parameterization is optimal for learning target policy via preference optimization, linked to log-margin ordered policies, and explains policy reinforcement and smoothing based on differential information entropy.  					AI-generated summary 				 Direct Preference Optimization (DPO) has become a standard technique for aligning language models with human preferences in a supervised manner. Despite its empirical success, the theoretical justification behind its log-ratio reward parameterization remains incomplete. In this work, we address this gap by utilizing the Differential Information Distribution (DID): a distribution over token sequences that captures the information gained during policy updates. First, we show that when preference labels encode the differential information required to transform a reference policy into a target policy, the log-ratio reward in DPO emerges as the uniquely optimal form for learning the target policy via preference optimization. This result naturally yields a closed-form expression for the optimal sampling distribution over rejected responses. Second, we find that the condition for preferences to encode differential information is fundamentally linked to an implicit assumption regarding log-margin ordered policies-an inductive bias widely used in preference optimization yet previously unrecognized. Finally, by analyzing the entropy of the DID, we characterize how learning low-entropy differential information reinforces the policy distribution, while high-entropy differential information induces a smoothing effect, which explains the log-likelihood displacement phenomenon. We validate our theoretical findings in synthetic experiments and extend them to real-world instruction-following datasets. Our results suggest that learning high-entropy differential information is crucial for general instruction-following, while learning low-entropy differential information benefits knowledge-intensive question answering. Overall, our work presents a unifying perspective on the DPO objective, the structure of preference data, and resulting policy behaviors through the lens of differential information."

[30.05.2025 07:13] Response: ```python
["RLHF", "TRAINING"]
```
[30.05.2025 07:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Theoretical analysis of Direct Preference Optimization (DPO) reveals that log-ratio reward parameterization is optimal for learning target policy via preference optimization, linked to log-margin ordered policies, and explains policy reinforcement and smoothing based on differential information entropy.  					AI-generated summary 				 Direct Preference Optimization (DPO) has become a standard technique for aligning language models with human preferences in a supervised manner. Despite its empirical success, the theoretical justification behind its log-ratio reward parameterization remains incomplete. In this work, we address this gap by utilizing the Differential Information Distribution (DID): a distribution over token sequences that captures the information gained during policy updates. First, we show that when preference labels encode the differential information required to transform a reference policy into a target policy, the log-ratio reward in DPO emerges as the uniquely optimal form for learning the target policy via preference optimization. This result naturally yields a closed-form expression for the optimal sampling distribution over rejected responses. Second, we find that the condition for preferences to encode differential information is fundamentally linked to an implicit assumption regarding log-margin ordered policies-an inductive bias widely used in preference optimization yet previously unrecognized. Finally, by analyzing the entropy of the DID, we characterize how learning low-entropy differential information reinforces the policy distribution, while high-entropy differential information induces a smoothing effect, which explains the log-likelihood displacement phenomenon. We validate our theoretical findings in synthetic experiments and extend them to real-world instruction-following datasets. Our results suggest that learning high-entropy differential information is crucial for general instruction-following, while learning low-entropy differential information benefits knowledge-intensive question answering. Overall, our work presents a unifying perspective on the DPO objective, the structure of preference data, and resulting policy behaviors through the lens of differential information."

[30.05.2025 07:13] Response: ```python
["ALIGNMENT", "OPTIMIZATION", "INTERPRETABILITY", "SYNTHETIC"]
```
[30.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper provides a theoretical analysis of Direct Preference Optimization (DPO), focusing on the log-ratio reward parameterization, which is shown to be optimal for learning target policies through preference optimization. It introduces the concept of Differential Information Distribution (DID), which captures the information gained during policy updates and links preference labels to the transformation of reference policies into target policies. The study reveals that the effectiveness of DPO is tied to log-margin ordered policies, an important but previously overlooked aspect of preference optimization. Additionally, it characterizes how different levels of entropy in differential information influence policy reinforcement and smoothing, offering insights into effective instruction-following and question answering tasks.","title":"Unlocking Optimal Learning with Differential Information in DPO"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper provides a theoretical analysis of Direct Preference Optimization (DPO), focusing on the log-ratio reward parameterization, which is shown to be optimal for learning target policies through preference optimization. It introduces the concept of Differential Information Distribution (DID), which captures the information gained during policy updates and links preference labels to the transformation of reference policies into target policies. The study reveals that the effectiveness of DPO is tied to log-margin ordered policies, an important but previously overlooked aspect of preference optimization. Additionally, it characterizes how different levels of entropy in differential information influence policy reinforcement and smoothing, offering insights into effective instruction-following and question answering tasks.', title='Unlocking Optimal Learning with Differential Information in DPO'))
[30.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DPODIDDPODID","title":""}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DPODIDDPODID', title=''))
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#hallucinations", "#multimodal", "#benchmark", "#security", "#training"], "emoji": "", "ru": {"title": "        ", "desc": "    Multimodal Adversarial Compositionality (MAC)   
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#benchmark", "#science", "#interpretability", "#multimodal", "#reasoning"], "emoji": "", "ru": {"title": "SridBench:      ", "desc": "SridBench -           .  
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#hallucinations", "#cv", "#benchmark"], "emoji": "", "ru": {"title": "     ChartLens", "desc": "ChartLens -          .   
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#creativity", "#dataset", "#open_source", "#data", "#benchmark"], "emoji": "", "ru": {"title": "CrEval:      ", "desc": "       ,    .  
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#training", "#rl", "#reasoning", "#hallucinations"], "emoji": "", "ru": {"title": "    :   ", "desc": "          (LRM)      
[30.05.2025 07:13] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#benchmark", "#training"], "emoji": "", "ru": {"title": "       ", "desc": "         (A-CFG)   
[30.05.2025 07:13] Loading Chinese text from previous data.
[30.05.2025 07:13] Renaming data file.
[30.05.2025 07:13] Renaming previous data. hf_papers.json to ./d/2025-05-30.json
[30.05.2025 07:13] Saving new data file.
[30.05.2025 07:13] Generating page.
[30.05.2025 07:13] Renaming previous page.
[30.05.2025 07:13] Renaming previous data. index.html to ./d/2025-05-30.html
[30.05.2025 07:13] [Experimental] Generating Chinese page for reading.
[30.05.2025 07:13] Chinese vocab [{'word': '', 'pinyin': 'zh zi', 'trans': 'aim to'}, {'word': '', 'pinyin': 'ji ju', 'trans': 'solve'}, {'word': '', 'pinyin': 'qing hu xu x', 'trans': 'reinforcement learning'}, {'word': '', 'pinyin': 'd y yn m xng', 'trans': 'large language model'}, {'word': '', 'pinyin': 'tu l', 'trans': 'reasoning'}, {'word': '', 'pinyin': 'zh yo', 'trans': 'major'}, {'word': '', 'pinyin': 'zhng i', 'trans': 'obstacle'}, {'word': '', 'pinyin': 'c l', 'trans': 'strategy'}, {'word': '', 'pinyin': 'shng', 'trans': 'entropy'}, {'word': '', 'pinyin': 'bng ku', 'trans': 'collapse'}, {'word': '', 'pinyin': 'yn ji', 'trans': 'research'}, {'word': '', 'pinyin': 'f xin', 'trans': 'discover'}, {'word': '', 'pinyin': 'gn y', 'trans': 'intervention'}, {'word': '', 'pinyin': 'qng kung', 'trans': 'situation'}, {'word': '', 'pinyin': 'ji dun', 'trans': 'stage'}, {'word': '', 'pinyin': 'j j', 'trans': 'drastic'}, {'word': '', 'pinyin': 'xi jing', 'trans': 'decline'}, {'word': '', 'pinyin': 'do zh', 'trans': 'lead to'}, {'word': '', 'pinyin': 'tn su', 'trans': 'exploration'}, {'word': '', 'pinyin': 'nng l', 'trans': 'ability'}, {'word': '', 'pinyin': 'jin ru', 'trans': 'weaken'}, {'word': '', 'pinyin': 'tng zh', 'trans': 'stagnate'}, {'word': '', 'pinyin': 'xng nng', 'trans': 'performance'}, {'word': '', 'pinyin': 't ch', 'trans': 'propose'}, {'word': '', 'pinyin': 'zhun hun', 'trans': 'conversion'}, {'word': '', 'pinyin': 'fng chng', 'trans': 'equation'}, {'word': '', 'pinyin': 'xi yu', 'trans': 'downstream'}, {'word': '', 'pinyin': 'l ln', 'trans': 'theory'}, {'word': '', 'pinyin': 'sh zhng', 'trans': 'empirical'}, {'word': '', 'pinyin': 'fn x', 'trans': 'analysis'}, {'word': '', 'pinyin': 'dng ti', 'trans': 'dynamics'}, {'word': '', 'pinyin': 'zu zhng', 'trans': 'ultimately'}, {'word': '', 'pinyin': 'j sh', 'trans': 'technique'}, {'word': '', 'pinyin': 'kng zh', 'trans': 'control'}, {'word': '', 'pinyin': 'sh yn', 'trans': 'experiment'}, {'word': '', 'pinyin': 'bio mng', 'trans': 'indicate'}, {'word': '', 'pinyin': 'fng f', 'trans': 'method'}, {'word': '', 'pinyin': 'c jn', 'trans': 'promote'}, {'word': '', 'pinyin': 'b min', 'trans': 'avoid'}, {'word': '', 'pinyin': 'sh xin', 'trans': 'achieve'}]
[30.05.2025 07:13] Renaming previous Chinese page.
[30.05.2025 07:13] Renaming previous data. zh.html to ./d/2025-05-29_zh_reading_task.html
[30.05.2025 07:13] Writing Chinese reading task.
[30.05.2025 07:13] Writing result.
[30.05.2025 07:13] Renaming log file.
[30.05.2025 07:13] Renaming previous data. log.txt to ./logs/2025-05-30_last_log.txt
